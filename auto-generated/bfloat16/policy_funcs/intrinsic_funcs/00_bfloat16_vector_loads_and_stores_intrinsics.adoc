
=== BFloat16 Vector Loads and Stores Intrinsics

[[policy-variant-bf16-vector-unit-stride-load]]
==== Vector Unit-Stride Load Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vle16_v_bf16mf4_tu(vbfloat16mf4_t vd, const __bf16 *rs1,
                                          size_t vl);
vbfloat16mf2_t __riscv_vle16_v_bf16mf2_tu(vbfloat16mf2_t vd, const __bf16 *rs1,
                                          size_t vl);
vbfloat16m1_t __riscv_vle16_v_bf16m1_tu(vbfloat16m1_t vd, const __bf16 *rs1,
                                        size_t vl);
vbfloat16m2_t __riscv_vle16_v_bf16m2_tu(vbfloat16m2_t vd, const __bf16 *rs1,
                                        size_t vl);
vbfloat16m4_t __riscv_vle16_v_bf16m4_tu(vbfloat16m4_t vd, const __bf16 *rs1,
                                        size_t vl);
vbfloat16m8_t __riscv_vle16_v_bf16m8_tu(vbfloat16m8_t vd, const __bf16 *rs1,
                                        size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vle16_v_bf16mf4_tum(vbool64_t vm, vbfloat16mf4_t vd,
                                           const __bf16 *rs1, size_t vl);
vbfloat16mf2_t __riscv_vle16_v_bf16mf2_tum(vbool32_t vm, vbfloat16mf2_t vd,
                                           const __bf16 *rs1, size_t vl);
vbfloat16m1_t __riscv_vle16_v_bf16m1_tum(vbool16_t vm, vbfloat16m1_t vd,
                                         const __bf16 *rs1, size_t vl);
vbfloat16m2_t __riscv_vle16_v_bf16m2_tum(vbool8_t vm, vbfloat16m2_t vd,
                                         const __bf16 *rs1, size_t vl);
vbfloat16m4_t __riscv_vle16_v_bf16m4_tum(vbool4_t vm, vbfloat16m4_t vd,
                                         const __bf16 *rs1, size_t vl);
vbfloat16m8_t __riscv_vle16_v_bf16m8_tum(vbool2_t vm, vbfloat16m8_t vd,
                                         const __bf16 *rs1, size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vle16_v_bf16mf4_tumu(vbool64_t vm, vbfloat16mf4_t vd,
                                            const __bf16 *rs1, size_t vl);
vbfloat16mf2_t __riscv_vle16_v_bf16mf2_tumu(vbool32_t vm, vbfloat16mf2_t vd,
                                            const __bf16 *rs1, size_t vl);
vbfloat16m1_t __riscv_vle16_v_bf16m1_tumu(vbool16_t vm, vbfloat16m1_t vd,
                                          const __bf16 *rs1, size_t vl);
vbfloat16m2_t __riscv_vle16_v_bf16m2_tumu(vbool8_t vm, vbfloat16m2_t vd,
                                          const __bf16 *rs1, size_t vl);
vbfloat16m4_t __riscv_vle16_v_bf16m4_tumu(vbool4_t vm, vbfloat16m4_t vd,
                                          const __bf16 *rs1, size_t vl);
vbfloat16m8_t __riscv_vle16_v_bf16m8_tumu(vbool2_t vm, vbfloat16m8_t vd,
                                          const __bf16 *rs1, size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vle16_v_bf16mf4_mu(vbool64_t vm, vbfloat16mf4_t vd,
                                          const __bf16 *rs1, size_t vl);
vbfloat16mf2_t __riscv_vle16_v_bf16mf2_mu(vbool32_t vm, vbfloat16mf2_t vd,
                                          const __bf16 *rs1, size_t vl);
vbfloat16m1_t __riscv_vle16_v_bf16m1_mu(vbool16_t vm, vbfloat16m1_t vd,
                                        const __bf16 *rs1, size_t vl);
vbfloat16m2_t __riscv_vle16_v_bf16m2_mu(vbool8_t vm, vbfloat16m2_t vd,
                                        const __bf16 *rs1, size_t vl);
vbfloat16m4_t __riscv_vle16_v_bf16m4_mu(vbool4_t vm, vbfloat16m4_t vd,
                                        const __bf16 *rs1, size_t vl);
vbfloat16m8_t __riscv_vle16_v_bf16m8_mu(vbool2_t vm, vbfloat16m8_t vd,
                                        const __bf16 *rs1, size_t vl);
----

[[policy-variant-bf16-vector-unit-stride-store]]
==== Vector Unit-Stride Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-strided-load]]
==== Vector Strided Load Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vlse16_v_bf16mf4_tu(vbfloat16mf4_t vd, const __bf16 *rs1,
                                           ptrdiff_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vlse16_v_bf16mf2_tu(vbfloat16mf2_t vd, const __bf16 *rs1,
                                           ptrdiff_t rs2, size_t vl);
vbfloat16m1_t __riscv_vlse16_v_bf16m1_tu(vbfloat16m1_t vd, const __bf16 *rs1,
                                         ptrdiff_t rs2, size_t vl);
vbfloat16m2_t __riscv_vlse16_v_bf16m2_tu(vbfloat16m2_t vd, const __bf16 *rs1,
                                         ptrdiff_t rs2, size_t vl);
vbfloat16m4_t __riscv_vlse16_v_bf16m4_tu(vbfloat16m4_t vd, const __bf16 *rs1,
                                         ptrdiff_t rs2, size_t vl);
vbfloat16m8_t __riscv_vlse16_v_bf16m8_tu(vbfloat16m8_t vd, const __bf16 *rs1,
                                         ptrdiff_t rs2, size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vlse16_v_bf16mf4_tum(vbool64_t vm, vbfloat16mf4_t vd,
                                            const __bf16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vbfloat16mf2_t __riscv_vlse16_v_bf16mf2_tum(vbool32_t vm, vbfloat16mf2_t vd,
                                            const __bf16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vbfloat16m1_t __riscv_vlse16_v_bf16m1_tum(vbool16_t vm, vbfloat16m1_t vd,
                                          const __bf16 *rs1, ptrdiff_t rs2,
                                          size_t vl);
vbfloat16m2_t __riscv_vlse16_v_bf16m2_tum(vbool8_t vm, vbfloat16m2_t vd,
                                          const __bf16 *rs1, ptrdiff_t rs2,
                                          size_t vl);
vbfloat16m4_t __riscv_vlse16_v_bf16m4_tum(vbool4_t vm, vbfloat16m4_t vd,
                                          const __bf16 *rs1, ptrdiff_t rs2,
                                          size_t vl);
vbfloat16m8_t __riscv_vlse16_v_bf16m8_tum(vbool2_t vm, vbfloat16m8_t vd,
                                          const __bf16 *rs1, ptrdiff_t rs2,
                                          size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vlse16_v_bf16mf4_tumu(vbool64_t vm, vbfloat16mf4_t vd,
                                             const __bf16 *rs1, ptrdiff_t rs2,
                                             size_t vl);
vbfloat16mf2_t __riscv_vlse16_v_bf16mf2_tumu(vbool32_t vm, vbfloat16mf2_t vd,
                                             const __bf16 *rs1, ptrdiff_t rs2,
                                             size_t vl);
vbfloat16m1_t __riscv_vlse16_v_bf16m1_tumu(vbool16_t vm, vbfloat16m1_t vd,
                                           const __bf16 *rs1, ptrdiff_t rs2,
                                           size_t vl);
vbfloat16m2_t __riscv_vlse16_v_bf16m2_tumu(vbool8_t vm, vbfloat16m2_t vd,
                                           const __bf16 *rs1, ptrdiff_t rs2,
                                           size_t vl);
vbfloat16m4_t __riscv_vlse16_v_bf16m4_tumu(vbool4_t vm, vbfloat16m4_t vd,
                                           const __bf16 *rs1, ptrdiff_t rs2,
                                           size_t vl);
vbfloat16m8_t __riscv_vlse16_v_bf16m8_tumu(vbool2_t vm, vbfloat16m8_t vd,
                                           const __bf16 *rs1, ptrdiff_t rs2,
                                           size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vlse16_v_bf16mf4_mu(vbool64_t vm, vbfloat16mf4_t vd,
                                           const __bf16 *rs1, ptrdiff_t rs2,
                                           size_t vl);
vbfloat16mf2_t __riscv_vlse16_v_bf16mf2_mu(vbool32_t vm, vbfloat16mf2_t vd,
                                           const __bf16 *rs1, ptrdiff_t rs2,
                                           size_t vl);
vbfloat16m1_t __riscv_vlse16_v_bf16m1_mu(vbool16_t vm, vbfloat16m1_t vd,
                                         const __bf16 *rs1, ptrdiff_t rs2,
                                         size_t vl);
vbfloat16m2_t __riscv_vlse16_v_bf16m2_mu(vbool8_t vm, vbfloat16m2_t vd,
                                         const __bf16 *rs1, ptrdiff_t rs2,
                                         size_t vl);
vbfloat16m4_t __riscv_vlse16_v_bf16m4_mu(vbool4_t vm, vbfloat16m4_t vd,
                                         const __bf16 *rs1, ptrdiff_t rs2,
                                         size_t vl);
vbfloat16m8_t __riscv_vlse16_v_bf16m8_mu(vbool2_t vm, vbfloat16m8_t vd,
                                         const __bf16 *rs1, ptrdiff_t rs2,
                                         size_t vl);
----

[[policy-variant-vector-strided-store]]
==== Vector Strided Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-indexed-load]]
==== Vector Indexed Load Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vloxei16_v_bf16mf4_tu(vbfloat16mf4_t vd,
                                             const __bf16 *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei16_v_bf16mf2_tu(vbfloat16mf2_t vd,
                                             const __bf16 *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei16_v_bf16m1_tu(vbfloat16m1_t vd, const __bf16 *rs1,
                                           vuint16m1_t rs2, size_t vl);
vbfloat16m2_t __riscv_vloxei16_v_bf16m2_tu(vbfloat16m2_t vd, const __bf16 *rs1,
                                           vuint16m2_t rs2, size_t vl);
vbfloat16m4_t __riscv_vloxei16_v_bf16m4_tu(vbfloat16m4_t vd, const __bf16 *rs1,
                                           vuint16m4_t rs2, size_t vl);
vbfloat16m8_t __riscv_vloxei16_v_bf16m8_tu(vbfloat16m8_t vd, const __bf16 *rs1,
                                           vuint16m8_t rs2, size_t vl);
vbfloat16mf4_t __riscv_vluxei16_v_bf16mf4_tu(vbfloat16mf4_t vd,
                                             const __bf16 *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei16_v_bf16mf2_tu(vbfloat16mf2_t vd,
                                             const __bf16 *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei16_v_bf16m1_tu(vbfloat16m1_t vd, const __bf16 *rs1,
                                           vuint16m1_t rs2, size_t vl);
vbfloat16m2_t __riscv_vluxei16_v_bf16m2_tu(vbfloat16m2_t vd, const __bf16 *rs1,
                                           vuint16m2_t rs2, size_t vl);
vbfloat16m4_t __riscv_vluxei16_v_bf16m4_tu(vbfloat16m4_t vd, const __bf16 *rs1,
                                           vuint16m4_t rs2, size_t vl);
vbfloat16m8_t __riscv_vluxei16_v_bf16m8_tu(vbfloat16m8_t vd, const __bf16 *rs1,
                                           vuint16m8_t rs2, size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vloxei16_v_bf16mf4_tum(vbool64_t vm, vbfloat16mf4_t vd,
                                              const __bf16 *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei16_v_bf16mf2_tum(vbool32_t vm, vbfloat16mf2_t vd,
                                              const __bf16 *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei16_v_bf16m1_tum(vbool16_t vm, vbfloat16m1_t vd,
                                            const __bf16 *rs1, vuint16m1_t rs2,
                                            size_t vl);
vbfloat16m2_t __riscv_vloxei16_v_bf16m2_tum(vbool8_t vm, vbfloat16m2_t vd,
                                            const __bf16 *rs1, vuint16m2_t rs2,
                                            size_t vl);
vbfloat16m4_t __riscv_vloxei16_v_bf16m4_tum(vbool4_t vm, vbfloat16m4_t vd,
                                            const __bf16 *rs1, vuint16m4_t rs2,
                                            size_t vl);
vbfloat16m8_t __riscv_vloxei16_v_bf16m8_tum(vbool2_t vm, vbfloat16m8_t vd,
                                            const __bf16 *rs1, vuint16m8_t rs2,
                                            size_t vl);
vbfloat16mf4_t __riscv_vluxei16_v_bf16mf4_tum(vbool64_t vm, vbfloat16mf4_t vd,
                                              const __bf16 *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei16_v_bf16mf2_tum(vbool32_t vm, vbfloat16mf2_t vd,
                                              const __bf16 *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei16_v_bf16m1_tum(vbool16_t vm, vbfloat16m1_t vd,
                                            const __bf16 *rs1, vuint16m1_t rs2,
                                            size_t vl);
vbfloat16m2_t __riscv_vluxei16_v_bf16m2_tum(vbool8_t vm, vbfloat16m2_t vd,
                                            const __bf16 *rs1, vuint16m2_t rs2,
                                            size_t vl);
vbfloat16m4_t __riscv_vluxei16_v_bf16m4_tum(vbool4_t vm, vbfloat16m4_t vd,
                                            const __bf16 *rs1, vuint16m4_t rs2,
                                            size_t vl);
vbfloat16m8_t __riscv_vluxei16_v_bf16m8_tum(vbool2_t vm, vbfloat16m8_t vd,
                                            const __bf16 *rs1, vuint16m8_t rs2,
                                            size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vloxei16_v_bf16mf4_tumu(vbool64_t vm, vbfloat16mf4_t vd,
                                               const __bf16 *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei16_v_bf16mf2_tumu(vbool32_t vm, vbfloat16mf2_t vd,
                                               const __bf16 *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei16_v_bf16m1_tumu(vbool16_t vm, vbfloat16m1_t vd,
                                             const __bf16 *rs1, vuint16m1_t rs2,
                                             size_t vl);
vbfloat16m2_t __riscv_vloxei16_v_bf16m2_tumu(vbool8_t vm, vbfloat16m2_t vd,
                                             const __bf16 *rs1, vuint16m2_t rs2,
                                             size_t vl);
vbfloat16m4_t __riscv_vloxei16_v_bf16m4_tumu(vbool4_t vm, vbfloat16m4_t vd,
                                             const __bf16 *rs1, vuint16m4_t rs2,
                                             size_t vl);
vbfloat16m8_t __riscv_vloxei16_v_bf16m8_tumu(vbool2_t vm, vbfloat16m8_t vd,
                                             const __bf16 *rs1, vuint16m8_t rs2,
                                             size_t vl);
vbfloat16mf4_t __riscv_vluxei16_v_bf16mf4_tumu(vbool64_t vm, vbfloat16mf4_t vd,
                                               const __bf16 *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei16_v_bf16mf2_tumu(vbool32_t vm, vbfloat16mf2_t vd,
                                               const __bf16 *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei16_v_bf16m1_tumu(vbool16_t vm, vbfloat16m1_t vd,
                                             const __bf16 *rs1, vuint16m1_t rs2,
                                             size_t vl);
vbfloat16m2_t __riscv_vluxei16_v_bf16m2_tumu(vbool8_t vm, vbfloat16m2_t vd,
                                             const __bf16 *rs1, vuint16m2_t rs2,
                                             size_t vl);
vbfloat16m4_t __riscv_vluxei16_v_bf16m4_tumu(vbool4_t vm, vbfloat16m4_t vd,
                                             const __bf16 *rs1, vuint16m4_t rs2,
                                             size_t vl);
vbfloat16m8_t __riscv_vluxei16_v_bf16m8_tumu(vbool2_t vm, vbfloat16m8_t vd,
                                             const __bf16 *rs1, vuint16m8_t rs2,
                                             size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vloxei16_v_bf16mf4_mu(vbool64_t vm, vbfloat16mf4_t vd,
                                             const __bf16 *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei16_v_bf16mf2_mu(vbool32_t vm, vbfloat16mf2_t vd,
                                             const __bf16 *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei16_v_bf16m1_mu(vbool16_t vm, vbfloat16m1_t vd,
                                           const __bf16 *rs1, vuint16m1_t rs2,
                                           size_t vl);
vbfloat16m2_t __riscv_vloxei16_v_bf16m2_mu(vbool8_t vm, vbfloat16m2_t vd,
                                           const __bf16 *rs1, vuint16m2_t rs2,
                                           size_t vl);
vbfloat16m4_t __riscv_vloxei16_v_bf16m4_mu(vbool4_t vm, vbfloat16m4_t vd,
                                           const __bf16 *rs1, vuint16m4_t rs2,
                                           size_t vl);
vbfloat16m8_t __riscv_vloxei16_v_bf16m8_mu(vbool2_t vm, vbfloat16m8_t vd,
                                           const __bf16 *rs1, vuint16m8_t rs2,
                                           size_t vl);
vbfloat16mf4_t __riscv_vluxei16_v_bf16mf4_mu(vbool64_t vm, vbfloat16mf4_t vd,
                                             const __bf16 *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei16_v_bf16mf2_mu(vbool32_t vm, vbfloat16mf2_t vd,
                                             const __bf16 *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei16_v_bf16m1_mu(vbool16_t vm, vbfloat16m1_t vd,
                                           const __bf16 *rs1, vuint16m1_t rs2,
                                           size_t vl);
vbfloat16m2_t __riscv_vluxei16_v_bf16m2_mu(vbool8_t vm, vbfloat16m2_t vd,
                                           const __bf16 *rs1, vuint16m2_t rs2,
                                           size_t vl);
vbfloat16m4_t __riscv_vluxei16_v_bf16m4_mu(vbool4_t vm, vbfloat16m4_t vd,
                                           const __bf16 *rs1, vuint16m4_t rs2,
                                           size_t vl);
vbfloat16m8_t __riscv_vluxei16_v_bf16m8_mu(vbool2_t vm, vbfloat16m8_t vd,
                                           const __bf16 *rs1, vuint16m8_t rs2,
                                           size_t vl);
----

[[policy-variant-vector-indexed-store]]
==== Vector Indexed Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-unit-stride-fault-only-first-loads]]
==== Unit-stride Fault-Only-First Loads Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vle16ff_v_bf16mf4_tu(vbfloat16mf4_t vd,
                                            const __bf16 *rs1, size_t *new_vl,
                                            size_t vl);
vbfloat16mf2_t __riscv_vle16ff_v_bf16mf2_tu(vbfloat16mf2_t vd,
                                            const __bf16 *rs1, size_t *new_vl,
                                            size_t vl);
vbfloat16m1_t __riscv_vle16ff_v_bf16m1_tu(vbfloat16m1_t vd, const __bf16 *rs1,
                                          size_t *new_vl, size_t vl);
vbfloat16m2_t __riscv_vle16ff_v_bf16m2_tu(vbfloat16m2_t vd, const __bf16 *rs1,
                                          size_t *new_vl, size_t vl);
vbfloat16m4_t __riscv_vle16ff_v_bf16m4_tu(vbfloat16m4_t vd, const __bf16 *rs1,
                                          size_t *new_vl, size_t vl);
vbfloat16m8_t __riscv_vle16ff_v_bf16m8_tu(vbfloat16m8_t vd, const __bf16 *rs1,
                                          size_t *new_vl, size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vle16ff_v_bf16mf4_tum(vbool64_t vm, vbfloat16mf4_t vd,
                                             const __bf16 *rs1, size_t *new_vl,
                                             size_t vl);
vbfloat16mf2_t __riscv_vle16ff_v_bf16mf2_tum(vbool32_t vm, vbfloat16mf2_t vd,
                                             const __bf16 *rs1, size_t *new_vl,
                                             size_t vl);
vbfloat16m1_t __riscv_vle16ff_v_bf16m1_tum(vbool16_t vm, vbfloat16m1_t vd,
                                           const __bf16 *rs1, size_t *new_vl,
                                           size_t vl);
vbfloat16m2_t __riscv_vle16ff_v_bf16m2_tum(vbool8_t vm, vbfloat16m2_t vd,
                                           const __bf16 *rs1, size_t *new_vl,
                                           size_t vl);
vbfloat16m4_t __riscv_vle16ff_v_bf16m4_tum(vbool4_t vm, vbfloat16m4_t vd,
                                           const __bf16 *rs1, size_t *new_vl,
                                           size_t vl);
vbfloat16m8_t __riscv_vle16ff_v_bf16m8_tum(vbool2_t vm, vbfloat16m8_t vd,
                                           const __bf16 *rs1, size_t *new_vl,
                                           size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vle16ff_v_bf16mf4_tumu(vbool64_t vm, vbfloat16mf4_t vd,
                                              const __bf16 *rs1, size_t *new_vl,
                                              size_t vl);
vbfloat16mf2_t __riscv_vle16ff_v_bf16mf2_tumu(vbool32_t vm, vbfloat16mf2_t vd,
                                              const __bf16 *rs1, size_t *new_vl,
                                              size_t vl);
vbfloat16m1_t __riscv_vle16ff_v_bf16m1_tumu(vbool16_t vm, vbfloat16m1_t vd,
                                            const __bf16 *rs1, size_t *new_vl,
                                            size_t vl);
vbfloat16m2_t __riscv_vle16ff_v_bf16m2_tumu(vbool8_t vm, vbfloat16m2_t vd,
                                            const __bf16 *rs1, size_t *new_vl,
                                            size_t vl);
vbfloat16m4_t __riscv_vle16ff_v_bf16m4_tumu(vbool4_t vm, vbfloat16m4_t vd,
                                            const __bf16 *rs1, size_t *new_vl,
                                            size_t vl);
vbfloat16m8_t __riscv_vle16ff_v_bf16m8_tumu(vbool2_t vm, vbfloat16m8_t vd,
                                            const __bf16 *rs1, size_t *new_vl,
                                            size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vle16ff_v_bf16mf4_mu(vbool64_t vm, vbfloat16mf4_t vd,
                                            const __bf16 *rs1, size_t *new_vl,
                                            size_t vl);
vbfloat16mf2_t __riscv_vle16ff_v_bf16mf2_mu(vbool32_t vm, vbfloat16mf2_t vd,
                                            const __bf16 *rs1, size_t *new_vl,
                                            size_t vl);
vbfloat16m1_t __riscv_vle16ff_v_bf16m1_mu(vbool16_t vm, vbfloat16m1_t vd,
                                          const __bf16 *rs1, size_t *new_vl,
                                          size_t vl);
vbfloat16m2_t __riscv_vle16ff_v_bf16m2_mu(vbool8_t vm, vbfloat16m2_t vd,
                                          const __bf16 *rs1, size_t *new_vl,
                                          size_t vl);
vbfloat16m4_t __riscv_vle16ff_v_bf16m4_mu(vbool4_t vm, vbfloat16m4_t vd,
                                          const __bf16 *rs1, size_t *new_vl,
                                          size_t vl);
vbfloat16m8_t __riscv_vle16ff_v_bf16m8_mu(vbool2_t vm, vbfloat16m8_t vd,
                                          const __bf16 *rs1, size_t *new_vl,
                                          size_t vl);
----
