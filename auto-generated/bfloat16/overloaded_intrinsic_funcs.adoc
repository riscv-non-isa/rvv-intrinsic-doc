
=== BFloat16 Vector Loads and Stores Intrinsics

[[overloaded-bf16-vector-unit-stride-load]]
==== Vector Unit-Stride Load Intrinsics

[,c]
----
// masked functions
vbfloat16mf4_t __riscv_vle16(vbool64_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf2_t __riscv_vle16(vbool32_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m1_t __riscv_vle16(vbool16_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m2_t __riscv_vle16(vbool8_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m4_t __riscv_vle16(vbool4_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m8_t __riscv_vle16(vbool2_t vm, const __bf16 *rs1, size_t vl);
----

[[overloaded-bf16-vector-unit-stride-store]]
==== Vector Unit-Stride Store Intrinsics

[,c]
----
void __riscv_vse16(__bf16 *rs1, vbfloat16mf4_t vs3, size_t vl);
void __riscv_vse16(__bf16 *rs1, vbfloat16mf2_t vs3, size_t vl);
void __riscv_vse16(__bf16 *rs1, vbfloat16m1_t vs3, size_t vl);
void __riscv_vse16(__bf16 *rs1, vbfloat16m2_t vs3, size_t vl);
void __riscv_vse16(__bf16 *rs1, vbfloat16m4_t vs3, size_t vl);
void __riscv_vse16(__bf16 *rs1, vbfloat16m8_t vs3, size_t vl);
// masked functions
void __riscv_vse16(vbool64_t vm, __bf16 *rs1, vbfloat16mf4_t vs3, size_t vl);
void __riscv_vse16(vbool32_t vm, __bf16 *rs1, vbfloat16mf2_t vs3, size_t vl);
void __riscv_vse16(vbool16_t vm, __bf16 *rs1, vbfloat16m1_t vs3, size_t vl);
void __riscv_vse16(vbool8_t vm, __bf16 *rs1, vbfloat16m2_t vs3, size_t vl);
void __riscv_vse16(vbool4_t vm, __bf16 *rs1, vbfloat16m4_t vs3, size_t vl);
void __riscv_vse16(vbool2_t vm, __bf16 *rs1, vbfloat16m8_t vs3, size_t vl);
----

[[overloaded-vector-strided-load]]
==== Vector Strided Load Intrinsics

[,c]
----
// masked functions
vbfloat16mf4_t __riscv_vlse16(vbool64_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                              size_t vl);
vbfloat16mf2_t __riscv_vlse16(vbool32_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                              size_t vl);
vbfloat16m1_t __riscv_vlse16(vbool16_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                             size_t vl);
vbfloat16m2_t __riscv_vlse16(vbool8_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                             size_t vl);
vbfloat16m4_t __riscv_vlse16(vbool4_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                             size_t vl);
vbfloat16m8_t __riscv_vlse16(vbool2_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                             size_t vl);
----

[[overloaded-vector-strided-store]]
==== Vector Strided Store Intrinsics

[,c]
----
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m1_t vs3, size_t vl);
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m2_t vs3, size_t vl);
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m4_t vs3, size_t vl);
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m8_t vs3, size_t vl);
// masked functions
void __riscv_vsse16(vbool64_t vm, __bf16 *rs1, ptrdiff_t rs2,
                    vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsse16(vbool32_t vm, __bf16 *rs1, ptrdiff_t rs2,
                    vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsse16(vbool16_t vm, __bf16 *rs1, ptrdiff_t rs2, vbfloat16m1_t vs3,
                    size_t vl);
void __riscv_vsse16(vbool8_t vm, __bf16 *rs1, ptrdiff_t rs2, vbfloat16m2_t vs3,
                    size_t vl);
void __riscv_vsse16(vbool4_t vm, __bf16 *rs1, ptrdiff_t rs2, vbfloat16m4_t vs3,
                    size_t vl);
void __riscv_vsse16(vbool2_t vm, __bf16 *rs1, ptrdiff_t rs2, vbfloat16m8_t vs3,
                    size_t vl);
----

[[overloaded-vector-indexed-load]]
==== Vector Indexed Load Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vloxei16(const __bf16 *rs1, vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei16(const __bf16 *rs1, vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei16(const __bf16 *rs1, vuint16m1_t rs2, size_t vl);
vbfloat16m2_t __riscv_vloxei16(const __bf16 *rs1, vuint16m2_t rs2, size_t vl);
vbfloat16m4_t __riscv_vloxei16(const __bf16 *rs1, vuint16m4_t rs2, size_t vl);
vbfloat16m8_t __riscv_vloxei16(const __bf16 *rs1, vuint16m8_t rs2, size_t vl);
vbfloat16mf4_t __riscv_vluxei16(const __bf16 *rs1, vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei16(const __bf16 *rs1, vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei16(const __bf16 *rs1, vuint16m1_t rs2, size_t vl);
vbfloat16m2_t __riscv_vluxei16(const __bf16 *rs1, vuint16m2_t rs2, size_t vl);
vbfloat16m4_t __riscv_vluxei16(const __bf16 *rs1, vuint16m4_t rs2, size_t vl);
vbfloat16m8_t __riscv_vluxei16(const __bf16 *rs1, vuint16m8_t rs2, size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vloxei16(vbool64_t vm, const __bf16 *rs1,
                                vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei16(vbool32_t vm, const __bf16 *rs1,
                                vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei16(vbool16_t vm, const __bf16 *rs1, vuint16m1_t rs2,
                               size_t vl);
vbfloat16m2_t __riscv_vloxei16(vbool8_t vm, const __bf16 *rs1, vuint16m2_t rs2,
                               size_t vl);
vbfloat16m4_t __riscv_vloxei16(vbool4_t vm, const __bf16 *rs1, vuint16m4_t rs2,
                               size_t vl);
vbfloat16m8_t __riscv_vloxei16(vbool2_t vm, const __bf16 *rs1, vuint16m8_t rs2,
                               size_t vl);
vbfloat16mf4_t __riscv_vluxei16(vbool64_t vm, const __bf16 *rs1,
                                vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei16(vbool32_t vm, const __bf16 *rs1,
                                vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei16(vbool16_t vm, const __bf16 *rs1, vuint16m1_t rs2,
                               size_t vl);
vbfloat16m2_t __riscv_vluxei16(vbool8_t vm, const __bf16 *rs1, vuint16m2_t rs2,
                               size_t vl);
vbfloat16m4_t __riscv_vluxei16(vbool4_t vm, const __bf16 *rs1, vuint16m4_t rs2,
                               size_t vl);
vbfloat16m8_t __riscv_vluxei16(vbool2_t vm, const __bf16 *rs1, vuint16m8_t rs2,
                               size_t vl);
----

[[overloaded-vector-indexed-store]]
==== Vector Indexed Store Intrinsics

[,c]
----
void __riscv_vsoxei16(__bf16 *rs1, vuint16mf4_t rs2, vbfloat16mf4_t vs3,
                      size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16mf2_t rs2, vbfloat16mf2_t vs3,
                      size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16m1_t rs2, vbfloat16m1_t vs3,
                      size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16m2_t rs2, vbfloat16m2_t vs3,
                      size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16m4_t rs2, vbfloat16m4_t vs3,
                      size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16m8_t rs2, vbfloat16m8_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16mf4_t rs2, vbfloat16mf4_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16mf2_t rs2, vbfloat16mf2_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16m1_t rs2, vbfloat16m1_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16m2_t rs2, vbfloat16m2_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16m4_t rs2, vbfloat16m4_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16m8_t rs2, vbfloat16m8_t vs3,
                      size_t vl);
// masked functions
void __riscv_vsoxei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t rs2,
                      vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t rs2,
                      vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t rs2,
                      vbfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei16(vbool8_t vm, __bf16 *rs1, vuint16m2_t rs2,
                      vbfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei16(vbool4_t vm, __bf16 *rs1, vuint16m4_t rs2,
                      vbfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei16(vbool2_t vm, __bf16 *rs1, vuint16m8_t rs2,
                      vbfloat16m8_t vs3, size_t vl);
void __riscv_vsuxei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t rs2,
                      vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t rs2,
                      vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t rs2,
                      vbfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei16(vbool8_t vm, __bf16 *rs1, vuint16m2_t rs2,
                      vbfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei16(vbool4_t vm, __bf16 *rs1, vuint16m4_t rs2,
                      vbfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei16(vbool2_t vm, __bf16 *rs1, vuint16m8_t rs2,
                      vbfloat16m8_t vs3, size_t vl);
----

[[overloaded-unit-stride-fault-only-first-loads]]
==== Unit-stride Fault-Only-First Loads Intrinsics

[,c]
----
// masked functions
vbfloat16mf4_t __riscv_vle16ff(vbool64_t vm, const __bf16 *rs1, size_t *new_vl,
                               size_t vl);
vbfloat16mf2_t __riscv_vle16ff(vbool32_t vm, const __bf16 *rs1, size_t *new_vl,
                               size_t vl);
vbfloat16m1_t __riscv_vle16ff(vbool16_t vm, const __bf16 *rs1, size_t *new_vl,
                              size_t vl);
vbfloat16m2_t __riscv_vle16ff(vbool8_t vm, const __bf16 *rs1, size_t *new_vl,
                              size_t vl);
vbfloat16m4_t __riscv_vle16ff(vbool4_t vm, const __bf16 *rs1, size_t *new_vl,
                              size_t vl);
vbfloat16m8_t __riscv_vle16ff(vbool2_t vm, const __bf16 *rs1, size_t *new_vl,
                              size_t vl);
----

=== BFloat16 Vector Loads and Stores Segment Intrinsics

[[overloaded-vector-unit-stride-segment-load]]
==== Vector Unit-Stride Segment Load Intrinsics

[,c]
----
// masked functions
vbfloat16mf4x2_t __riscv_vlseg2e16(vbool64_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf4x3_t __riscv_vlseg3e16(vbool64_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf4x4_t __riscv_vlseg4e16(vbool64_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf4x5_t __riscv_vlseg5e16(vbool64_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf4x6_t __riscv_vlseg6e16(vbool64_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf4x7_t __riscv_vlseg7e16(vbool64_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf4x8_t __riscv_vlseg8e16(vbool64_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf2x2_t __riscv_vlseg2e16(vbool32_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf2x3_t __riscv_vlseg3e16(vbool32_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf2x4_t __riscv_vlseg4e16(vbool32_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf2x5_t __riscv_vlseg5e16(vbool32_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf2x6_t __riscv_vlseg6e16(vbool32_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf2x7_t __riscv_vlseg7e16(vbool32_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf2x8_t __riscv_vlseg8e16(vbool32_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m1x2_t __riscv_vlseg2e16(vbool16_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m1x3_t __riscv_vlseg3e16(vbool16_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m1x4_t __riscv_vlseg4e16(vbool16_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m1x5_t __riscv_vlseg5e16(vbool16_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m1x6_t __riscv_vlseg6e16(vbool16_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m1x7_t __riscv_vlseg7e16(vbool16_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m1x8_t __riscv_vlseg8e16(vbool16_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m2x2_t __riscv_vlseg2e16(vbool8_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m2x3_t __riscv_vlseg3e16(vbool8_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m2x4_t __riscv_vlseg4e16(vbool8_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m4x2_t __riscv_vlseg2e16(vbool4_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf4x2_t __riscv_vlseg2e16ff(vbool64_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf4x3_t __riscv_vlseg3e16ff(vbool64_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf4x4_t __riscv_vlseg4e16ff(vbool64_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf4x5_t __riscv_vlseg5e16ff(vbool64_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf4x6_t __riscv_vlseg6e16ff(vbool64_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf4x7_t __riscv_vlseg7e16ff(vbool64_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf4x8_t __riscv_vlseg8e16ff(vbool64_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf2x2_t __riscv_vlseg2e16ff(vbool32_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf2x3_t __riscv_vlseg3e16ff(vbool32_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf2x4_t __riscv_vlseg4e16ff(vbool32_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf2x5_t __riscv_vlseg5e16ff(vbool32_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf2x6_t __riscv_vlseg6e16ff(vbool32_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf2x7_t __riscv_vlseg7e16ff(vbool32_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16mf2x8_t __riscv_vlseg8e16ff(vbool32_t vm, const __bf16 *rs1,
                                     size_t *new_vl, size_t vl);
vbfloat16m1x2_t __riscv_vlseg2e16ff(vbool16_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
vbfloat16m1x3_t __riscv_vlseg3e16ff(vbool16_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
vbfloat16m1x4_t __riscv_vlseg4e16ff(vbool16_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
vbfloat16m1x5_t __riscv_vlseg5e16ff(vbool16_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
vbfloat16m1x6_t __riscv_vlseg6e16ff(vbool16_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
vbfloat16m1x7_t __riscv_vlseg7e16ff(vbool16_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
vbfloat16m1x8_t __riscv_vlseg8e16ff(vbool16_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
vbfloat16m2x2_t __riscv_vlseg2e16ff(vbool8_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
vbfloat16m2x3_t __riscv_vlseg3e16ff(vbool8_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
vbfloat16m2x4_t __riscv_vlseg4e16ff(vbool8_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
vbfloat16m4x2_t __riscv_vlseg2e16ff(vbool4_t vm, const __bf16 *rs1,
                                    size_t *new_vl, size_t vl);
----

[[overloaded-vecrtor-unit-stride-segment-store]]
==== Vector Unit-Stride Segment Store Intrinsics

[,c]
----
void __riscv_vsseg2e16(__bf16 *rs1, vbfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsseg3e16(__bf16 *rs1, vbfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsseg4e16(__bf16 *rs1, vbfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsseg5e16(__bf16 *rs1, vbfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsseg6e16(__bf16 *rs1, vbfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsseg7e16(__bf16 *rs1, vbfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsseg8e16(__bf16 *rs1, vbfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsseg2e16(__bf16 *rs1, vbfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e16(__bf16 *rs1, vbfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e16(__bf16 *rs1, vbfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e16(__bf16 *rs1, vbfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e16(__bf16 *rs1, vbfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e16(__bf16 *rs1, vbfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e16(__bf16 *rs1, vbfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e16(__bf16 *rs1, vbfloat16m1x2_t vs3, size_t vl);
void __riscv_vsseg3e16(__bf16 *rs1, vbfloat16m1x3_t vs3, size_t vl);
void __riscv_vsseg4e16(__bf16 *rs1, vbfloat16m1x4_t vs3, size_t vl);
void __riscv_vsseg5e16(__bf16 *rs1, vbfloat16m1x5_t vs3, size_t vl);
void __riscv_vsseg6e16(__bf16 *rs1, vbfloat16m1x6_t vs3, size_t vl);
void __riscv_vsseg7e16(__bf16 *rs1, vbfloat16m1x7_t vs3, size_t vl);
void __riscv_vsseg8e16(__bf16 *rs1, vbfloat16m1x8_t vs3, size_t vl);
void __riscv_vsseg2e16(__bf16 *rs1, vbfloat16m2x2_t vs3, size_t vl);
void __riscv_vsseg3e16(__bf16 *rs1, vbfloat16m2x3_t vs3, size_t vl);
void __riscv_vsseg4e16(__bf16 *rs1, vbfloat16m2x4_t vs3, size_t vl);
void __riscv_vsseg2e16(__bf16 *rs1, vbfloat16m4x2_t vs3, size_t vl);
// masked functions
void __riscv_vsseg2e16(vbool64_t vm, __bf16 *rs1, vbfloat16mf4x2_t vs3,
                       size_t vl);
void __riscv_vsseg3e16(vbool64_t vm, __bf16 *rs1, vbfloat16mf4x3_t vs3,
                       size_t vl);
void __riscv_vsseg4e16(vbool64_t vm, __bf16 *rs1, vbfloat16mf4x4_t vs3,
                       size_t vl);
void __riscv_vsseg5e16(vbool64_t vm, __bf16 *rs1, vbfloat16mf4x5_t vs3,
                       size_t vl);
void __riscv_vsseg6e16(vbool64_t vm, __bf16 *rs1, vbfloat16mf4x6_t vs3,
                       size_t vl);
void __riscv_vsseg7e16(vbool64_t vm, __bf16 *rs1, vbfloat16mf4x7_t vs3,
                       size_t vl);
void __riscv_vsseg8e16(vbool64_t vm, __bf16 *rs1, vbfloat16mf4x8_t vs3,
                       size_t vl);
void __riscv_vsseg2e16(vbool32_t vm, __bf16 *rs1, vbfloat16mf2x2_t vs3,
                       size_t vl);
void __riscv_vsseg3e16(vbool32_t vm, __bf16 *rs1, vbfloat16mf2x3_t vs3,
                       size_t vl);
void __riscv_vsseg4e16(vbool32_t vm, __bf16 *rs1, vbfloat16mf2x4_t vs3,
                       size_t vl);
void __riscv_vsseg5e16(vbool32_t vm, __bf16 *rs1, vbfloat16mf2x5_t vs3,
                       size_t vl);
void __riscv_vsseg6e16(vbool32_t vm, __bf16 *rs1, vbfloat16mf2x6_t vs3,
                       size_t vl);
void __riscv_vsseg7e16(vbool32_t vm, __bf16 *rs1, vbfloat16mf2x7_t vs3,
                       size_t vl);
void __riscv_vsseg8e16(vbool32_t vm, __bf16 *rs1, vbfloat16mf2x8_t vs3,
                       size_t vl);
void __riscv_vsseg2e16(vbool16_t vm, __bf16 *rs1, vbfloat16m1x2_t vs3,
                       size_t vl);
void __riscv_vsseg3e16(vbool16_t vm, __bf16 *rs1, vbfloat16m1x3_t vs3,
                       size_t vl);
void __riscv_vsseg4e16(vbool16_t vm, __bf16 *rs1, vbfloat16m1x4_t vs3,
                       size_t vl);
void __riscv_vsseg5e16(vbool16_t vm, __bf16 *rs1, vbfloat16m1x5_t vs3,
                       size_t vl);
void __riscv_vsseg6e16(vbool16_t vm, __bf16 *rs1, vbfloat16m1x6_t vs3,
                       size_t vl);
void __riscv_vsseg7e16(vbool16_t vm, __bf16 *rs1, vbfloat16m1x7_t vs3,
                       size_t vl);
void __riscv_vsseg8e16(vbool16_t vm, __bf16 *rs1, vbfloat16m1x8_t vs3,
                       size_t vl);
void __riscv_vsseg2e16(vbool8_t vm, __bf16 *rs1, vbfloat16m2x2_t vs3,
                       size_t vl);
void __riscv_vsseg3e16(vbool8_t vm, __bf16 *rs1, vbfloat16m2x3_t vs3,
                       size_t vl);
void __riscv_vsseg4e16(vbool8_t vm, __bf16 *rs1, vbfloat16m2x4_t vs3,
                       size_t vl);
void __riscv_vsseg2e16(vbool4_t vm, __bf16 *rs1, vbfloat16m4x2_t vs3,
                       size_t vl);
----

[[overloaded-vector-strided-segment-load]]
==== Vector Strided Segment Load Intrinsics

[,c]
----
// masked functions
vbfloat16mf4x2_t __riscv_vlsseg2e16(vbool64_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf4x3_t __riscv_vlsseg3e16(vbool64_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf4x4_t __riscv_vlsseg4e16(vbool64_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf4x5_t __riscv_vlsseg5e16(vbool64_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf4x6_t __riscv_vlsseg6e16(vbool64_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf4x7_t __riscv_vlsseg7e16(vbool64_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf4x8_t __riscv_vlsseg8e16(vbool64_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf2x2_t __riscv_vlsseg2e16(vbool32_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf2x3_t __riscv_vlsseg3e16(vbool32_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf2x4_t __riscv_vlsseg4e16(vbool32_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf2x5_t __riscv_vlsseg5e16(vbool32_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf2x6_t __riscv_vlsseg6e16(vbool32_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf2x7_t __riscv_vlsseg7e16(vbool32_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16mf2x8_t __riscv_vlsseg8e16(vbool32_t vm, const __bf16 *rs1,
                                    ptrdiff_t rs2, size_t vl);
vbfloat16m1x2_t __riscv_vlsseg2e16(vbool16_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vbfloat16m1x3_t __riscv_vlsseg3e16(vbool16_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vbfloat16m1x4_t __riscv_vlsseg4e16(vbool16_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vbfloat16m1x5_t __riscv_vlsseg5e16(vbool16_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vbfloat16m1x6_t __riscv_vlsseg6e16(vbool16_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vbfloat16m1x7_t __riscv_vlsseg7e16(vbool16_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vbfloat16m1x8_t __riscv_vlsseg8e16(vbool16_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vbfloat16m2x2_t __riscv_vlsseg2e16(vbool8_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vbfloat16m2x3_t __riscv_vlsseg3e16(vbool8_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vbfloat16m2x4_t __riscv_vlsseg4e16(vbool8_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vbfloat16m4x2_t __riscv_vlsseg2e16(vbool4_t vm, const __bf16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
----

[[overloaded-vector-strided-segment-store]]
==== Vector Strided Segment Store Intrinsics

[,c]
----
void __riscv_vssseg2e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf4x2_t vs3,
                        size_t vl);
void __riscv_vssseg3e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf4x3_t vs3,
                        size_t vl);
void __riscv_vssseg4e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf4x4_t vs3,
                        size_t vl);
void __riscv_vssseg5e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf4x5_t vs3,
                        size_t vl);
void __riscv_vssseg6e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf4x6_t vs3,
                        size_t vl);
void __riscv_vssseg7e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf4x7_t vs3,
                        size_t vl);
void __riscv_vssseg8e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf4x8_t vs3,
                        size_t vl);
void __riscv_vssseg2e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf2x2_t vs3,
                        size_t vl);
void __riscv_vssseg3e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf2x3_t vs3,
                        size_t vl);
void __riscv_vssseg4e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf2x4_t vs3,
                        size_t vl);
void __riscv_vssseg5e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf2x5_t vs3,
                        size_t vl);
void __riscv_vssseg6e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf2x6_t vs3,
                        size_t vl);
void __riscv_vssseg7e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf2x7_t vs3,
                        size_t vl);
void __riscv_vssseg8e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf2x8_t vs3,
                        size_t vl);
void __riscv_vssseg2e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m1x2_t vs3,
                        size_t vl);
void __riscv_vssseg3e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m1x3_t vs3,
                        size_t vl);
void __riscv_vssseg4e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m1x4_t vs3,
                        size_t vl);
void __riscv_vssseg5e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m1x5_t vs3,
                        size_t vl);
void __riscv_vssseg6e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m1x6_t vs3,
                        size_t vl);
void __riscv_vssseg7e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m1x7_t vs3,
                        size_t vl);
void __riscv_vssseg8e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m1x8_t vs3,
                        size_t vl);
void __riscv_vssseg2e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m2x2_t vs3,
                        size_t vl);
void __riscv_vssseg3e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m2x3_t vs3,
                        size_t vl);
void __riscv_vssseg4e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m2x4_t vs3,
                        size_t vl);
void __riscv_vssseg2e16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m4x2_t vs3,
                        size_t vl);
// masked functions
void __riscv_vssseg2e16(vbool64_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e16(vbool64_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e16(vbool64_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e16(vbool64_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e16(vbool64_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e16(vbool64_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e16(vbool64_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e16(vbool32_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e16(vbool32_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e16(vbool32_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e16(vbool32_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e16(vbool32_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e16(vbool32_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e16(vbool32_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e16(vbool16_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m1x2_t vs3, size_t vl);
void __riscv_vssseg3e16(vbool16_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m1x3_t vs3, size_t vl);
void __riscv_vssseg4e16(vbool16_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m1x4_t vs3, size_t vl);
void __riscv_vssseg5e16(vbool16_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m1x5_t vs3, size_t vl);
void __riscv_vssseg6e16(vbool16_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m1x6_t vs3, size_t vl);
void __riscv_vssseg7e16(vbool16_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m1x7_t vs3, size_t vl);
void __riscv_vssseg8e16(vbool16_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m1x8_t vs3, size_t vl);
void __riscv_vssseg2e16(vbool8_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m2x2_t vs3, size_t vl);
void __riscv_vssseg3e16(vbool8_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m2x3_t vs3, size_t vl);
void __riscv_vssseg4e16(vbool8_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m2x4_t vs3, size_t vl);
void __riscv_vssseg2e16(vbool4_t vm, __bf16 *rs1, ptrdiff_t rs2,
                        vbfloat16m4x2_t vs3, size_t vl);
----

[[overloaded-vector-indexed-segment-load]]
==== Vector Indexed Segment Load Intrinsics

[,c]
----
vbfloat16mf4x2_t __riscv_vloxseg2ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x3_t __riscv_vloxseg3ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x4_t __riscv_vloxseg4ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x5_t __riscv_vloxseg5ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x6_t __riscv_vloxseg6ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x7_t __riscv_vloxseg7ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x8_t __riscv_vloxseg8ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf2x2_t __riscv_vloxseg2ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x3_t __riscv_vloxseg3ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x4_t __riscv_vloxseg4ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x5_t __riscv_vloxseg5ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x6_t __riscv_vloxseg6ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x7_t __riscv_vloxseg7ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x8_t __riscv_vloxseg8ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16m1x2_t __riscv_vloxseg2ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x3_t __riscv_vloxseg3ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x4_t __riscv_vloxseg4ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x5_t __riscv_vloxseg5ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x6_t __riscv_vloxseg6ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x7_t __riscv_vloxseg7ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x8_t __riscv_vloxseg8ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m2x2_t __riscv_vloxseg2ei16(const __bf16 *rs1, vuint16m2_t rs2,
                                     size_t vl);
vbfloat16m2x3_t __riscv_vloxseg3ei16(const __bf16 *rs1, vuint16m2_t rs2,
                                     size_t vl);
vbfloat16m2x4_t __riscv_vloxseg4ei16(const __bf16 *rs1, vuint16m2_t rs2,
                                     size_t vl);
vbfloat16m4x2_t __riscv_vloxseg2ei16(const __bf16 *rs1, vuint16m4_t rs2,
                                     size_t vl);
vbfloat16mf4x2_t __riscv_vluxseg2ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x3_t __riscv_vluxseg3ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x4_t __riscv_vluxseg4ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x5_t __riscv_vluxseg5ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x6_t __riscv_vluxseg6ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x7_t __riscv_vluxseg7ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf4x8_t __riscv_vluxseg8ei16(const __bf16 *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vbfloat16mf2x2_t __riscv_vluxseg2ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x3_t __riscv_vluxseg3ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x4_t __riscv_vluxseg4ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x5_t __riscv_vluxseg5ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x6_t __riscv_vluxseg6ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x7_t __riscv_vluxseg7ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16mf2x8_t __riscv_vluxseg8ei16(const __bf16 *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vbfloat16m1x2_t __riscv_vluxseg2ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x3_t __riscv_vluxseg3ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x4_t __riscv_vluxseg4ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x5_t __riscv_vluxseg5ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x6_t __riscv_vluxseg6ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x7_t __riscv_vluxseg7ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m1x8_t __riscv_vluxseg8ei16(const __bf16 *rs1, vuint16m1_t rs2,
                                     size_t vl);
vbfloat16m2x2_t __riscv_vluxseg2ei16(const __bf16 *rs1, vuint16m2_t rs2,
                                     size_t vl);
vbfloat16m2x3_t __riscv_vluxseg3ei16(const __bf16 *rs1, vuint16m2_t rs2,
                                     size_t vl);
vbfloat16m2x4_t __riscv_vluxseg4ei16(const __bf16 *rs1, vuint16m2_t rs2,
                                     size_t vl);
vbfloat16m4x2_t __riscv_vluxseg2ei16(const __bf16 *rs1, vuint16m4_t rs2,
                                     size_t vl);
// masked functions
vbfloat16mf4x2_t __riscv_vloxseg2ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x3_t __riscv_vloxseg3ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x4_t __riscv_vloxseg4ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x5_t __riscv_vloxseg5ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x6_t __riscv_vloxseg6ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x7_t __riscv_vloxseg7ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x8_t __riscv_vloxseg8ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf2x2_t __riscv_vloxseg2ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x3_t __riscv_vloxseg3ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x4_t __riscv_vloxseg4ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x5_t __riscv_vloxseg5ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x6_t __riscv_vloxseg6ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x7_t __riscv_vloxseg7ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x8_t __riscv_vloxseg8ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16m1x2_t __riscv_vloxseg2ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x3_t __riscv_vloxseg3ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x4_t __riscv_vloxseg4ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x5_t __riscv_vloxseg5ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x6_t __riscv_vloxseg6ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x7_t __riscv_vloxseg7ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x8_t __riscv_vloxseg8ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m2x2_t __riscv_vloxseg2ei16(vbool8_t vm, const __bf16 *rs1,
                                     vuint16m2_t rs2, size_t vl);
vbfloat16m2x3_t __riscv_vloxseg3ei16(vbool8_t vm, const __bf16 *rs1,
                                     vuint16m2_t rs2, size_t vl);
vbfloat16m2x4_t __riscv_vloxseg4ei16(vbool8_t vm, const __bf16 *rs1,
                                     vuint16m2_t rs2, size_t vl);
vbfloat16m4x2_t __riscv_vloxseg2ei16(vbool4_t vm, const __bf16 *rs1,
                                     vuint16m4_t rs2, size_t vl);
vbfloat16mf4x2_t __riscv_vluxseg2ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x3_t __riscv_vluxseg3ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x4_t __riscv_vluxseg4ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x5_t __riscv_vluxseg5ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x6_t __riscv_vluxseg6ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x7_t __riscv_vluxseg7ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf4x8_t __riscv_vluxseg8ei16(vbool64_t vm, const __bf16 *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vbfloat16mf2x2_t __riscv_vluxseg2ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x3_t __riscv_vluxseg3ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x4_t __riscv_vluxseg4ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x5_t __riscv_vluxseg5ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x6_t __riscv_vluxseg6ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x7_t __riscv_vluxseg7ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16mf2x8_t __riscv_vluxseg8ei16(vbool32_t vm, const __bf16 *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vbfloat16m1x2_t __riscv_vluxseg2ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x3_t __riscv_vluxseg3ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x4_t __riscv_vluxseg4ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x5_t __riscv_vluxseg5ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x6_t __riscv_vluxseg6ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x7_t __riscv_vluxseg7ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m1x8_t __riscv_vluxseg8ei16(vbool16_t vm, const __bf16 *rs1,
                                     vuint16m1_t rs2, size_t vl);
vbfloat16m2x2_t __riscv_vluxseg2ei16(vbool8_t vm, const __bf16 *rs1,
                                     vuint16m2_t rs2, size_t vl);
vbfloat16m2x3_t __riscv_vluxseg3ei16(vbool8_t vm, const __bf16 *rs1,
                                     vuint16m2_t rs2, size_t vl);
vbfloat16m2x4_t __riscv_vluxseg4ei16(vbool8_t vm, const __bf16 *rs1,
                                     vuint16m2_t rs2, size_t vl);
vbfloat16m4x2_t __riscv_vluxseg2ei16(vbool4_t vm, const __bf16 *rs1,
                                     vuint16m4_t rs2, size_t vl);
----

[[overloaded-vector-indexed-segment-store]]
==== Vector Indexed Segment Store Intrinsics

[,c]
----
void __riscv_vsoxseg2ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x2_t vs3,
                          size_t vl);
void __riscv_vsoxseg3ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x3_t vs3,
                          size_t vl);
void __riscv_vsoxseg4ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x4_t vs3,
                          size_t vl);
void __riscv_vsoxseg5ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x5_t vs3,
                          size_t vl);
void __riscv_vsoxseg6ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x6_t vs3,
                          size_t vl);
void __riscv_vsoxseg7ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x7_t vs3,
                          size_t vl);
void __riscv_vsoxseg8ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x8_t vs3,
                          size_t vl);
void __riscv_vsoxseg2ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x2_t vs3,
                          size_t vl);
void __riscv_vsoxseg3ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x3_t vs3,
                          size_t vl);
void __riscv_vsoxseg4ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x4_t vs3,
                          size_t vl);
void __riscv_vsoxseg5ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x5_t vs3,
                          size_t vl);
void __riscv_vsoxseg6ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x6_t vs3,
                          size_t vl);
void __riscv_vsoxseg7ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x7_t vs3,
                          size_t vl);
void __riscv_vsoxseg8ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x8_t vs3,
                          size_t vl);
void __riscv_vsoxseg2ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x2_t vs3,
                          size_t vl);
void __riscv_vsoxseg3ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x3_t vs3,
                          size_t vl);
void __riscv_vsoxseg4ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x4_t vs3,
                          size_t vl);
void __riscv_vsoxseg5ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x5_t vs3,
                          size_t vl);
void __riscv_vsoxseg6ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x6_t vs3,
                          size_t vl);
void __riscv_vsoxseg7ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x7_t vs3,
                          size_t vl);
void __riscv_vsoxseg8ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x8_t vs3,
                          size_t vl);
void __riscv_vsoxseg2ei16(__bf16 *rs1, vuint16m2_t vs2, vbfloat16m2x2_t vs3,
                          size_t vl);
void __riscv_vsoxseg3ei16(__bf16 *rs1, vuint16m2_t vs2, vbfloat16m2x3_t vs3,
                          size_t vl);
void __riscv_vsoxseg4ei16(__bf16 *rs1, vuint16m2_t vs2, vbfloat16m2x4_t vs3,
                          size_t vl);
void __riscv_vsoxseg2ei16(__bf16 *rs1, vuint16m4_t vs2, vbfloat16m4x2_t vs3,
                          size_t vl);
void __riscv_vsuxseg2ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x2_t vs3,
                          size_t vl);
void __riscv_vsuxseg3ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x3_t vs3,
                          size_t vl);
void __riscv_vsuxseg4ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x4_t vs3,
                          size_t vl);
void __riscv_vsuxseg5ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x5_t vs3,
                          size_t vl);
void __riscv_vsuxseg6ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x6_t vs3,
                          size_t vl);
void __riscv_vsuxseg7ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x7_t vs3,
                          size_t vl);
void __riscv_vsuxseg8ei16(__bf16 *rs1, vuint16mf4_t vs2, vbfloat16mf4x8_t vs3,
                          size_t vl);
void __riscv_vsuxseg2ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x2_t vs3,
                          size_t vl);
void __riscv_vsuxseg3ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x3_t vs3,
                          size_t vl);
void __riscv_vsuxseg4ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x4_t vs3,
                          size_t vl);
void __riscv_vsuxseg5ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x5_t vs3,
                          size_t vl);
void __riscv_vsuxseg6ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x6_t vs3,
                          size_t vl);
void __riscv_vsuxseg7ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x7_t vs3,
                          size_t vl);
void __riscv_vsuxseg8ei16(__bf16 *rs1, vuint16mf2_t vs2, vbfloat16mf2x8_t vs3,
                          size_t vl);
void __riscv_vsuxseg2ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x2_t vs3,
                          size_t vl);
void __riscv_vsuxseg3ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x3_t vs3,
                          size_t vl);
void __riscv_vsuxseg4ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x4_t vs3,
                          size_t vl);
void __riscv_vsuxseg5ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x5_t vs3,
                          size_t vl);
void __riscv_vsuxseg6ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x6_t vs3,
                          size_t vl);
void __riscv_vsuxseg7ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x7_t vs3,
                          size_t vl);
void __riscv_vsuxseg8ei16(__bf16 *rs1, vuint16m1_t vs2, vbfloat16m1x8_t vs3,
                          size_t vl);
void __riscv_vsuxseg2ei16(__bf16 *rs1, vuint16m2_t vs2, vbfloat16m2x2_t vs3,
                          size_t vl);
void __riscv_vsuxseg3ei16(__bf16 *rs1, vuint16m2_t vs2, vbfloat16m2x3_t vs3,
                          size_t vl);
void __riscv_vsuxseg4ei16(__bf16 *rs1, vuint16m2_t vs2, vbfloat16m2x4_t vs3,
                          size_t vl);
void __riscv_vsuxseg2ei16(__bf16 *rs1, vuint16m4_t vs2, vbfloat16m4x2_t vs3,
                          size_t vl);
// masked functions
void __riscv_vsoxseg2ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16(vbool8_t vm, __bf16 *rs1, vuint16m2_t vs2,
                          vbfloat16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16(vbool8_t vm, __bf16 *rs1, vuint16m2_t vs2,
                          vbfloat16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16(vbool8_t vm, __bf16 *rs1, vuint16m2_t vs2,
                          vbfloat16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16(vbool4_t vm, __bf16 *rs1, vuint16m4_t vs2,
                          vbfloat16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t vs2,
                          vbfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t vs2,
                          vbfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t vs2,
                          vbfloat16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16(vbool8_t vm, __bf16 *rs1, vuint16m2_t vs2,
                          vbfloat16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16(vbool8_t vm, __bf16 *rs1, vuint16m2_t vs2,
                          vbfloat16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16(vbool8_t vm, __bf16 *rs1, vuint16m2_t vs2,
                          vbfloat16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16(vbool4_t vm, __bf16 *rs1, vuint16m4_t vs2,
                          vbfloat16m4x2_t vs3, size_t vl);
----

=== BFloat16 Convert Intrinsics

[[overloaded-bf16-vector-narrow-convert]]
==== Vector Narrowing Convert Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vfncvtbf16_f(vfloat32mf2_t vs2, size_t vl);
vbfloat16mf2_t __riscv_vfncvtbf16_f(vfloat32m1_t vs2, size_t vl);
vbfloat16m1_t __riscv_vfncvtbf16_f(vfloat32m2_t vs2, size_t vl);
vbfloat16m2_t __riscv_vfncvtbf16_f(vfloat32m4_t vs2, size_t vl);
vbfloat16m4_t __riscv_vfncvtbf16_f(vfloat32m8_t vs2, size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vfncvtbf16_f(vbool64_t vm, vfloat32mf2_t vs2, size_t vl);
vbfloat16mf2_t __riscv_vfncvtbf16_f(vbool32_t vm, vfloat32m1_t vs2, size_t vl);
vbfloat16m1_t __riscv_vfncvtbf16_f(vbool16_t vm, vfloat32m2_t vs2, size_t vl);
vbfloat16m2_t __riscv_vfncvtbf16_f(vbool8_t vm, vfloat32m4_t vs2, size_t vl);
vbfloat16m4_t __riscv_vfncvtbf16_f(vbool4_t vm, vfloat32m8_t vs2, size_t vl);
vbfloat16mf4_t __riscv_vfncvtbf16_f(vfloat32mf2_t vs2, unsigned int frm,
                                    size_t vl);
vbfloat16mf2_t __riscv_vfncvtbf16_f(vfloat32m1_t vs2, unsigned int frm,
                                    size_t vl);
vbfloat16m1_t __riscv_vfncvtbf16_f(vfloat32m2_t vs2, unsigned int frm,
                                   size_t vl);
vbfloat16m2_t __riscv_vfncvtbf16_f(vfloat32m4_t vs2, unsigned int frm,
                                   size_t vl);
vbfloat16m4_t __riscv_vfncvtbf16_f(vfloat32m8_t vs2, unsigned int frm,
                                   size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vfncvtbf16_f(vbool64_t vm, vfloat32mf2_t vs2,
                                    unsigned int frm, size_t vl);
vbfloat16mf2_t __riscv_vfncvtbf16_f(vbool32_t vm, vfloat32m1_t vs2,
                                    unsigned int frm, size_t vl);
vbfloat16m1_t __riscv_vfncvtbf16_f(vbool16_t vm, vfloat32m2_t vs2,
                                   unsigned int frm, size_t vl);
vbfloat16m2_t __riscv_vfncvtbf16_f(vbool8_t vm, vfloat32m4_t vs2,
                                   unsigned int frm, size_t vl);
vbfloat16m4_t __riscv_vfncvtbf16_f(vbool4_t vm, vfloat32m8_t vs2,
                                   unsigned int frm, size_t vl);
----

[[overloaded-bf16-vector-widening-convert]]
==== Vector Widening Convert Intrinsics

[,c]
----
vfloat32mf2_t __riscv_vfwcvtbf16_f(vbfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvtbf16_f(vbfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvtbf16_f(vbfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvtbf16_f(vbfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvtbf16_f(vbfloat16m4_t vs2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwcvtbf16_f(vbool64_t vm, vbfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvtbf16_f(vbool32_t vm, vbfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvtbf16_f(vbool16_t vm, vbfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvtbf16_f(vbool8_t vm, vbfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvtbf16_f(vbool4_t vm, vbfloat16m4_t vs2, size_t vl);
----

=== BFloat16 Arithmetic Intrinsics

[[overloaded-bf16-widening-multiply-accumulate]]
==== Vector Widening Multiply-Accumulate Intrinsics

[,c]
----
vfloat32mf2_t __riscv_vfwmaccbf16(vfloat32mf2_t vd, vbfloat16mf4_t vs1,
                                  vbfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmaccbf16(vfloat32mf2_t vd, __bf16 vs1,
                                  vbfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmaccbf16(vfloat32m1_t vd, vbfloat16mf2_t vs1,
                                 vbfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmaccbf16(vfloat32m1_t vd, __bf16 vs1,
                                 vbfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmaccbf16(vfloat32m2_t vd, vbfloat16m1_t vs1,
                                 vbfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmaccbf16(vfloat32m2_t vd, __bf16 vs1, vbfloat16m1_t vs2,
                                 size_t vl);
vfloat32m4_t __riscv_vfwmaccbf16(vfloat32m4_t vd, vbfloat16m2_t vs1,
                                 vbfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmaccbf16(vfloat32m4_t vd, __bf16 vs1, vbfloat16m2_t vs2,
                                 size_t vl);
vfloat32m8_t __riscv_vfwmaccbf16(vfloat32m8_t vd, vbfloat16m4_t vs1,
                                 vbfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmaccbf16(vfloat32m8_t vd, __bf16 vs1, vbfloat16m4_t vs2,
                                 size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmaccbf16(vbool64_t vm, vfloat32mf2_t vd,
                                  vbfloat16mf4_t vs1, vbfloat16mf4_t vs2,
                                  size_t vl);
vfloat32mf2_t __riscv_vfwmaccbf16(vbool64_t vm, vfloat32mf2_t vd, __bf16 vs1,
                                  vbfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmaccbf16(vbool32_t vm, vfloat32m1_t vd,
                                 vbfloat16mf2_t vs1, vbfloat16mf2_t vs2,
                                 size_t vl);
vfloat32m1_t __riscv_vfwmaccbf16(vbool32_t vm, vfloat32m1_t vd, __bf16 vs1,
                                 vbfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmaccbf16(vbool16_t vm, vfloat32m2_t vd,
                                 vbfloat16m1_t vs1, vbfloat16m1_t vs2,
                                 size_t vl);
vfloat32m2_t __riscv_vfwmaccbf16(vbool16_t vm, vfloat32m2_t vd, __bf16 vs1,
                                 vbfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmaccbf16(vbool8_t vm, vfloat32m4_t vd,
                                 vbfloat16m2_t vs1, vbfloat16m2_t vs2,
                                 size_t vl);
vfloat32m4_t __riscv_vfwmaccbf16(vbool8_t vm, vfloat32m4_t vd, __bf16 vs1,
                                 vbfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmaccbf16(vbool4_t vm, vfloat32m8_t vd,
                                 vbfloat16m4_t vs1, vbfloat16m4_t vs2,
                                 size_t vl);
vfloat32m8_t __riscv_vfwmaccbf16(vbool4_t vm, vfloat32m8_t vd, __bf16 vs1,
                                 vbfloat16m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmaccbf16(vfloat32mf2_t vd, vbfloat16mf4_t vs1,
                                  vbfloat16mf4_t vs2, unsigned int frm,
                                  size_t vl);
vfloat32mf2_t __riscv_vfwmaccbf16(vfloat32mf2_t vd, __bf16 vs1,
                                  vbfloat16mf4_t vs2, unsigned int frm,
                                  size_t vl);
vfloat32m1_t __riscv_vfwmaccbf16(vfloat32m1_t vd, vbfloat16mf2_t vs1,
                                 vbfloat16mf2_t vs2, unsigned int frm,
                                 size_t vl);
vfloat32m1_t __riscv_vfwmaccbf16(vfloat32m1_t vd, __bf16 vs1,
                                 vbfloat16mf2_t vs2, unsigned int frm,
                                 size_t vl);
vfloat32m2_t __riscv_vfwmaccbf16(vfloat32m2_t vd, vbfloat16m1_t vs1,
                                 vbfloat16m1_t vs2, unsigned int frm,
                                 size_t vl);
vfloat32m2_t __riscv_vfwmaccbf16(vfloat32m2_t vd, __bf16 vs1, vbfloat16m1_t vs2,
                                 unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmaccbf16(vfloat32m4_t vd, vbfloat16m2_t vs1,
                                 vbfloat16m2_t vs2, unsigned int frm,
                                 size_t vl);
vfloat32m4_t __riscv_vfwmaccbf16(vfloat32m4_t vd, __bf16 vs1, vbfloat16m2_t vs2,
                                 unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmaccbf16(vfloat32m8_t vd, vbfloat16m4_t vs1,
                                 vbfloat16m4_t vs2, unsigned int frm,
                                 size_t vl);
vfloat32m8_t __riscv_vfwmaccbf16(vfloat32m8_t vd, __bf16 vs1, vbfloat16m4_t vs2,
                                 unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmaccbf16(vbool64_t vm, vfloat32mf2_t vd,
                                  vbfloat16mf4_t vs1, vbfloat16mf4_t vs2,
                                  unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmaccbf16(vbool64_t vm, vfloat32mf2_t vd, __bf16 vs1,
                                  vbfloat16mf4_t vs2, unsigned int frm,
                                  size_t vl);
vfloat32m1_t __riscv_vfwmaccbf16(vbool32_t vm, vfloat32m1_t vd,
                                 vbfloat16mf2_t vs1, vbfloat16mf2_t vs2,
                                 unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmaccbf16(vbool32_t vm, vfloat32m1_t vd, __bf16 vs1,
                                 vbfloat16mf2_t vs2, unsigned int frm,
                                 size_t vl);
vfloat32m2_t __riscv_vfwmaccbf16(vbool16_t vm, vfloat32m2_t vd,
                                 vbfloat16m1_t vs1, vbfloat16m1_t vs2,
                                 unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmaccbf16(vbool16_t vm, vfloat32m2_t vd, __bf16 vs1,
                                 vbfloat16m1_t vs2, unsigned int frm,
                                 size_t vl);
vfloat32m4_t __riscv_vfwmaccbf16(vbool8_t vm, vfloat32m4_t vd,
                                 vbfloat16m2_t vs1, vbfloat16m2_t vs2,
                                 unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmaccbf16(vbool8_t vm, vfloat32m4_t vd, __bf16 vs1,
                                 vbfloat16m2_t vs2, unsigned int frm,
                                 size_t vl);
vfloat32m8_t __riscv_vfwmaccbf16(vbool4_t vm, vfloat32m8_t vd,
                                 vbfloat16m4_t vs1, vbfloat16m4_t vs2,
                                 unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmaccbf16(vbool4_t vm, vfloat32m8_t vd, __bf16 vs1,
                                 vbfloat16m4_t vs2, unsigned int frm,
                                 size_t vl);
----

[[overloaded-vector-bf16-move]]
==== Vector BFloat16 Move Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vmv_v(vbfloat16mf4_t vs1, size_t vl);
vbfloat16mf2_t __riscv_vmv_v(vbfloat16mf2_t vs1, size_t vl);
vbfloat16m1_t __riscv_vmv_v(vbfloat16m1_t vs1, size_t vl);
vbfloat16m2_t __riscv_vmv_v(vbfloat16m2_t vs1, size_t vl);
vbfloat16m4_t __riscv_vmv_v(vbfloat16m4_t vs1, size_t vl);
vbfloat16m8_t __riscv_vmv_v(vbfloat16m8_t vs1, size_t vl);
----

[[overloaded-vector-bf16-merge]]
==== Vector BFloat16 Merge Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vmerge(vbfloat16mf4_t vs2, vbfloat16mf4_t vs1,
                              vbool64_t v0, size_t vl);
vbfloat16mf2_t __riscv_vmerge(vbfloat16mf2_t vs2, vbfloat16mf2_t vs1,
                              vbool32_t v0, size_t vl);
vbfloat16m1_t __riscv_vmerge(vbfloat16m1_t vs2, vbfloat16m1_t vs1, vbool16_t v0,
                             size_t vl);
vbfloat16m2_t __riscv_vmerge(vbfloat16m2_t vs2, vbfloat16m2_t vs1, vbool8_t v0,
                             size_t vl);
vbfloat16m4_t __riscv_vmerge(vbfloat16m4_t vs2, vbfloat16m4_t vs1, vbool4_t v0,
                             size_t vl);
vbfloat16m8_t __riscv_vmerge(vbfloat16m8_t vs2, vbfloat16m8_t vs1, vbool2_t v0,
                             size_t vl);
----

=== BFloat16 Miscellaneous Vector Utility Intrinsics

[[overloaded-reinterpret-cast-conversion]]
==== Reinterpret Cast Conversion Intrinsics

[,c]
----
// Reinterpret between different type under the same SEW/LMUL
vbfloat16mf4_t __riscv_vreinterpret_bf16mf4(vint16mf4_t src);
vbfloat16mf2_t __riscv_vreinterpret_bf16mf2(vint16mf2_t src);
vbfloat16m1_t __riscv_vreinterpret_bf16m1(vint16m1_t src);
vbfloat16m2_t __riscv_vreinterpret_bf16m2(vint16m2_t src);
vbfloat16m4_t __riscv_vreinterpret_bf16m4(vint16m4_t src);
vbfloat16m8_t __riscv_vreinterpret_bf16m8(vint16m8_t src);
vbfloat16mf4_t __riscv_vreinterpret_bf16mf4(vuint16mf4_t src);
vbfloat16mf2_t __riscv_vreinterpret_bf16mf2(vuint16mf2_t src);
vbfloat16m1_t __riscv_vreinterpret_bf16m1(vuint16m1_t src);
vbfloat16m2_t __riscv_vreinterpret_bf16m2(vuint16m2_t src);
vbfloat16m4_t __riscv_vreinterpret_bf16m4(vuint16m4_t src);
vbfloat16m8_t __riscv_vreinterpret_bf16m8(vuint16m8_t src);
vint16mf4_t __riscv_vreinterpret_i16mf4(vbfloat16mf4_t src);
vint16mf2_t __riscv_vreinterpret_i16mf2(vbfloat16mf2_t src);
vint16m1_t __riscv_vreinterpret_i16m1(vbfloat16m1_t src);
vint16m2_t __riscv_vreinterpret_i16m2(vbfloat16m2_t src);
vint16m4_t __riscv_vreinterpret_i16m4(vbfloat16m4_t src);
vint16m8_t __riscv_vreinterpret_i16m8(vbfloat16m8_t src);
vuint16mf4_t __riscv_vreinterpret_u16mf4(vbfloat16mf4_t src);
vuint16mf2_t __riscv_vreinterpret_u16mf2(vbfloat16mf2_t src);
vuint16m1_t __riscv_vreinterpret_u16m1(vbfloat16m1_t src);
vuint16m2_t __riscv_vreinterpret_u16m2(vbfloat16m2_t src);
vuint16m4_t __riscv_vreinterpret_u16m4(vbfloat16m4_t src);
vuint16m8_t __riscv_vreinterpret_u16m8(vbfloat16m8_t src);
----

[[overloaded-vector-lmul-extensionn]]
==== Vector LMUL Extension Intrinsics

[,c]
----
vbfloat16mf2_t __riscv_vlmul_ext_bf16mf2(vbfloat16mf4_t value);
vbfloat16m1_t __riscv_vlmul_ext_bf16m1(vbfloat16mf4_t value);
vbfloat16m2_t __riscv_vlmul_ext_bf16m2(vbfloat16mf4_t value);
vbfloat16m4_t __riscv_vlmul_ext_bf16m4(vbfloat16mf4_t value);
vbfloat16m8_t __riscv_vlmul_ext_bf16m8(vbfloat16mf4_t value);
vbfloat16m1_t __riscv_vlmul_ext_bf16m1(vbfloat16mf2_t value);
vbfloat16m2_t __riscv_vlmul_ext_bf16m2(vbfloat16mf2_t value);
vbfloat16m4_t __riscv_vlmul_ext_bf16m4(vbfloat16mf2_t value);
vbfloat16m8_t __riscv_vlmul_ext_bf16m8(vbfloat16mf2_t value);
vbfloat16m2_t __riscv_vlmul_ext_bf16m2(vbfloat16m1_t value);
vbfloat16m4_t __riscv_vlmul_ext_bf16m4(vbfloat16m1_t value);
vbfloat16m8_t __riscv_vlmul_ext_bf16m8(vbfloat16m1_t value);
vbfloat16m4_t __riscv_vlmul_ext_bf16m4(vbfloat16m2_t value);
vbfloat16m8_t __riscv_vlmul_ext_bf16m8(vbfloat16m2_t value);
vbfloat16m8_t __riscv_vlmul_ext_bf16m8(vbfloat16m4_t value);
----

[[overloaded-vector-lmul-truncation]]
==== Vector LMUL Truncation Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vlmul_trunc_bf16mf4(vbfloat16mf2_t value);
vbfloat16mf4_t __riscv_vlmul_trunc_bf16mf4(vbfloat16m1_t value);
vbfloat16mf2_t __riscv_vlmul_trunc_bf16mf2(vbfloat16m1_t value);
vbfloat16mf4_t __riscv_vlmul_trunc_bf16mf4(vbfloat16m2_t value);
vbfloat16mf2_t __riscv_vlmul_trunc_bf16mf2(vbfloat16m2_t value);
vbfloat16m1_t __riscv_vlmul_trunc_bf16m1(vbfloat16m2_t value);
vbfloat16mf4_t __riscv_vlmul_trunc_bf16mf4(vbfloat16m4_t value);
vbfloat16mf2_t __riscv_vlmul_trunc_bf16mf2(vbfloat16m4_t value);
vbfloat16m1_t __riscv_vlmul_trunc_bf16m1(vbfloat16m4_t value);
vbfloat16m2_t __riscv_vlmul_trunc_bf16m2(vbfloat16m4_t value);
vbfloat16mf4_t __riscv_vlmul_trunc_bf16mf4(vbfloat16m8_t value);
vbfloat16mf2_t __riscv_vlmul_trunc_bf16mf2(vbfloat16m8_t value);
vbfloat16m1_t __riscv_vlmul_trunc_bf16m1(vbfloat16m8_t value);
vbfloat16m2_t __riscv_vlmul_trunc_bf16m2(vbfloat16m8_t value);
vbfloat16m4_t __riscv_vlmul_trunc_bf16m4(vbfloat16m8_t value);
----

[[overloaded-vector-initialization]]
==== Vector Initialization Intrinsics
Intrinsics here don't have an overloaded variant.

[[overloaded-vector-insertion]]
==== Vector Insertion Intrinsics

[,c]
----
vbfloat16m2_t __riscv_vset(vbfloat16m2_t dest, size_t index,
                           vbfloat16m1_t value);
vbfloat16m4_t __riscv_vset(vbfloat16m4_t dest, size_t index,
                           vbfloat16m1_t value);
vbfloat16m4_t __riscv_vset(vbfloat16m4_t dest, size_t index,
                           vbfloat16m2_t value);
vbfloat16m8_t __riscv_vset(vbfloat16m8_t dest, size_t index,
                           vbfloat16m1_t value);
vbfloat16m8_t __riscv_vset(vbfloat16m8_t dest, size_t index,
                           vbfloat16m2_t value);
vbfloat16m8_t __riscv_vset(vbfloat16m8_t dest, size_t index,
                           vbfloat16m4_t value);
vbfloat16mf4x2_t __riscv_vset(vbfloat16mf4x2_t dest, size_t index,
                              vbfloat16mf4_t value);
vbfloat16mf4x3_t __riscv_vset(vbfloat16mf4x3_t dest, size_t index,
                              vbfloat16mf4_t value);
vbfloat16mf4x4_t __riscv_vset(vbfloat16mf4x4_t dest, size_t index,
                              vbfloat16mf4_t value);
vbfloat16mf4x5_t __riscv_vset(vbfloat16mf4x5_t dest, size_t index,
                              vbfloat16mf4_t value);
vbfloat16mf4x6_t __riscv_vset(vbfloat16mf4x6_t dest, size_t index,
                              vbfloat16mf4_t value);
vbfloat16mf4x7_t __riscv_vset(vbfloat16mf4x7_t dest, size_t index,
                              vbfloat16mf4_t value);
vbfloat16mf4x8_t __riscv_vset(vbfloat16mf4x8_t dest, size_t index,
                              vbfloat16mf4_t value);
vbfloat16mf2x2_t __riscv_vset(vbfloat16mf2x2_t dest, size_t index,
                              vbfloat16mf2_t value);
vbfloat16mf2x3_t __riscv_vset(vbfloat16mf2x3_t dest, size_t index,
                              vbfloat16mf2_t value);
vbfloat16mf2x4_t __riscv_vset(vbfloat16mf2x4_t dest, size_t index,
                              vbfloat16mf2_t value);
vbfloat16mf2x5_t __riscv_vset(vbfloat16mf2x5_t dest, size_t index,
                              vbfloat16mf2_t value);
vbfloat16mf2x6_t __riscv_vset(vbfloat16mf2x6_t dest, size_t index,
                              vbfloat16mf2_t value);
vbfloat16mf2x7_t __riscv_vset(vbfloat16mf2x7_t dest, size_t index,
                              vbfloat16mf2_t value);
vbfloat16mf2x8_t __riscv_vset(vbfloat16mf2x8_t dest, size_t index,
                              vbfloat16mf2_t value);
vbfloat16m1x2_t __riscv_vset(vbfloat16m1x2_t dest, size_t index,
                             vbfloat16m1_t value);
vbfloat16m1x3_t __riscv_vset(vbfloat16m1x3_t dest, size_t index,
                             vbfloat16m1_t value);
vbfloat16m1x4_t __riscv_vset(vbfloat16m1x4_t dest, size_t index,
                             vbfloat16m1_t value);
vbfloat16m1x5_t __riscv_vset(vbfloat16m1x5_t dest, size_t index,
                             vbfloat16m1_t value);
vbfloat16m1x6_t __riscv_vset(vbfloat16m1x6_t dest, size_t index,
                             vbfloat16m1_t value);
vbfloat16m1x7_t __riscv_vset(vbfloat16m1x7_t dest, size_t index,
                             vbfloat16m1_t value);
vbfloat16m1x8_t __riscv_vset(vbfloat16m1x8_t dest, size_t index,
                             vbfloat16m1_t value);
vbfloat16m2x2_t __riscv_vset(vbfloat16m2x2_t dest, size_t index,
                             vbfloat16m2_t value);
vbfloat16m2x3_t __riscv_vset(vbfloat16m2x3_t dest, size_t index,
                             vbfloat16m2_t value);
vbfloat16m2x4_t __riscv_vset(vbfloat16m2x4_t dest, size_t index,
                             vbfloat16m2_t value);
vbfloat16m4x2_t __riscv_vset(vbfloat16m4x2_t dest, size_t index,
                             vbfloat16m4_t value);
----

[[overloaded-vector-extraction]]
==== Vector Extraction Intrinsics

[,c]
----
vbfloat16m1_t __riscv_vget_bf16m1(vbfloat16m2_t src, size_t index);
vbfloat16m1_t __riscv_vget_bf16m1(vbfloat16m4_t src, size_t index);
vbfloat16m1_t __riscv_vget_bf16m1(vbfloat16m8_t src, size_t index);
vbfloat16m2_t __riscv_vget_bf16m2(vbfloat16m4_t src, size_t index);
vbfloat16m2_t __riscv_vget_bf16m2(vbfloat16m8_t src, size_t index);
vbfloat16m4_t __riscv_vget_bf16m4(vbfloat16m8_t src, size_t index);
vbfloat16mf4_t __riscv_vget_bf16mf4(vbfloat16mf4x2_t src, size_t index);
vbfloat16mf4_t __riscv_vget_bf16mf4(vbfloat16mf4x3_t src, size_t index);
vbfloat16mf4_t __riscv_vget_bf16mf4(vbfloat16mf4x4_t src, size_t index);
vbfloat16mf4_t __riscv_vget_bf16mf4(vbfloat16mf4x5_t src, size_t index);
vbfloat16mf4_t __riscv_vget_bf16mf4(vbfloat16mf4x6_t src, size_t index);
vbfloat16mf4_t __riscv_vget_bf16mf4(vbfloat16mf4x7_t src, size_t index);
vbfloat16mf4_t __riscv_vget_bf16mf4(vbfloat16mf4x8_t src, size_t index);
vbfloat16mf2_t __riscv_vget_bf16mf2(vbfloat16mf2x2_t src, size_t index);
vbfloat16mf2_t __riscv_vget_bf16mf2(vbfloat16mf2x3_t src, size_t index);
vbfloat16mf2_t __riscv_vget_bf16mf2(vbfloat16mf2x4_t src, size_t index);
vbfloat16mf2_t __riscv_vget_bf16mf2(vbfloat16mf2x5_t src, size_t index);
vbfloat16mf2_t __riscv_vget_bf16mf2(vbfloat16mf2x6_t src, size_t index);
vbfloat16mf2_t __riscv_vget_bf16mf2(vbfloat16mf2x7_t src, size_t index);
vbfloat16mf2_t __riscv_vget_bf16mf2(vbfloat16mf2x8_t src, size_t index);
vbfloat16m1_t __riscv_vget_bf16m1(vbfloat16m1x2_t src, size_t index);
vbfloat16m1_t __riscv_vget_bf16m1(vbfloat16m1x3_t src, size_t index);
vbfloat16m1_t __riscv_vget_bf16m1(vbfloat16m1x4_t src, size_t index);
vbfloat16m1_t __riscv_vget_bf16m1(vbfloat16m1x5_t src, size_t index);
vbfloat16m1_t __riscv_vget_bf16m1(vbfloat16m1x6_t src, size_t index);
vbfloat16m1_t __riscv_vget_bf16m1(vbfloat16m1x7_t src, size_t index);
vbfloat16m1_t __riscv_vget_bf16m1(vbfloat16m1x8_t src, size_t index);
vbfloat16m2_t __riscv_vget_bf16m2(vbfloat16m2x2_t src, size_t index);
vbfloat16m2_t __riscv_vget_bf16m2(vbfloat16m2x3_t src, size_t index);
vbfloat16m2_t __riscv_vget_bf16m2(vbfloat16m2x4_t src, size_t index);
vbfloat16m4_t __riscv_vget_bf16m4(vbfloat16m4x2_t src, size_t index);
----

[[overloaded-vector-creation]]
==== Vector Creation Intrinsics
Intrinsics here don't have an overloaded variant.
