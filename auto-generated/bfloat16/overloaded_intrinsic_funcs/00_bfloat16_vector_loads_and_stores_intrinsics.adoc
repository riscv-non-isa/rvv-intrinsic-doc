
=== BFloat16 Vector Loads and Stores Intrinsics

[[overloaded-bf16-vector-unit-stride-load]]
==== Vector Unit-Stride Load Intrinsics

[,c]
----
// masked functions
vbfloat16mf4_t __riscv_vle16(vbool64_t vm, const __bf16 *rs1, size_t vl);
vbfloat16mf2_t __riscv_vle16(vbool32_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m1_t __riscv_vle16(vbool16_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m2_t __riscv_vle16(vbool8_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m4_t __riscv_vle16(vbool4_t vm, const __bf16 *rs1, size_t vl);
vbfloat16m8_t __riscv_vle16(vbool2_t vm, const __bf16 *rs1, size_t vl);
----

[[overloaded-bf16-vector-unit-stride-store]]
==== Vector Unit-Stride Store Intrinsics

[,c]
----
void __riscv_vse16(__bf16 *rs1, vbfloat16mf4_t vs3, size_t vl);
void __riscv_vse16(__bf16 *rs1, vbfloat16mf2_t vs3, size_t vl);
void __riscv_vse16(__bf16 *rs1, vbfloat16m1_t vs3, size_t vl);
void __riscv_vse16(__bf16 *rs1, vbfloat16m2_t vs3, size_t vl);
void __riscv_vse16(__bf16 *rs1, vbfloat16m4_t vs3, size_t vl);
void __riscv_vse16(__bf16 *rs1, vbfloat16m8_t vs3, size_t vl);
// masked functions
void __riscv_vse16(vbool64_t vm, __bf16 *rs1, vbfloat16mf4_t vs3, size_t vl);
void __riscv_vse16(vbool32_t vm, __bf16 *rs1, vbfloat16mf2_t vs3, size_t vl);
void __riscv_vse16(vbool16_t vm, __bf16 *rs1, vbfloat16m1_t vs3, size_t vl);
void __riscv_vse16(vbool8_t vm, __bf16 *rs1, vbfloat16m2_t vs3, size_t vl);
void __riscv_vse16(vbool4_t vm, __bf16 *rs1, vbfloat16m4_t vs3, size_t vl);
void __riscv_vse16(vbool2_t vm, __bf16 *rs1, vbfloat16m8_t vs3, size_t vl);
----

[[overloaded-vector-strided-load]]
==== Vector Strided Load Intrinsics

[,c]
----
// masked functions
vbfloat16mf4_t __riscv_vlse16(vbool64_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                              size_t vl);
vbfloat16mf2_t __riscv_vlse16(vbool32_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                              size_t vl);
vbfloat16m1_t __riscv_vlse16(vbool16_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                             size_t vl);
vbfloat16m2_t __riscv_vlse16(vbool8_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                             size_t vl);
vbfloat16m4_t __riscv_vlse16(vbool4_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                             size_t vl);
vbfloat16m8_t __riscv_vlse16(vbool2_t vm, const __bf16 *rs1, ptrdiff_t rs2,
                             size_t vl);
----

[[overloaded-vector-strided-store]]
==== Vector Strided Store Intrinsics

[,c]
----
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m1_t vs3, size_t vl);
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m2_t vs3, size_t vl);
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m4_t vs3, size_t vl);
void __riscv_vsse16(__bf16 *rs1, ptrdiff_t rs2, vbfloat16m8_t vs3, size_t vl);
// masked functions
void __riscv_vsse16(vbool64_t vm, __bf16 *rs1, ptrdiff_t rs2,
                    vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsse16(vbool32_t vm, __bf16 *rs1, ptrdiff_t rs2,
                    vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsse16(vbool16_t vm, __bf16 *rs1, ptrdiff_t rs2, vbfloat16m1_t vs3,
                    size_t vl);
void __riscv_vsse16(vbool8_t vm, __bf16 *rs1, ptrdiff_t rs2, vbfloat16m2_t vs3,
                    size_t vl);
void __riscv_vsse16(vbool4_t vm, __bf16 *rs1, ptrdiff_t rs2, vbfloat16m4_t vs3,
                    size_t vl);
void __riscv_vsse16(vbool2_t vm, __bf16 *rs1, ptrdiff_t rs2, vbfloat16m8_t vs3,
                    size_t vl);
----

[[overloaded-vector-indexed-load]]
==== Vector Indexed Load Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vloxei8(const __bf16 *rs1, vuint8mf8_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei8(const __bf16 *rs1, vuint8mf4_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei8(const __bf16 *rs1, vuint8mf2_t rs2, size_t vl);
vbfloat16m2_t __riscv_vloxei8(const __bf16 *rs1, vuint8m1_t rs2, size_t vl);
vbfloat16m4_t __riscv_vloxei8(const __bf16 *rs1, vuint8m2_t rs2, size_t vl);
vbfloat16m8_t __riscv_vloxei8(const __bf16 *rs1, vuint8m4_t rs2, size_t vl);
vbfloat16mf4_t __riscv_vloxei16(const __bf16 *rs1, vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei16(const __bf16 *rs1, vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei16(const __bf16 *rs1, vuint16m1_t rs2, size_t vl);
vbfloat16m2_t __riscv_vloxei16(const __bf16 *rs1, vuint16m2_t rs2, size_t vl);
vbfloat16m4_t __riscv_vloxei16(const __bf16 *rs1, vuint16m4_t rs2, size_t vl);
vbfloat16m8_t __riscv_vloxei16(const __bf16 *rs1, vuint16m8_t rs2, size_t vl);
vbfloat16mf4_t __riscv_vloxei32(const __bf16 *rs1, vuint32mf2_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei32(const __bf16 *rs1, vuint32m1_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei32(const __bf16 *rs1, vuint32m2_t rs2, size_t vl);
vbfloat16m2_t __riscv_vloxei32(const __bf16 *rs1, vuint32m4_t rs2, size_t vl);
vbfloat16m4_t __riscv_vloxei32(const __bf16 *rs1, vuint32m8_t rs2, size_t vl);
vbfloat16mf4_t __riscv_vloxei64(const __bf16 *rs1, vuint64m1_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei64(const __bf16 *rs1, vuint64m2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei64(const __bf16 *rs1, vuint64m4_t rs2, size_t vl);
vbfloat16m2_t __riscv_vloxei64(const __bf16 *rs1, vuint64m8_t rs2, size_t vl);
vbfloat16mf4_t __riscv_vluxei8(const __bf16 *rs1, vuint8mf8_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei8(const __bf16 *rs1, vuint8mf4_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei8(const __bf16 *rs1, vuint8mf2_t rs2, size_t vl);
vbfloat16m2_t __riscv_vluxei8(const __bf16 *rs1, vuint8m1_t rs2, size_t vl);
vbfloat16m4_t __riscv_vluxei8(const __bf16 *rs1, vuint8m2_t rs2, size_t vl);
vbfloat16m8_t __riscv_vluxei8(const __bf16 *rs1, vuint8m4_t rs2, size_t vl);
vbfloat16mf4_t __riscv_vluxei16(const __bf16 *rs1, vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei16(const __bf16 *rs1, vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei16(const __bf16 *rs1, vuint16m1_t rs2, size_t vl);
vbfloat16m2_t __riscv_vluxei16(const __bf16 *rs1, vuint16m2_t rs2, size_t vl);
vbfloat16m4_t __riscv_vluxei16(const __bf16 *rs1, vuint16m4_t rs2, size_t vl);
vbfloat16m8_t __riscv_vluxei16(const __bf16 *rs1, vuint16m8_t rs2, size_t vl);
vbfloat16mf4_t __riscv_vluxei32(const __bf16 *rs1, vuint32mf2_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei32(const __bf16 *rs1, vuint32m1_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei32(const __bf16 *rs1, vuint32m2_t rs2, size_t vl);
vbfloat16m2_t __riscv_vluxei32(const __bf16 *rs1, vuint32m4_t rs2, size_t vl);
vbfloat16m4_t __riscv_vluxei32(const __bf16 *rs1, vuint32m8_t rs2, size_t vl);
vbfloat16mf4_t __riscv_vluxei64(const __bf16 *rs1, vuint64m1_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei64(const __bf16 *rs1, vuint64m2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei64(const __bf16 *rs1, vuint64m4_t rs2, size_t vl);
vbfloat16m2_t __riscv_vluxei64(const __bf16 *rs1, vuint64m8_t rs2, size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vloxei8(vbool64_t vm, const __bf16 *rs1, vuint8mf8_t rs2,
                               size_t vl);
vbfloat16mf2_t __riscv_vloxei8(vbool32_t vm, const __bf16 *rs1, vuint8mf4_t rs2,
                               size_t vl);
vbfloat16m1_t __riscv_vloxei8(vbool16_t vm, const __bf16 *rs1, vuint8mf2_t rs2,
                              size_t vl);
vbfloat16m2_t __riscv_vloxei8(vbool8_t vm, const __bf16 *rs1, vuint8m1_t rs2,
                              size_t vl);
vbfloat16m4_t __riscv_vloxei8(vbool4_t vm, const __bf16 *rs1, vuint8m2_t rs2,
                              size_t vl);
vbfloat16m8_t __riscv_vloxei8(vbool2_t vm, const __bf16 *rs1, vuint8m4_t rs2,
                              size_t vl);
vbfloat16mf4_t __riscv_vloxei16(vbool64_t vm, const __bf16 *rs1,
                                vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei16(vbool32_t vm, const __bf16 *rs1,
                                vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei16(vbool16_t vm, const __bf16 *rs1, vuint16m1_t rs2,
                               size_t vl);
vbfloat16m2_t __riscv_vloxei16(vbool8_t vm, const __bf16 *rs1, vuint16m2_t rs2,
                               size_t vl);
vbfloat16m4_t __riscv_vloxei16(vbool4_t vm, const __bf16 *rs1, vuint16m4_t rs2,
                               size_t vl);
vbfloat16m8_t __riscv_vloxei16(vbool2_t vm, const __bf16 *rs1, vuint16m8_t rs2,
                               size_t vl);
vbfloat16mf4_t __riscv_vloxei32(vbool64_t vm, const __bf16 *rs1,
                                vuint32mf2_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei32(vbool32_t vm, const __bf16 *rs1,
                                vuint32m1_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei32(vbool16_t vm, const __bf16 *rs1, vuint32m2_t rs2,
                               size_t vl);
vbfloat16m2_t __riscv_vloxei32(vbool8_t vm, const __bf16 *rs1, vuint32m4_t rs2,
                               size_t vl);
vbfloat16m4_t __riscv_vloxei32(vbool4_t vm, const __bf16 *rs1, vuint32m8_t rs2,
                               size_t vl);
vbfloat16mf4_t __riscv_vloxei64(vbool64_t vm, const __bf16 *rs1,
                                vuint64m1_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vloxei64(vbool32_t vm, const __bf16 *rs1,
                                vuint64m2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vloxei64(vbool16_t vm, const __bf16 *rs1, vuint64m4_t rs2,
                               size_t vl);
vbfloat16m2_t __riscv_vloxei64(vbool8_t vm, const __bf16 *rs1, vuint64m8_t rs2,
                               size_t vl);
vbfloat16mf4_t __riscv_vluxei8(vbool64_t vm, const __bf16 *rs1, vuint8mf8_t rs2,
                               size_t vl);
vbfloat16mf2_t __riscv_vluxei8(vbool32_t vm, const __bf16 *rs1, vuint8mf4_t rs2,
                               size_t vl);
vbfloat16m1_t __riscv_vluxei8(vbool16_t vm, const __bf16 *rs1, vuint8mf2_t rs2,
                              size_t vl);
vbfloat16m2_t __riscv_vluxei8(vbool8_t vm, const __bf16 *rs1, vuint8m1_t rs2,
                              size_t vl);
vbfloat16m4_t __riscv_vluxei8(vbool4_t vm, const __bf16 *rs1, vuint8m2_t rs2,
                              size_t vl);
vbfloat16m8_t __riscv_vluxei8(vbool2_t vm, const __bf16 *rs1, vuint8m4_t rs2,
                              size_t vl);
vbfloat16mf4_t __riscv_vluxei16(vbool64_t vm, const __bf16 *rs1,
                                vuint16mf4_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei16(vbool32_t vm, const __bf16 *rs1,
                                vuint16mf2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei16(vbool16_t vm, const __bf16 *rs1, vuint16m1_t rs2,
                               size_t vl);
vbfloat16m2_t __riscv_vluxei16(vbool8_t vm, const __bf16 *rs1, vuint16m2_t rs2,
                               size_t vl);
vbfloat16m4_t __riscv_vluxei16(vbool4_t vm, const __bf16 *rs1, vuint16m4_t rs2,
                               size_t vl);
vbfloat16m8_t __riscv_vluxei16(vbool2_t vm, const __bf16 *rs1, vuint16m8_t rs2,
                               size_t vl);
vbfloat16mf4_t __riscv_vluxei32(vbool64_t vm, const __bf16 *rs1,
                                vuint32mf2_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei32(vbool32_t vm, const __bf16 *rs1,
                                vuint32m1_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei32(vbool16_t vm, const __bf16 *rs1, vuint32m2_t rs2,
                               size_t vl);
vbfloat16m2_t __riscv_vluxei32(vbool8_t vm, const __bf16 *rs1, vuint32m4_t rs2,
                               size_t vl);
vbfloat16m4_t __riscv_vluxei32(vbool4_t vm, const __bf16 *rs1, vuint32m8_t rs2,
                               size_t vl);
vbfloat16mf4_t __riscv_vluxei64(vbool64_t vm, const __bf16 *rs1,
                                vuint64m1_t rs2, size_t vl);
vbfloat16mf2_t __riscv_vluxei64(vbool32_t vm, const __bf16 *rs1,
                                vuint64m2_t rs2, size_t vl);
vbfloat16m1_t __riscv_vluxei64(vbool16_t vm, const __bf16 *rs1, vuint64m4_t rs2,
                               size_t vl);
vbfloat16m2_t __riscv_vluxei64(vbool8_t vm, const __bf16 *rs1, vuint64m8_t rs2,
                               size_t vl);
----

[[overloaded-vector-indexed-store]]
==== Vector Indexed Store Intrinsics

[,c]
----
void __riscv_vsoxei8(__bf16 *rs1, vuint8mf8_t rs2, vbfloat16mf4_t vs3,
                     size_t vl);
void __riscv_vsoxei8(__bf16 *rs1, vuint8mf4_t rs2, vbfloat16mf2_t vs3,
                     size_t vl);
void __riscv_vsoxei8(__bf16 *rs1, vuint8mf2_t rs2, vbfloat16m1_t vs3,
                     size_t vl);
void __riscv_vsoxei8(__bf16 *rs1, vuint8m1_t rs2, vbfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei8(__bf16 *rs1, vuint8m2_t rs2, vbfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei8(__bf16 *rs1, vuint8m4_t rs2, vbfloat16m8_t vs3, size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16mf4_t rs2, vbfloat16mf4_t vs3,
                      size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16mf2_t rs2, vbfloat16mf2_t vs3,
                      size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16m1_t rs2, vbfloat16m1_t vs3,
                      size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16m2_t rs2, vbfloat16m2_t vs3,
                      size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16m4_t rs2, vbfloat16m4_t vs3,
                      size_t vl);
void __riscv_vsoxei16(__bf16 *rs1, vuint16m8_t rs2, vbfloat16m8_t vs3,
                      size_t vl);
void __riscv_vsoxei32(__bf16 *rs1, vuint32mf2_t rs2, vbfloat16mf4_t vs3,
                      size_t vl);
void __riscv_vsoxei32(__bf16 *rs1, vuint32m1_t rs2, vbfloat16mf2_t vs3,
                      size_t vl);
void __riscv_vsoxei32(__bf16 *rs1, vuint32m2_t rs2, vbfloat16m1_t vs3,
                      size_t vl);
void __riscv_vsoxei32(__bf16 *rs1, vuint32m4_t rs2, vbfloat16m2_t vs3,
                      size_t vl);
void __riscv_vsoxei32(__bf16 *rs1, vuint32m8_t rs2, vbfloat16m4_t vs3,
                      size_t vl);
void __riscv_vsoxei64(__bf16 *rs1, vuint64m1_t rs2, vbfloat16mf4_t vs3,
                      size_t vl);
void __riscv_vsoxei64(__bf16 *rs1, vuint64m2_t rs2, vbfloat16mf2_t vs3,
                      size_t vl);
void __riscv_vsoxei64(__bf16 *rs1, vuint64m4_t rs2, vbfloat16m1_t vs3,
                      size_t vl);
void __riscv_vsoxei64(__bf16 *rs1, vuint64m8_t rs2, vbfloat16m2_t vs3,
                      size_t vl);
void __riscv_vsuxei8(__bf16 *rs1, vuint8mf8_t rs2, vbfloat16mf4_t vs3,
                     size_t vl);
void __riscv_vsuxei8(__bf16 *rs1, vuint8mf4_t rs2, vbfloat16mf2_t vs3,
                     size_t vl);
void __riscv_vsuxei8(__bf16 *rs1, vuint8mf2_t rs2, vbfloat16m1_t vs3,
                     size_t vl);
void __riscv_vsuxei8(__bf16 *rs1, vuint8m1_t rs2, vbfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei8(__bf16 *rs1, vuint8m2_t rs2, vbfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei8(__bf16 *rs1, vuint8m4_t rs2, vbfloat16m8_t vs3, size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16mf4_t rs2, vbfloat16mf4_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16mf2_t rs2, vbfloat16mf2_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16m1_t rs2, vbfloat16m1_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16m2_t rs2, vbfloat16m2_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16m4_t rs2, vbfloat16m4_t vs3,
                      size_t vl);
void __riscv_vsuxei16(__bf16 *rs1, vuint16m8_t rs2, vbfloat16m8_t vs3,
                      size_t vl);
void __riscv_vsuxei32(__bf16 *rs1, vuint32mf2_t rs2, vbfloat16mf4_t vs3,
                      size_t vl);
void __riscv_vsuxei32(__bf16 *rs1, vuint32m1_t rs2, vbfloat16mf2_t vs3,
                      size_t vl);
void __riscv_vsuxei32(__bf16 *rs1, vuint32m2_t rs2, vbfloat16m1_t vs3,
                      size_t vl);
void __riscv_vsuxei32(__bf16 *rs1, vuint32m4_t rs2, vbfloat16m2_t vs3,
                      size_t vl);
void __riscv_vsuxei32(__bf16 *rs1, vuint32m8_t rs2, vbfloat16m4_t vs3,
                      size_t vl);
void __riscv_vsuxei64(__bf16 *rs1, vuint64m1_t rs2, vbfloat16mf4_t vs3,
                      size_t vl);
void __riscv_vsuxei64(__bf16 *rs1, vuint64m2_t rs2, vbfloat16mf2_t vs3,
                      size_t vl);
void __riscv_vsuxei64(__bf16 *rs1, vuint64m4_t rs2, vbfloat16m1_t vs3,
                      size_t vl);
void __riscv_vsuxei64(__bf16 *rs1, vuint64m8_t rs2, vbfloat16m2_t vs3,
                      size_t vl);
// masked functions
void __riscv_vsoxei8(vbool64_t vm, __bf16 *rs1, vuint8mf8_t rs2,
                     vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei8(vbool32_t vm, __bf16 *rs1, vuint8mf4_t rs2,
                     vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei8(vbool16_t vm, __bf16 *rs1, vuint8mf2_t rs2,
                     vbfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei8(vbool8_t vm, __bf16 *rs1, vuint8m1_t rs2,
                     vbfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei8(vbool4_t vm, __bf16 *rs1, vuint8m2_t rs2,
                     vbfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei8(vbool2_t vm, __bf16 *rs1, vuint8m4_t rs2,
                     vbfloat16m8_t vs3, size_t vl);
void __riscv_vsoxei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t rs2,
                      vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t rs2,
                      vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t rs2,
                      vbfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei16(vbool8_t vm, __bf16 *rs1, vuint16m2_t rs2,
                      vbfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei16(vbool4_t vm, __bf16 *rs1, vuint16m4_t rs2,
                      vbfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei16(vbool2_t vm, __bf16 *rs1, vuint16m8_t rs2,
                      vbfloat16m8_t vs3, size_t vl);
void __riscv_vsoxei32(vbool64_t vm, __bf16 *rs1, vuint32mf2_t rs2,
                      vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei32(vbool32_t vm, __bf16 *rs1, vuint32m1_t rs2,
                      vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei32(vbool16_t vm, __bf16 *rs1, vuint32m2_t rs2,
                      vbfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei32(vbool8_t vm, __bf16 *rs1, vuint32m4_t rs2,
                      vbfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei32(vbool4_t vm, __bf16 *rs1, vuint32m8_t rs2,
                      vbfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei64(vbool64_t vm, __bf16 *rs1, vuint64m1_t rs2,
                      vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei64(vbool32_t vm, __bf16 *rs1, vuint64m2_t rs2,
                      vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei64(vbool16_t vm, __bf16 *rs1, vuint64m4_t rs2,
                      vbfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei64(vbool8_t vm, __bf16 *rs1, vuint64m8_t rs2,
                      vbfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei8(vbool64_t vm, __bf16 *rs1, vuint8mf8_t rs2,
                     vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei8(vbool32_t vm, __bf16 *rs1, vuint8mf4_t rs2,
                     vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei8(vbool16_t vm, __bf16 *rs1, vuint8mf2_t rs2,
                     vbfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei8(vbool8_t vm, __bf16 *rs1, vuint8m1_t rs2,
                     vbfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei8(vbool4_t vm, __bf16 *rs1, vuint8m2_t rs2,
                     vbfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei8(vbool2_t vm, __bf16 *rs1, vuint8m4_t rs2,
                     vbfloat16m8_t vs3, size_t vl);
void __riscv_vsuxei16(vbool64_t vm, __bf16 *rs1, vuint16mf4_t rs2,
                      vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei16(vbool32_t vm, __bf16 *rs1, vuint16mf2_t rs2,
                      vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei16(vbool16_t vm, __bf16 *rs1, vuint16m1_t rs2,
                      vbfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei16(vbool8_t vm, __bf16 *rs1, vuint16m2_t rs2,
                      vbfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei16(vbool4_t vm, __bf16 *rs1, vuint16m4_t rs2,
                      vbfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei16(vbool2_t vm, __bf16 *rs1, vuint16m8_t rs2,
                      vbfloat16m8_t vs3, size_t vl);
void __riscv_vsuxei32(vbool64_t vm, __bf16 *rs1, vuint32mf2_t rs2,
                      vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei32(vbool32_t vm, __bf16 *rs1, vuint32m1_t rs2,
                      vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei32(vbool16_t vm, __bf16 *rs1, vuint32m2_t rs2,
                      vbfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei32(vbool8_t vm, __bf16 *rs1, vuint32m4_t rs2,
                      vbfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei32(vbool4_t vm, __bf16 *rs1, vuint32m8_t rs2,
                      vbfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei64(vbool64_t vm, __bf16 *rs1, vuint64m1_t rs2,
                      vbfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei64(vbool32_t vm, __bf16 *rs1, vuint64m2_t rs2,
                      vbfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei64(vbool16_t vm, __bf16 *rs1, vuint64m4_t rs2,
                      vbfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei64(vbool8_t vm, __bf16 *rs1, vuint64m8_t rs2,
                      vbfloat16m2_t vs3, size_t vl);
----

[[overloaded-unit-stride-fault-only-first-loads]]
==== Unit-stride Fault-Only-First Loads Intrinsics

[,c]
----
// masked functions
vbfloat16mf4_t __riscv_vle16ff(vbool64_t vm, const __bf16 *rs1, size_t *new_vl,
                               size_t vl);
vbfloat16mf2_t __riscv_vle16ff(vbool32_t vm, const __bf16 *rs1, size_t *new_vl,
                               size_t vl);
vbfloat16m1_t __riscv_vle16ff(vbool16_t vm, const __bf16 *rs1, size_t *new_vl,
                              size_t vl);
vbfloat16m2_t __riscv_vle16ff(vbool8_t vm, const __bf16 *rs1, size_t *new_vl,
                              size_t vl);
vbfloat16m4_t __riscv_vle16ff(vbool4_t vm, const __bf16 *rs1, size_t *new_vl,
                              size_t vl);
vbfloat16m8_t __riscv_vle16ff(vbool2_t vm, const __bf16 *rs1, size_t *new_vl,
                              size_t vl);
----
