
=== BFloat16 Vector Permutation Intrinsics

[[vector-slideup]]
==== Vector Slideup Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vslideup_vx_bf16mf4(vbfloat16mf4_t vd,
                                           vbfloat16mf4_t vs2, size_t rs1,
                                           size_t vl);
vbfloat16mf2_t __riscv_vslideup_vx_bf16mf2(vbfloat16mf2_t vd,
                                           vbfloat16mf2_t vs2, size_t rs1,
                                           size_t vl);
vbfloat16m1_t __riscv_vslideup_vx_bf16m1(vbfloat16m1_t vd, vbfloat16m1_t vs2,
                                         size_t rs1, size_t vl);
vbfloat16m2_t __riscv_vslideup_vx_bf16m2(vbfloat16m2_t vd, vbfloat16m2_t vs2,
                                         size_t rs1, size_t vl);
vbfloat16m4_t __riscv_vslideup_vx_bf16m4(vbfloat16m4_t vd, vbfloat16m4_t vs2,
                                         size_t rs1, size_t vl);
vbfloat16m8_t __riscv_vslideup_vx_bf16m8(vbfloat16m8_t vd, vbfloat16m8_t vs2,
                                         size_t rs1, size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vslideup_vx_bf16mf4_m(vbool64_t vm, vbfloat16mf4_t vd,
                                             vbfloat16mf4_t vs2, size_t rs1,
                                             size_t vl);
vbfloat16mf2_t __riscv_vslideup_vx_bf16mf2_m(vbool32_t vm, vbfloat16mf2_t vd,
                                             vbfloat16mf2_t vs2, size_t rs1,
                                             size_t vl);
vbfloat16m1_t __riscv_vslideup_vx_bf16m1_m(vbool16_t vm, vbfloat16m1_t vd,
                                           vbfloat16m1_t vs2, size_t rs1,
                                           size_t vl);
vbfloat16m2_t __riscv_vslideup_vx_bf16m2_m(vbool8_t vm, vbfloat16m2_t vd,
                                           vbfloat16m2_t vs2, size_t rs1,
                                           size_t vl);
vbfloat16m4_t __riscv_vslideup_vx_bf16m4_m(vbool4_t vm, vbfloat16m4_t vd,
                                           vbfloat16m4_t vs2, size_t rs1,
                                           size_t vl);
vbfloat16m8_t __riscv_vslideup_vx_bf16m8_m(vbool2_t vm, vbfloat16m8_t vd,
                                           vbfloat16m8_t vs2, size_t rs1,
                                           size_t vl);
----

[[vector-slidedown]]
==== Vector Slidedown Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vslidedown_vx_bf16mf4(vbfloat16mf4_t vs2, size_t rs1,
                                             size_t vl);
vbfloat16mf2_t __riscv_vslidedown_vx_bf16mf2(vbfloat16mf2_t vs2, size_t rs1,
                                             size_t vl);
vbfloat16m1_t __riscv_vslidedown_vx_bf16m1(vbfloat16m1_t vs2, size_t rs1,
                                           size_t vl);
vbfloat16m2_t __riscv_vslidedown_vx_bf16m2(vbfloat16m2_t vs2, size_t rs1,
                                           size_t vl);
vbfloat16m4_t __riscv_vslidedown_vx_bf16m4(vbfloat16m4_t vs2, size_t rs1,
                                           size_t vl);
vbfloat16m8_t __riscv_vslidedown_vx_bf16m8(vbfloat16m8_t vs2, size_t rs1,
                                           size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vslidedown_vx_bf16mf4_m(vbool64_t vm, vbfloat16mf4_t vs2,
                                               size_t rs1, size_t vl);
vbfloat16mf2_t __riscv_vslidedown_vx_bf16mf2_m(vbool32_t vm, vbfloat16mf2_t vs2,
                                               size_t rs1, size_t vl);
vbfloat16m1_t __riscv_vslidedown_vx_bf16m1_m(vbool16_t vm, vbfloat16m1_t vs2,
                                             size_t rs1, size_t vl);
vbfloat16m2_t __riscv_vslidedown_vx_bf16m2_m(vbool8_t vm, vbfloat16m2_t vs2,
                                             size_t rs1, size_t vl);
vbfloat16m4_t __riscv_vslidedown_vx_bf16m4_m(vbool4_t vm, vbfloat16m4_t vs2,
                                             size_t rs1, size_t vl);
vbfloat16m8_t __riscv_vslidedown_vx_bf16m8_m(vbool2_t vm, vbfloat16m8_t vs2,
                                             size_t rs1, size_t vl);
----

[[vector-register-gather]]
==== Vector Register Gather Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vrgather_vv_bf16mf4(vbfloat16mf4_t vs2, vuint16mf4_t vs1,
                                           size_t vl);
vbfloat16mf4_t __riscv_vrgather_vx_bf16mf4(vbfloat16mf4_t vs2, size_t vs1,
                                           size_t vl);
vbfloat16mf2_t __riscv_vrgather_vv_bf16mf2(vbfloat16mf2_t vs2, vuint16mf2_t vs1,
                                           size_t vl);
vbfloat16mf2_t __riscv_vrgather_vx_bf16mf2(vbfloat16mf2_t vs2, size_t vs1,
                                           size_t vl);
vbfloat16m1_t __riscv_vrgather_vv_bf16m1(vbfloat16m1_t vs2, vuint16m1_t vs1,
                                         size_t vl);
vbfloat16m1_t __riscv_vrgather_vx_bf16m1(vbfloat16m1_t vs2, size_t vs1,
                                         size_t vl);
vbfloat16m2_t __riscv_vrgather_vv_bf16m2(vbfloat16m2_t vs2, vuint16m2_t vs1,
                                         size_t vl);
vbfloat16m2_t __riscv_vrgather_vx_bf16m2(vbfloat16m2_t vs2, size_t vs1,
                                         size_t vl);
vbfloat16m4_t __riscv_vrgather_vv_bf16m4(vbfloat16m4_t vs2, vuint16m4_t vs1,
                                         size_t vl);
vbfloat16m4_t __riscv_vrgather_vx_bf16m4(vbfloat16m4_t vs2, size_t vs1,
                                         size_t vl);
vbfloat16m8_t __riscv_vrgather_vv_bf16m8(vbfloat16m8_t vs2, vuint16m8_t vs1,
                                         size_t vl);
vbfloat16m8_t __riscv_vrgather_vx_bf16m8(vbfloat16m8_t vs2, size_t vs1,
                                         size_t vl);
vbfloat16mf4_t __riscv_vrgatherei16_vv_bf16mf4(vbfloat16mf4_t vs2,
                                               vuint16mf4_t vs1, size_t vl);
vbfloat16mf2_t __riscv_vrgatherei16_vv_bf16mf2(vbfloat16mf2_t vs2,
                                               vuint16mf2_t vs1, size_t vl);
vbfloat16m1_t __riscv_vrgatherei16_vv_bf16m1(vbfloat16m1_t vs2, vuint16m1_t vs1,
                                             size_t vl);
vbfloat16m2_t __riscv_vrgatherei16_vv_bf16m2(vbfloat16m2_t vs2, vuint16m2_t vs1,
                                             size_t vl);
vbfloat16m4_t __riscv_vrgatherei16_vv_bf16m4(vbfloat16m4_t vs2, vuint16m4_t vs1,
                                             size_t vl);
vbfloat16m8_t __riscv_vrgatherei16_vv_bf16m8(vbfloat16m8_t vs2, vuint16m8_t vs1,
                                             size_t vl);
// masked functions
vbfloat16mf4_t __riscv_vrgather_vv_bf16mf4_m(vbool64_t vm, vbfloat16mf4_t vs2,
                                             vuint16mf4_t vs1, size_t vl);
vbfloat16mf4_t __riscv_vrgather_vx_bf16mf4_m(vbool64_t vm, vbfloat16mf4_t vs2,
                                             size_t vs1, size_t vl);
vbfloat16mf2_t __riscv_vrgather_vv_bf16mf2_m(vbool32_t vm, vbfloat16mf2_t vs2,
                                             vuint16mf2_t vs1, size_t vl);
vbfloat16mf2_t __riscv_vrgather_vx_bf16mf2_m(vbool32_t vm, vbfloat16mf2_t vs2,
                                             size_t vs1, size_t vl);
vbfloat16m1_t __riscv_vrgather_vv_bf16m1_m(vbool16_t vm, vbfloat16m1_t vs2,
                                           vuint16m1_t vs1, size_t vl);
vbfloat16m1_t __riscv_vrgather_vx_bf16m1_m(vbool16_t vm, vbfloat16m1_t vs2,
                                           size_t vs1, size_t vl);
vbfloat16m2_t __riscv_vrgather_vv_bf16m2_m(vbool8_t vm, vbfloat16m2_t vs2,
                                           vuint16m2_t vs1, size_t vl);
vbfloat16m2_t __riscv_vrgather_vx_bf16m2_m(vbool8_t vm, vbfloat16m2_t vs2,
                                           size_t vs1, size_t vl);
vbfloat16m4_t __riscv_vrgather_vv_bf16m4_m(vbool4_t vm, vbfloat16m4_t vs2,
                                           vuint16m4_t vs1, size_t vl);
vbfloat16m4_t __riscv_vrgather_vx_bf16m4_m(vbool4_t vm, vbfloat16m4_t vs2,
                                           size_t vs1, size_t vl);
vbfloat16m8_t __riscv_vrgather_vv_bf16m8_m(vbool2_t vm, vbfloat16m8_t vs2,
                                           vuint16m8_t vs1, size_t vl);
vbfloat16m8_t __riscv_vrgather_vx_bf16m8_m(vbool2_t vm, vbfloat16m8_t vs2,
                                           size_t vs1, size_t vl);
vbfloat16mf4_t __riscv_vrgatherei16_vv_bf16mf4_m(vbool64_t vm,
                                                 vbfloat16mf4_t vs2,
                                                 vuint16mf4_t vs1, size_t vl);
vbfloat16mf2_t __riscv_vrgatherei16_vv_bf16mf2_m(vbool32_t vm,
                                                 vbfloat16mf2_t vs2,
                                                 vuint16mf2_t vs1, size_t vl);
vbfloat16m1_t __riscv_vrgatherei16_vv_bf16m1_m(vbool16_t vm, vbfloat16m1_t vs2,
                                               vuint16m1_t vs1, size_t vl);
vbfloat16m2_t __riscv_vrgatherei16_vv_bf16m2_m(vbool8_t vm, vbfloat16m2_t vs2,
                                               vuint16m2_t vs1, size_t vl);
vbfloat16m4_t __riscv_vrgatherei16_vv_bf16m4_m(vbool4_t vm, vbfloat16m4_t vs2,
                                               vuint16m4_t vs1, size_t vl);
vbfloat16m8_t __riscv_vrgatherei16_vv_bf16m8_m(vbool2_t vm, vbfloat16m8_t vs2,
                                               vuint16m8_t vs1, size_t vl);
----

[[vector-compress]]
==== Vector Compress Intrinsics

[,c]
----
vbfloat16mf4_t __riscv_vcompress_vm_bf16mf4(vbfloat16mf4_t vs2, vbool64_t vs1,
                                            size_t vl);
vbfloat16mf2_t __riscv_vcompress_vm_bf16mf2(vbfloat16mf2_t vs2, vbool32_t vs1,
                                            size_t vl);
vbfloat16m1_t __riscv_vcompress_vm_bf16m1(vbfloat16m1_t vs2, vbool16_t vs1,
                                          size_t vl);
vbfloat16m2_t __riscv_vcompress_vm_bf16m2(vbfloat16m2_t vs2, vbool8_t vs1,
                                          size_t vl);
vbfloat16m4_t __riscv_vcompress_vm_bf16m4(vbfloat16m4_t vs2, vbool4_t vs1,
                                          size_t vl);
vbfloat16m8_t __riscv_vcompress_vm_bf16m8(vbfloat16m8_t vs2, vbool2_t vs1,
                                          size_t vl);
----
