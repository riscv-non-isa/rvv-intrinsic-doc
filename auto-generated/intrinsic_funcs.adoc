
=== Vector Loads and Stores Intrinsics

[[vector-unit-stride-load]]
==== Vector Unit-Stride Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vle16_v_f16mf4(const _Float16 *rs1, size_t vl);
vfloat16mf2_t __riscv_vle16_v_f16mf2(const _Float16 *rs1, size_t vl);
vfloat16m1_t __riscv_vle16_v_f16m1(const _Float16 *rs1, size_t vl);
vfloat16m2_t __riscv_vle16_v_f16m2(const _Float16 *rs1, size_t vl);
vfloat16m4_t __riscv_vle16_v_f16m4(const _Float16 *rs1, size_t vl);
vfloat16m8_t __riscv_vle16_v_f16m8(const _Float16 *rs1, size_t vl);
vfloat32mf2_t __riscv_vle32_v_f32mf2(const float *rs1, size_t vl);
vfloat32m1_t __riscv_vle32_v_f32m1(const float *rs1, size_t vl);
vfloat32m2_t __riscv_vle32_v_f32m2(const float *rs1, size_t vl);
vfloat32m4_t __riscv_vle32_v_f32m4(const float *rs1, size_t vl);
vfloat32m8_t __riscv_vle32_v_f32m8(const float *rs1, size_t vl);
vfloat64m1_t __riscv_vle64_v_f64m1(const double *rs1, size_t vl);
vfloat64m2_t __riscv_vle64_v_f64m2(const double *rs1, size_t vl);
vfloat64m4_t __riscv_vle64_v_f64m4(const double *rs1, size_t vl);
vfloat64m8_t __riscv_vle64_v_f64m8(const double *rs1, size_t vl);
vint8mf8_t __riscv_vle8_v_i8mf8(const int8_t *rs1, size_t vl);
vint8mf4_t __riscv_vle8_v_i8mf4(const int8_t *rs1, size_t vl);
vint8mf2_t __riscv_vle8_v_i8mf2(const int8_t *rs1, size_t vl);
vint8m1_t __riscv_vle8_v_i8m1(const int8_t *rs1, size_t vl);
vint8m2_t __riscv_vle8_v_i8m2(const int8_t *rs1, size_t vl);
vint8m4_t __riscv_vle8_v_i8m4(const int8_t *rs1, size_t vl);
vint8m8_t __riscv_vle8_v_i8m8(const int8_t *rs1, size_t vl);
vint16mf4_t __riscv_vle16_v_i16mf4(const int16_t *rs1, size_t vl);
vint16mf2_t __riscv_vle16_v_i16mf2(const int16_t *rs1, size_t vl);
vint16m1_t __riscv_vle16_v_i16m1(const int16_t *rs1, size_t vl);
vint16m2_t __riscv_vle16_v_i16m2(const int16_t *rs1, size_t vl);
vint16m4_t __riscv_vle16_v_i16m4(const int16_t *rs1, size_t vl);
vint16m8_t __riscv_vle16_v_i16m8(const int16_t *rs1, size_t vl);
vint32mf2_t __riscv_vle32_v_i32mf2(const int32_t *rs1, size_t vl);
vint32m1_t __riscv_vle32_v_i32m1(const int32_t *rs1, size_t vl);
vint32m2_t __riscv_vle32_v_i32m2(const int32_t *rs1, size_t vl);
vint32m4_t __riscv_vle32_v_i32m4(const int32_t *rs1, size_t vl);
vint32m8_t __riscv_vle32_v_i32m8(const int32_t *rs1, size_t vl);
vint64m1_t __riscv_vle64_v_i64m1(const int64_t *rs1, size_t vl);
vint64m2_t __riscv_vle64_v_i64m2(const int64_t *rs1, size_t vl);
vint64m4_t __riscv_vle64_v_i64m4(const int64_t *rs1, size_t vl);
vint64m8_t __riscv_vle64_v_i64m8(const int64_t *rs1, size_t vl);
vuint8mf8_t __riscv_vle8_v_u8mf8(const uint8_t *rs1, size_t vl);
vuint8mf4_t __riscv_vle8_v_u8mf4(const uint8_t *rs1, size_t vl);
vuint8mf2_t __riscv_vle8_v_u8mf2(const uint8_t *rs1, size_t vl);
vuint8m1_t __riscv_vle8_v_u8m1(const uint8_t *rs1, size_t vl);
vuint8m2_t __riscv_vle8_v_u8m2(const uint8_t *rs1, size_t vl);
vuint8m4_t __riscv_vle8_v_u8m4(const uint8_t *rs1, size_t vl);
vuint8m8_t __riscv_vle8_v_u8m8(const uint8_t *rs1, size_t vl);
vuint16mf4_t __riscv_vle16_v_u16mf4(const uint16_t *rs1, size_t vl);
vuint16mf2_t __riscv_vle16_v_u16mf2(const uint16_t *rs1, size_t vl);
vuint16m1_t __riscv_vle16_v_u16m1(const uint16_t *rs1, size_t vl);
vuint16m2_t __riscv_vle16_v_u16m2(const uint16_t *rs1, size_t vl);
vuint16m4_t __riscv_vle16_v_u16m4(const uint16_t *rs1, size_t vl);
vuint16m8_t __riscv_vle16_v_u16m8(const uint16_t *rs1, size_t vl);
vuint32mf2_t __riscv_vle32_v_u32mf2(const uint32_t *rs1, size_t vl);
vuint32m1_t __riscv_vle32_v_u32m1(const uint32_t *rs1, size_t vl);
vuint32m2_t __riscv_vle32_v_u32m2(const uint32_t *rs1, size_t vl);
vuint32m4_t __riscv_vle32_v_u32m4(const uint32_t *rs1, size_t vl);
vuint32m8_t __riscv_vle32_v_u32m8(const uint32_t *rs1, size_t vl);
vuint64m1_t __riscv_vle64_v_u64m1(const uint64_t *rs1, size_t vl);
vuint64m2_t __riscv_vle64_v_u64m2(const uint64_t *rs1, size_t vl);
vuint64m4_t __riscv_vle64_v_u64m4(const uint64_t *rs1, size_t vl);
vuint64m8_t __riscv_vle64_v_u64m8(const uint64_t *rs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                       size_t vl);
vfloat16mf2_t __riscv_vle16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                       size_t vl);
vfloat16m1_t __riscv_vle16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                     size_t vl);
vfloat16m2_t __riscv_vle16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                     size_t vl);
vfloat16m4_t __riscv_vle16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                     size_t vl);
vfloat16m8_t __riscv_vle16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                     size_t vl);
vfloat32mf2_t __riscv_vle32_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                       size_t vl);
vfloat32m1_t __riscv_vle32_v_f32m1_m(vbool32_t vm, const float *rs1, size_t vl);
vfloat32m2_t __riscv_vle32_v_f32m2_m(vbool16_t vm, const float *rs1, size_t vl);
vfloat32m4_t __riscv_vle32_v_f32m4_m(vbool8_t vm, const float *rs1, size_t vl);
vfloat32m8_t __riscv_vle32_v_f32m8_m(vbool4_t vm, const float *rs1, size_t vl);
vfloat64m1_t __riscv_vle64_v_f64m1_m(vbool64_t vm, const double *rs1,
                                     size_t vl);
vfloat64m2_t __riscv_vle64_v_f64m2_m(vbool32_t vm, const double *rs1,
                                     size_t vl);
vfloat64m4_t __riscv_vle64_v_f64m4_m(vbool16_t vm, const double *rs1,
                                     size_t vl);
vfloat64m8_t __riscv_vle64_v_f64m8_m(vbool8_t vm, const double *rs1, size_t vl);
vint8mf8_t __riscv_vle8_v_i8mf8_m(vbool64_t vm, const int8_t *rs1, size_t vl);
vint8mf4_t __riscv_vle8_v_i8mf4_m(vbool32_t vm, const int8_t *rs1, size_t vl);
vint8mf2_t __riscv_vle8_v_i8mf2_m(vbool16_t vm, const int8_t *rs1, size_t vl);
vint8m1_t __riscv_vle8_v_i8m1_m(vbool8_t vm, const int8_t *rs1, size_t vl);
vint8m2_t __riscv_vle8_v_i8m2_m(vbool4_t vm, const int8_t *rs1, size_t vl);
vint8m4_t __riscv_vle8_v_i8m4_m(vbool2_t vm, const int8_t *rs1, size_t vl);
vint8m8_t __riscv_vle8_v_i8m8_m(vbool1_t vm, const int8_t *rs1, size_t vl);
vint16mf4_t __riscv_vle16_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                     size_t vl);
vint16mf2_t __riscv_vle16_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                     size_t vl);
vint16m1_t __riscv_vle16_v_i16m1_m(vbool16_t vm, const int16_t *rs1, size_t vl);
vint16m2_t __riscv_vle16_v_i16m2_m(vbool8_t vm, const int16_t *rs1, size_t vl);
vint16m4_t __riscv_vle16_v_i16m4_m(vbool4_t vm, const int16_t *rs1, size_t vl);
vint16m8_t __riscv_vle16_v_i16m8_m(vbool2_t vm, const int16_t *rs1, size_t vl);
vint32mf2_t __riscv_vle32_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                     size_t vl);
vint32m1_t __riscv_vle32_v_i32m1_m(vbool32_t vm, const int32_t *rs1, size_t vl);
vint32m2_t __riscv_vle32_v_i32m2_m(vbool16_t vm, const int32_t *rs1, size_t vl);
vint32m4_t __riscv_vle32_v_i32m4_m(vbool8_t vm, const int32_t *rs1, size_t vl);
vint32m8_t __riscv_vle32_v_i32m8_m(vbool4_t vm, const int32_t *rs1, size_t vl);
vint64m1_t __riscv_vle64_v_i64m1_m(vbool64_t vm, const int64_t *rs1, size_t vl);
vint64m2_t __riscv_vle64_v_i64m2_m(vbool32_t vm, const int64_t *rs1, size_t vl);
vint64m4_t __riscv_vle64_v_i64m4_m(vbool16_t vm, const int64_t *rs1, size_t vl);
vint64m8_t __riscv_vle64_v_i64m8_m(vbool8_t vm, const int64_t *rs1, size_t vl);
vuint8mf8_t __riscv_vle8_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1, size_t vl);
vuint8mf4_t __riscv_vle8_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1, size_t vl);
vuint8mf2_t __riscv_vle8_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1, size_t vl);
vuint8m1_t __riscv_vle8_v_u8m1_m(vbool8_t vm, const uint8_t *rs1, size_t vl);
vuint8m2_t __riscv_vle8_v_u8m2_m(vbool4_t vm, const uint8_t *rs1, size_t vl);
vuint8m4_t __riscv_vle8_v_u8m4_m(vbool2_t vm, const uint8_t *rs1, size_t vl);
vuint8m8_t __riscv_vle8_v_u8m8_m(vbool1_t vm, const uint8_t *rs1, size_t vl);
vuint16mf4_t __riscv_vle16_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                      size_t vl);
vuint16mf2_t __riscv_vle16_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                      size_t vl);
vuint16m1_t __riscv_vle16_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                    size_t vl);
vuint16m2_t __riscv_vle16_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                    size_t vl);
vuint16m4_t __riscv_vle16_v_u16m4_m(vbool4_t vm, const uint16_t *rs1,
                                    size_t vl);
vuint16m8_t __riscv_vle16_v_u16m8_m(vbool2_t vm, const uint16_t *rs1,
                                    size_t vl);
vuint32mf2_t __riscv_vle32_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                      size_t vl);
vuint32m1_t __riscv_vle32_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                    size_t vl);
vuint32m2_t __riscv_vle32_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                    size_t vl);
vuint32m4_t __riscv_vle32_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                    size_t vl);
vuint32m8_t __riscv_vle32_v_u32m8_m(vbool4_t vm, const uint32_t *rs1,
                                    size_t vl);
vuint64m1_t __riscv_vle64_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                    size_t vl);
vuint64m2_t __riscv_vle64_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                    size_t vl);
vuint64m4_t __riscv_vle64_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                    size_t vl);
vuint64m8_t __riscv_vle64_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                    size_t vl);
----

[[vector-unit-stride-store]]
==== Vector Unit-Stride Store Intrinsics

[,c]
----
void __riscv_vse16_v_f16mf4(_Float16 *rs1, vfloat16mf4_t vs3, size_t vl);
void __riscv_vse16_v_f16mf2(_Float16 *rs1, vfloat16mf2_t vs3, size_t vl);
void __riscv_vse16_v_f16m1(_Float16 *rs1, vfloat16m1_t vs3, size_t vl);
void __riscv_vse16_v_f16m2(_Float16 *rs1, vfloat16m2_t vs3, size_t vl);
void __riscv_vse16_v_f16m4(_Float16 *rs1, vfloat16m4_t vs3, size_t vl);
void __riscv_vse16_v_f16m8(_Float16 *rs1, vfloat16m8_t vs3, size_t vl);
void __riscv_vse32_v_f32mf2(float *rs1, vfloat32mf2_t vs3, size_t vl);
void __riscv_vse32_v_f32m1(float *rs1, vfloat32m1_t vs3, size_t vl);
void __riscv_vse32_v_f32m2(float *rs1, vfloat32m2_t vs3, size_t vl);
void __riscv_vse32_v_f32m4(float *rs1, vfloat32m4_t vs3, size_t vl);
void __riscv_vse32_v_f32m8(float *rs1, vfloat32m8_t vs3, size_t vl);
void __riscv_vse64_v_f64m1(double *rs1, vfloat64m1_t vs3, size_t vl);
void __riscv_vse64_v_f64m2(double *rs1, vfloat64m2_t vs3, size_t vl);
void __riscv_vse64_v_f64m4(double *rs1, vfloat64m4_t vs3, size_t vl);
void __riscv_vse64_v_f64m8(double *rs1, vfloat64m8_t vs3, size_t vl);
void __riscv_vse8_v_i8mf8(int8_t *rs1, vint8mf8_t vs3, size_t vl);
void __riscv_vse8_v_i8mf4(int8_t *rs1, vint8mf4_t vs3, size_t vl);
void __riscv_vse8_v_i8mf2(int8_t *rs1, vint8mf2_t vs3, size_t vl);
void __riscv_vse8_v_i8m1(int8_t *rs1, vint8m1_t vs3, size_t vl);
void __riscv_vse8_v_i8m2(int8_t *rs1, vint8m2_t vs3, size_t vl);
void __riscv_vse8_v_i8m4(int8_t *rs1, vint8m4_t vs3, size_t vl);
void __riscv_vse8_v_i8m8(int8_t *rs1, vint8m8_t vs3, size_t vl);
void __riscv_vse16_v_i16mf4(int16_t *rs1, vint16mf4_t vs3, size_t vl);
void __riscv_vse16_v_i16mf2(int16_t *rs1, vint16mf2_t vs3, size_t vl);
void __riscv_vse16_v_i16m1(int16_t *rs1, vint16m1_t vs3, size_t vl);
void __riscv_vse16_v_i16m2(int16_t *rs1, vint16m2_t vs3, size_t vl);
void __riscv_vse16_v_i16m4(int16_t *rs1, vint16m4_t vs3, size_t vl);
void __riscv_vse16_v_i16m8(int16_t *rs1, vint16m8_t vs3, size_t vl);
void __riscv_vse32_v_i32mf2(int32_t *rs1, vint32mf2_t vs3, size_t vl);
void __riscv_vse32_v_i32m1(int32_t *rs1, vint32m1_t vs3, size_t vl);
void __riscv_vse32_v_i32m2(int32_t *rs1, vint32m2_t vs3, size_t vl);
void __riscv_vse32_v_i32m4(int32_t *rs1, vint32m4_t vs3, size_t vl);
void __riscv_vse32_v_i32m8(int32_t *rs1, vint32m8_t vs3, size_t vl);
void __riscv_vse64_v_i64m1(int64_t *rs1, vint64m1_t vs3, size_t vl);
void __riscv_vse64_v_i64m2(int64_t *rs1, vint64m2_t vs3, size_t vl);
void __riscv_vse64_v_i64m4(int64_t *rs1, vint64m4_t vs3, size_t vl);
void __riscv_vse64_v_i64m8(int64_t *rs1, vint64m8_t vs3, size_t vl);
void __riscv_vse8_v_u8mf8(uint8_t *rs1, vuint8mf8_t vs3, size_t vl);
void __riscv_vse8_v_u8mf4(uint8_t *rs1, vuint8mf4_t vs3, size_t vl);
void __riscv_vse8_v_u8mf2(uint8_t *rs1, vuint8mf2_t vs3, size_t vl);
void __riscv_vse8_v_u8m1(uint8_t *rs1, vuint8m1_t vs3, size_t vl);
void __riscv_vse8_v_u8m2(uint8_t *rs1, vuint8m2_t vs3, size_t vl);
void __riscv_vse8_v_u8m4(uint8_t *rs1, vuint8m4_t vs3, size_t vl);
void __riscv_vse8_v_u8m8(uint8_t *rs1, vuint8m8_t vs3, size_t vl);
void __riscv_vse16_v_u16mf4(uint16_t *rs1, vuint16mf4_t vs3, size_t vl);
void __riscv_vse16_v_u16mf2(uint16_t *rs1, vuint16mf2_t vs3, size_t vl);
void __riscv_vse16_v_u16m1(uint16_t *rs1, vuint16m1_t vs3, size_t vl);
void __riscv_vse16_v_u16m2(uint16_t *rs1, vuint16m2_t vs3, size_t vl);
void __riscv_vse16_v_u16m4(uint16_t *rs1, vuint16m4_t vs3, size_t vl);
void __riscv_vse16_v_u16m8(uint16_t *rs1, vuint16m8_t vs3, size_t vl);
void __riscv_vse32_v_u32mf2(uint32_t *rs1, vuint32mf2_t vs3, size_t vl);
void __riscv_vse32_v_u32m1(uint32_t *rs1, vuint32m1_t vs3, size_t vl);
void __riscv_vse32_v_u32m2(uint32_t *rs1, vuint32m2_t vs3, size_t vl);
void __riscv_vse32_v_u32m4(uint32_t *rs1, vuint32m4_t vs3, size_t vl);
void __riscv_vse32_v_u32m8(uint32_t *rs1, vuint32m8_t vs3, size_t vl);
void __riscv_vse64_v_u64m1(uint64_t *rs1, vuint64m1_t vs3, size_t vl);
void __riscv_vse64_v_u64m2(uint64_t *rs1, vuint64m2_t vs3, size_t vl);
void __riscv_vse64_v_u64m4(uint64_t *rs1, vuint64m4_t vs3, size_t vl);
void __riscv_vse64_v_u64m8(uint64_t *rs1, vuint64m8_t vs3, size_t vl);
// masked functions
void __riscv_vse16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vfloat16mf4_t vs3,
                              size_t vl);
void __riscv_vse16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vfloat16mf2_t vs3,
                              size_t vl);
void __riscv_vse16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vfloat16m1_t vs3,
                             size_t vl);
void __riscv_vse16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vfloat16m2_t vs3,
                             size_t vl);
void __riscv_vse16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vfloat16m4_t vs3,
                             size_t vl);
void __riscv_vse16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vfloat16m8_t vs3,
                             size_t vl);
void __riscv_vse32_v_f32mf2_m(vbool64_t vm, float *rs1, vfloat32mf2_t vs3,
                              size_t vl);
void __riscv_vse32_v_f32m1_m(vbool32_t vm, float *rs1, vfloat32m1_t vs3,
                             size_t vl);
void __riscv_vse32_v_f32m2_m(vbool16_t vm, float *rs1, vfloat32m2_t vs3,
                             size_t vl);
void __riscv_vse32_v_f32m4_m(vbool8_t vm, float *rs1, vfloat32m4_t vs3,
                             size_t vl);
void __riscv_vse32_v_f32m8_m(vbool4_t vm, float *rs1, vfloat32m8_t vs3,
                             size_t vl);
void __riscv_vse64_v_f64m1_m(vbool64_t vm, double *rs1, vfloat64m1_t vs3,
                             size_t vl);
void __riscv_vse64_v_f64m2_m(vbool32_t vm, double *rs1, vfloat64m2_t vs3,
                             size_t vl);
void __riscv_vse64_v_f64m4_m(vbool16_t vm, double *rs1, vfloat64m4_t vs3,
                             size_t vl);
void __riscv_vse64_v_f64m8_m(vbool8_t vm, double *rs1, vfloat64m8_t vs3,
                             size_t vl);
void __riscv_vse8_v_i8mf8_m(vbool64_t vm, int8_t *rs1, vint8mf8_t vs3,
                            size_t vl);
void __riscv_vse8_v_i8mf4_m(vbool32_t vm, int8_t *rs1, vint8mf4_t vs3,
                            size_t vl);
void __riscv_vse8_v_i8mf2_m(vbool16_t vm, int8_t *rs1, vint8mf2_t vs3,
                            size_t vl);
void __riscv_vse8_v_i8m1_m(vbool8_t vm, int8_t *rs1, vint8m1_t vs3, size_t vl);
void __riscv_vse8_v_i8m2_m(vbool4_t vm, int8_t *rs1, vint8m2_t vs3, size_t vl);
void __riscv_vse8_v_i8m4_m(vbool2_t vm, int8_t *rs1, vint8m4_t vs3, size_t vl);
void __riscv_vse8_v_i8m8_m(vbool1_t vm, int8_t *rs1, vint8m8_t vs3, size_t vl);
void __riscv_vse16_v_i16mf4_m(vbool64_t vm, int16_t *rs1, vint16mf4_t vs3,
                              size_t vl);
void __riscv_vse16_v_i16mf2_m(vbool32_t vm, int16_t *rs1, vint16mf2_t vs3,
                              size_t vl);
void __riscv_vse16_v_i16m1_m(vbool16_t vm, int16_t *rs1, vint16m1_t vs3,
                             size_t vl);
void __riscv_vse16_v_i16m2_m(vbool8_t vm, int16_t *rs1, vint16m2_t vs3,
                             size_t vl);
void __riscv_vse16_v_i16m4_m(vbool4_t vm, int16_t *rs1, vint16m4_t vs3,
                             size_t vl);
void __riscv_vse16_v_i16m8_m(vbool2_t vm, int16_t *rs1, vint16m8_t vs3,
                             size_t vl);
void __riscv_vse32_v_i32mf2_m(vbool64_t vm, int32_t *rs1, vint32mf2_t vs3,
                              size_t vl);
void __riscv_vse32_v_i32m1_m(vbool32_t vm, int32_t *rs1, vint32m1_t vs3,
                             size_t vl);
void __riscv_vse32_v_i32m2_m(vbool16_t vm, int32_t *rs1, vint32m2_t vs3,
                             size_t vl);
void __riscv_vse32_v_i32m4_m(vbool8_t vm, int32_t *rs1, vint32m4_t vs3,
                             size_t vl);
void __riscv_vse32_v_i32m8_m(vbool4_t vm, int32_t *rs1, vint32m8_t vs3,
                             size_t vl);
void __riscv_vse64_v_i64m1_m(vbool64_t vm, int64_t *rs1, vint64m1_t vs3,
                             size_t vl);
void __riscv_vse64_v_i64m2_m(vbool32_t vm, int64_t *rs1, vint64m2_t vs3,
                             size_t vl);
void __riscv_vse64_v_i64m4_m(vbool16_t vm, int64_t *rs1, vint64m4_t vs3,
                             size_t vl);
void __riscv_vse64_v_i64m8_m(vbool8_t vm, int64_t *rs1, vint64m8_t vs3,
                             size_t vl);
void __riscv_vse8_v_u8mf8_m(vbool64_t vm, uint8_t *rs1, vuint8mf8_t vs3,
                            size_t vl);
void __riscv_vse8_v_u8mf4_m(vbool32_t vm, uint8_t *rs1, vuint8mf4_t vs3,
                            size_t vl);
void __riscv_vse8_v_u8mf2_m(vbool16_t vm, uint8_t *rs1, vuint8mf2_t vs3,
                            size_t vl);
void __riscv_vse8_v_u8m1_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs3,
                           size_t vl);
void __riscv_vse8_v_u8m2_m(vbool4_t vm, uint8_t *rs1, vuint8m2_t vs3,
                           size_t vl);
void __riscv_vse8_v_u8m4_m(vbool2_t vm, uint8_t *rs1, vuint8m4_t vs3,
                           size_t vl);
void __riscv_vse8_v_u8m8_m(vbool1_t vm, uint8_t *rs1, vuint8m8_t vs3,
                           size_t vl);
void __riscv_vse16_v_u16mf4_m(vbool64_t vm, uint16_t *rs1, vuint16mf4_t vs3,
                              size_t vl);
void __riscv_vse16_v_u16mf2_m(vbool32_t vm, uint16_t *rs1, vuint16mf2_t vs3,
                              size_t vl);
void __riscv_vse16_v_u16m1_m(vbool16_t vm, uint16_t *rs1, vuint16m1_t vs3,
                             size_t vl);
void __riscv_vse16_v_u16m2_m(vbool8_t vm, uint16_t *rs1, vuint16m2_t vs3,
                             size_t vl);
void __riscv_vse16_v_u16m4_m(vbool4_t vm, uint16_t *rs1, vuint16m4_t vs3,
                             size_t vl);
void __riscv_vse16_v_u16m8_m(vbool2_t vm, uint16_t *rs1, vuint16m8_t vs3,
                             size_t vl);
void __riscv_vse32_v_u32mf2_m(vbool64_t vm, uint32_t *rs1, vuint32mf2_t vs3,
                              size_t vl);
void __riscv_vse32_v_u32m1_m(vbool32_t vm, uint32_t *rs1, vuint32m1_t vs3,
                             size_t vl);
void __riscv_vse32_v_u32m2_m(vbool16_t vm, uint32_t *rs1, vuint32m2_t vs3,
                             size_t vl);
void __riscv_vse32_v_u32m4_m(vbool8_t vm, uint32_t *rs1, vuint32m4_t vs3,
                             size_t vl);
void __riscv_vse32_v_u32m8_m(vbool4_t vm, uint32_t *rs1, vuint32m8_t vs3,
                             size_t vl);
void __riscv_vse64_v_u64m1_m(vbool64_t vm, uint64_t *rs1, vuint64m1_t vs3,
                             size_t vl);
void __riscv_vse64_v_u64m2_m(vbool32_t vm, uint64_t *rs1, vuint64m2_t vs3,
                             size_t vl);
void __riscv_vse64_v_u64m4_m(vbool16_t vm, uint64_t *rs1, vuint64m4_t vs3,
                             size_t vl);
void __riscv_vse64_v_u64m8_m(vbool8_t vm, uint64_t *rs1, vuint64m8_t vs3,
                             size_t vl);
----

[[vector-unit-stride]]
==== Vector Mask Load/Store Intrinsics

[,c]
----
vbool1_t __riscv_vlm_v_b1(const uint8_t *rs1, size_t vl);
vbool2_t __riscv_vlm_v_b2(const uint8_t *rs1, size_t vl);
vbool4_t __riscv_vlm_v_b4(const uint8_t *rs1, size_t vl);
vbool8_t __riscv_vlm_v_b8(const uint8_t *rs1, size_t vl);
vbool16_t __riscv_vlm_v_b16(const uint8_t *rs1, size_t vl);
vbool32_t __riscv_vlm_v_b32(const uint8_t *rs1, size_t vl);
vbool64_t __riscv_vlm_v_b64(const uint8_t *rs1, size_t vl);
void __riscv_vsm_v_b1(uint8_t *rs1, vbool1_t vs3, size_t vl);
void __riscv_vsm_v_b2(uint8_t *rs1, vbool2_t vs3, size_t vl);
void __riscv_vsm_v_b4(uint8_t *rs1, vbool4_t vs3, size_t vl);
void __riscv_vsm_v_b8(uint8_t *rs1, vbool8_t vs3, size_t vl);
void __riscv_vsm_v_b16(uint8_t *rs1, vbool16_t vs3, size_t vl);
void __riscv_vsm_v_b32(uint8_t *rs1, vbool32_t vs3, size_t vl);
void __riscv_vsm_v_b64(uint8_t *rs1, vbool64_t vs3, size_t vl);
----

[[vector-strided-load]]
==== Vector Strided Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vlse16_v_f16mf4(const _Float16 *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat16mf2_t __riscv_vlse16_v_f16mf2(const _Float16 *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat16m1_t __riscv_vlse16_v_f16m1(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat16m2_t __riscv_vlse16_v_f16m2(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat16m4_t __riscv_vlse16_v_f16m4(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat16m8_t __riscv_vlse16_v_f16m8(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat32mf2_t __riscv_vlse32_v_f32mf2(const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m1_t __riscv_vlse32_v_f32m1(const float *rs1, ptrdiff_t rs2, size_t vl);
vfloat32m2_t __riscv_vlse32_v_f32m2(const float *rs1, ptrdiff_t rs2, size_t vl);
vfloat32m4_t __riscv_vlse32_v_f32m4(const float *rs1, ptrdiff_t rs2, size_t vl);
vfloat32m8_t __riscv_vlse32_v_f32m8(const float *rs1, ptrdiff_t rs2, size_t vl);
vfloat64m1_t __riscv_vlse64_v_f64m1(const double *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat64m2_t __riscv_vlse64_v_f64m2(const double *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat64m4_t __riscv_vlse64_v_f64m4(const double *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat64m8_t __riscv_vlse64_v_f64m8(const double *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf8_t __riscv_vlse8_v_i8mf8(const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4_t __riscv_vlse8_v_i8mf4(const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2_t __riscv_vlse8_v_i8mf2(const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1_t __riscv_vlse8_v_i8m1(const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m2_t __riscv_vlse8_v_i8m2(const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m4_t __riscv_vlse8_v_i8m4(const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m8_t __riscv_vlse8_v_i8m8(const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint16mf4_t __riscv_vlse16_v_i16mf4(const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf2_t __riscv_vlse16_v_i16mf2(const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m1_t __riscv_vlse16_v_i16m1(const int16_t *rs1, ptrdiff_t rs2, size_t vl);
vint16m2_t __riscv_vlse16_v_i16m2(const int16_t *rs1, ptrdiff_t rs2, size_t vl);
vint16m4_t __riscv_vlse16_v_i16m4(const int16_t *rs1, ptrdiff_t rs2, size_t vl);
vint16m8_t __riscv_vlse16_v_i16m8(const int16_t *rs1, ptrdiff_t rs2, size_t vl);
vint32mf2_t __riscv_vlse32_v_i32mf2(const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m1_t __riscv_vlse32_v_i32m1(const int32_t *rs1, ptrdiff_t rs2, size_t vl);
vint32m2_t __riscv_vlse32_v_i32m2(const int32_t *rs1, ptrdiff_t rs2, size_t vl);
vint32m4_t __riscv_vlse32_v_i32m4(const int32_t *rs1, ptrdiff_t rs2, size_t vl);
vint32m8_t __riscv_vlse32_v_i32m8(const int32_t *rs1, ptrdiff_t rs2, size_t vl);
vint64m1_t __riscv_vlse64_v_i64m1(const int64_t *rs1, ptrdiff_t rs2, size_t vl);
vint64m2_t __riscv_vlse64_v_i64m2(const int64_t *rs1, ptrdiff_t rs2, size_t vl);
vint64m4_t __riscv_vlse64_v_i64m4(const int64_t *rs1, ptrdiff_t rs2, size_t vl);
vint64m8_t __riscv_vlse64_v_i64m8(const int64_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8mf8_t __riscv_vlse8_v_u8mf8(const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8mf4_t __riscv_vlse8_v_u8mf4(const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8mf2_t __riscv_vlse8_v_u8mf2(const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m1_t __riscv_vlse8_v_u8m1(const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m2_t __riscv_vlse8_v_u8m2(const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m4_t __riscv_vlse8_v_u8m4(const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m8_t __riscv_vlse8_v_u8m8(const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint16mf4_t __riscv_vlse16_v_u16mf4(const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf2_t __riscv_vlse16_v_u16mf2(const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m1_t __riscv_vlse16_v_u16m1(const uint16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint16m2_t __riscv_vlse16_v_u16m2(const uint16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint16m4_t __riscv_vlse16_v_u16m4(const uint16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint16m8_t __riscv_vlse16_v_u16m8(const uint16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint32mf2_t __riscv_vlse32_v_u32mf2(const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m1_t __riscv_vlse32_v_u32m1(const uint32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint32m2_t __riscv_vlse32_v_u32m2(const uint32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint32m4_t __riscv_vlse32_v_u32m4(const uint32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint32m8_t __riscv_vlse32_v_u32m8(const uint32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint64m1_t __riscv_vlse64_v_u64m1(const uint64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint64m2_t __riscv_vlse64_v_u64m2(const uint64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint64m4_t __riscv_vlse64_v_u64m4(const uint64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint64m8_t __riscv_vlse64_v_u64m8(const uint64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
// masked functions
vfloat16mf4_t __riscv_vlse16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                        ptrdiff_t rs2, size_t vl);
vfloat16mf2_t __riscv_vlse16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                        ptrdiff_t rs2, size_t vl);
vfloat16m1_t __riscv_vlse16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat16m2_t __riscv_vlse16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat16m4_t __riscv_vlse16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat16m8_t __riscv_vlse16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32mf2_t __riscv_vlse32_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                        ptrdiff_t rs2, size_t vl);
vfloat32m1_t __riscv_vlse32_v_f32m1_m(vbool32_t vm, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32m2_t __riscv_vlse32_v_f32m2_m(vbool16_t vm, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32m4_t __riscv_vlse32_v_f32m4_m(vbool8_t vm, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32m8_t __riscv_vlse32_v_f32m8_m(vbool4_t vm, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat64m1_t __riscv_vlse64_v_f64m1_m(vbool64_t vm, const double *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat64m2_t __riscv_vlse64_v_f64m2_m(vbool32_t vm, const double *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat64m4_t __riscv_vlse64_v_f64m4_m(vbool16_t vm, const double *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat64m8_t __riscv_vlse64_v_f64m8_m(vbool8_t vm, const double *rs1,
                                      ptrdiff_t rs2, size_t vl);
vint8mf8_t __riscv_vlse8_v_i8mf8_m(vbool64_t vm, const int8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint8mf4_t __riscv_vlse8_v_i8mf4_m(vbool32_t vm, const int8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint8mf2_t __riscv_vlse8_v_i8mf2_m(vbool16_t vm, const int8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint8m1_t __riscv_vlse8_v_i8m1_m(vbool8_t vm, const int8_t *rs1, ptrdiff_t rs2,
                                 size_t vl);
vint8m2_t __riscv_vlse8_v_i8m2_m(vbool4_t vm, const int8_t *rs1, ptrdiff_t rs2,
                                 size_t vl);
vint8m4_t __riscv_vlse8_v_i8m4_m(vbool2_t vm, const int8_t *rs1, ptrdiff_t rs2,
                                 size_t vl);
vint8m8_t __riscv_vlse8_v_i8m8_m(vbool1_t vm, const int8_t *rs1, ptrdiff_t rs2,
                                 size_t vl);
vint16mf4_t __riscv_vlse16_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                      ptrdiff_t rs2, size_t vl);
vint16mf2_t __riscv_vlse16_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                      ptrdiff_t rs2, size_t vl);
vint16m1_t __riscv_vlse16_v_i16m1_m(vbool16_t vm, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16m2_t __riscv_vlse16_v_i16m2_m(vbool8_t vm, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16m4_t __riscv_vlse16_v_i16m4_m(vbool4_t vm, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16m8_t __riscv_vlse16_v_i16m8_m(vbool2_t vm, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32mf2_t __riscv_vlse32_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                      ptrdiff_t rs2, size_t vl);
vint32m1_t __riscv_vlse32_v_i32m1_m(vbool32_t vm, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32m2_t __riscv_vlse32_v_i32m2_m(vbool16_t vm, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32m4_t __riscv_vlse32_v_i32m4_m(vbool8_t vm, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32m8_t __riscv_vlse32_v_i32m8_m(vbool4_t vm, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint64m1_t __riscv_vlse64_v_i64m1_m(vbool64_t vm, const int64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint64m2_t __riscv_vlse64_v_i64m2_m(vbool32_t vm, const int64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint64m4_t __riscv_vlse64_v_i64m4_m(vbool16_t vm, const int64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint64m8_t __riscv_vlse64_v_i64m8_m(vbool8_t vm, const int64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint8mf8_t __riscv_vlse8_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint8mf4_t __riscv_vlse8_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint8mf2_t __riscv_vlse8_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint8m1_t __riscv_vlse8_v_u8m1_m(vbool8_t vm, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m2_t __riscv_vlse8_v_u8m2_m(vbool4_t vm, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m4_t __riscv_vlse8_v_u8m4_m(vbool2_t vm, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m8_t __riscv_vlse8_v_u8m8_m(vbool1_t vm, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint16mf4_t __riscv_vlse16_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                       ptrdiff_t rs2, size_t vl);
vuint16mf2_t __riscv_vlse16_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                       ptrdiff_t rs2, size_t vl);
vuint16m1_t __riscv_vlse16_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16m2_t __riscv_vlse16_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16m4_t __riscv_vlse16_v_u16m4_m(vbool4_t vm, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16m8_t __riscv_vlse16_v_u16m8_m(vbool2_t vm, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32mf2_t __riscv_vlse32_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                       ptrdiff_t rs2, size_t vl);
vuint32m1_t __riscv_vlse32_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32m2_t __riscv_vlse32_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32m4_t __riscv_vlse32_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32m8_t __riscv_vlse32_v_u32m8_m(vbool4_t vm, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint64m1_t __riscv_vlse64_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint64m2_t __riscv_vlse64_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint64m4_t __riscv_vlse64_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint64m8_t __riscv_vlse64_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
----

[[vector-strided-store]]
==== Vector Strided Store Intrinsics

[,c]
----
void __riscv_vsse16_v_f16mf4(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4_t vs3,
                             size_t vl);
void __riscv_vsse16_v_f16mf2(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2_t vs3,
                             size_t vl);
void __riscv_vsse16_v_f16m1(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1_t vs3,
                            size_t vl);
void __riscv_vsse16_v_f16m2(_Float16 *rs1, ptrdiff_t rs2, vfloat16m2_t vs3,
                            size_t vl);
void __riscv_vsse16_v_f16m4(_Float16 *rs1, ptrdiff_t rs2, vfloat16m4_t vs3,
                            size_t vl);
void __riscv_vsse16_v_f16m8(_Float16 *rs1, ptrdiff_t rs2, vfloat16m8_t vs3,
                            size_t vl);
void __riscv_vsse32_v_f32mf2(float *rs1, ptrdiff_t rs2, vfloat32mf2_t vs3,
                             size_t vl);
void __riscv_vsse32_v_f32m1(float *rs1, ptrdiff_t rs2, vfloat32m1_t vs3,
                            size_t vl);
void __riscv_vsse32_v_f32m2(float *rs1, ptrdiff_t rs2, vfloat32m2_t vs3,
                            size_t vl);
void __riscv_vsse32_v_f32m4(float *rs1, ptrdiff_t rs2, vfloat32m4_t vs3,
                            size_t vl);
void __riscv_vsse32_v_f32m8(float *rs1, ptrdiff_t rs2, vfloat32m8_t vs3,
                            size_t vl);
void __riscv_vsse64_v_f64m1(double *rs1, ptrdiff_t rs2, vfloat64m1_t vs3,
                            size_t vl);
void __riscv_vsse64_v_f64m2(double *rs1, ptrdiff_t rs2, vfloat64m2_t vs3,
                            size_t vl);
void __riscv_vsse64_v_f64m4(double *rs1, ptrdiff_t rs2, vfloat64m4_t vs3,
                            size_t vl);
void __riscv_vsse64_v_f64m8(double *rs1, ptrdiff_t rs2, vfloat64m8_t vs3,
                            size_t vl);
void __riscv_vsse8_v_i8mf8(int8_t *rs1, ptrdiff_t rs2, vint8mf8_t vs3,
                           size_t vl);
void __riscv_vsse8_v_i8mf4(int8_t *rs1, ptrdiff_t rs2, vint8mf4_t vs3,
                           size_t vl);
void __riscv_vsse8_v_i8mf2(int8_t *rs1, ptrdiff_t rs2, vint8mf2_t vs3,
                           size_t vl);
void __riscv_vsse8_v_i8m1(int8_t *rs1, ptrdiff_t rs2, vint8m1_t vs3, size_t vl);
void __riscv_vsse8_v_i8m2(int8_t *rs1, ptrdiff_t rs2, vint8m2_t vs3, size_t vl);
void __riscv_vsse8_v_i8m4(int8_t *rs1, ptrdiff_t rs2, vint8m4_t vs3, size_t vl);
void __riscv_vsse8_v_i8m8(int8_t *rs1, ptrdiff_t rs2, vint8m8_t vs3, size_t vl);
void __riscv_vsse16_v_i16mf4(int16_t *rs1, ptrdiff_t rs2, vint16mf4_t vs3,
                             size_t vl);
void __riscv_vsse16_v_i16mf2(int16_t *rs1, ptrdiff_t rs2, vint16mf2_t vs3,
                             size_t vl);
void __riscv_vsse16_v_i16m1(int16_t *rs1, ptrdiff_t rs2, vint16m1_t vs3,
                            size_t vl);
void __riscv_vsse16_v_i16m2(int16_t *rs1, ptrdiff_t rs2, vint16m2_t vs3,
                            size_t vl);
void __riscv_vsse16_v_i16m4(int16_t *rs1, ptrdiff_t rs2, vint16m4_t vs3,
                            size_t vl);
void __riscv_vsse16_v_i16m8(int16_t *rs1, ptrdiff_t rs2, vint16m8_t vs3,
                            size_t vl);
void __riscv_vsse32_v_i32mf2(int32_t *rs1, ptrdiff_t rs2, vint32mf2_t vs3,
                             size_t vl);
void __riscv_vsse32_v_i32m1(int32_t *rs1, ptrdiff_t rs2, vint32m1_t vs3,
                            size_t vl);
void __riscv_vsse32_v_i32m2(int32_t *rs1, ptrdiff_t rs2, vint32m2_t vs3,
                            size_t vl);
void __riscv_vsse32_v_i32m4(int32_t *rs1, ptrdiff_t rs2, vint32m4_t vs3,
                            size_t vl);
void __riscv_vsse32_v_i32m8(int32_t *rs1, ptrdiff_t rs2, vint32m8_t vs3,
                            size_t vl);
void __riscv_vsse64_v_i64m1(int64_t *rs1, ptrdiff_t rs2, vint64m1_t vs3,
                            size_t vl);
void __riscv_vsse64_v_i64m2(int64_t *rs1, ptrdiff_t rs2, vint64m2_t vs3,
                            size_t vl);
void __riscv_vsse64_v_i64m4(int64_t *rs1, ptrdiff_t rs2, vint64m4_t vs3,
                            size_t vl);
void __riscv_vsse64_v_i64m8(int64_t *rs1, ptrdiff_t rs2, vint64m8_t vs3,
                            size_t vl);
void __riscv_vsse8_v_u8mf8(uint8_t *rs1, ptrdiff_t rs2, vuint8mf8_t vs3,
                           size_t vl);
void __riscv_vsse8_v_u8mf4(uint8_t *rs1, ptrdiff_t rs2, vuint8mf4_t vs3,
                           size_t vl);
void __riscv_vsse8_v_u8mf2(uint8_t *rs1, ptrdiff_t rs2, vuint8mf2_t vs3,
                           size_t vl);
void __riscv_vsse8_v_u8m1(uint8_t *rs1, ptrdiff_t rs2, vuint8m1_t vs3,
                          size_t vl);
void __riscv_vsse8_v_u8m2(uint8_t *rs1, ptrdiff_t rs2, vuint8m2_t vs3,
                          size_t vl);
void __riscv_vsse8_v_u8m4(uint8_t *rs1, ptrdiff_t rs2, vuint8m4_t vs3,
                          size_t vl);
void __riscv_vsse8_v_u8m8(uint8_t *rs1, ptrdiff_t rs2, vuint8m8_t vs3,
                          size_t vl);
void __riscv_vsse16_v_u16mf4(uint16_t *rs1, ptrdiff_t rs2, vuint16mf4_t vs3,
                             size_t vl);
void __riscv_vsse16_v_u16mf2(uint16_t *rs1, ptrdiff_t rs2, vuint16mf2_t vs3,
                             size_t vl);
void __riscv_vsse16_v_u16m1(uint16_t *rs1, ptrdiff_t rs2, vuint16m1_t vs3,
                            size_t vl);
void __riscv_vsse16_v_u16m2(uint16_t *rs1, ptrdiff_t rs2, vuint16m2_t vs3,
                            size_t vl);
void __riscv_vsse16_v_u16m4(uint16_t *rs1, ptrdiff_t rs2, vuint16m4_t vs3,
                            size_t vl);
void __riscv_vsse16_v_u16m8(uint16_t *rs1, ptrdiff_t rs2, vuint16m8_t vs3,
                            size_t vl);
void __riscv_vsse32_v_u32mf2(uint32_t *rs1, ptrdiff_t rs2, vuint32mf2_t vs3,
                             size_t vl);
void __riscv_vsse32_v_u32m1(uint32_t *rs1, ptrdiff_t rs2, vuint32m1_t vs3,
                            size_t vl);
void __riscv_vsse32_v_u32m2(uint32_t *rs1, ptrdiff_t rs2, vuint32m2_t vs3,
                            size_t vl);
void __riscv_vsse32_v_u32m4(uint32_t *rs1, ptrdiff_t rs2, vuint32m4_t vs3,
                            size_t vl);
void __riscv_vsse32_v_u32m8(uint32_t *rs1, ptrdiff_t rs2, vuint32m8_t vs3,
                            size_t vl);
void __riscv_vsse64_v_u64m1(uint64_t *rs1, ptrdiff_t rs2, vuint64m1_t vs3,
                            size_t vl);
void __riscv_vsse64_v_u64m2(uint64_t *rs1, ptrdiff_t rs2, vuint64m2_t vs3,
                            size_t vl);
void __riscv_vsse64_v_u64m4(uint64_t *rs1, ptrdiff_t rs2, vuint64m4_t vs3,
                            size_t vl);
void __riscv_vsse64_v_u64m8(uint64_t *rs1, ptrdiff_t rs2, vuint64m8_t vs3,
                            size_t vl);
// masked functions
void __riscv_vsse16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsse16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsse16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m1_t vs3, size_t vl);
void __riscv_vsse16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m2_t vs3, size_t vl);
void __riscv_vsse16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m4_t vs3, size_t vl);
void __riscv_vsse16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m8_t vs3, size_t vl);
void __riscv_vsse32_v_f32mf2_m(vbool64_t vm, float *rs1, ptrdiff_t rs2,
                               vfloat32mf2_t vs3, size_t vl);
void __riscv_vsse32_v_f32m1_m(vbool32_t vm, float *rs1, ptrdiff_t rs2,
                              vfloat32m1_t vs3, size_t vl);
void __riscv_vsse32_v_f32m2_m(vbool16_t vm, float *rs1, ptrdiff_t rs2,
                              vfloat32m2_t vs3, size_t vl);
void __riscv_vsse32_v_f32m4_m(vbool8_t vm, float *rs1, ptrdiff_t rs2,
                              vfloat32m4_t vs3, size_t vl);
void __riscv_vsse32_v_f32m8_m(vbool4_t vm, float *rs1, ptrdiff_t rs2,
                              vfloat32m8_t vs3, size_t vl);
void __riscv_vsse64_v_f64m1_m(vbool64_t vm, double *rs1, ptrdiff_t rs2,
                              vfloat64m1_t vs3, size_t vl);
void __riscv_vsse64_v_f64m2_m(vbool32_t vm, double *rs1, ptrdiff_t rs2,
                              vfloat64m2_t vs3, size_t vl);
void __riscv_vsse64_v_f64m4_m(vbool16_t vm, double *rs1, ptrdiff_t rs2,
                              vfloat64m4_t vs3, size_t vl);
void __riscv_vsse64_v_f64m8_m(vbool8_t vm, double *rs1, ptrdiff_t rs2,
                              vfloat64m8_t vs3, size_t vl);
void __riscv_vsse8_v_i8mf8_m(vbool64_t vm, int8_t *rs1, ptrdiff_t rs2,
                             vint8mf8_t vs3, size_t vl);
void __riscv_vsse8_v_i8mf4_m(vbool32_t vm, int8_t *rs1, ptrdiff_t rs2,
                             vint8mf4_t vs3, size_t vl);
void __riscv_vsse8_v_i8mf2_m(vbool16_t vm, int8_t *rs1, ptrdiff_t rs2,
                             vint8mf2_t vs3, size_t vl);
void __riscv_vsse8_v_i8m1_m(vbool8_t vm, int8_t *rs1, ptrdiff_t rs2,
                            vint8m1_t vs3, size_t vl);
void __riscv_vsse8_v_i8m2_m(vbool4_t vm, int8_t *rs1, ptrdiff_t rs2,
                            vint8m2_t vs3, size_t vl);
void __riscv_vsse8_v_i8m4_m(vbool2_t vm, int8_t *rs1, ptrdiff_t rs2,
                            vint8m4_t vs3, size_t vl);
void __riscv_vsse8_v_i8m8_m(vbool1_t vm, int8_t *rs1, ptrdiff_t rs2,
                            vint8m8_t vs3, size_t vl);
void __riscv_vsse16_v_i16mf4_m(vbool64_t vm, int16_t *rs1, ptrdiff_t rs2,
                               vint16mf4_t vs3, size_t vl);
void __riscv_vsse16_v_i16mf2_m(vbool32_t vm, int16_t *rs1, ptrdiff_t rs2,
                               vint16mf2_t vs3, size_t vl);
void __riscv_vsse16_v_i16m1_m(vbool16_t vm, int16_t *rs1, ptrdiff_t rs2,
                              vint16m1_t vs3, size_t vl);
void __riscv_vsse16_v_i16m2_m(vbool8_t vm, int16_t *rs1, ptrdiff_t rs2,
                              vint16m2_t vs3, size_t vl);
void __riscv_vsse16_v_i16m4_m(vbool4_t vm, int16_t *rs1, ptrdiff_t rs2,
                              vint16m4_t vs3, size_t vl);
void __riscv_vsse16_v_i16m8_m(vbool2_t vm, int16_t *rs1, ptrdiff_t rs2,
                              vint16m8_t vs3, size_t vl);
void __riscv_vsse32_v_i32mf2_m(vbool64_t vm, int32_t *rs1, ptrdiff_t rs2,
                               vint32mf2_t vs3, size_t vl);
void __riscv_vsse32_v_i32m1_m(vbool32_t vm, int32_t *rs1, ptrdiff_t rs2,
                              vint32m1_t vs3, size_t vl);
void __riscv_vsse32_v_i32m2_m(vbool16_t vm, int32_t *rs1, ptrdiff_t rs2,
                              vint32m2_t vs3, size_t vl);
void __riscv_vsse32_v_i32m4_m(vbool8_t vm, int32_t *rs1, ptrdiff_t rs2,
                              vint32m4_t vs3, size_t vl);
void __riscv_vsse32_v_i32m8_m(vbool4_t vm, int32_t *rs1, ptrdiff_t rs2,
                              vint32m8_t vs3, size_t vl);
void __riscv_vsse64_v_i64m1_m(vbool64_t vm, int64_t *rs1, ptrdiff_t rs2,
                              vint64m1_t vs3, size_t vl);
void __riscv_vsse64_v_i64m2_m(vbool32_t vm, int64_t *rs1, ptrdiff_t rs2,
                              vint64m2_t vs3, size_t vl);
void __riscv_vsse64_v_i64m4_m(vbool16_t vm, int64_t *rs1, ptrdiff_t rs2,
                              vint64m4_t vs3, size_t vl);
void __riscv_vsse64_v_i64m8_m(vbool8_t vm, int64_t *rs1, ptrdiff_t rs2,
                              vint64m8_t vs3, size_t vl);
void __riscv_vsse8_v_u8mf8_m(vbool64_t vm, uint8_t *rs1, ptrdiff_t rs2,
                             vuint8mf8_t vs3, size_t vl);
void __riscv_vsse8_v_u8mf4_m(vbool32_t vm, uint8_t *rs1, ptrdiff_t rs2,
                             vuint8mf4_t vs3, size_t vl);
void __riscv_vsse8_v_u8mf2_m(vbool16_t vm, uint8_t *rs1, ptrdiff_t rs2,
                             vuint8mf2_t vs3, size_t vl);
void __riscv_vsse8_v_u8m1_m(vbool8_t vm, uint8_t *rs1, ptrdiff_t rs2,
                            vuint8m1_t vs3, size_t vl);
void __riscv_vsse8_v_u8m2_m(vbool4_t vm, uint8_t *rs1, ptrdiff_t rs2,
                            vuint8m2_t vs3, size_t vl);
void __riscv_vsse8_v_u8m4_m(vbool2_t vm, uint8_t *rs1, ptrdiff_t rs2,
                            vuint8m4_t vs3, size_t vl);
void __riscv_vsse8_v_u8m8_m(vbool1_t vm, uint8_t *rs1, ptrdiff_t rs2,
                            vuint8m8_t vs3, size_t vl);
void __riscv_vsse16_v_u16mf4_m(vbool64_t vm, uint16_t *rs1, ptrdiff_t rs2,
                               vuint16mf4_t vs3, size_t vl);
void __riscv_vsse16_v_u16mf2_m(vbool32_t vm, uint16_t *rs1, ptrdiff_t rs2,
                               vuint16mf2_t vs3, size_t vl);
void __riscv_vsse16_v_u16m1_m(vbool16_t vm, uint16_t *rs1, ptrdiff_t rs2,
                              vuint16m1_t vs3, size_t vl);
void __riscv_vsse16_v_u16m2_m(vbool8_t vm, uint16_t *rs1, ptrdiff_t rs2,
                              vuint16m2_t vs3, size_t vl);
void __riscv_vsse16_v_u16m4_m(vbool4_t vm, uint16_t *rs1, ptrdiff_t rs2,
                              vuint16m4_t vs3, size_t vl);
void __riscv_vsse16_v_u16m8_m(vbool2_t vm, uint16_t *rs1, ptrdiff_t rs2,
                              vuint16m8_t vs3, size_t vl);
void __riscv_vsse32_v_u32mf2_m(vbool64_t vm, uint32_t *rs1, ptrdiff_t rs2,
                               vuint32mf2_t vs3, size_t vl);
void __riscv_vsse32_v_u32m1_m(vbool32_t vm, uint32_t *rs1, ptrdiff_t rs2,
                              vuint32m1_t vs3, size_t vl);
void __riscv_vsse32_v_u32m2_m(vbool16_t vm, uint32_t *rs1, ptrdiff_t rs2,
                              vuint32m2_t vs3, size_t vl);
void __riscv_vsse32_v_u32m4_m(vbool8_t vm, uint32_t *rs1, ptrdiff_t rs2,
                              vuint32m4_t vs3, size_t vl);
void __riscv_vsse32_v_u32m8_m(vbool4_t vm, uint32_t *rs1, ptrdiff_t rs2,
                              vuint32m8_t vs3, size_t vl);
void __riscv_vsse64_v_u64m1_m(vbool64_t vm, uint64_t *rs1, ptrdiff_t rs2,
                              vuint64m1_t vs3, size_t vl);
void __riscv_vsse64_v_u64m2_m(vbool32_t vm, uint64_t *rs1, ptrdiff_t rs2,
                              vuint64m2_t vs3, size_t vl);
void __riscv_vsse64_v_u64m4_m(vbool16_t vm, uint64_t *rs1, ptrdiff_t rs2,
                              vuint64m4_t vs3, size_t vl);
void __riscv_vsse64_v_u64m8_m(vbool8_t vm, uint64_t *rs1, ptrdiff_t rs2,
                              vuint64m8_t vs3, size_t vl);
----

[[vector-indexed-load]]
==== Vector Indexed Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vloxei8_v_f16mf4(const _Float16 *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vfloat16mf2_t __riscv_vloxei8_v_f16mf2(const _Float16 *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vfloat16m1_t __riscv_vloxei8_v_f16m1(const _Float16 *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vfloat16m2_t __riscv_vloxei8_v_f16m2(const _Float16 *rs1, vuint8m1_t rs2,
                                     size_t vl);
vfloat16m4_t __riscv_vloxei8_v_f16m4(const _Float16 *rs1, vuint8m2_t rs2,
                                     size_t vl);
vfloat16m8_t __riscv_vloxei8_v_f16m8(const _Float16 *rs1, vuint8m4_t rs2,
                                     size_t vl);
vfloat16mf4_t __riscv_vloxei16_v_f16mf4(const _Float16 *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vloxei16_v_f16mf2(const _Float16 *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vfloat16m1_t __riscv_vloxei16_v_f16m1(const _Float16 *rs1, vuint16m1_t rs2,
                                      size_t vl);
vfloat16m2_t __riscv_vloxei16_v_f16m2(const _Float16 *rs1, vuint16m2_t rs2,
                                      size_t vl);
vfloat16m4_t __riscv_vloxei16_v_f16m4(const _Float16 *rs1, vuint16m4_t rs2,
                                      size_t vl);
vfloat16m8_t __riscv_vloxei16_v_f16m8(const _Float16 *rs1, vuint16m8_t rs2,
                                      size_t vl);
vfloat16mf4_t __riscv_vloxei32_v_f16mf4(const _Float16 *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vloxei32_v_f16mf2(const _Float16 *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat16m1_t __riscv_vloxei32_v_f16m1(const _Float16 *rs1, vuint32m2_t rs2,
                                      size_t vl);
vfloat16m2_t __riscv_vloxei32_v_f16m2(const _Float16 *rs1, vuint32m4_t rs2,
                                      size_t vl);
vfloat16m4_t __riscv_vloxei32_v_f16m4(const _Float16 *rs1, vuint32m8_t rs2,
                                      size_t vl);
vfloat16mf4_t __riscv_vloxei64_v_f16mf4(const _Float16 *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vloxei64_v_f16mf2(const _Float16 *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat16m1_t __riscv_vloxei64_v_f16m1(const _Float16 *rs1, vuint64m4_t rs2,
                                      size_t vl);
vfloat16m2_t __riscv_vloxei64_v_f16m2(const _Float16 *rs1, vuint64m8_t rs2,
                                      size_t vl);
vfloat32mf2_t __riscv_vloxei8_v_f32mf2(const float *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vfloat32m1_t __riscv_vloxei8_v_f32m1(const float *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vfloat32m2_t __riscv_vloxei8_v_f32m2(const float *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vfloat32m4_t __riscv_vloxei8_v_f32m4(const float *rs1, vuint8m1_t rs2,
                                     size_t vl);
vfloat32m8_t __riscv_vloxei8_v_f32m8(const float *rs1, vuint8m2_t rs2,
                                     size_t vl);
vfloat32mf2_t __riscv_vloxei16_v_f32mf2(const float *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vfloat32m1_t __riscv_vloxei16_v_f32m1(const float *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vfloat32m2_t __riscv_vloxei16_v_f32m2(const float *rs1, vuint16m1_t rs2,
                                      size_t vl);
vfloat32m4_t __riscv_vloxei16_v_f32m4(const float *rs1, vuint16m2_t rs2,
                                      size_t vl);
vfloat32m8_t __riscv_vloxei16_v_f32m8(const float *rs1, vuint16m4_t rs2,
                                      size_t vl);
vfloat32mf2_t __riscv_vloxei32_v_f32mf2(const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32m1_t __riscv_vloxei32_v_f32m1(const float *rs1, vuint32m1_t rs2,
                                      size_t vl);
vfloat32m2_t __riscv_vloxei32_v_f32m2(const float *rs1, vuint32m2_t rs2,
                                      size_t vl);
vfloat32m4_t __riscv_vloxei32_v_f32m4(const float *rs1, vuint32m4_t rs2,
                                      size_t vl);
vfloat32m8_t __riscv_vloxei32_v_f32m8(const float *rs1, vuint32m8_t rs2,
                                      size_t vl);
vfloat32mf2_t __riscv_vloxei64_v_f32mf2(const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32m1_t __riscv_vloxei64_v_f32m1(const float *rs1, vuint64m2_t rs2,
                                      size_t vl);
vfloat32m2_t __riscv_vloxei64_v_f32m2(const float *rs1, vuint64m4_t rs2,
                                      size_t vl);
vfloat32m4_t __riscv_vloxei64_v_f32m4(const float *rs1, vuint64m8_t rs2,
                                      size_t vl);
vfloat64m1_t __riscv_vloxei8_v_f64m1(const double *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vfloat64m2_t __riscv_vloxei8_v_f64m2(const double *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vfloat64m4_t __riscv_vloxei8_v_f64m4(const double *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vfloat64m8_t __riscv_vloxei8_v_f64m8(const double *rs1, vuint8m1_t rs2,
                                     size_t vl);
vfloat64m1_t __riscv_vloxei16_v_f64m1(const double *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vfloat64m2_t __riscv_vloxei16_v_f64m2(const double *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vfloat64m4_t __riscv_vloxei16_v_f64m4(const double *rs1, vuint16m1_t rs2,
                                      size_t vl);
vfloat64m8_t __riscv_vloxei16_v_f64m8(const double *rs1, vuint16m2_t rs2,
                                      size_t vl);
vfloat64m1_t __riscv_vloxei32_v_f64m1(const double *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vfloat64m2_t __riscv_vloxei32_v_f64m2(const double *rs1, vuint32m1_t rs2,
                                      size_t vl);
vfloat64m4_t __riscv_vloxei32_v_f64m4(const double *rs1, vuint32m2_t rs2,
                                      size_t vl);
vfloat64m8_t __riscv_vloxei32_v_f64m8(const double *rs1, vuint32m4_t rs2,
                                      size_t vl);
vfloat64m1_t __riscv_vloxei64_v_f64m1(const double *rs1, vuint64m1_t rs2,
                                      size_t vl);
vfloat64m2_t __riscv_vloxei64_v_f64m2(const double *rs1, vuint64m2_t rs2,
                                      size_t vl);
vfloat64m4_t __riscv_vloxei64_v_f64m4(const double *rs1, vuint64m4_t rs2,
                                      size_t vl);
vfloat64m8_t __riscv_vloxei64_v_f64m8(const double *rs1, vuint64m8_t rs2,
                                      size_t vl);
vfloat16mf4_t __riscv_vluxei8_v_f16mf4(const _Float16 *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vfloat16mf2_t __riscv_vluxei8_v_f16mf2(const _Float16 *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vfloat16m1_t __riscv_vluxei8_v_f16m1(const _Float16 *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vfloat16m2_t __riscv_vluxei8_v_f16m2(const _Float16 *rs1, vuint8m1_t rs2,
                                     size_t vl);
vfloat16m4_t __riscv_vluxei8_v_f16m4(const _Float16 *rs1, vuint8m2_t rs2,
                                     size_t vl);
vfloat16m8_t __riscv_vluxei8_v_f16m8(const _Float16 *rs1, vuint8m4_t rs2,
                                     size_t vl);
vfloat16mf4_t __riscv_vluxei16_v_f16mf4(const _Float16 *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vluxei16_v_f16mf2(const _Float16 *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vfloat16m1_t __riscv_vluxei16_v_f16m1(const _Float16 *rs1, vuint16m1_t rs2,
                                      size_t vl);
vfloat16m2_t __riscv_vluxei16_v_f16m2(const _Float16 *rs1, vuint16m2_t rs2,
                                      size_t vl);
vfloat16m4_t __riscv_vluxei16_v_f16m4(const _Float16 *rs1, vuint16m4_t rs2,
                                      size_t vl);
vfloat16m8_t __riscv_vluxei16_v_f16m8(const _Float16 *rs1, vuint16m8_t rs2,
                                      size_t vl);
vfloat16mf4_t __riscv_vluxei32_v_f16mf4(const _Float16 *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vluxei32_v_f16mf2(const _Float16 *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat16m1_t __riscv_vluxei32_v_f16m1(const _Float16 *rs1, vuint32m2_t rs2,
                                      size_t vl);
vfloat16m2_t __riscv_vluxei32_v_f16m2(const _Float16 *rs1, vuint32m4_t rs2,
                                      size_t vl);
vfloat16m4_t __riscv_vluxei32_v_f16m4(const _Float16 *rs1, vuint32m8_t rs2,
                                      size_t vl);
vfloat16mf4_t __riscv_vluxei64_v_f16mf4(const _Float16 *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vluxei64_v_f16mf2(const _Float16 *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat16m1_t __riscv_vluxei64_v_f16m1(const _Float16 *rs1, vuint64m4_t rs2,
                                      size_t vl);
vfloat16m2_t __riscv_vluxei64_v_f16m2(const _Float16 *rs1, vuint64m8_t rs2,
                                      size_t vl);
vfloat32mf2_t __riscv_vluxei8_v_f32mf2(const float *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vfloat32m1_t __riscv_vluxei8_v_f32m1(const float *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vfloat32m2_t __riscv_vluxei8_v_f32m2(const float *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vfloat32m4_t __riscv_vluxei8_v_f32m4(const float *rs1, vuint8m1_t rs2,
                                     size_t vl);
vfloat32m8_t __riscv_vluxei8_v_f32m8(const float *rs1, vuint8m2_t rs2,
                                     size_t vl);
vfloat32mf2_t __riscv_vluxei16_v_f32mf2(const float *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vfloat32m1_t __riscv_vluxei16_v_f32m1(const float *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vfloat32m2_t __riscv_vluxei16_v_f32m2(const float *rs1, vuint16m1_t rs2,
                                      size_t vl);
vfloat32m4_t __riscv_vluxei16_v_f32m4(const float *rs1, vuint16m2_t rs2,
                                      size_t vl);
vfloat32m8_t __riscv_vluxei16_v_f32m8(const float *rs1, vuint16m4_t rs2,
                                      size_t vl);
vfloat32mf2_t __riscv_vluxei32_v_f32mf2(const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32m1_t __riscv_vluxei32_v_f32m1(const float *rs1, vuint32m1_t rs2,
                                      size_t vl);
vfloat32m2_t __riscv_vluxei32_v_f32m2(const float *rs1, vuint32m2_t rs2,
                                      size_t vl);
vfloat32m4_t __riscv_vluxei32_v_f32m4(const float *rs1, vuint32m4_t rs2,
                                      size_t vl);
vfloat32m8_t __riscv_vluxei32_v_f32m8(const float *rs1, vuint32m8_t rs2,
                                      size_t vl);
vfloat32mf2_t __riscv_vluxei64_v_f32mf2(const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32m1_t __riscv_vluxei64_v_f32m1(const float *rs1, vuint64m2_t rs2,
                                      size_t vl);
vfloat32m2_t __riscv_vluxei64_v_f32m2(const float *rs1, vuint64m4_t rs2,
                                      size_t vl);
vfloat32m4_t __riscv_vluxei64_v_f32m4(const float *rs1, vuint64m8_t rs2,
                                      size_t vl);
vfloat64m1_t __riscv_vluxei8_v_f64m1(const double *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vfloat64m2_t __riscv_vluxei8_v_f64m2(const double *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vfloat64m4_t __riscv_vluxei8_v_f64m4(const double *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vfloat64m8_t __riscv_vluxei8_v_f64m8(const double *rs1, vuint8m1_t rs2,
                                     size_t vl);
vfloat64m1_t __riscv_vluxei16_v_f64m1(const double *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vfloat64m2_t __riscv_vluxei16_v_f64m2(const double *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vfloat64m4_t __riscv_vluxei16_v_f64m4(const double *rs1, vuint16m1_t rs2,
                                      size_t vl);
vfloat64m8_t __riscv_vluxei16_v_f64m8(const double *rs1, vuint16m2_t rs2,
                                      size_t vl);
vfloat64m1_t __riscv_vluxei32_v_f64m1(const double *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vfloat64m2_t __riscv_vluxei32_v_f64m2(const double *rs1, vuint32m1_t rs2,
                                      size_t vl);
vfloat64m4_t __riscv_vluxei32_v_f64m4(const double *rs1, vuint32m2_t rs2,
                                      size_t vl);
vfloat64m8_t __riscv_vluxei32_v_f64m8(const double *rs1, vuint32m4_t rs2,
                                      size_t vl);
vfloat64m1_t __riscv_vluxei64_v_f64m1(const double *rs1, vuint64m1_t rs2,
                                      size_t vl);
vfloat64m2_t __riscv_vluxei64_v_f64m2(const double *rs1, vuint64m2_t rs2,
                                      size_t vl);
vfloat64m4_t __riscv_vluxei64_v_f64m4(const double *rs1, vuint64m4_t rs2,
                                      size_t vl);
vfloat64m8_t __riscv_vluxei64_v_f64m8(const double *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8mf8_t __riscv_vloxei8_v_i8mf8(const int8_t *rs1, vuint8mf8_t rs2,
                                   size_t vl);
vint8mf4_t __riscv_vloxei8_v_i8mf4(const int8_t *rs1, vuint8mf4_t rs2,
                                   size_t vl);
vint8mf2_t __riscv_vloxei8_v_i8mf2(const int8_t *rs1, vuint8mf2_t rs2,
                                   size_t vl);
vint8m1_t __riscv_vloxei8_v_i8m1(const int8_t *rs1, vuint8m1_t rs2, size_t vl);
vint8m2_t __riscv_vloxei8_v_i8m2(const int8_t *rs1, vuint8m2_t rs2, size_t vl);
vint8m4_t __riscv_vloxei8_v_i8m4(const int8_t *rs1, vuint8m4_t rs2, size_t vl);
vint8m8_t __riscv_vloxei8_v_i8m8(const int8_t *rs1, vuint8m8_t rs2, size_t vl);
vint8mf8_t __riscv_vloxei16_v_i8mf8(const int8_t *rs1, vuint16mf4_t rs2,
                                    size_t vl);
vint8mf4_t __riscv_vloxei16_v_i8mf4(const int8_t *rs1, vuint16mf2_t rs2,
                                    size_t vl);
vint8mf2_t __riscv_vloxei16_v_i8mf2(const int8_t *rs1, vuint16m1_t rs2,
                                    size_t vl);
vint8m1_t __riscv_vloxei16_v_i8m1(const int8_t *rs1, vuint16m2_t rs2,
                                  size_t vl);
vint8m2_t __riscv_vloxei16_v_i8m2(const int8_t *rs1, vuint16m4_t rs2,
                                  size_t vl);
vint8m4_t __riscv_vloxei16_v_i8m4(const int8_t *rs1, vuint16m8_t rs2,
                                  size_t vl);
vint8mf8_t __riscv_vloxei32_v_i8mf8(const int8_t *rs1, vuint32mf2_t rs2,
                                    size_t vl);
vint8mf4_t __riscv_vloxei32_v_i8mf4(const int8_t *rs1, vuint32m1_t rs2,
                                    size_t vl);
vint8mf2_t __riscv_vloxei32_v_i8mf2(const int8_t *rs1, vuint32m2_t rs2,
                                    size_t vl);
vint8m1_t __riscv_vloxei32_v_i8m1(const int8_t *rs1, vuint32m4_t rs2,
                                  size_t vl);
vint8m2_t __riscv_vloxei32_v_i8m2(const int8_t *rs1, vuint32m8_t rs2,
                                  size_t vl);
vint8mf8_t __riscv_vloxei64_v_i8mf8(const int8_t *rs1, vuint64m1_t rs2,
                                    size_t vl);
vint8mf4_t __riscv_vloxei64_v_i8mf4(const int8_t *rs1, vuint64m2_t rs2,
                                    size_t vl);
vint8mf2_t __riscv_vloxei64_v_i8mf2(const int8_t *rs1, vuint64m4_t rs2,
                                    size_t vl);
vint8m1_t __riscv_vloxei64_v_i8m1(const int8_t *rs1, vuint64m8_t rs2,
                                  size_t vl);
vint16mf4_t __riscv_vloxei8_v_i16mf4(const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf2_t __riscv_vloxei8_v_i16mf2(const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16m1_t __riscv_vloxei8_v_i16m1(const int16_t *rs1, vuint8mf2_t rs2,
                                   size_t vl);
vint16m2_t __riscv_vloxei8_v_i16m2(const int16_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint16m4_t __riscv_vloxei8_v_i16m4(const int16_t *rs1, vuint8m2_t rs2,
                                   size_t vl);
vint16m8_t __riscv_vloxei8_v_i16m8(const int16_t *rs1, vuint8m4_t rs2,
                                   size_t vl);
vint16mf4_t __riscv_vloxei16_v_i16mf4(const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf2_t __riscv_vloxei16_v_i16mf2(const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16m1_t __riscv_vloxei16_v_i16m1(const int16_t *rs1, vuint16m1_t rs2,
                                    size_t vl);
vint16m2_t __riscv_vloxei16_v_i16m2(const int16_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint16m4_t __riscv_vloxei16_v_i16m4(const int16_t *rs1, vuint16m4_t rs2,
                                    size_t vl);
vint16m8_t __riscv_vloxei16_v_i16m8(const int16_t *rs1, vuint16m8_t rs2,
                                    size_t vl);
vint16mf4_t __riscv_vloxei32_v_i16mf4(const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf2_t __riscv_vloxei32_v_i16mf2(const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16m1_t __riscv_vloxei32_v_i16m1(const int16_t *rs1, vuint32m2_t rs2,
                                    size_t vl);
vint16m2_t __riscv_vloxei32_v_i16m2(const int16_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint16m4_t __riscv_vloxei32_v_i16m4(const int16_t *rs1, vuint32m8_t rs2,
                                    size_t vl);
vint16mf4_t __riscv_vloxei64_v_i16mf4(const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf2_t __riscv_vloxei64_v_i16mf2(const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16m1_t __riscv_vloxei64_v_i16m1(const int16_t *rs1, vuint64m4_t rs2,
                                    size_t vl);
vint16m2_t __riscv_vloxei64_v_i16m2(const int16_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint32mf2_t __riscv_vloxei8_v_i32mf2(const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32m1_t __riscv_vloxei8_v_i32m1(const int32_t *rs1, vuint8mf4_t rs2,
                                   size_t vl);
vint32m2_t __riscv_vloxei8_v_i32m2(const int32_t *rs1, vuint8mf2_t rs2,
                                   size_t vl);
vint32m4_t __riscv_vloxei8_v_i32m4(const int32_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint32m8_t __riscv_vloxei8_v_i32m8(const int32_t *rs1, vuint8m2_t rs2,
                                   size_t vl);
vint32mf2_t __riscv_vloxei16_v_i32mf2(const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32m1_t __riscv_vloxei16_v_i32m1(const int32_t *rs1, vuint16mf2_t rs2,
                                    size_t vl);
vint32m2_t __riscv_vloxei16_v_i32m2(const int32_t *rs1, vuint16m1_t rs2,
                                    size_t vl);
vint32m4_t __riscv_vloxei16_v_i32m4(const int32_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint32m8_t __riscv_vloxei16_v_i32m8(const int32_t *rs1, vuint16m4_t rs2,
                                    size_t vl);
vint32mf2_t __riscv_vloxei32_v_i32mf2(const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32m1_t __riscv_vloxei32_v_i32m1(const int32_t *rs1, vuint32m1_t rs2,
                                    size_t vl);
vint32m2_t __riscv_vloxei32_v_i32m2(const int32_t *rs1, vuint32m2_t rs2,
                                    size_t vl);
vint32m4_t __riscv_vloxei32_v_i32m4(const int32_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint32m8_t __riscv_vloxei32_v_i32m8(const int32_t *rs1, vuint32m8_t rs2,
                                    size_t vl);
vint32mf2_t __riscv_vloxei64_v_i32mf2(const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32m1_t __riscv_vloxei64_v_i32m1(const int32_t *rs1, vuint64m2_t rs2,
                                    size_t vl);
vint32m2_t __riscv_vloxei64_v_i32m2(const int32_t *rs1, vuint64m4_t rs2,
                                    size_t vl);
vint32m4_t __riscv_vloxei64_v_i32m4(const int32_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint64m1_t __riscv_vloxei8_v_i64m1(const int64_t *rs1, vuint8mf8_t rs2,
                                   size_t vl);
vint64m2_t __riscv_vloxei8_v_i64m2(const int64_t *rs1, vuint8mf4_t rs2,
                                   size_t vl);
vint64m4_t __riscv_vloxei8_v_i64m4(const int64_t *rs1, vuint8mf2_t rs2,
                                   size_t vl);
vint64m8_t __riscv_vloxei8_v_i64m8(const int64_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint64m1_t __riscv_vloxei16_v_i64m1(const int64_t *rs1, vuint16mf4_t rs2,
                                    size_t vl);
vint64m2_t __riscv_vloxei16_v_i64m2(const int64_t *rs1, vuint16mf2_t rs2,
                                    size_t vl);
vint64m4_t __riscv_vloxei16_v_i64m4(const int64_t *rs1, vuint16m1_t rs2,
                                    size_t vl);
vint64m8_t __riscv_vloxei16_v_i64m8(const int64_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint64m1_t __riscv_vloxei32_v_i64m1(const int64_t *rs1, vuint32mf2_t rs2,
                                    size_t vl);
vint64m2_t __riscv_vloxei32_v_i64m2(const int64_t *rs1, vuint32m1_t rs2,
                                    size_t vl);
vint64m4_t __riscv_vloxei32_v_i64m4(const int64_t *rs1, vuint32m2_t rs2,
                                    size_t vl);
vint64m8_t __riscv_vloxei32_v_i64m8(const int64_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint64m1_t __riscv_vloxei64_v_i64m1(const int64_t *rs1, vuint64m1_t rs2,
                                    size_t vl);
vint64m2_t __riscv_vloxei64_v_i64m2(const int64_t *rs1, vuint64m2_t rs2,
                                    size_t vl);
vint64m4_t __riscv_vloxei64_v_i64m4(const int64_t *rs1, vuint64m4_t rs2,
                                    size_t vl);
vint64m8_t __riscv_vloxei64_v_i64m8(const int64_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8mf8_t __riscv_vluxei8_v_i8mf8(const int8_t *rs1, vuint8mf8_t rs2,
                                   size_t vl);
vint8mf4_t __riscv_vluxei8_v_i8mf4(const int8_t *rs1, vuint8mf4_t rs2,
                                   size_t vl);
vint8mf2_t __riscv_vluxei8_v_i8mf2(const int8_t *rs1, vuint8mf2_t rs2,
                                   size_t vl);
vint8m1_t __riscv_vluxei8_v_i8m1(const int8_t *rs1, vuint8m1_t rs2, size_t vl);
vint8m2_t __riscv_vluxei8_v_i8m2(const int8_t *rs1, vuint8m2_t rs2, size_t vl);
vint8m4_t __riscv_vluxei8_v_i8m4(const int8_t *rs1, vuint8m4_t rs2, size_t vl);
vint8m8_t __riscv_vluxei8_v_i8m8(const int8_t *rs1, vuint8m8_t rs2, size_t vl);
vint8mf8_t __riscv_vluxei16_v_i8mf8(const int8_t *rs1, vuint16mf4_t rs2,
                                    size_t vl);
vint8mf4_t __riscv_vluxei16_v_i8mf4(const int8_t *rs1, vuint16mf2_t rs2,
                                    size_t vl);
vint8mf2_t __riscv_vluxei16_v_i8mf2(const int8_t *rs1, vuint16m1_t rs2,
                                    size_t vl);
vint8m1_t __riscv_vluxei16_v_i8m1(const int8_t *rs1, vuint16m2_t rs2,
                                  size_t vl);
vint8m2_t __riscv_vluxei16_v_i8m2(const int8_t *rs1, vuint16m4_t rs2,
                                  size_t vl);
vint8m4_t __riscv_vluxei16_v_i8m4(const int8_t *rs1, vuint16m8_t rs2,
                                  size_t vl);
vint8mf8_t __riscv_vluxei32_v_i8mf8(const int8_t *rs1, vuint32mf2_t rs2,
                                    size_t vl);
vint8mf4_t __riscv_vluxei32_v_i8mf4(const int8_t *rs1, vuint32m1_t rs2,
                                    size_t vl);
vint8mf2_t __riscv_vluxei32_v_i8mf2(const int8_t *rs1, vuint32m2_t rs2,
                                    size_t vl);
vint8m1_t __riscv_vluxei32_v_i8m1(const int8_t *rs1, vuint32m4_t rs2,
                                  size_t vl);
vint8m2_t __riscv_vluxei32_v_i8m2(const int8_t *rs1, vuint32m8_t rs2,
                                  size_t vl);
vint8mf8_t __riscv_vluxei64_v_i8mf8(const int8_t *rs1, vuint64m1_t rs2,
                                    size_t vl);
vint8mf4_t __riscv_vluxei64_v_i8mf4(const int8_t *rs1, vuint64m2_t rs2,
                                    size_t vl);
vint8mf2_t __riscv_vluxei64_v_i8mf2(const int8_t *rs1, vuint64m4_t rs2,
                                    size_t vl);
vint8m1_t __riscv_vluxei64_v_i8m1(const int8_t *rs1, vuint64m8_t rs2,
                                  size_t vl);
vint16mf4_t __riscv_vluxei8_v_i16mf4(const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf2_t __riscv_vluxei8_v_i16mf2(const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16m1_t __riscv_vluxei8_v_i16m1(const int16_t *rs1, vuint8mf2_t rs2,
                                   size_t vl);
vint16m2_t __riscv_vluxei8_v_i16m2(const int16_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint16m4_t __riscv_vluxei8_v_i16m4(const int16_t *rs1, vuint8m2_t rs2,
                                   size_t vl);
vint16m8_t __riscv_vluxei8_v_i16m8(const int16_t *rs1, vuint8m4_t rs2,
                                   size_t vl);
vint16mf4_t __riscv_vluxei16_v_i16mf4(const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf2_t __riscv_vluxei16_v_i16mf2(const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16m1_t __riscv_vluxei16_v_i16m1(const int16_t *rs1, vuint16m1_t rs2,
                                    size_t vl);
vint16m2_t __riscv_vluxei16_v_i16m2(const int16_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint16m4_t __riscv_vluxei16_v_i16m4(const int16_t *rs1, vuint16m4_t rs2,
                                    size_t vl);
vint16m8_t __riscv_vluxei16_v_i16m8(const int16_t *rs1, vuint16m8_t rs2,
                                    size_t vl);
vint16mf4_t __riscv_vluxei32_v_i16mf4(const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf2_t __riscv_vluxei32_v_i16mf2(const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16m1_t __riscv_vluxei32_v_i16m1(const int16_t *rs1, vuint32m2_t rs2,
                                    size_t vl);
vint16m2_t __riscv_vluxei32_v_i16m2(const int16_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint16m4_t __riscv_vluxei32_v_i16m4(const int16_t *rs1, vuint32m8_t rs2,
                                    size_t vl);
vint16mf4_t __riscv_vluxei64_v_i16mf4(const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf2_t __riscv_vluxei64_v_i16mf2(const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16m1_t __riscv_vluxei64_v_i16m1(const int16_t *rs1, vuint64m4_t rs2,
                                    size_t vl);
vint16m2_t __riscv_vluxei64_v_i16m2(const int16_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint32mf2_t __riscv_vluxei8_v_i32mf2(const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32m1_t __riscv_vluxei8_v_i32m1(const int32_t *rs1, vuint8mf4_t rs2,
                                   size_t vl);
vint32m2_t __riscv_vluxei8_v_i32m2(const int32_t *rs1, vuint8mf2_t rs2,
                                   size_t vl);
vint32m4_t __riscv_vluxei8_v_i32m4(const int32_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint32m8_t __riscv_vluxei8_v_i32m8(const int32_t *rs1, vuint8m2_t rs2,
                                   size_t vl);
vint32mf2_t __riscv_vluxei16_v_i32mf2(const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32m1_t __riscv_vluxei16_v_i32m1(const int32_t *rs1, vuint16mf2_t rs2,
                                    size_t vl);
vint32m2_t __riscv_vluxei16_v_i32m2(const int32_t *rs1, vuint16m1_t rs2,
                                    size_t vl);
vint32m4_t __riscv_vluxei16_v_i32m4(const int32_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint32m8_t __riscv_vluxei16_v_i32m8(const int32_t *rs1, vuint16m4_t rs2,
                                    size_t vl);
vint32mf2_t __riscv_vluxei32_v_i32mf2(const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32m1_t __riscv_vluxei32_v_i32m1(const int32_t *rs1, vuint32m1_t rs2,
                                    size_t vl);
vint32m2_t __riscv_vluxei32_v_i32m2(const int32_t *rs1, vuint32m2_t rs2,
                                    size_t vl);
vint32m4_t __riscv_vluxei32_v_i32m4(const int32_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint32m8_t __riscv_vluxei32_v_i32m8(const int32_t *rs1, vuint32m8_t rs2,
                                    size_t vl);
vint32mf2_t __riscv_vluxei64_v_i32mf2(const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32m1_t __riscv_vluxei64_v_i32m1(const int32_t *rs1, vuint64m2_t rs2,
                                    size_t vl);
vint32m2_t __riscv_vluxei64_v_i32m2(const int32_t *rs1, vuint64m4_t rs2,
                                    size_t vl);
vint32m4_t __riscv_vluxei64_v_i32m4(const int32_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint64m1_t __riscv_vluxei8_v_i64m1(const int64_t *rs1, vuint8mf8_t rs2,
                                   size_t vl);
vint64m2_t __riscv_vluxei8_v_i64m2(const int64_t *rs1, vuint8mf4_t rs2,
                                   size_t vl);
vint64m4_t __riscv_vluxei8_v_i64m4(const int64_t *rs1, vuint8mf2_t rs2,
                                   size_t vl);
vint64m8_t __riscv_vluxei8_v_i64m8(const int64_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint64m1_t __riscv_vluxei16_v_i64m1(const int64_t *rs1, vuint16mf4_t rs2,
                                    size_t vl);
vint64m2_t __riscv_vluxei16_v_i64m2(const int64_t *rs1, vuint16mf2_t rs2,
                                    size_t vl);
vint64m4_t __riscv_vluxei16_v_i64m4(const int64_t *rs1, vuint16m1_t rs2,
                                    size_t vl);
vint64m8_t __riscv_vluxei16_v_i64m8(const int64_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint64m1_t __riscv_vluxei32_v_i64m1(const int64_t *rs1, vuint32mf2_t rs2,
                                    size_t vl);
vint64m2_t __riscv_vluxei32_v_i64m2(const int64_t *rs1, vuint32m1_t rs2,
                                    size_t vl);
vint64m4_t __riscv_vluxei32_v_i64m4(const int64_t *rs1, vuint32m2_t rs2,
                                    size_t vl);
vint64m8_t __riscv_vluxei32_v_i64m8(const int64_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint64m1_t __riscv_vluxei64_v_i64m1(const int64_t *rs1, vuint64m1_t rs2,
                                    size_t vl);
vint64m2_t __riscv_vluxei64_v_i64m2(const int64_t *rs1, vuint64m2_t rs2,
                                    size_t vl);
vint64m4_t __riscv_vluxei64_v_i64m4(const int64_t *rs1, vuint64m4_t rs2,
                                    size_t vl);
vint64m8_t __riscv_vluxei64_v_i64m8(const int64_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vuint8mf8_t __riscv_vloxei8_v_u8mf8(const uint8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vuint8mf4_t __riscv_vloxei8_v_u8mf4(const uint8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vuint8mf2_t __riscv_vloxei8_v_u8mf2(const uint8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vuint8m1_t __riscv_vloxei8_v_u8m1(const uint8_t *rs1, vuint8m1_t rs2,
                                  size_t vl);
vuint8m2_t __riscv_vloxei8_v_u8m2(const uint8_t *rs1, vuint8m2_t rs2,
                                  size_t vl);
vuint8m4_t __riscv_vloxei8_v_u8m4(const uint8_t *rs1, vuint8m4_t rs2,
                                  size_t vl);
vuint8m8_t __riscv_vloxei8_v_u8m8(const uint8_t *rs1, vuint8m8_t rs2,
                                  size_t vl);
vuint8mf8_t __riscv_vloxei16_v_u8mf8(const uint8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vuint8mf4_t __riscv_vloxei16_v_u8mf4(const uint8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vuint8mf2_t __riscv_vloxei16_v_u8mf2(const uint8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vuint8m1_t __riscv_vloxei16_v_u8m1(const uint8_t *rs1, vuint16m2_t rs2,
                                   size_t vl);
vuint8m2_t __riscv_vloxei16_v_u8m2(const uint8_t *rs1, vuint16m4_t rs2,
                                   size_t vl);
vuint8m4_t __riscv_vloxei16_v_u8m4(const uint8_t *rs1, vuint16m8_t rs2,
                                   size_t vl);
vuint8mf8_t __riscv_vloxei32_v_u8mf8(const uint8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vuint8mf4_t __riscv_vloxei32_v_u8mf4(const uint8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vuint8mf2_t __riscv_vloxei32_v_u8mf2(const uint8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vuint8m1_t __riscv_vloxei32_v_u8m1(const uint8_t *rs1, vuint32m4_t rs2,
                                   size_t vl);
vuint8m2_t __riscv_vloxei32_v_u8m2(const uint8_t *rs1, vuint32m8_t rs2,
                                   size_t vl);
vuint8mf8_t __riscv_vloxei64_v_u8mf8(const uint8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vuint8mf4_t __riscv_vloxei64_v_u8mf4(const uint8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vuint8mf2_t __riscv_vloxei64_v_u8mf2(const uint8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vuint8m1_t __riscv_vloxei64_v_u8m1(const uint8_t *rs1, vuint64m8_t rs2,
                                   size_t vl);
vuint16mf4_t __riscv_vloxei8_v_u16mf4(const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf2_t __riscv_vloxei8_v_u16mf2(const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16m1_t __riscv_vloxei8_v_u16m1(const uint16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vuint16m2_t __riscv_vloxei8_v_u16m2(const uint16_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint16m4_t __riscv_vloxei8_v_u16m4(const uint16_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vuint16m8_t __riscv_vloxei8_v_u16m8(const uint16_t *rs1, vuint8m4_t rs2,
                                    size_t vl);
vuint16mf4_t __riscv_vloxei16_v_u16mf4(const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf2_t __riscv_vloxei16_v_u16mf2(const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16m1_t __riscv_vloxei16_v_u16m1(const uint16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vuint16m2_t __riscv_vloxei16_v_u16m2(const uint16_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint16m4_t __riscv_vloxei16_v_u16m4(const uint16_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vuint16m8_t __riscv_vloxei16_v_u16m8(const uint16_t *rs1, vuint16m8_t rs2,
                                     size_t vl);
vuint16mf4_t __riscv_vloxei32_v_u16mf4(const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf2_t __riscv_vloxei32_v_u16mf2(const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16m1_t __riscv_vloxei32_v_u16m1(const uint16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vuint16m2_t __riscv_vloxei32_v_u16m2(const uint16_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint16m4_t __riscv_vloxei32_v_u16m4(const uint16_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vuint16mf4_t __riscv_vloxei64_v_u16mf4(const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf2_t __riscv_vloxei64_v_u16mf2(const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16m1_t __riscv_vloxei64_v_u16m1(const uint16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vuint16m2_t __riscv_vloxei64_v_u16m2(const uint16_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint32mf2_t __riscv_vloxei8_v_u32mf2(const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32m1_t __riscv_vloxei8_v_u32m1(const uint32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vuint32m2_t __riscv_vloxei8_v_u32m2(const uint32_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vuint32m4_t __riscv_vloxei8_v_u32m4(const uint32_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint32m8_t __riscv_vloxei8_v_u32m8(const uint32_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vuint32mf2_t __riscv_vloxei16_v_u32mf2(const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32m1_t __riscv_vloxei16_v_u32m1(const uint32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vuint32m2_t __riscv_vloxei16_v_u32m2(const uint32_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vuint32m4_t __riscv_vloxei16_v_u32m4(const uint32_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint32m8_t __riscv_vloxei16_v_u32m8(const uint32_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vuint32mf2_t __riscv_vloxei32_v_u32mf2(const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32m1_t __riscv_vloxei32_v_u32m1(const uint32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vuint32m2_t __riscv_vloxei32_v_u32m2(const uint32_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vuint32m4_t __riscv_vloxei32_v_u32m4(const uint32_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint32m8_t __riscv_vloxei32_v_u32m8(const uint32_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vuint32mf2_t __riscv_vloxei64_v_u32mf2(const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32m1_t __riscv_vloxei64_v_u32m1(const uint32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vuint32m2_t __riscv_vloxei64_v_u32m2(const uint32_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vuint32m4_t __riscv_vloxei64_v_u32m4(const uint32_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint64m1_t __riscv_vloxei8_v_u64m1(const uint64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vuint64m2_t __riscv_vloxei8_v_u64m2(const uint64_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vuint64m4_t __riscv_vloxei8_v_u64m4(const uint64_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vuint64m8_t __riscv_vloxei8_v_u64m8(const uint64_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint64m1_t __riscv_vloxei16_v_u64m1(const uint64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vuint64m2_t __riscv_vloxei16_v_u64m2(const uint64_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vuint64m4_t __riscv_vloxei16_v_u64m4(const uint64_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vuint64m8_t __riscv_vloxei16_v_u64m8(const uint64_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint64m1_t __riscv_vloxei32_v_u64m1(const uint64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vuint64m2_t __riscv_vloxei32_v_u64m2(const uint64_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vuint64m4_t __riscv_vloxei32_v_u64m4(const uint64_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vuint64m8_t __riscv_vloxei32_v_u64m8(const uint64_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint64m1_t __riscv_vloxei64_v_u64m1(const uint64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vuint64m2_t __riscv_vloxei64_v_u64m2(const uint64_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vuint64m4_t __riscv_vloxei64_v_u64m4(const uint64_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vuint64m8_t __riscv_vloxei64_v_u64m8(const uint64_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8mf8_t __riscv_vluxei8_v_u8mf8(const uint8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vuint8mf4_t __riscv_vluxei8_v_u8mf4(const uint8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vuint8mf2_t __riscv_vluxei8_v_u8mf2(const uint8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vuint8m1_t __riscv_vluxei8_v_u8m1(const uint8_t *rs1, vuint8m1_t rs2,
                                  size_t vl);
vuint8m2_t __riscv_vluxei8_v_u8m2(const uint8_t *rs1, vuint8m2_t rs2,
                                  size_t vl);
vuint8m4_t __riscv_vluxei8_v_u8m4(const uint8_t *rs1, vuint8m4_t rs2,
                                  size_t vl);
vuint8m8_t __riscv_vluxei8_v_u8m8(const uint8_t *rs1, vuint8m8_t rs2,
                                  size_t vl);
vuint8mf8_t __riscv_vluxei16_v_u8mf8(const uint8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vuint8mf4_t __riscv_vluxei16_v_u8mf4(const uint8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vuint8mf2_t __riscv_vluxei16_v_u8mf2(const uint8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vuint8m1_t __riscv_vluxei16_v_u8m1(const uint8_t *rs1, vuint16m2_t rs2,
                                   size_t vl);
vuint8m2_t __riscv_vluxei16_v_u8m2(const uint8_t *rs1, vuint16m4_t rs2,
                                   size_t vl);
vuint8m4_t __riscv_vluxei16_v_u8m4(const uint8_t *rs1, vuint16m8_t rs2,
                                   size_t vl);
vuint8mf8_t __riscv_vluxei32_v_u8mf8(const uint8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vuint8mf4_t __riscv_vluxei32_v_u8mf4(const uint8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vuint8mf2_t __riscv_vluxei32_v_u8mf2(const uint8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vuint8m1_t __riscv_vluxei32_v_u8m1(const uint8_t *rs1, vuint32m4_t rs2,
                                   size_t vl);
vuint8m2_t __riscv_vluxei32_v_u8m2(const uint8_t *rs1, vuint32m8_t rs2,
                                   size_t vl);
vuint8mf8_t __riscv_vluxei64_v_u8mf8(const uint8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vuint8mf4_t __riscv_vluxei64_v_u8mf4(const uint8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vuint8mf2_t __riscv_vluxei64_v_u8mf2(const uint8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vuint8m1_t __riscv_vluxei64_v_u8m1(const uint8_t *rs1, vuint64m8_t rs2,
                                   size_t vl);
vuint16mf4_t __riscv_vluxei8_v_u16mf4(const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf2_t __riscv_vluxei8_v_u16mf2(const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16m1_t __riscv_vluxei8_v_u16m1(const uint16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vuint16m2_t __riscv_vluxei8_v_u16m2(const uint16_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint16m4_t __riscv_vluxei8_v_u16m4(const uint16_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vuint16m8_t __riscv_vluxei8_v_u16m8(const uint16_t *rs1, vuint8m4_t rs2,
                                    size_t vl);
vuint16mf4_t __riscv_vluxei16_v_u16mf4(const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf2_t __riscv_vluxei16_v_u16mf2(const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16m1_t __riscv_vluxei16_v_u16m1(const uint16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vuint16m2_t __riscv_vluxei16_v_u16m2(const uint16_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint16m4_t __riscv_vluxei16_v_u16m4(const uint16_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vuint16m8_t __riscv_vluxei16_v_u16m8(const uint16_t *rs1, vuint16m8_t rs2,
                                     size_t vl);
vuint16mf4_t __riscv_vluxei32_v_u16mf4(const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf2_t __riscv_vluxei32_v_u16mf2(const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16m1_t __riscv_vluxei32_v_u16m1(const uint16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vuint16m2_t __riscv_vluxei32_v_u16m2(const uint16_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint16m4_t __riscv_vluxei32_v_u16m4(const uint16_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vuint16mf4_t __riscv_vluxei64_v_u16mf4(const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf2_t __riscv_vluxei64_v_u16mf2(const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16m1_t __riscv_vluxei64_v_u16m1(const uint16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vuint16m2_t __riscv_vluxei64_v_u16m2(const uint16_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint32mf2_t __riscv_vluxei8_v_u32mf2(const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32m1_t __riscv_vluxei8_v_u32m1(const uint32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vuint32m2_t __riscv_vluxei8_v_u32m2(const uint32_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vuint32m4_t __riscv_vluxei8_v_u32m4(const uint32_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint32m8_t __riscv_vluxei8_v_u32m8(const uint32_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vuint32mf2_t __riscv_vluxei16_v_u32mf2(const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32m1_t __riscv_vluxei16_v_u32m1(const uint32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vuint32m2_t __riscv_vluxei16_v_u32m2(const uint32_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vuint32m4_t __riscv_vluxei16_v_u32m4(const uint32_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint32m8_t __riscv_vluxei16_v_u32m8(const uint32_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vuint32mf2_t __riscv_vluxei32_v_u32mf2(const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32m1_t __riscv_vluxei32_v_u32m1(const uint32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vuint32m2_t __riscv_vluxei32_v_u32m2(const uint32_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vuint32m4_t __riscv_vluxei32_v_u32m4(const uint32_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint32m8_t __riscv_vluxei32_v_u32m8(const uint32_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vuint32mf2_t __riscv_vluxei64_v_u32mf2(const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32m1_t __riscv_vluxei64_v_u32m1(const uint32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vuint32m2_t __riscv_vluxei64_v_u32m2(const uint32_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vuint32m4_t __riscv_vluxei64_v_u32m4(const uint32_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint64m1_t __riscv_vluxei8_v_u64m1(const uint64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vuint64m2_t __riscv_vluxei8_v_u64m2(const uint64_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vuint64m4_t __riscv_vluxei8_v_u64m4(const uint64_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vuint64m8_t __riscv_vluxei8_v_u64m8(const uint64_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint64m1_t __riscv_vluxei16_v_u64m1(const uint64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vuint64m2_t __riscv_vluxei16_v_u64m2(const uint64_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vuint64m4_t __riscv_vluxei16_v_u64m4(const uint64_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vuint64m8_t __riscv_vluxei16_v_u64m8(const uint64_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint64m1_t __riscv_vluxei32_v_u64m1(const uint64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vuint64m2_t __riscv_vluxei32_v_u64m2(const uint64_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vuint64m4_t __riscv_vluxei32_v_u64m4(const uint64_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vuint64m8_t __riscv_vluxei32_v_u64m8(const uint64_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint64m1_t __riscv_vluxei64_v_u64m1(const uint64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vuint64m2_t __riscv_vluxei64_v_u64m2(const uint64_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vuint64m4_t __riscv_vluxei64_v_u64m4(const uint64_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vuint64m8_t __riscv_vluxei64_v_u64m8(const uint64_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
// masked functions
vfloat16mf4_t __riscv_vloxei8_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                         vuint8mf8_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei8_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                         vuint8mf4_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei8_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                       vuint8mf2_t rs2, size_t vl);
vfloat16m2_t __riscv_vloxei8_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                       vuint8m1_t rs2, size_t vl);
vfloat16m4_t __riscv_vloxei8_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                       vuint8m2_t rs2, size_t vl);
vfloat16m8_t __riscv_vloxei8_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                       vuint8m4_t rs2, size_t vl);
vfloat16mf4_t __riscv_vloxei16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                          vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                          vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                        vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vloxei16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                        vuint16m2_t rs2, size_t vl);
vfloat16m4_t __riscv_vloxei16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                        vuint16m4_t rs2, size_t vl);
vfloat16m8_t __riscv_vloxei16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                        vuint16m8_t rs2, size_t vl);
vfloat16mf4_t __riscv_vloxei32_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                          vuint32mf2_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei32_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                          vuint32m1_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei32_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                        vuint32m2_t rs2, size_t vl);
vfloat16m2_t __riscv_vloxei32_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                        vuint32m4_t rs2, size_t vl);
vfloat16m4_t __riscv_vloxei32_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                        vuint32m8_t rs2, size_t vl);
vfloat16mf4_t __riscv_vloxei64_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                          vuint64m1_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei64_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                          vuint64m2_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei64_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                        vuint64m4_t rs2, size_t vl);
vfloat16m2_t __riscv_vloxei64_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                        vuint64m8_t rs2, size_t vl);
vfloat32mf2_t __riscv_vloxei8_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                         vuint8mf8_t rs2, size_t vl);
vfloat32m1_t __riscv_vloxei8_v_f32m1_m(vbool32_t vm, const float *rs1,
                                       vuint8mf4_t rs2, size_t vl);
vfloat32m2_t __riscv_vloxei8_v_f32m2_m(vbool16_t vm, const float *rs1,
                                       vuint8mf2_t rs2, size_t vl);
vfloat32m4_t __riscv_vloxei8_v_f32m4_m(vbool8_t vm, const float *rs1,
                                       vuint8m1_t rs2, size_t vl);
vfloat32m8_t __riscv_vloxei8_v_f32m8_m(vbool4_t vm, const float *rs1,
                                       vuint8m2_t rs2, size_t vl);
vfloat32mf2_t __riscv_vloxei16_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                          vuint16mf4_t rs2, size_t vl);
vfloat32m1_t __riscv_vloxei16_v_f32m1_m(vbool32_t vm, const float *rs1,
                                        vuint16mf2_t rs2, size_t vl);
vfloat32m2_t __riscv_vloxei16_v_f32m2_m(vbool16_t vm, const float *rs1,
                                        vuint16m1_t rs2, size_t vl);
vfloat32m4_t __riscv_vloxei16_v_f32m4_m(vbool8_t vm, const float *rs1,
                                        vuint16m2_t rs2, size_t vl);
vfloat32m8_t __riscv_vloxei16_v_f32m8_m(vbool4_t vm, const float *rs1,
                                        vuint16m4_t rs2, size_t vl);
vfloat32mf2_t __riscv_vloxei32_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                          vuint32mf2_t rs2, size_t vl);
vfloat32m1_t __riscv_vloxei32_v_f32m1_m(vbool32_t vm, const float *rs1,
                                        vuint32m1_t rs2, size_t vl);
vfloat32m2_t __riscv_vloxei32_v_f32m2_m(vbool16_t vm, const float *rs1,
                                        vuint32m2_t rs2, size_t vl);
vfloat32m4_t __riscv_vloxei32_v_f32m4_m(vbool8_t vm, const float *rs1,
                                        vuint32m4_t rs2, size_t vl);
vfloat32m8_t __riscv_vloxei32_v_f32m8_m(vbool4_t vm, const float *rs1,
                                        vuint32m8_t rs2, size_t vl);
vfloat32mf2_t __riscv_vloxei64_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                          vuint64m1_t rs2, size_t vl);
vfloat32m1_t __riscv_vloxei64_v_f32m1_m(vbool32_t vm, const float *rs1,
                                        vuint64m2_t rs2, size_t vl);
vfloat32m2_t __riscv_vloxei64_v_f32m2_m(vbool16_t vm, const float *rs1,
                                        vuint64m4_t rs2, size_t vl);
vfloat32m4_t __riscv_vloxei64_v_f32m4_m(vbool8_t vm, const float *rs1,
                                        vuint64m8_t rs2, size_t vl);
vfloat64m1_t __riscv_vloxei8_v_f64m1_m(vbool64_t vm, const double *rs1,
                                       vuint8mf8_t rs2, size_t vl);
vfloat64m2_t __riscv_vloxei8_v_f64m2_m(vbool32_t vm, const double *rs1,
                                       vuint8mf4_t rs2, size_t vl);
vfloat64m4_t __riscv_vloxei8_v_f64m4_m(vbool16_t vm, const double *rs1,
                                       vuint8mf2_t rs2, size_t vl);
vfloat64m8_t __riscv_vloxei8_v_f64m8_m(vbool8_t vm, const double *rs1,
                                       vuint8m1_t rs2, size_t vl);
vfloat64m1_t __riscv_vloxei16_v_f64m1_m(vbool64_t vm, const double *rs1,
                                        vuint16mf4_t rs2, size_t vl);
vfloat64m2_t __riscv_vloxei16_v_f64m2_m(vbool32_t vm, const double *rs1,
                                        vuint16mf2_t rs2, size_t vl);
vfloat64m4_t __riscv_vloxei16_v_f64m4_m(vbool16_t vm, const double *rs1,
                                        vuint16m1_t rs2, size_t vl);
vfloat64m8_t __riscv_vloxei16_v_f64m8_m(vbool8_t vm, const double *rs1,
                                        vuint16m2_t rs2, size_t vl);
vfloat64m1_t __riscv_vloxei32_v_f64m1_m(vbool64_t vm, const double *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat64m2_t __riscv_vloxei32_v_f64m2_m(vbool32_t vm, const double *rs1,
                                        vuint32m1_t rs2, size_t vl);
vfloat64m4_t __riscv_vloxei32_v_f64m4_m(vbool16_t vm, const double *rs1,
                                        vuint32m2_t rs2, size_t vl);
vfloat64m8_t __riscv_vloxei32_v_f64m8_m(vbool8_t vm, const double *rs1,
                                        vuint32m4_t rs2, size_t vl);
vfloat64m1_t __riscv_vloxei64_v_f64m1_m(vbool64_t vm, const double *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat64m2_t __riscv_vloxei64_v_f64m2_m(vbool32_t vm, const double *rs1,
                                        vuint64m2_t rs2, size_t vl);
vfloat64m4_t __riscv_vloxei64_v_f64m4_m(vbool16_t vm, const double *rs1,
                                        vuint64m4_t rs2, size_t vl);
vfloat64m8_t __riscv_vloxei64_v_f64m8_m(vbool8_t vm, const double *rs1,
                                        vuint64m8_t rs2, size_t vl);
vfloat16mf4_t __riscv_vluxei8_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                         vuint8mf8_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei8_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                         vuint8mf4_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei8_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                       vuint8mf2_t rs2, size_t vl);
vfloat16m2_t __riscv_vluxei8_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                       vuint8m1_t rs2, size_t vl);
vfloat16m4_t __riscv_vluxei8_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                       vuint8m2_t rs2, size_t vl);
vfloat16m8_t __riscv_vluxei8_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                       vuint8m4_t rs2, size_t vl);
vfloat16mf4_t __riscv_vluxei16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                          vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                          vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                        vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vluxei16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                        vuint16m2_t rs2, size_t vl);
vfloat16m4_t __riscv_vluxei16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                        vuint16m4_t rs2, size_t vl);
vfloat16m8_t __riscv_vluxei16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                        vuint16m8_t rs2, size_t vl);
vfloat16mf4_t __riscv_vluxei32_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                          vuint32mf2_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei32_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                          vuint32m1_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei32_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                        vuint32m2_t rs2, size_t vl);
vfloat16m2_t __riscv_vluxei32_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                        vuint32m4_t rs2, size_t vl);
vfloat16m4_t __riscv_vluxei32_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                        vuint32m8_t rs2, size_t vl);
vfloat16mf4_t __riscv_vluxei64_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                          vuint64m1_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei64_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                          vuint64m2_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei64_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                        vuint64m4_t rs2, size_t vl);
vfloat16m2_t __riscv_vluxei64_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                        vuint64m8_t rs2, size_t vl);
vfloat32mf2_t __riscv_vluxei8_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                         vuint8mf8_t rs2, size_t vl);
vfloat32m1_t __riscv_vluxei8_v_f32m1_m(vbool32_t vm, const float *rs1,
                                       vuint8mf4_t rs2, size_t vl);
vfloat32m2_t __riscv_vluxei8_v_f32m2_m(vbool16_t vm, const float *rs1,
                                       vuint8mf2_t rs2, size_t vl);
vfloat32m4_t __riscv_vluxei8_v_f32m4_m(vbool8_t vm, const float *rs1,
                                       vuint8m1_t rs2, size_t vl);
vfloat32m8_t __riscv_vluxei8_v_f32m8_m(vbool4_t vm, const float *rs1,
                                       vuint8m2_t rs2, size_t vl);
vfloat32mf2_t __riscv_vluxei16_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                          vuint16mf4_t rs2, size_t vl);
vfloat32m1_t __riscv_vluxei16_v_f32m1_m(vbool32_t vm, const float *rs1,
                                        vuint16mf2_t rs2, size_t vl);
vfloat32m2_t __riscv_vluxei16_v_f32m2_m(vbool16_t vm, const float *rs1,
                                        vuint16m1_t rs2, size_t vl);
vfloat32m4_t __riscv_vluxei16_v_f32m4_m(vbool8_t vm, const float *rs1,
                                        vuint16m2_t rs2, size_t vl);
vfloat32m8_t __riscv_vluxei16_v_f32m8_m(vbool4_t vm, const float *rs1,
                                        vuint16m4_t rs2, size_t vl);
vfloat32mf2_t __riscv_vluxei32_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                          vuint32mf2_t rs2, size_t vl);
vfloat32m1_t __riscv_vluxei32_v_f32m1_m(vbool32_t vm, const float *rs1,
                                        vuint32m1_t rs2, size_t vl);
vfloat32m2_t __riscv_vluxei32_v_f32m2_m(vbool16_t vm, const float *rs1,
                                        vuint32m2_t rs2, size_t vl);
vfloat32m4_t __riscv_vluxei32_v_f32m4_m(vbool8_t vm, const float *rs1,
                                        vuint32m4_t rs2, size_t vl);
vfloat32m8_t __riscv_vluxei32_v_f32m8_m(vbool4_t vm, const float *rs1,
                                        vuint32m8_t rs2, size_t vl);
vfloat32mf2_t __riscv_vluxei64_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                          vuint64m1_t rs2, size_t vl);
vfloat32m1_t __riscv_vluxei64_v_f32m1_m(vbool32_t vm, const float *rs1,
                                        vuint64m2_t rs2, size_t vl);
vfloat32m2_t __riscv_vluxei64_v_f32m2_m(vbool16_t vm, const float *rs1,
                                        vuint64m4_t rs2, size_t vl);
vfloat32m4_t __riscv_vluxei64_v_f32m4_m(vbool8_t vm, const float *rs1,
                                        vuint64m8_t rs2, size_t vl);
vfloat64m1_t __riscv_vluxei8_v_f64m1_m(vbool64_t vm, const double *rs1,
                                       vuint8mf8_t rs2, size_t vl);
vfloat64m2_t __riscv_vluxei8_v_f64m2_m(vbool32_t vm, const double *rs1,
                                       vuint8mf4_t rs2, size_t vl);
vfloat64m4_t __riscv_vluxei8_v_f64m4_m(vbool16_t vm, const double *rs1,
                                       vuint8mf2_t rs2, size_t vl);
vfloat64m8_t __riscv_vluxei8_v_f64m8_m(vbool8_t vm, const double *rs1,
                                       vuint8m1_t rs2, size_t vl);
vfloat64m1_t __riscv_vluxei16_v_f64m1_m(vbool64_t vm, const double *rs1,
                                        vuint16mf4_t rs2, size_t vl);
vfloat64m2_t __riscv_vluxei16_v_f64m2_m(vbool32_t vm, const double *rs1,
                                        vuint16mf2_t rs2, size_t vl);
vfloat64m4_t __riscv_vluxei16_v_f64m4_m(vbool16_t vm, const double *rs1,
                                        vuint16m1_t rs2, size_t vl);
vfloat64m8_t __riscv_vluxei16_v_f64m8_m(vbool8_t vm, const double *rs1,
                                        vuint16m2_t rs2, size_t vl);
vfloat64m1_t __riscv_vluxei32_v_f64m1_m(vbool64_t vm, const double *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat64m2_t __riscv_vluxei32_v_f64m2_m(vbool32_t vm, const double *rs1,
                                        vuint32m1_t rs2, size_t vl);
vfloat64m4_t __riscv_vluxei32_v_f64m4_m(vbool16_t vm, const double *rs1,
                                        vuint32m2_t rs2, size_t vl);
vfloat64m8_t __riscv_vluxei32_v_f64m8_m(vbool8_t vm, const double *rs1,
                                        vuint32m4_t rs2, size_t vl);
vfloat64m1_t __riscv_vluxei64_v_f64m1_m(vbool64_t vm, const double *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat64m2_t __riscv_vluxei64_v_f64m2_m(vbool32_t vm, const double *rs1,
                                        vuint64m2_t rs2, size_t vl);
vfloat64m4_t __riscv_vluxei64_v_f64m4_m(vbool16_t vm, const double *rs1,
                                        vuint64m4_t rs2, size_t vl);
vfloat64m8_t __riscv_vluxei64_v_f64m8_m(vbool8_t vm, const double *rs1,
                                        vuint64m8_t rs2, size_t vl);
vint8mf8_t __riscv_vloxei8_v_i8mf8_m(vbool64_t vm, const int8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint8mf4_t __riscv_vloxei8_v_i8mf4_m(vbool32_t vm, const int8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint8mf2_t __riscv_vloxei8_v_i8mf2_m(vbool16_t vm, const int8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vint8m1_t __riscv_vloxei8_v_i8m1_m(vbool8_t vm, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m2_t __riscv_vloxei8_v_i8m2_m(vbool4_t vm, const int8_t *rs1,
                                   vuint8m2_t rs2, size_t vl);
vint8m4_t __riscv_vloxei8_v_i8m4_m(vbool2_t vm, const int8_t *rs1,
                                   vuint8m4_t rs2, size_t vl);
vint8m8_t __riscv_vloxei8_v_i8m8_m(vbool1_t vm, const int8_t *rs1,
                                   vuint8m8_t rs2, size_t vl);
vint8mf8_t __riscv_vloxei16_v_i8mf8_m(vbool64_t vm, const int8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint8mf4_t __riscv_vloxei16_v_i8mf4_m(vbool32_t vm, const int8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint8mf2_t __riscv_vloxei16_v_i8mf2_m(vbool16_t vm, const int8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vint8m1_t __riscv_vloxei16_v_i8m1_m(vbool8_t vm, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m2_t __riscv_vloxei16_v_i8m2_m(vbool4_t vm, const int8_t *rs1,
                                    vuint16m4_t rs2, size_t vl);
vint8m4_t __riscv_vloxei16_v_i8m4_m(vbool2_t vm, const int8_t *rs1,
                                    vuint16m8_t rs2, size_t vl);
vint8mf8_t __riscv_vloxei32_v_i8mf8_m(vbool64_t vm, const int8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint8mf4_t __riscv_vloxei32_v_i8mf4_m(vbool32_t vm, const int8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint8mf2_t __riscv_vloxei32_v_i8mf2_m(vbool16_t vm, const int8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vint8m1_t __riscv_vloxei32_v_i8m1_m(vbool8_t vm, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m2_t __riscv_vloxei32_v_i8m2_m(vbool4_t vm, const int8_t *rs1,
                                    vuint32m8_t rs2, size_t vl);
vint8mf8_t __riscv_vloxei64_v_i8mf8_m(vbool64_t vm, const int8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint8mf4_t __riscv_vloxei64_v_i8mf4_m(vbool32_t vm, const int8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint8mf2_t __riscv_vloxei64_v_i8mf2_m(vbool16_t vm, const int8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vint8m1_t __riscv_vloxei64_v_i8m1_m(vbool8_t vm, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint16mf4_t __riscv_vloxei8_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                       vuint8mf8_t rs2, size_t vl);
vint16mf2_t __riscv_vloxei8_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                       vuint8mf4_t rs2, size_t vl);
vint16m1_t __riscv_vloxei8_v_i16m1_m(vbool16_t vm, const int16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vint16m2_t __riscv_vloxei8_v_i16m2_m(vbool8_t vm, const int16_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vint16m4_t __riscv_vloxei8_v_i16m4_m(vbool4_t vm, const int16_t *rs1,
                                     vuint8m2_t rs2, size_t vl);
vint16m8_t __riscv_vloxei8_v_i16m8_m(vbool2_t vm, const int16_t *rs1,
                                     vuint8m4_t rs2, size_t vl);
vint16mf4_t __riscv_vloxei16_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                        vuint16mf4_t rs2, size_t vl);
vint16mf2_t __riscv_vloxei16_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                        vuint16mf2_t rs2, size_t vl);
vint16m1_t __riscv_vloxei16_v_i16m1_m(vbool16_t vm, const int16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vint16m2_t __riscv_vloxei16_v_i16m2_m(vbool8_t vm, const int16_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vint16m4_t __riscv_vloxei16_v_i16m4_m(vbool4_t vm, const int16_t *rs1,
                                      vuint16m4_t rs2, size_t vl);
vint16m8_t __riscv_vloxei16_v_i16m8_m(vbool2_t vm, const int16_t *rs1,
                                      vuint16m8_t rs2, size_t vl);
vint16mf4_t __riscv_vloxei32_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vint16mf2_t __riscv_vloxei32_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                        vuint32m1_t rs2, size_t vl);
vint16m1_t __riscv_vloxei32_v_i16m1_m(vbool16_t vm, const int16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vint16m2_t __riscv_vloxei32_v_i16m2_m(vbool8_t vm, const int16_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vint16m4_t __riscv_vloxei32_v_i16m4_m(vbool4_t vm, const int16_t *rs1,
                                      vuint32m8_t rs2, size_t vl);
vint16mf4_t __riscv_vloxei64_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                        vuint64m1_t rs2, size_t vl);
vint16mf2_t __riscv_vloxei64_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                        vuint64m2_t rs2, size_t vl);
vint16m1_t __riscv_vloxei64_v_i16m1_m(vbool16_t vm, const int16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vint16m2_t __riscv_vloxei64_v_i16m2_m(vbool8_t vm, const int16_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vint32mf2_t __riscv_vloxei8_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                       vuint8mf8_t rs2, size_t vl);
vint32m1_t __riscv_vloxei8_v_i32m1_m(vbool32_t vm, const int32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint32m2_t __riscv_vloxei8_v_i32m2_m(vbool16_t vm, const int32_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vint32m4_t __riscv_vloxei8_v_i32m4_m(vbool8_t vm, const int32_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vint32m8_t __riscv_vloxei8_v_i32m8_m(vbool4_t vm, const int32_t *rs1,
                                     vuint8m2_t rs2, size_t vl);
vint32mf2_t __riscv_vloxei16_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                        vuint16mf4_t rs2, size_t vl);
vint32m1_t __riscv_vloxei16_v_i32m1_m(vbool32_t vm, const int32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint32m2_t __riscv_vloxei16_v_i32m2_m(vbool16_t vm, const int32_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vint32m4_t __riscv_vloxei16_v_i32m4_m(vbool8_t vm, const int32_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vint32m8_t __riscv_vloxei16_v_i32m8_m(vbool4_t vm, const int32_t *rs1,
                                      vuint16m4_t rs2, size_t vl);
vint32mf2_t __riscv_vloxei32_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vint32m1_t __riscv_vloxei32_v_i32m1_m(vbool32_t vm, const int32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint32m2_t __riscv_vloxei32_v_i32m2_m(vbool16_t vm, const int32_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vint32m4_t __riscv_vloxei32_v_i32m4_m(vbool8_t vm, const int32_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vint32m8_t __riscv_vloxei32_v_i32m8_m(vbool4_t vm, const int32_t *rs1,
                                      vuint32m8_t rs2, size_t vl);
vint32mf2_t __riscv_vloxei64_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                        vuint64m1_t rs2, size_t vl);
vint32m1_t __riscv_vloxei64_v_i32m1_m(vbool32_t vm, const int32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint32m2_t __riscv_vloxei64_v_i32m2_m(vbool16_t vm, const int32_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vint32m4_t __riscv_vloxei64_v_i32m4_m(vbool8_t vm, const int32_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vint64m1_t __riscv_vloxei8_v_i64m1_m(vbool64_t vm, const int64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint64m2_t __riscv_vloxei8_v_i64m2_m(vbool32_t vm, const int64_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint64m4_t __riscv_vloxei8_v_i64m4_m(vbool16_t vm, const int64_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vint64m8_t __riscv_vloxei8_v_i64m8_m(vbool8_t vm, const int64_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vint64m1_t __riscv_vloxei16_v_i64m1_m(vbool64_t vm, const int64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint64m2_t __riscv_vloxei16_v_i64m2_m(vbool32_t vm, const int64_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint64m4_t __riscv_vloxei16_v_i64m4_m(vbool16_t vm, const int64_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vint64m8_t __riscv_vloxei16_v_i64m8_m(vbool8_t vm, const int64_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vint64m1_t __riscv_vloxei32_v_i64m1_m(vbool64_t vm, const int64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint64m2_t __riscv_vloxei32_v_i64m2_m(vbool32_t vm, const int64_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint64m4_t __riscv_vloxei32_v_i64m4_m(vbool16_t vm, const int64_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vint64m8_t __riscv_vloxei32_v_i64m8_m(vbool8_t vm, const int64_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vint64m1_t __riscv_vloxei64_v_i64m1_m(vbool64_t vm, const int64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint64m2_t __riscv_vloxei64_v_i64m2_m(vbool32_t vm, const int64_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint64m4_t __riscv_vloxei64_v_i64m4_m(vbool16_t vm, const int64_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vint64m8_t __riscv_vloxei64_v_i64m8_m(vbool8_t vm, const int64_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vint8mf8_t __riscv_vluxei8_v_i8mf8_m(vbool64_t vm, const int8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint8mf4_t __riscv_vluxei8_v_i8mf4_m(vbool32_t vm, const int8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint8mf2_t __riscv_vluxei8_v_i8mf2_m(vbool16_t vm, const int8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vint8m1_t __riscv_vluxei8_v_i8m1_m(vbool8_t vm, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m2_t __riscv_vluxei8_v_i8m2_m(vbool4_t vm, const int8_t *rs1,
                                   vuint8m2_t rs2, size_t vl);
vint8m4_t __riscv_vluxei8_v_i8m4_m(vbool2_t vm, const int8_t *rs1,
                                   vuint8m4_t rs2, size_t vl);
vint8m8_t __riscv_vluxei8_v_i8m8_m(vbool1_t vm, const int8_t *rs1,
                                   vuint8m8_t rs2, size_t vl);
vint8mf8_t __riscv_vluxei16_v_i8mf8_m(vbool64_t vm, const int8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint8mf4_t __riscv_vluxei16_v_i8mf4_m(vbool32_t vm, const int8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint8mf2_t __riscv_vluxei16_v_i8mf2_m(vbool16_t vm, const int8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vint8m1_t __riscv_vluxei16_v_i8m1_m(vbool8_t vm, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m2_t __riscv_vluxei16_v_i8m2_m(vbool4_t vm, const int8_t *rs1,
                                    vuint16m4_t rs2, size_t vl);
vint8m4_t __riscv_vluxei16_v_i8m4_m(vbool2_t vm, const int8_t *rs1,
                                    vuint16m8_t rs2, size_t vl);
vint8mf8_t __riscv_vluxei32_v_i8mf8_m(vbool64_t vm, const int8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint8mf4_t __riscv_vluxei32_v_i8mf4_m(vbool32_t vm, const int8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint8mf2_t __riscv_vluxei32_v_i8mf2_m(vbool16_t vm, const int8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vint8m1_t __riscv_vluxei32_v_i8m1_m(vbool8_t vm, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m2_t __riscv_vluxei32_v_i8m2_m(vbool4_t vm, const int8_t *rs1,
                                    vuint32m8_t rs2, size_t vl);
vint8mf8_t __riscv_vluxei64_v_i8mf8_m(vbool64_t vm, const int8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint8mf4_t __riscv_vluxei64_v_i8mf4_m(vbool32_t vm, const int8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint8mf2_t __riscv_vluxei64_v_i8mf2_m(vbool16_t vm, const int8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vint8m1_t __riscv_vluxei64_v_i8m1_m(vbool8_t vm, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint16mf4_t __riscv_vluxei8_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                       vuint8mf8_t rs2, size_t vl);
vint16mf2_t __riscv_vluxei8_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                       vuint8mf4_t rs2, size_t vl);
vint16m1_t __riscv_vluxei8_v_i16m1_m(vbool16_t vm, const int16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vint16m2_t __riscv_vluxei8_v_i16m2_m(vbool8_t vm, const int16_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vint16m4_t __riscv_vluxei8_v_i16m4_m(vbool4_t vm, const int16_t *rs1,
                                     vuint8m2_t rs2, size_t vl);
vint16m8_t __riscv_vluxei8_v_i16m8_m(vbool2_t vm, const int16_t *rs1,
                                     vuint8m4_t rs2, size_t vl);
vint16mf4_t __riscv_vluxei16_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                        vuint16mf4_t rs2, size_t vl);
vint16mf2_t __riscv_vluxei16_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                        vuint16mf2_t rs2, size_t vl);
vint16m1_t __riscv_vluxei16_v_i16m1_m(vbool16_t vm, const int16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vint16m2_t __riscv_vluxei16_v_i16m2_m(vbool8_t vm, const int16_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vint16m4_t __riscv_vluxei16_v_i16m4_m(vbool4_t vm, const int16_t *rs1,
                                      vuint16m4_t rs2, size_t vl);
vint16m8_t __riscv_vluxei16_v_i16m8_m(vbool2_t vm, const int16_t *rs1,
                                      vuint16m8_t rs2, size_t vl);
vint16mf4_t __riscv_vluxei32_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vint16mf2_t __riscv_vluxei32_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                        vuint32m1_t rs2, size_t vl);
vint16m1_t __riscv_vluxei32_v_i16m1_m(vbool16_t vm, const int16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vint16m2_t __riscv_vluxei32_v_i16m2_m(vbool8_t vm, const int16_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vint16m4_t __riscv_vluxei32_v_i16m4_m(vbool4_t vm, const int16_t *rs1,
                                      vuint32m8_t rs2, size_t vl);
vint16mf4_t __riscv_vluxei64_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                        vuint64m1_t rs2, size_t vl);
vint16mf2_t __riscv_vluxei64_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                        vuint64m2_t rs2, size_t vl);
vint16m1_t __riscv_vluxei64_v_i16m1_m(vbool16_t vm, const int16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vint16m2_t __riscv_vluxei64_v_i16m2_m(vbool8_t vm, const int16_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vint32mf2_t __riscv_vluxei8_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                       vuint8mf8_t rs2, size_t vl);
vint32m1_t __riscv_vluxei8_v_i32m1_m(vbool32_t vm, const int32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint32m2_t __riscv_vluxei8_v_i32m2_m(vbool16_t vm, const int32_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vint32m4_t __riscv_vluxei8_v_i32m4_m(vbool8_t vm, const int32_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vint32m8_t __riscv_vluxei8_v_i32m8_m(vbool4_t vm, const int32_t *rs1,
                                     vuint8m2_t rs2, size_t vl);
vint32mf2_t __riscv_vluxei16_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                        vuint16mf4_t rs2, size_t vl);
vint32m1_t __riscv_vluxei16_v_i32m1_m(vbool32_t vm, const int32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint32m2_t __riscv_vluxei16_v_i32m2_m(vbool16_t vm, const int32_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vint32m4_t __riscv_vluxei16_v_i32m4_m(vbool8_t vm, const int32_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vint32m8_t __riscv_vluxei16_v_i32m8_m(vbool4_t vm, const int32_t *rs1,
                                      vuint16m4_t rs2, size_t vl);
vint32mf2_t __riscv_vluxei32_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vint32m1_t __riscv_vluxei32_v_i32m1_m(vbool32_t vm, const int32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint32m2_t __riscv_vluxei32_v_i32m2_m(vbool16_t vm, const int32_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vint32m4_t __riscv_vluxei32_v_i32m4_m(vbool8_t vm, const int32_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vint32m8_t __riscv_vluxei32_v_i32m8_m(vbool4_t vm, const int32_t *rs1,
                                      vuint32m8_t rs2, size_t vl);
vint32mf2_t __riscv_vluxei64_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                        vuint64m1_t rs2, size_t vl);
vint32m1_t __riscv_vluxei64_v_i32m1_m(vbool32_t vm, const int32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint32m2_t __riscv_vluxei64_v_i32m2_m(vbool16_t vm, const int32_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vint32m4_t __riscv_vluxei64_v_i32m4_m(vbool8_t vm, const int32_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vint64m1_t __riscv_vluxei8_v_i64m1_m(vbool64_t vm, const int64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint64m2_t __riscv_vluxei8_v_i64m2_m(vbool32_t vm, const int64_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint64m4_t __riscv_vluxei8_v_i64m4_m(vbool16_t vm, const int64_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vint64m8_t __riscv_vluxei8_v_i64m8_m(vbool8_t vm, const int64_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vint64m1_t __riscv_vluxei16_v_i64m1_m(vbool64_t vm, const int64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint64m2_t __riscv_vluxei16_v_i64m2_m(vbool32_t vm, const int64_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint64m4_t __riscv_vluxei16_v_i64m4_m(vbool16_t vm, const int64_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vint64m8_t __riscv_vluxei16_v_i64m8_m(vbool8_t vm, const int64_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vint64m1_t __riscv_vluxei32_v_i64m1_m(vbool64_t vm, const int64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint64m2_t __riscv_vluxei32_v_i64m2_m(vbool32_t vm, const int64_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint64m4_t __riscv_vluxei32_v_i64m4_m(vbool16_t vm, const int64_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vint64m8_t __riscv_vluxei32_v_i64m8_m(vbool8_t vm, const int64_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vint64m1_t __riscv_vluxei64_v_i64m1_m(vbool64_t vm, const int64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint64m2_t __riscv_vluxei64_v_i64m2_m(vbool32_t vm, const int64_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint64m4_t __riscv_vluxei64_v_i64m4_m(vbool16_t vm, const int64_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vint64m8_t __riscv_vluxei64_v_i64m8_m(vbool8_t vm, const int64_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vuint8mf8_t __riscv_vloxei8_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint8mf4_t __riscv_vloxei8_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint8mf2_t __riscv_vloxei8_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1,
                                      vuint8mf2_t rs2, size_t vl);
vuint8m1_t __riscv_vloxei8_v_u8m1_m(vbool8_t vm, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m2_t __riscv_vloxei8_v_u8m2_m(vbool4_t vm, const uint8_t *rs1,
                                    vuint8m2_t rs2, size_t vl);
vuint8m4_t __riscv_vloxei8_v_u8m4_m(vbool2_t vm, const uint8_t *rs1,
                                    vuint8m4_t rs2, size_t vl);
vuint8m8_t __riscv_vloxei8_v_u8m8_m(vbool1_t vm, const uint8_t *rs1,
                                    vuint8m8_t rs2, size_t vl);
vuint8mf8_t __riscv_vloxei16_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint8mf4_t __riscv_vloxei16_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint8mf2_t __riscv_vloxei16_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1,
                                       vuint16m1_t rs2, size_t vl);
vuint8m1_t __riscv_vloxei16_v_u8m1_m(vbool8_t vm, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m2_t __riscv_vloxei16_v_u8m2_m(vbool4_t vm, const uint8_t *rs1,
                                     vuint16m4_t rs2, size_t vl);
vuint8m4_t __riscv_vloxei16_v_u8m4_m(vbool2_t vm, const uint8_t *rs1,
                                     vuint16m8_t rs2, size_t vl);
vuint8mf8_t __riscv_vloxei32_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint8mf4_t __riscv_vloxei32_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint8mf2_t __riscv_vloxei32_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1,
                                       vuint32m2_t rs2, size_t vl);
vuint8m1_t __riscv_vloxei32_v_u8m1_m(vbool8_t vm, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m2_t __riscv_vloxei32_v_u8m2_m(vbool4_t vm, const uint8_t *rs1,
                                     vuint32m8_t rs2, size_t vl);
vuint8mf8_t __riscv_vloxei64_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint8mf4_t __riscv_vloxei64_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint8mf2_t __riscv_vloxei64_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1,
                                       vuint64m4_t rs2, size_t vl);
vuint8m1_t __riscv_vloxei64_v_u8m1_m(vbool8_t vm, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint16mf4_t __riscv_vloxei8_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                        vuint8mf8_t rs2, size_t vl);
vuint16mf2_t __riscv_vloxei8_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                        vuint8mf4_t rs2, size_t vl);
vuint16m1_t __riscv_vloxei8_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                      vuint8mf2_t rs2, size_t vl);
vuint16m2_t __riscv_vloxei8_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                      vuint8m1_t rs2, size_t vl);
vuint16m4_t __riscv_vloxei8_v_u16m4_m(vbool4_t vm, const uint16_t *rs1,
                                      vuint8m2_t rs2, size_t vl);
vuint16m8_t __riscv_vloxei8_v_u16m8_m(vbool2_t vm, const uint16_t *rs1,
                                      vuint8m4_t rs2, size_t vl);
vuint16mf4_t __riscv_vloxei16_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                         vuint16mf4_t rs2, size_t vl);
vuint16mf2_t __riscv_vloxei16_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                         vuint16mf2_t rs2, size_t vl);
vuint16m1_t __riscv_vloxei16_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                       vuint16m1_t rs2, size_t vl);
vuint16m2_t __riscv_vloxei16_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                       vuint16m2_t rs2, size_t vl);
vuint16m4_t __riscv_vloxei16_v_u16m4_m(vbool4_t vm, const uint16_t *rs1,
                                       vuint16m4_t rs2, size_t vl);
vuint16m8_t __riscv_vloxei16_v_u16m8_m(vbool2_t vm, const uint16_t *rs1,
                                       vuint16m8_t rs2, size_t vl);
vuint16mf4_t __riscv_vloxei32_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                         vuint32mf2_t rs2, size_t vl);
vuint16mf2_t __riscv_vloxei32_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                         vuint32m1_t rs2, size_t vl);
vuint16m1_t __riscv_vloxei32_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                       vuint32m2_t rs2, size_t vl);
vuint16m2_t __riscv_vloxei32_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                       vuint32m4_t rs2, size_t vl);
vuint16m4_t __riscv_vloxei32_v_u16m4_m(vbool4_t vm, const uint16_t *rs1,
                                       vuint32m8_t rs2, size_t vl);
vuint16mf4_t __riscv_vloxei64_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                         vuint64m1_t rs2, size_t vl);
vuint16mf2_t __riscv_vloxei64_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                         vuint64m2_t rs2, size_t vl);
vuint16m1_t __riscv_vloxei64_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                       vuint64m4_t rs2, size_t vl);
vuint16m2_t __riscv_vloxei64_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                       vuint64m8_t rs2, size_t vl);
vuint32mf2_t __riscv_vloxei8_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                        vuint8mf8_t rs2, size_t vl);
vuint32m1_t __riscv_vloxei8_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint32m2_t __riscv_vloxei8_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                      vuint8mf2_t rs2, size_t vl);
vuint32m4_t __riscv_vloxei8_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                      vuint8m1_t rs2, size_t vl);
vuint32m8_t __riscv_vloxei8_v_u32m8_m(vbool4_t vm, const uint32_t *rs1,
                                      vuint8m2_t rs2, size_t vl);
vuint32mf2_t __riscv_vloxei16_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                         vuint16mf4_t rs2, size_t vl);
vuint32m1_t __riscv_vloxei16_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint32m2_t __riscv_vloxei16_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                       vuint16m1_t rs2, size_t vl);
vuint32m4_t __riscv_vloxei16_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                       vuint16m2_t rs2, size_t vl);
vuint32m8_t __riscv_vloxei16_v_u32m8_m(vbool4_t vm, const uint32_t *rs1,
                                       vuint16m4_t rs2, size_t vl);
vuint32mf2_t __riscv_vloxei32_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                         vuint32mf2_t rs2, size_t vl);
vuint32m1_t __riscv_vloxei32_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint32m2_t __riscv_vloxei32_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                       vuint32m2_t rs2, size_t vl);
vuint32m4_t __riscv_vloxei32_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                       vuint32m4_t rs2, size_t vl);
vuint32m8_t __riscv_vloxei32_v_u32m8_m(vbool4_t vm, const uint32_t *rs1,
                                       vuint32m8_t rs2, size_t vl);
vuint32mf2_t __riscv_vloxei64_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                         vuint64m1_t rs2, size_t vl);
vuint32m1_t __riscv_vloxei64_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint32m2_t __riscv_vloxei64_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                       vuint64m4_t rs2, size_t vl);
vuint32m4_t __riscv_vloxei64_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                       vuint64m8_t rs2, size_t vl);
vuint64m1_t __riscv_vloxei8_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint64m2_t __riscv_vloxei8_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint64m4_t __riscv_vloxei8_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                      vuint8mf2_t rs2, size_t vl);
vuint64m8_t __riscv_vloxei8_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                      vuint8m1_t rs2, size_t vl);
vuint64m1_t __riscv_vloxei16_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint64m2_t __riscv_vloxei16_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint64m4_t __riscv_vloxei16_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                       vuint16m1_t rs2, size_t vl);
vuint64m8_t __riscv_vloxei16_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                       vuint16m2_t rs2, size_t vl);
vuint64m1_t __riscv_vloxei32_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint64m2_t __riscv_vloxei32_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint64m4_t __riscv_vloxei32_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                       vuint32m2_t rs2, size_t vl);
vuint64m8_t __riscv_vloxei32_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                       vuint32m4_t rs2, size_t vl);
vuint64m1_t __riscv_vloxei64_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint64m2_t __riscv_vloxei64_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint64m4_t __riscv_vloxei64_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                       vuint64m4_t rs2, size_t vl);
vuint64m8_t __riscv_vloxei64_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                       vuint64m8_t rs2, size_t vl);
vuint8mf8_t __riscv_vluxei8_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint8mf4_t __riscv_vluxei8_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint8mf2_t __riscv_vluxei8_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1,
                                      vuint8mf2_t rs2, size_t vl);
vuint8m1_t __riscv_vluxei8_v_u8m1_m(vbool8_t vm, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m2_t __riscv_vluxei8_v_u8m2_m(vbool4_t vm, const uint8_t *rs1,
                                    vuint8m2_t rs2, size_t vl);
vuint8m4_t __riscv_vluxei8_v_u8m4_m(vbool2_t vm, const uint8_t *rs1,
                                    vuint8m4_t rs2, size_t vl);
vuint8m8_t __riscv_vluxei8_v_u8m8_m(vbool1_t vm, const uint8_t *rs1,
                                    vuint8m8_t rs2, size_t vl);
vuint8mf8_t __riscv_vluxei16_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint8mf4_t __riscv_vluxei16_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint8mf2_t __riscv_vluxei16_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1,
                                       vuint16m1_t rs2, size_t vl);
vuint8m1_t __riscv_vluxei16_v_u8m1_m(vbool8_t vm, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m2_t __riscv_vluxei16_v_u8m2_m(vbool4_t vm, const uint8_t *rs1,
                                     vuint16m4_t rs2, size_t vl);
vuint8m4_t __riscv_vluxei16_v_u8m4_m(vbool2_t vm, const uint8_t *rs1,
                                     vuint16m8_t rs2, size_t vl);
vuint8mf8_t __riscv_vluxei32_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint8mf4_t __riscv_vluxei32_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint8mf2_t __riscv_vluxei32_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1,
                                       vuint32m2_t rs2, size_t vl);
vuint8m1_t __riscv_vluxei32_v_u8m1_m(vbool8_t vm, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m2_t __riscv_vluxei32_v_u8m2_m(vbool4_t vm, const uint8_t *rs1,
                                     vuint32m8_t rs2, size_t vl);
vuint8mf8_t __riscv_vluxei64_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint8mf4_t __riscv_vluxei64_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint8mf2_t __riscv_vluxei64_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1,
                                       vuint64m4_t rs2, size_t vl);
vuint8m1_t __riscv_vluxei64_v_u8m1_m(vbool8_t vm, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint16mf4_t __riscv_vluxei8_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                        vuint8mf8_t rs2, size_t vl);
vuint16mf2_t __riscv_vluxei8_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                        vuint8mf4_t rs2, size_t vl);
vuint16m1_t __riscv_vluxei8_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                      vuint8mf2_t rs2, size_t vl);
vuint16m2_t __riscv_vluxei8_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                      vuint8m1_t rs2, size_t vl);
vuint16m4_t __riscv_vluxei8_v_u16m4_m(vbool4_t vm, const uint16_t *rs1,
                                      vuint8m2_t rs2, size_t vl);
vuint16m8_t __riscv_vluxei8_v_u16m8_m(vbool2_t vm, const uint16_t *rs1,
                                      vuint8m4_t rs2, size_t vl);
vuint16mf4_t __riscv_vluxei16_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                         vuint16mf4_t rs2, size_t vl);
vuint16mf2_t __riscv_vluxei16_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                         vuint16mf2_t rs2, size_t vl);
vuint16m1_t __riscv_vluxei16_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                       vuint16m1_t rs2, size_t vl);
vuint16m2_t __riscv_vluxei16_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                       vuint16m2_t rs2, size_t vl);
vuint16m4_t __riscv_vluxei16_v_u16m4_m(vbool4_t vm, const uint16_t *rs1,
                                       vuint16m4_t rs2, size_t vl);
vuint16m8_t __riscv_vluxei16_v_u16m8_m(vbool2_t vm, const uint16_t *rs1,
                                       vuint16m8_t rs2, size_t vl);
vuint16mf4_t __riscv_vluxei32_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                         vuint32mf2_t rs2, size_t vl);
vuint16mf2_t __riscv_vluxei32_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                         vuint32m1_t rs2, size_t vl);
vuint16m1_t __riscv_vluxei32_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                       vuint32m2_t rs2, size_t vl);
vuint16m2_t __riscv_vluxei32_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                       vuint32m4_t rs2, size_t vl);
vuint16m4_t __riscv_vluxei32_v_u16m4_m(vbool4_t vm, const uint16_t *rs1,
                                       vuint32m8_t rs2, size_t vl);
vuint16mf4_t __riscv_vluxei64_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                         vuint64m1_t rs2, size_t vl);
vuint16mf2_t __riscv_vluxei64_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                         vuint64m2_t rs2, size_t vl);
vuint16m1_t __riscv_vluxei64_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                       vuint64m4_t rs2, size_t vl);
vuint16m2_t __riscv_vluxei64_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                       vuint64m8_t rs2, size_t vl);
vuint32mf2_t __riscv_vluxei8_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                        vuint8mf8_t rs2, size_t vl);
vuint32m1_t __riscv_vluxei8_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint32m2_t __riscv_vluxei8_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                      vuint8mf2_t rs2, size_t vl);
vuint32m4_t __riscv_vluxei8_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                      vuint8m1_t rs2, size_t vl);
vuint32m8_t __riscv_vluxei8_v_u32m8_m(vbool4_t vm, const uint32_t *rs1,
                                      vuint8m2_t rs2, size_t vl);
vuint32mf2_t __riscv_vluxei16_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                         vuint16mf4_t rs2, size_t vl);
vuint32m1_t __riscv_vluxei16_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint32m2_t __riscv_vluxei16_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                       vuint16m1_t rs2, size_t vl);
vuint32m4_t __riscv_vluxei16_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                       vuint16m2_t rs2, size_t vl);
vuint32m8_t __riscv_vluxei16_v_u32m8_m(vbool4_t vm, const uint32_t *rs1,
                                       vuint16m4_t rs2, size_t vl);
vuint32mf2_t __riscv_vluxei32_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                         vuint32mf2_t rs2, size_t vl);
vuint32m1_t __riscv_vluxei32_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint32m2_t __riscv_vluxei32_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                       vuint32m2_t rs2, size_t vl);
vuint32m4_t __riscv_vluxei32_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                       vuint32m4_t rs2, size_t vl);
vuint32m8_t __riscv_vluxei32_v_u32m8_m(vbool4_t vm, const uint32_t *rs1,
                                       vuint32m8_t rs2, size_t vl);
vuint32mf2_t __riscv_vluxei64_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                         vuint64m1_t rs2, size_t vl);
vuint32m1_t __riscv_vluxei64_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint32m2_t __riscv_vluxei64_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                       vuint64m4_t rs2, size_t vl);
vuint32m4_t __riscv_vluxei64_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                       vuint64m8_t rs2, size_t vl);
vuint64m1_t __riscv_vluxei8_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint64m2_t __riscv_vluxei8_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint64m4_t __riscv_vluxei8_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                      vuint8mf2_t rs2, size_t vl);
vuint64m8_t __riscv_vluxei8_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                      vuint8m1_t rs2, size_t vl);
vuint64m1_t __riscv_vluxei16_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint64m2_t __riscv_vluxei16_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint64m4_t __riscv_vluxei16_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                       vuint16m1_t rs2, size_t vl);
vuint64m8_t __riscv_vluxei16_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                       vuint16m2_t rs2, size_t vl);
vuint64m1_t __riscv_vluxei32_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint64m2_t __riscv_vluxei32_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint64m4_t __riscv_vluxei32_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                       vuint32m2_t rs2, size_t vl);
vuint64m8_t __riscv_vluxei32_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                       vuint32m4_t rs2, size_t vl);
vuint64m1_t __riscv_vluxei64_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint64m2_t __riscv_vluxei64_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint64m4_t __riscv_vluxei64_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                       vuint64m4_t rs2, size_t vl);
vuint64m8_t __riscv_vluxei64_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                       vuint64m8_t rs2, size_t vl);
----

[[vector-indexed-store]]
==== Vector Indexed Store Intrinsics

[,c]
----
void __riscv_vsoxei8_v_f16mf4(_Float16 *rs1, vuint8mf8_t rs2, vfloat16mf4_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_f16mf2(_Float16 *rs1, vuint8mf4_t rs2, vfloat16mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_f16m1(_Float16 *rs1, vuint8mf2_t rs2, vfloat16m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_f16m2(_Float16 *rs1, vuint8m1_t rs2, vfloat16m2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_f16m4(_Float16 *rs1, vuint8m2_t rs2, vfloat16m4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_f16m8(_Float16 *rs1, vuint8m4_t rs2, vfloat16m8_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_f16mf4(_Float16 *rs1, vuint16mf4_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16mf2(_Float16 *rs1, vuint16mf2_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m1(_Float16 *rs1, vuint16m1_t rs2, vfloat16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f16m2(_Float16 *rs1, vuint16m2_t rs2, vfloat16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f16m4(_Float16 *rs1, vuint16m4_t rs2, vfloat16m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f16m8(_Float16 *rs1, vuint16m8_t rs2, vfloat16m8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f16mf4(_Float16 *rs1, vuint32mf2_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei32_v_f16mf2(_Float16 *rs1, vuint32m1_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei32_v_f16m1(_Float16 *rs1, vuint32m2_t rs2, vfloat16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f16m2(_Float16 *rs1, vuint32m4_t rs2, vfloat16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f16m4(_Float16 *rs1, vuint32m8_t rs2, vfloat16m4_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_f16mf4(_Float16 *rs1, vuint64m1_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei64_v_f16mf2(_Float16 *rs1, vuint64m2_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei64_v_f16m1(_Float16 *rs1, vuint64m4_t rs2, vfloat16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_f16m2(_Float16 *rs1, vuint64m8_t rs2, vfloat16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_f32mf2(float *rs1, vuint8mf8_t rs2, vfloat32mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_f32m1(float *rs1, vuint8mf4_t rs2, vfloat32m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_f32m2(float *rs1, vuint8mf2_t rs2, vfloat32m2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_f32m4(float *rs1, vuint8m1_t rs2, vfloat32m4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_f32m8(float *rs1, vuint8m2_t rs2, vfloat32m8_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_f32mf2(float *rs1, vuint16mf4_t rs2, vfloat32mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei16_v_f32m1(float *rs1, vuint16mf2_t rs2, vfloat32m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f32m2(float *rs1, vuint16m1_t rs2, vfloat32m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f32m4(float *rs1, vuint16m2_t rs2, vfloat32m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f32m8(float *rs1, vuint16m4_t rs2, vfloat32m8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f32mf2(float *rs1, vuint32mf2_t rs2, vfloat32mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei32_v_f32m1(float *rs1, vuint32m1_t rs2, vfloat32m1_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f32m2(float *rs1, vuint32m2_t rs2, vfloat32m2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f32m4(float *rs1, vuint32m4_t rs2, vfloat32m4_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f32m8(float *rs1, vuint32m8_t rs2, vfloat32m8_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_f32mf2(float *rs1, vuint64m1_t rs2, vfloat32mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei64_v_f32m1(float *rs1, vuint64m2_t rs2, vfloat32m1_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_f32m2(float *rs1, vuint64m4_t rs2, vfloat32m2_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_f32m4(float *rs1, vuint64m8_t rs2, vfloat32m4_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_f64m1(double *rs1, vuint8mf8_t rs2, vfloat64m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_f64m2(double *rs1, vuint8mf4_t rs2, vfloat64m2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_f64m4(double *rs1, vuint8mf2_t rs2, vfloat64m4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_f64m8(double *rs1, vuint8m1_t rs2, vfloat64m8_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_f64m1(double *rs1, vuint16mf4_t rs2, vfloat64m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f64m2(double *rs1, vuint16mf2_t rs2, vfloat64m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f64m4(double *rs1, vuint16m1_t rs2, vfloat64m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f64m8(double *rs1, vuint16m2_t rs2, vfloat64m8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f64m1(double *rs1, vuint32mf2_t rs2, vfloat64m1_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f64m2(double *rs1, vuint32m1_t rs2, vfloat64m2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f64m4(double *rs1, vuint32m2_t rs2, vfloat64m4_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_f64m8(double *rs1, vuint32m4_t rs2, vfloat64m8_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_f64m1(double *rs1, vuint64m1_t rs2, vfloat64m1_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_f64m2(double *rs1, vuint64m2_t rs2, vfloat64m2_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_f64m4(double *rs1, vuint64m4_t rs2, vfloat64m4_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_f64m8(double *rs1, vuint64m8_t rs2, vfloat64m8_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_f16mf4(_Float16 *rs1, vuint8mf8_t rs2, vfloat16mf4_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_f16mf2(_Float16 *rs1, vuint8mf4_t rs2, vfloat16mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_f16m1(_Float16 *rs1, vuint8mf2_t rs2, vfloat16m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_f16m2(_Float16 *rs1, vuint8m1_t rs2, vfloat16m2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_f16m4(_Float16 *rs1, vuint8m2_t rs2, vfloat16m4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_f16m8(_Float16 *rs1, vuint8m4_t rs2, vfloat16m8_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_f16mf4(_Float16 *rs1, vuint16mf4_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16mf2(_Float16 *rs1, vuint16mf2_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m1(_Float16 *rs1, vuint16m1_t rs2, vfloat16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16m2(_Float16 *rs1, vuint16m2_t rs2, vfloat16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16m4(_Float16 *rs1, vuint16m4_t rs2, vfloat16m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16m8(_Float16 *rs1, vuint16m8_t rs2, vfloat16m8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f16mf4(_Float16 *rs1, vuint32mf2_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei32_v_f16mf2(_Float16 *rs1, vuint32m1_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei32_v_f16m1(_Float16 *rs1, vuint32m2_t rs2, vfloat16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f16m2(_Float16 *rs1, vuint32m4_t rs2, vfloat16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f16m4(_Float16 *rs1, vuint32m8_t rs2, vfloat16m4_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_f16mf4(_Float16 *rs1, vuint64m1_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei64_v_f16mf2(_Float16 *rs1, vuint64m2_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei64_v_f16m1(_Float16 *rs1, vuint64m4_t rs2, vfloat16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_f16m2(_Float16 *rs1, vuint64m8_t rs2, vfloat16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_f32mf2(float *rs1, vuint8mf8_t rs2, vfloat32mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_f32m1(float *rs1, vuint8mf4_t rs2, vfloat32m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_f32m2(float *rs1, vuint8mf2_t rs2, vfloat32m2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_f32m4(float *rs1, vuint8m1_t rs2, vfloat32m4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_f32m8(float *rs1, vuint8m2_t rs2, vfloat32m8_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_f32mf2(float *rs1, vuint16mf4_t rs2, vfloat32mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei16_v_f32m1(float *rs1, vuint16mf2_t rs2, vfloat32m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f32m2(float *rs1, vuint16m1_t rs2, vfloat32m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f32m4(float *rs1, vuint16m2_t rs2, vfloat32m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f32m8(float *rs1, vuint16m4_t rs2, vfloat32m8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f32mf2(float *rs1, vuint32mf2_t rs2, vfloat32mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei32_v_f32m1(float *rs1, vuint32m1_t rs2, vfloat32m1_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f32m2(float *rs1, vuint32m2_t rs2, vfloat32m2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f32m4(float *rs1, vuint32m4_t rs2, vfloat32m4_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f32m8(float *rs1, vuint32m8_t rs2, vfloat32m8_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_f32mf2(float *rs1, vuint64m1_t rs2, vfloat32mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei64_v_f32m1(float *rs1, vuint64m2_t rs2, vfloat32m1_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_f32m2(float *rs1, vuint64m4_t rs2, vfloat32m2_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_f32m4(float *rs1, vuint64m8_t rs2, vfloat32m4_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_f64m1(double *rs1, vuint8mf8_t rs2, vfloat64m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_f64m2(double *rs1, vuint8mf4_t rs2, vfloat64m2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_f64m4(double *rs1, vuint8mf2_t rs2, vfloat64m4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_f64m8(double *rs1, vuint8m1_t rs2, vfloat64m8_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_f64m1(double *rs1, vuint16mf4_t rs2, vfloat64m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f64m2(double *rs1, vuint16mf2_t rs2, vfloat64m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f64m4(double *rs1, vuint16m1_t rs2, vfloat64m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f64m8(double *rs1, vuint16m2_t rs2, vfloat64m8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f64m1(double *rs1, vuint32mf2_t rs2, vfloat64m1_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f64m2(double *rs1, vuint32m1_t rs2, vfloat64m2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f64m4(double *rs1, vuint32m2_t rs2, vfloat64m4_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_f64m8(double *rs1, vuint32m4_t rs2, vfloat64m8_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_f64m1(double *rs1, vuint64m1_t rs2, vfloat64m1_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_f64m2(double *rs1, vuint64m2_t rs2, vfloat64m2_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_f64m4(double *rs1, vuint64m4_t rs2, vfloat64m4_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_f64m8(double *rs1, vuint64m8_t rs2, vfloat64m8_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_i8mf8(int8_t *rs1, vuint8mf8_t rs2, vint8mf8_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i8mf4(int8_t *rs1, vuint8mf4_t rs2, vint8mf4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i8mf2(int8_t *rs1, vuint8mf2_t rs2, vint8mf2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i8m1(int8_t *rs1, vuint8m1_t rs2, vint8m1_t vs3,
                            size_t vl);
void __riscv_vsoxei8_v_i8m2(int8_t *rs1, vuint8m2_t rs2, vint8m2_t vs3,
                            size_t vl);
void __riscv_vsoxei8_v_i8m4(int8_t *rs1, vuint8m4_t rs2, vint8m4_t vs3,
                            size_t vl);
void __riscv_vsoxei8_v_i8m8(int8_t *rs1, vuint8m8_t rs2, vint8m8_t vs3,
                            size_t vl);
void __riscv_vsoxei16_v_i8mf8(int8_t *rs1, vuint16mf4_t rs2, vint8mf8_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i8mf4(int8_t *rs1, vuint16mf2_t rs2, vint8mf4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i8mf2(int8_t *rs1, vuint16m1_t rs2, vint8mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i8m1(int8_t *rs1, vuint16m2_t rs2, vint8m1_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_i8m2(int8_t *rs1, vuint16m4_t rs2, vint8m2_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_i8m4(int8_t *rs1, vuint16m8_t rs2, vint8m4_t vs3,
                             size_t vl);
void __riscv_vsoxei32_v_i8mf8(int8_t *rs1, vuint32mf2_t rs2, vint8mf8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i8mf4(int8_t *rs1, vuint32m1_t rs2, vint8mf4_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i8mf2(int8_t *rs1, vuint32m2_t rs2, vint8mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i8m1(int8_t *rs1, vuint32m4_t rs2, vint8m1_t vs3,
                             size_t vl);
void __riscv_vsoxei32_v_i8m2(int8_t *rs1, vuint32m8_t rs2, vint8m2_t vs3,
                             size_t vl);
void __riscv_vsoxei64_v_i8mf8(int8_t *rs1, vuint64m1_t rs2, vint8mf8_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i8mf4(int8_t *rs1, vuint64m2_t rs2, vint8mf4_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i8mf2(int8_t *rs1, vuint64m4_t rs2, vint8mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i8m1(int8_t *rs1, vuint64m8_t rs2, vint8m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i16mf4(int16_t *rs1, vuint8mf8_t rs2, vint16mf4_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_i16mf2(int16_t *rs1, vuint8mf4_t rs2, vint16mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_i16m1(int16_t *rs1, vuint8mf2_t rs2, vint16m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i16m2(int16_t *rs1, vuint8m1_t rs2, vint16m2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i16m4(int16_t *rs1, vuint8m2_t rs2, vint16m4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i16m8(int16_t *rs1, vuint8m4_t rs2, vint16m8_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_i16mf4(int16_t *rs1, vuint16mf4_t rs2, vint16mf4_t vs3,
                               size_t vl);
void __riscv_vsoxei16_v_i16mf2(int16_t *rs1, vuint16mf2_t rs2, vint16mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei16_v_i16m1(int16_t *rs1, vuint16m1_t rs2, vint16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i16m2(int16_t *rs1, vuint16m2_t rs2, vint16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i16m4(int16_t *rs1, vuint16m4_t rs2, vint16m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i16m8(int16_t *rs1, vuint16m8_t rs2, vint16m8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i16mf4(int16_t *rs1, vuint32mf2_t rs2, vint16mf4_t vs3,
                               size_t vl);
void __riscv_vsoxei32_v_i16mf2(int16_t *rs1, vuint32m1_t rs2, vint16mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei32_v_i16m1(int16_t *rs1, vuint32m2_t rs2, vint16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i16m2(int16_t *rs1, vuint32m4_t rs2, vint16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i16m4(int16_t *rs1, vuint32m8_t rs2, vint16m4_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i16mf4(int16_t *rs1, vuint64m1_t rs2, vint16mf4_t vs3,
                               size_t vl);
void __riscv_vsoxei64_v_i16mf2(int16_t *rs1, vuint64m2_t rs2, vint16mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei64_v_i16m1(int16_t *rs1, vuint64m4_t rs2, vint16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i16m2(int16_t *rs1, vuint64m8_t rs2, vint16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_i32mf2(int32_t *rs1, vuint8mf8_t rs2, vint32mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_i32m1(int32_t *rs1, vuint8mf4_t rs2, vint32m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i32m2(int32_t *rs1, vuint8mf2_t rs2, vint32m2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i32m4(int32_t *rs1, vuint8m1_t rs2, vint32m4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i32m8(int32_t *rs1, vuint8m2_t rs2, vint32m8_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_i32mf2(int32_t *rs1, vuint16mf4_t rs2, vint32mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei16_v_i32m1(int32_t *rs1, vuint16mf2_t rs2, vint32m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i32m2(int32_t *rs1, vuint16m1_t rs2, vint32m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i32m4(int32_t *rs1, vuint16m2_t rs2, vint32m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i32m8(int32_t *rs1, vuint16m4_t rs2, vint32m8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i32mf2(int32_t *rs1, vuint32mf2_t rs2, vint32mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei32_v_i32m1(int32_t *rs1, vuint32m1_t rs2, vint32m1_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i32m2(int32_t *rs1, vuint32m2_t rs2, vint32m2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i32m4(int32_t *rs1, vuint32m4_t rs2, vint32m4_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i32m8(int32_t *rs1, vuint32m8_t rs2, vint32m8_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i32mf2(int32_t *rs1, vuint64m1_t rs2, vint32mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei64_v_i32m1(int32_t *rs1, vuint64m2_t rs2, vint32m1_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i32m2(int32_t *rs1, vuint64m4_t rs2, vint32m2_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i32m4(int32_t *rs1, vuint64m8_t rs2, vint32m4_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_i64m1(int64_t *rs1, vuint8mf8_t rs2, vint64m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i64m2(int64_t *rs1, vuint8mf4_t rs2, vint64m2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i64m4(int64_t *rs1, vuint8mf2_t rs2, vint64m4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_i64m8(int64_t *rs1, vuint8m1_t rs2, vint64m8_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_i64m1(int64_t *rs1, vuint16mf4_t rs2, vint64m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i64m2(int64_t *rs1, vuint16mf2_t rs2, vint64m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i64m4(int64_t *rs1, vuint16m1_t rs2, vint64m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_i64m8(int64_t *rs1, vuint16m2_t rs2, vint64m8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i64m1(int64_t *rs1, vuint32mf2_t rs2, vint64m1_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i64m2(int64_t *rs1, vuint32m1_t rs2, vint64m2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i64m4(int64_t *rs1, vuint32m2_t rs2, vint64m4_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_i64m8(int64_t *rs1, vuint32m4_t rs2, vint64m8_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i64m1(int64_t *rs1, vuint64m1_t rs2, vint64m1_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i64m2(int64_t *rs1, vuint64m2_t rs2, vint64m2_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i64m4(int64_t *rs1, vuint64m4_t rs2, vint64m4_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_i64m8(int64_t *rs1, vuint64m8_t rs2, vint64m8_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_i8mf8(int8_t *rs1, vuint8mf8_t rs2, vint8mf8_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i8mf4(int8_t *rs1, vuint8mf4_t rs2, vint8mf4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i8mf2(int8_t *rs1, vuint8mf2_t rs2, vint8mf2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i8m1(int8_t *rs1, vuint8m1_t rs2, vint8m1_t vs3,
                            size_t vl);
void __riscv_vsuxei8_v_i8m2(int8_t *rs1, vuint8m2_t rs2, vint8m2_t vs3,
                            size_t vl);
void __riscv_vsuxei8_v_i8m4(int8_t *rs1, vuint8m4_t rs2, vint8m4_t vs3,
                            size_t vl);
void __riscv_vsuxei8_v_i8m8(int8_t *rs1, vuint8m8_t rs2, vint8m8_t vs3,
                            size_t vl);
void __riscv_vsuxei16_v_i8mf8(int8_t *rs1, vuint16mf4_t rs2, vint8mf8_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i8mf4(int8_t *rs1, vuint16mf2_t rs2, vint8mf4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i8mf2(int8_t *rs1, vuint16m1_t rs2, vint8mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i8m1(int8_t *rs1, vuint16m2_t rs2, vint8m1_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_i8m2(int8_t *rs1, vuint16m4_t rs2, vint8m2_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_i8m4(int8_t *rs1, vuint16m8_t rs2, vint8m4_t vs3,
                             size_t vl);
void __riscv_vsuxei32_v_i8mf8(int8_t *rs1, vuint32mf2_t rs2, vint8mf8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i8mf4(int8_t *rs1, vuint32m1_t rs2, vint8mf4_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i8mf2(int8_t *rs1, vuint32m2_t rs2, vint8mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i8m1(int8_t *rs1, vuint32m4_t rs2, vint8m1_t vs3,
                             size_t vl);
void __riscv_vsuxei32_v_i8m2(int8_t *rs1, vuint32m8_t rs2, vint8m2_t vs3,
                             size_t vl);
void __riscv_vsuxei64_v_i8mf8(int8_t *rs1, vuint64m1_t rs2, vint8mf8_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i8mf4(int8_t *rs1, vuint64m2_t rs2, vint8mf4_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i8mf2(int8_t *rs1, vuint64m4_t rs2, vint8mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i8m1(int8_t *rs1, vuint64m8_t rs2, vint8m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i16mf4(int16_t *rs1, vuint8mf8_t rs2, vint16mf4_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_i16mf2(int16_t *rs1, vuint8mf4_t rs2, vint16mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_i16m1(int16_t *rs1, vuint8mf2_t rs2, vint16m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i16m2(int16_t *rs1, vuint8m1_t rs2, vint16m2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i16m4(int16_t *rs1, vuint8m2_t rs2, vint16m4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i16m8(int16_t *rs1, vuint8m4_t rs2, vint16m8_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_i16mf4(int16_t *rs1, vuint16mf4_t rs2, vint16mf4_t vs3,
                               size_t vl);
void __riscv_vsuxei16_v_i16mf2(int16_t *rs1, vuint16mf2_t rs2, vint16mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei16_v_i16m1(int16_t *rs1, vuint16m1_t rs2, vint16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i16m2(int16_t *rs1, vuint16m2_t rs2, vint16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i16m4(int16_t *rs1, vuint16m4_t rs2, vint16m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i16m8(int16_t *rs1, vuint16m8_t rs2, vint16m8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i16mf4(int16_t *rs1, vuint32mf2_t rs2, vint16mf4_t vs3,
                               size_t vl);
void __riscv_vsuxei32_v_i16mf2(int16_t *rs1, vuint32m1_t rs2, vint16mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei32_v_i16m1(int16_t *rs1, vuint32m2_t rs2, vint16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i16m2(int16_t *rs1, vuint32m4_t rs2, vint16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i16m4(int16_t *rs1, vuint32m8_t rs2, vint16m4_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i16mf4(int16_t *rs1, vuint64m1_t rs2, vint16mf4_t vs3,
                               size_t vl);
void __riscv_vsuxei64_v_i16mf2(int16_t *rs1, vuint64m2_t rs2, vint16mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei64_v_i16m1(int16_t *rs1, vuint64m4_t rs2, vint16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i16m2(int16_t *rs1, vuint64m8_t rs2, vint16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_i32mf2(int32_t *rs1, vuint8mf8_t rs2, vint32mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_i32m1(int32_t *rs1, vuint8mf4_t rs2, vint32m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i32m2(int32_t *rs1, vuint8mf2_t rs2, vint32m2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i32m4(int32_t *rs1, vuint8m1_t rs2, vint32m4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i32m8(int32_t *rs1, vuint8m2_t rs2, vint32m8_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_i32mf2(int32_t *rs1, vuint16mf4_t rs2, vint32mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei16_v_i32m1(int32_t *rs1, vuint16mf2_t rs2, vint32m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i32m2(int32_t *rs1, vuint16m1_t rs2, vint32m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i32m4(int32_t *rs1, vuint16m2_t rs2, vint32m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i32m8(int32_t *rs1, vuint16m4_t rs2, vint32m8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i32mf2(int32_t *rs1, vuint32mf2_t rs2, vint32mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei32_v_i32m1(int32_t *rs1, vuint32m1_t rs2, vint32m1_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i32m2(int32_t *rs1, vuint32m2_t rs2, vint32m2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i32m4(int32_t *rs1, vuint32m4_t rs2, vint32m4_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i32m8(int32_t *rs1, vuint32m8_t rs2, vint32m8_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i32mf2(int32_t *rs1, vuint64m1_t rs2, vint32mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei64_v_i32m1(int32_t *rs1, vuint64m2_t rs2, vint32m1_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i32m2(int32_t *rs1, vuint64m4_t rs2, vint32m2_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i32m4(int32_t *rs1, vuint64m8_t rs2, vint32m4_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_i64m1(int64_t *rs1, vuint8mf8_t rs2, vint64m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i64m2(int64_t *rs1, vuint8mf4_t rs2, vint64m2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i64m4(int64_t *rs1, vuint8mf2_t rs2, vint64m4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_i64m8(int64_t *rs1, vuint8m1_t rs2, vint64m8_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_i64m1(int64_t *rs1, vuint16mf4_t rs2, vint64m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i64m2(int64_t *rs1, vuint16mf2_t rs2, vint64m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i64m4(int64_t *rs1, vuint16m1_t rs2, vint64m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_i64m8(int64_t *rs1, vuint16m2_t rs2, vint64m8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i64m1(int64_t *rs1, vuint32mf2_t rs2, vint64m1_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i64m2(int64_t *rs1, vuint32m1_t rs2, vint64m2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i64m4(int64_t *rs1, vuint32m2_t rs2, vint64m4_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_i64m8(int64_t *rs1, vuint32m4_t rs2, vint64m8_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i64m1(int64_t *rs1, vuint64m1_t rs2, vint64m1_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i64m2(int64_t *rs1, vuint64m2_t rs2, vint64m2_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i64m4(int64_t *rs1, vuint64m4_t rs2, vint64m4_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_i64m8(int64_t *rs1, vuint64m8_t rs2, vint64m8_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_u8mf8(uint8_t *rs1, vuint8mf8_t rs2, vuint8mf8_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u8mf4(uint8_t *rs1, vuint8mf4_t rs2, vuint8mf4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u8mf2(uint8_t *rs1, vuint8mf2_t rs2, vuint8mf2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u8m1(uint8_t *rs1, vuint8m1_t rs2, vuint8m1_t vs3,
                            size_t vl);
void __riscv_vsoxei8_v_u8m2(uint8_t *rs1, vuint8m2_t rs2, vuint8m2_t vs3,
                            size_t vl);
void __riscv_vsoxei8_v_u8m4(uint8_t *rs1, vuint8m4_t rs2, vuint8m4_t vs3,
                            size_t vl);
void __riscv_vsoxei8_v_u8m8(uint8_t *rs1, vuint8m8_t rs2, vuint8m8_t vs3,
                            size_t vl);
void __riscv_vsoxei16_v_u8mf8(uint8_t *rs1, vuint16mf4_t rs2, vuint8mf8_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u8mf4(uint8_t *rs1, vuint16mf2_t rs2, vuint8mf4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u8mf2(uint8_t *rs1, vuint16m1_t rs2, vuint8mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u8m1(uint8_t *rs1, vuint16m2_t rs2, vuint8m1_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_u8m2(uint8_t *rs1, vuint16m4_t rs2, vuint8m2_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_u8m4(uint8_t *rs1, vuint16m8_t rs2, vuint8m4_t vs3,
                             size_t vl);
void __riscv_vsoxei32_v_u8mf8(uint8_t *rs1, vuint32mf2_t rs2, vuint8mf8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u8mf4(uint8_t *rs1, vuint32m1_t rs2, vuint8mf4_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u8mf2(uint8_t *rs1, vuint32m2_t rs2, vuint8mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u8m1(uint8_t *rs1, vuint32m4_t rs2, vuint8m1_t vs3,
                             size_t vl);
void __riscv_vsoxei32_v_u8m2(uint8_t *rs1, vuint32m8_t rs2, vuint8m2_t vs3,
                             size_t vl);
void __riscv_vsoxei64_v_u8mf8(uint8_t *rs1, vuint64m1_t rs2, vuint8mf8_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u8mf4(uint8_t *rs1, vuint64m2_t rs2, vuint8mf4_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u8mf2(uint8_t *rs1, vuint64m4_t rs2, vuint8mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u8m1(uint8_t *rs1, vuint64m8_t rs2, vuint8m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u16mf4(uint16_t *rs1, vuint8mf8_t rs2, vuint16mf4_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_u16mf2(uint16_t *rs1, vuint8mf4_t rs2, vuint16mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_u16m1(uint16_t *rs1, vuint8mf2_t rs2, vuint16m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u16m2(uint16_t *rs1, vuint8m1_t rs2, vuint16m2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u16m4(uint16_t *rs1, vuint8m2_t rs2, vuint16m4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u16m8(uint16_t *rs1, vuint8m4_t rs2, vuint16m8_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_u16mf4(uint16_t *rs1, vuint16mf4_t rs2,
                               vuint16mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_u16mf2(uint16_t *rs1, vuint16mf2_t rs2,
                               vuint16mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_u16m1(uint16_t *rs1, vuint16m1_t rs2, vuint16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u16m2(uint16_t *rs1, vuint16m2_t rs2, vuint16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u16m4(uint16_t *rs1, vuint16m4_t rs2, vuint16m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u16m8(uint16_t *rs1, vuint16m8_t rs2, vuint16m8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u16mf4(uint16_t *rs1, vuint32mf2_t rs2,
                               vuint16mf4_t vs3, size_t vl);
void __riscv_vsoxei32_v_u16mf2(uint16_t *rs1, vuint32m1_t rs2, vuint16mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei32_v_u16m1(uint16_t *rs1, vuint32m2_t rs2, vuint16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u16m2(uint16_t *rs1, vuint32m4_t rs2, vuint16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u16m4(uint16_t *rs1, vuint32m8_t rs2, vuint16m4_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u16mf4(uint16_t *rs1, vuint64m1_t rs2, vuint16mf4_t vs3,
                               size_t vl);
void __riscv_vsoxei64_v_u16mf2(uint16_t *rs1, vuint64m2_t rs2, vuint16mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei64_v_u16m1(uint16_t *rs1, vuint64m4_t rs2, vuint16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u16m2(uint16_t *rs1, vuint64m8_t rs2, vuint16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_u32mf2(uint32_t *rs1, vuint8mf8_t rs2, vuint32mf2_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_u32m1(uint32_t *rs1, vuint8mf4_t rs2, vuint32m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u32m2(uint32_t *rs1, vuint8mf2_t rs2, vuint32m2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u32m4(uint32_t *rs1, vuint8m1_t rs2, vuint32m4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u32m8(uint32_t *rs1, vuint8m2_t rs2, vuint32m8_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_u32mf2(uint32_t *rs1, vuint16mf4_t rs2,
                               vuint32mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_u32m1(uint32_t *rs1, vuint16mf2_t rs2, vuint32m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u32m2(uint32_t *rs1, vuint16m1_t rs2, vuint32m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u32m4(uint32_t *rs1, vuint16m2_t rs2, vuint32m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u32m8(uint32_t *rs1, vuint16m4_t rs2, vuint32m8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u32mf2(uint32_t *rs1, vuint32mf2_t rs2,
                               vuint32mf2_t vs3, size_t vl);
void __riscv_vsoxei32_v_u32m1(uint32_t *rs1, vuint32m1_t rs2, vuint32m1_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u32m2(uint32_t *rs1, vuint32m2_t rs2, vuint32m2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u32m4(uint32_t *rs1, vuint32m4_t rs2, vuint32m4_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u32m8(uint32_t *rs1, vuint32m8_t rs2, vuint32m8_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u32mf2(uint32_t *rs1, vuint64m1_t rs2, vuint32mf2_t vs3,
                               size_t vl);
void __riscv_vsoxei64_v_u32m1(uint32_t *rs1, vuint64m2_t rs2, vuint32m1_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u32m2(uint32_t *rs1, vuint64m4_t rs2, vuint32m2_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u32m4(uint32_t *rs1, vuint64m8_t rs2, vuint32m4_t vs3,
                              size_t vl);
void __riscv_vsoxei8_v_u64m1(uint64_t *rs1, vuint8mf8_t rs2, vuint64m1_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u64m2(uint64_t *rs1, vuint8mf4_t rs2, vuint64m2_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u64m4(uint64_t *rs1, vuint8mf2_t rs2, vuint64m4_t vs3,
                             size_t vl);
void __riscv_vsoxei8_v_u64m8(uint64_t *rs1, vuint8m1_t rs2, vuint64m8_t vs3,
                             size_t vl);
void __riscv_vsoxei16_v_u64m1(uint64_t *rs1, vuint16mf4_t rs2, vuint64m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u64m2(uint64_t *rs1, vuint16mf2_t rs2, vuint64m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u64m4(uint64_t *rs1, vuint16m1_t rs2, vuint64m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_u64m8(uint64_t *rs1, vuint16m2_t rs2, vuint64m8_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u64m1(uint64_t *rs1, vuint32mf2_t rs2, vuint64m1_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u64m2(uint64_t *rs1, vuint32m1_t rs2, vuint64m2_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u64m4(uint64_t *rs1, vuint32m2_t rs2, vuint64m4_t vs3,
                              size_t vl);
void __riscv_vsoxei32_v_u64m8(uint64_t *rs1, vuint32m4_t rs2, vuint64m8_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u64m1(uint64_t *rs1, vuint64m1_t rs2, vuint64m1_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u64m2(uint64_t *rs1, vuint64m2_t rs2, vuint64m2_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u64m4(uint64_t *rs1, vuint64m4_t rs2, vuint64m4_t vs3,
                              size_t vl);
void __riscv_vsoxei64_v_u64m8(uint64_t *rs1, vuint64m8_t rs2, vuint64m8_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_u8mf8(uint8_t *rs1, vuint8mf8_t rs2, vuint8mf8_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u8mf4(uint8_t *rs1, vuint8mf4_t rs2, vuint8mf4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u8mf2(uint8_t *rs1, vuint8mf2_t rs2, vuint8mf2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u8m1(uint8_t *rs1, vuint8m1_t rs2, vuint8m1_t vs3,
                            size_t vl);
void __riscv_vsuxei8_v_u8m2(uint8_t *rs1, vuint8m2_t rs2, vuint8m2_t vs3,
                            size_t vl);
void __riscv_vsuxei8_v_u8m4(uint8_t *rs1, vuint8m4_t rs2, vuint8m4_t vs3,
                            size_t vl);
void __riscv_vsuxei8_v_u8m8(uint8_t *rs1, vuint8m8_t rs2, vuint8m8_t vs3,
                            size_t vl);
void __riscv_vsuxei16_v_u8mf8(uint8_t *rs1, vuint16mf4_t rs2, vuint8mf8_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u8mf4(uint8_t *rs1, vuint16mf2_t rs2, vuint8mf4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u8mf2(uint8_t *rs1, vuint16m1_t rs2, vuint8mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u8m1(uint8_t *rs1, vuint16m2_t rs2, vuint8m1_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_u8m2(uint8_t *rs1, vuint16m4_t rs2, vuint8m2_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_u8m4(uint8_t *rs1, vuint16m8_t rs2, vuint8m4_t vs3,
                             size_t vl);
void __riscv_vsuxei32_v_u8mf8(uint8_t *rs1, vuint32mf2_t rs2, vuint8mf8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u8mf4(uint8_t *rs1, vuint32m1_t rs2, vuint8mf4_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u8mf2(uint8_t *rs1, vuint32m2_t rs2, vuint8mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u8m1(uint8_t *rs1, vuint32m4_t rs2, vuint8m1_t vs3,
                             size_t vl);
void __riscv_vsuxei32_v_u8m2(uint8_t *rs1, vuint32m8_t rs2, vuint8m2_t vs3,
                             size_t vl);
void __riscv_vsuxei64_v_u8mf8(uint8_t *rs1, vuint64m1_t rs2, vuint8mf8_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u8mf4(uint8_t *rs1, vuint64m2_t rs2, vuint8mf4_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u8mf2(uint8_t *rs1, vuint64m4_t rs2, vuint8mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u8m1(uint8_t *rs1, vuint64m8_t rs2, vuint8m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u16mf4(uint16_t *rs1, vuint8mf8_t rs2, vuint16mf4_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_u16mf2(uint16_t *rs1, vuint8mf4_t rs2, vuint16mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_u16m1(uint16_t *rs1, vuint8mf2_t rs2, vuint16m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u16m2(uint16_t *rs1, vuint8m1_t rs2, vuint16m2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u16m4(uint16_t *rs1, vuint8m2_t rs2, vuint16m4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u16m8(uint16_t *rs1, vuint8m4_t rs2, vuint16m8_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_u16mf4(uint16_t *rs1, vuint16mf4_t rs2,
                               vuint16mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_u16mf2(uint16_t *rs1, vuint16mf2_t rs2,
                               vuint16mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_u16m1(uint16_t *rs1, vuint16m1_t rs2, vuint16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u16m2(uint16_t *rs1, vuint16m2_t rs2, vuint16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u16m4(uint16_t *rs1, vuint16m4_t rs2, vuint16m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u16m8(uint16_t *rs1, vuint16m8_t rs2, vuint16m8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u16mf4(uint16_t *rs1, vuint32mf2_t rs2,
                               vuint16mf4_t vs3, size_t vl);
void __riscv_vsuxei32_v_u16mf2(uint16_t *rs1, vuint32m1_t rs2, vuint16mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei32_v_u16m1(uint16_t *rs1, vuint32m2_t rs2, vuint16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u16m2(uint16_t *rs1, vuint32m4_t rs2, vuint16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u16m4(uint16_t *rs1, vuint32m8_t rs2, vuint16m4_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u16mf4(uint16_t *rs1, vuint64m1_t rs2, vuint16mf4_t vs3,
                               size_t vl);
void __riscv_vsuxei64_v_u16mf2(uint16_t *rs1, vuint64m2_t rs2, vuint16mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei64_v_u16m1(uint16_t *rs1, vuint64m4_t rs2, vuint16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u16m2(uint16_t *rs1, vuint64m8_t rs2, vuint16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_u32mf2(uint32_t *rs1, vuint8mf8_t rs2, vuint32mf2_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_u32m1(uint32_t *rs1, vuint8mf4_t rs2, vuint32m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u32m2(uint32_t *rs1, vuint8mf2_t rs2, vuint32m2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u32m4(uint32_t *rs1, vuint8m1_t rs2, vuint32m4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u32m8(uint32_t *rs1, vuint8m2_t rs2, vuint32m8_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_u32mf2(uint32_t *rs1, vuint16mf4_t rs2,
                               vuint32mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_u32m1(uint32_t *rs1, vuint16mf2_t rs2, vuint32m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u32m2(uint32_t *rs1, vuint16m1_t rs2, vuint32m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u32m4(uint32_t *rs1, vuint16m2_t rs2, vuint32m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u32m8(uint32_t *rs1, vuint16m4_t rs2, vuint32m8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u32mf2(uint32_t *rs1, vuint32mf2_t rs2,
                               vuint32mf2_t vs3, size_t vl);
void __riscv_vsuxei32_v_u32m1(uint32_t *rs1, vuint32m1_t rs2, vuint32m1_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u32m2(uint32_t *rs1, vuint32m2_t rs2, vuint32m2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u32m4(uint32_t *rs1, vuint32m4_t rs2, vuint32m4_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u32m8(uint32_t *rs1, vuint32m8_t rs2, vuint32m8_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u32mf2(uint32_t *rs1, vuint64m1_t rs2, vuint32mf2_t vs3,
                               size_t vl);
void __riscv_vsuxei64_v_u32m1(uint32_t *rs1, vuint64m2_t rs2, vuint32m1_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u32m2(uint32_t *rs1, vuint64m4_t rs2, vuint32m2_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u32m4(uint32_t *rs1, vuint64m8_t rs2, vuint32m4_t vs3,
                              size_t vl);
void __riscv_vsuxei8_v_u64m1(uint64_t *rs1, vuint8mf8_t rs2, vuint64m1_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u64m2(uint64_t *rs1, vuint8mf4_t rs2, vuint64m2_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u64m4(uint64_t *rs1, vuint8mf2_t rs2, vuint64m4_t vs3,
                             size_t vl);
void __riscv_vsuxei8_v_u64m8(uint64_t *rs1, vuint8m1_t rs2, vuint64m8_t vs3,
                             size_t vl);
void __riscv_vsuxei16_v_u64m1(uint64_t *rs1, vuint16mf4_t rs2, vuint64m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u64m2(uint64_t *rs1, vuint16mf2_t rs2, vuint64m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u64m4(uint64_t *rs1, vuint16m1_t rs2, vuint64m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_u64m8(uint64_t *rs1, vuint16m2_t rs2, vuint64m8_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u64m1(uint64_t *rs1, vuint32mf2_t rs2, vuint64m1_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u64m2(uint64_t *rs1, vuint32m1_t rs2, vuint64m2_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u64m4(uint64_t *rs1, vuint32m2_t rs2, vuint64m4_t vs3,
                              size_t vl);
void __riscv_vsuxei32_v_u64m8(uint64_t *rs1, vuint32m4_t rs2, vuint64m8_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u64m1(uint64_t *rs1, vuint64m1_t rs2, vuint64m1_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u64m2(uint64_t *rs1, vuint64m2_t rs2, vuint64m2_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u64m4(uint64_t *rs1, vuint64m4_t rs2, vuint64m4_t vs3,
                              size_t vl);
void __riscv_vsuxei64_v_u64m8(uint64_t *rs1, vuint64m8_t rs2, vuint64m8_t vs3,
                              size_t vl);
// masked functions
void __riscv_vsoxei8_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint8mf8_t rs2,
                                vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei8_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint8mf4_t rs2,
                                vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei8_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint8mf2_t rs2,
                               vfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint8m1_t rs2,
                               vfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vuint8m2_t rs2,
                               vfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vuint8m4_t rs2,
                               vfloat16m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint16mf4_t rs2,
                                 vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint16mf2_t rs2,
                                 vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint16m1_t rs2,
                                vfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint16m2_t rs2,
                                vfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vuint16m4_t rs2,
                                vfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vuint16m8_t rs2,
                                vfloat16m8_t vs3, size_t vl);
void __riscv_vsoxei32_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint32mf2_t rs2,
                                 vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei32_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint32m1_t rs2,
                                 vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei32_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint32m2_t rs2,
                                vfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint32m4_t rs2,
                                vfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei32_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vuint32m8_t rs2,
                                vfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei64_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint64m1_t rs2,
                                 vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei64_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint64m2_t rs2,
                                 vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei64_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint64m4_t rs2,
                                vfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei64_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint64m8_t rs2,
                                vfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_f32mf2_m(vbool64_t vm, float *rs1, vuint8mf8_t rs2,
                                vfloat32mf2_t vs3, size_t vl);
void __riscv_vsoxei8_v_f32m1_m(vbool32_t vm, float *rs1, vuint8mf4_t rs2,
                               vfloat32m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_f32m2_m(vbool16_t vm, float *rs1, vuint8mf2_t rs2,
                               vfloat32m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_f32m4_m(vbool8_t vm, float *rs1, vuint8m1_t rs2,
                               vfloat32m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_f32m8_m(vbool4_t vm, float *rs1, vuint8m2_t rs2,
                               vfloat32m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_f32mf2_m(vbool64_t vm, float *rs1, vuint16mf4_t rs2,
                                 vfloat32mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f32m1_m(vbool32_t vm, float *rs1, vuint16mf2_t rs2,
                                vfloat32m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_f32m2_m(vbool16_t vm, float *rs1, vuint16m1_t rs2,
                                vfloat32m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f32m4_m(vbool8_t vm, float *rs1, vuint16m2_t rs2,
                                vfloat32m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f32m8_m(vbool4_t vm, float *rs1, vuint16m4_t rs2,
                                vfloat32m8_t vs3, size_t vl);
void __riscv_vsoxei32_v_f32mf2_m(vbool64_t vm, float *rs1, vuint32mf2_t rs2,
                                 vfloat32mf2_t vs3, size_t vl);
void __riscv_vsoxei32_v_f32m1_m(vbool32_t vm, float *rs1, vuint32m1_t rs2,
                                vfloat32m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_f32m2_m(vbool16_t vm, float *rs1, vuint32m2_t rs2,
                                vfloat32m2_t vs3, size_t vl);
void __riscv_vsoxei32_v_f32m4_m(vbool8_t vm, float *rs1, vuint32m4_t rs2,
                                vfloat32m4_t vs3, size_t vl);
void __riscv_vsoxei32_v_f32m8_m(vbool4_t vm, float *rs1, vuint32m8_t rs2,
                                vfloat32m8_t vs3, size_t vl);
void __riscv_vsoxei64_v_f32mf2_m(vbool64_t vm, float *rs1, vuint64m1_t rs2,
                                 vfloat32mf2_t vs3, size_t vl);
void __riscv_vsoxei64_v_f32m1_m(vbool32_t vm, float *rs1, vuint64m2_t rs2,
                                vfloat32m1_t vs3, size_t vl);
void __riscv_vsoxei64_v_f32m2_m(vbool16_t vm, float *rs1, vuint64m4_t rs2,
                                vfloat32m2_t vs3, size_t vl);
void __riscv_vsoxei64_v_f32m4_m(vbool8_t vm, float *rs1, vuint64m8_t rs2,
                                vfloat32m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_f64m1_m(vbool64_t vm, double *rs1, vuint8mf8_t rs2,
                               vfloat64m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_f64m2_m(vbool32_t vm, double *rs1, vuint8mf4_t rs2,
                               vfloat64m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_f64m4_m(vbool16_t vm, double *rs1, vuint8mf2_t rs2,
                               vfloat64m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_f64m8_m(vbool8_t vm, double *rs1, vuint8m1_t rs2,
                               vfloat64m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_f64m1_m(vbool64_t vm, double *rs1, vuint16mf4_t rs2,
                                vfloat64m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_f64m2_m(vbool32_t vm, double *rs1, vuint16mf2_t rs2,
                                vfloat64m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f64m4_m(vbool16_t vm, double *rs1, vuint16m1_t rs2,
                                vfloat64m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f64m8_m(vbool8_t vm, double *rs1, vuint16m2_t rs2,
                                vfloat64m8_t vs3, size_t vl);
void __riscv_vsoxei32_v_f64m1_m(vbool64_t vm, double *rs1, vuint32mf2_t rs2,
                                vfloat64m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_f64m2_m(vbool32_t vm, double *rs1, vuint32m1_t rs2,
                                vfloat64m2_t vs3, size_t vl);
void __riscv_vsoxei32_v_f64m4_m(vbool16_t vm, double *rs1, vuint32m2_t rs2,
                                vfloat64m4_t vs3, size_t vl);
void __riscv_vsoxei32_v_f64m8_m(vbool8_t vm, double *rs1, vuint32m4_t rs2,
                                vfloat64m8_t vs3, size_t vl);
void __riscv_vsoxei64_v_f64m1_m(vbool64_t vm, double *rs1, vuint64m1_t rs2,
                                vfloat64m1_t vs3, size_t vl);
void __riscv_vsoxei64_v_f64m2_m(vbool32_t vm, double *rs1, vuint64m2_t rs2,
                                vfloat64m2_t vs3, size_t vl);
void __riscv_vsoxei64_v_f64m4_m(vbool16_t vm, double *rs1, vuint64m4_t rs2,
                                vfloat64m4_t vs3, size_t vl);
void __riscv_vsoxei64_v_f64m8_m(vbool8_t vm, double *rs1, vuint64m8_t rs2,
                                vfloat64m8_t vs3, size_t vl);
void __riscv_vsuxei8_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint8mf8_t rs2,
                                vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei8_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint8mf4_t rs2,
                                vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei8_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint8mf2_t rs2,
                               vfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint8m1_t rs2,
                               vfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vuint8m2_t rs2,
                               vfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vuint8m4_t rs2,
                               vfloat16m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint16mf4_t rs2,
                                 vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint16mf2_t rs2,
                                 vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint16m1_t rs2,
                                vfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint16m2_t rs2,
                                vfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vuint16m4_t rs2,
                                vfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vuint16m8_t rs2,
                                vfloat16m8_t vs3, size_t vl);
void __riscv_vsuxei32_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint32mf2_t rs2,
                                 vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei32_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint32m1_t rs2,
                                 vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei32_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint32m2_t rs2,
                                vfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint32m4_t rs2,
                                vfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei32_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vuint32m8_t rs2,
                                vfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei64_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint64m1_t rs2,
                                 vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei64_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint64m2_t rs2,
                                 vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei64_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint64m4_t rs2,
                                vfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei64_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint64m8_t rs2,
                                vfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_f32mf2_m(vbool64_t vm, float *rs1, vuint8mf8_t rs2,
                                vfloat32mf2_t vs3, size_t vl);
void __riscv_vsuxei8_v_f32m1_m(vbool32_t vm, float *rs1, vuint8mf4_t rs2,
                               vfloat32m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_f32m2_m(vbool16_t vm, float *rs1, vuint8mf2_t rs2,
                               vfloat32m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_f32m4_m(vbool8_t vm, float *rs1, vuint8m1_t rs2,
                               vfloat32m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_f32m8_m(vbool4_t vm, float *rs1, vuint8m2_t rs2,
                               vfloat32m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_f32mf2_m(vbool64_t vm, float *rs1, vuint16mf4_t rs2,
                                 vfloat32mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f32m1_m(vbool32_t vm, float *rs1, vuint16mf2_t rs2,
                                vfloat32m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_f32m2_m(vbool16_t vm, float *rs1, vuint16m1_t rs2,
                                vfloat32m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f32m4_m(vbool8_t vm, float *rs1, vuint16m2_t rs2,
                                vfloat32m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f32m8_m(vbool4_t vm, float *rs1, vuint16m4_t rs2,
                                vfloat32m8_t vs3, size_t vl);
void __riscv_vsuxei32_v_f32mf2_m(vbool64_t vm, float *rs1, vuint32mf2_t rs2,
                                 vfloat32mf2_t vs3, size_t vl);
void __riscv_vsuxei32_v_f32m1_m(vbool32_t vm, float *rs1, vuint32m1_t rs2,
                                vfloat32m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_f32m2_m(vbool16_t vm, float *rs1, vuint32m2_t rs2,
                                vfloat32m2_t vs3, size_t vl);
void __riscv_vsuxei32_v_f32m4_m(vbool8_t vm, float *rs1, vuint32m4_t rs2,
                                vfloat32m4_t vs3, size_t vl);
void __riscv_vsuxei32_v_f32m8_m(vbool4_t vm, float *rs1, vuint32m8_t rs2,
                                vfloat32m8_t vs3, size_t vl);
void __riscv_vsuxei64_v_f32mf2_m(vbool64_t vm, float *rs1, vuint64m1_t rs2,
                                 vfloat32mf2_t vs3, size_t vl);
void __riscv_vsuxei64_v_f32m1_m(vbool32_t vm, float *rs1, vuint64m2_t rs2,
                                vfloat32m1_t vs3, size_t vl);
void __riscv_vsuxei64_v_f32m2_m(vbool16_t vm, float *rs1, vuint64m4_t rs2,
                                vfloat32m2_t vs3, size_t vl);
void __riscv_vsuxei64_v_f32m4_m(vbool8_t vm, float *rs1, vuint64m8_t rs2,
                                vfloat32m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_f64m1_m(vbool64_t vm, double *rs1, vuint8mf8_t rs2,
                               vfloat64m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_f64m2_m(vbool32_t vm, double *rs1, vuint8mf4_t rs2,
                               vfloat64m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_f64m4_m(vbool16_t vm, double *rs1, vuint8mf2_t rs2,
                               vfloat64m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_f64m8_m(vbool8_t vm, double *rs1, vuint8m1_t rs2,
                               vfloat64m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_f64m1_m(vbool64_t vm, double *rs1, vuint16mf4_t rs2,
                                vfloat64m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_f64m2_m(vbool32_t vm, double *rs1, vuint16mf2_t rs2,
                                vfloat64m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f64m4_m(vbool16_t vm, double *rs1, vuint16m1_t rs2,
                                vfloat64m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f64m8_m(vbool8_t vm, double *rs1, vuint16m2_t rs2,
                                vfloat64m8_t vs3, size_t vl);
void __riscv_vsuxei32_v_f64m1_m(vbool64_t vm, double *rs1, vuint32mf2_t rs2,
                                vfloat64m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_f64m2_m(vbool32_t vm, double *rs1, vuint32m1_t rs2,
                                vfloat64m2_t vs3, size_t vl);
void __riscv_vsuxei32_v_f64m4_m(vbool16_t vm, double *rs1, vuint32m2_t rs2,
                                vfloat64m4_t vs3, size_t vl);
void __riscv_vsuxei32_v_f64m8_m(vbool8_t vm, double *rs1, vuint32m4_t rs2,
                                vfloat64m8_t vs3, size_t vl);
void __riscv_vsuxei64_v_f64m1_m(vbool64_t vm, double *rs1, vuint64m1_t rs2,
                                vfloat64m1_t vs3, size_t vl);
void __riscv_vsuxei64_v_f64m2_m(vbool32_t vm, double *rs1, vuint64m2_t rs2,
                                vfloat64m2_t vs3, size_t vl);
void __riscv_vsuxei64_v_f64m4_m(vbool16_t vm, double *rs1, vuint64m4_t rs2,
                                vfloat64m4_t vs3, size_t vl);
void __riscv_vsuxei64_v_f64m8_m(vbool8_t vm, double *rs1, vuint64m8_t rs2,
                                vfloat64m8_t vs3, size_t vl);
void __riscv_vsoxei8_v_i8mf8_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t rs2,
                               vint8mf8_t vs3, size_t vl);
void __riscv_vsoxei8_v_i8mf4_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t rs2,
                               vint8mf4_t vs3, size_t vl);
void __riscv_vsoxei8_v_i8mf2_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t rs2,
                               vint8mf2_t vs3, size_t vl);
void __riscv_vsoxei8_v_i8m1_m(vbool8_t vm, int8_t *rs1, vuint8m1_t rs2,
                              vint8m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_i8m2_m(vbool4_t vm, int8_t *rs1, vuint8m2_t rs2,
                              vint8m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_i8m4_m(vbool2_t vm, int8_t *rs1, vuint8m4_t rs2,
                              vint8m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_i8m8_m(vbool1_t vm, int8_t *rs1, vuint8m8_t rs2,
                              vint8m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_i8mf8_m(vbool64_t vm, int8_t *rs1, vuint16mf4_t rs2,
                                vint8mf8_t vs3, size_t vl);
void __riscv_vsoxei16_v_i8mf4_m(vbool32_t vm, int8_t *rs1, vuint16mf2_t rs2,
                                vint8mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_i8mf2_m(vbool16_t vm, int8_t *rs1, vuint16m1_t rs2,
                                vint8mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_i8m1_m(vbool8_t vm, int8_t *rs1, vuint16m2_t rs2,
                               vint8m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_i8m2_m(vbool4_t vm, int8_t *rs1, vuint16m4_t rs2,
                               vint8m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_i8m4_m(vbool2_t vm, int8_t *rs1, vuint16m8_t rs2,
                               vint8m4_t vs3, size_t vl);
void __riscv_vsoxei32_v_i8mf8_m(vbool64_t vm, int8_t *rs1, vuint32mf2_t rs2,
                                vint8mf8_t vs3, size_t vl);
void __riscv_vsoxei32_v_i8mf4_m(vbool32_t vm, int8_t *rs1, vuint32m1_t rs2,
                                vint8mf4_t vs3, size_t vl);
void __riscv_vsoxei32_v_i8mf2_m(vbool16_t vm, int8_t *rs1, vuint32m2_t rs2,
                                vint8mf2_t vs3, size_t vl);
void __riscv_vsoxei32_v_i8m1_m(vbool8_t vm, int8_t *rs1, vuint32m4_t rs2,
                               vint8m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_i8m2_m(vbool4_t vm, int8_t *rs1, vuint32m8_t rs2,
                               vint8m2_t vs3, size_t vl);
void __riscv_vsoxei64_v_i8mf8_m(vbool64_t vm, int8_t *rs1, vuint64m1_t rs2,
                                vint8mf8_t vs3, size_t vl);
void __riscv_vsoxei64_v_i8mf4_m(vbool32_t vm, int8_t *rs1, vuint64m2_t rs2,
                                vint8mf4_t vs3, size_t vl);
void __riscv_vsoxei64_v_i8mf2_m(vbool16_t vm, int8_t *rs1, vuint64m4_t rs2,
                                vint8mf2_t vs3, size_t vl);
void __riscv_vsoxei64_v_i8m1_m(vbool8_t vm, int8_t *rs1, vuint64m8_t rs2,
                               vint8m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_i16mf4_m(vbool64_t vm, int16_t *rs1, vuint8mf8_t rs2,
                                vint16mf4_t vs3, size_t vl);
void __riscv_vsoxei8_v_i16mf2_m(vbool32_t vm, int16_t *rs1, vuint8mf4_t rs2,
                                vint16mf2_t vs3, size_t vl);
void __riscv_vsoxei8_v_i16m1_m(vbool16_t vm, int16_t *rs1, vuint8mf2_t rs2,
                               vint16m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_i16m2_m(vbool8_t vm, int16_t *rs1, vuint8m1_t rs2,
                               vint16m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_i16m4_m(vbool4_t vm, int16_t *rs1, vuint8m2_t rs2,
                               vint16m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_i16m8_m(vbool2_t vm, int16_t *rs1, vuint8m4_t rs2,
                               vint16m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_i16mf4_m(vbool64_t vm, int16_t *rs1, vuint16mf4_t rs2,
                                 vint16mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_i16mf2_m(vbool32_t vm, int16_t *rs1, vuint16mf2_t rs2,
                                 vint16mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_i16m1_m(vbool16_t vm, int16_t *rs1, vuint16m1_t rs2,
                                vint16m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_i16m2_m(vbool8_t vm, int16_t *rs1, vuint16m2_t rs2,
                                vint16m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_i16m4_m(vbool4_t vm, int16_t *rs1, vuint16m4_t rs2,
                                vint16m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_i16m8_m(vbool2_t vm, int16_t *rs1, vuint16m8_t rs2,
                                vint16m8_t vs3, size_t vl);
void __riscv_vsoxei32_v_i16mf4_m(vbool64_t vm, int16_t *rs1, vuint32mf2_t rs2,
                                 vint16mf4_t vs3, size_t vl);
void __riscv_vsoxei32_v_i16mf2_m(vbool32_t vm, int16_t *rs1, vuint32m1_t rs2,
                                 vint16mf2_t vs3, size_t vl);
void __riscv_vsoxei32_v_i16m1_m(vbool16_t vm, int16_t *rs1, vuint32m2_t rs2,
                                vint16m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_i16m2_m(vbool8_t vm, int16_t *rs1, vuint32m4_t rs2,
                                vint16m2_t vs3, size_t vl);
void __riscv_vsoxei32_v_i16m4_m(vbool4_t vm, int16_t *rs1, vuint32m8_t rs2,
                                vint16m4_t vs3, size_t vl);
void __riscv_vsoxei64_v_i16mf4_m(vbool64_t vm, int16_t *rs1, vuint64m1_t rs2,
                                 vint16mf4_t vs3, size_t vl);
void __riscv_vsoxei64_v_i16mf2_m(vbool32_t vm, int16_t *rs1, vuint64m2_t rs2,
                                 vint16mf2_t vs3, size_t vl);
void __riscv_vsoxei64_v_i16m1_m(vbool16_t vm, int16_t *rs1, vuint64m4_t rs2,
                                vint16m1_t vs3, size_t vl);
void __riscv_vsoxei64_v_i16m2_m(vbool8_t vm, int16_t *rs1, vuint64m8_t rs2,
                                vint16m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_i32mf2_m(vbool64_t vm, int32_t *rs1, vuint8mf8_t rs2,
                                vint32mf2_t vs3, size_t vl);
void __riscv_vsoxei8_v_i32m1_m(vbool32_t vm, int32_t *rs1, vuint8mf4_t rs2,
                               vint32m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_i32m2_m(vbool16_t vm, int32_t *rs1, vuint8mf2_t rs2,
                               vint32m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_i32m4_m(vbool8_t vm, int32_t *rs1, vuint8m1_t rs2,
                               vint32m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_i32m8_m(vbool4_t vm, int32_t *rs1, vuint8m2_t rs2,
                               vint32m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_i32mf2_m(vbool64_t vm, int32_t *rs1, vuint16mf4_t rs2,
                                 vint32mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_i32m1_m(vbool32_t vm, int32_t *rs1, vuint16mf2_t rs2,
                                vint32m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_i32m2_m(vbool16_t vm, int32_t *rs1, vuint16m1_t rs2,
                                vint32m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_i32m4_m(vbool8_t vm, int32_t *rs1, vuint16m2_t rs2,
                                vint32m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_i32m8_m(vbool4_t vm, int32_t *rs1, vuint16m4_t rs2,
                                vint32m8_t vs3, size_t vl);
void __riscv_vsoxei32_v_i32mf2_m(vbool64_t vm, int32_t *rs1, vuint32mf2_t rs2,
                                 vint32mf2_t vs3, size_t vl);
void __riscv_vsoxei32_v_i32m1_m(vbool32_t vm, int32_t *rs1, vuint32m1_t rs2,
                                vint32m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_i32m2_m(vbool16_t vm, int32_t *rs1, vuint32m2_t rs2,
                                vint32m2_t vs3, size_t vl);
void __riscv_vsoxei32_v_i32m4_m(vbool8_t vm, int32_t *rs1, vuint32m4_t rs2,
                                vint32m4_t vs3, size_t vl);
void __riscv_vsoxei32_v_i32m8_m(vbool4_t vm, int32_t *rs1, vuint32m8_t rs2,
                                vint32m8_t vs3, size_t vl);
void __riscv_vsoxei64_v_i32mf2_m(vbool64_t vm, int32_t *rs1, vuint64m1_t rs2,
                                 vint32mf2_t vs3, size_t vl);
void __riscv_vsoxei64_v_i32m1_m(vbool32_t vm, int32_t *rs1, vuint64m2_t rs2,
                                vint32m1_t vs3, size_t vl);
void __riscv_vsoxei64_v_i32m2_m(vbool16_t vm, int32_t *rs1, vuint64m4_t rs2,
                                vint32m2_t vs3, size_t vl);
void __riscv_vsoxei64_v_i32m4_m(vbool8_t vm, int32_t *rs1, vuint64m8_t rs2,
                                vint32m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_i64m1_m(vbool64_t vm, int64_t *rs1, vuint8mf8_t rs2,
                               vint64m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_i64m2_m(vbool32_t vm, int64_t *rs1, vuint8mf4_t rs2,
                               vint64m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_i64m4_m(vbool16_t vm, int64_t *rs1, vuint8mf2_t rs2,
                               vint64m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_i64m8_m(vbool8_t vm, int64_t *rs1, vuint8m1_t rs2,
                               vint64m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_i64m1_m(vbool64_t vm, int64_t *rs1, vuint16mf4_t rs2,
                                vint64m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_i64m2_m(vbool32_t vm, int64_t *rs1, vuint16mf2_t rs2,
                                vint64m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_i64m4_m(vbool16_t vm, int64_t *rs1, vuint16m1_t rs2,
                                vint64m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_i64m8_m(vbool8_t vm, int64_t *rs1, vuint16m2_t rs2,
                                vint64m8_t vs3, size_t vl);
void __riscv_vsoxei32_v_i64m1_m(vbool64_t vm, int64_t *rs1, vuint32mf2_t rs2,
                                vint64m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_i64m2_m(vbool32_t vm, int64_t *rs1, vuint32m1_t rs2,
                                vint64m2_t vs3, size_t vl);
void __riscv_vsoxei32_v_i64m4_m(vbool16_t vm, int64_t *rs1, vuint32m2_t rs2,
                                vint64m4_t vs3, size_t vl);
void __riscv_vsoxei32_v_i64m8_m(vbool8_t vm, int64_t *rs1, vuint32m4_t rs2,
                                vint64m8_t vs3, size_t vl);
void __riscv_vsoxei64_v_i64m1_m(vbool64_t vm, int64_t *rs1, vuint64m1_t rs2,
                                vint64m1_t vs3, size_t vl);
void __riscv_vsoxei64_v_i64m2_m(vbool32_t vm, int64_t *rs1, vuint64m2_t rs2,
                                vint64m2_t vs3, size_t vl);
void __riscv_vsoxei64_v_i64m4_m(vbool16_t vm, int64_t *rs1, vuint64m4_t rs2,
                                vint64m4_t vs3, size_t vl);
void __riscv_vsoxei64_v_i64m8_m(vbool8_t vm, int64_t *rs1, vuint64m8_t rs2,
                                vint64m8_t vs3, size_t vl);
void __riscv_vsuxei8_v_i8mf8_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t rs2,
                               vint8mf8_t vs3, size_t vl);
void __riscv_vsuxei8_v_i8mf4_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t rs2,
                               vint8mf4_t vs3, size_t vl);
void __riscv_vsuxei8_v_i8mf2_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t rs2,
                               vint8mf2_t vs3, size_t vl);
void __riscv_vsuxei8_v_i8m1_m(vbool8_t vm, int8_t *rs1, vuint8m1_t rs2,
                              vint8m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_i8m2_m(vbool4_t vm, int8_t *rs1, vuint8m2_t rs2,
                              vint8m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_i8m4_m(vbool2_t vm, int8_t *rs1, vuint8m4_t rs2,
                              vint8m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_i8m8_m(vbool1_t vm, int8_t *rs1, vuint8m8_t rs2,
                              vint8m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_i8mf8_m(vbool64_t vm, int8_t *rs1, vuint16mf4_t rs2,
                                vint8mf8_t vs3, size_t vl);
void __riscv_vsuxei16_v_i8mf4_m(vbool32_t vm, int8_t *rs1, vuint16mf2_t rs2,
                                vint8mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_i8mf2_m(vbool16_t vm, int8_t *rs1, vuint16m1_t rs2,
                                vint8mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_i8m1_m(vbool8_t vm, int8_t *rs1, vuint16m2_t rs2,
                               vint8m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_i8m2_m(vbool4_t vm, int8_t *rs1, vuint16m4_t rs2,
                               vint8m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_i8m4_m(vbool2_t vm, int8_t *rs1, vuint16m8_t rs2,
                               vint8m4_t vs3, size_t vl);
void __riscv_vsuxei32_v_i8mf8_m(vbool64_t vm, int8_t *rs1, vuint32mf2_t rs2,
                                vint8mf8_t vs3, size_t vl);
void __riscv_vsuxei32_v_i8mf4_m(vbool32_t vm, int8_t *rs1, vuint32m1_t rs2,
                                vint8mf4_t vs3, size_t vl);
void __riscv_vsuxei32_v_i8mf2_m(vbool16_t vm, int8_t *rs1, vuint32m2_t rs2,
                                vint8mf2_t vs3, size_t vl);
void __riscv_vsuxei32_v_i8m1_m(vbool8_t vm, int8_t *rs1, vuint32m4_t rs2,
                               vint8m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_i8m2_m(vbool4_t vm, int8_t *rs1, vuint32m8_t rs2,
                               vint8m2_t vs3, size_t vl);
void __riscv_vsuxei64_v_i8mf8_m(vbool64_t vm, int8_t *rs1, vuint64m1_t rs2,
                                vint8mf8_t vs3, size_t vl);
void __riscv_vsuxei64_v_i8mf4_m(vbool32_t vm, int8_t *rs1, vuint64m2_t rs2,
                                vint8mf4_t vs3, size_t vl);
void __riscv_vsuxei64_v_i8mf2_m(vbool16_t vm, int8_t *rs1, vuint64m4_t rs2,
                                vint8mf2_t vs3, size_t vl);
void __riscv_vsuxei64_v_i8m1_m(vbool8_t vm, int8_t *rs1, vuint64m8_t rs2,
                               vint8m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_i16mf4_m(vbool64_t vm, int16_t *rs1, vuint8mf8_t rs2,
                                vint16mf4_t vs3, size_t vl);
void __riscv_vsuxei8_v_i16mf2_m(vbool32_t vm, int16_t *rs1, vuint8mf4_t rs2,
                                vint16mf2_t vs3, size_t vl);
void __riscv_vsuxei8_v_i16m1_m(vbool16_t vm, int16_t *rs1, vuint8mf2_t rs2,
                               vint16m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_i16m2_m(vbool8_t vm, int16_t *rs1, vuint8m1_t rs2,
                               vint16m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_i16m4_m(vbool4_t vm, int16_t *rs1, vuint8m2_t rs2,
                               vint16m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_i16m8_m(vbool2_t vm, int16_t *rs1, vuint8m4_t rs2,
                               vint16m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_i16mf4_m(vbool64_t vm, int16_t *rs1, vuint16mf4_t rs2,
                                 vint16mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_i16mf2_m(vbool32_t vm, int16_t *rs1, vuint16mf2_t rs2,
                                 vint16mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_i16m1_m(vbool16_t vm, int16_t *rs1, vuint16m1_t rs2,
                                vint16m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_i16m2_m(vbool8_t vm, int16_t *rs1, vuint16m2_t rs2,
                                vint16m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_i16m4_m(vbool4_t vm, int16_t *rs1, vuint16m4_t rs2,
                                vint16m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_i16m8_m(vbool2_t vm, int16_t *rs1, vuint16m8_t rs2,
                                vint16m8_t vs3, size_t vl);
void __riscv_vsuxei32_v_i16mf4_m(vbool64_t vm, int16_t *rs1, vuint32mf2_t rs2,
                                 vint16mf4_t vs3, size_t vl);
void __riscv_vsuxei32_v_i16mf2_m(vbool32_t vm, int16_t *rs1, vuint32m1_t rs2,
                                 vint16mf2_t vs3, size_t vl);
void __riscv_vsuxei32_v_i16m1_m(vbool16_t vm, int16_t *rs1, vuint32m2_t rs2,
                                vint16m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_i16m2_m(vbool8_t vm, int16_t *rs1, vuint32m4_t rs2,
                                vint16m2_t vs3, size_t vl);
void __riscv_vsuxei32_v_i16m4_m(vbool4_t vm, int16_t *rs1, vuint32m8_t rs2,
                                vint16m4_t vs3, size_t vl);
void __riscv_vsuxei64_v_i16mf4_m(vbool64_t vm, int16_t *rs1, vuint64m1_t rs2,
                                 vint16mf4_t vs3, size_t vl);
void __riscv_vsuxei64_v_i16mf2_m(vbool32_t vm, int16_t *rs1, vuint64m2_t rs2,
                                 vint16mf2_t vs3, size_t vl);
void __riscv_vsuxei64_v_i16m1_m(vbool16_t vm, int16_t *rs1, vuint64m4_t rs2,
                                vint16m1_t vs3, size_t vl);
void __riscv_vsuxei64_v_i16m2_m(vbool8_t vm, int16_t *rs1, vuint64m8_t rs2,
                                vint16m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_i32mf2_m(vbool64_t vm, int32_t *rs1, vuint8mf8_t rs2,
                                vint32mf2_t vs3, size_t vl);
void __riscv_vsuxei8_v_i32m1_m(vbool32_t vm, int32_t *rs1, vuint8mf4_t rs2,
                               vint32m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_i32m2_m(vbool16_t vm, int32_t *rs1, vuint8mf2_t rs2,
                               vint32m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_i32m4_m(vbool8_t vm, int32_t *rs1, vuint8m1_t rs2,
                               vint32m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_i32m8_m(vbool4_t vm, int32_t *rs1, vuint8m2_t rs2,
                               vint32m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_i32mf2_m(vbool64_t vm, int32_t *rs1, vuint16mf4_t rs2,
                                 vint32mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_i32m1_m(vbool32_t vm, int32_t *rs1, vuint16mf2_t rs2,
                                vint32m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_i32m2_m(vbool16_t vm, int32_t *rs1, vuint16m1_t rs2,
                                vint32m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_i32m4_m(vbool8_t vm, int32_t *rs1, vuint16m2_t rs2,
                                vint32m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_i32m8_m(vbool4_t vm, int32_t *rs1, vuint16m4_t rs2,
                                vint32m8_t vs3, size_t vl);
void __riscv_vsuxei32_v_i32mf2_m(vbool64_t vm, int32_t *rs1, vuint32mf2_t rs2,
                                 vint32mf2_t vs3, size_t vl);
void __riscv_vsuxei32_v_i32m1_m(vbool32_t vm, int32_t *rs1, vuint32m1_t rs2,
                                vint32m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_i32m2_m(vbool16_t vm, int32_t *rs1, vuint32m2_t rs2,
                                vint32m2_t vs3, size_t vl);
void __riscv_vsuxei32_v_i32m4_m(vbool8_t vm, int32_t *rs1, vuint32m4_t rs2,
                                vint32m4_t vs3, size_t vl);
void __riscv_vsuxei32_v_i32m8_m(vbool4_t vm, int32_t *rs1, vuint32m8_t rs2,
                                vint32m8_t vs3, size_t vl);
void __riscv_vsuxei64_v_i32mf2_m(vbool64_t vm, int32_t *rs1, vuint64m1_t rs2,
                                 vint32mf2_t vs3, size_t vl);
void __riscv_vsuxei64_v_i32m1_m(vbool32_t vm, int32_t *rs1, vuint64m2_t rs2,
                                vint32m1_t vs3, size_t vl);
void __riscv_vsuxei64_v_i32m2_m(vbool16_t vm, int32_t *rs1, vuint64m4_t rs2,
                                vint32m2_t vs3, size_t vl);
void __riscv_vsuxei64_v_i32m4_m(vbool8_t vm, int32_t *rs1, vuint64m8_t rs2,
                                vint32m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_i64m1_m(vbool64_t vm, int64_t *rs1, vuint8mf8_t rs2,
                               vint64m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_i64m2_m(vbool32_t vm, int64_t *rs1, vuint8mf4_t rs2,
                               vint64m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_i64m4_m(vbool16_t vm, int64_t *rs1, vuint8mf2_t rs2,
                               vint64m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_i64m8_m(vbool8_t vm, int64_t *rs1, vuint8m1_t rs2,
                               vint64m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_i64m1_m(vbool64_t vm, int64_t *rs1, vuint16mf4_t rs2,
                                vint64m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_i64m2_m(vbool32_t vm, int64_t *rs1, vuint16mf2_t rs2,
                                vint64m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_i64m4_m(vbool16_t vm, int64_t *rs1, vuint16m1_t rs2,
                                vint64m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_i64m8_m(vbool8_t vm, int64_t *rs1, vuint16m2_t rs2,
                                vint64m8_t vs3, size_t vl);
void __riscv_vsuxei32_v_i64m1_m(vbool64_t vm, int64_t *rs1, vuint32mf2_t rs2,
                                vint64m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_i64m2_m(vbool32_t vm, int64_t *rs1, vuint32m1_t rs2,
                                vint64m2_t vs3, size_t vl);
void __riscv_vsuxei32_v_i64m4_m(vbool16_t vm, int64_t *rs1, vuint32m2_t rs2,
                                vint64m4_t vs3, size_t vl);
void __riscv_vsuxei32_v_i64m8_m(vbool8_t vm, int64_t *rs1, vuint32m4_t rs2,
                                vint64m8_t vs3, size_t vl);
void __riscv_vsuxei64_v_i64m1_m(vbool64_t vm, int64_t *rs1, vuint64m1_t rs2,
                                vint64m1_t vs3, size_t vl);
void __riscv_vsuxei64_v_i64m2_m(vbool32_t vm, int64_t *rs1, vuint64m2_t rs2,
                                vint64m2_t vs3, size_t vl);
void __riscv_vsuxei64_v_i64m4_m(vbool16_t vm, int64_t *rs1, vuint64m4_t rs2,
                                vint64m4_t vs3, size_t vl);
void __riscv_vsuxei64_v_i64m8_m(vbool8_t vm, int64_t *rs1, vuint64m8_t rs2,
                                vint64m8_t vs3, size_t vl);
void __riscv_vsoxei8_v_u8mf8_m(vbool64_t vm, uint8_t *rs1, vuint8mf8_t rs2,
                               vuint8mf8_t vs3, size_t vl);
void __riscv_vsoxei8_v_u8mf4_m(vbool32_t vm, uint8_t *rs1, vuint8mf4_t rs2,
                               vuint8mf4_t vs3, size_t vl);
void __riscv_vsoxei8_v_u8mf2_m(vbool16_t vm, uint8_t *rs1, vuint8mf2_t rs2,
                               vuint8mf2_t vs3, size_t vl);
void __riscv_vsoxei8_v_u8m1_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t rs2,
                              vuint8m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_u8m2_m(vbool4_t vm, uint8_t *rs1, vuint8m2_t rs2,
                              vuint8m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_u8m4_m(vbool2_t vm, uint8_t *rs1, vuint8m4_t rs2,
                              vuint8m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_u8m8_m(vbool1_t vm, uint8_t *rs1, vuint8m8_t rs2,
                              vuint8m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_u8mf8_m(vbool64_t vm, uint8_t *rs1, vuint16mf4_t rs2,
                                vuint8mf8_t vs3, size_t vl);
void __riscv_vsoxei16_v_u8mf4_m(vbool32_t vm, uint8_t *rs1, vuint16mf2_t rs2,
                                vuint8mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_u8mf2_m(vbool16_t vm, uint8_t *rs1, vuint16m1_t rs2,
                                vuint8mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_u8m1_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t rs2,
                               vuint8m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_u8m2_m(vbool4_t vm, uint8_t *rs1, vuint16m4_t rs2,
                               vuint8m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_u8m4_m(vbool2_t vm, uint8_t *rs1, vuint16m8_t rs2,
                               vuint8m4_t vs3, size_t vl);
void __riscv_vsoxei32_v_u8mf8_m(vbool64_t vm, uint8_t *rs1, vuint32mf2_t rs2,
                                vuint8mf8_t vs3, size_t vl);
void __riscv_vsoxei32_v_u8mf4_m(vbool32_t vm, uint8_t *rs1, vuint32m1_t rs2,
                                vuint8mf4_t vs3, size_t vl);
void __riscv_vsoxei32_v_u8mf2_m(vbool16_t vm, uint8_t *rs1, vuint32m2_t rs2,
                                vuint8mf2_t vs3, size_t vl);
void __riscv_vsoxei32_v_u8m1_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t rs2,
                               vuint8m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_u8m2_m(vbool4_t vm, uint8_t *rs1, vuint32m8_t rs2,
                               vuint8m2_t vs3, size_t vl);
void __riscv_vsoxei64_v_u8mf8_m(vbool64_t vm, uint8_t *rs1, vuint64m1_t rs2,
                                vuint8mf8_t vs3, size_t vl);
void __riscv_vsoxei64_v_u8mf4_m(vbool32_t vm, uint8_t *rs1, vuint64m2_t rs2,
                                vuint8mf4_t vs3, size_t vl);
void __riscv_vsoxei64_v_u8mf2_m(vbool16_t vm, uint8_t *rs1, vuint64m4_t rs2,
                                vuint8mf2_t vs3, size_t vl);
void __riscv_vsoxei64_v_u8m1_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t rs2,
                               vuint8m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_u16mf4_m(vbool64_t vm, uint16_t *rs1, vuint8mf8_t rs2,
                                vuint16mf4_t vs3, size_t vl);
void __riscv_vsoxei8_v_u16mf2_m(vbool32_t vm, uint16_t *rs1, vuint8mf4_t rs2,
                                vuint16mf2_t vs3, size_t vl);
void __riscv_vsoxei8_v_u16m1_m(vbool16_t vm, uint16_t *rs1, vuint8mf2_t rs2,
                               vuint16m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_u16m2_m(vbool8_t vm, uint16_t *rs1, vuint8m1_t rs2,
                               vuint16m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_u16m4_m(vbool4_t vm, uint16_t *rs1, vuint8m2_t rs2,
                               vuint16m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_u16m8_m(vbool2_t vm, uint16_t *rs1, vuint8m4_t rs2,
                               vuint16m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_u16mf4_m(vbool64_t vm, uint16_t *rs1, vuint16mf4_t rs2,
                                 vuint16mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_u16mf2_m(vbool32_t vm, uint16_t *rs1, vuint16mf2_t rs2,
                                 vuint16mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_u16m1_m(vbool16_t vm, uint16_t *rs1, vuint16m1_t rs2,
                                vuint16m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_u16m2_m(vbool8_t vm, uint16_t *rs1, vuint16m2_t rs2,
                                vuint16m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_u16m4_m(vbool4_t vm, uint16_t *rs1, vuint16m4_t rs2,
                                vuint16m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_u16m8_m(vbool2_t vm, uint16_t *rs1, vuint16m8_t rs2,
                                vuint16m8_t vs3, size_t vl);
void __riscv_vsoxei32_v_u16mf4_m(vbool64_t vm, uint16_t *rs1, vuint32mf2_t rs2,
                                 vuint16mf4_t vs3, size_t vl);
void __riscv_vsoxei32_v_u16mf2_m(vbool32_t vm, uint16_t *rs1, vuint32m1_t rs2,
                                 vuint16mf2_t vs3, size_t vl);
void __riscv_vsoxei32_v_u16m1_m(vbool16_t vm, uint16_t *rs1, vuint32m2_t rs2,
                                vuint16m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_u16m2_m(vbool8_t vm, uint16_t *rs1, vuint32m4_t rs2,
                                vuint16m2_t vs3, size_t vl);
void __riscv_vsoxei32_v_u16m4_m(vbool4_t vm, uint16_t *rs1, vuint32m8_t rs2,
                                vuint16m4_t vs3, size_t vl);
void __riscv_vsoxei64_v_u16mf4_m(vbool64_t vm, uint16_t *rs1, vuint64m1_t rs2,
                                 vuint16mf4_t vs3, size_t vl);
void __riscv_vsoxei64_v_u16mf2_m(vbool32_t vm, uint16_t *rs1, vuint64m2_t rs2,
                                 vuint16mf2_t vs3, size_t vl);
void __riscv_vsoxei64_v_u16m1_m(vbool16_t vm, uint16_t *rs1, vuint64m4_t rs2,
                                vuint16m1_t vs3, size_t vl);
void __riscv_vsoxei64_v_u16m2_m(vbool8_t vm, uint16_t *rs1, vuint64m8_t rs2,
                                vuint16m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_u32mf2_m(vbool64_t vm, uint32_t *rs1, vuint8mf8_t rs2,
                                vuint32mf2_t vs3, size_t vl);
void __riscv_vsoxei8_v_u32m1_m(vbool32_t vm, uint32_t *rs1, vuint8mf4_t rs2,
                               vuint32m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_u32m2_m(vbool16_t vm, uint32_t *rs1, vuint8mf2_t rs2,
                               vuint32m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_u32m4_m(vbool8_t vm, uint32_t *rs1, vuint8m1_t rs2,
                               vuint32m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_u32m8_m(vbool4_t vm, uint32_t *rs1, vuint8m2_t rs2,
                               vuint32m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_u32mf2_m(vbool64_t vm, uint32_t *rs1, vuint16mf4_t rs2,
                                 vuint32mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_u32m1_m(vbool32_t vm, uint32_t *rs1, vuint16mf2_t rs2,
                                vuint32m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_u32m2_m(vbool16_t vm, uint32_t *rs1, vuint16m1_t rs2,
                                vuint32m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_u32m4_m(vbool8_t vm, uint32_t *rs1, vuint16m2_t rs2,
                                vuint32m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_u32m8_m(vbool4_t vm, uint32_t *rs1, vuint16m4_t rs2,
                                vuint32m8_t vs3, size_t vl);
void __riscv_vsoxei32_v_u32mf2_m(vbool64_t vm, uint32_t *rs1, vuint32mf2_t rs2,
                                 vuint32mf2_t vs3, size_t vl);
void __riscv_vsoxei32_v_u32m1_m(vbool32_t vm, uint32_t *rs1, vuint32m1_t rs2,
                                vuint32m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_u32m2_m(vbool16_t vm, uint32_t *rs1, vuint32m2_t rs2,
                                vuint32m2_t vs3, size_t vl);
void __riscv_vsoxei32_v_u32m4_m(vbool8_t vm, uint32_t *rs1, vuint32m4_t rs2,
                                vuint32m4_t vs3, size_t vl);
void __riscv_vsoxei32_v_u32m8_m(vbool4_t vm, uint32_t *rs1, vuint32m8_t rs2,
                                vuint32m8_t vs3, size_t vl);
void __riscv_vsoxei64_v_u32mf2_m(vbool64_t vm, uint32_t *rs1, vuint64m1_t rs2,
                                 vuint32mf2_t vs3, size_t vl);
void __riscv_vsoxei64_v_u32m1_m(vbool32_t vm, uint32_t *rs1, vuint64m2_t rs2,
                                vuint32m1_t vs3, size_t vl);
void __riscv_vsoxei64_v_u32m2_m(vbool16_t vm, uint32_t *rs1, vuint64m4_t rs2,
                                vuint32m2_t vs3, size_t vl);
void __riscv_vsoxei64_v_u32m4_m(vbool8_t vm, uint32_t *rs1, vuint64m8_t rs2,
                                vuint32m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_u64m1_m(vbool64_t vm, uint64_t *rs1, vuint8mf8_t rs2,
                               vuint64m1_t vs3, size_t vl);
void __riscv_vsoxei8_v_u64m2_m(vbool32_t vm, uint64_t *rs1, vuint8mf4_t rs2,
                               vuint64m2_t vs3, size_t vl);
void __riscv_vsoxei8_v_u64m4_m(vbool16_t vm, uint64_t *rs1, vuint8mf2_t rs2,
                               vuint64m4_t vs3, size_t vl);
void __riscv_vsoxei8_v_u64m8_m(vbool8_t vm, uint64_t *rs1, vuint8m1_t rs2,
                               vuint64m8_t vs3, size_t vl);
void __riscv_vsoxei16_v_u64m1_m(vbool64_t vm, uint64_t *rs1, vuint16mf4_t rs2,
                                vuint64m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_u64m2_m(vbool32_t vm, uint64_t *rs1, vuint16mf2_t rs2,
                                vuint64m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_u64m4_m(vbool16_t vm, uint64_t *rs1, vuint16m1_t rs2,
                                vuint64m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_u64m8_m(vbool8_t vm, uint64_t *rs1, vuint16m2_t rs2,
                                vuint64m8_t vs3, size_t vl);
void __riscv_vsoxei32_v_u64m1_m(vbool64_t vm, uint64_t *rs1, vuint32mf2_t rs2,
                                vuint64m1_t vs3, size_t vl);
void __riscv_vsoxei32_v_u64m2_m(vbool32_t vm, uint64_t *rs1, vuint32m1_t rs2,
                                vuint64m2_t vs3, size_t vl);
void __riscv_vsoxei32_v_u64m4_m(vbool16_t vm, uint64_t *rs1, vuint32m2_t rs2,
                                vuint64m4_t vs3, size_t vl);
void __riscv_vsoxei32_v_u64m8_m(vbool8_t vm, uint64_t *rs1, vuint32m4_t rs2,
                                vuint64m8_t vs3, size_t vl);
void __riscv_vsoxei64_v_u64m1_m(vbool64_t vm, uint64_t *rs1, vuint64m1_t rs2,
                                vuint64m1_t vs3, size_t vl);
void __riscv_vsoxei64_v_u64m2_m(vbool32_t vm, uint64_t *rs1, vuint64m2_t rs2,
                                vuint64m2_t vs3, size_t vl);
void __riscv_vsoxei64_v_u64m4_m(vbool16_t vm, uint64_t *rs1, vuint64m4_t rs2,
                                vuint64m4_t vs3, size_t vl);
void __riscv_vsoxei64_v_u64m8_m(vbool8_t vm, uint64_t *rs1, vuint64m8_t rs2,
                                vuint64m8_t vs3, size_t vl);
void __riscv_vsuxei8_v_u8mf8_m(vbool64_t vm, uint8_t *rs1, vuint8mf8_t rs2,
                               vuint8mf8_t vs3, size_t vl);
void __riscv_vsuxei8_v_u8mf4_m(vbool32_t vm, uint8_t *rs1, vuint8mf4_t rs2,
                               vuint8mf4_t vs3, size_t vl);
void __riscv_vsuxei8_v_u8mf2_m(vbool16_t vm, uint8_t *rs1, vuint8mf2_t rs2,
                               vuint8mf2_t vs3, size_t vl);
void __riscv_vsuxei8_v_u8m1_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t rs2,
                              vuint8m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_u8m2_m(vbool4_t vm, uint8_t *rs1, vuint8m2_t rs2,
                              vuint8m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_u8m4_m(vbool2_t vm, uint8_t *rs1, vuint8m4_t rs2,
                              vuint8m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_u8m8_m(vbool1_t vm, uint8_t *rs1, vuint8m8_t rs2,
                              vuint8m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_u8mf8_m(vbool64_t vm, uint8_t *rs1, vuint16mf4_t rs2,
                                vuint8mf8_t vs3, size_t vl);
void __riscv_vsuxei16_v_u8mf4_m(vbool32_t vm, uint8_t *rs1, vuint16mf2_t rs2,
                                vuint8mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_u8mf2_m(vbool16_t vm, uint8_t *rs1, vuint16m1_t rs2,
                                vuint8mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_u8m1_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t rs2,
                               vuint8m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_u8m2_m(vbool4_t vm, uint8_t *rs1, vuint16m4_t rs2,
                               vuint8m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_u8m4_m(vbool2_t vm, uint8_t *rs1, vuint16m8_t rs2,
                               vuint8m4_t vs3, size_t vl);
void __riscv_vsuxei32_v_u8mf8_m(vbool64_t vm, uint8_t *rs1, vuint32mf2_t rs2,
                                vuint8mf8_t vs3, size_t vl);
void __riscv_vsuxei32_v_u8mf4_m(vbool32_t vm, uint8_t *rs1, vuint32m1_t rs2,
                                vuint8mf4_t vs3, size_t vl);
void __riscv_vsuxei32_v_u8mf2_m(vbool16_t vm, uint8_t *rs1, vuint32m2_t rs2,
                                vuint8mf2_t vs3, size_t vl);
void __riscv_vsuxei32_v_u8m1_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t rs2,
                               vuint8m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_u8m2_m(vbool4_t vm, uint8_t *rs1, vuint32m8_t rs2,
                               vuint8m2_t vs3, size_t vl);
void __riscv_vsuxei64_v_u8mf8_m(vbool64_t vm, uint8_t *rs1, vuint64m1_t rs2,
                                vuint8mf8_t vs3, size_t vl);
void __riscv_vsuxei64_v_u8mf4_m(vbool32_t vm, uint8_t *rs1, vuint64m2_t rs2,
                                vuint8mf4_t vs3, size_t vl);
void __riscv_vsuxei64_v_u8mf2_m(vbool16_t vm, uint8_t *rs1, vuint64m4_t rs2,
                                vuint8mf2_t vs3, size_t vl);
void __riscv_vsuxei64_v_u8m1_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t rs2,
                               vuint8m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_u16mf4_m(vbool64_t vm, uint16_t *rs1, vuint8mf8_t rs2,
                                vuint16mf4_t vs3, size_t vl);
void __riscv_vsuxei8_v_u16mf2_m(vbool32_t vm, uint16_t *rs1, vuint8mf4_t rs2,
                                vuint16mf2_t vs3, size_t vl);
void __riscv_vsuxei8_v_u16m1_m(vbool16_t vm, uint16_t *rs1, vuint8mf2_t rs2,
                               vuint16m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_u16m2_m(vbool8_t vm, uint16_t *rs1, vuint8m1_t rs2,
                               vuint16m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_u16m4_m(vbool4_t vm, uint16_t *rs1, vuint8m2_t rs2,
                               vuint16m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_u16m8_m(vbool2_t vm, uint16_t *rs1, vuint8m4_t rs2,
                               vuint16m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_u16mf4_m(vbool64_t vm, uint16_t *rs1, vuint16mf4_t rs2,
                                 vuint16mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_u16mf2_m(vbool32_t vm, uint16_t *rs1, vuint16mf2_t rs2,
                                 vuint16mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_u16m1_m(vbool16_t vm, uint16_t *rs1, vuint16m1_t rs2,
                                vuint16m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_u16m2_m(vbool8_t vm, uint16_t *rs1, vuint16m2_t rs2,
                                vuint16m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_u16m4_m(vbool4_t vm, uint16_t *rs1, vuint16m4_t rs2,
                                vuint16m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_u16m8_m(vbool2_t vm, uint16_t *rs1, vuint16m8_t rs2,
                                vuint16m8_t vs3, size_t vl);
void __riscv_vsuxei32_v_u16mf4_m(vbool64_t vm, uint16_t *rs1, vuint32mf2_t rs2,
                                 vuint16mf4_t vs3, size_t vl);
void __riscv_vsuxei32_v_u16mf2_m(vbool32_t vm, uint16_t *rs1, vuint32m1_t rs2,
                                 vuint16mf2_t vs3, size_t vl);
void __riscv_vsuxei32_v_u16m1_m(vbool16_t vm, uint16_t *rs1, vuint32m2_t rs2,
                                vuint16m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_u16m2_m(vbool8_t vm, uint16_t *rs1, vuint32m4_t rs2,
                                vuint16m2_t vs3, size_t vl);
void __riscv_vsuxei32_v_u16m4_m(vbool4_t vm, uint16_t *rs1, vuint32m8_t rs2,
                                vuint16m4_t vs3, size_t vl);
void __riscv_vsuxei64_v_u16mf4_m(vbool64_t vm, uint16_t *rs1, vuint64m1_t rs2,
                                 vuint16mf4_t vs3, size_t vl);
void __riscv_vsuxei64_v_u16mf2_m(vbool32_t vm, uint16_t *rs1, vuint64m2_t rs2,
                                 vuint16mf2_t vs3, size_t vl);
void __riscv_vsuxei64_v_u16m1_m(vbool16_t vm, uint16_t *rs1, vuint64m4_t rs2,
                                vuint16m1_t vs3, size_t vl);
void __riscv_vsuxei64_v_u16m2_m(vbool8_t vm, uint16_t *rs1, vuint64m8_t rs2,
                                vuint16m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_u32mf2_m(vbool64_t vm, uint32_t *rs1, vuint8mf8_t rs2,
                                vuint32mf2_t vs3, size_t vl);
void __riscv_vsuxei8_v_u32m1_m(vbool32_t vm, uint32_t *rs1, vuint8mf4_t rs2,
                               vuint32m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_u32m2_m(vbool16_t vm, uint32_t *rs1, vuint8mf2_t rs2,
                               vuint32m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_u32m4_m(vbool8_t vm, uint32_t *rs1, vuint8m1_t rs2,
                               vuint32m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_u32m8_m(vbool4_t vm, uint32_t *rs1, vuint8m2_t rs2,
                               vuint32m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_u32mf2_m(vbool64_t vm, uint32_t *rs1, vuint16mf4_t rs2,
                                 vuint32mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_u32m1_m(vbool32_t vm, uint32_t *rs1, vuint16mf2_t rs2,
                                vuint32m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_u32m2_m(vbool16_t vm, uint32_t *rs1, vuint16m1_t rs2,
                                vuint32m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_u32m4_m(vbool8_t vm, uint32_t *rs1, vuint16m2_t rs2,
                                vuint32m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_u32m8_m(vbool4_t vm, uint32_t *rs1, vuint16m4_t rs2,
                                vuint32m8_t vs3, size_t vl);
void __riscv_vsuxei32_v_u32mf2_m(vbool64_t vm, uint32_t *rs1, vuint32mf2_t rs2,
                                 vuint32mf2_t vs3, size_t vl);
void __riscv_vsuxei32_v_u32m1_m(vbool32_t vm, uint32_t *rs1, vuint32m1_t rs2,
                                vuint32m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_u32m2_m(vbool16_t vm, uint32_t *rs1, vuint32m2_t rs2,
                                vuint32m2_t vs3, size_t vl);
void __riscv_vsuxei32_v_u32m4_m(vbool8_t vm, uint32_t *rs1, vuint32m4_t rs2,
                                vuint32m4_t vs3, size_t vl);
void __riscv_vsuxei32_v_u32m8_m(vbool4_t vm, uint32_t *rs1, vuint32m8_t rs2,
                                vuint32m8_t vs3, size_t vl);
void __riscv_vsuxei64_v_u32mf2_m(vbool64_t vm, uint32_t *rs1, vuint64m1_t rs2,
                                 vuint32mf2_t vs3, size_t vl);
void __riscv_vsuxei64_v_u32m1_m(vbool32_t vm, uint32_t *rs1, vuint64m2_t rs2,
                                vuint32m1_t vs3, size_t vl);
void __riscv_vsuxei64_v_u32m2_m(vbool16_t vm, uint32_t *rs1, vuint64m4_t rs2,
                                vuint32m2_t vs3, size_t vl);
void __riscv_vsuxei64_v_u32m4_m(vbool8_t vm, uint32_t *rs1, vuint64m8_t rs2,
                                vuint32m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_u64m1_m(vbool64_t vm, uint64_t *rs1, vuint8mf8_t rs2,
                               vuint64m1_t vs3, size_t vl);
void __riscv_vsuxei8_v_u64m2_m(vbool32_t vm, uint64_t *rs1, vuint8mf4_t rs2,
                               vuint64m2_t vs3, size_t vl);
void __riscv_vsuxei8_v_u64m4_m(vbool16_t vm, uint64_t *rs1, vuint8mf2_t rs2,
                               vuint64m4_t vs3, size_t vl);
void __riscv_vsuxei8_v_u64m8_m(vbool8_t vm, uint64_t *rs1, vuint8m1_t rs2,
                               vuint64m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_u64m1_m(vbool64_t vm, uint64_t *rs1, vuint16mf4_t rs2,
                                vuint64m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_u64m2_m(vbool32_t vm, uint64_t *rs1, vuint16mf2_t rs2,
                                vuint64m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_u64m4_m(vbool16_t vm, uint64_t *rs1, vuint16m1_t rs2,
                                vuint64m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_u64m8_m(vbool8_t vm, uint64_t *rs1, vuint16m2_t rs2,
                                vuint64m8_t vs3, size_t vl);
void __riscv_vsuxei32_v_u64m1_m(vbool64_t vm, uint64_t *rs1, vuint32mf2_t rs2,
                                vuint64m1_t vs3, size_t vl);
void __riscv_vsuxei32_v_u64m2_m(vbool32_t vm, uint64_t *rs1, vuint32m1_t rs2,
                                vuint64m2_t vs3, size_t vl);
void __riscv_vsuxei32_v_u64m4_m(vbool16_t vm, uint64_t *rs1, vuint32m2_t rs2,
                                vuint64m4_t vs3, size_t vl);
void __riscv_vsuxei32_v_u64m8_m(vbool8_t vm, uint64_t *rs1, vuint32m4_t rs2,
                                vuint64m8_t vs3, size_t vl);
void __riscv_vsuxei64_v_u64m1_m(vbool64_t vm, uint64_t *rs1, vuint64m1_t rs2,
                                vuint64m1_t vs3, size_t vl);
void __riscv_vsuxei64_v_u64m2_m(vbool32_t vm, uint64_t *rs1, vuint64m2_t rs2,
                                vuint64m2_t vs3, size_t vl);
void __riscv_vsuxei64_v_u64m4_m(vbool16_t vm, uint64_t *rs1, vuint64m4_t rs2,
                                vuint64m4_t vs3, size_t vl);
void __riscv_vsuxei64_v_u64m8_m(vbool8_t vm, uint64_t *rs1, vuint64m8_t rs2,
                                vuint64m8_t vs3, size_t vl);
----

[[unit-stride-fault-only-first-loads]]
==== Unit-stride Fault-Only-First Loads Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vle16ff_v_f16mf4(const _Float16 *rs1, size_t *new_vl,
                                       size_t vl);
vfloat16mf2_t __riscv_vle16ff_v_f16mf2(const _Float16 *rs1, size_t *new_vl,
                                       size_t vl);
vfloat16m1_t __riscv_vle16ff_v_f16m1(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
vfloat16m2_t __riscv_vle16ff_v_f16m2(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
vfloat16m4_t __riscv_vle16ff_v_f16m4(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
vfloat16m8_t __riscv_vle16ff_v_f16m8(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
vfloat32mf2_t __riscv_vle32ff_v_f32mf2(const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m1_t __riscv_vle32ff_v_f32m1(const float *rs1, size_t *new_vl,
                                     size_t vl);
vfloat32m2_t __riscv_vle32ff_v_f32m2(const float *rs1, size_t *new_vl,
                                     size_t vl);
vfloat32m4_t __riscv_vle32ff_v_f32m4(const float *rs1, size_t *new_vl,
                                     size_t vl);
vfloat32m8_t __riscv_vle32ff_v_f32m8(const float *rs1, size_t *new_vl,
                                     size_t vl);
vfloat64m1_t __riscv_vle64ff_v_f64m1(const double *rs1, size_t *new_vl,
                                     size_t vl);
vfloat64m2_t __riscv_vle64ff_v_f64m2(const double *rs1, size_t *new_vl,
                                     size_t vl);
vfloat64m4_t __riscv_vle64ff_v_f64m4(const double *rs1, size_t *new_vl,
                                     size_t vl);
vfloat64m8_t __riscv_vle64ff_v_f64m8(const double *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf8_t __riscv_vle8ff_v_i8mf8(const int8_t *rs1, size_t *new_vl, size_t vl);
vint8mf4_t __riscv_vle8ff_v_i8mf4(const int8_t *rs1, size_t *new_vl, size_t vl);
vint8mf2_t __riscv_vle8ff_v_i8mf2(const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m1_t __riscv_vle8ff_v_i8m1(const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m2_t __riscv_vle8ff_v_i8m2(const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m4_t __riscv_vle8ff_v_i8m4(const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m8_t __riscv_vle8ff_v_i8m8(const int8_t *rs1, size_t *new_vl, size_t vl);
vint16mf4_t __riscv_vle16ff_v_i16mf4(const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf2_t __riscv_vle16ff_v_i16mf2(const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m1_t __riscv_vle16ff_v_i16m1(const int16_t *rs1, size_t *new_vl,
                                   size_t vl);
vint16m2_t __riscv_vle16ff_v_i16m2(const int16_t *rs1, size_t *new_vl,
                                   size_t vl);
vint16m4_t __riscv_vle16ff_v_i16m4(const int16_t *rs1, size_t *new_vl,
                                   size_t vl);
vint16m8_t __riscv_vle16ff_v_i16m8(const int16_t *rs1, size_t *new_vl,
                                   size_t vl);
vint32mf2_t __riscv_vle32ff_v_i32mf2(const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m1_t __riscv_vle32ff_v_i32m1(const int32_t *rs1, size_t *new_vl,
                                   size_t vl);
vint32m2_t __riscv_vle32ff_v_i32m2(const int32_t *rs1, size_t *new_vl,
                                   size_t vl);
vint32m4_t __riscv_vle32ff_v_i32m4(const int32_t *rs1, size_t *new_vl,
                                   size_t vl);
vint32m8_t __riscv_vle32ff_v_i32m8(const int32_t *rs1, size_t *new_vl,
                                   size_t vl);
vint64m1_t __riscv_vle64ff_v_i64m1(const int64_t *rs1, size_t *new_vl,
                                   size_t vl);
vint64m2_t __riscv_vle64ff_v_i64m2(const int64_t *rs1, size_t *new_vl,
                                   size_t vl);
vint64m4_t __riscv_vle64ff_v_i64m4(const int64_t *rs1, size_t *new_vl,
                                   size_t vl);
vint64m8_t __riscv_vle64ff_v_i64m8(const int64_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8mf8_t __riscv_vle8ff_v_u8mf8(const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8mf4_t __riscv_vle8ff_v_u8mf4(const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8mf2_t __riscv_vle8ff_v_u8mf2(const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m1_t __riscv_vle8ff_v_u8m1(const uint8_t *rs1, size_t *new_vl, size_t vl);
vuint8m2_t __riscv_vle8ff_v_u8m2(const uint8_t *rs1, size_t *new_vl, size_t vl);
vuint8m4_t __riscv_vle8ff_v_u8m4(const uint8_t *rs1, size_t *new_vl, size_t vl);
vuint8m8_t __riscv_vle8ff_v_u8m8(const uint8_t *rs1, size_t *new_vl, size_t vl);
vuint16mf4_t __riscv_vle16ff_v_u16mf4(const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf2_t __riscv_vle16ff_v_u16mf2(const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m1_t __riscv_vle16ff_v_u16m1(const uint16_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint16m2_t __riscv_vle16ff_v_u16m2(const uint16_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint16m4_t __riscv_vle16ff_v_u16m4(const uint16_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint16m8_t __riscv_vle16ff_v_u16m8(const uint16_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint32mf2_t __riscv_vle32ff_v_u32mf2(const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m1_t __riscv_vle32ff_v_u32m1(const uint32_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint32m2_t __riscv_vle32ff_v_u32m2(const uint32_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint32m4_t __riscv_vle32ff_v_u32m4(const uint32_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint32m8_t __riscv_vle32ff_v_u32m8(const uint32_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint64m1_t __riscv_vle64ff_v_u64m1(const uint64_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint64m2_t __riscv_vle64ff_v_u64m2(const uint64_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint64m4_t __riscv_vle64ff_v_u64m4(const uint64_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint64m8_t __riscv_vle64ff_v_u64m8(const uint64_t *rs1, size_t *new_vl,
                                    size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16ff_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                         size_t *new_vl, size_t vl);
vfloat16mf2_t __riscv_vle16ff_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                         size_t *new_vl, size_t vl);
vfloat16m1_t __riscv_vle16ff_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
vfloat16m2_t __riscv_vle16ff_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
vfloat16m4_t __riscv_vle16ff_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
vfloat16m8_t __riscv_vle16ff_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32mf2_t __riscv_vle32ff_v_f32mf2_m(vbool64_t vm, const float *rs1,
                                         size_t *new_vl, size_t vl);
vfloat32m1_t __riscv_vle32ff_v_f32m1_m(vbool32_t vm, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32m2_t __riscv_vle32ff_v_f32m2_m(vbool16_t vm, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32m4_t __riscv_vle32ff_v_f32m4_m(vbool8_t vm, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32m8_t __riscv_vle32ff_v_f32m8_m(vbool4_t vm, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat64m1_t __riscv_vle64ff_v_f64m1_m(vbool64_t vm, const double *rs1,
                                       size_t *new_vl, size_t vl);
vfloat64m2_t __riscv_vle64ff_v_f64m2_m(vbool32_t vm, const double *rs1,
                                       size_t *new_vl, size_t vl);
vfloat64m4_t __riscv_vle64ff_v_f64m4_m(vbool16_t vm, const double *rs1,
                                       size_t *new_vl, size_t vl);
vfloat64m8_t __riscv_vle64ff_v_f64m8_m(vbool8_t vm, const double *rs1,
                                       size_t *new_vl, size_t vl);
vint8mf8_t __riscv_vle8ff_v_i8mf8_m(vbool64_t vm, const int8_t *rs1,
                                    size_t *new_vl, size_t vl);
vint8mf4_t __riscv_vle8ff_v_i8mf4_m(vbool32_t vm, const int8_t *rs1,
                                    size_t *new_vl, size_t vl);
vint8mf2_t __riscv_vle8ff_v_i8mf2_m(vbool16_t vm, const int8_t *rs1,
                                    size_t *new_vl, size_t vl);
vint8m1_t __riscv_vle8ff_v_i8m1_m(vbool8_t vm, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m2_t __riscv_vle8ff_v_i8m2_m(vbool4_t vm, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m4_t __riscv_vle8ff_v_i8m4_m(vbool2_t vm, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m8_t __riscv_vle8ff_v_i8m8_m(vbool1_t vm, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint16mf4_t __riscv_vle16ff_v_i16mf4_m(vbool64_t vm, const int16_t *rs1,
                                       size_t *new_vl, size_t vl);
vint16mf2_t __riscv_vle16ff_v_i16mf2_m(vbool32_t vm, const int16_t *rs1,
                                       size_t *new_vl, size_t vl);
vint16m1_t __riscv_vle16ff_v_i16m1_m(vbool16_t vm, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16m2_t __riscv_vle16ff_v_i16m2_m(vbool8_t vm, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16m4_t __riscv_vle16ff_v_i16m4_m(vbool4_t vm, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16m8_t __riscv_vle16ff_v_i16m8_m(vbool2_t vm, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32mf2_t __riscv_vle32ff_v_i32mf2_m(vbool64_t vm, const int32_t *rs1,
                                       size_t *new_vl, size_t vl);
vint32m1_t __riscv_vle32ff_v_i32m1_m(vbool32_t vm, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32m2_t __riscv_vle32ff_v_i32m2_m(vbool16_t vm, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32m4_t __riscv_vle32ff_v_i32m4_m(vbool8_t vm, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32m8_t __riscv_vle32ff_v_i32m8_m(vbool4_t vm, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint64m1_t __riscv_vle64ff_v_i64m1_m(vbool64_t vm, const int64_t *rs1,
                                     size_t *new_vl, size_t vl);
vint64m2_t __riscv_vle64ff_v_i64m2_m(vbool32_t vm, const int64_t *rs1,
                                     size_t *new_vl, size_t vl);
vint64m4_t __riscv_vle64ff_v_i64m4_m(vbool16_t vm, const int64_t *rs1,
                                     size_t *new_vl, size_t vl);
vint64m8_t __riscv_vle64ff_v_i64m8_m(vbool8_t vm, const int64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint8mf8_t __riscv_vle8ff_v_u8mf8_m(vbool64_t vm, const uint8_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint8mf4_t __riscv_vle8ff_v_u8mf4_m(vbool32_t vm, const uint8_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint8mf2_t __riscv_vle8ff_v_u8mf2_m(vbool16_t vm, const uint8_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint8m1_t __riscv_vle8ff_v_u8m1_m(vbool8_t vm, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m2_t __riscv_vle8ff_v_u8m2_m(vbool4_t vm, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m4_t __riscv_vle8ff_v_u8m4_m(vbool2_t vm, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m8_t __riscv_vle8ff_v_u8m8_m(vbool1_t vm, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint16mf4_t __riscv_vle16ff_v_u16mf4_m(vbool64_t vm, const uint16_t *rs1,
                                        size_t *new_vl, size_t vl);
vuint16mf2_t __riscv_vle16ff_v_u16mf2_m(vbool32_t vm, const uint16_t *rs1,
                                        size_t *new_vl, size_t vl);
vuint16m1_t __riscv_vle16ff_v_u16m1_m(vbool16_t vm, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16m2_t __riscv_vle16ff_v_u16m2_m(vbool8_t vm, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16m4_t __riscv_vle16ff_v_u16m4_m(vbool4_t vm, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16m8_t __riscv_vle16ff_v_u16m8_m(vbool2_t vm, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32mf2_t __riscv_vle32ff_v_u32mf2_m(vbool64_t vm, const uint32_t *rs1,
                                        size_t *new_vl, size_t vl);
vuint32m1_t __riscv_vle32ff_v_u32m1_m(vbool32_t vm, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32m2_t __riscv_vle32ff_v_u32m2_m(vbool16_t vm, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32m4_t __riscv_vle32ff_v_u32m4_m(vbool8_t vm, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32m8_t __riscv_vle32ff_v_u32m8_m(vbool4_t vm, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint64m1_t __riscv_vle64ff_v_u64m1_m(vbool64_t vm, const uint64_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint64m2_t __riscv_vle64ff_v_u64m2_m(vbool32_t vm, const uint64_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint64m4_t __riscv_vle64ff_v_u64m4_m(vbool16_t vm, const uint64_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint64m8_t __riscv_vle64ff_v_u64m8_m(vbool8_t vm, const uint64_t *rs1,
                                      size_t *new_vl, size_t vl);
----

=== Vector Loads and Stores Segment Intrinsics

[[vector-unit-stride-segment-load]]
==== Vector Unit-Stride Segment Load Intrinsics

[,c]
----
vfloat16mf4x2_t __riscv_vlseg2e16_v_f16mf4x2(const _Float16 *rs1, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_v_f16mf4x3(const _Float16 *rs1, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_v_f16mf4x4(const _Float16 *rs1, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_v_f16mf4x5(const _Float16 *rs1, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_v_f16mf4x6(const _Float16 *rs1, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_v_f16mf4x7(const _Float16 *rs1, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_v_f16mf4x8(const _Float16 *rs1, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_v_f16mf2x2(const _Float16 *rs1, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_v_f16mf2x3(const _Float16 *rs1, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_v_f16mf2x4(const _Float16 *rs1, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_v_f16mf2x5(const _Float16 *rs1, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_v_f16mf2x6(const _Float16 *rs1, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_v_f16mf2x7(const _Float16 *rs1, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_v_f16mf2x8(const _Float16 *rs1, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_v_f16m1x2(const _Float16 *rs1, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_v_f16m1x3(const _Float16 *rs1, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_v_f16m1x4(const _Float16 *rs1, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_v_f16m1x5(const _Float16 *rs1, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_v_f16m1x6(const _Float16 *rs1, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_v_f16m1x7(const _Float16 *rs1, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_v_f16m1x8(const _Float16 *rs1, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_v_f16m2x2(const _Float16 *rs1, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_v_f16m2x3(const _Float16 *rs1, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_v_f16m2x4(const _Float16 *rs1, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_v_f16m4x2(const _Float16 *rs1, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32_v_f32mf2x2(const float *rs1, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_v_f32mf2x3(const float *rs1, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_v_f32mf2x4(const float *rs1, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_v_f32mf2x5(const float *rs1, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_v_f32mf2x6(const float *rs1, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_v_f32mf2x7(const float *rs1, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_v_f32mf2x8(const float *rs1, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_v_f32m1x2(const float *rs1, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_v_f32m1x3(const float *rs1, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_v_f32m1x4(const float *rs1, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_v_f32m1x5(const float *rs1, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_v_f32m1x6(const float *rs1, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_v_f32m1x7(const float *rs1, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_v_f32m1x8(const float *rs1, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_v_f32m2x2(const float *rs1, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_v_f32m2x3(const float *rs1, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_v_f32m2x4(const float *rs1, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_v_f32m4x2(const float *rs1, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_v_f64m1x2(const double *rs1, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_v_f64m1x3(const double *rs1, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_v_f64m1x4(const double *rs1, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_v_f64m1x5(const double *rs1, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_v_f64m1x6(const double *rs1, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_v_f64m1x7(const double *rs1, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_v_f64m1x8(const double *rs1, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_v_f64m2x2(const double *rs1, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_v_f64m2x3(const double *rs1, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_v_f64m2x4(const double *rs1, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_v_f64m4x2(const double *rs1, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_v_f16mf4x2(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_v_f16mf4x3(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_v_f16mf4x4(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_v_f16mf4x5(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_v_f16mf4x6(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_v_f16mf4x7(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_v_f16mf4x8(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_v_f16mf2x2(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_v_f16mf2x3(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_v_f16mf2x4(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_v_f16mf2x5(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_v_f16mf2x6(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_v_f16mf2x7(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_v_f16mf2x8(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_v_f16m1x2(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_v_f16m1x3(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_v_f16m1x4(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_v_f16m1x5(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_v_f16m1x6(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_v_f16m1x7(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_v_f16m1x8(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_v_f16m2x2(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_v_f16m2x3(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_v_f16m2x4(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_v_f16m4x2(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_v_f32mf2x2(const float *rs1, size_t *new_vl,
                                               size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_v_f32mf2x3(const float *rs1, size_t *new_vl,
                                               size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_v_f32mf2x4(const float *rs1, size_t *new_vl,
                                               size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_v_f32mf2x5(const float *rs1, size_t *new_vl,
                                               size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_v_f32mf2x6(const float *rs1, size_t *new_vl,
                                               size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_v_f32mf2x7(const float *rs1, size_t *new_vl,
                                               size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_v_f32mf2x8(const float *rs1, size_t *new_vl,
                                               size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_v_f32m1x2(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_v_f32m1x3(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_v_f32m1x4(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_v_f32m1x5(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_v_f32m1x6(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_v_f32m1x7(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_v_f32m1x8(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_v_f32m2x2(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_v_f32m2x3(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_v_f32m2x4(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_v_f32m4x2(const float *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_v_f64m1x2(const double *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_v_f64m1x3(const double *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_v_f64m1x4(const double *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_v_f64m1x5(const double *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_v_f64m1x6(const double *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_v_f64m1x7(const double *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_v_f64m1x8(const double *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_v_f64m2x2(const double *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_v_f64m2x3(const double *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_v_f64m2x4(const double *rs1, size_t *new_vl,
                                             size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_v_f64m4x2(const double *rs1, size_t *new_vl,
                                             size_t vl);
vint8mf8x2_t __riscv_vlseg2e8_v_i8mf8x2(const int8_t *rs1, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_v_i8mf8x3(const int8_t *rs1, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_v_i8mf8x4(const int8_t *rs1, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_v_i8mf8x5(const int8_t *rs1, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_v_i8mf8x6(const int8_t *rs1, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_v_i8mf8x7(const int8_t *rs1, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_v_i8mf8x8(const int8_t *rs1, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_v_i8mf4x2(const int8_t *rs1, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_v_i8mf4x3(const int8_t *rs1, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_v_i8mf4x4(const int8_t *rs1, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_v_i8mf4x5(const int8_t *rs1, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_v_i8mf4x6(const int8_t *rs1, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_v_i8mf4x7(const int8_t *rs1, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_v_i8mf4x8(const int8_t *rs1, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_v_i8mf2x2(const int8_t *rs1, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_v_i8mf2x3(const int8_t *rs1, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_v_i8mf2x4(const int8_t *rs1, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_v_i8mf2x5(const int8_t *rs1, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_v_i8mf2x6(const int8_t *rs1, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_v_i8mf2x7(const int8_t *rs1, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_v_i8mf2x8(const int8_t *rs1, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_v_i8m1x2(const int8_t *rs1, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_v_i8m1x3(const int8_t *rs1, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_v_i8m1x4(const int8_t *rs1, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_v_i8m1x5(const int8_t *rs1, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_v_i8m1x6(const int8_t *rs1, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_v_i8m1x7(const int8_t *rs1, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_v_i8m1x8(const int8_t *rs1, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_v_i8m2x2(const int8_t *rs1, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_v_i8m2x3(const int8_t *rs1, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_v_i8m2x4(const int8_t *rs1, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_v_i8m4x2(const int8_t *rs1, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_v_i16mf4x2(const int16_t *rs1, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_v_i16mf4x3(const int16_t *rs1, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_v_i16mf4x4(const int16_t *rs1, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_v_i16mf4x5(const int16_t *rs1, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_v_i16mf4x6(const int16_t *rs1, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_v_i16mf4x7(const int16_t *rs1, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_v_i16mf4x8(const int16_t *rs1, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_v_i16mf2x2(const int16_t *rs1, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_v_i16mf2x3(const int16_t *rs1, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_v_i16mf2x4(const int16_t *rs1, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_v_i16mf2x5(const int16_t *rs1, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_v_i16mf2x6(const int16_t *rs1, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_v_i16mf2x7(const int16_t *rs1, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_v_i16mf2x8(const int16_t *rs1, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_v_i16m1x2(const int16_t *rs1, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_v_i16m1x3(const int16_t *rs1, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_v_i16m1x4(const int16_t *rs1, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_v_i16m1x5(const int16_t *rs1, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_v_i16m1x6(const int16_t *rs1, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_v_i16m1x7(const int16_t *rs1, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_v_i16m1x8(const int16_t *rs1, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_v_i16m2x2(const int16_t *rs1, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_v_i16m2x3(const int16_t *rs1, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_v_i16m2x4(const int16_t *rs1, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_v_i16m4x2(const int16_t *rs1, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_v_i32mf2x2(const int32_t *rs1, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_v_i32mf2x3(const int32_t *rs1, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_v_i32mf2x4(const int32_t *rs1, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_v_i32mf2x5(const int32_t *rs1, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_v_i32mf2x6(const int32_t *rs1, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_v_i32mf2x7(const int32_t *rs1, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_v_i32mf2x8(const int32_t *rs1, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_v_i32m1x2(const int32_t *rs1, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_v_i32m1x3(const int32_t *rs1, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_v_i32m1x4(const int32_t *rs1, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_v_i32m1x5(const int32_t *rs1, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_v_i32m1x6(const int32_t *rs1, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_v_i32m1x7(const int32_t *rs1, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_v_i32m1x8(const int32_t *rs1, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_v_i32m2x2(const int32_t *rs1, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_v_i32m2x3(const int32_t *rs1, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_v_i32m2x4(const int32_t *rs1, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_v_i32m4x2(const int32_t *rs1, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_v_i64m1x2(const int64_t *rs1, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_v_i64m1x3(const int64_t *rs1, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_v_i64m1x4(const int64_t *rs1, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_v_i64m1x5(const int64_t *rs1, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_v_i64m1x6(const int64_t *rs1, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_v_i64m1x7(const int64_t *rs1, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_v_i64m1x8(const int64_t *rs1, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_v_i64m2x2(const int64_t *rs1, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_v_i64m2x3(const int64_t *rs1, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_v_i64m2x4(const int64_t *rs1, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_v_i64m4x2(const int64_t *rs1, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_v_i8mf8x2(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_v_i8mf8x3(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_v_i8mf8x4(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_v_i8mf8x5(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_v_i8mf8x6(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_v_i8mf8x7(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_v_i8mf8x8(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_v_i8mf4x2(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_v_i8mf4x3(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_v_i8mf4x4(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_v_i8mf4x5(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_v_i8mf4x6(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_v_i8mf4x7(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_v_i8mf4x8(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_v_i8mf2x2(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_v_i8mf2x3(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_v_i8mf2x4(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_v_i8mf2x5(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_v_i8mf2x6(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_v_i8mf2x7(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_v_i8mf2x8(const int8_t *rs1, size_t *new_vl,
                                          size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_v_i8m1x2(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_v_i8m1x3(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_v_i8m1x4(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_v_i8m1x5(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_v_i8m1x6(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_v_i8m1x7(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_v_i8m1x8(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_v_i8m2x2(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_v_i8m2x3(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_v_i8m2x4(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_v_i8m4x2(const int8_t *rs1, size_t *new_vl,
                                        size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_v_i16mf4x2(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_v_i16mf4x3(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_v_i16mf4x4(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_v_i16mf4x5(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_v_i16mf4x6(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_v_i16mf4x7(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_v_i16mf4x8(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_v_i16mf2x2(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_v_i16mf2x3(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_v_i16mf2x4(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_v_i16mf2x5(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_v_i16mf2x6(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_v_i16mf2x7(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_v_i16mf2x8(const int16_t *rs1, size_t *new_vl,
                                             size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_v_i16m1x2(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_v_i16m1x3(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_v_i16m1x4(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_v_i16m1x5(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_v_i16m1x6(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_v_i16m1x7(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_v_i16m1x8(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_v_i16m2x2(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_v_i16m2x3(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_v_i16m2x4(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_v_i16m4x2(const int16_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_v_i32mf2x2(const int32_t *rs1, size_t *new_vl,
                                             size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_v_i32mf2x3(const int32_t *rs1, size_t *new_vl,
                                             size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_v_i32mf2x4(const int32_t *rs1, size_t *new_vl,
                                             size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_v_i32mf2x5(const int32_t *rs1, size_t *new_vl,
                                             size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_v_i32mf2x6(const int32_t *rs1, size_t *new_vl,
                                             size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_v_i32mf2x7(const int32_t *rs1, size_t *new_vl,
                                             size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_v_i32mf2x8(const int32_t *rs1, size_t *new_vl,
                                             size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_v_i32m1x2(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_v_i32m1x3(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_v_i32m1x4(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_v_i32m1x5(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_v_i32m1x6(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_v_i32m1x7(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_v_i32m1x8(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_v_i32m2x2(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_v_i32m2x3(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_v_i32m2x4(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_v_i32m4x2(const int32_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_v_i64m1x2(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_v_i64m1x3(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_v_i64m1x4(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_v_i64m1x5(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_v_i64m1x6(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_v_i64m1x7(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_v_i64m1x8(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_v_i64m2x2(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_v_i64m2x3(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_v_i64m2x4(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_v_i64m4x2(const int64_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_v_u8mf8x2(const uint8_t *rs1, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_v_u8mf8x3(const uint8_t *rs1, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_v_u8mf8x4(const uint8_t *rs1, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_v_u8mf8x5(const uint8_t *rs1, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_v_u8mf8x6(const uint8_t *rs1, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_v_u8mf8x7(const uint8_t *rs1, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_v_u8mf8x8(const uint8_t *rs1, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_v_u8mf4x2(const uint8_t *rs1, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_v_u8mf4x3(const uint8_t *rs1, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_v_u8mf4x4(const uint8_t *rs1, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_v_u8mf4x5(const uint8_t *rs1, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_v_u8mf4x6(const uint8_t *rs1, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_v_u8mf4x7(const uint8_t *rs1, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_v_u8mf4x8(const uint8_t *rs1, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_v_u8mf2x2(const uint8_t *rs1, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_v_u8mf2x3(const uint8_t *rs1, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_v_u8mf2x4(const uint8_t *rs1, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_v_u8mf2x5(const uint8_t *rs1, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_v_u8mf2x6(const uint8_t *rs1, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_v_u8mf2x7(const uint8_t *rs1, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_v_u8mf2x8(const uint8_t *rs1, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_v_u8m1x2(const uint8_t *rs1, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_v_u8m1x3(const uint8_t *rs1, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_v_u8m1x4(const uint8_t *rs1, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_v_u8m1x5(const uint8_t *rs1, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_v_u8m1x6(const uint8_t *rs1, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_v_u8m1x7(const uint8_t *rs1, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_v_u8m1x8(const uint8_t *rs1, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_v_u8m2x2(const uint8_t *rs1, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_v_u8m2x3(const uint8_t *rs1, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_v_u8m2x4(const uint8_t *rs1, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_v_u8m4x2(const uint8_t *rs1, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_v_u16mf4x2(const uint16_t *rs1, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_v_u16mf4x3(const uint16_t *rs1, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_v_u16mf4x4(const uint16_t *rs1, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_v_u16mf4x5(const uint16_t *rs1, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_v_u16mf4x6(const uint16_t *rs1, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_v_u16mf4x7(const uint16_t *rs1, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_v_u16mf4x8(const uint16_t *rs1, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_v_u16mf2x2(const uint16_t *rs1, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_v_u16mf2x3(const uint16_t *rs1, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_v_u16mf2x4(const uint16_t *rs1, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_v_u16mf2x5(const uint16_t *rs1, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_v_u16mf2x6(const uint16_t *rs1, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_v_u16mf2x7(const uint16_t *rs1, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_v_u16mf2x8(const uint16_t *rs1, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_v_u16m1x2(const uint16_t *rs1, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_v_u16m1x3(const uint16_t *rs1, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_v_u16m1x4(const uint16_t *rs1, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_v_u16m1x5(const uint16_t *rs1, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_v_u16m1x6(const uint16_t *rs1, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_v_u16m1x7(const uint16_t *rs1, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_v_u16m1x8(const uint16_t *rs1, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_v_u16m2x2(const uint16_t *rs1, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_v_u16m2x3(const uint16_t *rs1, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_v_u16m2x4(const uint16_t *rs1, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_v_u16m4x2(const uint16_t *rs1, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_v_u32mf2x2(const uint32_t *rs1, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_v_u32mf2x3(const uint32_t *rs1, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_v_u32mf2x4(const uint32_t *rs1, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_v_u32mf2x5(const uint32_t *rs1, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_v_u32mf2x6(const uint32_t *rs1, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_v_u32mf2x7(const uint32_t *rs1, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_v_u32mf2x8(const uint32_t *rs1, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_v_u32m1x2(const uint32_t *rs1, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_v_u32m1x3(const uint32_t *rs1, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_v_u32m1x4(const uint32_t *rs1, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_v_u32m1x5(const uint32_t *rs1, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_v_u32m1x6(const uint32_t *rs1, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_v_u32m1x7(const uint32_t *rs1, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_v_u32m1x8(const uint32_t *rs1, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_v_u32m2x2(const uint32_t *rs1, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_v_u32m2x3(const uint32_t *rs1, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_v_u32m2x4(const uint32_t *rs1, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_v_u32m4x2(const uint32_t *rs1, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_v_u64m1x2(const uint64_t *rs1, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_v_u64m1x3(const uint64_t *rs1, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_v_u64m1x4(const uint64_t *rs1, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_v_u64m1x5(const uint64_t *rs1, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_v_u64m1x6(const uint64_t *rs1, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_v_u64m1x7(const uint64_t *rs1, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_v_u64m1x8(const uint64_t *rs1, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_v_u64m2x2(const uint64_t *rs1, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_v_u64m2x3(const uint64_t *rs1, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_v_u64m2x4(const uint64_t *rs1, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_v_u64m4x2(const uint64_t *rs1, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_v_u8mf8x2(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_v_u8mf8x3(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_v_u8mf8x4(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_v_u8mf8x5(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_v_u8mf8x6(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_v_u8mf8x7(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_v_u8mf8x8(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_v_u8mf4x2(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_v_u8mf4x3(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_v_u8mf4x4(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_v_u8mf4x5(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_v_u8mf4x6(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_v_u8mf4x7(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_v_u8mf4x8(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_v_u8mf2x2(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_v_u8mf2x3(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_v_u8mf2x4(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_v_u8mf2x5(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_v_u8mf2x6(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_v_u8mf2x7(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_v_u8mf2x8(const uint8_t *rs1, size_t *new_vl,
                                           size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_v_u8m1x2(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_v_u8m1x3(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_v_u8m1x4(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_v_u8m1x5(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_v_u8m1x6(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_v_u8m1x7(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_v_u8m1x8(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_v_u8m2x2(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_v_u8m2x3(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_v_u8m2x4(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_v_u8m4x2(const uint8_t *rs1, size_t *new_vl,
                                         size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_v_u16mf4x2(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_v_u16mf4x3(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_v_u16mf4x4(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_v_u16mf4x5(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_v_u16mf4x6(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_v_u16mf4x7(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_v_u16mf4x8(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_v_u16mf2x2(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_v_u16mf2x3(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_v_u16mf2x4(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_v_u16mf2x5(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_v_u16mf2x6(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_v_u16mf2x7(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_v_u16mf2x8(const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_v_u16m1x2(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_v_u16m1x3(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_v_u16m1x4(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_v_u16m1x5(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_v_u16m1x6(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_v_u16m1x7(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_v_u16m1x8(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_v_u16m2x2(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_v_u16m2x3(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_v_u16m2x4(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_v_u16m4x2(const uint16_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_v_u32mf2x2(const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_v_u32mf2x3(const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_v_u32mf2x4(const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_v_u32mf2x5(const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_v_u32mf2x6(const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_v_u32mf2x7(const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_v_u32mf2x8(const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_v_u32m1x2(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_v_u32m1x3(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_v_u32m1x4(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_v_u32m1x5(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_v_u32m1x6(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_v_u32m1x7(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_v_u32m1x8(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_v_u32m2x2(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_v_u32m2x3(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_v_u32m2x4(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_v_u32m4x2(const uint32_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_v_u64m1x2(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_v_u64m1x3(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_v_u64m1x4(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_v_u64m1x5(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_v_u64m1x6(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_v_u64m1x7(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_v_u64m1x8(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_v_u64m2x2(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_v_u64m2x3(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_v_u64m2x4(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_v_u64m4x2(const uint64_t *rs1, size_t *new_vl,
                                            size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_v_f16mf4x2_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_v_f16mf4x3_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_v_f16mf4x4_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_v_f16mf4x5_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_v_f16mf4x6_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_v_f16mf4x7_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_v_f16mf4x8_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_v_f16mf2x2_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_v_f16mf2x3_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_v_f16mf2x4_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_v_f16mf2x5_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_v_f16mf2x6_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_v_f16mf2x7_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_v_f16mf2x8_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_v_f16m1x2_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_v_f16m1x3_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_v_f16m1x4_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_v_f16m1x5_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_v_f16m1x6_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_v_f16m1x7_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_v_f16m1x8_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_v_f16m2x2_m(vbool8_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_v_f16m2x3_m(vbool8_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_v_f16m2x4_m(vbool8_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_v_f16m4x2_m(vbool4_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32_v_f32mf2x2_m(vbool64_t vm, const float *rs1,
                                               size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_v_f32mf2x3_m(vbool64_t vm, const float *rs1,
                                               size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_v_f32mf2x4_m(vbool64_t vm, const float *rs1,
                                               size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_v_f32mf2x5_m(vbool64_t vm, const float *rs1,
                                               size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_v_f32mf2x6_m(vbool64_t vm, const float *rs1,
                                               size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_v_f32mf2x7_m(vbool64_t vm, const float *rs1,
                                               size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_v_f32mf2x8_m(vbool64_t vm, const float *rs1,
                                               size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                             size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                             size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                             size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                             size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                             size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                             size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                             size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                             size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                             size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                             size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                             size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                             size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                             size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                             size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                             size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                             size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                             size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                             size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                             size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                             size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                             size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                             size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_v_f16mf4x2_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_v_f16mf4x3_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_v_f16mf4x4_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_v_f16mf4x5_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_v_f16mf4x6_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_v_f16mf4x7_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_v_f16mf4x8_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_v_f16mf2x2_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_v_f16mf2x3_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_v_f16mf2x4_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_v_f16mf2x5_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_v_f16mf2x6_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_v_f16mf2x7_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_v_f16mf2x8_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_v_f16m1x2_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_v_f16m1x3_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_v_f16m1x4_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_v_f16m1x5_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_v_f16m1x6_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_v_f16m1x7_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_v_f16m1x8_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_v_f16m2x2_m(vbool8_t vm, const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_v_f16m2x3_m(vbool8_t vm, const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_v_f16m2x4_m(vbool8_t vm, const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_v_f16m4x2_m(vbool4_t vm, const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_v_f32mf2x2_m(vbool64_t vm, const float *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_v_f32mf2x3_m(vbool64_t vm, const float *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_v_f32mf2x4_m(vbool64_t vm, const float *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_v_f32mf2x5_m(vbool64_t vm, const float *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_v_f32mf2x6_m(vbool64_t vm, const float *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_v_f32mf2x7_m(vbool64_t vm, const float *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_v_f32mf2x8_m(vbool64_t vm, const float *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                               size_t *new_vl, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                          size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                          size_t vl);
vint8m1x2_t __riscv_vlseg2e8_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                        size_t vl);
vint8m1x3_t __riscv_vlseg3e8_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                        size_t vl);
vint8m1x4_t __riscv_vlseg4e8_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                        size_t vl);
vint8m1x5_t __riscv_vlseg5e8_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                        size_t vl);
vint8m1x6_t __riscv_vlseg6e8_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                        size_t vl);
vint8m1x7_t __riscv_vlseg7e8_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                        size_t vl);
vint8m1x8_t __riscv_vlseg8e8_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                        size_t vl);
vint8m2x2_t __riscv_vlseg2e8_v_i8m2x2_m(vbool4_t vm, const int8_t *rs1,
                                        size_t vl);
vint8m2x3_t __riscv_vlseg3e8_v_i8m2x3_m(vbool4_t vm, const int8_t *rs1,
                                        size_t vl);
vint8m2x4_t __riscv_vlseg4e8_v_i8m2x4_m(vbool4_t vm, const int8_t *rs1,
                                        size_t vl);
vint8m4x2_t __riscv_vlseg2e8_v_i8m4x2_m(vbool2_t vm, const int8_t *rs1,
                                        size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_v_i16mf4x2_m(vbool64_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_v_i16mf4x3_m(vbool64_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_v_i16mf4x4_m(vbool64_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_v_i16mf4x5_m(vbool64_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_v_i16mf4x6_m(vbool64_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_v_i16mf4x7_m(vbool64_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_v_i16mf4x8_m(vbool64_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_v_i16mf2x2_m(vbool32_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_v_i16mf2x3_m(vbool32_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_v_i16mf2x4_m(vbool32_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_v_i16mf2x5_m(vbool32_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_v_i16mf2x6_m(vbool32_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_v_i16mf2x7_m(vbool32_t vm, const int16_t *rs1,
                                             size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_v_i16mf2x8_m(vbool32_t vm, const int16_t *rs1,
                                             size_t vl);
vint16m1x2_t __riscv_vlseg2e16_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                           size_t vl);
vint16m1x3_t __riscv_vlseg3e16_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                           size_t vl);
vint16m1x4_t __riscv_vlseg4e16_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                           size_t vl);
vint16m1x5_t __riscv_vlseg5e16_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                           size_t vl);
vint16m1x6_t __riscv_vlseg6e16_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                           size_t vl);
vint16m1x7_t __riscv_vlseg7e16_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                           size_t vl);
vint16m1x8_t __riscv_vlseg8e16_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                           size_t vl);
vint16m2x2_t __riscv_vlseg2e16_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                           size_t vl);
vint16m2x3_t __riscv_vlseg3e16_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                           size_t vl);
vint16m2x4_t __riscv_vlseg4e16_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                           size_t vl);
vint16m4x2_t __riscv_vlseg2e16_v_i16m4x2_m(vbool4_t vm, const int16_t *rs1,
                                           size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_v_i32mf2x2_m(vbool64_t vm, const int32_t *rs1,
                                             size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_v_i32mf2x3_m(vbool64_t vm, const int32_t *rs1,
                                             size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_v_i32mf2x4_m(vbool64_t vm, const int32_t *rs1,
                                             size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_v_i32mf2x5_m(vbool64_t vm, const int32_t *rs1,
                                             size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_v_i32mf2x6_m(vbool64_t vm, const int32_t *rs1,
                                             size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_v_i32mf2x7_m(vbool64_t vm, const int32_t *rs1,
                                             size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_v_i32mf2x8_m(vbool64_t vm, const int32_t *rs1,
                                             size_t vl);
vint32m1x2_t __riscv_vlseg2e32_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                           size_t vl);
vint32m1x3_t __riscv_vlseg3e32_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                           size_t vl);
vint32m1x4_t __riscv_vlseg4e32_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                           size_t vl);
vint32m1x5_t __riscv_vlseg5e32_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                           size_t vl);
vint32m1x6_t __riscv_vlseg6e32_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                           size_t vl);
vint32m1x7_t __riscv_vlseg7e32_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                           size_t vl);
vint32m1x8_t __riscv_vlseg8e32_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                           size_t vl);
vint32m2x2_t __riscv_vlseg2e32_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                           size_t vl);
vint32m2x3_t __riscv_vlseg3e32_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                           size_t vl);
vint32m2x4_t __riscv_vlseg4e32_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                           size_t vl);
vint32m4x2_t __riscv_vlseg2e32_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                           size_t vl);
vint64m1x2_t __riscv_vlseg2e64_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                           size_t vl);
vint64m1x3_t __riscv_vlseg3e64_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                           size_t vl);
vint64m1x4_t __riscv_vlseg4e64_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                           size_t vl);
vint64m1x5_t __riscv_vlseg5e64_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                           size_t vl);
vint64m1x6_t __riscv_vlseg6e64_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                           size_t vl);
vint64m1x7_t __riscv_vlseg7e64_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                           size_t vl);
vint64m1x8_t __riscv_vlseg8e64_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                           size_t vl);
vint64m2x2_t __riscv_vlseg2e64_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                           size_t vl);
vint64m2x3_t __riscv_vlseg3e64_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                           size_t vl);
vint64m2x4_t __riscv_vlseg4e64_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                           size_t vl);
vint64m4x2_t __riscv_vlseg2e64_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                           size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                            size_t *new_vl, size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_v_i8m2x2_m(vbool4_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_v_i8m2x3_m(vbool4_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_v_i8m2x4_m(vbool4_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_v_i8m4x2_m(vbool2_t vm, const int8_t *rs1,
                                          size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_v_i16mf4x2_m(vbool64_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_v_i16mf4x3_m(vbool64_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_v_i16mf4x4_m(vbool64_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_v_i16mf4x5_m(vbool64_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_v_i16mf4x6_m(vbool64_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_v_i16mf4x7_m(vbool64_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_v_i16mf4x8_m(vbool64_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_v_i16mf2x2_m(vbool32_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_v_i16mf2x3_m(vbool32_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_v_i16mf2x4_m(vbool32_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_v_i16mf2x5_m(vbool32_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_v_i16mf2x6_m(vbool32_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_v_i16mf2x7_m(vbool32_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_v_i16mf2x8_m(vbool32_t vm, const int16_t *rs1,
                                               size_t *new_vl, size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_v_i16m4x2_m(vbool4_t vm, const int16_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_v_i32mf2x2_m(vbool64_t vm, const int32_t *rs1,
                                               size_t *new_vl, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_v_i32mf2x3_m(vbool64_t vm, const int32_t *rs1,
                                               size_t *new_vl, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_v_i32mf2x4_m(vbool64_t vm, const int32_t *rs1,
                                               size_t *new_vl, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_v_i32mf2x5_m(vbool64_t vm, const int32_t *rs1,
                                               size_t *new_vl, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_v_i32mf2x6_m(vbool64_t vm, const int32_t *rs1,
                                               size_t *new_vl, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_v_i32mf2x7_m(vbool64_t vm, const int32_t *rs1,
                                               size_t *new_vl, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_v_i32mf2x8_m(vbool64_t vm, const int32_t *rs1,
                                               size_t *new_vl, size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                           size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_v_u8m2x2_m(vbool4_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_v_u8m2x3_m(vbool4_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_v_u8m2x4_m(vbool4_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_v_u8m4x2_m(vbool2_t vm, const uint8_t *rs1,
                                         size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_v_u16mf4x2_m(vbool64_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_v_u16mf4x3_m(vbool64_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_v_u16mf4x4_m(vbool64_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_v_u16mf4x5_m(vbool64_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_v_u16mf4x6_m(vbool64_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_v_u16mf4x7_m(vbool64_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_v_u16mf4x8_m(vbool64_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_v_u16mf2x2_m(vbool32_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_v_u16mf2x3_m(vbool32_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_v_u16mf2x4_m(vbool32_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_v_u16mf2x5_m(vbool32_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_v_u16mf2x6_m(vbool32_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_v_u16mf2x7_m(vbool32_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_v_u16mf2x8_m(vbool32_t vm, const uint16_t *rs1,
                                              size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_v_u16m1x2_m(vbool16_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_v_u16m1x3_m(vbool16_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_v_u16m1x4_m(vbool16_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_v_u16m1x5_m(vbool16_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_v_u16m1x6_m(vbool16_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_v_u16m1x7_m(vbool16_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_v_u16m1x8_m(vbool16_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_v_u16m4x2_m(vbool4_t vm, const uint16_t *rs1,
                                            size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_v_u32mf2x2_m(vbool64_t vm, const uint32_t *rs1,
                                              size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_v_u32mf2x3_m(vbool64_t vm, const uint32_t *rs1,
                                              size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_v_u32mf2x4_m(vbool64_t vm, const uint32_t *rs1,
                                              size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_v_u32mf2x5_m(vbool64_t vm, const uint32_t *rs1,
                                              size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_v_u32mf2x6_m(vbool64_t vm, const uint32_t *rs1,
                                              size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_v_u32mf2x7_m(vbool64_t vm, const uint32_t *rs1,
                                              size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_v_u32mf2x8_m(vbool64_t vm, const uint32_t *rs1,
                                              size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_v_u32m1x2_m(vbool32_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_v_u32m1x3_m(vbool32_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_v_u32m1x4_m(vbool32_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_v_u32m1x5_m(vbool32_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_v_u32m1x6_m(vbool32_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_v_u32m1x7_m(vbool32_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_v_u32m1x8_m(vbool32_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_v_u32m2x2_m(vbool16_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_v_u32m2x3_m(vbool16_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_v_u32m2x4_m(vbool16_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                            size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_v_u64m1x2_m(vbool64_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_v_u64m1x3_m(vbool64_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_v_u64m1x4_m(vbool64_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_v_u64m1x5_m(vbool64_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_v_u64m1x6_m(vbool64_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_v_u64m1x7_m(vbool64_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_v_u64m1x8_m(vbool64_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_v_u64m2x2_m(vbool32_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_v_u64m2x3_m(vbool32_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_v_u64m2x4_m(vbool32_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_v_u64m4x2_m(vbool16_t vm, const uint64_t *rs1,
                                            size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                             size_t *new_vl, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_v_u8m2x2_m(vbool4_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_v_u8m2x3_m(vbool4_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_v_u8m2x4_m(vbool4_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_v_u8m4x2_m(vbool2_t vm, const uint8_t *rs1,
                                           size_t *new_vl, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_v_u16mf4x2_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_v_u16mf4x3_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_v_u16mf4x4_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_v_u16mf4x5_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_v_u16mf4x6_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_v_u16mf4x7_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_v_u16mf4x8_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_v_u16mf2x2_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_v_u16mf2x3_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_v_u16mf2x4_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_v_u16mf2x5_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_v_u16mf2x6_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_v_u16mf2x7_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_v_u16mf2x8_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_v_u16m1x2_m(vbool16_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_v_u16m1x3_m(vbool16_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_v_u16m1x4_m(vbool16_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_v_u16m1x5_m(vbool16_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_v_u16m1x6_m(vbool16_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_v_u16m1x7_m(vbool16_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_v_u16m1x8_m(vbool16_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_v_u16m4x2_m(vbool4_t vm, const uint16_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_v_u32mf2x2_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_v_u32mf2x3_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_v_u32mf2x4_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_v_u32mf2x5_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_v_u32mf2x6_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_v_u32mf2x7_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_v_u32mf2x8_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_v_u32m1x2_m(vbool32_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_v_u32m1x3_m(vbool32_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_v_u32m1x4_m(vbool32_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_v_u32m1x5_m(vbool32_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_v_u32m1x6_m(vbool32_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_v_u32m1x7_m(vbool32_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_v_u32m1x8_m(vbool32_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_v_u32m2x2_m(vbool16_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_v_u32m2x3_m(vbool16_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_v_u32m2x4_m(vbool16_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_v_u64m1x2_m(vbool64_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_v_u64m1x3_m(vbool64_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_v_u64m1x4_m(vbool64_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_v_u64m1x5_m(vbool64_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_v_u64m1x6_m(vbool64_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_v_u64m1x7_m(vbool64_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_v_u64m1x8_m(vbool64_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_v_u64m2x2_m(vbool32_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_v_u64m2x3_m(vbool32_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_v_u64m2x4_m(vbool32_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_v_u64m4x2_m(vbool16_t vm, const uint64_t *rs1,
                                              size_t *new_vl, size_t vl);
----

[[vecrtor-unit-stride-segment-store]]
==== Vector Unit-Stride Segment Store Intrinsics

[,c]
----
void __riscv_vsseg2e16_v_f16mf4x2(_Float16 *rs1, vfloat16mf4x2_t vs3,
                                  size_t vl);
void __riscv_vsseg3e16_v_f16mf4x3(_Float16 *rs1, vfloat16mf4x3_t vs3,
                                  size_t vl);
void __riscv_vsseg4e16_v_f16mf4x4(_Float16 *rs1, vfloat16mf4x4_t vs3,
                                  size_t vl);
void __riscv_vsseg5e16_v_f16mf4x5(_Float16 *rs1, vfloat16mf4x5_t vs3,
                                  size_t vl);
void __riscv_vsseg6e16_v_f16mf4x6(_Float16 *rs1, vfloat16mf4x6_t vs3,
                                  size_t vl);
void __riscv_vsseg7e16_v_f16mf4x7(_Float16 *rs1, vfloat16mf4x7_t vs3,
                                  size_t vl);
void __riscv_vsseg8e16_v_f16mf4x8(_Float16 *rs1, vfloat16mf4x8_t vs3,
                                  size_t vl);
void __riscv_vsseg2e16_v_f16mf2x2(_Float16 *rs1, vfloat16mf2x2_t vs3,
                                  size_t vl);
void __riscv_vsseg3e16_v_f16mf2x3(_Float16 *rs1, vfloat16mf2x3_t vs3,
                                  size_t vl);
void __riscv_vsseg4e16_v_f16mf2x4(_Float16 *rs1, vfloat16mf2x4_t vs3,
                                  size_t vl);
void __riscv_vsseg5e16_v_f16mf2x5(_Float16 *rs1, vfloat16mf2x5_t vs3,
                                  size_t vl);
void __riscv_vsseg6e16_v_f16mf2x6(_Float16 *rs1, vfloat16mf2x6_t vs3,
                                  size_t vl);
void __riscv_vsseg7e16_v_f16mf2x7(_Float16 *rs1, vfloat16mf2x7_t vs3,
                                  size_t vl);
void __riscv_vsseg8e16_v_f16mf2x8(_Float16 *rs1, vfloat16mf2x8_t vs3,
                                  size_t vl);
void __riscv_vsseg2e16_v_f16m1x2(_Float16 *rs1, vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16m1x3(_Float16 *rs1, vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16m1x4(_Float16 *rs1, vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_f16m1x5(_Float16 *rs1, vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_f16m1x6(_Float16 *rs1, vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_f16m1x7(_Float16 *rs1, vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_f16m1x8(_Float16 *rs1, vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16m2x2(_Float16 *rs1, vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16m2x3(_Float16 *rs1, vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16m2x4(_Float16 *rs1, vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16m4x2(_Float16 *rs1, vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsseg2e32_v_f32mf2x2(float *rs1, vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_f32mf2x3(float *rs1, vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_f32mf2x4(float *rs1, vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e32_v_f32mf2x5(float *rs1, vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e32_v_f32mf2x6(float *rs1, vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e32_v_f32mf2x7(float *rs1, vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e32_v_f32mf2x8(float *rs1, vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e32_v_f32m1x2(float *rs1, vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_f32m1x3(float *rs1, vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_f32m1x4(float *rs1, vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsseg5e32_v_f32m1x5(float *rs1, vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsseg6e32_v_f32m1x6(float *rs1, vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsseg7e32_v_f32m1x7(float *rs1, vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsseg8e32_v_f32m1x8(float *rs1, vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsseg2e32_v_f32m2x2(float *rs1, vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_f32m2x3(float *rs1, vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_f32m2x4(float *rs1, vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsseg2e32_v_f32m4x2(float *rs1, vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsseg2e64_v_f64m1x2(double *rs1, vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsseg3e64_v_f64m1x3(double *rs1, vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsseg4e64_v_f64m1x4(double *rs1, vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsseg5e64_v_f64m1x5(double *rs1, vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsseg6e64_v_f64m1x6(double *rs1, vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsseg7e64_v_f64m1x7(double *rs1, vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsseg8e64_v_f64m1x8(double *rs1, vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsseg2e64_v_f64m2x2(double *rs1, vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsseg3e64_v_f64m2x3(double *rs1, vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsseg4e64_v_f64m2x4(double *rs1, vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsseg2e64_v_f64m4x2(double *rs1, vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsseg2e8_v_i8mf8x2(int8_t *rs1, vint8mf8x2_t vs3, size_t vl);
void __riscv_vsseg3e8_v_i8mf8x3(int8_t *rs1, vint8mf8x3_t vs3, size_t vl);
void __riscv_vsseg4e8_v_i8mf8x4(int8_t *rs1, vint8mf8x4_t vs3, size_t vl);
void __riscv_vsseg5e8_v_i8mf8x5(int8_t *rs1, vint8mf8x5_t vs3, size_t vl);
void __riscv_vsseg6e8_v_i8mf8x6(int8_t *rs1, vint8mf8x6_t vs3, size_t vl);
void __riscv_vsseg7e8_v_i8mf8x7(int8_t *rs1, vint8mf8x7_t vs3, size_t vl);
void __riscv_vsseg8e8_v_i8mf8x8(int8_t *rs1, vint8mf8x8_t vs3, size_t vl);
void __riscv_vsseg2e8_v_i8mf4x2(int8_t *rs1, vint8mf4x2_t vs3, size_t vl);
void __riscv_vsseg3e8_v_i8mf4x3(int8_t *rs1, vint8mf4x3_t vs3, size_t vl);
void __riscv_vsseg4e8_v_i8mf4x4(int8_t *rs1, vint8mf4x4_t vs3, size_t vl);
void __riscv_vsseg5e8_v_i8mf4x5(int8_t *rs1, vint8mf4x5_t vs3, size_t vl);
void __riscv_vsseg6e8_v_i8mf4x6(int8_t *rs1, vint8mf4x6_t vs3, size_t vl);
void __riscv_vsseg7e8_v_i8mf4x7(int8_t *rs1, vint8mf4x7_t vs3, size_t vl);
void __riscv_vsseg8e8_v_i8mf4x8(int8_t *rs1, vint8mf4x8_t vs3, size_t vl);
void __riscv_vsseg2e8_v_i8mf2x2(int8_t *rs1, vint8mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e8_v_i8mf2x3(int8_t *rs1, vint8mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e8_v_i8mf2x4(int8_t *rs1, vint8mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e8_v_i8mf2x5(int8_t *rs1, vint8mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e8_v_i8mf2x6(int8_t *rs1, vint8mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e8_v_i8mf2x7(int8_t *rs1, vint8mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e8_v_i8mf2x8(int8_t *rs1, vint8mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e8_v_i8m1x2(int8_t *rs1, vint8m1x2_t vs3, size_t vl);
void __riscv_vsseg3e8_v_i8m1x3(int8_t *rs1, vint8m1x3_t vs3, size_t vl);
void __riscv_vsseg4e8_v_i8m1x4(int8_t *rs1, vint8m1x4_t vs3, size_t vl);
void __riscv_vsseg5e8_v_i8m1x5(int8_t *rs1, vint8m1x5_t vs3, size_t vl);
void __riscv_vsseg6e8_v_i8m1x6(int8_t *rs1, vint8m1x6_t vs3, size_t vl);
void __riscv_vsseg7e8_v_i8m1x7(int8_t *rs1, vint8m1x7_t vs3, size_t vl);
void __riscv_vsseg8e8_v_i8m1x8(int8_t *rs1, vint8m1x8_t vs3, size_t vl);
void __riscv_vsseg2e8_v_i8m2x2(int8_t *rs1, vint8m2x2_t vs3, size_t vl);
void __riscv_vsseg3e8_v_i8m2x3(int8_t *rs1, vint8m2x3_t vs3, size_t vl);
void __riscv_vsseg4e8_v_i8m2x4(int8_t *rs1, vint8m2x4_t vs3, size_t vl);
void __riscv_vsseg2e8_v_i8m4x2(int8_t *rs1, vint8m4x2_t vs3, size_t vl);
void __riscv_vsseg2e16_v_i16mf4x2(int16_t *rs1, vint16mf4x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_i16mf4x3(int16_t *rs1, vint16mf4x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_i16mf4x4(int16_t *rs1, vint16mf4x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_i16mf4x5(int16_t *rs1, vint16mf4x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_i16mf4x6(int16_t *rs1, vint16mf4x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_i16mf4x7(int16_t *rs1, vint16mf4x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_i16mf4x8(int16_t *rs1, vint16mf4x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_i16mf2x2(int16_t *rs1, vint16mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_i16mf2x3(int16_t *rs1, vint16mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_i16mf2x4(int16_t *rs1, vint16mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_i16mf2x5(int16_t *rs1, vint16mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_i16mf2x6(int16_t *rs1, vint16mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_i16mf2x7(int16_t *rs1, vint16mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_i16mf2x8(int16_t *rs1, vint16mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_i16m1x2(int16_t *rs1, vint16m1x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_i16m1x3(int16_t *rs1, vint16m1x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_i16m1x4(int16_t *rs1, vint16m1x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_i16m1x5(int16_t *rs1, vint16m1x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_i16m1x6(int16_t *rs1, vint16m1x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_i16m1x7(int16_t *rs1, vint16m1x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_i16m1x8(int16_t *rs1, vint16m1x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_i16m2x2(int16_t *rs1, vint16m2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_i16m2x3(int16_t *rs1, vint16m2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_i16m2x4(int16_t *rs1, vint16m2x4_t vs3, size_t vl);
void __riscv_vsseg2e16_v_i16m4x2(int16_t *rs1, vint16m4x2_t vs3, size_t vl);
void __riscv_vsseg2e32_v_i32mf2x2(int32_t *rs1, vint32mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_i32mf2x3(int32_t *rs1, vint32mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_i32mf2x4(int32_t *rs1, vint32mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e32_v_i32mf2x5(int32_t *rs1, vint32mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e32_v_i32mf2x6(int32_t *rs1, vint32mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e32_v_i32mf2x7(int32_t *rs1, vint32mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e32_v_i32mf2x8(int32_t *rs1, vint32mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e32_v_i32m1x2(int32_t *rs1, vint32m1x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_i32m1x3(int32_t *rs1, vint32m1x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_i32m1x4(int32_t *rs1, vint32m1x4_t vs3, size_t vl);
void __riscv_vsseg5e32_v_i32m1x5(int32_t *rs1, vint32m1x5_t vs3, size_t vl);
void __riscv_vsseg6e32_v_i32m1x6(int32_t *rs1, vint32m1x6_t vs3, size_t vl);
void __riscv_vsseg7e32_v_i32m1x7(int32_t *rs1, vint32m1x7_t vs3, size_t vl);
void __riscv_vsseg8e32_v_i32m1x8(int32_t *rs1, vint32m1x8_t vs3, size_t vl);
void __riscv_vsseg2e32_v_i32m2x2(int32_t *rs1, vint32m2x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_i32m2x3(int32_t *rs1, vint32m2x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_i32m2x4(int32_t *rs1, vint32m2x4_t vs3, size_t vl);
void __riscv_vsseg2e32_v_i32m4x2(int32_t *rs1, vint32m4x2_t vs3, size_t vl);
void __riscv_vsseg2e64_v_i64m1x2(int64_t *rs1, vint64m1x2_t vs3, size_t vl);
void __riscv_vsseg3e64_v_i64m1x3(int64_t *rs1, vint64m1x3_t vs3, size_t vl);
void __riscv_vsseg4e64_v_i64m1x4(int64_t *rs1, vint64m1x4_t vs3, size_t vl);
void __riscv_vsseg5e64_v_i64m1x5(int64_t *rs1, vint64m1x5_t vs3, size_t vl);
void __riscv_vsseg6e64_v_i64m1x6(int64_t *rs1, vint64m1x6_t vs3, size_t vl);
void __riscv_vsseg7e64_v_i64m1x7(int64_t *rs1, vint64m1x7_t vs3, size_t vl);
void __riscv_vsseg8e64_v_i64m1x8(int64_t *rs1, vint64m1x8_t vs3, size_t vl);
void __riscv_vsseg2e64_v_i64m2x2(int64_t *rs1, vint64m2x2_t vs3, size_t vl);
void __riscv_vsseg3e64_v_i64m2x3(int64_t *rs1, vint64m2x3_t vs3, size_t vl);
void __riscv_vsseg4e64_v_i64m2x4(int64_t *rs1, vint64m2x4_t vs3, size_t vl);
void __riscv_vsseg2e64_v_i64m4x2(int64_t *rs1, vint64m4x2_t vs3, size_t vl);
void __riscv_vsseg2e8_v_u8mf8x2(uint8_t *rs1, vuint8mf8x2_t vs3, size_t vl);
void __riscv_vsseg3e8_v_u8mf8x3(uint8_t *rs1, vuint8mf8x3_t vs3, size_t vl);
void __riscv_vsseg4e8_v_u8mf8x4(uint8_t *rs1, vuint8mf8x4_t vs3, size_t vl);
void __riscv_vsseg5e8_v_u8mf8x5(uint8_t *rs1, vuint8mf8x5_t vs3, size_t vl);
void __riscv_vsseg6e8_v_u8mf8x6(uint8_t *rs1, vuint8mf8x6_t vs3, size_t vl);
void __riscv_vsseg7e8_v_u8mf8x7(uint8_t *rs1, vuint8mf8x7_t vs3, size_t vl);
void __riscv_vsseg8e8_v_u8mf8x8(uint8_t *rs1, vuint8mf8x8_t vs3, size_t vl);
void __riscv_vsseg2e8_v_u8mf4x2(uint8_t *rs1, vuint8mf4x2_t vs3, size_t vl);
void __riscv_vsseg3e8_v_u8mf4x3(uint8_t *rs1, vuint8mf4x3_t vs3, size_t vl);
void __riscv_vsseg4e8_v_u8mf4x4(uint8_t *rs1, vuint8mf4x4_t vs3, size_t vl);
void __riscv_vsseg5e8_v_u8mf4x5(uint8_t *rs1, vuint8mf4x5_t vs3, size_t vl);
void __riscv_vsseg6e8_v_u8mf4x6(uint8_t *rs1, vuint8mf4x6_t vs3, size_t vl);
void __riscv_vsseg7e8_v_u8mf4x7(uint8_t *rs1, vuint8mf4x7_t vs3, size_t vl);
void __riscv_vsseg8e8_v_u8mf4x8(uint8_t *rs1, vuint8mf4x8_t vs3, size_t vl);
void __riscv_vsseg2e8_v_u8mf2x2(uint8_t *rs1, vuint8mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e8_v_u8mf2x3(uint8_t *rs1, vuint8mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e8_v_u8mf2x4(uint8_t *rs1, vuint8mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e8_v_u8mf2x5(uint8_t *rs1, vuint8mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e8_v_u8mf2x6(uint8_t *rs1, vuint8mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e8_v_u8mf2x7(uint8_t *rs1, vuint8mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e8_v_u8mf2x8(uint8_t *rs1, vuint8mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e8_v_u8m1x2(uint8_t *rs1, vuint8m1x2_t vs3, size_t vl);
void __riscv_vsseg3e8_v_u8m1x3(uint8_t *rs1, vuint8m1x3_t vs3, size_t vl);
void __riscv_vsseg4e8_v_u8m1x4(uint8_t *rs1, vuint8m1x4_t vs3, size_t vl);
void __riscv_vsseg5e8_v_u8m1x5(uint8_t *rs1, vuint8m1x5_t vs3, size_t vl);
void __riscv_vsseg6e8_v_u8m1x6(uint8_t *rs1, vuint8m1x6_t vs3, size_t vl);
void __riscv_vsseg7e8_v_u8m1x7(uint8_t *rs1, vuint8m1x7_t vs3, size_t vl);
void __riscv_vsseg8e8_v_u8m1x8(uint8_t *rs1, vuint8m1x8_t vs3, size_t vl);
void __riscv_vsseg2e8_v_u8m2x2(uint8_t *rs1, vuint8m2x2_t vs3, size_t vl);
void __riscv_vsseg3e8_v_u8m2x3(uint8_t *rs1, vuint8m2x3_t vs3, size_t vl);
void __riscv_vsseg4e8_v_u8m2x4(uint8_t *rs1, vuint8m2x4_t vs3, size_t vl);
void __riscv_vsseg2e8_v_u8m4x2(uint8_t *rs1, vuint8m4x2_t vs3, size_t vl);
void __riscv_vsseg2e16_v_u16mf4x2(uint16_t *rs1, vuint16mf4x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_u16mf4x3(uint16_t *rs1, vuint16mf4x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_u16mf4x4(uint16_t *rs1, vuint16mf4x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_u16mf4x5(uint16_t *rs1, vuint16mf4x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_u16mf4x6(uint16_t *rs1, vuint16mf4x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_u16mf4x7(uint16_t *rs1, vuint16mf4x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_u16mf4x8(uint16_t *rs1, vuint16mf4x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_u16mf2x2(uint16_t *rs1, vuint16mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_u16mf2x3(uint16_t *rs1, vuint16mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_u16mf2x4(uint16_t *rs1, vuint16mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_u16mf2x5(uint16_t *rs1, vuint16mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_u16mf2x6(uint16_t *rs1, vuint16mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_u16mf2x7(uint16_t *rs1, vuint16mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_u16mf2x8(uint16_t *rs1, vuint16mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_u16m1x2(uint16_t *rs1, vuint16m1x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_u16m1x3(uint16_t *rs1, vuint16m1x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_u16m1x4(uint16_t *rs1, vuint16m1x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_u16m1x5(uint16_t *rs1, vuint16m1x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_u16m1x6(uint16_t *rs1, vuint16m1x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_u16m1x7(uint16_t *rs1, vuint16m1x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_u16m1x8(uint16_t *rs1, vuint16m1x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_u16m2x2(uint16_t *rs1, vuint16m2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_u16m2x3(uint16_t *rs1, vuint16m2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_u16m2x4(uint16_t *rs1, vuint16m2x4_t vs3, size_t vl);
void __riscv_vsseg2e16_v_u16m4x2(uint16_t *rs1, vuint16m4x2_t vs3, size_t vl);
void __riscv_vsseg2e32_v_u32mf2x2(uint32_t *rs1, vuint32mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_u32mf2x3(uint32_t *rs1, vuint32mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_u32mf2x4(uint32_t *rs1, vuint32mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e32_v_u32mf2x5(uint32_t *rs1, vuint32mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e32_v_u32mf2x6(uint32_t *rs1, vuint32mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e32_v_u32mf2x7(uint32_t *rs1, vuint32mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e32_v_u32mf2x8(uint32_t *rs1, vuint32mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e32_v_u32m1x2(uint32_t *rs1, vuint32m1x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_u32m1x3(uint32_t *rs1, vuint32m1x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_u32m1x4(uint32_t *rs1, vuint32m1x4_t vs3, size_t vl);
void __riscv_vsseg5e32_v_u32m1x5(uint32_t *rs1, vuint32m1x5_t vs3, size_t vl);
void __riscv_vsseg6e32_v_u32m1x6(uint32_t *rs1, vuint32m1x6_t vs3, size_t vl);
void __riscv_vsseg7e32_v_u32m1x7(uint32_t *rs1, vuint32m1x7_t vs3, size_t vl);
void __riscv_vsseg8e32_v_u32m1x8(uint32_t *rs1, vuint32m1x8_t vs3, size_t vl);
void __riscv_vsseg2e32_v_u32m2x2(uint32_t *rs1, vuint32m2x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_u32m2x3(uint32_t *rs1, vuint32m2x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_u32m2x4(uint32_t *rs1, vuint32m2x4_t vs3, size_t vl);
void __riscv_vsseg2e32_v_u32m4x2(uint32_t *rs1, vuint32m4x2_t vs3, size_t vl);
void __riscv_vsseg2e64_v_u64m1x2(uint64_t *rs1, vuint64m1x2_t vs3, size_t vl);
void __riscv_vsseg3e64_v_u64m1x3(uint64_t *rs1, vuint64m1x3_t vs3, size_t vl);
void __riscv_vsseg4e64_v_u64m1x4(uint64_t *rs1, vuint64m1x4_t vs3, size_t vl);
void __riscv_vsseg5e64_v_u64m1x5(uint64_t *rs1, vuint64m1x5_t vs3, size_t vl);
void __riscv_vsseg6e64_v_u64m1x6(uint64_t *rs1, vuint64m1x6_t vs3, size_t vl);
void __riscv_vsseg7e64_v_u64m1x7(uint64_t *rs1, vuint64m1x7_t vs3, size_t vl);
void __riscv_vsseg8e64_v_u64m1x8(uint64_t *rs1, vuint64m1x8_t vs3, size_t vl);
void __riscv_vsseg2e64_v_u64m2x2(uint64_t *rs1, vuint64m2x2_t vs3, size_t vl);
void __riscv_vsseg3e64_v_u64m2x3(uint64_t *rs1, vuint64m2x3_t vs3, size_t vl);
void __riscv_vsseg4e64_v_u64m2x4(uint64_t *rs1, vuint64m2x4_t vs3, size_t vl);
void __riscv_vsseg2e64_v_u64m4x2(uint64_t *rs1, vuint64m4x2_t vs3, size_t vl);
// masked functions
void __riscv_vsseg2e16_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1,
                                   vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1,
                                   vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1,
                                   vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1,
                                   vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsseg2e32_v_f32mf2x2_m(vbool64_t vm, float *rs1,
                                    vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_f32mf2x3_m(vbool64_t vm, float *rs1,
                                    vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_f32mf2x4_m(vbool64_t vm, float *rs1,
                                    vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e32_v_f32mf2x5_m(vbool64_t vm, float *rs1,
                                    vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e32_v_f32mf2x6_m(vbool64_t vm, float *rs1,
                                    vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e32_v_f32mf2x7_m(vbool64_t vm, float *rs1,
                                    vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e32_v_f32mf2x8_m(vbool64_t vm, float *rs1,
                                    vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e32_v_f32m1x2_m(vbool32_t vm, float *rs1, vfloat32m1x2_t vs3,
                                   size_t vl);
void __riscv_vsseg3e32_v_f32m1x3_m(vbool32_t vm, float *rs1, vfloat32m1x3_t vs3,
                                   size_t vl);
void __riscv_vsseg4e32_v_f32m1x4_m(vbool32_t vm, float *rs1, vfloat32m1x4_t vs3,
                                   size_t vl);
void __riscv_vsseg5e32_v_f32m1x5_m(vbool32_t vm, float *rs1, vfloat32m1x5_t vs3,
                                   size_t vl);
void __riscv_vsseg6e32_v_f32m1x6_m(vbool32_t vm, float *rs1, vfloat32m1x6_t vs3,
                                   size_t vl);
void __riscv_vsseg7e32_v_f32m1x7_m(vbool32_t vm, float *rs1, vfloat32m1x7_t vs3,
                                   size_t vl);
void __riscv_vsseg8e32_v_f32m1x8_m(vbool32_t vm, float *rs1, vfloat32m1x8_t vs3,
                                   size_t vl);
void __riscv_vsseg2e32_v_f32m2x2_m(vbool16_t vm, float *rs1, vfloat32m2x2_t vs3,
                                   size_t vl);
void __riscv_vsseg3e32_v_f32m2x3_m(vbool16_t vm, float *rs1, vfloat32m2x3_t vs3,
                                   size_t vl);
void __riscv_vsseg4e32_v_f32m2x4_m(vbool16_t vm, float *rs1, vfloat32m2x4_t vs3,
                                   size_t vl);
void __riscv_vsseg2e32_v_f32m4x2_m(vbool8_t vm, float *rs1, vfloat32m4x2_t vs3,
                                   size_t vl);
void __riscv_vsseg2e64_v_f64m1x2_m(vbool64_t vm, double *rs1,
                                   vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsseg3e64_v_f64m1x3_m(vbool64_t vm, double *rs1,
                                   vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsseg4e64_v_f64m1x4_m(vbool64_t vm, double *rs1,
                                   vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsseg5e64_v_f64m1x5_m(vbool64_t vm, double *rs1,
                                   vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsseg6e64_v_f64m1x6_m(vbool64_t vm, double *rs1,
                                   vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsseg7e64_v_f64m1x7_m(vbool64_t vm, double *rs1,
                                   vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsseg8e64_v_f64m1x8_m(vbool64_t vm, double *rs1,
                                   vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsseg2e64_v_f64m2x2_m(vbool32_t vm, double *rs1,
                                   vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsseg3e64_v_f64m2x3_m(vbool32_t vm, double *rs1,
                                   vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsseg4e64_v_f64m2x4_m(vbool32_t vm, double *rs1,
                                   vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsseg2e64_v_f64m4x2_m(vbool16_t vm, double *rs1,
                                   vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsseg2e8_v_i8mf8x2_m(vbool64_t vm, int8_t *rs1, vint8mf8x2_t vs3,
                                  size_t vl);
void __riscv_vsseg3e8_v_i8mf8x3_m(vbool64_t vm, int8_t *rs1, vint8mf8x3_t vs3,
                                  size_t vl);
void __riscv_vsseg4e8_v_i8mf8x4_m(vbool64_t vm, int8_t *rs1, vint8mf8x4_t vs3,
                                  size_t vl);
void __riscv_vsseg5e8_v_i8mf8x5_m(vbool64_t vm, int8_t *rs1, vint8mf8x5_t vs3,
                                  size_t vl);
void __riscv_vsseg6e8_v_i8mf8x6_m(vbool64_t vm, int8_t *rs1, vint8mf8x6_t vs3,
                                  size_t vl);
void __riscv_vsseg7e8_v_i8mf8x7_m(vbool64_t vm, int8_t *rs1, vint8mf8x7_t vs3,
                                  size_t vl);
void __riscv_vsseg8e8_v_i8mf8x8_m(vbool64_t vm, int8_t *rs1, vint8mf8x8_t vs3,
                                  size_t vl);
void __riscv_vsseg2e8_v_i8mf4x2_m(vbool32_t vm, int8_t *rs1, vint8mf4x2_t vs3,
                                  size_t vl);
void __riscv_vsseg3e8_v_i8mf4x3_m(vbool32_t vm, int8_t *rs1, vint8mf4x3_t vs3,
                                  size_t vl);
void __riscv_vsseg4e8_v_i8mf4x4_m(vbool32_t vm, int8_t *rs1, vint8mf4x4_t vs3,
                                  size_t vl);
void __riscv_vsseg5e8_v_i8mf4x5_m(vbool32_t vm, int8_t *rs1, vint8mf4x5_t vs3,
                                  size_t vl);
void __riscv_vsseg6e8_v_i8mf4x6_m(vbool32_t vm, int8_t *rs1, vint8mf4x6_t vs3,
                                  size_t vl);
void __riscv_vsseg7e8_v_i8mf4x7_m(vbool32_t vm, int8_t *rs1, vint8mf4x7_t vs3,
                                  size_t vl);
void __riscv_vsseg8e8_v_i8mf4x8_m(vbool32_t vm, int8_t *rs1, vint8mf4x8_t vs3,
                                  size_t vl);
void __riscv_vsseg2e8_v_i8mf2x2_m(vbool16_t vm, int8_t *rs1, vint8mf2x2_t vs3,
                                  size_t vl);
void __riscv_vsseg3e8_v_i8mf2x3_m(vbool16_t vm, int8_t *rs1, vint8mf2x3_t vs3,
                                  size_t vl);
void __riscv_vsseg4e8_v_i8mf2x4_m(vbool16_t vm, int8_t *rs1, vint8mf2x4_t vs3,
                                  size_t vl);
void __riscv_vsseg5e8_v_i8mf2x5_m(vbool16_t vm, int8_t *rs1, vint8mf2x5_t vs3,
                                  size_t vl);
void __riscv_vsseg6e8_v_i8mf2x6_m(vbool16_t vm, int8_t *rs1, vint8mf2x6_t vs3,
                                  size_t vl);
void __riscv_vsseg7e8_v_i8mf2x7_m(vbool16_t vm, int8_t *rs1, vint8mf2x7_t vs3,
                                  size_t vl);
void __riscv_vsseg8e8_v_i8mf2x8_m(vbool16_t vm, int8_t *rs1, vint8mf2x8_t vs3,
                                  size_t vl);
void __riscv_vsseg2e8_v_i8m1x2_m(vbool8_t vm, int8_t *rs1, vint8m1x2_t vs3,
                                 size_t vl);
void __riscv_vsseg3e8_v_i8m1x3_m(vbool8_t vm, int8_t *rs1, vint8m1x3_t vs3,
                                 size_t vl);
void __riscv_vsseg4e8_v_i8m1x4_m(vbool8_t vm, int8_t *rs1, vint8m1x4_t vs3,
                                 size_t vl);
void __riscv_vsseg5e8_v_i8m1x5_m(vbool8_t vm, int8_t *rs1, vint8m1x5_t vs3,
                                 size_t vl);
void __riscv_vsseg6e8_v_i8m1x6_m(vbool8_t vm, int8_t *rs1, vint8m1x6_t vs3,
                                 size_t vl);
void __riscv_vsseg7e8_v_i8m1x7_m(vbool8_t vm, int8_t *rs1, vint8m1x7_t vs3,
                                 size_t vl);
void __riscv_vsseg8e8_v_i8m1x8_m(vbool8_t vm, int8_t *rs1, vint8m1x8_t vs3,
                                 size_t vl);
void __riscv_vsseg2e8_v_i8m2x2_m(vbool4_t vm, int8_t *rs1, vint8m2x2_t vs3,
                                 size_t vl);
void __riscv_vsseg3e8_v_i8m2x3_m(vbool4_t vm, int8_t *rs1, vint8m2x3_t vs3,
                                 size_t vl);
void __riscv_vsseg4e8_v_i8m2x4_m(vbool4_t vm, int8_t *rs1, vint8m2x4_t vs3,
                                 size_t vl);
void __riscv_vsseg2e8_v_i8m4x2_m(vbool2_t vm, int8_t *rs1, vint8m4x2_t vs3,
                                 size_t vl);
void __riscv_vsseg2e16_v_i16mf4x2_m(vbool64_t vm, int16_t *rs1,
                                    vint16mf4x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_i16mf4x3_m(vbool64_t vm, int16_t *rs1,
                                    vint16mf4x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_i16mf4x4_m(vbool64_t vm, int16_t *rs1,
                                    vint16mf4x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_i16mf4x5_m(vbool64_t vm, int16_t *rs1,
                                    vint16mf4x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_i16mf4x6_m(vbool64_t vm, int16_t *rs1,
                                    vint16mf4x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_i16mf4x7_m(vbool64_t vm, int16_t *rs1,
                                    vint16mf4x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_i16mf4x8_m(vbool64_t vm, int16_t *rs1,
                                    vint16mf4x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_i16mf2x2_m(vbool32_t vm, int16_t *rs1,
                                    vint16mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_i16mf2x3_m(vbool32_t vm, int16_t *rs1,
                                    vint16mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_i16mf2x4_m(vbool32_t vm, int16_t *rs1,
                                    vint16mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_i16mf2x5_m(vbool32_t vm, int16_t *rs1,
                                    vint16mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_i16mf2x6_m(vbool32_t vm, int16_t *rs1,
                                    vint16mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_i16mf2x7_m(vbool32_t vm, int16_t *rs1,
                                    vint16mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_i16mf2x8_m(vbool32_t vm, int16_t *rs1,
                                    vint16mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_i16m1x2_m(vbool16_t vm, int16_t *rs1, vint16m1x2_t vs3,
                                   size_t vl);
void __riscv_vsseg3e16_v_i16m1x3_m(vbool16_t vm, int16_t *rs1, vint16m1x3_t vs3,
                                   size_t vl);
void __riscv_vsseg4e16_v_i16m1x4_m(vbool16_t vm, int16_t *rs1, vint16m1x4_t vs3,
                                   size_t vl);
void __riscv_vsseg5e16_v_i16m1x5_m(vbool16_t vm, int16_t *rs1, vint16m1x5_t vs3,
                                   size_t vl);
void __riscv_vsseg6e16_v_i16m1x6_m(vbool16_t vm, int16_t *rs1, vint16m1x6_t vs3,
                                   size_t vl);
void __riscv_vsseg7e16_v_i16m1x7_m(vbool16_t vm, int16_t *rs1, vint16m1x7_t vs3,
                                   size_t vl);
void __riscv_vsseg8e16_v_i16m1x8_m(vbool16_t vm, int16_t *rs1, vint16m1x8_t vs3,
                                   size_t vl);
void __riscv_vsseg2e16_v_i16m2x2_m(vbool8_t vm, int16_t *rs1, vint16m2x2_t vs3,
                                   size_t vl);
void __riscv_vsseg3e16_v_i16m2x3_m(vbool8_t vm, int16_t *rs1, vint16m2x3_t vs3,
                                   size_t vl);
void __riscv_vsseg4e16_v_i16m2x4_m(vbool8_t vm, int16_t *rs1, vint16m2x4_t vs3,
                                   size_t vl);
void __riscv_vsseg2e16_v_i16m4x2_m(vbool4_t vm, int16_t *rs1, vint16m4x2_t vs3,
                                   size_t vl);
void __riscv_vsseg2e32_v_i32mf2x2_m(vbool64_t vm, int32_t *rs1,
                                    vint32mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_i32mf2x3_m(vbool64_t vm, int32_t *rs1,
                                    vint32mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_i32mf2x4_m(vbool64_t vm, int32_t *rs1,
                                    vint32mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e32_v_i32mf2x5_m(vbool64_t vm, int32_t *rs1,
                                    vint32mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e32_v_i32mf2x6_m(vbool64_t vm, int32_t *rs1,
                                    vint32mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e32_v_i32mf2x7_m(vbool64_t vm, int32_t *rs1,
                                    vint32mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e32_v_i32mf2x8_m(vbool64_t vm, int32_t *rs1,
                                    vint32mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e32_v_i32m1x2_m(vbool32_t vm, int32_t *rs1, vint32m1x2_t vs3,
                                   size_t vl);
void __riscv_vsseg3e32_v_i32m1x3_m(vbool32_t vm, int32_t *rs1, vint32m1x3_t vs3,
                                   size_t vl);
void __riscv_vsseg4e32_v_i32m1x4_m(vbool32_t vm, int32_t *rs1, vint32m1x4_t vs3,
                                   size_t vl);
void __riscv_vsseg5e32_v_i32m1x5_m(vbool32_t vm, int32_t *rs1, vint32m1x5_t vs3,
                                   size_t vl);
void __riscv_vsseg6e32_v_i32m1x6_m(vbool32_t vm, int32_t *rs1, vint32m1x6_t vs3,
                                   size_t vl);
void __riscv_vsseg7e32_v_i32m1x7_m(vbool32_t vm, int32_t *rs1, vint32m1x7_t vs3,
                                   size_t vl);
void __riscv_vsseg8e32_v_i32m1x8_m(vbool32_t vm, int32_t *rs1, vint32m1x8_t vs3,
                                   size_t vl);
void __riscv_vsseg2e32_v_i32m2x2_m(vbool16_t vm, int32_t *rs1, vint32m2x2_t vs3,
                                   size_t vl);
void __riscv_vsseg3e32_v_i32m2x3_m(vbool16_t vm, int32_t *rs1, vint32m2x3_t vs3,
                                   size_t vl);
void __riscv_vsseg4e32_v_i32m2x4_m(vbool16_t vm, int32_t *rs1, vint32m2x4_t vs3,
                                   size_t vl);
void __riscv_vsseg2e32_v_i32m4x2_m(vbool8_t vm, int32_t *rs1, vint32m4x2_t vs3,
                                   size_t vl);
void __riscv_vsseg2e64_v_i64m1x2_m(vbool64_t vm, int64_t *rs1, vint64m1x2_t vs3,
                                   size_t vl);
void __riscv_vsseg3e64_v_i64m1x3_m(vbool64_t vm, int64_t *rs1, vint64m1x3_t vs3,
                                   size_t vl);
void __riscv_vsseg4e64_v_i64m1x4_m(vbool64_t vm, int64_t *rs1, vint64m1x4_t vs3,
                                   size_t vl);
void __riscv_vsseg5e64_v_i64m1x5_m(vbool64_t vm, int64_t *rs1, vint64m1x5_t vs3,
                                   size_t vl);
void __riscv_vsseg6e64_v_i64m1x6_m(vbool64_t vm, int64_t *rs1, vint64m1x6_t vs3,
                                   size_t vl);
void __riscv_vsseg7e64_v_i64m1x7_m(vbool64_t vm, int64_t *rs1, vint64m1x7_t vs3,
                                   size_t vl);
void __riscv_vsseg8e64_v_i64m1x8_m(vbool64_t vm, int64_t *rs1, vint64m1x8_t vs3,
                                   size_t vl);
void __riscv_vsseg2e64_v_i64m2x2_m(vbool32_t vm, int64_t *rs1, vint64m2x2_t vs3,
                                   size_t vl);
void __riscv_vsseg3e64_v_i64m2x3_m(vbool32_t vm, int64_t *rs1, vint64m2x3_t vs3,
                                   size_t vl);
void __riscv_vsseg4e64_v_i64m2x4_m(vbool32_t vm, int64_t *rs1, vint64m2x4_t vs3,
                                   size_t vl);
void __riscv_vsseg2e64_v_i64m4x2_m(vbool16_t vm, int64_t *rs1, vint64m4x2_t vs3,
                                   size_t vl);
void __riscv_vsseg2e8_v_u8mf8x2_m(vbool64_t vm, uint8_t *rs1, vuint8mf8x2_t vs3,
                                  size_t vl);
void __riscv_vsseg3e8_v_u8mf8x3_m(vbool64_t vm, uint8_t *rs1, vuint8mf8x3_t vs3,
                                  size_t vl);
void __riscv_vsseg4e8_v_u8mf8x4_m(vbool64_t vm, uint8_t *rs1, vuint8mf8x4_t vs3,
                                  size_t vl);
void __riscv_vsseg5e8_v_u8mf8x5_m(vbool64_t vm, uint8_t *rs1, vuint8mf8x5_t vs3,
                                  size_t vl);
void __riscv_vsseg6e8_v_u8mf8x6_m(vbool64_t vm, uint8_t *rs1, vuint8mf8x6_t vs3,
                                  size_t vl);
void __riscv_vsseg7e8_v_u8mf8x7_m(vbool64_t vm, uint8_t *rs1, vuint8mf8x7_t vs3,
                                  size_t vl);
void __riscv_vsseg8e8_v_u8mf8x8_m(vbool64_t vm, uint8_t *rs1, vuint8mf8x8_t vs3,
                                  size_t vl);
void __riscv_vsseg2e8_v_u8mf4x2_m(vbool32_t vm, uint8_t *rs1, vuint8mf4x2_t vs3,
                                  size_t vl);
void __riscv_vsseg3e8_v_u8mf4x3_m(vbool32_t vm, uint8_t *rs1, vuint8mf4x3_t vs3,
                                  size_t vl);
void __riscv_vsseg4e8_v_u8mf4x4_m(vbool32_t vm, uint8_t *rs1, vuint8mf4x4_t vs3,
                                  size_t vl);
void __riscv_vsseg5e8_v_u8mf4x5_m(vbool32_t vm, uint8_t *rs1, vuint8mf4x5_t vs3,
                                  size_t vl);
void __riscv_vsseg6e8_v_u8mf4x6_m(vbool32_t vm, uint8_t *rs1, vuint8mf4x6_t vs3,
                                  size_t vl);
void __riscv_vsseg7e8_v_u8mf4x7_m(vbool32_t vm, uint8_t *rs1, vuint8mf4x7_t vs3,
                                  size_t vl);
void __riscv_vsseg8e8_v_u8mf4x8_m(vbool32_t vm, uint8_t *rs1, vuint8mf4x8_t vs3,
                                  size_t vl);
void __riscv_vsseg2e8_v_u8mf2x2_m(vbool16_t vm, uint8_t *rs1, vuint8mf2x2_t vs3,
                                  size_t vl);
void __riscv_vsseg3e8_v_u8mf2x3_m(vbool16_t vm, uint8_t *rs1, vuint8mf2x3_t vs3,
                                  size_t vl);
void __riscv_vsseg4e8_v_u8mf2x4_m(vbool16_t vm, uint8_t *rs1, vuint8mf2x4_t vs3,
                                  size_t vl);
void __riscv_vsseg5e8_v_u8mf2x5_m(vbool16_t vm, uint8_t *rs1, vuint8mf2x5_t vs3,
                                  size_t vl);
void __riscv_vsseg6e8_v_u8mf2x6_m(vbool16_t vm, uint8_t *rs1, vuint8mf2x6_t vs3,
                                  size_t vl);
void __riscv_vsseg7e8_v_u8mf2x7_m(vbool16_t vm, uint8_t *rs1, vuint8mf2x7_t vs3,
                                  size_t vl);
void __riscv_vsseg8e8_v_u8mf2x8_m(vbool16_t vm, uint8_t *rs1, vuint8mf2x8_t vs3,
                                  size_t vl);
void __riscv_vsseg2e8_v_u8m1x2_m(vbool8_t vm, uint8_t *rs1, vuint8m1x2_t vs3,
                                 size_t vl);
void __riscv_vsseg3e8_v_u8m1x3_m(vbool8_t vm, uint8_t *rs1, vuint8m1x3_t vs3,
                                 size_t vl);
void __riscv_vsseg4e8_v_u8m1x4_m(vbool8_t vm, uint8_t *rs1, vuint8m1x4_t vs3,
                                 size_t vl);
void __riscv_vsseg5e8_v_u8m1x5_m(vbool8_t vm, uint8_t *rs1, vuint8m1x5_t vs3,
                                 size_t vl);
void __riscv_vsseg6e8_v_u8m1x6_m(vbool8_t vm, uint8_t *rs1, vuint8m1x6_t vs3,
                                 size_t vl);
void __riscv_vsseg7e8_v_u8m1x7_m(vbool8_t vm, uint8_t *rs1, vuint8m1x7_t vs3,
                                 size_t vl);
void __riscv_vsseg8e8_v_u8m1x8_m(vbool8_t vm, uint8_t *rs1, vuint8m1x8_t vs3,
                                 size_t vl);
void __riscv_vsseg2e8_v_u8m2x2_m(vbool4_t vm, uint8_t *rs1, vuint8m2x2_t vs3,
                                 size_t vl);
void __riscv_vsseg3e8_v_u8m2x3_m(vbool4_t vm, uint8_t *rs1, vuint8m2x3_t vs3,
                                 size_t vl);
void __riscv_vsseg4e8_v_u8m2x4_m(vbool4_t vm, uint8_t *rs1, vuint8m2x4_t vs3,
                                 size_t vl);
void __riscv_vsseg2e8_v_u8m4x2_m(vbool2_t vm, uint8_t *rs1, vuint8m4x2_t vs3,
                                 size_t vl);
void __riscv_vsseg2e16_v_u16mf4x2_m(vbool64_t vm, uint16_t *rs1,
                                    vuint16mf4x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_u16mf4x3_m(vbool64_t vm, uint16_t *rs1,
                                    vuint16mf4x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_u16mf4x4_m(vbool64_t vm, uint16_t *rs1,
                                    vuint16mf4x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_u16mf4x5_m(vbool64_t vm, uint16_t *rs1,
                                    vuint16mf4x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_u16mf4x6_m(vbool64_t vm, uint16_t *rs1,
                                    vuint16mf4x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_u16mf4x7_m(vbool64_t vm, uint16_t *rs1,
                                    vuint16mf4x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_u16mf4x8_m(vbool64_t vm, uint16_t *rs1,
                                    vuint16mf4x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_u16mf2x2_m(vbool32_t vm, uint16_t *rs1,
                                    vuint16mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_u16mf2x3_m(vbool32_t vm, uint16_t *rs1,
                                    vuint16mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_u16mf2x4_m(vbool32_t vm, uint16_t *rs1,
                                    vuint16mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_u16mf2x5_m(vbool32_t vm, uint16_t *rs1,
                                    vuint16mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_u16mf2x6_m(vbool32_t vm, uint16_t *rs1,
                                    vuint16mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_u16mf2x7_m(vbool32_t vm, uint16_t *rs1,
                                    vuint16mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_u16mf2x8_m(vbool32_t vm, uint16_t *rs1,
                                    vuint16mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_u16m1x2_m(vbool16_t vm, uint16_t *rs1,
                                   vuint16m1x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_u16m1x3_m(vbool16_t vm, uint16_t *rs1,
                                   vuint16m1x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_u16m1x4_m(vbool16_t vm, uint16_t *rs1,
                                   vuint16m1x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_u16m1x5_m(vbool16_t vm, uint16_t *rs1,
                                   vuint16m1x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_u16m1x6_m(vbool16_t vm, uint16_t *rs1,
                                   vuint16m1x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_u16m1x7_m(vbool16_t vm, uint16_t *rs1,
                                   vuint16m1x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_u16m1x8_m(vbool16_t vm, uint16_t *rs1,
                                   vuint16m1x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_u16m2x2_m(vbool8_t vm, uint16_t *rs1,
                                   vuint16m2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_u16m2x3_m(vbool8_t vm, uint16_t *rs1,
                                   vuint16m2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_u16m2x4_m(vbool8_t vm, uint16_t *rs1,
                                   vuint16m2x4_t vs3, size_t vl);
void __riscv_vsseg2e16_v_u16m4x2_m(vbool4_t vm, uint16_t *rs1,
                                   vuint16m4x2_t vs3, size_t vl);
void __riscv_vsseg2e32_v_u32mf2x2_m(vbool64_t vm, uint32_t *rs1,
                                    vuint32mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_u32mf2x3_m(vbool64_t vm, uint32_t *rs1,
                                    vuint32mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_u32mf2x4_m(vbool64_t vm, uint32_t *rs1,
                                    vuint32mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e32_v_u32mf2x5_m(vbool64_t vm, uint32_t *rs1,
                                    vuint32mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e32_v_u32mf2x6_m(vbool64_t vm, uint32_t *rs1,
                                    vuint32mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e32_v_u32mf2x7_m(vbool64_t vm, uint32_t *rs1,
                                    vuint32mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e32_v_u32mf2x8_m(vbool64_t vm, uint32_t *rs1,
                                    vuint32mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e32_v_u32m1x2_m(vbool32_t vm, uint32_t *rs1,
                                   vuint32m1x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_u32m1x3_m(vbool32_t vm, uint32_t *rs1,
                                   vuint32m1x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_u32m1x4_m(vbool32_t vm, uint32_t *rs1,
                                   vuint32m1x4_t vs3, size_t vl);
void __riscv_vsseg5e32_v_u32m1x5_m(vbool32_t vm, uint32_t *rs1,
                                   vuint32m1x5_t vs3, size_t vl);
void __riscv_vsseg6e32_v_u32m1x6_m(vbool32_t vm, uint32_t *rs1,
                                   vuint32m1x6_t vs3, size_t vl);
void __riscv_vsseg7e32_v_u32m1x7_m(vbool32_t vm, uint32_t *rs1,
                                   vuint32m1x7_t vs3, size_t vl);
void __riscv_vsseg8e32_v_u32m1x8_m(vbool32_t vm, uint32_t *rs1,
                                   vuint32m1x8_t vs3, size_t vl);
void __riscv_vsseg2e32_v_u32m2x2_m(vbool16_t vm, uint32_t *rs1,
                                   vuint32m2x2_t vs3, size_t vl);
void __riscv_vsseg3e32_v_u32m2x3_m(vbool16_t vm, uint32_t *rs1,
                                   vuint32m2x3_t vs3, size_t vl);
void __riscv_vsseg4e32_v_u32m2x4_m(vbool16_t vm, uint32_t *rs1,
                                   vuint32m2x4_t vs3, size_t vl);
void __riscv_vsseg2e32_v_u32m4x2_m(vbool8_t vm, uint32_t *rs1,
                                   vuint32m4x2_t vs3, size_t vl);
void __riscv_vsseg2e64_v_u64m1x2_m(vbool64_t vm, uint64_t *rs1,
                                   vuint64m1x2_t vs3, size_t vl);
void __riscv_vsseg3e64_v_u64m1x3_m(vbool64_t vm, uint64_t *rs1,
                                   vuint64m1x3_t vs3, size_t vl);
void __riscv_vsseg4e64_v_u64m1x4_m(vbool64_t vm, uint64_t *rs1,
                                   vuint64m1x4_t vs3, size_t vl);
void __riscv_vsseg5e64_v_u64m1x5_m(vbool64_t vm, uint64_t *rs1,
                                   vuint64m1x5_t vs3, size_t vl);
void __riscv_vsseg6e64_v_u64m1x6_m(vbool64_t vm, uint64_t *rs1,
                                   vuint64m1x6_t vs3, size_t vl);
void __riscv_vsseg7e64_v_u64m1x7_m(vbool64_t vm, uint64_t *rs1,
                                   vuint64m1x7_t vs3, size_t vl);
void __riscv_vsseg8e64_v_u64m1x8_m(vbool64_t vm, uint64_t *rs1,
                                   vuint64m1x8_t vs3, size_t vl);
void __riscv_vsseg2e64_v_u64m2x2_m(vbool32_t vm, uint64_t *rs1,
                                   vuint64m2x2_t vs3, size_t vl);
void __riscv_vsseg3e64_v_u64m2x3_m(vbool32_t vm, uint64_t *rs1,
                                   vuint64m2x3_t vs3, size_t vl);
void __riscv_vsseg4e64_v_u64m2x4_m(vbool32_t vm, uint64_t *rs1,
                                   vuint64m2x4_t vs3, size_t vl);
void __riscv_vsseg2e64_v_u64m4x2_m(vbool16_t vm, uint64_t *rs1,
                                   vuint64m4x2_t vs3, size_t vl);
----

[[vector-strided-segment-load]]
==== Vector Strided Segment Load Intrinsics

[,c]
----
vfloat16mf4x2_t __riscv_vlsseg2e16_v_f16mf4x2(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_v_f16mf4x3(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_v_f16mf4x4(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_v_f16mf4x5(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_v_f16mf4x6(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_v_f16mf4x7(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_v_f16mf4x8(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_v_f16mf2x2(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_v_f16mf2x3(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_v_f16mf2x4(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_v_f16mf2x5(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_v_f16mf2x6(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_v_f16mf2x7(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_v_f16mf2x8(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_v_f16m1x2(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_v_f16m1x3(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_v_f16m1x4(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_v_f16m1x5(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_v_f16m1x6(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_v_f16m1x7(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_v_f16m1x8(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_v_f16m2x2(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_v_f16m2x3(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_v_f16m2x4(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_v_f16m4x2(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32mf2x2_t __riscv_vlsseg2e32_v_f32mf2x2(const float *rs1, ptrdiff_t rs2,
                                              size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_v_f32mf2x3(const float *rs1, ptrdiff_t rs2,
                                              size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_v_f32mf2x4(const float *rs1, ptrdiff_t rs2,
                                              size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_v_f32mf2x5(const float *rs1, ptrdiff_t rs2,
                                              size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_v_f32mf2x6(const float *rs1, ptrdiff_t rs2,
                                              size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_v_f32mf2x7(const float *rs1, ptrdiff_t rs2,
                                              size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_v_f32mf2x8(const float *rs1, ptrdiff_t rs2,
                                              size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_v_f32m1x2(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_v_f32m1x3(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_v_f32m1x4(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_v_f32m1x5(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_v_f32m1x6(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_v_f32m1x7(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_v_f32m1x8(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_v_f32m2x2(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_v_f32m2x3(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_v_f32m2x4(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_v_f32m4x2(const float *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_v_f64m1x2(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_v_f64m1x3(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_v_f64m1x4(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_v_f64m1x5(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_v_f64m1x6(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_v_f64m1x7(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_v_f64m1x8(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_v_f64m2x2(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_v_f64m2x3(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_v_f64m2x4(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_v_f64m4x2(const double *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint8mf8x2_t __riscv_vlsseg2e8_v_i8mf8x2(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_v_i8mf8x3(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_v_i8mf8x4(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_v_i8mf8x5(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_v_i8mf8x6(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_v_i8mf8x7(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_v_i8mf8x8(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_v_i8mf4x2(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_v_i8mf4x3(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_v_i8mf4x4(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_v_i8mf4x5(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_v_i8mf4x6(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_v_i8mf4x7(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_v_i8mf4x8(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_v_i8mf2x2(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_v_i8mf2x3(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_v_i8mf2x4(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_v_i8mf2x5(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_v_i8mf2x6(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_v_i8mf2x7(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_v_i8mf2x8(const int8_t *rs1, ptrdiff_t rs2,
                                         size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_v_i8m1x2(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_v_i8m1x3(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_v_i8m1x4(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_v_i8m1x5(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_v_i8m1x6(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_v_i8m1x7(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_v_i8m1x8(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_v_i8m2x2(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_v_i8m2x3(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_v_i8m2x4(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_v_i8m4x2(const int8_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_v_i16mf4x2(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_v_i16mf4x3(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_v_i16mf4x4(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_v_i16mf4x5(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_v_i16mf4x6(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_v_i16mf4x7(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_v_i16mf4x8(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_v_i16mf2x2(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_v_i16mf2x3(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_v_i16mf2x4(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_v_i16mf2x5(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_v_i16mf2x6(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_v_i16mf2x7(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_v_i16mf2x8(const int16_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_v_i16m1x2(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_v_i16m1x3(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_v_i16m1x4(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_v_i16m1x5(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_v_i16m1x6(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_v_i16m1x7(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_v_i16m1x8(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_v_i16m2x2(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_v_i16m2x3(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_v_i16m2x4(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_v_i16m4x2(const int16_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_v_i32mf2x2(const int32_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_v_i32mf2x3(const int32_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_v_i32mf2x4(const int32_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_v_i32mf2x5(const int32_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_v_i32mf2x6(const int32_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_v_i32mf2x7(const int32_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_v_i32mf2x8(const int32_t *rs1, ptrdiff_t rs2,
                                            size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_v_i32m1x2(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_v_i32m1x3(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_v_i32m1x4(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_v_i32m1x5(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_v_i32m1x6(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_v_i32m1x7(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_v_i32m1x8(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_v_i32m2x2(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_v_i32m2x3(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_v_i32m2x4(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_v_i32m4x2(const int32_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_v_i64m1x2(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_v_i64m1x3(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_v_i64m1x4(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_v_i64m1x5(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_v_i64m1x6(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_v_i64m1x7(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_v_i64m1x8(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_v_i64m2x2(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_v_i64m2x3(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_v_i64m2x4(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_v_i64m4x2(const int64_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_v_u8mf8x2(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_v_u8mf8x3(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_v_u8mf8x4(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_v_u8mf8x5(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_v_u8mf8x6(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_v_u8mf8x7(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_v_u8mf8x8(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_v_u8mf4x2(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_v_u8mf4x3(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_v_u8mf4x4(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_v_u8mf4x5(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_v_u8mf4x6(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_v_u8mf4x7(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_v_u8mf4x8(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_v_u8mf2x2(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_v_u8mf2x3(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_v_u8mf2x4(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_v_u8mf2x5(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_v_u8mf2x6(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_v_u8mf2x7(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_v_u8mf2x8(const uint8_t *rs1, ptrdiff_t rs2,
                                          size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_v_u8m1x2(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_v_u8m1x3(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_v_u8m1x4(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_v_u8m1x5(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_v_u8m1x6(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_v_u8m1x7(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_v_u8m1x8(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_v_u8m2x2(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_v_u8m2x3(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_v_u8m2x4(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_v_u8m4x2(const uint8_t *rs1, ptrdiff_t rs2,
                                        size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_v_u16mf4x2(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_v_u16mf4x3(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_v_u16mf4x4(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_v_u16mf4x5(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_v_u16mf4x6(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_v_u16mf4x7(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_v_u16mf4x8(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_v_u16mf2x2(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_v_u16mf2x3(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_v_u16mf2x4(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_v_u16mf2x5(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_v_u16mf2x6(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_v_u16mf2x7(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_v_u16mf2x8(const uint16_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_v_u16m1x2(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_v_u16m1x3(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_v_u16m1x4(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_v_u16m1x5(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_v_u16m1x6(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_v_u16m1x7(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_v_u16m1x8(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_v_u16m2x2(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_v_u16m2x3(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_v_u16m2x4(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_v_u16m4x2(const uint16_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_v_u32mf2x2(const uint32_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_v_u32mf2x3(const uint32_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_v_u32mf2x4(const uint32_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_v_u32mf2x5(const uint32_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_v_u32mf2x6(const uint32_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_v_u32mf2x7(const uint32_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_v_u32mf2x8(const uint32_t *rs1, ptrdiff_t rs2,
                                             size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_v_u32m1x2(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_v_u32m1x3(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_v_u32m1x4(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_v_u32m1x5(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_v_u32m1x6(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_v_u32m1x7(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_v_u32m1x8(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_v_u32m2x2(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_v_u32m2x3(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_v_u32m2x4(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_v_u32m4x2(const uint32_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_v_u64m1x2(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_v_u64m1x3(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_v_u64m1x4(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_v_u64m1x5(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_v_u64m1x6(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_v_u64m1x7(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_v_u64m1x8(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_v_u64m2x2(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_v_u64m2x3(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_v_u64m2x4(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_v_u64m4x2(const uint64_t *rs1, ptrdiff_t rs2,
                                           size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_v_f16mf4x2_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_v_f16mf4x3_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_v_f16mf4x4_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_v_f16mf4x5_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_v_f16mf4x6_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_v_f16mf4x7_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_v_f16mf4x8_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_v_f16mf2x2_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_v_f16mf2x3_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_v_f16mf2x4_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_v_f16mf2x5_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_v_f16mf2x6_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_v_f16mf2x7_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_v_f16mf2x8_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_v_f16m1x2_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_v_f16m1x3_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_v_f16m1x4_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_v_f16m1x5_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_v_f16m1x6_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_v_f16m1x7_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_v_f16m1x8_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_v_f16m2x2_m(vbool8_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_v_f16m2x3_m(vbool8_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_v_f16m2x4_m(vbool8_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_v_f16m4x2_m(vbool4_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vlsseg2e32_v_f32mf2x2_m(vbool64_t vm, const float *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_v_f32mf2x3_m(vbool64_t vm, const float *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_v_f32mf2x4_m(vbool64_t vm, const float *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_v_f32mf2x5_m(vbool64_t vm, const float *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_v_f32mf2x6_m(vbool64_t vm, const float *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_v_f32mf2x7_m(vbool64_t vm, const float *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_v_f32mf2x8_m(vbool64_t vm, const float *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint8mf8x2_t __riscv_vlsseg2e8_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                           ptrdiff_t rs2, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_v_i8m2x2_m(vbool4_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_v_i8m2x3_m(vbool4_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_v_i8m2x4_m(vbool4_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_v_i8m4x2_m(vbool2_t vm, const int8_t *rs1,
                                         ptrdiff_t rs2, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_v_i16mf4x2_m(vbool64_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_v_i16mf4x3_m(vbool64_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_v_i16mf4x4_m(vbool64_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_v_i16mf4x5_m(vbool64_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_v_i16mf4x6_m(vbool64_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_v_i16mf4x7_m(vbool64_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_v_i16mf4x8_m(vbool64_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_v_i16mf2x2_m(vbool32_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_v_i16mf2x3_m(vbool32_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_v_i16mf2x4_m(vbool32_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_v_i16mf2x5_m(vbool32_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_v_i16mf2x6_m(vbool32_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_v_i16mf2x7_m(vbool32_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_v_i16mf2x8_m(vbool32_t vm, const int16_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_v_i16m4x2_m(vbool4_t vm, const int16_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_v_i32mf2x2_m(vbool64_t vm, const int32_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_v_i32mf2x3_m(vbool64_t vm, const int32_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_v_i32mf2x4_m(vbool64_t vm, const int32_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_v_i32mf2x5_m(vbool64_t vm, const int32_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_v_i32mf2x6_m(vbool64_t vm, const int32_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_v_i32mf2x7_m(vbool64_t vm, const int32_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_v_i32mf2x8_m(vbool64_t vm, const int32_t *rs1,
                                              ptrdiff_t rs2, size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                            ptrdiff_t rs2, size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_v_u8m2x2_m(vbool4_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_v_u8m2x3_m(vbool4_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_v_u8m2x4_m(vbool4_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_v_u8m4x2_m(vbool2_t vm, const uint8_t *rs1,
                                          ptrdiff_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_v_u16mf4x2_m(vbool64_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_v_u16mf4x3_m(vbool64_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_v_u16mf4x4_m(vbool64_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_v_u16mf4x5_m(vbool64_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_v_u16mf4x6_m(vbool64_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_v_u16mf4x7_m(vbool64_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_v_u16mf4x8_m(vbool64_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_v_u16mf2x2_m(vbool32_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_v_u16mf2x3_m(vbool32_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_v_u16mf2x4_m(vbool32_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_v_u16mf2x5_m(vbool32_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_v_u16mf2x6_m(vbool32_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_v_u16mf2x7_m(vbool32_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_v_u16mf2x8_m(vbool32_t vm,
                                               const uint16_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_v_u16m1x2_m(vbool16_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_v_u16m1x3_m(vbool16_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_v_u16m1x4_m(vbool16_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_v_u16m1x5_m(vbool16_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_v_u16m1x6_m(vbool16_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_v_u16m1x7_m(vbool16_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_v_u16m1x8_m(vbool16_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_v_u16m4x2_m(vbool4_t vm, const uint16_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_v_u32mf2x2_m(vbool64_t vm,
                                               const uint32_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_v_u32mf2x3_m(vbool64_t vm,
                                               const uint32_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_v_u32mf2x4_m(vbool64_t vm,
                                               const uint32_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_v_u32mf2x5_m(vbool64_t vm,
                                               const uint32_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_v_u32mf2x6_m(vbool64_t vm,
                                               const uint32_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_v_u32mf2x7_m(vbool64_t vm,
                                               const uint32_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_v_u32mf2x8_m(vbool64_t vm,
                                               const uint32_t *rs1,
                                               ptrdiff_t rs2, size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_v_u32m1x2_m(vbool32_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_v_u32m1x3_m(vbool32_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_v_u32m1x4_m(vbool32_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_v_u32m1x5_m(vbool32_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_v_u32m1x6_m(vbool32_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_v_u32m1x7_m(vbool32_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_v_u32m1x8_m(vbool32_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_v_u32m2x2_m(vbool16_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_v_u32m2x3_m(vbool16_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_v_u32m2x4_m(vbool16_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_v_u64m1x2_m(vbool64_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_v_u64m1x3_m(vbool64_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_v_u64m1x4_m(vbool64_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_v_u64m1x5_m(vbool64_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_v_u64m1x6_m(vbool64_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_v_u64m1x7_m(vbool64_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_v_u64m1x8_m(vbool64_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_v_u64m2x2_m(vbool32_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_v_u64m2x3_m(vbool32_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_v_u64m2x4_m(vbool32_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_v_u64m4x2_m(vbool16_t vm, const uint64_t *rs1,
                                             ptrdiff_t rs2, size_t vl);
----

[[vector-strided-segment-store]]
==== Vector Strided Segment Store Intrinsics

[,c]
----
void __riscv_vssseg2e16_v_f16mf4x2(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16mf4x3(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16mf4x4(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16mf4x5(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16mf4x6(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16mf4x7(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16mf4x8(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16mf2x2(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16mf2x3(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16mf2x4(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16mf2x5(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16mf2x6(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16mf2x7(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16mf2x8(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m1x2(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16m1x3(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16m1x4(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16m1x5(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16m1x6(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16m1x7(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16m1x8(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m2x2(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16m2x3(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16m2x4(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m2x4_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m4x2(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m4x2_t vs3, size_t vl);
void __riscv_vssseg2e32_v_f32mf2x2(float *rs1, ptrdiff_t rs2,
                                   vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_f32mf2x3(float *rs1, ptrdiff_t rs2,
                                   vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_f32mf2x4(float *rs1, ptrdiff_t rs2,
                                   vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e32_v_f32mf2x5(float *rs1, ptrdiff_t rs2,
                                   vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e32_v_f32mf2x6(float *rs1, ptrdiff_t rs2,
                                   vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e32_v_f32mf2x7(float *rs1, ptrdiff_t rs2,
                                   vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e32_v_f32mf2x8(float *rs1, ptrdiff_t rs2,
                                   vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e32_v_f32m1x2(float *rs1, ptrdiff_t rs2, vfloat32m1x2_t vs3,
                                  size_t vl);
void __riscv_vssseg3e32_v_f32m1x3(float *rs1, ptrdiff_t rs2, vfloat32m1x3_t vs3,
                                  size_t vl);
void __riscv_vssseg4e32_v_f32m1x4(float *rs1, ptrdiff_t rs2, vfloat32m1x4_t vs3,
                                  size_t vl);
void __riscv_vssseg5e32_v_f32m1x5(float *rs1, ptrdiff_t rs2, vfloat32m1x5_t vs3,
                                  size_t vl);
void __riscv_vssseg6e32_v_f32m1x6(float *rs1, ptrdiff_t rs2, vfloat32m1x6_t vs3,
                                  size_t vl);
void __riscv_vssseg7e32_v_f32m1x7(float *rs1, ptrdiff_t rs2, vfloat32m1x7_t vs3,
                                  size_t vl);
void __riscv_vssseg8e32_v_f32m1x8(float *rs1, ptrdiff_t rs2, vfloat32m1x8_t vs3,
                                  size_t vl);
void __riscv_vssseg2e32_v_f32m2x2(float *rs1, ptrdiff_t rs2, vfloat32m2x2_t vs3,
                                  size_t vl);
void __riscv_vssseg3e32_v_f32m2x3(float *rs1, ptrdiff_t rs2, vfloat32m2x3_t vs3,
                                  size_t vl);
void __riscv_vssseg4e32_v_f32m2x4(float *rs1, ptrdiff_t rs2, vfloat32m2x4_t vs3,
                                  size_t vl);
void __riscv_vssseg2e32_v_f32m4x2(float *rs1, ptrdiff_t rs2, vfloat32m4x2_t vs3,
                                  size_t vl);
void __riscv_vssseg2e64_v_f64m1x2(double *rs1, ptrdiff_t rs2,
                                  vfloat64m1x2_t vs3, size_t vl);
void __riscv_vssseg3e64_v_f64m1x3(double *rs1, ptrdiff_t rs2,
                                  vfloat64m1x3_t vs3, size_t vl);
void __riscv_vssseg4e64_v_f64m1x4(double *rs1, ptrdiff_t rs2,
                                  vfloat64m1x4_t vs3, size_t vl);
void __riscv_vssseg5e64_v_f64m1x5(double *rs1, ptrdiff_t rs2,
                                  vfloat64m1x5_t vs3, size_t vl);
void __riscv_vssseg6e64_v_f64m1x6(double *rs1, ptrdiff_t rs2,
                                  vfloat64m1x6_t vs3, size_t vl);
void __riscv_vssseg7e64_v_f64m1x7(double *rs1, ptrdiff_t rs2,
                                  vfloat64m1x7_t vs3, size_t vl);
void __riscv_vssseg8e64_v_f64m1x8(double *rs1, ptrdiff_t rs2,
                                  vfloat64m1x8_t vs3, size_t vl);
void __riscv_vssseg2e64_v_f64m2x2(double *rs1, ptrdiff_t rs2,
                                  vfloat64m2x2_t vs3, size_t vl);
void __riscv_vssseg3e64_v_f64m2x3(double *rs1, ptrdiff_t rs2,
                                  vfloat64m2x3_t vs3, size_t vl);
void __riscv_vssseg4e64_v_f64m2x4(double *rs1, ptrdiff_t rs2,
                                  vfloat64m2x4_t vs3, size_t vl);
void __riscv_vssseg2e64_v_f64m4x2(double *rs1, ptrdiff_t rs2,
                                  vfloat64m4x2_t vs3, size_t vl);
void __riscv_vssseg2e8_v_i8mf8x2(int8_t *rs1, ptrdiff_t rs2, vint8mf8x2_t vs3,
                                 size_t vl);
void __riscv_vssseg3e8_v_i8mf8x3(int8_t *rs1, ptrdiff_t rs2, vint8mf8x3_t vs3,
                                 size_t vl);
void __riscv_vssseg4e8_v_i8mf8x4(int8_t *rs1, ptrdiff_t rs2, vint8mf8x4_t vs3,
                                 size_t vl);
void __riscv_vssseg5e8_v_i8mf8x5(int8_t *rs1, ptrdiff_t rs2, vint8mf8x5_t vs3,
                                 size_t vl);
void __riscv_vssseg6e8_v_i8mf8x6(int8_t *rs1, ptrdiff_t rs2, vint8mf8x6_t vs3,
                                 size_t vl);
void __riscv_vssseg7e8_v_i8mf8x7(int8_t *rs1, ptrdiff_t rs2, vint8mf8x7_t vs3,
                                 size_t vl);
void __riscv_vssseg8e8_v_i8mf8x8(int8_t *rs1, ptrdiff_t rs2, vint8mf8x8_t vs3,
                                 size_t vl);
void __riscv_vssseg2e8_v_i8mf4x2(int8_t *rs1, ptrdiff_t rs2, vint8mf4x2_t vs3,
                                 size_t vl);
void __riscv_vssseg3e8_v_i8mf4x3(int8_t *rs1, ptrdiff_t rs2, vint8mf4x3_t vs3,
                                 size_t vl);
void __riscv_vssseg4e8_v_i8mf4x4(int8_t *rs1, ptrdiff_t rs2, vint8mf4x4_t vs3,
                                 size_t vl);
void __riscv_vssseg5e8_v_i8mf4x5(int8_t *rs1, ptrdiff_t rs2, vint8mf4x5_t vs3,
                                 size_t vl);
void __riscv_vssseg6e8_v_i8mf4x6(int8_t *rs1, ptrdiff_t rs2, vint8mf4x6_t vs3,
                                 size_t vl);
void __riscv_vssseg7e8_v_i8mf4x7(int8_t *rs1, ptrdiff_t rs2, vint8mf4x7_t vs3,
                                 size_t vl);
void __riscv_vssseg8e8_v_i8mf4x8(int8_t *rs1, ptrdiff_t rs2, vint8mf4x8_t vs3,
                                 size_t vl);
void __riscv_vssseg2e8_v_i8mf2x2(int8_t *rs1, ptrdiff_t rs2, vint8mf2x2_t vs3,
                                 size_t vl);
void __riscv_vssseg3e8_v_i8mf2x3(int8_t *rs1, ptrdiff_t rs2, vint8mf2x3_t vs3,
                                 size_t vl);
void __riscv_vssseg4e8_v_i8mf2x4(int8_t *rs1, ptrdiff_t rs2, vint8mf2x4_t vs3,
                                 size_t vl);
void __riscv_vssseg5e8_v_i8mf2x5(int8_t *rs1, ptrdiff_t rs2, vint8mf2x5_t vs3,
                                 size_t vl);
void __riscv_vssseg6e8_v_i8mf2x6(int8_t *rs1, ptrdiff_t rs2, vint8mf2x6_t vs3,
                                 size_t vl);
void __riscv_vssseg7e8_v_i8mf2x7(int8_t *rs1, ptrdiff_t rs2, vint8mf2x7_t vs3,
                                 size_t vl);
void __riscv_vssseg8e8_v_i8mf2x8(int8_t *rs1, ptrdiff_t rs2, vint8mf2x8_t vs3,
                                 size_t vl);
void __riscv_vssseg2e8_v_i8m1x2(int8_t *rs1, ptrdiff_t rs2, vint8m1x2_t vs3,
                                size_t vl);
void __riscv_vssseg3e8_v_i8m1x3(int8_t *rs1, ptrdiff_t rs2, vint8m1x3_t vs3,
                                size_t vl);
void __riscv_vssseg4e8_v_i8m1x4(int8_t *rs1, ptrdiff_t rs2, vint8m1x4_t vs3,
                                size_t vl);
void __riscv_vssseg5e8_v_i8m1x5(int8_t *rs1, ptrdiff_t rs2, vint8m1x5_t vs3,
                                size_t vl);
void __riscv_vssseg6e8_v_i8m1x6(int8_t *rs1, ptrdiff_t rs2, vint8m1x6_t vs3,
                                size_t vl);
void __riscv_vssseg7e8_v_i8m1x7(int8_t *rs1, ptrdiff_t rs2, vint8m1x7_t vs3,
                                size_t vl);
void __riscv_vssseg8e8_v_i8m1x8(int8_t *rs1, ptrdiff_t rs2, vint8m1x8_t vs3,
                                size_t vl);
void __riscv_vssseg2e8_v_i8m2x2(int8_t *rs1, ptrdiff_t rs2, vint8m2x2_t vs3,
                                size_t vl);
void __riscv_vssseg3e8_v_i8m2x3(int8_t *rs1, ptrdiff_t rs2, vint8m2x3_t vs3,
                                size_t vl);
void __riscv_vssseg4e8_v_i8m2x4(int8_t *rs1, ptrdiff_t rs2, vint8m2x4_t vs3,
                                size_t vl);
void __riscv_vssseg2e8_v_i8m4x2(int8_t *rs1, ptrdiff_t rs2, vint8m4x2_t vs3,
                                size_t vl);
void __riscv_vssseg2e16_v_i16mf4x2(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_i16mf4x3(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_i16mf4x4(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_i16mf4x5(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_i16mf4x6(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_i16mf4x7(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_i16mf4x8(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_i16mf2x2(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_i16mf2x3(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_i16mf2x4(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_i16mf2x5(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_i16mf2x6(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_i16mf2x7(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_i16mf2x8(int16_t *rs1, ptrdiff_t rs2,
                                   vint16mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_i16m1x2(int16_t *rs1, ptrdiff_t rs2, vint16m1x2_t vs3,
                                  size_t vl);
void __riscv_vssseg3e16_v_i16m1x3(int16_t *rs1, ptrdiff_t rs2, vint16m1x3_t vs3,
                                  size_t vl);
void __riscv_vssseg4e16_v_i16m1x4(int16_t *rs1, ptrdiff_t rs2, vint16m1x4_t vs3,
                                  size_t vl);
void __riscv_vssseg5e16_v_i16m1x5(int16_t *rs1, ptrdiff_t rs2, vint16m1x5_t vs3,
                                  size_t vl);
void __riscv_vssseg6e16_v_i16m1x6(int16_t *rs1, ptrdiff_t rs2, vint16m1x6_t vs3,
                                  size_t vl);
void __riscv_vssseg7e16_v_i16m1x7(int16_t *rs1, ptrdiff_t rs2, vint16m1x7_t vs3,
                                  size_t vl);
void __riscv_vssseg8e16_v_i16m1x8(int16_t *rs1, ptrdiff_t rs2, vint16m1x8_t vs3,
                                  size_t vl);
void __riscv_vssseg2e16_v_i16m2x2(int16_t *rs1, ptrdiff_t rs2, vint16m2x2_t vs3,
                                  size_t vl);
void __riscv_vssseg3e16_v_i16m2x3(int16_t *rs1, ptrdiff_t rs2, vint16m2x3_t vs3,
                                  size_t vl);
void __riscv_vssseg4e16_v_i16m2x4(int16_t *rs1, ptrdiff_t rs2, vint16m2x4_t vs3,
                                  size_t vl);
void __riscv_vssseg2e16_v_i16m4x2(int16_t *rs1, ptrdiff_t rs2, vint16m4x2_t vs3,
                                  size_t vl);
void __riscv_vssseg2e32_v_i32mf2x2(int32_t *rs1, ptrdiff_t rs2,
                                   vint32mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_i32mf2x3(int32_t *rs1, ptrdiff_t rs2,
                                   vint32mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_i32mf2x4(int32_t *rs1, ptrdiff_t rs2,
                                   vint32mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e32_v_i32mf2x5(int32_t *rs1, ptrdiff_t rs2,
                                   vint32mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e32_v_i32mf2x6(int32_t *rs1, ptrdiff_t rs2,
                                   vint32mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e32_v_i32mf2x7(int32_t *rs1, ptrdiff_t rs2,
                                   vint32mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e32_v_i32mf2x8(int32_t *rs1, ptrdiff_t rs2,
                                   vint32mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e32_v_i32m1x2(int32_t *rs1, ptrdiff_t rs2, vint32m1x2_t vs3,
                                  size_t vl);
void __riscv_vssseg3e32_v_i32m1x3(int32_t *rs1, ptrdiff_t rs2, vint32m1x3_t vs3,
                                  size_t vl);
void __riscv_vssseg4e32_v_i32m1x4(int32_t *rs1, ptrdiff_t rs2, vint32m1x4_t vs3,
                                  size_t vl);
void __riscv_vssseg5e32_v_i32m1x5(int32_t *rs1, ptrdiff_t rs2, vint32m1x5_t vs3,
                                  size_t vl);
void __riscv_vssseg6e32_v_i32m1x6(int32_t *rs1, ptrdiff_t rs2, vint32m1x6_t vs3,
                                  size_t vl);
void __riscv_vssseg7e32_v_i32m1x7(int32_t *rs1, ptrdiff_t rs2, vint32m1x7_t vs3,
                                  size_t vl);
void __riscv_vssseg8e32_v_i32m1x8(int32_t *rs1, ptrdiff_t rs2, vint32m1x8_t vs3,
                                  size_t vl);
void __riscv_vssseg2e32_v_i32m2x2(int32_t *rs1, ptrdiff_t rs2, vint32m2x2_t vs3,
                                  size_t vl);
void __riscv_vssseg3e32_v_i32m2x3(int32_t *rs1, ptrdiff_t rs2, vint32m2x3_t vs3,
                                  size_t vl);
void __riscv_vssseg4e32_v_i32m2x4(int32_t *rs1, ptrdiff_t rs2, vint32m2x4_t vs3,
                                  size_t vl);
void __riscv_vssseg2e32_v_i32m4x2(int32_t *rs1, ptrdiff_t rs2, vint32m4x2_t vs3,
                                  size_t vl);
void __riscv_vssseg2e64_v_i64m1x2(int64_t *rs1, ptrdiff_t rs2, vint64m1x2_t vs3,
                                  size_t vl);
void __riscv_vssseg3e64_v_i64m1x3(int64_t *rs1, ptrdiff_t rs2, vint64m1x3_t vs3,
                                  size_t vl);
void __riscv_vssseg4e64_v_i64m1x4(int64_t *rs1, ptrdiff_t rs2, vint64m1x4_t vs3,
                                  size_t vl);
void __riscv_vssseg5e64_v_i64m1x5(int64_t *rs1, ptrdiff_t rs2, vint64m1x5_t vs3,
                                  size_t vl);
void __riscv_vssseg6e64_v_i64m1x6(int64_t *rs1, ptrdiff_t rs2, vint64m1x6_t vs3,
                                  size_t vl);
void __riscv_vssseg7e64_v_i64m1x7(int64_t *rs1, ptrdiff_t rs2, vint64m1x7_t vs3,
                                  size_t vl);
void __riscv_vssseg8e64_v_i64m1x8(int64_t *rs1, ptrdiff_t rs2, vint64m1x8_t vs3,
                                  size_t vl);
void __riscv_vssseg2e64_v_i64m2x2(int64_t *rs1, ptrdiff_t rs2, vint64m2x2_t vs3,
                                  size_t vl);
void __riscv_vssseg3e64_v_i64m2x3(int64_t *rs1, ptrdiff_t rs2, vint64m2x3_t vs3,
                                  size_t vl);
void __riscv_vssseg4e64_v_i64m2x4(int64_t *rs1, ptrdiff_t rs2, vint64m2x4_t vs3,
                                  size_t vl);
void __riscv_vssseg2e64_v_i64m4x2(int64_t *rs1, ptrdiff_t rs2, vint64m4x2_t vs3,
                                  size_t vl);
void __riscv_vssseg2e8_v_u8mf8x2(uint8_t *rs1, ptrdiff_t rs2, vuint8mf8x2_t vs3,
                                 size_t vl);
void __riscv_vssseg3e8_v_u8mf8x3(uint8_t *rs1, ptrdiff_t rs2, vuint8mf8x3_t vs3,
                                 size_t vl);
void __riscv_vssseg4e8_v_u8mf8x4(uint8_t *rs1, ptrdiff_t rs2, vuint8mf8x4_t vs3,
                                 size_t vl);
void __riscv_vssseg5e8_v_u8mf8x5(uint8_t *rs1, ptrdiff_t rs2, vuint8mf8x5_t vs3,
                                 size_t vl);
void __riscv_vssseg6e8_v_u8mf8x6(uint8_t *rs1, ptrdiff_t rs2, vuint8mf8x6_t vs3,
                                 size_t vl);
void __riscv_vssseg7e8_v_u8mf8x7(uint8_t *rs1, ptrdiff_t rs2, vuint8mf8x7_t vs3,
                                 size_t vl);
void __riscv_vssseg8e8_v_u8mf8x8(uint8_t *rs1, ptrdiff_t rs2, vuint8mf8x8_t vs3,
                                 size_t vl);
void __riscv_vssseg2e8_v_u8mf4x2(uint8_t *rs1, ptrdiff_t rs2, vuint8mf4x2_t vs3,
                                 size_t vl);
void __riscv_vssseg3e8_v_u8mf4x3(uint8_t *rs1, ptrdiff_t rs2, vuint8mf4x3_t vs3,
                                 size_t vl);
void __riscv_vssseg4e8_v_u8mf4x4(uint8_t *rs1, ptrdiff_t rs2, vuint8mf4x4_t vs3,
                                 size_t vl);
void __riscv_vssseg5e8_v_u8mf4x5(uint8_t *rs1, ptrdiff_t rs2, vuint8mf4x5_t vs3,
                                 size_t vl);
void __riscv_vssseg6e8_v_u8mf4x6(uint8_t *rs1, ptrdiff_t rs2, vuint8mf4x6_t vs3,
                                 size_t vl);
void __riscv_vssseg7e8_v_u8mf4x7(uint8_t *rs1, ptrdiff_t rs2, vuint8mf4x7_t vs3,
                                 size_t vl);
void __riscv_vssseg8e8_v_u8mf4x8(uint8_t *rs1, ptrdiff_t rs2, vuint8mf4x8_t vs3,
                                 size_t vl);
void __riscv_vssseg2e8_v_u8mf2x2(uint8_t *rs1, ptrdiff_t rs2, vuint8mf2x2_t vs3,
                                 size_t vl);
void __riscv_vssseg3e8_v_u8mf2x3(uint8_t *rs1, ptrdiff_t rs2, vuint8mf2x3_t vs3,
                                 size_t vl);
void __riscv_vssseg4e8_v_u8mf2x4(uint8_t *rs1, ptrdiff_t rs2, vuint8mf2x4_t vs3,
                                 size_t vl);
void __riscv_vssseg5e8_v_u8mf2x5(uint8_t *rs1, ptrdiff_t rs2, vuint8mf2x5_t vs3,
                                 size_t vl);
void __riscv_vssseg6e8_v_u8mf2x6(uint8_t *rs1, ptrdiff_t rs2, vuint8mf2x6_t vs3,
                                 size_t vl);
void __riscv_vssseg7e8_v_u8mf2x7(uint8_t *rs1, ptrdiff_t rs2, vuint8mf2x7_t vs3,
                                 size_t vl);
void __riscv_vssseg8e8_v_u8mf2x8(uint8_t *rs1, ptrdiff_t rs2, vuint8mf2x8_t vs3,
                                 size_t vl);
void __riscv_vssseg2e8_v_u8m1x2(uint8_t *rs1, ptrdiff_t rs2, vuint8m1x2_t vs3,
                                size_t vl);
void __riscv_vssseg3e8_v_u8m1x3(uint8_t *rs1, ptrdiff_t rs2, vuint8m1x3_t vs3,
                                size_t vl);
void __riscv_vssseg4e8_v_u8m1x4(uint8_t *rs1, ptrdiff_t rs2, vuint8m1x4_t vs3,
                                size_t vl);
void __riscv_vssseg5e8_v_u8m1x5(uint8_t *rs1, ptrdiff_t rs2, vuint8m1x5_t vs3,
                                size_t vl);
void __riscv_vssseg6e8_v_u8m1x6(uint8_t *rs1, ptrdiff_t rs2, vuint8m1x6_t vs3,
                                size_t vl);
void __riscv_vssseg7e8_v_u8m1x7(uint8_t *rs1, ptrdiff_t rs2, vuint8m1x7_t vs3,
                                size_t vl);
void __riscv_vssseg8e8_v_u8m1x8(uint8_t *rs1, ptrdiff_t rs2, vuint8m1x8_t vs3,
                                size_t vl);
void __riscv_vssseg2e8_v_u8m2x2(uint8_t *rs1, ptrdiff_t rs2, vuint8m2x2_t vs3,
                                size_t vl);
void __riscv_vssseg3e8_v_u8m2x3(uint8_t *rs1, ptrdiff_t rs2, vuint8m2x3_t vs3,
                                size_t vl);
void __riscv_vssseg4e8_v_u8m2x4(uint8_t *rs1, ptrdiff_t rs2, vuint8m2x4_t vs3,
                                size_t vl);
void __riscv_vssseg2e8_v_u8m4x2(uint8_t *rs1, ptrdiff_t rs2, vuint8m4x2_t vs3,
                                size_t vl);
void __riscv_vssseg2e16_v_u16mf4x2(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_u16mf4x3(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_u16mf4x4(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_u16mf4x5(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_u16mf4x6(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_u16mf4x7(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_u16mf4x8(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_u16mf2x2(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_u16mf2x3(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_u16mf2x4(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_u16mf2x5(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_u16mf2x6(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_u16mf2x7(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_u16mf2x8(uint16_t *rs1, ptrdiff_t rs2,
                                   vuint16mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_u16m1x2(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m1x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_u16m1x3(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m1x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_u16m1x4(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m1x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_u16m1x5(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m1x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_u16m1x6(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m1x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_u16m1x7(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m1x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_u16m1x8(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m1x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_u16m2x2(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_u16m2x3(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_u16m2x4(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m2x4_t vs3, size_t vl);
void __riscv_vssseg2e16_v_u16m4x2(uint16_t *rs1, ptrdiff_t rs2,
                                  vuint16m4x2_t vs3, size_t vl);
void __riscv_vssseg2e32_v_u32mf2x2(uint32_t *rs1, ptrdiff_t rs2,
                                   vuint32mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_u32mf2x3(uint32_t *rs1, ptrdiff_t rs2,
                                   vuint32mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_u32mf2x4(uint32_t *rs1, ptrdiff_t rs2,
                                   vuint32mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e32_v_u32mf2x5(uint32_t *rs1, ptrdiff_t rs2,
                                   vuint32mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e32_v_u32mf2x6(uint32_t *rs1, ptrdiff_t rs2,
                                   vuint32mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e32_v_u32mf2x7(uint32_t *rs1, ptrdiff_t rs2,
                                   vuint32mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e32_v_u32mf2x8(uint32_t *rs1, ptrdiff_t rs2,
                                   vuint32mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e32_v_u32m1x2(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m1x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_u32m1x3(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m1x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_u32m1x4(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m1x4_t vs3, size_t vl);
void __riscv_vssseg5e32_v_u32m1x5(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m1x5_t vs3, size_t vl);
void __riscv_vssseg6e32_v_u32m1x6(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m1x6_t vs3, size_t vl);
void __riscv_vssseg7e32_v_u32m1x7(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m1x7_t vs3, size_t vl);
void __riscv_vssseg8e32_v_u32m1x8(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m1x8_t vs3, size_t vl);
void __riscv_vssseg2e32_v_u32m2x2(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m2x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_u32m2x3(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m2x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_u32m2x4(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m2x4_t vs3, size_t vl);
void __riscv_vssseg2e32_v_u32m4x2(uint32_t *rs1, ptrdiff_t rs2,
                                  vuint32m4x2_t vs3, size_t vl);
void __riscv_vssseg2e64_v_u64m1x2(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m1x2_t vs3, size_t vl);
void __riscv_vssseg3e64_v_u64m1x3(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m1x3_t vs3, size_t vl);
void __riscv_vssseg4e64_v_u64m1x4(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m1x4_t vs3, size_t vl);
void __riscv_vssseg5e64_v_u64m1x5(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m1x5_t vs3, size_t vl);
void __riscv_vssseg6e64_v_u64m1x6(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m1x6_t vs3, size_t vl);
void __riscv_vssseg7e64_v_u64m1x7(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m1x7_t vs3, size_t vl);
void __riscv_vssseg8e64_v_u64m1x8(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m1x8_t vs3, size_t vl);
void __riscv_vssseg2e64_v_u64m2x2(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m2x2_t vs3, size_t vl);
void __riscv_vssseg3e64_v_u64m2x3(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m2x3_t vs3, size_t vl);
void __riscv_vssseg4e64_v_u64m2x4(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m2x4_t vs3, size_t vl);
void __riscv_vssseg2e64_v_u64m4x2(uint64_t *rs1, ptrdiff_t rs2,
                                  vuint64m4x2_t vs3, size_t vl);
// masked functions
void __riscv_vssseg2e16_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m2x4_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m4x2_t vs3, size_t vl);
void __riscv_vssseg2e32_v_f32mf2x2_m(vbool64_t vm, float *rs1, ptrdiff_t rs2,
                                     vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_f32mf2x3_m(vbool64_t vm, float *rs1, ptrdiff_t rs2,
                                     vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_f32mf2x4_m(vbool64_t vm, float *rs1, ptrdiff_t rs2,
                                     vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e32_v_f32mf2x5_m(vbool64_t vm, float *rs1, ptrdiff_t rs2,
                                     vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e32_v_f32mf2x6_m(vbool64_t vm, float *rs1, ptrdiff_t rs2,
                                     vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e32_v_f32mf2x7_m(vbool64_t vm, float *rs1, ptrdiff_t rs2,
                                     vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e32_v_f32mf2x8_m(vbool64_t vm, float *rs1, ptrdiff_t rs2,
                                     vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e32_v_f32m1x2_m(vbool32_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m1x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_f32m1x3_m(vbool32_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m1x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_f32m1x4_m(vbool32_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m1x4_t vs3, size_t vl);
void __riscv_vssseg5e32_v_f32m1x5_m(vbool32_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m1x5_t vs3, size_t vl);
void __riscv_vssseg6e32_v_f32m1x6_m(vbool32_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m1x6_t vs3, size_t vl);
void __riscv_vssseg7e32_v_f32m1x7_m(vbool32_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m1x7_t vs3, size_t vl);
void __riscv_vssseg8e32_v_f32m1x8_m(vbool32_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m1x8_t vs3, size_t vl);
void __riscv_vssseg2e32_v_f32m2x2_m(vbool16_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m2x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_f32m2x3_m(vbool16_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m2x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_f32m2x4_m(vbool16_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m2x4_t vs3, size_t vl);
void __riscv_vssseg2e32_v_f32m4x2_m(vbool8_t vm, float *rs1, ptrdiff_t rs2,
                                    vfloat32m4x2_t vs3, size_t vl);
void __riscv_vssseg2e64_v_f64m1x2_m(vbool64_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m1x2_t vs3, size_t vl);
void __riscv_vssseg3e64_v_f64m1x3_m(vbool64_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m1x3_t vs3, size_t vl);
void __riscv_vssseg4e64_v_f64m1x4_m(vbool64_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m1x4_t vs3, size_t vl);
void __riscv_vssseg5e64_v_f64m1x5_m(vbool64_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m1x5_t vs3, size_t vl);
void __riscv_vssseg6e64_v_f64m1x6_m(vbool64_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m1x6_t vs3, size_t vl);
void __riscv_vssseg7e64_v_f64m1x7_m(vbool64_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m1x7_t vs3, size_t vl);
void __riscv_vssseg8e64_v_f64m1x8_m(vbool64_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m1x8_t vs3, size_t vl);
void __riscv_vssseg2e64_v_f64m2x2_m(vbool32_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m2x2_t vs3, size_t vl);
void __riscv_vssseg3e64_v_f64m2x3_m(vbool32_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m2x3_t vs3, size_t vl);
void __riscv_vssseg4e64_v_f64m2x4_m(vbool32_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m2x4_t vs3, size_t vl);
void __riscv_vssseg2e64_v_f64m4x2_m(vbool16_t vm, double *rs1, ptrdiff_t rs2,
                                    vfloat64m4x2_t vs3, size_t vl);
void __riscv_vssseg2e8_v_i8mf8x2_m(vbool64_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf8x2_t vs3, size_t vl);
void __riscv_vssseg3e8_v_i8mf8x3_m(vbool64_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf8x3_t vs3, size_t vl);
void __riscv_vssseg4e8_v_i8mf8x4_m(vbool64_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf8x4_t vs3, size_t vl);
void __riscv_vssseg5e8_v_i8mf8x5_m(vbool64_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf8x5_t vs3, size_t vl);
void __riscv_vssseg6e8_v_i8mf8x6_m(vbool64_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf8x6_t vs3, size_t vl);
void __riscv_vssseg7e8_v_i8mf8x7_m(vbool64_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf8x7_t vs3, size_t vl);
void __riscv_vssseg8e8_v_i8mf8x8_m(vbool64_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf8x8_t vs3, size_t vl);
void __riscv_vssseg2e8_v_i8mf4x2_m(vbool32_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e8_v_i8mf4x3_m(vbool32_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e8_v_i8mf4x4_m(vbool32_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e8_v_i8mf4x5_m(vbool32_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e8_v_i8mf4x6_m(vbool32_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e8_v_i8mf4x7_m(vbool32_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e8_v_i8mf4x8_m(vbool32_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e8_v_i8mf2x2_m(vbool16_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e8_v_i8mf2x3_m(vbool16_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e8_v_i8mf2x4_m(vbool16_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e8_v_i8mf2x5_m(vbool16_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e8_v_i8mf2x6_m(vbool16_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e8_v_i8mf2x7_m(vbool16_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e8_v_i8mf2x8_m(vbool16_t vm, int8_t *rs1, ptrdiff_t rs2,
                                   vint8mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e8_v_i8m1x2_m(vbool8_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m1x2_t vs3, size_t vl);
void __riscv_vssseg3e8_v_i8m1x3_m(vbool8_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m1x3_t vs3, size_t vl);
void __riscv_vssseg4e8_v_i8m1x4_m(vbool8_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m1x4_t vs3, size_t vl);
void __riscv_vssseg5e8_v_i8m1x5_m(vbool8_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m1x5_t vs3, size_t vl);
void __riscv_vssseg6e8_v_i8m1x6_m(vbool8_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m1x6_t vs3, size_t vl);
void __riscv_vssseg7e8_v_i8m1x7_m(vbool8_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m1x7_t vs3, size_t vl);
void __riscv_vssseg8e8_v_i8m1x8_m(vbool8_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m1x8_t vs3, size_t vl);
void __riscv_vssseg2e8_v_i8m2x2_m(vbool4_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m2x2_t vs3, size_t vl);
void __riscv_vssseg3e8_v_i8m2x3_m(vbool4_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m2x3_t vs3, size_t vl);
void __riscv_vssseg4e8_v_i8m2x4_m(vbool4_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m2x4_t vs3, size_t vl);
void __riscv_vssseg2e8_v_i8m4x2_m(vbool2_t vm, int8_t *rs1, ptrdiff_t rs2,
                                  vint8m4x2_t vs3, size_t vl);
void __riscv_vssseg2e16_v_i16mf4x2_m(vbool64_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_i16mf4x3_m(vbool64_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_i16mf4x4_m(vbool64_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_i16mf4x5_m(vbool64_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_i16mf4x6_m(vbool64_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_i16mf4x7_m(vbool64_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_i16mf4x8_m(vbool64_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_i16mf2x2_m(vbool32_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_i16mf2x3_m(vbool32_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_i16mf2x4_m(vbool32_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_i16mf2x5_m(vbool32_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_i16mf2x6_m(vbool32_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_i16mf2x7_m(vbool32_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_i16mf2x8_m(vbool32_t vm, int16_t *rs1, ptrdiff_t rs2,
                                     vint16mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_i16m1x2_m(vbool16_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m1x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_i16m1x3_m(vbool16_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m1x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_i16m1x4_m(vbool16_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m1x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_i16m1x5_m(vbool16_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m1x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_i16m1x6_m(vbool16_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m1x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_i16m1x7_m(vbool16_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m1x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_i16m1x8_m(vbool16_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m1x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_i16m2x2_m(vbool8_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_i16m2x3_m(vbool8_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_i16m2x4_m(vbool8_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m2x4_t vs3, size_t vl);
void __riscv_vssseg2e16_v_i16m4x2_m(vbool4_t vm, int16_t *rs1, ptrdiff_t rs2,
                                    vint16m4x2_t vs3, size_t vl);
void __riscv_vssseg2e32_v_i32mf2x2_m(vbool64_t vm, int32_t *rs1, ptrdiff_t rs2,
                                     vint32mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_i32mf2x3_m(vbool64_t vm, int32_t *rs1, ptrdiff_t rs2,
                                     vint32mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_i32mf2x4_m(vbool64_t vm, int32_t *rs1, ptrdiff_t rs2,
                                     vint32mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e32_v_i32mf2x5_m(vbool64_t vm, int32_t *rs1, ptrdiff_t rs2,
                                     vint32mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e32_v_i32mf2x6_m(vbool64_t vm, int32_t *rs1, ptrdiff_t rs2,
                                     vint32mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e32_v_i32mf2x7_m(vbool64_t vm, int32_t *rs1, ptrdiff_t rs2,
                                     vint32mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e32_v_i32mf2x8_m(vbool64_t vm, int32_t *rs1, ptrdiff_t rs2,
                                     vint32mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e32_v_i32m1x2_m(vbool32_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m1x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_i32m1x3_m(vbool32_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m1x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_i32m1x4_m(vbool32_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m1x4_t vs3, size_t vl);
void __riscv_vssseg5e32_v_i32m1x5_m(vbool32_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m1x5_t vs3, size_t vl);
void __riscv_vssseg6e32_v_i32m1x6_m(vbool32_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m1x6_t vs3, size_t vl);
void __riscv_vssseg7e32_v_i32m1x7_m(vbool32_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m1x7_t vs3, size_t vl);
void __riscv_vssseg8e32_v_i32m1x8_m(vbool32_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m1x8_t vs3, size_t vl);
void __riscv_vssseg2e32_v_i32m2x2_m(vbool16_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m2x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_i32m2x3_m(vbool16_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m2x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_i32m2x4_m(vbool16_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m2x4_t vs3, size_t vl);
void __riscv_vssseg2e32_v_i32m4x2_m(vbool8_t vm, int32_t *rs1, ptrdiff_t rs2,
                                    vint32m4x2_t vs3, size_t vl);
void __riscv_vssseg2e64_v_i64m1x2_m(vbool64_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m1x2_t vs3, size_t vl);
void __riscv_vssseg3e64_v_i64m1x3_m(vbool64_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m1x3_t vs3, size_t vl);
void __riscv_vssseg4e64_v_i64m1x4_m(vbool64_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m1x4_t vs3, size_t vl);
void __riscv_vssseg5e64_v_i64m1x5_m(vbool64_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m1x5_t vs3, size_t vl);
void __riscv_vssseg6e64_v_i64m1x6_m(vbool64_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m1x6_t vs3, size_t vl);
void __riscv_vssseg7e64_v_i64m1x7_m(vbool64_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m1x7_t vs3, size_t vl);
void __riscv_vssseg8e64_v_i64m1x8_m(vbool64_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m1x8_t vs3, size_t vl);
void __riscv_vssseg2e64_v_i64m2x2_m(vbool32_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m2x2_t vs3, size_t vl);
void __riscv_vssseg3e64_v_i64m2x3_m(vbool32_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m2x3_t vs3, size_t vl);
void __riscv_vssseg4e64_v_i64m2x4_m(vbool32_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m2x4_t vs3, size_t vl);
void __riscv_vssseg2e64_v_i64m4x2_m(vbool16_t vm, int64_t *rs1, ptrdiff_t rs2,
                                    vint64m4x2_t vs3, size_t vl);
void __riscv_vssseg2e8_v_u8mf8x2_m(vbool64_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf8x2_t vs3, size_t vl);
void __riscv_vssseg3e8_v_u8mf8x3_m(vbool64_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf8x3_t vs3, size_t vl);
void __riscv_vssseg4e8_v_u8mf8x4_m(vbool64_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf8x4_t vs3, size_t vl);
void __riscv_vssseg5e8_v_u8mf8x5_m(vbool64_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf8x5_t vs3, size_t vl);
void __riscv_vssseg6e8_v_u8mf8x6_m(vbool64_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf8x6_t vs3, size_t vl);
void __riscv_vssseg7e8_v_u8mf8x7_m(vbool64_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf8x7_t vs3, size_t vl);
void __riscv_vssseg8e8_v_u8mf8x8_m(vbool64_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf8x8_t vs3, size_t vl);
void __riscv_vssseg2e8_v_u8mf4x2_m(vbool32_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e8_v_u8mf4x3_m(vbool32_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e8_v_u8mf4x4_m(vbool32_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e8_v_u8mf4x5_m(vbool32_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e8_v_u8mf4x6_m(vbool32_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e8_v_u8mf4x7_m(vbool32_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e8_v_u8mf4x8_m(vbool32_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e8_v_u8mf2x2_m(vbool16_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e8_v_u8mf2x3_m(vbool16_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e8_v_u8mf2x4_m(vbool16_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e8_v_u8mf2x5_m(vbool16_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e8_v_u8mf2x6_m(vbool16_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e8_v_u8mf2x7_m(vbool16_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e8_v_u8mf2x8_m(vbool16_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                   vuint8mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e8_v_u8m1x2_m(vbool8_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m1x2_t vs3, size_t vl);
void __riscv_vssseg3e8_v_u8m1x3_m(vbool8_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m1x3_t vs3, size_t vl);
void __riscv_vssseg4e8_v_u8m1x4_m(vbool8_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m1x4_t vs3, size_t vl);
void __riscv_vssseg5e8_v_u8m1x5_m(vbool8_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m1x5_t vs3, size_t vl);
void __riscv_vssseg6e8_v_u8m1x6_m(vbool8_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m1x6_t vs3, size_t vl);
void __riscv_vssseg7e8_v_u8m1x7_m(vbool8_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m1x7_t vs3, size_t vl);
void __riscv_vssseg8e8_v_u8m1x8_m(vbool8_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m1x8_t vs3, size_t vl);
void __riscv_vssseg2e8_v_u8m2x2_m(vbool4_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m2x2_t vs3, size_t vl);
void __riscv_vssseg3e8_v_u8m2x3_m(vbool4_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m2x3_t vs3, size_t vl);
void __riscv_vssseg4e8_v_u8m2x4_m(vbool4_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m2x4_t vs3, size_t vl);
void __riscv_vssseg2e8_v_u8m4x2_m(vbool2_t vm, uint8_t *rs1, ptrdiff_t rs2,
                                  vuint8m4x2_t vs3, size_t vl);
void __riscv_vssseg2e16_v_u16mf4x2_m(vbool64_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_u16mf4x3_m(vbool64_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_u16mf4x4_m(vbool64_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_u16mf4x5_m(vbool64_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_u16mf4x6_m(vbool64_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_u16mf4x7_m(vbool64_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_u16mf4x8_m(vbool64_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_u16mf2x2_m(vbool32_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_u16mf2x3_m(vbool32_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_u16mf2x4_m(vbool32_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_u16mf2x5_m(vbool32_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_u16mf2x6_m(vbool32_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_u16mf2x7_m(vbool32_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_u16mf2x8_m(vbool32_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                     vuint16mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_u16m1x2_m(vbool16_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m1x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_u16m1x3_m(vbool16_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m1x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_u16m1x4_m(vbool16_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m1x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_u16m1x5_m(vbool16_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m1x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_u16m1x6_m(vbool16_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m1x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_u16m1x7_m(vbool16_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m1x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_u16m1x8_m(vbool16_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m1x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_u16m2x2_m(vbool8_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_u16m2x3_m(vbool8_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_u16m2x4_m(vbool8_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m2x4_t vs3, size_t vl);
void __riscv_vssseg2e16_v_u16m4x2_m(vbool4_t vm, uint16_t *rs1, ptrdiff_t rs2,
                                    vuint16m4x2_t vs3, size_t vl);
void __riscv_vssseg2e32_v_u32mf2x2_m(vbool64_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                     vuint32mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_u32mf2x3_m(vbool64_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                     vuint32mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_u32mf2x4_m(vbool64_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                     vuint32mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e32_v_u32mf2x5_m(vbool64_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                     vuint32mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e32_v_u32mf2x6_m(vbool64_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                     vuint32mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e32_v_u32mf2x7_m(vbool64_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                     vuint32mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e32_v_u32mf2x8_m(vbool64_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                     vuint32mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e32_v_u32m1x2_m(vbool32_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m1x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_u32m1x3_m(vbool32_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m1x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_u32m1x4_m(vbool32_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m1x4_t vs3, size_t vl);
void __riscv_vssseg5e32_v_u32m1x5_m(vbool32_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m1x5_t vs3, size_t vl);
void __riscv_vssseg6e32_v_u32m1x6_m(vbool32_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m1x6_t vs3, size_t vl);
void __riscv_vssseg7e32_v_u32m1x7_m(vbool32_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m1x7_t vs3, size_t vl);
void __riscv_vssseg8e32_v_u32m1x8_m(vbool32_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m1x8_t vs3, size_t vl);
void __riscv_vssseg2e32_v_u32m2x2_m(vbool16_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m2x2_t vs3, size_t vl);
void __riscv_vssseg3e32_v_u32m2x3_m(vbool16_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m2x3_t vs3, size_t vl);
void __riscv_vssseg4e32_v_u32m2x4_m(vbool16_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m2x4_t vs3, size_t vl);
void __riscv_vssseg2e32_v_u32m4x2_m(vbool8_t vm, uint32_t *rs1, ptrdiff_t rs2,
                                    vuint32m4x2_t vs3, size_t vl);
void __riscv_vssseg2e64_v_u64m1x2_m(vbool64_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m1x2_t vs3, size_t vl);
void __riscv_vssseg3e64_v_u64m1x3_m(vbool64_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m1x3_t vs3, size_t vl);
void __riscv_vssseg4e64_v_u64m1x4_m(vbool64_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m1x4_t vs3, size_t vl);
void __riscv_vssseg5e64_v_u64m1x5_m(vbool64_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m1x5_t vs3, size_t vl);
void __riscv_vssseg6e64_v_u64m1x6_m(vbool64_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m1x6_t vs3, size_t vl);
void __riscv_vssseg7e64_v_u64m1x7_m(vbool64_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m1x7_t vs3, size_t vl);
void __riscv_vssseg8e64_v_u64m1x8_m(vbool64_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m1x8_t vs3, size_t vl);
void __riscv_vssseg2e64_v_u64m2x2_m(vbool32_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m2x2_t vs3, size_t vl);
void __riscv_vssseg3e64_v_u64m2x3_m(vbool32_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m2x3_t vs3, size_t vl);
void __riscv_vssseg4e64_v_u64m2x4_m(vbool32_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m2x4_t vs3, size_t vl);
void __riscv_vssseg2e64_v_u64m4x2_m(vbool16_t vm, uint64_t *rs1, ptrdiff_t rs2,
                                    vuint64m4x2_t vs3, size_t vl);
----

[[vector-indexed-segment-load]]
==== Vector Indexed Segment Load Intrinsics

[,c]
----
vfloat16mf4x2_t __riscv_vloxseg2ei8_v_f16mf4x2(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei8_v_f16mf4x3(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei8_v_f16mf4x4(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei8_v_f16mf4x5(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei8_v_f16mf4x6(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei8_v_f16mf4x7(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei8_v_f16mf4x8(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei8_v_f16mf2x2(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei8_v_f16mf2x3(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei8_v_f16mf2x4(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei8_v_f16mf2x5(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei8_v_f16mf2x6(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei8_v_f16mf2x7(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei8_v_f16mf2x8(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei8_v_f16m1x2(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei8_v_f16m1x3(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei8_v_f16m1x4(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei8_v_f16m1x5(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei8_v_f16m1x6(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei8_v_f16m1x7(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei8_v_f16m1x8(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei8_v_f16m2x2(const _Float16 *rs1,
                                             vuint8m1_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei8_v_f16m2x3(const _Float16 *rs1,
                                             vuint8m1_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei8_v_f16m2x4(const _Float16 *rs1,
                                             vuint8m1_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei8_v_f16m4x2(const _Float16 *rs1,
                                             vuint8m2_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei16_v_f16mf4x2(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_v_f16mf4x3(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_v_f16mf4x4(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_v_f16mf4x5(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_v_f16mf4x6(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_v_f16mf4x7(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_v_f16mf4x8(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_v_f16mf2x2(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_v_f16mf2x3(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_v_f16mf2x4(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_v_f16mf2x5(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_v_f16mf2x6(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_v_f16mf2x7(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_v_f16mf2x8(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_v_f16m1x2(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_v_f16m1x3(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_v_f16m1x4(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_v_f16m1x5(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_v_f16m1x6(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_v_f16m1x7(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_v_f16m1x8(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_v_f16m2x2(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_v_f16m2x3(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_v_f16m2x4(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_v_f16m4x2(const _Float16 *rs1,
                                              vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei32_v_f16mf4x2(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei32_v_f16mf4x3(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei32_v_f16mf4x4(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei32_v_f16mf4x5(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei32_v_f16mf4x6(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei32_v_f16mf4x7(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei32_v_f16mf4x8(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei32_v_f16mf2x2(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei32_v_f16mf2x3(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei32_v_f16mf2x4(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei32_v_f16mf2x5(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei32_v_f16mf2x6(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei32_v_f16mf2x7(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei32_v_f16mf2x8(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei32_v_f16m1x2(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei32_v_f16m1x3(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei32_v_f16m1x4(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei32_v_f16m1x5(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei32_v_f16m1x6(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei32_v_f16m1x7(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei32_v_f16m1x8(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei32_v_f16m2x2(const _Float16 *rs1,
                                              vuint32m4_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei32_v_f16m2x3(const _Float16 *rs1,
                                              vuint32m4_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei32_v_f16m2x4(const _Float16 *rs1,
                                              vuint32m4_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei32_v_f16m4x2(const _Float16 *rs1,
                                              vuint32m8_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei64_v_f16mf4x2(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei64_v_f16mf4x3(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei64_v_f16mf4x4(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei64_v_f16mf4x5(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei64_v_f16mf4x6(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei64_v_f16mf4x7(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei64_v_f16mf4x8(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei64_v_f16mf2x2(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei64_v_f16mf2x3(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei64_v_f16mf2x4(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei64_v_f16mf2x5(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei64_v_f16mf2x6(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei64_v_f16mf2x7(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei64_v_f16mf2x8(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei64_v_f16m1x2(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei64_v_f16m1x3(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei64_v_f16m1x4(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei64_v_f16m1x5(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei64_v_f16m1x6(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei64_v_f16m1x7(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei64_v_f16m1x8(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei64_v_f16m2x2(const _Float16 *rs1,
                                              vuint64m8_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei64_v_f16m2x3(const _Float16 *rs1,
                                              vuint64m8_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei64_v_f16m2x4(const _Float16 *rs1,
                                              vuint64m8_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei8_v_f32mf2x2(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei8_v_f32mf2x3(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei8_v_f32mf2x4(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei8_v_f32mf2x5(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei8_v_f32mf2x6(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei8_v_f32mf2x7(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei8_v_f32mf2x8(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei8_v_f32m1x2(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei8_v_f32m1x3(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei8_v_f32m1x4(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei8_v_f32m1x5(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei8_v_f32m1x6(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei8_v_f32m1x7(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei8_v_f32m1x8(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei8_v_f32m2x2(const float *rs1, vuint8mf2_t rs2,
                                             size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei8_v_f32m2x3(const float *rs1, vuint8mf2_t rs2,
                                             size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei8_v_f32m2x4(const float *rs1, vuint8mf2_t rs2,
                                             size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei8_v_f32m4x2(const float *rs1, vuint8m1_t rs2,
                                             size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei16_v_f32mf2x2(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei16_v_f32mf2x3(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei16_v_f32mf2x4(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei16_v_f32mf2x5(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei16_v_f32mf2x6(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei16_v_f32mf2x7(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei16_v_f32mf2x8(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei16_v_f32m1x2(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei16_v_f32m1x3(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei16_v_f32m1x4(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei16_v_f32m1x5(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei16_v_f32m1x6(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei16_v_f32m1x7(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei16_v_f32m1x8(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei16_v_f32m2x2(const float *rs1, vuint16m1_t rs2,
                                              size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei16_v_f32m2x3(const float *rs1, vuint16m1_t rs2,
                                              size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei16_v_f32m2x4(const float *rs1, vuint16m1_t rs2,
                                              size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei16_v_f32m4x2(const float *rs1, vuint16m2_t rs2,
                                              size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei32_v_f32mf2x2(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_v_f32mf2x3(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_v_f32mf2x4(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_v_f32mf2x5(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_v_f32mf2x6(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_v_f32mf2x7(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_v_f32mf2x8(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_v_f32m1x2(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_v_f32m1x3(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_v_f32m1x4(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_v_f32m1x5(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_v_f32m1x6(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_v_f32m1x7(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_v_f32m1x8(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_v_f32m2x2(const float *rs1, vuint32m2_t rs2,
                                              size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_v_f32m2x3(const float *rs1, vuint32m2_t rs2,
                                              size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_v_f32m2x4(const float *rs1, vuint32m2_t rs2,
                                              size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_v_f32m4x2(const float *rs1, vuint32m4_t rs2,
                                              size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_v_f32mf2x2(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_v_f32mf2x3(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_v_f32mf2x4(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_v_f32mf2x5(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_v_f32mf2x6(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_v_f32mf2x7(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_v_f32mf2x8(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_v_f32m1x2(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_v_f32m1x3(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_v_f32m1x4(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_v_f32m1x5(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_v_f32m1x6(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_v_f32m1x7(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_v_f32m1x8(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_v_f32m2x2(const float *rs1, vuint64m4_t rs2,
                                              size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_v_f32m2x3(const float *rs1, vuint64m4_t rs2,
                                              size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_v_f32m2x4(const float *rs1, vuint64m4_t rs2,
                                              size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_v_f32m4x2(const float *rs1, vuint64m8_t rs2,
                                              size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei8_v_f64m1x2(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei8_v_f64m1x3(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei8_v_f64m1x4(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei8_v_f64m1x5(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei8_v_f64m1x6(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei8_v_f64m1x7(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei8_v_f64m1x8(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei8_v_f64m2x2(const double *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei8_v_f64m2x3(const double *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei8_v_f64m2x4(const double *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei8_v_f64m4x2(const double *rs1, vuint8mf2_t rs2,
                                             size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei16_v_f64m1x2(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei16_v_f64m1x3(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei16_v_f64m1x4(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei16_v_f64m1x5(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei16_v_f64m1x6(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei16_v_f64m1x7(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei16_v_f64m1x8(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei16_v_f64m2x2(const double *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei16_v_f64m2x3(const double *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei16_v_f64m2x4(const double *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei16_v_f64m4x2(const double *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_v_f64m1x2(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_v_f64m1x3(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_v_f64m1x4(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_v_f64m1x5(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_v_f64m1x6(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_v_f64m1x7(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_v_f64m1x8(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_v_f64m2x2(const double *rs1,
                                              vuint32m1_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_v_f64m2x3(const double *rs1,
                                              vuint32m1_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_v_f64m2x4(const double *rs1,
                                              vuint32m1_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_v_f64m4x2(const double *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_v_f64m1x2(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_v_f64m1x3(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_v_f64m1x4(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_v_f64m1x5(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_v_f64m1x6(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_v_f64m1x7(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_v_f64m1x8(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_v_f64m2x2(const double *rs1,
                                              vuint64m2_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_v_f64m2x3(const double *rs1,
                                              vuint64m2_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_v_f64m2x4(const double *rs1,
                                              vuint64m2_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_v_f64m4x2(const double *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei8_v_f16mf4x2(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei8_v_f16mf4x3(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei8_v_f16mf4x4(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei8_v_f16mf4x5(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei8_v_f16mf4x6(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei8_v_f16mf4x7(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei8_v_f16mf4x8(const _Float16 *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei8_v_f16mf2x2(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei8_v_f16mf2x3(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei8_v_f16mf2x4(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei8_v_f16mf2x5(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei8_v_f16mf2x6(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei8_v_f16mf2x7(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei8_v_f16mf2x8(const _Float16 *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei8_v_f16m1x2(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei8_v_f16m1x3(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei8_v_f16m1x4(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei8_v_f16m1x5(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei8_v_f16m1x6(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei8_v_f16m1x7(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei8_v_f16m1x8(const _Float16 *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei8_v_f16m2x2(const _Float16 *rs1,
                                             vuint8m1_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei8_v_f16m2x3(const _Float16 *rs1,
                                             vuint8m1_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei8_v_f16m2x4(const _Float16 *rs1,
                                             vuint8m1_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei8_v_f16m4x2(const _Float16 *rs1,
                                             vuint8m2_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_v_f16mf4x2(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_v_f16mf4x3(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_v_f16mf4x4(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_v_f16mf4x5(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_v_f16mf4x6(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_v_f16mf4x7(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_v_f16mf4x8(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_v_f16mf2x2(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_v_f16mf2x3(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_v_f16mf2x4(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_v_f16mf2x5(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_v_f16mf2x6(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_v_f16mf2x7(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_v_f16mf2x8(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_v_f16m1x2(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_v_f16m1x3(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_v_f16m1x4(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_v_f16m1x5(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_v_f16m1x6(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_v_f16m1x7(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_v_f16m1x8(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_v_f16m2x2(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_v_f16m2x3(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_v_f16m2x4(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_v_f16m4x2(const _Float16 *rs1,
                                              vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei32_v_f16mf4x2(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei32_v_f16mf4x3(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei32_v_f16mf4x4(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei32_v_f16mf4x5(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei32_v_f16mf4x6(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei32_v_f16mf4x7(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei32_v_f16mf4x8(const _Float16 *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei32_v_f16mf2x2(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei32_v_f16mf2x3(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei32_v_f16mf2x4(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei32_v_f16mf2x5(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei32_v_f16mf2x6(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei32_v_f16mf2x7(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei32_v_f16mf2x8(const _Float16 *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei32_v_f16m1x2(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei32_v_f16m1x3(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei32_v_f16m1x4(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei32_v_f16m1x5(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei32_v_f16m1x6(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei32_v_f16m1x7(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei32_v_f16m1x8(const _Float16 *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei32_v_f16m2x2(const _Float16 *rs1,
                                              vuint32m4_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei32_v_f16m2x3(const _Float16 *rs1,
                                              vuint32m4_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei32_v_f16m2x4(const _Float16 *rs1,
                                              vuint32m4_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei32_v_f16m4x2(const _Float16 *rs1,
                                              vuint32m8_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei64_v_f16mf4x2(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei64_v_f16mf4x3(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei64_v_f16mf4x4(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei64_v_f16mf4x5(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei64_v_f16mf4x6(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei64_v_f16mf4x7(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei64_v_f16mf4x8(const _Float16 *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei64_v_f16mf2x2(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei64_v_f16mf2x3(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei64_v_f16mf2x4(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei64_v_f16mf2x5(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei64_v_f16mf2x6(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei64_v_f16mf2x7(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei64_v_f16mf2x8(const _Float16 *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei64_v_f16m1x2(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei64_v_f16m1x3(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei64_v_f16m1x4(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei64_v_f16m1x5(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei64_v_f16m1x6(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei64_v_f16m1x7(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei64_v_f16m1x8(const _Float16 *rs1,
                                              vuint64m4_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei64_v_f16m2x2(const _Float16 *rs1,
                                              vuint64m8_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei64_v_f16m2x3(const _Float16 *rs1,
                                              vuint64m8_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei64_v_f16m2x4(const _Float16 *rs1,
                                              vuint64m8_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei8_v_f32mf2x2(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei8_v_f32mf2x3(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei8_v_f32mf2x4(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei8_v_f32mf2x5(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei8_v_f32mf2x6(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei8_v_f32mf2x7(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei8_v_f32mf2x8(const float *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei8_v_f32m1x2(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei8_v_f32m1x3(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei8_v_f32m1x4(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei8_v_f32m1x5(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei8_v_f32m1x6(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei8_v_f32m1x7(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei8_v_f32m1x8(const float *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei8_v_f32m2x2(const float *rs1, vuint8mf2_t rs2,
                                             size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei8_v_f32m2x3(const float *rs1, vuint8mf2_t rs2,
                                             size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei8_v_f32m2x4(const float *rs1, vuint8mf2_t rs2,
                                             size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei8_v_f32m4x2(const float *rs1, vuint8m1_t rs2,
                                             size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei16_v_f32mf2x2(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei16_v_f32mf2x3(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei16_v_f32mf2x4(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei16_v_f32mf2x5(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei16_v_f32mf2x6(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei16_v_f32mf2x7(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei16_v_f32mf2x8(const float *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei16_v_f32m1x2(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei16_v_f32m1x3(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei16_v_f32m1x4(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei16_v_f32m1x5(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei16_v_f32m1x6(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei16_v_f32m1x7(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei16_v_f32m1x8(const float *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei16_v_f32m2x2(const float *rs1, vuint16m1_t rs2,
                                              size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei16_v_f32m2x3(const float *rs1, vuint16m1_t rs2,
                                              size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei16_v_f32m2x4(const float *rs1, vuint16m1_t rs2,
                                              size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei16_v_f32m4x2(const float *rs1, vuint16m2_t rs2,
                                              size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_v_f32mf2x2(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_v_f32mf2x3(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_v_f32mf2x4(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_v_f32mf2x5(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_v_f32mf2x6(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_v_f32mf2x7(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_v_f32mf2x8(const float *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_v_f32m1x2(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_v_f32m1x3(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_v_f32m1x4(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_v_f32m1x5(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_v_f32m1x6(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_v_f32m1x7(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_v_f32m1x8(const float *rs1, vuint32m1_t rs2,
                                              size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_v_f32m2x2(const float *rs1, vuint32m2_t rs2,
                                              size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_v_f32m2x3(const float *rs1, vuint32m2_t rs2,
                                              size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_v_f32m2x4(const float *rs1, vuint32m2_t rs2,
                                              size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_v_f32m4x2(const float *rs1, vuint32m4_t rs2,
                                              size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_v_f32mf2x2(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_v_f32mf2x3(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_v_f32mf2x4(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_v_f32mf2x5(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_v_f32mf2x6(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_v_f32mf2x7(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_v_f32mf2x8(const float *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_v_f32m1x2(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_v_f32m1x3(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_v_f32m1x4(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_v_f32m1x5(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_v_f32m1x6(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_v_f32m1x7(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_v_f32m1x8(const float *rs1, vuint64m2_t rs2,
                                              size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_v_f32m2x2(const float *rs1, vuint64m4_t rs2,
                                              size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_v_f32m2x3(const float *rs1, vuint64m4_t rs2,
                                              size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_v_f32m2x4(const float *rs1, vuint64m4_t rs2,
                                              size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_v_f32m4x2(const float *rs1, vuint64m8_t rs2,
                                              size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei8_v_f64m1x2(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei8_v_f64m1x3(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei8_v_f64m1x4(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei8_v_f64m1x5(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei8_v_f64m1x6(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei8_v_f64m1x7(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei8_v_f64m1x8(const double *rs1, vuint8mf8_t rs2,
                                             size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei8_v_f64m2x2(const double *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei8_v_f64m2x3(const double *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei8_v_f64m2x4(const double *rs1, vuint8mf4_t rs2,
                                             size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei8_v_f64m4x2(const double *rs1, vuint8mf2_t rs2,
                                             size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei16_v_f64m1x2(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei16_v_f64m1x3(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei16_v_f64m1x4(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei16_v_f64m1x5(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei16_v_f64m1x6(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei16_v_f64m1x7(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei16_v_f64m1x8(const double *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei16_v_f64m2x2(const double *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei16_v_f64m2x3(const double *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei16_v_f64m2x4(const double *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei16_v_f64m4x2(const double *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_v_f64m1x2(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_v_f64m1x3(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_v_f64m1x4(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_v_f64m1x5(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_v_f64m1x6(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_v_f64m1x7(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_v_f64m1x8(const double *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_v_f64m2x2(const double *rs1,
                                              vuint32m1_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_v_f64m2x3(const double *rs1,
                                              vuint32m1_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_v_f64m2x4(const double *rs1,
                                              vuint32m1_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_v_f64m4x2(const double *rs1,
                                              vuint32m2_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_v_f64m1x2(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_v_f64m1x3(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_v_f64m1x4(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_v_f64m1x5(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_v_f64m1x6(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_v_f64m1x7(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_v_f64m1x8(const double *rs1,
                                              vuint64m1_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_v_f64m2x2(const double *rs1,
                                              vuint64m2_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_v_f64m2x3(const double *rs1,
                                              vuint64m2_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_v_f64m2x4(const double *rs1,
                                              vuint64m2_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_v_f64m4x2(const double *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei8_v_i8mf8x2(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_v_i8mf8x3(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_v_i8mf8x4(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_v_i8mf8x5(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_v_i8mf8x6(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_v_i8mf8x7(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_v_i8mf8x8(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_v_i8mf4x2(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_v_i8mf4x3(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_v_i8mf4x4(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_v_i8mf4x5(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_v_i8mf4x6(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_v_i8mf4x7(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_v_i8mf4x8(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_v_i8mf2x2(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_v_i8mf2x3(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_v_i8mf2x4(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_v_i8mf2x5(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_v_i8mf2x6(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_v_i8mf2x7(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_v_i8mf2x8(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_v_i8m1x2(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_v_i8m1x3(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_v_i8m1x4(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_v_i8m1x5(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_v_i8m1x6(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_v_i8m1x7(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_v_i8m1x8(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_v_i8m2x2(const int8_t *rs1, vuint8m2_t rs2,
                                         size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_v_i8m2x3(const int8_t *rs1, vuint8m2_t rs2,
                                         size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_v_i8m2x4(const int8_t *rs1, vuint8m2_t rs2,
                                         size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_v_i8m4x2(const int8_t *rs1, vuint8m4_t rs2,
                                         size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_v_i8mf8x2(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_v_i8mf8x3(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_v_i8mf8x4(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_v_i8mf8x5(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_v_i8mf8x6(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_v_i8mf8x7(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_v_i8mf8x8(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_v_i8mf4x2(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_v_i8mf4x3(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_v_i8mf4x4(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_v_i8mf4x5(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_v_i8mf4x6(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_v_i8mf4x7(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_v_i8mf4x8(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_v_i8mf2x2(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_v_i8mf2x3(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_v_i8mf2x4(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_v_i8mf2x5(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_v_i8mf2x6(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_v_i8mf2x7(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_v_i8mf2x8(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_v_i8m1x2(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_v_i8m1x3(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_v_i8m1x4(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_v_i8m1x5(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_v_i8m1x6(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_v_i8m1x7(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_v_i8m1x8(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_v_i8m2x2(const int8_t *rs1, vuint16m4_t rs2,
                                          size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_v_i8m2x3(const int8_t *rs1, vuint16m4_t rs2,
                                          size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_v_i8m2x4(const int8_t *rs1, vuint16m4_t rs2,
                                          size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_v_i8m4x2(const int8_t *rs1, vuint16m8_t rs2,
                                          size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_v_i8mf8x2(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_v_i8mf8x3(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_v_i8mf8x4(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_v_i8mf8x5(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_v_i8mf8x6(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_v_i8mf8x7(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_v_i8mf8x8(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_v_i8mf4x2(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_v_i8mf4x3(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_v_i8mf4x4(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_v_i8mf4x5(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_v_i8mf4x6(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_v_i8mf4x7(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_v_i8mf4x8(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_v_i8mf2x2(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_v_i8mf2x3(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_v_i8mf2x4(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_v_i8mf2x5(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_v_i8mf2x6(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_v_i8mf2x7(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_v_i8mf2x8(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_v_i8m1x2(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_v_i8m1x3(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_v_i8m1x4(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_v_i8m1x5(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_v_i8m1x6(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_v_i8m1x7(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_v_i8m1x8(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_v_i8m2x2(const int8_t *rs1, vuint32m8_t rs2,
                                          size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_v_i8m2x3(const int8_t *rs1, vuint32m8_t rs2,
                                          size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_v_i8m2x4(const int8_t *rs1, vuint32m8_t rs2,
                                          size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_v_i8mf8x2(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_v_i8mf8x3(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_v_i8mf8x4(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_v_i8mf8x5(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_v_i8mf8x6(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_v_i8mf8x7(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_v_i8mf8x8(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_v_i8mf4x2(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_v_i8mf4x3(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_v_i8mf4x4(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_v_i8mf4x5(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_v_i8mf4x6(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_v_i8mf4x7(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_v_i8mf4x8(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_v_i8mf2x2(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_v_i8mf2x3(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_v_i8mf2x4(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_v_i8mf2x5(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_v_i8mf2x6(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_v_i8mf2x7(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_v_i8mf2x8(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_v_i8m1x2(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_v_i8m1x3(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_v_i8m1x4(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_v_i8m1x5(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_v_i8m1x6(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_v_i8m1x7(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_v_i8m1x8(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_v_i16mf4x2(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_v_i16mf4x3(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_v_i16mf4x4(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_v_i16mf4x5(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_v_i16mf4x6(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_v_i16mf4x7(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_v_i16mf4x8(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_v_i16mf2x2(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_v_i16mf2x3(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_v_i16mf2x4(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_v_i16mf2x5(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_v_i16mf2x6(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_v_i16mf2x7(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_v_i16mf2x8(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_v_i16m1x2(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_v_i16m1x3(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_v_i16m1x4(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_v_i16m1x5(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_v_i16m1x6(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_v_i16m1x7(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_v_i16m1x8(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_v_i16m2x2(const int16_t *rs1, vuint8m1_t rs2,
                                           size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_v_i16m2x3(const int16_t *rs1, vuint8m1_t rs2,
                                           size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_v_i16m2x4(const int16_t *rs1, vuint8m1_t rs2,
                                           size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_v_i16m4x2(const int16_t *rs1, vuint8m2_t rs2,
                                           size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_v_i16mf4x2(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_v_i16mf4x3(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_v_i16mf4x4(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_v_i16mf4x5(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_v_i16mf4x6(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_v_i16mf4x7(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_v_i16mf4x8(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_v_i16mf2x2(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_v_i16mf2x3(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_v_i16mf2x4(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_v_i16mf2x5(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_v_i16mf2x6(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_v_i16mf2x7(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_v_i16mf2x8(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_v_i16m1x2(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_v_i16m1x3(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_v_i16m1x4(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_v_i16m1x5(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_v_i16m1x6(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_v_i16m1x7(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_v_i16m1x8(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_v_i16m2x2(const int16_t *rs1, vuint16m2_t rs2,
                                            size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_v_i16m2x3(const int16_t *rs1, vuint16m2_t rs2,
                                            size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_v_i16m2x4(const int16_t *rs1, vuint16m2_t rs2,
                                            size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_v_i16m4x2(const int16_t *rs1, vuint16m4_t rs2,
                                            size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_v_i16mf4x2(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_v_i16mf4x3(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_v_i16mf4x4(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_v_i16mf4x5(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_v_i16mf4x6(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_v_i16mf4x7(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_v_i16mf4x8(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_v_i16mf2x2(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_v_i16mf2x3(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_v_i16mf2x4(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_v_i16mf2x5(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_v_i16mf2x6(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_v_i16mf2x7(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_v_i16mf2x8(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_v_i16m1x2(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_v_i16m1x3(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_v_i16m1x4(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_v_i16m1x5(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_v_i16m1x6(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_v_i16m1x7(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_v_i16m1x8(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_v_i16m2x2(const int16_t *rs1, vuint32m4_t rs2,
                                            size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_v_i16m2x3(const int16_t *rs1, vuint32m4_t rs2,
                                            size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_v_i16m2x4(const int16_t *rs1, vuint32m4_t rs2,
                                            size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_v_i16m4x2(const int16_t *rs1, vuint32m8_t rs2,
                                            size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_v_i16mf4x2(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_v_i16mf4x3(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_v_i16mf4x4(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_v_i16mf4x5(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_v_i16mf4x6(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_v_i16mf4x7(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_v_i16mf4x8(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_v_i16mf2x2(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_v_i16mf2x3(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_v_i16mf2x4(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_v_i16mf2x5(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_v_i16mf2x6(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_v_i16mf2x7(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_v_i16mf2x8(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_v_i16m1x2(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_v_i16m1x3(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_v_i16m1x4(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_v_i16m1x5(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_v_i16m1x6(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_v_i16m1x7(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_v_i16m1x8(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_v_i16m2x2(const int16_t *rs1, vuint64m8_t rs2,
                                            size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_v_i16m2x3(const int16_t *rs1, vuint64m8_t rs2,
                                            size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_v_i16m2x4(const int16_t *rs1, vuint64m8_t rs2,
                                            size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_v_i32mf2x2(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_v_i32mf2x3(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_v_i32mf2x4(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_v_i32mf2x5(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_v_i32mf2x6(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_v_i32mf2x7(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_v_i32mf2x8(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_v_i32m1x2(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_v_i32m1x3(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_v_i32m1x4(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_v_i32m1x5(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_v_i32m1x6(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_v_i32m1x7(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_v_i32m1x8(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_v_i32m2x2(const int32_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_v_i32m2x3(const int32_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_v_i32m2x4(const int32_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_v_i32m4x2(const int32_t *rs1, vuint8m1_t rs2,
                                           size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_v_i32mf2x2(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_v_i32mf2x3(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_v_i32mf2x4(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_v_i32mf2x5(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_v_i32mf2x6(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_v_i32mf2x7(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_v_i32mf2x8(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_v_i32m1x2(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_v_i32m1x3(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_v_i32m1x4(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_v_i32m1x5(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_v_i32m1x6(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_v_i32m1x7(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_v_i32m1x8(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_v_i32m2x2(const int32_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_v_i32m2x3(const int32_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_v_i32m2x4(const int32_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_v_i32m4x2(const int32_t *rs1, vuint16m2_t rs2,
                                            size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_v_i32mf2x2(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_v_i32mf2x3(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_v_i32mf2x4(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_v_i32mf2x5(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_v_i32mf2x6(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_v_i32mf2x7(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_v_i32mf2x8(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_v_i32m1x2(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_v_i32m1x3(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_v_i32m1x4(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_v_i32m1x5(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_v_i32m1x6(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_v_i32m1x7(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_v_i32m1x8(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_v_i32m2x2(const int32_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_v_i32m2x3(const int32_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_v_i32m2x4(const int32_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_v_i32m4x2(const int32_t *rs1, vuint32m4_t rs2,
                                            size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_v_i32mf2x2(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_v_i32mf2x3(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_v_i32mf2x4(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_v_i32mf2x5(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_v_i32mf2x6(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_v_i32mf2x7(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_v_i32mf2x8(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_v_i32m1x2(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_v_i32m1x3(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_v_i32m1x4(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_v_i32m1x5(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_v_i32m1x6(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_v_i32m1x7(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_v_i32m1x8(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_v_i32m2x2(const int32_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_v_i32m2x3(const int32_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_v_i32m2x4(const int32_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_v_i32m4x2(const int32_t *rs1, vuint64m8_t rs2,
                                            size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_v_i64m1x2(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_v_i64m1x3(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_v_i64m1x4(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_v_i64m1x5(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_v_i64m1x6(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_v_i64m1x7(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_v_i64m1x8(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_v_i64m2x2(const int64_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_v_i64m2x3(const int64_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_v_i64m2x4(const int64_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_v_i64m4x2(const int64_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_v_i64m1x2(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_v_i64m1x3(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_v_i64m1x4(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_v_i64m1x5(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_v_i64m1x6(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_v_i64m1x7(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_v_i64m1x8(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_v_i64m2x2(const int64_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_v_i64m2x3(const int64_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_v_i64m2x4(const int64_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_v_i64m4x2(const int64_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_v_i64m1x2(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_v_i64m1x3(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_v_i64m1x4(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_v_i64m1x5(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_v_i64m1x6(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_v_i64m1x7(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_v_i64m1x8(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_v_i64m2x2(const int64_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_v_i64m2x3(const int64_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_v_i64m2x4(const int64_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_v_i64m4x2(const int64_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_v_i64m1x2(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_v_i64m1x3(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_v_i64m1x4(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_v_i64m1x5(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_v_i64m1x6(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_v_i64m1x7(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_v_i64m1x8(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_v_i64m2x2(const int64_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_v_i64m2x3(const int64_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_v_i64m2x4(const int64_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_v_i64m4x2(const int64_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_v_i8mf8x2(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_v_i8mf8x3(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_v_i8mf8x4(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_v_i8mf8x5(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_v_i8mf8x6(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_v_i8mf8x7(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_v_i8mf8x8(const int8_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_v_i8mf4x2(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_v_i8mf4x3(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_v_i8mf4x4(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_v_i8mf4x5(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_v_i8mf4x6(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_v_i8mf4x7(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_v_i8mf4x8(const int8_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_v_i8mf2x2(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_v_i8mf2x3(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_v_i8mf2x4(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_v_i8mf2x5(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_v_i8mf2x6(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_v_i8mf2x7(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_v_i8mf2x8(const int8_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_v_i8m1x2(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_v_i8m1x3(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_v_i8m1x4(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_v_i8m1x5(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_v_i8m1x6(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_v_i8m1x7(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_v_i8m1x8(const int8_t *rs1, vuint8m1_t rs2,
                                         size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_v_i8m2x2(const int8_t *rs1, vuint8m2_t rs2,
                                         size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_v_i8m2x3(const int8_t *rs1, vuint8m2_t rs2,
                                         size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_v_i8m2x4(const int8_t *rs1, vuint8m2_t rs2,
                                         size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_v_i8m4x2(const int8_t *rs1, vuint8m4_t rs2,
                                         size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_v_i8mf8x2(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_v_i8mf8x3(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_v_i8mf8x4(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_v_i8mf8x5(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_v_i8mf8x6(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_v_i8mf8x7(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_v_i8mf8x8(const int8_t *rs1, vuint16mf4_t rs2,
                                            size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_v_i8mf4x2(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_v_i8mf4x3(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_v_i8mf4x4(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_v_i8mf4x5(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_v_i8mf4x6(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_v_i8mf4x7(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_v_i8mf4x8(const int8_t *rs1, vuint16mf2_t rs2,
                                            size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_v_i8mf2x2(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_v_i8mf2x3(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_v_i8mf2x4(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_v_i8mf2x5(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_v_i8mf2x6(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_v_i8mf2x7(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_v_i8mf2x8(const int8_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_v_i8m1x2(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_v_i8m1x3(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_v_i8m1x4(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_v_i8m1x5(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_v_i8m1x6(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_v_i8m1x7(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_v_i8m1x8(const int8_t *rs1, vuint16m2_t rs2,
                                          size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_v_i8m2x2(const int8_t *rs1, vuint16m4_t rs2,
                                          size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_v_i8m2x3(const int8_t *rs1, vuint16m4_t rs2,
                                          size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_v_i8m2x4(const int8_t *rs1, vuint16m4_t rs2,
                                          size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_v_i8m4x2(const int8_t *rs1, vuint16m8_t rs2,
                                          size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_v_i8mf8x2(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_v_i8mf8x3(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_v_i8mf8x4(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_v_i8mf8x5(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_v_i8mf8x6(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_v_i8mf8x7(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_v_i8mf8x8(const int8_t *rs1, vuint32mf2_t rs2,
                                            size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_v_i8mf4x2(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_v_i8mf4x3(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_v_i8mf4x4(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_v_i8mf4x5(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_v_i8mf4x6(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_v_i8mf4x7(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_v_i8mf4x8(const int8_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_v_i8mf2x2(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_v_i8mf2x3(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_v_i8mf2x4(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_v_i8mf2x5(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_v_i8mf2x6(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_v_i8mf2x7(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_v_i8mf2x8(const int8_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_v_i8m1x2(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_v_i8m1x3(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_v_i8m1x4(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_v_i8m1x5(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_v_i8m1x6(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_v_i8m1x7(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_v_i8m1x8(const int8_t *rs1, vuint32m4_t rs2,
                                          size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_v_i8m2x2(const int8_t *rs1, vuint32m8_t rs2,
                                          size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_v_i8m2x3(const int8_t *rs1, vuint32m8_t rs2,
                                          size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_v_i8m2x4(const int8_t *rs1, vuint32m8_t rs2,
                                          size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_v_i8mf8x2(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_v_i8mf8x3(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_v_i8mf8x4(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_v_i8mf8x5(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_v_i8mf8x6(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_v_i8mf8x7(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_v_i8mf8x8(const int8_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_v_i8mf4x2(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_v_i8mf4x3(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_v_i8mf4x4(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_v_i8mf4x5(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_v_i8mf4x6(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_v_i8mf4x7(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_v_i8mf4x8(const int8_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_v_i8mf2x2(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_v_i8mf2x3(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_v_i8mf2x4(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_v_i8mf2x5(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_v_i8mf2x6(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_v_i8mf2x7(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_v_i8mf2x8(const int8_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_v_i8m1x2(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_v_i8m1x3(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_v_i8m1x4(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_v_i8m1x5(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_v_i8m1x6(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_v_i8m1x7(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_v_i8m1x8(const int8_t *rs1, vuint64m8_t rs2,
                                          size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_v_i16mf4x2(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_v_i16mf4x3(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_v_i16mf4x4(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_v_i16mf4x5(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_v_i16mf4x6(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_v_i16mf4x7(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_v_i16mf4x8(const int16_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_v_i16mf2x2(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_v_i16mf2x3(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_v_i16mf2x4(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_v_i16mf2x5(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_v_i16mf2x6(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_v_i16mf2x7(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_v_i16mf2x8(const int16_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_v_i16m1x2(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_v_i16m1x3(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_v_i16m1x4(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_v_i16m1x5(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_v_i16m1x6(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_v_i16m1x7(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_v_i16m1x8(const int16_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_v_i16m2x2(const int16_t *rs1, vuint8m1_t rs2,
                                           size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_v_i16m2x3(const int16_t *rs1, vuint8m1_t rs2,
                                           size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_v_i16m2x4(const int16_t *rs1, vuint8m1_t rs2,
                                           size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_v_i16m4x2(const int16_t *rs1, vuint8m2_t rs2,
                                           size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_v_i16mf4x2(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_v_i16mf4x3(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_v_i16mf4x4(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_v_i16mf4x5(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_v_i16mf4x6(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_v_i16mf4x7(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_v_i16mf4x8(const int16_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_v_i16mf2x2(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_v_i16mf2x3(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_v_i16mf2x4(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_v_i16mf2x5(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_v_i16mf2x6(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_v_i16mf2x7(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_v_i16mf2x8(const int16_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_v_i16m1x2(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_v_i16m1x3(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_v_i16m1x4(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_v_i16m1x5(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_v_i16m1x6(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_v_i16m1x7(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_v_i16m1x8(const int16_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_v_i16m2x2(const int16_t *rs1, vuint16m2_t rs2,
                                            size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_v_i16m2x3(const int16_t *rs1, vuint16m2_t rs2,
                                            size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_v_i16m2x4(const int16_t *rs1, vuint16m2_t rs2,
                                            size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_v_i16m4x2(const int16_t *rs1, vuint16m4_t rs2,
                                            size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_v_i16mf4x2(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_v_i16mf4x3(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_v_i16mf4x4(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_v_i16mf4x5(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_v_i16mf4x6(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_v_i16mf4x7(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_v_i16mf4x8(const int16_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_v_i16mf2x2(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_v_i16mf2x3(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_v_i16mf2x4(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_v_i16mf2x5(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_v_i16mf2x6(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_v_i16mf2x7(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_v_i16mf2x8(const int16_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_v_i16m1x2(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_v_i16m1x3(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_v_i16m1x4(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_v_i16m1x5(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_v_i16m1x6(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_v_i16m1x7(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_v_i16m1x8(const int16_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_v_i16m2x2(const int16_t *rs1, vuint32m4_t rs2,
                                            size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_v_i16m2x3(const int16_t *rs1, vuint32m4_t rs2,
                                            size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_v_i16m2x4(const int16_t *rs1, vuint32m4_t rs2,
                                            size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_v_i16m4x2(const int16_t *rs1, vuint32m8_t rs2,
                                            size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_v_i16mf4x2(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_v_i16mf4x3(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_v_i16mf4x4(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_v_i16mf4x5(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_v_i16mf4x6(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_v_i16mf4x7(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_v_i16mf4x8(const int16_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_v_i16mf2x2(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_v_i16mf2x3(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_v_i16mf2x4(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_v_i16mf2x5(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_v_i16mf2x6(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_v_i16mf2x7(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_v_i16mf2x8(const int16_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_v_i16m1x2(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_v_i16m1x3(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_v_i16m1x4(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_v_i16m1x5(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_v_i16m1x6(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_v_i16m1x7(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_v_i16m1x8(const int16_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_v_i16m2x2(const int16_t *rs1, vuint64m8_t rs2,
                                            size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_v_i16m2x3(const int16_t *rs1, vuint64m8_t rs2,
                                            size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_v_i16m2x4(const int16_t *rs1, vuint64m8_t rs2,
                                            size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_v_i32mf2x2(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_v_i32mf2x3(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_v_i32mf2x4(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_v_i32mf2x5(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_v_i32mf2x6(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_v_i32mf2x7(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_v_i32mf2x8(const int32_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_v_i32m1x2(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_v_i32m1x3(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_v_i32m1x4(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_v_i32m1x5(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_v_i32m1x6(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_v_i32m1x7(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_v_i32m1x8(const int32_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_v_i32m2x2(const int32_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_v_i32m2x3(const int32_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_v_i32m2x4(const int32_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_v_i32m4x2(const int32_t *rs1, vuint8m1_t rs2,
                                           size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_v_i32mf2x2(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_v_i32mf2x3(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_v_i32mf2x4(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_v_i32mf2x5(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_v_i32mf2x6(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_v_i32mf2x7(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_v_i32mf2x8(const int32_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_v_i32m1x2(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_v_i32m1x3(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_v_i32m1x4(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_v_i32m1x5(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_v_i32m1x6(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_v_i32m1x7(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_v_i32m1x8(const int32_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_v_i32m2x2(const int32_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_v_i32m2x3(const int32_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_v_i32m2x4(const int32_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_v_i32m4x2(const int32_t *rs1, vuint16m2_t rs2,
                                            size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_v_i32mf2x2(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_v_i32mf2x3(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_v_i32mf2x4(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_v_i32mf2x5(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_v_i32mf2x6(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_v_i32mf2x7(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_v_i32mf2x8(const int32_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_v_i32m1x2(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_v_i32m1x3(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_v_i32m1x4(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_v_i32m1x5(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_v_i32m1x6(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_v_i32m1x7(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_v_i32m1x8(const int32_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_v_i32m2x2(const int32_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_v_i32m2x3(const int32_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_v_i32m2x4(const int32_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_v_i32m4x2(const int32_t *rs1, vuint32m4_t rs2,
                                            size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_v_i32mf2x2(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_v_i32mf2x3(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_v_i32mf2x4(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_v_i32mf2x5(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_v_i32mf2x6(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_v_i32mf2x7(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_v_i32mf2x8(const int32_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_v_i32m1x2(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_v_i32m1x3(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_v_i32m1x4(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_v_i32m1x5(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_v_i32m1x6(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_v_i32m1x7(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_v_i32m1x8(const int32_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_v_i32m2x2(const int32_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_v_i32m2x3(const int32_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_v_i32m2x4(const int32_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_v_i32m4x2(const int32_t *rs1, vuint64m8_t rs2,
                                            size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_v_i64m1x2(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_v_i64m1x3(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_v_i64m1x4(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_v_i64m1x5(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_v_i64m1x6(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_v_i64m1x7(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_v_i64m1x8(const int64_t *rs1, vuint8mf8_t rs2,
                                           size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_v_i64m2x2(const int64_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_v_i64m2x3(const int64_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_v_i64m2x4(const int64_t *rs1, vuint8mf4_t rs2,
                                           size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_v_i64m4x2(const int64_t *rs1, vuint8mf2_t rs2,
                                           size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_v_i64m1x2(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_v_i64m1x3(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_v_i64m1x4(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_v_i64m1x5(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_v_i64m1x6(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_v_i64m1x7(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_v_i64m1x8(const int64_t *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_v_i64m2x2(const int64_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_v_i64m2x3(const int64_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_v_i64m2x4(const int64_t *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_v_i64m4x2(const int64_t *rs1, vuint16m1_t rs2,
                                            size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_v_i64m1x2(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_v_i64m1x3(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_v_i64m1x4(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_v_i64m1x5(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_v_i64m1x6(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_v_i64m1x7(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_v_i64m1x8(const int64_t *rs1,
                                            vuint32mf2_t rs2, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_v_i64m2x2(const int64_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_v_i64m2x3(const int64_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_v_i64m2x4(const int64_t *rs1, vuint32m1_t rs2,
                                            size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_v_i64m4x2(const int64_t *rs1, vuint32m2_t rs2,
                                            size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_v_i64m1x2(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_v_i64m1x3(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_v_i64m1x4(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_v_i64m1x5(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_v_i64m1x6(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_v_i64m1x7(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_v_i64m1x8(const int64_t *rs1, vuint64m1_t rs2,
                                            size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_v_i64m2x2(const int64_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_v_i64m2x3(const int64_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_v_i64m2x4(const int64_t *rs1, vuint64m2_t rs2,
                                            size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_v_i64m4x2(const int64_t *rs1, vuint64m4_t rs2,
                                            size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_v_u8mf8x2(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_v_u8mf8x3(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_v_u8mf8x4(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_v_u8mf8x5(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_v_u8mf8x6(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_v_u8mf8x7(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_v_u8mf8x8(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_v_u8mf4x2(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_v_u8mf4x3(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_v_u8mf4x4(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_v_u8mf4x5(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_v_u8mf4x6(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_v_u8mf4x7(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_v_u8mf4x8(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_v_u8mf2x2(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_v_u8mf2x3(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_v_u8mf2x4(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_v_u8mf2x5(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_v_u8mf2x6(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_v_u8mf2x7(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_v_u8mf2x8(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_v_u8m1x2(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_v_u8m1x3(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_v_u8m1x4(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_v_u8m1x5(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_v_u8m1x6(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_v_u8m1x7(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_v_u8m1x8(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_v_u8m2x2(const uint8_t *rs1, vuint8m2_t rs2,
                                          size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_v_u8m2x3(const uint8_t *rs1, vuint8m2_t rs2,
                                          size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_v_u8m2x4(const uint8_t *rs1, vuint8m2_t rs2,
                                          size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_v_u8m4x2(const uint8_t *rs1, vuint8m4_t rs2,
                                          size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_v_u8mf8x2(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_v_u8mf8x3(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_v_u8mf8x4(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_v_u8mf8x5(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_v_u8mf8x6(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_v_u8mf8x7(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_v_u8mf8x8(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_v_u8mf4x2(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_v_u8mf4x3(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_v_u8mf4x4(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_v_u8mf4x5(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_v_u8mf4x6(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_v_u8mf4x7(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_v_u8mf4x8(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_v_u8mf2x2(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_v_u8mf2x3(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_v_u8mf2x4(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_v_u8mf2x5(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_v_u8mf2x6(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_v_u8mf2x7(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_v_u8mf2x8(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_v_u8m1x2(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_v_u8m1x3(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_v_u8m1x4(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_v_u8m1x5(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_v_u8m1x6(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_v_u8m1x7(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_v_u8m1x8(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_v_u8m2x2(const uint8_t *rs1, vuint16m4_t rs2,
                                           size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_v_u8m2x3(const uint8_t *rs1, vuint16m4_t rs2,
                                           size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_v_u8m2x4(const uint8_t *rs1, vuint16m4_t rs2,
                                           size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_v_u8m4x2(const uint8_t *rs1, vuint16m8_t rs2,
                                           size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_v_u8mf8x2(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_v_u8mf8x3(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_v_u8mf8x4(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_v_u8mf8x5(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_v_u8mf8x6(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_v_u8mf8x7(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_v_u8mf8x8(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_v_u8mf4x2(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_v_u8mf4x3(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_v_u8mf4x4(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_v_u8mf4x5(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_v_u8mf4x6(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_v_u8mf4x7(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_v_u8mf4x8(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_v_u8mf2x2(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_v_u8mf2x3(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_v_u8mf2x4(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_v_u8mf2x5(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_v_u8mf2x6(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_v_u8mf2x7(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_v_u8mf2x8(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_v_u8m1x2(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_v_u8m1x3(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_v_u8m1x4(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_v_u8m1x5(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_v_u8m1x6(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_v_u8m1x7(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_v_u8m1x8(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_v_u8m2x2(const uint8_t *rs1, vuint32m8_t rs2,
                                           size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_v_u8m2x3(const uint8_t *rs1, vuint32m8_t rs2,
                                           size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_v_u8m2x4(const uint8_t *rs1, vuint32m8_t rs2,
                                           size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_v_u8mf8x2(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_v_u8mf8x3(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_v_u8mf8x4(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_v_u8mf8x5(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_v_u8mf8x6(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_v_u8mf8x7(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_v_u8mf8x8(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_v_u8mf4x2(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_v_u8mf4x3(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_v_u8mf4x4(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_v_u8mf4x5(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_v_u8mf4x6(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_v_u8mf4x7(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_v_u8mf4x8(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_v_u8mf2x2(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_v_u8mf2x3(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_v_u8mf2x4(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_v_u8mf2x5(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_v_u8mf2x6(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_v_u8mf2x7(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_v_u8mf2x8(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_v_u8m1x2(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_v_u8m1x3(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_v_u8m1x4(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_v_u8m1x5(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_v_u8m1x6(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_v_u8m1x7(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_v_u8m1x8(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_v_u16mf4x2(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_v_u16mf4x3(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_v_u16mf4x4(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_v_u16mf4x5(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_v_u16mf4x6(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_v_u16mf4x7(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_v_u16mf4x8(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_v_u16mf2x2(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_v_u16mf2x3(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_v_u16mf2x4(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_v_u16mf2x5(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_v_u16mf2x6(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_v_u16mf2x7(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_v_u16mf2x8(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_v_u16m1x2(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_v_u16m1x3(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_v_u16m1x4(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_v_u16m1x5(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_v_u16m1x6(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_v_u16m1x7(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_v_u16m1x8(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_v_u16m2x2(const uint16_t *rs1, vuint8m1_t rs2,
                                            size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_v_u16m2x3(const uint16_t *rs1, vuint8m1_t rs2,
                                            size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_v_u16m2x4(const uint16_t *rs1, vuint8m1_t rs2,
                                            size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_v_u16m4x2(const uint16_t *rs1, vuint8m2_t rs2,
                                            size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_v_u16mf4x2(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_v_u16mf4x3(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_v_u16mf4x4(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_v_u16mf4x5(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_v_u16mf4x6(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_v_u16mf4x7(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_v_u16mf4x8(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_v_u16mf2x2(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_v_u16mf2x3(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_v_u16mf2x4(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_v_u16mf2x5(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_v_u16mf2x6(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_v_u16mf2x7(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_v_u16mf2x8(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_v_u16m1x2(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_v_u16m1x3(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_v_u16m1x4(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_v_u16m1x5(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_v_u16m1x6(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_v_u16m1x7(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_v_u16m1x8(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_v_u16m2x2(const uint16_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_v_u16m2x3(const uint16_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_v_u16m2x4(const uint16_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_v_u16m4x2(const uint16_t *rs1,
                                             vuint16m4_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_v_u16mf4x2(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_v_u16mf4x3(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_v_u16mf4x4(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_v_u16mf4x5(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_v_u16mf4x6(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_v_u16mf4x7(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_v_u16mf4x8(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_v_u16mf2x2(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_v_u16mf2x3(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_v_u16mf2x4(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_v_u16mf2x5(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_v_u16mf2x6(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_v_u16mf2x7(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_v_u16mf2x8(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_v_u16m1x2(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_v_u16m1x3(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_v_u16m1x4(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_v_u16m1x5(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_v_u16m1x6(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_v_u16m1x7(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_v_u16m1x8(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_v_u16m2x2(const uint16_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_v_u16m2x3(const uint16_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_v_u16m2x4(const uint16_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_v_u16m4x2(const uint16_t *rs1,
                                             vuint32m8_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_v_u16mf4x2(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_v_u16mf4x3(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_v_u16mf4x4(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_v_u16mf4x5(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_v_u16mf4x6(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_v_u16mf4x7(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_v_u16mf4x8(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_v_u16mf2x2(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_v_u16mf2x3(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_v_u16mf2x4(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_v_u16mf2x5(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_v_u16mf2x6(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_v_u16mf2x7(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_v_u16mf2x8(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_v_u16m1x2(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_v_u16m1x3(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_v_u16m1x4(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_v_u16m1x5(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_v_u16m1x6(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_v_u16m1x7(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_v_u16m1x8(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_v_u16m2x2(const uint16_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_v_u16m2x3(const uint16_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_v_u16m2x4(const uint16_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_v_u32mf2x2(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_v_u32mf2x3(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_v_u32mf2x4(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_v_u32mf2x5(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_v_u32mf2x6(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_v_u32mf2x7(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_v_u32mf2x8(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_v_u32m1x2(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_v_u32m1x3(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_v_u32m1x4(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_v_u32m1x5(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_v_u32m1x6(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_v_u32m1x7(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_v_u32m1x8(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_v_u32m2x2(const uint32_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_v_u32m2x3(const uint32_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_v_u32m2x4(const uint32_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_v_u32m4x2(const uint32_t *rs1, vuint8m1_t rs2,
                                            size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_v_u32mf2x2(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_v_u32mf2x3(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_v_u32mf2x4(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_v_u32mf2x5(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_v_u32mf2x6(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_v_u32mf2x7(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_v_u32mf2x8(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_v_u32m1x2(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_v_u32m1x3(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_v_u32m1x4(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_v_u32m1x5(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_v_u32m1x6(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_v_u32m1x7(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_v_u32m1x8(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_v_u32m2x2(const uint32_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_v_u32m2x3(const uint32_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_v_u32m2x4(const uint32_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_v_u32m4x2(const uint32_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_v_u32mf2x2(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_v_u32mf2x3(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_v_u32mf2x4(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_v_u32mf2x5(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_v_u32mf2x6(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_v_u32mf2x7(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_v_u32mf2x8(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_v_u32m1x2(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_v_u32m1x3(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_v_u32m1x4(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_v_u32m1x5(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_v_u32m1x6(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_v_u32m1x7(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_v_u32m1x8(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_v_u32m2x2(const uint32_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_v_u32m2x3(const uint32_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_v_u32m2x4(const uint32_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_v_u32m4x2(const uint32_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_v_u32mf2x2(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_v_u32mf2x3(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_v_u32mf2x4(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_v_u32mf2x5(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_v_u32mf2x6(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_v_u32mf2x7(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_v_u32mf2x8(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_v_u32m1x2(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_v_u32m1x3(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_v_u32m1x4(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_v_u32m1x5(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_v_u32m1x6(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_v_u32m1x7(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_v_u32m1x8(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_v_u32m2x2(const uint32_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_v_u32m2x3(const uint32_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_v_u32m2x4(const uint32_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_v_u32m4x2(const uint32_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_v_u64m1x2(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_v_u64m1x3(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_v_u64m1x4(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_v_u64m1x5(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_v_u64m1x6(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_v_u64m1x7(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_v_u64m1x8(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_v_u64m2x2(const uint64_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_v_u64m2x3(const uint64_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_v_u64m2x4(const uint64_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_v_u64m4x2(const uint64_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_v_u64m1x2(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_v_u64m1x3(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_v_u64m1x4(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_v_u64m1x5(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_v_u64m1x6(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_v_u64m1x7(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_v_u64m1x8(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_v_u64m2x2(const uint64_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_v_u64m2x3(const uint64_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_v_u64m2x4(const uint64_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_v_u64m4x2(const uint64_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_v_u64m1x2(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_v_u64m1x3(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_v_u64m1x4(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_v_u64m1x5(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_v_u64m1x6(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_v_u64m1x7(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_v_u64m1x8(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_v_u64m2x2(const uint64_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_v_u64m2x3(const uint64_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_v_u64m2x4(const uint64_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_v_u64m4x2(const uint64_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_v_u64m1x2(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_v_u64m1x3(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_v_u64m1x4(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_v_u64m1x5(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_v_u64m1x6(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_v_u64m1x7(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_v_u64m1x8(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_v_u64m2x2(const uint64_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_v_u64m2x3(const uint64_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_v_u64m2x4(const uint64_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_v_u64m4x2(const uint64_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_v_u8mf8x2(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_v_u8mf8x3(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_v_u8mf8x4(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_v_u8mf8x5(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_v_u8mf8x6(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_v_u8mf8x7(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_v_u8mf8x8(const uint8_t *rs1, vuint8mf8_t rs2,
                                            size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_v_u8mf4x2(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_v_u8mf4x3(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_v_u8mf4x4(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_v_u8mf4x5(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_v_u8mf4x6(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_v_u8mf4x7(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_v_u8mf4x8(const uint8_t *rs1, vuint8mf4_t rs2,
                                            size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_v_u8mf2x2(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_v_u8mf2x3(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_v_u8mf2x4(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_v_u8mf2x5(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_v_u8mf2x6(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_v_u8mf2x7(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_v_u8mf2x8(const uint8_t *rs1, vuint8mf2_t rs2,
                                            size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_v_u8m1x2(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_v_u8m1x3(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_v_u8m1x4(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_v_u8m1x5(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_v_u8m1x6(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_v_u8m1x7(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_v_u8m1x8(const uint8_t *rs1, vuint8m1_t rs2,
                                          size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_v_u8m2x2(const uint8_t *rs1, vuint8m2_t rs2,
                                          size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_v_u8m2x3(const uint8_t *rs1, vuint8m2_t rs2,
                                          size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_v_u8m2x4(const uint8_t *rs1, vuint8m2_t rs2,
                                          size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_v_u8m4x2(const uint8_t *rs1, vuint8m4_t rs2,
                                          size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_v_u8mf8x2(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_v_u8mf8x3(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_v_u8mf8x4(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_v_u8mf8x5(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_v_u8mf8x6(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_v_u8mf8x7(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_v_u8mf8x8(const uint8_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_v_u8mf4x2(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_v_u8mf4x3(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_v_u8mf4x4(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_v_u8mf4x5(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_v_u8mf4x6(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_v_u8mf4x7(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_v_u8mf4x8(const uint8_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_v_u8mf2x2(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_v_u8mf2x3(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_v_u8mf2x4(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_v_u8mf2x5(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_v_u8mf2x6(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_v_u8mf2x7(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_v_u8mf2x8(const uint8_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_v_u8m1x2(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_v_u8m1x3(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_v_u8m1x4(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_v_u8m1x5(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_v_u8m1x6(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_v_u8m1x7(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_v_u8m1x8(const uint8_t *rs1, vuint16m2_t rs2,
                                           size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_v_u8m2x2(const uint8_t *rs1, vuint16m4_t rs2,
                                           size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_v_u8m2x3(const uint8_t *rs1, vuint16m4_t rs2,
                                           size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_v_u8m2x4(const uint8_t *rs1, vuint16m4_t rs2,
                                           size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_v_u8m4x2(const uint8_t *rs1, vuint16m8_t rs2,
                                           size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_v_u8mf8x2(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_v_u8mf8x3(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_v_u8mf8x4(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_v_u8mf8x5(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_v_u8mf8x6(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_v_u8mf8x7(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_v_u8mf8x8(const uint8_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_v_u8mf4x2(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_v_u8mf4x3(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_v_u8mf4x4(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_v_u8mf4x5(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_v_u8mf4x6(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_v_u8mf4x7(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_v_u8mf4x8(const uint8_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_v_u8mf2x2(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_v_u8mf2x3(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_v_u8mf2x4(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_v_u8mf2x5(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_v_u8mf2x6(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_v_u8mf2x7(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_v_u8mf2x8(const uint8_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_v_u8m1x2(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_v_u8m1x3(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_v_u8m1x4(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_v_u8m1x5(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_v_u8m1x6(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_v_u8m1x7(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_v_u8m1x8(const uint8_t *rs1, vuint32m4_t rs2,
                                           size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_v_u8m2x2(const uint8_t *rs1, vuint32m8_t rs2,
                                           size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_v_u8m2x3(const uint8_t *rs1, vuint32m8_t rs2,
                                           size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_v_u8m2x4(const uint8_t *rs1, vuint32m8_t rs2,
                                           size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_v_u8mf8x2(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_v_u8mf8x3(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_v_u8mf8x4(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_v_u8mf8x5(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_v_u8mf8x6(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_v_u8mf8x7(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_v_u8mf8x8(const uint8_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_v_u8mf4x2(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_v_u8mf4x3(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_v_u8mf4x4(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_v_u8mf4x5(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_v_u8mf4x6(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_v_u8mf4x7(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_v_u8mf4x8(const uint8_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_v_u8mf2x2(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_v_u8mf2x3(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_v_u8mf2x4(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_v_u8mf2x5(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_v_u8mf2x6(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_v_u8mf2x7(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_v_u8mf2x8(const uint8_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_v_u8m1x2(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_v_u8m1x3(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_v_u8m1x4(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_v_u8m1x5(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_v_u8m1x6(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_v_u8m1x7(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_v_u8m1x8(const uint8_t *rs1, vuint64m8_t rs2,
                                           size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_v_u16mf4x2(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_v_u16mf4x3(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_v_u16mf4x4(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_v_u16mf4x5(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_v_u16mf4x6(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_v_u16mf4x7(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_v_u16mf4x8(const uint16_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_v_u16mf2x2(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_v_u16mf2x3(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_v_u16mf2x4(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_v_u16mf2x5(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_v_u16mf2x6(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_v_u16mf2x7(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_v_u16mf2x8(const uint16_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_v_u16m1x2(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_v_u16m1x3(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_v_u16m1x4(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_v_u16m1x5(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_v_u16m1x6(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_v_u16m1x7(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_v_u16m1x8(const uint16_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_v_u16m2x2(const uint16_t *rs1, vuint8m1_t rs2,
                                            size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_v_u16m2x3(const uint16_t *rs1, vuint8m1_t rs2,
                                            size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_v_u16m2x4(const uint16_t *rs1, vuint8m1_t rs2,
                                            size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_v_u16m4x2(const uint16_t *rs1, vuint8m2_t rs2,
                                            size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_v_u16mf4x2(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_v_u16mf4x3(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_v_u16mf4x4(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_v_u16mf4x5(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_v_u16mf4x6(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_v_u16mf4x7(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_v_u16mf4x8(const uint16_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_v_u16mf2x2(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_v_u16mf2x3(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_v_u16mf2x4(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_v_u16mf2x5(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_v_u16mf2x6(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_v_u16mf2x7(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_v_u16mf2x8(const uint16_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_v_u16m1x2(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_v_u16m1x3(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_v_u16m1x4(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_v_u16m1x5(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_v_u16m1x6(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_v_u16m1x7(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_v_u16m1x8(const uint16_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_v_u16m2x2(const uint16_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_v_u16m2x3(const uint16_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_v_u16m2x4(const uint16_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_v_u16m4x2(const uint16_t *rs1,
                                             vuint16m4_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_v_u16mf4x2(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_v_u16mf4x3(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_v_u16mf4x4(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_v_u16mf4x5(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_v_u16mf4x6(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_v_u16mf4x7(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_v_u16mf4x8(const uint16_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_v_u16mf2x2(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_v_u16mf2x3(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_v_u16mf2x4(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_v_u16mf2x5(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_v_u16mf2x6(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_v_u16mf2x7(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_v_u16mf2x8(const uint16_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_v_u16m1x2(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_v_u16m1x3(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_v_u16m1x4(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_v_u16m1x5(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_v_u16m1x6(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_v_u16m1x7(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_v_u16m1x8(const uint16_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_v_u16m2x2(const uint16_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_v_u16m2x3(const uint16_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_v_u16m2x4(const uint16_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_v_u16m4x2(const uint16_t *rs1,
                                             vuint32m8_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_v_u16mf4x2(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_v_u16mf4x3(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_v_u16mf4x4(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_v_u16mf4x5(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_v_u16mf4x6(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_v_u16mf4x7(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_v_u16mf4x8(const uint16_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_v_u16mf2x2(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_v_u16mf2x3(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_v_u16mf2x4(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_v_u16mf2x5(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_v_u16mf2x6(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_v_u16mf2x7(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_v_u16mf2x8(const uint16_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_v_u16m1x2(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_v_u16m1x3(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_v_u16m1x4(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_v_u16m1x5(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_v_u16m1x6(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_v_u16m1x7(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_v_u16m1x8(const uint16_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_v_u16m2x2(const uint16_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_v_u16m2x3(const uint16_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_v_u16m2x4(const uint16_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_v_u32mf2x2(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_v_u32mf2x3(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_v_u32mf2x4(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_v_u32mf2x5(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_v_u32mf2x6(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_v_u32mf2x7(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_v_u32mf2x8(const uint32_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_v_u32m1x2(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_v_u32m1x3(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_v_u32m1x4(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_v_u32m1x5(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_v_u32m1x6(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_v_u32m1x7(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_v_u32m1x8(const uint32_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_v_u32m2x2(const uint32_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_v_u32m2x3(const uint32_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_v_u32m2x4(const uint32_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_v_u32m4x2(const uint32_t *rs1, vuint8m1_t rs2,
                                            size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_v_u32mf2x2(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_v_u32mf2x3(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_v_u32mf2x4(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_v_u32mf2x5(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_v_u32mf2x6(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_v_u32mf2x7(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_v_u32mf2x8(const uint32_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_v_u32m1x2(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_v_u32m1x3(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_v_u32m1x4(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_v_u32m1x5(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_v_u32m1x6(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_v_u32m1x7(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_v_u32m1x8(const uint32_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_v_u32m2x2(const uint32_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_v_u32m2x3(const uint32_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_v_u32m2x4(const uint32_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_v_u32m4x2(const uint32_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_v_u32mf2x2(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_v_u32mf2x3(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_v_u32mf2x4(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_v_u32mf2x5(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_v_u32mf2x6(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_v_u32mf2x7(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_v_u32mf2x8(const uint32_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_v_u32m1x2(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_v_u32m1x3(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_v_u32m1x4(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_v_u32m1x5(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_v_u32m1x6(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_v_u32m1x7(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_v_u32m1x8(const uint32_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_v_u32m2x2(const uint32_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_v_u32m2x3(const uint32_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_v_u32m2x4(const uint32_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_v_u32m4x2(const uint32_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_v_u32mf2x2(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_v_u32mf2x3(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_v_u32mf2x4(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_v_u32mf2x5(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_v_u32mf2x6(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_v_u32mf2x7(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_v_u32mf2x8(const uint32_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_v_u32m1x2(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_v_u32m1x3(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_v_u32m1x4(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_v_u32m1x5(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_v_u32m1x6(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_v_u32m1x7(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_v_u32m1x8(const uint32_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_v_u32m2x2(const uint32_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_v_u32m2x3(const uint32_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_v_u32m2x4(const uint32_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_v_u32m4x2(const uint32_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_v_u64m1x2(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_v_u64m1x3(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_v_u64m1x4(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_v_u64m1x5(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_v_u64m1x6(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_v_u64m1x7(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_v_u64m1x8(const uint64_t *rs1,
                                            vuint8mf8_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_v_u64m2x2(const uint64_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_v_u64m2x3(const uint64_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_v_u64m2x4(const uint64_t *rs1,
                                            vuint8mf4_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_v_u64m4x2(const uint64_t *rs1,
                                            vuint8mf2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_v_u64m1x2(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_v_u64m1x3(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_v_u64m1x4(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_v_u64m1x5(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_v_u64m1x6(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_v_u64m1x7(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_v_u64m1x8(const uint64_t *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_v_u64m2x2(const uint64_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_v_u64m2x3(const uint64_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_v_u64m2x4(const uint64_t *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_v_u64m4x2(const uint64_t *rs1,
                                             vuint16m1_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_v_u64m1x2(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_v_u64m1x3(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_v_u64m1x4(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_v_u64m1x5(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_v_u64m1x6(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_v_u64m1x7(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_v_u64m1x8(const uint64_t *rs1,
                                             vuint32mf2_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_v_u64m2x2(const uint64_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_v_u64m2x3(const uint64_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_v_u64m2x4(const uint64_t *rs1,
                                             vuint32m1_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_v_u64m4x2(const uint64_t *rs1,
                                             vuint32m2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_v_u64m1x2(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_v_u64m1x3(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_v_u64m1x4(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_v_u64m1x5(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_v_u64m1x6(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_v_u64m1x7(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_v_u64m1x8(const uint64_t *rs1,
                                             vuint64m1_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_v_u64m2x2(const uint64_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_v_u64m2x3(const uint64_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_v_u64m2x4(const uint64_t *rs1,
                                             vuint64m2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_v_u64m4x2(const uint64_t *rs1,
                                             vuint64m4_t rs2, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei8_v_f16mf4x2_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei8_v_f16mf4x3_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei8_v_f16mf4x4_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei8_v_f16mf4x5_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei8_v_f16mf4x6_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei8_v_f16mf4x7_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei8_v_f16mf4x8_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei8_v_f16mf2x2_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei8_v_f16mf2x3_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei8_v_f16mf2x4_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei8_v_f16mf2x5_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei8_v_f16mf2x6_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei8_v_f16mf2x7_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei8_v_f16mf2x8_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei8_v_f16m1x2_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei8_v_f16m1x3_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei8_v_f16m1x4_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei8_v_f16m1x5_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei8_v_f16m1x6_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei8_v_f16m1x7_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei8_v_f16m1x8_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei8_v_f16m2x2_m(vbool8_t vm, const _Float16 *rs1,
                                               vuint8m1_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei8_v_f16m2x3_m(vbool8_t vm, const _Float16 *rs1,
                                               vuint8m1_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei8_v_f16m2x4_m(vbool8_t vm, const _Float16 *rs1,
                                               vuint8m1_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei8_v_f16m4x2_m(vbool4_t vm, const _Float16 *rs1,
                                               vuint8m2_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei16_v_f16mf4x2_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_v_f16mf4x3_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_v_f16mf4x4_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_v_f16mf4x5_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_v_f16mf4x6_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_v_f16mf4x7_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_v_f16mf4x8_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_v_f16mf2x2_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_v_f16mf2x3_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_v_f16mf2x4_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_v_f16mf2x5_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_v_f16mf2x6_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_v_f16mf2x7_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_v_f16mf2x8_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_v_f16m1x2_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_v_f16m1x3_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_v_f16m1x4_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_v_f16m1x5_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_v_f16m1x6_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_v_f16m1x7_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_v_f16m1x8_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_v_f16m2x2_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_v_f16m2x3_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_v_f16m2x4_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_v_f16m4x2_m(vbool4_t vm,
                                                const _Float16 *rs1,
                                                vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei32_v_f16mf4x2_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei32_v_f16mf4x3_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei32_v_f16mf4x4_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei32_v_f16mf4x5_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei32_v_f16mf4x6_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei32_v_f16mf4x7_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei32_v_f16mf4x8_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei32_v_f16mf2x2_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei32_v_f16mf2x3_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei32_v_f16mf2x4_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei32_v_f16mf2x5_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei32_v_f16mf2x6_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei32_v_f16mf2x7_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei32_v_f16mf2x8_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei32_v_f16m1x2_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei32_v_f16m1x3_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei32_v_f16m1x4_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei32_v_f16m1x5_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei32_v_f16m1x6_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei32_v_f16m1x7_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei32_v_f16m1x8_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei32_v_f16m2x2_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint32m4_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei32_v_f16m2x3_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint32m4_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei32_v_f16m2x4_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint32m4_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei32_v_f16m4x2_m(vbool4_t vm,
                                                const _Float16 *rs1,
                                                vuint32m8_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei64_v_f16mf4x2_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei64_v_f16mf4x3_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei64_v_f16mf4x4_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei64_v_f16mf4x5_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei64_v_f16mf4x6_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei64_v_f16mf4x7_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei64_v_f16mf4x8_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei64_v_f16mf2x2_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei64_v_f16mf2x3_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei64_v_f16mf2x4_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei64_v_f16mf2x5_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei64_v_f16mf2x6_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei64_v_f16mf2x7_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei64_v_f16mf2x8_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei64_v_f16m1x2_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei64_v_f16m1x3_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei64_v_f16m1x4_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei64_v_f16m1x5_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei64_v_f16m1x6_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei64_v_f16m1x7_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei64_v_f16m1x8_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei64_v_f16m2x2_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint64m8_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei64_v_f16m2x3_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint64m8_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei64_v_f16m2x4_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint64m8_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei8_v_f32mf2x2_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei8_v_f32mf2x3_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei8_v_f32mf2x4_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei8_v_f32mf2x5_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei8_v_f32mf2x6_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei8_v_f32mf2x7_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei8_v_f32mf2x8_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei8_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei8_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei8_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei8_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei8_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei8_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei8_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei8_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei8_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei8_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei8_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                               vuint8m1_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei16_v_f32mf2x2_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei16_v_f32mf2x3_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei16_v_f32mf2x4_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei16_v_f32mf2x5_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei16_v_f32mf2x6_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei16_v_f32mf2x7_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei16_v_f32mf2x8_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei16_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei16_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei16_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei16_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei16_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei16_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei16_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei16_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei16_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei16_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei16_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei32_v_f32mf2x2_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_v_f32mf2x3_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_v_f32mf2x4_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_v_f32mf2x5_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_v_f32mf2x6_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_v_f32mf2x7_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_v_f32mf2x8_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                                vuint32m4_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_v_f32mf2x2_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_v_f32mf2x3_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_v_f32mf2x4_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_v_f32mf2x5_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_v_f32mf2x6_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_v_f32mf2x7_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_v_f32mf2x8_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                                vuint64m8_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei8_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei8_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei8_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei8_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei8_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei8_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei8_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei8_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei8_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei8_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei8_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei16_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei16_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei16_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei16_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei16_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei16_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei16_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei16_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei16_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei16_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei16_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei8_v_f16mf4x2_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei8_v_f16mf4x3_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei8_v_f16mf4x4_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei8_v_f16mf4x5_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei8_v_f16mf4x6_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei8_v_f16mf4x7_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei8_v_f16mf4x8_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei8_v_f16mf2x2_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei8_v_f16mf2x3_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei8_v_f16mf2x4_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei8_v_f16mf2x5_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei8_v_f16mf2x6_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei8_v_f16mf2x7_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei8_v_f16mf2x8_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 vuint8mf4_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei8_v_f16m1x2_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei8_v_f16m1x3_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei8_v_f16m1x4_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei8_v_f16m1x5_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei8_v_f16m1x6_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei8_v_f16m1x7_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei8_v_f16m1x8_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei8_v_f16m2x2_m(vbool8_t vm, const _Float16 *rs1,
                                               vuint8m1_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei8_v_f16m2x3_m(vbool8_t vm, const _Float16 *rs1,
                                               vuint8m1_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei8_v_f16m2x4_m(vbool8_t vm, const _Float16 *rs1,
                                               vuint8m1_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei8_v_f16m4x2_m(vbool4_t vm, const _Float16 *rs1,
                                               vuint8m2_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_v_f16mf4x2_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_v_f16mf4x3_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_v_f16mf4x4_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_v_f16mf4x5_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_v_f16mf4x6_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_v_f16mf4x7_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_v_f16mf4x8_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_v_f16mf2x2_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_v_f16mf2x3_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_v_f16mf2x4_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_v_f16mf2x5_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_v_f16mf2x6_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_v_f16mf2x7_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_v_f16mf2x8_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_v_f16m1x2_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_v_f16m1x3_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_v_f16m1x4_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_v_f16m1x5_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_v_f16m1x6_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_v_f16m1x7_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_v_f16m1x8_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_v_f16m2x2_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_v_f16m2x3_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_v_f16m2x4_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_v_f16m4x2_m(vbool4_t vm,
                                                const _Float16 *rs1,
                                                vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei32_v_f16mf4x2_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei32_v_f16mf4x3_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei32_v_f16mf4x4_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei32_v_f16mf4x5_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei32_v_f16mf4x6_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei32_v_f16mf4x7_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei32_v_f16mf4x8_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei32_v_f16mf2x2_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei32_v_f16mf2x3_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei32_v_f16mf2x4_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei32_v_f16mf2x5_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei32_v_f16mf2x6_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei32_v_f16mf2x7_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei32_v_f16mf2x8_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint32m1_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei32_v_f16m1x2_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei32_v_f16m1x3_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei32_v_f16m1x4_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei32_v_f16m1x5_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei32_v_f16m1x6_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei32_v_f16m1x7_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei32_v_f16m1x8_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei32_v_f16m2x2_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint32m4_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei32_v_f16m2x3_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint32m4_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei32_v_f16m2x4_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint32m4_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei32_v_f16m4x2_m(vbool4_t vm,
                                                const _Float16 *rs1,
                                                vuint32m8_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei64_v_f16mf4x2_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei64_v_f16mf4x3_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei64_v_f16mf4x4_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei64_v_f16mf4x5_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei64_v_f16mf4x6_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei64_v_f16mf4x7_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei64_v_f16mf4x8_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei64_v_f16mf2x2_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei64_v_f16mf2x3_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei64_v_f16mf2x4_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei64_v_f16mf2x5_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei64_v_f16mf2x6_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei64_v_f16mf2x7_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei64_v_f16mf2x8_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint64m2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei64_v_f16m1x2_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei64_v_f16m1x3_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei64_v_f16m1x4_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei64_v_f16m1x5_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei64_v_f16m1x6_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei64_v_f16m1x7_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei64_v_f16m1x8_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei64_v_f16m2x2_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint64m8_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei64_v_f16m2x3_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint64m8_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei64_v_f16m2x4_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint64m8_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei8_v_f32mf2x2_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei8_v_f32mf2x3_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei8_v_f32mf2x4_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei8_v_f32mf2x5_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei8_v_f32mf2x6_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei8_v_f32mf2x7_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei8_v_f32mf2x8_m(vbool64_t vm, const float *rs1,
                                                 vuint8mf8_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei8_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei8_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei8_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei8_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei8_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei8_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei8_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei8_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei8_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei8_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei8_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                               vuint8m1_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei16_v_f32mf2x2_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei16_v_f32mf2x3_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei16_v_f32mf2x4_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei16_v_f32mf2x5_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei16_v_f32mf2x6_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei16_v_f32mf2x7_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei16_v_f32mf2x8_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei16_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei16_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei16_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei16_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei16_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei16_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei16_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei16_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei16_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei16_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei16_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_v_f32mf2x2_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_v_f32mf2x3_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_v_f32mf2x4_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_v_f32mf2x5_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_v_f32mf2x6_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_v_f32mf2x7_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_v_f32mf2x8_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint32mf2_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                                vuint32m4_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_v_f32mf2x2_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_v_f32mf2x3_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_v_f32mf2x4_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_v_f32mf2x5_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_v_f32mf2x6_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_v_f32mf2x7_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_v_f32mf2x8_m(vbool64_t vm,
                                                  const float *rs1,
                                                  vuint64m1_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_v_f32m1x2_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_v_f32m1x3_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_v_f32m1x4_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_v_f32m1x5_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_v_f32m1x6_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_v_f32m1x7_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_v_f32m1x8_m(vbool32_t vm, const float *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_v_f32m2x2_m(vbool16_t vm, const float *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_v_f32m2x3_m(vbool16_t vm, const float *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_v_f32m2x4_m(vbool16_t vm, const float *rs1,
                                                vuint64m4_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_v_f32m4x2_m(vbool8_t vm, const float *rs1,
                                                vuint64m8_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei8_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei8_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei8_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei8_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei8_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei8_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei8_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei8_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei8_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei8_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei8_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                               vuint8mf2_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei16_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei16_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei16_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei16_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei16_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei16_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei16_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei16_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei16_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei16_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei16_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                                vuint32m1_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                                vuint32m2_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_v_f64m1x2_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_v_f64m1x3_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_v_f64m1x4_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_v_f64m1x5_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_v_f64m1x6_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_v_f64m1x7_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_v_f64m1x8_m(vbool64_t vm, const double *rs1,
                                                vuint64m1_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_v_f64m2x2_m(vbool32_t vm, const double *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_v_f64m2x3_m(vbool32_t vm, const double *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_v_f64m2x4_m(vbool32_t vm, const double *rs1,
                                                vuint64m2_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_v_f64m4x2_m(vbool16_t vm, const double *rs1,
                                                vuint64m4_t rs2, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei8_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_v_i8m2x2_m(vbool4_t vm, const int8_t *rs1,
                                           vuint8m2_t rs2, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_v_i8m2x3_m(vbool4_t vm, const int8_t *rs1,
                                           vuint8m2_t rs2, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_v_i8m2x4_m(vbool4_t vm, const int8_t *rs1,
                                           vuint8m2_t rs2, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_v_i8m4x2_m(vbool2_t vm, const int8_t *rs1,
                                           vuint8m4_t rs2, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_v_i8m2x2_m(vbool4_t vm, const int8_t *rs1,
                                            vuint16m4_t rs2, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_v_i8m2x3_m(vbool4_t vm, const int8_t *rs1,
                                            vuint16m4_t rs2, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_v_i8m2x4_m(vbool4_t vm, const int8_t *rs1,
                                            vuint16m4_t rs2, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_v_i8m4x2_m(vbool2_t vm, const int8_t *rs1,
                                            vuint16m8_t rs2, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_v_i8m2x2_m(vbool4_t vm, const int8_t *rs1,
                                            vuint32m8_t rs2, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_v_i8m2x3_m(vbool4_t vm, const int8_t *rs1,
                                            vuint32m8_t rs2, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_v_i8m2x4_m(vbool4_t vm, const int8_t *rs1,
                                            vuint32m8_t rs2, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_v_i16mf4x2_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_v_i16mf4x3_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_v_i16mf4x4_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_v_i16mf4x5_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_v_i16mf4x6_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_v_i16mf4x7_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_v_i16mf4x8_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_v_i16mf2x2_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_v_i16mf2x3_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_v_i16mf2x4_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_v_i16mf2x5_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_v_i16mf2x6_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_v_i16mf2x7_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_v_i16mf2x8_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                             vuint8m1_t rs2, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                             vuint8m1_t rs2, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                             vuint8m1_t rs2, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_v_i16m4x2_m(vbool4_t vm, const int16_t *rs1,
                                             vuint8m2_t rs2, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_v_i16mf4x2_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_v_i16mf4x3_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_v_i16mf4x4_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_v_i16mf4x5_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_v_i16mf4x6_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_v_i16mf4x7_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_v_i16mf4x8_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_v_i16mf2x2_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_v_i16mf2x3_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_v_i16mf2x4_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_v_i16mf2x5_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_v_i16mf2x6_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_v_i16mf2x7_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_v_i16mf2x8_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                              vuint16m2_t rs2, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                              vuint16m2_t rs2, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                              vuint16m2_t rs2, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_v_i16m4x2_m(vbool4_t vm, const int16_t *rs1,
                                              vuint16m4_t rs2, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_v_i16mf4x2_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_v_i16mf4x3_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_v_i16mf4x4_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_v_i16mf4x5_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_v_i16mf4x6_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_v_i16mf4x7_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_v_i16mf4x8_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_v_i16mf2x2_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_v_i16mf2x3_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_v_i16mf2x4_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_v_i16mf2x5_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_v_i16mf2x6_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_v_i16mf2x7_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_v_i16mf2x8_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                              vuint32m4_t rs2, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                              vuint32m4_t rs2, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                              vuint32m4_t rs2, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_v_i16m4x2_m(vbool4_t vm, const int16_t *rs1,
                                              vuint32m8_t rs2, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_v_i16mf4x2_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_v_i16mf4x3_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_v_i16mf4x4_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_v_i16mf4x5_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_v_i16mf4x6_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_v_i16mf4x7_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_v_i16mf4x8_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_v_i16mf2x2_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_v_i16mf2x3_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_v_i16mf2x4_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_v_i16mf2x5_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_v_i16mf2x6_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_v_i16mf2x7_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_v_i16mf2x8_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                              vuint64m8_t rs2, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                              vuint64m8_t rs2, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                              vuint64m8_t rs2, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_v_i32mf2x2_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_v_i32mf2x3_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_v_i32mf2x4_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_v_i32mf2x5_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_v_i32mf2x6_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_v_i32mf2x7_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_v_i32mf2x8_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                             vuint8m1_t rs2, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_v_i32mf2x2_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_v_i32mf2x3_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_v_i32mf2x4_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_v_i32mf2x5_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_v_i32mf2x6_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_v_i32mf2x7_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_v_i32mf2x8_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                              vuint16m2_t rs2, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_v_i32mf2x2_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_v_i32mf2x3_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_v_i32mf2x4_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_v_i32mf2x5_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_v_i32mf2x6_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_v_i32mf2x7_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_v_i32mf2x8_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                              vuint32m4_t rs2, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_v_i32mf2x2_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_v_i32mf2x3_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_v_i32mf2x4_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_v_i32mf2x5_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_v_i32mf2x6_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_v_i32mf2x7_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_v_i32mf2x8_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                              vuint64m8_t rs2, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                           vuint8m1_t rs2, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_v_i8m2x2_m(vbool4_t vm, const int8_t *rs1,
                                           vuint8m2_t rs2, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_v_i8m2x3_m(vbool4_t vm, const int8_t *rs1,
                                           vuint8m2_t rs2, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_v_i8m2x4_m(vbool4_t vm, const int8_t *rs1,
                                           vuint8m2_t rs2, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_v_i8m4x2_m(vbool2_t vm, const int8_t *rs1,
                                           vuint8m4_t rs2, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                            vuint16m2_t rs2, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_v_i8m2x2_m(vbool4_t vm, const int8_t *rs1,
                                            vuint16m4_t rs2, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_v_i8m2x3_m(vbool4_t vm, const int8_t *rs1,
                                            vuint16m4_t rs2, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_v_i8m2x4_m(vbool4_t vm, const int8_t *rs1,
                                            vuint16m4_t rs2, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_v_i8m4x2_m(vbool2_t vm, const int8_t *rs1,
                                            vuint16m8_t rs2, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                            vuint32m4_t rs2, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_v_i8m2x2_m(vbool4_t vm, const int8_t *rs1,
                                            vuint32m8_t rs2, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_v_i8m2x3_m(vbool4_t vm, const int8_t *rs1,
                                            vuint32m8_t rs2, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_v_i8m2x4_m(vbool4_t vm, const int8_t *rs1,
                                            vuint32m8_t rs2, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_v_i8mf8x2_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_v_i8mf8x3_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_v_i8mf8x4_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_v_i8mf8x5_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_v_i8mf8x6_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_v_i8mf8x7_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_v_i8mf8x8_m(vbool64_t vm, const int8_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_v_i8mf4x2_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_v_i8mf4x3_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_v_i8mf4x4_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_v_i8mf4x5_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_v_i8mf4x6_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_v_i8mf4x7_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_v_i8mf4x8_m(vbool32_t vm, const int8_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_v_i8mf2x2_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_v_i8mf2x3_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_v_i8mf2x4_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_v_i8mf2x5_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_v_i8mf2x6_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_v_i8mf2x7_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_v_i8mf2x8_m(vbool16_t vm, const int8_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_v_i8m1x2_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_v_i8m1x3_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_v_i8m1x4_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_v_i8m1x5_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_v_i8m1x6_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_v_i8m1x7_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_v_i8m1x8_m(vbool8_t vm, const int8_t *rs1,
                                            vuint64m8_t rs2, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_v_i16mf4x2_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_v_i16mf4x3_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_v_i16mf4x4_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_v_i16mf4x5_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_v_i16mf4x6_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_v_i16mf4x7_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_v_i16mf4x8_m(vbool64_t vm, const int16_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_v_i16mf2x2_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_v_i16mf2x3_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_v_i16mf2x4_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_v_i16mf2x5_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_v_i16mf2x6_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_v_i16mf2x7_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_v_i16mf2x8_m(vbool32_t vm, const int16_t *rs1,
                                               vuint8mf4_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                             vuint8m1_t rs2, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                             vuint8m1_t rs2, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                             vuint8m1_t rs2, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_v_i16m4x2_m(vbool4_t vm, const int16_t *rs1,
                                             vuint8m2_t rs2, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_v_i16mf4x2_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_v_i16mf4x3_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_v_i16mf4x4_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_v_i16mf4x5_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_v_i16mf4x6_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_v_i16mf4x7_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_v_i16mf4x8_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_v_i16mf2x2_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_v_i16mf2x3_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_v_i16mf2x4_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_v_i16mf2x5_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_v_i16mf2x6_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_v_i16mf2x7_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_v_i16mf2x8_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                              vuint16m2_t rs2, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                              vuint16m2_t rs2, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                              vuint16m2_t rs2, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_v_i16m4x2_m(vbool4_t vm, const int16_t *rs1,
                                              vuint16m4_t rs2, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_v_i16mf4x2_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_v_i16mf4x3_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_v_i16mf4x4_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_v_i16mf4x5_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_v_i16mf4x6_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_v_i16mf4x7_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_v_i16mf4x8_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_v_i16mf2x2_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_v_i16mf2x3_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_v_i16mf2x4_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_v_i16mf2x5_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_v_i16mf2x6_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_v_i16mf2x7_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_v_i16mf2x8_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint32m1_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                              vuint32m4_t rs2, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                              vuint32m4_t rs2, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                              vuint32m4_t rs2, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_v_i16m4x2_m(vbool4_t vm, const int16_t *rs1,
                                              vuint32m8_t rs2, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_v_i16mf4x2_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_v_i16mf4x3_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_v_i16mf4x4_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_v_i16mf4x5_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_v_i16mf4x6_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_v_i16mf4x7_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_v_i16mf4x8_m(vbool64_t vm,
                                                const int16_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_v_i16mf2x2_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_v_i16mf2x3_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_v_i16mf2x4_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_v_i16mf2x5_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_v_i16mf2x6_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_v_i16mf2x7_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_v_i16mf2x8_m(vbool32_t vm,
                                                const int16_t *rs1,
                                                vuint64m2_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_v_i16m1x2_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_v_i16m1x3_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_v_i16m1x4_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_v_i16m1x5_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_v_i16m1x6_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_v_i16m1x7_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_v_i16m1x8_m(vbool16_t vm, const int16_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_v_i16m2x2_m(vbool8_t vm, const int16_t *rs1,
                                              vuint64m8_t rs2, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_v_i16m2x3_m(vbool8_t vm, const int16_t *rs1,
                                              vuint64m8_t rs2, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_v_i16m2x4_m(vbool8_t vm, const int16_t *rs1,
                                              vuint64m8_t rs2, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_v_i32mf2x2_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_v_i32mf2x3_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_v_i32mf2x4_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_v_i32mf2x5_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_v_i32mf2x6_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_v_i32mf2x7_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_v_i32mf2x8_m(vbool64_t vm, const int32_t *rs1,
                                               vuint8mf8_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                             vuint8m1_t rs2, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_v_i32mf2x2_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_v_i32mf2x3_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_v_i32mf2x4_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_v_i32mf2x5_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_v_i32mf2x6_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_v_i32mf2x7_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_v_i32mf2x8_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                              vuint16m2_t rs2, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_v_i32mf2x2_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_v_i32mf2x3_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_v_i32mf2x4_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_v_i32mf2x5_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_v_i32mf2x6_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_v_i32mf2x7_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_v_i32mf2x8_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint32mf2_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                              vuint32m4_t rs2, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_v_i32mf2x2_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_v_i32mf2x3_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_v_i32mf2x4_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_v_i32mf2x5_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_v_i32mf2x6_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_v_i32mf2x7_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_v_i32mf2x8_m(vbool64_t vm,
                                                const int32_t *rs1,
                                                vuint64m1_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_v_i32m1x2_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_v_i32m1x3_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_v_i32m1x4_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_v_i32m1x5_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_v_i32m1x6_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_v_i32m1x7_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_v_i32m1x8_m(vbool32_t vm, const int32_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_v_i32m2x2_m(vbool16_t vm, const int32_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_v_i32m2x3_m(vbool16_t vm, const int32_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_v_i32m2x4_m(vbool16_t vm, const int32_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_v_i32m4x2_m(vbool8_t vm, const int32_t *rs1,
                                              vuint64m8_t rs2, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                             vuint8mf8_t rs2, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                             vuint8mf4_t rs2, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                             vuint8mf2_t rs2, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                              vuint16mf4_t rs2, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                              vuint16mf2_t rs2, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                              vuint16m1_t rs2, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                              vuint32mf2_t rs2, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                              vuint32m1_t rs2, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                              vuint32m2_t rs2, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_v_i64m1x2_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_v_i64m1x3_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_v_i64m1x4_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_v_i64m1x5_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_v_i64m1x6_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_v_i64m1x7_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_v_i64m1x8_m(vbool64_t vm, const int64_t *rs1,
                                              vuint64m1_t rs2, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_v_i64m2x2_m(vbool32_t vm, const int64_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_v_i64m2x3_m(vbool32_t vm, const int64_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_v_i64m2x4_m(vbool32_t vm, const int64_t *rs1,
                                              vuint64m2_t rs2, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_v_i64m4x2_m(vbool16_t vm, const int64_t *rs1,
                                              vuint64m4_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_v_u8m2x2_m(vbool4_t vm, const uint8_t *rs1,
                                            vuint8m2_t rs2, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_v_u8m2x3_m(vbool4_t vm, const uint8_t *rs1,
                                            vuint8m2_t rs2, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_v_u8m2x4_m(vbool4_t vm, const uint8_t *rs1,
                                            vuint8m2_t rs2, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_v_u8m4x2_m(vbool2_t vm, const uint8_t *rs1,
                                            vuint8m4_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_v_u8m2x2_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint16m4_t rs2, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_v_u8m2x3_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint16m4_t rs2, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_v_u8m2x4_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint16m4_t rs2, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_v_u8m4x2_m(vbool2_t vm, const uint8_t *rs1,
                                             vuint16m8_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_v_u8m2x2_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint32m8_t rs2, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_v_u8m2x3_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint32m8_t rs2, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_v_u8m2x4_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint32m8_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_v_u16mf4x2_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_v_u16mf4x3_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_v_u16mf4x4_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_v_u16mf4x5_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_v_u16mf4x6_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_v_u16mf4x7_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_v_u16mf4x8_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_v_u16mf2x2_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_v_u16mf2x3_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_v_u16mf2x4_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_v_u16mf2x5_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_v_u16mf2x6_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_v_u16mf2x7_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_v_u16mf2x8_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_v_u16m1x2_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_v_u16m1x3_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_v_u16m1x4_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_v_u16m1x5_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_v_u16m1x6_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_v_u16m1x7_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_v_u16m1x8_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                              vuint8m1_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                              vuint8m1_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                              vuint8m1_t rs2, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_v_u16m4x2_m(vbool4_t vm, const uint16_t *rs1,
                                              vuint8m2_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_v_u16mf4x2_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_v_u16mf4x3_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_v_u16mf4x4_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_v_u16mf4x5_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_v_u16mf4x6_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_v_u16mf4x7_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_v_u16mf4x8_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_v_u16mf2x2_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_v_u16mf2x3_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_v_u16mf2x4_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_v_u16mf2x5_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_v_u16mf2x6_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_v_u16mf2x7_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_v_u16mf2x8_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_v_u16m1x2_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_v_u16m1x3_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_v_u16m1x4_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_v_u16m1x5_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_v_u16m1x6_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_v_u16m1x7_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_v_u16m1x8_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint16m2_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint16m2_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint16m2_t rs2, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_v_u16m4x2_m(vbool4_t vm, const uint16_t *rs1,
                                               vuint16m4_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_v_u16mf4x2_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_v_u16mf4x3_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_v_u16mf4x4_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_v_u16mf4x5_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_v_u16mf4x6_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_v_u16mf4x7_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_v_u16mf4x8_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_v_u16mf2x2_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_v_u16mf2x3_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_v_u16mf2x4_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_v_u16mf2x5_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_v_u16mf2x6_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_v_u16mf2x7_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_v_u16mf2x8_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_v_u16m1x2_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_v_u16m1x3_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_v_u16m1x4_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_v_u16m1x5_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_v_u16m1x6_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_v_u16m1x7_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_v_u16m1x8_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint32m4_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint32m4_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint32m4_t rs2, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_v_u16m4x2_m(vbool4_t vm, const uint16_t *rs1,
                                               vuint32m8_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_v_u16mf4x2_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_v_u16mf4x3_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_v_u16mf4x4_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_v_u16mf4x5_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_v_u16mf4x6_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_v_u16mf4x7_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_v_u16mf4x8_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_v_u16mf2x2_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_v_u16mf2x3_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_v_u16mf2x4_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_v_u16mf2x5_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_v_u16mf2x6_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_v_u16mf2x7_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_v_u16mf2x8_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_v_u16m1x2_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_v_u16m1x3_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_v_u16m1x4_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_v_u16m1x5_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_v_u16m1x6_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_v_u16m1x7_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_v_u16m1x8_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint64m8_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint64m8_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint64m8_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_v_u32mf2x2_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_v_u32mf2x3_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_v_u32mf2x4_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_v_u32mf2x5_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_v_u32mf2x6_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_v_u32mf2x7_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_v_u32mf2x8_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_v_u32m1x2_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_v_u32m1x3_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_v_u32m1x4_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_v_u32m1x5_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_v_u32m1x6_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_v_u32m1x7_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_v_u32m1x8_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_v_u32m2x2_m(vbool16_t vm, const uint32_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_v_u32m2x3_m(vbool16_t vm, const uint32_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_v_u32m2x4_m(vbool16_t vm, const uint32_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                              vuint8m1_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_v_u32mf2x2_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_v_u32mf2x3_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_v_u32mf2x4_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_v_u32mf2x5_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_v_u32mf2x6_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_v_u32mf2x7_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_v_u32mf2x8_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_v_u32m1x2_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_v_u32m1x3_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_v_u32m1x4_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_v_u32m1x5_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_v_u32m1x6_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_v_u32m1x7_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_v_u32m1x8_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_v_u32m2x2_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_v_u32m2x3_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_v_u32m2x4_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                               vuint16m2_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_v_u32mf2x2_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_v_u32mf2x3_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_v_u32mf2x4_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_v_u32mf2x5_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_v_u32mf2x6_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_v_u32mf2x7_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_v_u32mf2x8_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_v_u32m1x2_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_v_u32m1x3_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_v_u32m1x4_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_v_u32m1x5_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_v_u32m1x6_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_v_u32m1x7_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_v_u32m1x8_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_v_u32m2x2_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_v_u32m2x3_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_v_u32m2x4_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                               vuint32m4_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_v_u32mf2x2_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_v_u32mf2x3_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_v_u32mf2x4_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_v_u32mf2x5_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_v_u32mf2x6_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_v_u32mf2x7_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_v_u32mf2x8_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_v_u32m1x2_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_v_u32m1x3_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_v_u32m1x4_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_v_u32m1x5_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_v_u32m1x6_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_v_u32m1x7_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_v_u32m1x8_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_v_u32m2x2_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_v_u32m2x3_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_v_u32m2x4_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                               vuint64m8_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_v_u64m1x2_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_v_u64m1x3_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_v_u64m1x4_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_v_u64m1x5_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_v_u64m1x6_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_v_u64m1x7_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_v_u64m1x8_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_v_u64m2x2_m(vbool32_t vm, const uint64_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_v_u64m2x3_m(vbool32_t vm, const uint64_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_v_u64m2x4_m(vbool32_t vm, const uint64_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_v_u64m4x2_m(vbool16_t vm, const uint64_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_v_u64m1x2_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_v_u64m1x3_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_v_u64m1x4_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_v_u64m1x5_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_v_u64m1x6_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_v_u64m1x7_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_v_u64m1x8_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_v_u64m2x2_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_v_u64m2x3_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_v_u64m2x4_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_v_u64m4x2_m(vbool16_t vm,
                                               const uint64_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_v_u64m1x2_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_v_u64m1x3_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_v_u64m1x4_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_v_u64m1x5_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_v_u64m1x6_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_v_u64m1x7_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_v_u64m1x8_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_v_u64m2x2_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_v_u64m2x3_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_v_u64m2x4_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_v_u64m4x2_m(vbool16_t vm,
                                               const uint64_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_v_u64m1x2_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_v_u64m1x3_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_v_u64m1x4_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_v_u64m1x5_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_v_u64m1x6_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_v_u64m1x7_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_v_u64m1x8_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_v_u64m2x2_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_v_u64m2x3_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_v_u64m2x4_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_v_u64m4x2_m(vbool16_t vm,
                                               const uint64_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                            vuint8m1_t rs2, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_v_u8m2x2_m(vbool4_t vm, const uint8_t *rs1,
                                            vuint8m2_t rs2, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_v_u8m2x3_m(vbool4_t vm, const uint8_t *rs1,
                                            vuint8m2_t rs2, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_v_u8m2x4_m(vbool4_t vm, const uint8_t *rs1,
                                            vuint8m2_t rs2, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_v_u8m4x2_m(vbool2_t vm, const uint8_t *rs1,
                                            vuint8m4_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint16m2_t rs2, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_v_u8m2x2_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint16m4_t rs2, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_v_u8m2x3_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint16m4_t rs2, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_v_u8m2x4_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint16m4_t rs2, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_v_u8m4x2_m(vbool2_t vm, const uint8_t *rs1,
                                             vuint16m8_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint32m4_t rs2, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_v_u8m2x2_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint32m8_t rs2, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_v_u8m2x3_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint32m8_t rs2, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_v_u8m2x4_m(vbool4_t vm, const uint8_t *rs1,
                                             vuint32m8_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_v_u8mf8x2_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_v_u8mf8x3_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_v_u8mf8x4_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_v_u8mf8x5_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_v_u8mf8x6_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_v_u8mf8x7_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_v_u8mf8x8_m(vbool64_t vm, const uint8_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_v_u8mf4x2_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_v_u8mf4x3_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_v_u8mf4x4_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_v_u8mf4x5_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_v_u8mf4x6_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_v_u8mf4x7_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_v_u8mf4x8_m(vbool32_t vm, const uint8_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_v_u8mf2x2_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_v_u8mf2x3_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_v_u8mf2x4_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_v_u8mf2x5_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_v_u8mf2x6_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_v_u8mf2x7_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_v_u8mf2x8_m(vbool16_t vm, const uint8_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_v_u8m1x2_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_v_u8m1x3_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_v_u8m1x4_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_v_u8m1x5_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_v_u8m1x6_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_v_u8m1x7_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_v_u8m1x8_m(vbool8_t vm, const uint8_t *rs1,
                                             vuint64m8_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_v_u16mf4x2_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_v_u16mf4x3_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_v_u16mf4x4_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_v_u16mf4x5_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_v_u16mf4x6_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_v_u16mf4x7_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_v_u16mf4x8_m(vbool64_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_v_u16mf2x2_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_v_u16mf2x3_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_v_u16mf2x4_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_v_u16mf2x5_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_v_u16mf2x6_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_v_u16mf2x7_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_v_u16mf2x8_m(vbool32_t vm,
                                                const uint16_t *rs1,
                                                vuint8mf4_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_v_u16m1x2_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_v_u16m1x3_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_v_u16m1x4_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_v_u16m1x5_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_v_u16m1x6_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_v_u16m1x7_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_v_u16m1x8_m(vbool16_t vm, const uint16_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                              vuint8m1_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                              vuint8m1_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                              vuint8m1_t rs2, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_v_u16m4x2_m(vbool4_t vm, const uint16_t *rs1,
                                              vuint8m2_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_v_u16mf4x2_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_v_u16mf4x3_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_v_u16mf4x4_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_v_u16mf4x5_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_v_u16mf4x6_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_v_u16mf4x7_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_v_u16mf4x8_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_v_u16mf2x2_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_v_u16mf2x3_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_v_u16mf2x4_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_v_u16mf2x5_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_v_u16mf2x6_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_v_u16mf2x7_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_v_u16mf2x8_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint16mf2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_v_u16m1x2_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_v_u16m1x3_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_v_u16m1x4_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_v_u16m1x5_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_v_u16m1x6_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_v_u16m1x7_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_v_u16m1x8_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint16m2_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint16m2_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint16m2_t rs2, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_v_u16m4x2_m(vbool4_t vm, const uint16_t *rs1,
                                               vuint16m4_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_v_u16mf4x2_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_v_u16mf4x3_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_v_u16mf4x4_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_v_u16mf4x5_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_v_u16mf4x6_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_v_u16mf4x7_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_v_u16mf4x8_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_v_u16mf2x2_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_v_u16mf2x3_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_v_u16mf2x4_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_v_u16mf2x5_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_v_u16mf2x6_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_v_u16mf2x7_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_v_u16mf2x8_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint32m1_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_v_u16m1x2_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_v_u16m1x3_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_v_u16m1x4_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_v_u16m1x5_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_v_u16m1x6_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_v_u16m1x7_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_v_u16m1x8_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint32m4_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint32m4_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint32m4_t rs2, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_v_u16m4x2_m(vbool4_t vm, const uint16_t *rs1,
                                               vuint32m8_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_v_u16mf4x2_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_v_u16mf4x3_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_v_u16mf4x4_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_v_u16mf4x5_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_v_u16mf4x6_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_v_u16mf4x7_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_v_u16mf4x8_m(vbool64_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_v_u16mf2x2_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_v_u16mf2x3_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_v_u16mf2x4_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_v_u16mf2x5_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_v_u16mf2x6_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_v_u16mf2x7_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_v_u16mf2x8_m(vbool32_t vm,
                                                 const uint16_t *rs1,
                                                 vuint64m2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_v_u16m1x2_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_v_u16m1x3_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_v_u16m1x4_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_v_u16m1x5_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_v_u16m1x6_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_v_u16m1x7_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_v_u16m1x8_m(vbool16_t vm,
                                               const uint16_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_v_u16m2x2_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint64m8_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_v_u16m2x3_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint64m8_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_v_u16m2x4_m(vbool8_t vm, const uint16_t *rs1,
                                               vuint64m8_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_v_u32mf2x2_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_v_u32mf2x3_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_v_u32mf2x4_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_v_u32mf2x5_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_v_u32mf2x6_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_v_u32mf2x7_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_v_u32mf2x8_m(vbool64_t vm,
                                                const uint32_t *rs1,
                                                vuint8mf8_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_v_u32m1x2_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_v_u32m1x3_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_v_u32m1x4_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_v_u32m1x5_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_v_u32m1x6_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_v_u32m1x7_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_v_u32m1x8_m(vbool32_t vm, const uint32_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_v_u32m2x2_m(vbool16_t vm, const uint32_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_v_u32m2x3_m(vbool16_t vm, const uint32_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_v_u32m2x4_m(vbool16_t vm, const uint32_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                              vuint8m1_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_v_u32mf2x2_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_v_u32mf2x3_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_v_u32mf2x4_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_v_u32mf2x5_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_v_u32mf2x6_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_v_u32mf2x7_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_v_u32mf2x8_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint16mf4_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_v_u32m1x2_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_v_u32m1x3_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_v_u32m1x4_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_v_u32m1x5_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_v_u32m1x6_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_v_u32m1x7_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_v_u32m1x8_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_v_u32m2x2_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_v_u32m2x3_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_v_u32m2x4_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                               vuint16m2_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_v_u32mf2x2_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_v_u32mf2x3_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_v_u32mf2x4_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_v_u32mf2x5_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_v_u32mf2x6_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_v_u32mf2x7_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_v_u32mf2x8_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint32mf2_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_v_u32m1x2_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_v_u32m1x3_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_v_u32m1x4_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_v_u32m1x5_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_v_u32m1x6_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_v_u32m1x7_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_v_u32m1x8_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_v_u32m2x2_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_v_u32m2x3_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_v_u32m2x4_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                               vuint32m4_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_v_u32mf2x2_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_v_u32mf2x3_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_v_u32mf2x4_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_v_u32mf2x5_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_v_u32mf2x6_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_v_u32mf2x7_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_v_u32mf2x8_m(vbool64_t vm,
                                                 const uint32_t *rs1,
                                                 vuint64m1_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_v_u32m1x2_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_v_u32m1x3_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_v_u32m1x4_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_v_u32m1x5_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_v_u32m1x6_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_v_u32m1x7_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_v_u32m1x8_m(vbool32_t vm,
                                               const uint32_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_v_u32m2x2_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_v_u32m2x3_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_v_u32m2x4_m(vbool16_t vm,
                                               const uint32_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_v_u32m4x2_m(vbool8_t vm, const uint32_t *rs1,
                                               vuint64m8_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_v_u64m1x2_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_v_u64m1x3_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_v_u64m1x4_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_v_u64m1x5_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_v_u64m1x6_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_v_u64m1x7_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_v_u64m1x8_m(vbool64_t vm, const uint64_t *rs1,
                                              vuint8mf8_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_v_u64m2x2_m(vbool32_t vm, const uint64_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_v_u64m2x3_m(vbool32_t vm, const uint64_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_v_u64m2x4_m(vbool32_t vm, const uint64_t *rs1,
                                              vuint8mf4_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_v_u64m4x2_m(vbool16_t vm, const uint64_t *rs1,
                                              vuint8mf2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_v_u64m1x2_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_v_u64m1x3_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_v_u64m1x4_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_v_u64m1x5_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_v_u64m1x6_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_v_u64m1x7_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_v_u64m1x8_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf4_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_v_u64m2x2_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_v_u64m2x3_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_v_u64m2x4_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint16mf2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_v_u64m4x2_m(vbool16_t vm,
                                               const uint64_t *rs1,
                                               vuint16m1_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_v_u64m1x2_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_v_u64m1x3_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_v_u64m1x4_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_v_u64m1x5_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_v_u64m1x6_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_v_u64m1x7_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_v_u64m1x8_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint32mf2_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_v_u64m2x2_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_v_u64m2x3_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_v_u64m2x4_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint32m1_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_v_u64m4x2_m(vbool16_t vm,
                                               const uint64_t *rs1,
                                               vuint32m2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_v_u64m1x2_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_v_u64m1x3_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_v_u64m1x4_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_v_u64m1x5_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_v_u64m1x6_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_v_u64m1x7_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_v_u64m1x8_m(vbool64_t vm,
                                               const uint64_t *rs1,
                                               vuint64m1_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_v_u64m2x2_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_v_u64m2x3_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_v_u64m2x4_m(vbool32_t vm,
                                               const uint64_t *rs1,
                                               vuint64m2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_v_u64m4x2_m(vbool16_t vm,
                                               const uint64_t *rs1,
                                               vuint64m4_t rs2, size_t vl);
----

[[vector-indexed-segment-store]]
==== Vector Indexed Segment Store Intrinsics

[,c]
----
void __riscv_vsoxseg2ei8_v_f16mf4x2(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f16mf4x3(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f16mf4x4(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_f16mf4x5(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_f16mf4x6(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_f16mf4x7(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_f16mf4x8(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f16mf2x2(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f16mf2x3(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f16mf2x4(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_f16mf2x5(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_f16mf2x6(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_f16mf2x7(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_f16mf2x8(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f16m1x2(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f16m1x3(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f16m1x4(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_f16m1x5(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_f16m1x6(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_f16m1x7(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_f16m1x8(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f16m2x2(_Float16 *rs1, vuint8m1_t vs2,
                                   vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f16m2x3(_Float16 *rs1, vuint8m1_t vs2,
                                   vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f16m2x4(_Float16 *rs1, vuint8m1_t vs2,
                                   vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f16m4x2(_Float16 *rs1, vuint8m2_t vs2,
                                   vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f16mf4x2(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f16mf4x3(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f16mf4x4(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_f16mf4x5(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_f16mf4x6(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_f16mf4x7(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_f16mf4x8(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f16mf2x2(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f16mf2x3(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f16mf2x4(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_f16mf2x5(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_f16mf2x6(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_f16mf2x7(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_f16mf2x8(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f16m1x2(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f16m1x3(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f16m1x4(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_f16m1x5(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_f16m1x6(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_f16m1x7(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_f16m1x8(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f16m2x2(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f16m2x3(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f16m2x4(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f16m4x2(_Float16 *rs1, vuint16m4_t vs2,
                                    vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f16mf4x2(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f16mf4x3(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f16mf4x4(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_f16mf4x5(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_f16mf4x6(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_f16mf4x7(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_f16mf4x8(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f16mf2x2(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f16mf2x3(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f16mf2x4(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_f16mf2x5(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_f16mf2x6(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_f16mf2x7(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_f16mf2x8(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f16m1x2(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f16m1x3(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f16m1x4(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_f16m1x5(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_f16m1x6(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_f16m1x7(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_f16m1x8(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f16m2x2(_Float16 *rs1, vuint32m4_t vs2,
                                    vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f16m2x3(_Float16 *rs1, vuint32m4_t vs2,
                                    vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f16m2x4(_Float16 *rs1, vuint32m4_t vs2,
                                    vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f16m4x2(_Float16 *rs1, vuint32m8_t vs2,
                                    vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f16mf4x2(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f16mf4x3(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f16mf4x4(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_f16mf4x5(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_f16mf4x6(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_f16mf4x7(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_f16mf4x8(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f16mf2x2(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f16mf2x3(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f16mf2x4(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_f16mf2x5(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_f16mf2x6(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_f16mf2x7(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_f16mf2x8(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f16m1x2(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f16m1x3(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f16m1x4(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_f16m1x5(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_f16m1x6(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_f16m1x7(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_f16m1x8(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f16m2x2(_Float16 *rs1, vuint64m8_t vs2,
                                    vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f16m2x3(_Float16 *rs1, vuint64m8_t vs2,
                                    vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f16m2x4(_Float16 *rs1, vuint64m8_t vs2,
                                    vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f32mf2x2(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f32mf2x3(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f32mf2x4(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_f32mf2x5(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_f32mf2x6(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_f32mf2x7(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_f32mf2x8(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f32m1x2(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f32m1x3(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f32m1x4(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_f32m1x5(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_f32m1x6(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_f32m1x7(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_f32m1x8(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f32m2x2(float *rs1, vuint8mf2_t vs2,
                                   vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f32m2x3(float *rs1, vuint8mf2_t vs2,
                                   vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f32m2x4(float *rs1, vuint8mf2_t vs2,
                                   vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f32m4x2(float *rs1, vuint8m1_t vs2,
                                   vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f32mf2x2(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f32mf2x3(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f32mf2x4(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_f32mf2x5(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_f32mf2x6(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_f32mf2x7(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_f32mf2x8(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f32m1x2(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f32m1x3(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f32m1x4(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_f32m1x5(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_f32m1x6(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_f32m1x7(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_f32m1x8(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f32m2x2(float *rs1, vuint16m1_t vs2,
                                    vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f32m2x3(float *rs1, vuint16m1_t vs2,
                                    vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f32m2x4(float *rs1, vuint16m1_t vs2,
                                    vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f32m4x2(float *rs1, vuint16m2_t vs2,
                                    vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f32mf2x2(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f32mf2x3(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f32mf2x4(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_f32mf2x5(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_f32mf2x6(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_f32mf2x7(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_f32mf2x8(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f32m1x2(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f32m1x3(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f32m1x4(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_f32m1x5(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_f32m1x6(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_f32m1x7(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_f32m1x8(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f32m2x2(float *rs1, vuint32m2_t vs2,
                                    vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f32m2x3(float *rs1, vuint32m2_t vs2,
                                    vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f32m2x4(float *rs1, vuint32m2_t vs2,
                                    vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f32m4x2(float *rs1, vuint32m4_t vs2,
                                    vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f32mf2x2(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f32mf2x3(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f32mf2x4(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_f32mf2x5(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_f32mf2x6(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_f32mf2x7(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_f32mf2x8(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f32m1x2(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f32m1x3(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f32m1x4(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_f32m1x5(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_f32m1x6(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_f32m1x7(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_f32m1x8(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f32m2x2(float *rs1, vuint64m4_t vs2,
                                    vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f32m2x3(float *rs1, vuint64m4_t vs2,
                                    vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f32m2x4(float *rs1, vuint64m4_t vs2,
                                    vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f32m4x2(float *rs1, vuint64m8_t vs2,
                                    vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f64m1x2(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f64m1x3(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f64m1x4(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_f64m1x5(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_f64m1x6(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_f64m1x7(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_f64m1x8(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f64m2x2(double *rs1, vuint8mf4_t vs2,
                                   vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f64m2x3(double *rs1, vuint8mf4_t vs2,
                                   vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f64m2x4(double *rs1, vuint8mf4_t vs2,
                                   vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f64m4x2(double *rs1, vuint8mf2_t vs2,
                                   vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f64m1x2(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f64m1x3(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f64m1x4(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_f64m1x5(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_f64m1x6(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_f64m1x7(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_f64m1x8(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f64m2x2(double *rs1, vuint16mf2_t vs2,
                                    vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f64m2x3(double *rs1, vuint16mf2_t vs2,
                                    vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f64m2x4(double *rs1, vuint16mf2_t vs2,
                                    vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f64m4x2(double *rs1, vuint16m1_t vs2,
                                    vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f64m1x2(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f64m1x3(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f64m1x4(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_f64m1x5(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_f64m1x6(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_f64m1x7(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_f64m1x8(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f64m2x2(double *rs1, vuint32m1_t vs2,
                                    vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f64m2x3(double *rs1, vuint32m1_t vs2,
                                    vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f64m2x4(double *rs1, vuint32m1_t vs2,
                                    vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f64m4x2(double *rs1, vuint32m2_t vs2,
                                    vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f64m1x2(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f64m1x3(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f64m1x4(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_f64m1x5(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_f64m1x6(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_f64m1x7(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_f64m1x8(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f64m2x2(double *rs1, vuint64m2_t vs2,
                                    vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f64m2x3(double *rs1, vuint64m2_t vs2,
                                    vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f64m2x4(double *rs1, vuint64m2_t vs2,
                                    vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f64m4x2(double *rs1, vuint64m4_t vs2,
                                    vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f16mf4x2(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f16mf4x3(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f16mf4x4(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_f16mf4x5(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_f16mf4x6(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_f16mf4x7(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_f16mf4x8(_Float16 *rs1, vuint8mf8_t vs2,
                                    vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f16mf2x2(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f16mf2x3(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f16mf2x4(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_f16mf2x5(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_f16mf2x6(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_f16mf2x7(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_f16mf2x8(_Float16 *rs1, vuint8mf4_t vs2,
                                    vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f16m1x2(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f16m1x3(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f16m1x4(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_f16m1x5(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_f16m1x6(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_f16m1x7(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_f16m1x8(_Float16 *rs1, vuint8mf2_t vs2,
                                   vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f16m2x2(_Float16 *rs1, vuint8m1_t vs2,
                                   vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f16m2x3(_Float16 *rs1, vuint8m1_t vs2,
                                   vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f16m2x4(_Float16 *rs1, vuint8m1_t vs2,
                                   vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f16m4x2(_Float16 *rs1, vuint8m2_t vs2,
                                   vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16mf4x2(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f16mf4x3(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f16mf4x4(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_f16mf4x5(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_f16mf4x6(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_f16mf4x7(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_f16mf4x8(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16mf2x2(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f16mf2x3(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f16mf2x4(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_f16mf2x5(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_f16mf2x6(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_f16mf2x7(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_f16mf2x8(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16m1x2(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f16m1x3(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f16m1x4(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_f16m1x5(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_f16m1x6(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_f16m1x7(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_f16m1x8(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16m2x2(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f16m2x3(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f16m2x4(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16m4x2(_Float16 *rs1, vuint16m4_t vs2,
                                    vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f16mf4x2(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f16mf4x3(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f16mf4x4(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_f16mf4x5(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_f16mf4x6(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_f16mf4x7(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_f16mf4x8(_Float16 *rs1, vuint32mf2_t vs2,
                                     vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f16mf2x2(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f16mf2x3(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f16mf2x4(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_f16mf2x5(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_f16mf2x6(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_f16mf2x7(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_f16mf2x8(_Float16 *rs1, vuint32m1_t vs2,
                                     vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f16m1x2(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f16m1x3(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f16m1x4(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_f16m1x5(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_f16m1x6(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_f16m1x7(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_f16m1x8(_Float16 *rs1, vuint32m2_t vs2,
                                    vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f16m2x2(_Float16 *rs1, vuint32m4_t vs2,
                                    vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f16m2x3(_Float16 *rs1, vuint32m4_t vs2,
                                    vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f16m2x4(_Float16 *rs1, vuint32m4_t vs2,
                                    vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f16m4x2(_Float16 *rs1, vuint32m8_t vs2,
                                    vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f16mf4x2(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f16mf4x3(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f16mf4x4(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_f16mf4x5(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_f16mf4x6(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_f16mf4x7(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_f16mf4x8(_Float16 *rs1, vuint64m1_t vs2,
                                     vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f16mf2x2(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f16mf2x3(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f16mf2x4(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_f16mf2x5(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_f16mf2x6(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_f16mf2x7(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_f16mf2x8(_Float16 *rs1, vuint64m2_t vs2,
                                     vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f16m1x2(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f16m1x3(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f16m1x4(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_f16m1x5(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_f16m1x6(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_f16m1x7(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_f16m1x8(_Float16 *rs1, vuint64m4_t vs2,
                                    vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f16m2x2(_Float16 *rs1, vuint64m8_t vs2,
                                    vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f16m2x3(_Float16 *rs1, vuint64m8_t vs2,
                                    vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f16m2x4(_Float16 *rs1, vuint64m8_t vs2,
                                    vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f32mf2x2(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f32mf2x3(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f32mf2x4(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_f32mf2x5(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_f32mf2x6(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_f32mf2x7(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_f32mf2x8(float *rs1, vuint8mf8_t vs2,
                                    vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f32m1x2(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f32m1x3(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f32m1x4(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_f32m1x5(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_f32m1x6(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_f32m1x7(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_f32m1x8(float *rs1, vuint8mf4_t vs2,
                                   vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f32m2x2(float *rs1, vuint8mf2_t vs2,
                                   vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f32m2x3(float *rs1, vuint8mf2_t vs2,
                                   vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f32m2x4(float *rs1, vuint8mf2_t vs2,
                                   vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f32m4x2(float *rs1, vuint8m1_t vs2,
                                   vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f32mf2x2(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f32mf2x3(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f32mf2x4(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_f32mf2x5(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_f32mf2x6(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_f32mf2x7(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_f32mf2x8(float *rs1, vuint16mf4_t vs2,
                                     vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f32m1x2(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f32m1x3(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f32m1x4(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_f32m1x5(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_f32m1x6(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_f32m1x7(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_f32m1x8(float *rs1, vuint16mf2_t vs2,
                                    vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f32m2x2(float *rs1, vuint16m1_t vs2,
                                    vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f32m2x3(float *rs1, vuint16m1_t vs2,
                                    vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f32m2x4(float *rs1, vuint16m1_t vs2,
                                    vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f32m4x2(float *rs1, vuint16m2_t vs2,
                                    vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f32mf2x2(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f32mf2x3(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f32mf2x4(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_f32mf2x5(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_f32mf2x6(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_f32mf2x7(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_f32mf2x8(float *rs1, vuint32mf2_t vs2,
                                     vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f32m1x2(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f32m1x3(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f32m1x4(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_f32m1x5(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_f32m1x6(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_f32m1x7(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_f32m1x8(float *rs1, vuint32m1_t vs2,
                                    vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f32m2x2(float *rs1, vuint32m2_t vs2,
                                    vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f32m2x3(float *rs1, vuint32m2_t vs2,
                                    vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f32m2x4(float *rs1, vuint32m2_t vs2,
                                    vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f32m4x2(float *rs1, vuint32m4_t vs2,
                                    vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f32mf2x2(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f32mf2x3(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f32mf2x4(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_f32mf2x5(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_f32mf2x6(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_f32mf2x7(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_f32mf2x8(float *rs1, vuint64m1_t vs2,
                                     vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f32m1x2(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f32m1x3(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f32m1x4(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_f32m1x5(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_f32m1x6(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_f32m1x7(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_f32m1x8(float *rs1, vuint64m2_t vs2,
                                    vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f32m2x2(float *rs1, vuint64m4_t vs2,
                                    vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f32m2x3(float *rs1, vuint64m4_t vs2,
                                    vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f32m2x4(float *rs1, vuint64m4_t vs2,
                                    vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f32m4x2(float *rs1, vuint64m8_t vs2,
                                    vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f64m1x2(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f64m1x3(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f64m1x4(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_f64m1x5(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_f64m1x6(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_f64m1x7(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_f64m1x8(double *rs1, vuint8mf8_t vs2,
                                   vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f64m2x2(double *rs1, vuint8mf4_t vs2,
                                   vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f64m2x3(double *rs1, vuint8mf4_t vs2,
                                   vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f64m2x4(double *rs1, vuint8mf4_t vs2,
                                   vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f64m4x2(double *rs1, vuint8mf2_t vs2,
                                   vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f64m1x2(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f64m1x3(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f64m1x4(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_f64m1x5(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_f64m1x6(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_f64m1x7(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_f64m1x8(double *rs1, vuint16mf4_t vs2,
                                    vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f64m2x2(double *rs1, vuint16mf2_t vs2,
                                    vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f64m2x3(double *rs1, vuint16mf2_t vs2,
                                    vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f64m2x4(double *rs1, vuint16mf2_t vs2,
                                    vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f64m4x2(double *rs1, vuint16m1_t vs2,
                                    vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f64m1x2(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f64m1x3(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f64m1x4(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_f64m1x5(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_f64m1x6(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_f64m1x7(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_f64m1x8(double *rs1, vuint32mf2_t vs2,
                                    vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f64m2x2(double *rs1, vuint32m1_t vs2,
                                    vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f64m2x3(double *rs1, vuint32m1_t vs2,
                                    vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f64m2x4(double *rs1, vuint32m1_t vs2,
                                    vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f64m4x2(double *rs1, vuint32m2_t vs2,
                                    vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f64m1x2(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f64m1x3(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f64m1x4(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_f64m1x5(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_f64m1x6(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_f64m1x7(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_f64m1x8(double *rs1, vuint64m1_t vs2,
                                    vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f64m2x2(double *rs1, vuint64m2_t vs2,
                                    vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f64m2x3(double *rs1, vuint64m2_t vs2,
                                    vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f64m2x4(double *rs1, vuint64m2_t vs2,
                                    vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f64m4x2(double *rs1, vuint64m4_t vs2,
                                    vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i8mf8x2(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i8mf8x3(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i8mf8x4(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i8mf8x5(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i8mf8x6(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i8mf8x7(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i8mf8x8(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i8mf4x2(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i8mf4x3(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i8mf4x4(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i8mf4x5(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i8mf4x6(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i8mf4x7(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i8mf4x8(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i8mf2x2(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i8mf2x3(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i8mf2x4(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i8mf2x5(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i8mf2x6(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i8mf2x7(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i8mf2x8(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i8m1x2(int8_t *rs1, vuint8m1_t vs2, vint8m1x2_t vs3,
                                  size_t vl);
void __riscv_vsoxseg3ei8_v_i8m1x3(int8_t *rs1, vuint8m1_t vs2, vint8m1x3_t vs3,
                                  size_t vl);
void __riscv_vsoxseg4ei8_v_i8m1x4(int8_t *rs1, vuint8m1_t vs2, vint8m1x4_t vs3,
                                  size_t vl);
void __riscv_vsoxseg5ei8_v_i8m1x5(int8_t *rs1, vuint8m1_t vs2, vint8m1x5_t vs3,
                                  size_t vl);
void __riscv_vsoxseg6ei8_v_i8m1x6(int8_t *rs1, vuint8m1_t vs2, vint8m1x6_t vs3,
                                  size_t vl);
void __riscv_vsoxseg7ei8_v_i8m1x7(int8_t *rs1, vuint8m1_t vs2, vint8m1x7_t vs3,
                                  size_t vl);
void __riscv_vsoxseg8ei8_v_i8m1x8(int8_t *rs1, vuint8m1_t vs2, vint8m1x8_t vs3,
                                  size_t vl);
void __riscv_vsoxseg2ei8_v_i8m2x2(int8_t *rs1, vuint8m2_t vs2, vint8m2x2_t vs3,
                                  size_t vl);
void __riscv_vsoxseg3ei8_v_i8m2x3(int8_t *rs1, vuint8m2_t vs2, vint8m2x3_t vs3,
                                  size_t vl);
void __riscv_vsoxseg4ei8_v_i8m2x4(int8_t *rs1, vuint8m2_t vs2, vint8m2x4_t vs3,
                                  size_t vl);
void __riscv_vsoxseg2ei8_v_i8m4x2(int8_t *rs1, vuint8m4_t vs2, vint8m4x2_t vs3,
                                  size_t vl);
void __riscv_vsoxseg2ei16_v_i8mf8x2(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i8mf8x3(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i8mf8x4(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i8mf8x5(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i8mf8x6(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i8mf8x7(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i8mf8x8(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i8mf4x2(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i8mf4x3(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i8mf4x4(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i8mf4x5(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i8mf4x6(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i8mf4x7(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i8mf4x8(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i8mf2x2(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i8mf2x3(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i8mf2x4(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i8mf2x5(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i8mf2x6(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i8mf2x7(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i8mf2x8(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i8m1x2(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i8m1x3(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i8m1x4(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i8m1x5(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i8m1x6(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i8m1x7(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i8m1x8(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i8m2x2(int8_t *rs1, vuint16m4_t vs2,
                                   vint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i8m2x3(int8_t *rs1, vuint16m4_t vs2,
                                   vint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i8m2x4(int8_t *rs1, vuint16m4_t vs2,
                                   vint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i8m4x2(int8_t *rs1, vuint16m8_t vs2,
                                   vint8m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i8mf8x2(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i8mf8x3(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i8mf8x4(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i8mf8x5(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i8mf8x6(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i8mf8x7(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i8mf8x8(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i8mf4x2(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i8mf4x3(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i8mf4x4(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i8mf4x5(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i8mf4x6(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i8mf4x7(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i8mf4x8(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i8mf2x2(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i8mf2x3(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i8mf2x4(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i8mf2x5(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i8mf2x6(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i8mf2x7(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i8mf2x8(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i8m1x2(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i8m1x3(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i8m1x4(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i8m1x5(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i8m1x6(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i8m1x7(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i8m1x8(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i8m2x2(int8_t *rs1, vuint32m8_t vs2,
                                   vint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i8m2x3(int8_t *rs1, vuint32m8_t vs2,
                                   vint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i8m2x4(int8_t *rs1, vuint32m8_t vs2,
                                   vint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i8mf8x2(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i8mf8x3(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i8mf8x4(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i8mf8x5(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i8mf8x6(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i8mf8x7(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i8mf8x8(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i8mf4x2(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i8mf4x3(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i8mf4x4(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i8mf4x5(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i8mf4x6(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i8mf4x7(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i8mf4x8(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i8mf2x2(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i8mf2x3(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i8mf2x4(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i8mf2x5(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i8mf2x6(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i8mf2x7(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i8mf2x8(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i8m1x2(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i8m1x3(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i8m1x4(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i8m1x5(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i8m1x6(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i8m1x7(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i8m1x8(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i16mf4x2(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i16mf4x3(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i16mf4x4(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i16mf4x5(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i16mf4x6(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i16mf4x7(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i16mf4x8(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i16mf2x2(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i16mf2x3(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i16mf2x4(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i16mf2x5(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i16mf2x6(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i16mf2x7(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i16mf2x8(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i16m1x2(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i16m1x3(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i16m1x4(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i16m1x5(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i16m1x6(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i16m1x7(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i16m1x8(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i16m2x2(int16_t *rs1, vuint8m1_t vs2,
                                   vint16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i16m2x3(int16_t *rs1, vuint8m1_t vs2,
                                   vint16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i16m2x4(int16_t *rs1, vuint8m1_t vs2,
                                   vint16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i16m4x2(int16_t *rs1, vuint8m2_t vs2,
                                   vint16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i16mf4x2(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i16mf4x3(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i16mf4x4(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i16mf4x5(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i16mf4x6(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i16mf4x7(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i16mf4x8(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i16mf2x2(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i16mf2x3(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i16mf2x4(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i16mf2x5(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i16mf2x6(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i16mf2x7(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i16mf2x8(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i16m1x2(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i16m1x3(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i16m1x4(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i16m1x5(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i16m1x6(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i16m1x7(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i16m1x8(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i16m2x2(int16_t *rs1, vuint16m2_t vs2,
                                    vint16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i16m2x3(int16_t *rs1, vuint16m2_t vs2,
                                    vint16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i16m2x4(int16_t *rs1, vuint16m2_t vs2,
                                    vint16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i16m4x2(int16_t *rs1, vuint16m4_t vs2,
                                    vint16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i16mf4x2(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i16mf4x3(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i16mf4x4(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i16mf4x5(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i16mf4x6(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i16mf4x7(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i16mf4x8(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i16mf2x2(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i16mf2x3(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i16mf2x4(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i16mf2x5(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i16mf2x6(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i16mf2x7(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i16mf2x8(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i16m1x2(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i16m1x3(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i16m1x4(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i16m1x5(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i16m1x6(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i16m1x7(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i16m1x8(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i16m2x2(int16_t *rs1, vuint32m4_t vs2,
                                    vint16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i16m2x3(int16_t *rs1, vuint32m4_t vs2,
                                    vint16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i16m2x4(int16_t *rs1, vuint32m4_t vs2,
                                    vint16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i16m4x2(int16_t *rs1, vuint32m8_t vs2,
                                    vint16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i16mf4x2(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i16mf4x3(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i16mf4x4(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i16mf4x5(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i16mf4x6(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i16mf4x7(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i16mf4x8(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i16mf2x2(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i16mf2x3(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i16mf2x4(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i16mf2x5(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i16mf2x6(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i16mf2x7(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i16mf2x8(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i16m1x2(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i16m1x3(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i16m1x4(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i16m1x5(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i16m1x6(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i16m1x7(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i16m1x8(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i16m2x2(int16_t *rs1, vuint64m8_t vs2,
                                    vint16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i16m2x3(int16_t *rs1, vuint64m8_t vs2,
                                    vint16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i16m2x4(int16_t *rs1, vuint64m8_t vs2,
                                    vint16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i32mf2x2(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i32mf2x3(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i32mf2x4(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i32mf2x5(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i32mf2x6(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i32mf2x7(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i32mf2x8(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i32m1x2(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i32m1x3(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i32m1x4(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i32m1x5(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i32m1x6(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i32m1x7(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i32m1x8(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i32m2x2(int32_t *rs1, vuint8mf2_t vs2,
                                   vint32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i32m2x3(int32_t *rs1, vuint8mf2_t vs2,
                                   vint32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i32m2x4(int32_t *rs1, vuint8mf2_t vs2,
                                   vint32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i32m4x2(int32_t *rs1, vuint8m1_t vs2,
                                   vint32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i32mf2x2(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i32mf2x3(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i32mf2x4(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i32mf2x5(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i32mf2x6(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i32mf2x7(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i32mf2x8(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i32m1x2(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i32m1x3(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i32m1x4(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i32m1x5(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i32m1x6(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i32m1x7(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i32m1x8(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i32m2x2(int32_t *rs1, vuint16m1_t vs2,
                                    vint32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i32m2x3(int32_t *rs1, vuint16m1_t vs2,
                                    vint32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i32m2x4(int32_t *rs1, vuint16m1_t vs2,
                                    vint32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i32m4x2(int32_t *rs1, vuint16m2_t vs2,
                                    vint32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i32mf2x2(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i32mf2x3(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i32mf2x4(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i32mf2x5(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i32mf2x6(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i32mf2x7(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i32mf2x8(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i32m1x2(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i32m1x3(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i32m1x4(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i32m1x5(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i32m1x6(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i32m1x7(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i32m1x8(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i32m2x2(int32_t *rs1, vuint32m2_t vs2,
                                    vint32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i32m2x3(int32_t *rs1, vuint32m2_t vs2,
                                    vint32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i32m2x4(int32_t *rs1, vuint32m2_t vs2,
                                    vint32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i32m4x2(int32_t *rs1, vuint32m4_t vs2,
                                    vint32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i32mf2x2(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i32mf2x3(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i32mf2x4(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i32mf2x5(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i32mf2x6(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i32mf2x7(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i32mf2x8(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i32m1x2(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i32m1x3(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i32m1x4(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i32m1x5(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i32m1x6(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i32m1x7(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i32m1x8(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i32m2x2(int32_t *rs1, vuint64m4_t vs2,
                                    vint32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i32m2x3(int32_t *rs1, vuint64m4_t vs2,
                                    vint32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i32m2x4(int32_t *rs1, vuint64m4_t vs2,
                                    vint32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i32m4x2(int32_t *rs1, vuint64m8_t vs2,
                                    vint32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i64m1x2(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i64m1x3(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i64m1x4(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i64m1x5(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i64m1x6(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i64m1x7(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i64m1x8(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i64m2x2(int64_t *rs1, vuint8mf4_t vs2,
                                   vint64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i64m2x3(int64_t *rs1, vuint8mf4_t vs2,
                                   vint64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i64m2x4(int64_t *rs1, vuint8mf4_t vs2,
                                   vint64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i64m4x2(int64_t *rs1, vuint8mf2_t vs2,
                                   vint64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i64m1x2(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i64m1x3(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i64m1x4(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i64m1x5(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i64m1x6(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i64m1x7(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i64m1x8(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i64m2x2(int64_t *rs1, vuint16mf2_t vs2,
                                    vint64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i64m2x3(int64_t *rs1, vuint16mf2_t vs2,
                                    vint64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i64m2x4(int64_t *rs1, vuint16mf2_t vs2,
                                    vint64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i64m4x2(int64_t *rs1, vuint16m1_t vs2,
                                    vint64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i64m1x2(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i64m1x3(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i64m1x4(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i64m1x5(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i64m1x6(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i64m1x7(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i64m1x8(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i64m2x2(int64_t *rs1, vuint32m1_t vs2,
                                    vint64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i64m2x3(int64_t *rs1, vuint32m1_t vs2,
                                    vint64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i64m2x4(int64_t *rs1, vuint32m1_t vs2,
                                    vint64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i64m4x2(int64_t *rs1, vuint32m2_t vs2,
                                    vint64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i64m1x2(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i64m1x3(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i64m1x4(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i64m1x5(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i64m1x6(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i64m1x7(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i64m1x8(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i64m2x2(int64_t *rs1, vuint64m2_t vs2,
                                    vint64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i64m2x3(int64_t *rs1, vuint64m2_t vs2,
                                    vint64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i64m2x4(int64_t *rs1, vuint64m2_t vs2,
                                    vint64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i64m4x2(int64_t *rs1, vuint64m4_t vs2,
                                    vint64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i8mf8x2(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i8mf8x3(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i8mf8x4(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i8mf8x5(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i8mf8x6(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i8mf8x7(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i8mf8x8(int8_t *rs1, vuint8mf8_t vs2,
                                   vint8mf8x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i8mf4x2(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i8mf4x3(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i8mf4x4(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i8mf4x5(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i8mf4x6(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i8mf4x7(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i8mf4x8(int8_t *rs1, vuint8mf4_t vs2,
                                   vint8mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i8mf2x2(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i8mf2x3(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i8mf2x4(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i8mf2x5(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i8mf2x6(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i8mf2x7(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i8mf2x8(int8_t *rs1, vuint8mf2_t vs2,
                                   vint8mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i8m1x2(int8_t *rs1, vuint8m1_t vs2, vint8m1x2_t vs3,
                                  size_t vl);
void __riscv_vsuxseg3ei8_v_i8m1x3(int8_t *rs1, vuint8m1_t vs2, vint8m1x3_t vs3,
                                  size_t vl);
void __riscv_vsuxseg4ei8_v_i8m1x4(int8_t *rs1, vuint8m1_t vs2, vint8m1x4_t vs3,
                                  size_t vl);
void __riscv_vsuxseg5ei8_v_i8m1x5(int8_t *rs1, vuint8m1_t vs2, vint8m1x5_t vs3,
                                  size_t vl);
void __riscv_vsuxseg6ei8_v_i8m1x6(int8_t *rs1, vuint8m1_t vs2, vint8m1x6_t vs3,
                                  size_t vl);
void __riscv_vsuxseg7ei8_v_i8m1x7(int8_t *rs1, vuint8m1_t vs2, vint8m1x7_t vs3,
                                  size_t vl);
void __riscv_vsuxseg8ei8_v_i8m1x8(int8_t *rs1, vuint8m1_t vs2, vint8m1x8_t vs3,
                                  size_t vl);
void __riscv_vsuxseg2ei8_v_i8m2x2(int8_t *rs1, vuint8m2_t vs2, vint8m2x2_t vs3,
                                  size_t vl);
void __riscv_vsuxseg3ei8_v_i8m2x3(int8_t *rs1, vuint8m2_t vs2, vint8m2x3_t vs3,
                                  size_t vl);
void __riscv_vsuxseg4ei8_v_i8m2x4(int8_t *rs1, vuint8m2_t vs2, vint8m2x4_t vs3,
                                  size_t vl);
void __riscv_vsuxseg2ei8_v_i8m4x2(int8_t *rs1, vuint8m4_t vs2, vint8m4x2_t vs3,
                                  size_t vl);
void __riscv_vsuxseg2ei16_v_i8mf8x2(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i8mf8x3(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i8mf8x4(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i8mf8x5(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i8mf8x6(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i8mf8x7(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i8mf8x8(int8_t *rs1, vuint16mf4_t vs2,
                                    vint8mf8x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i8mf4x2(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i8mf4x3(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i8mf4x4(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i8mf4x5(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i8mf4x6(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i8mf4x7(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i8mf4x8(int8_t *rs1, vuint16mf2_t vs2,
                                    vint8mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i8mf2x2(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i8mf2x3(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i8mf2x4(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i8mf2x5(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i8mf2x6(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i8mf2x7(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i8mf2x8(int8_t *rs1, vuint16m1_t vs2,
                                    vint8mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i8m1x2(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i8m1x3(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i8m1x4(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i8m1x5(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i8m1x6(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i8m1x7(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i8m1x8(int8_t *rs1, vuint16m2_t vs2,
                                   vint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i8m2x2(int8_t *rs1, vuint16m4_t vs2,
                                   vint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i8m2x3(int8_t *rs1, vuint16m4_t vs2,
                                   vint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i8m2x4(int8_t *rs1, vuint16m4_t vs2,
                                   vint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i8m4x2(int8_t *rs1, vuint16m8_t vs2,
                                   vint8m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i8mf8x2(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i8mf8x3(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i8mf8x4(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i8mf8x5(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i8mf8x6(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i8mf8x7(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i8mf8x8(int8_t *rs1, vuint32mf2_t vs2,
                                    vint8mf8x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i8mf4x2(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i8mf4x3(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i8mf4x4(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i8mf4x5(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i8mf4x6(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i8mf4x7(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i8mf4x8(int8_t *rs1, vuint32m1_t vs2,
                                    vint8mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i8mf2x2(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i8mf2x3(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i8mf2x4(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i8mf2x5(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i8mf2x6(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i8mf2x7(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i8mf2x8(int8_t *rs1, vuint32m2_t vs2,
                                    vint8mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i8m1x2(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i8m1x3(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i8m1x4(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i8m1x5(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i8m1x6(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i8m1x7(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i8m1x8(int8_t *rs1, vuint32m4_t vs2,
                                   vint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i8m2x2(int8_t *rs1, vuint32m8_t vs2,
                                   vint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i8m2x3(int8_t *rs1, vuint32m8_t vs2,
                                   vint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i8m2x4(int8_t *rs1, vuint32m8_t vs2,
                                   vint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i8mf8x2(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i8mf8x3(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i8mf8x4(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i8mf8x5(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i8mf8x6(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i8mf8x7(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i8mf8x8(int8_t *rs1, vuint64m1_t vs2,
                                    vint8mf8x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i8mf4x2(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i8mf4x3(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i8mf4x4(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i8mf4x5(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i8mf4x6(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i8mf4x7(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i8mf4x8(int8_t *rs1, vuint64m2_t vs2,
                                    vint8mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i8mf2x2(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i8mf2x3(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i8mf2x4(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i8mf2x5(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i8mf2x6(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i8mf2x7(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i8mf2x8(int8_t *rs1, vuint64m4_t vs2,
                                    vint8mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i8m1x2(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i8m1x3(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i8m1x4(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i8m1x5(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i8m1x6(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i8m1x7(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i8m1x8(int8_t *rs1, vuint64m8_t vs2,
                                   vint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i16mf4x2(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i16mf4x3(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i16mf4x4(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i16mf4x5(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i16mf4x6(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i16mf4x7(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i16mf4x8(int16_t *rs1, vuint8mf8_t vs2,
                                    vint16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i16mf2x2(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i16mf2x3(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i16mf2x4(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i16mf2x5(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i16mf2x6(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i16mf2x7(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i16mf2x8(int16_t *rs1, vuint8mf4_t vs2,
                                    vint16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i16m1x2(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i16m1x3(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i16m1x4(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i16m1x5(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i16m1x6(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i16m1x7(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i16m1x8(int16_t *rs1, vuint8mf2_t vs2,
                                   vint16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i16m2x2(int16_t *rs1, vuint8m1_t vs2,
                                   vint16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i16m2x3(int16_t *rs1, vuint8m1_t vs2,
                                   vint16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i16m2x4(int16_t *rs1, vuint8m1_t vs2,
                                   vint16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i16m4x2(int16_t *rs1, vuint8m2_t vs2,
                                   vint16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i16mf4x2(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i16mf4x3(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i16mf4x4(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i16mf4x5(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i16mf4x6(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i16mf4x7(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i16mf4x8(int16_t *rs1, vuint16mf4_t vs2,
                                     vint16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i16mf2x2(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i16mf2x3(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i16mf2x4(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i16mf2x5(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i16mf2x6(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i16mf2x7(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i16mf2x8(int16_t *rs1, vuint16mf2_t vs2,
                                     vint16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i16m1x2(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i16m1x3(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i16m1x4(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i16m1x5(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i16m1x6(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i16m1x7(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i16m1x8(int16_t *rs1, vuint16m1_t vs2,
                                    vint16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i16m2x2(int16_t *rs1, vuint16m2_t vs2,
                                    vint16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i16m2x3(int16_t *rs1, vuint16m2_t vs2,
                                    vint16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i16m2x4(int16_t *rs1, vuint16m2_t vs2,
                                    vint16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i16m4x2(int16_t *rs1, vuint16m4_t vs2,
                                    vint16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i16mf4x2(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i16mf4x3(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i16mf4x4(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i16mf4x5(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i16mf4x6(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i16mf4x7(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i16mf4x8(int16_t *rs1, vuint32mf2_t vs2,
                                     vint16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i16mf2x2(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i16mf2x3(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i16mf2x4(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i16mf2x5(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i16mf2x6(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i16mf2x7(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i16mf2x8(int16_t *rs1, vuint32m1_t vs2,
                                     vint16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i16m1x2(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i16m1x3(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i16m1x4(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i16m1x5(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i16m1x6(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i16m1x7(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i16m1x8(int16_t *rs1, vuint32m2_t vs2,
                                    vint16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i16m2x2(int16_t *rs1, vuint32m4_t vs2,
                                    vint16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i16m2x3(int16_t *rs1, vuint32m4_t vs2,
                                    vint16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i16m2x4(int16_t *rs1, vuint32m4_t vs2,
                                    vint16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i16m4x2(int16_t *rs1, vuint32m8_t vs2,
                                    vint16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i16mf4x2(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i16mf4x3(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i16mf4x4(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i16mf4x5(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i16mf4x6(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i16mf4x7(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i16mf4x8(int16_t *rs1, vuint64m1_t vs2,
                                     vint16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i16mf2x2(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i16mf2x3(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i16mf2x4(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i16mf2x5(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i16mf2x6(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i16mf2x7(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i16mf2x8(int16_t *rs1, vuint64m2_t vs2,
                                     vint16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i16m1x2(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i16m1x3(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i16m1x4(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i16m1x5(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i16m1x6(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i16m1x7(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i16m1x8(int16_t *rs1, vuint64m4_t vs2,
                                    vint16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i16m2x2(int16_t *rs1, vuint64m8_t vs2,
                                    vint16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i16m2x3(int16_t *rs1, vuint64m8_t vs2,
                                    vint16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i16m2x4(int16_t *rs1, vuint64m8_t vs2,
                                    vint16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i32mf2x2(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i32mf2x3(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i32mf2x4(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i32mf2x5(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i32mf2x6(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i32mf2x7(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i32mf2x8(int32_t *rs1, vuint8mf8_t vs2,
                                    vint32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i32m1x2(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i32m1x3(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i32m1x4(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i32m1x5(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i32m1x6(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i32m1x7(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i32m1x8(int32_t *rs1, vuint8mf4_t vs2,
                                   vint32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i32m2x2(int32_t *rs1, vuint8mf2_t vs2,
                                   vint32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i32m2x3(int32_t *rs1, vuint8mf2_t vs2,
                                   vint32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i32m2x4(int32_t *rs1, vuint8mf2_t vs2,
                                   vint32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i32m4x2(int32_t *rs1, vuint8m1_t vs2,
                                   vint32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i32mf2x2(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i32mf2x3(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i32mf2x4(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i32mf2x5(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i32mf2x6(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i32mf2x7(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i32mf2x8(int32_t *rs1, vuint16mf4_t vs2,
                                     vint32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i32m1x2(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i32m1x3(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i32m1x4(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i32m1x5(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i32m1x6(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i32m1x7(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i32m1x8(int32_t *rs1, vuint16mf2_t vs2,
                                    vint32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i32m2x2(int32_t *rs1, vuint16m1_t vs2,
                                    vint32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i32m2x3(int32_t *rs1, vuint16m1_t vs2,
                                    vint32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i32m2x4(int32_t *rs1, vuint16m1_t vs2,
                                    vint32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i32m4x2(int32_t *rs1, vuint16m2_t vs2,
                                    vint32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i32mf2x2(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i32mf2x3(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i32mf2x4(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i32mf2x5(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i32mf2x6(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i32mf2x7(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i32mf2x8(int32_t *rs1, vuint32mf2_t vs2,
                                     vint32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i32m1x2(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i32m1x3(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i32m1x4(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i32m1x5(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i32m1x6(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i32m1x7(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i32m1x8(int32_t *rs1, vuint32m1_t vs2,
                                    vint32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i32m2x2(int32_t *rs1, vuint32m2_t vs2,
                                    vint32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i32m2x3(int32_t *rs1, vuint32m2_t vs2,
                                    vint32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i32m2x4(int32_t *rs1, vuint32m2_t vs2,
                                    vint32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i32m4x2(int32_t *rs1, vuint32m4_t vs2,
                                    vint32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i32mf2x2(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i32mf2x3(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i32mf2x4(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i32mf2x5(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i32mf2x6(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i32mf2x7(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i32mf2x8(int32_t *rs1, vuint64m1_t vs2,
                                     vint32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i32m1x2(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i32m1x3(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i32m1x4(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i32m1x5(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i32m1x6(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i32m1x7(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i32m1x8(int32_t *rs1, vuint64m2_t vs2,
                                    vint32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i32m2x2(int32_t *rs1, vuint64m4_t vs2,
                                    vint32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i32m2x3(int32_t *rs1, vuint64m4_t vs2,
                                    vint32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i32m2x4(int32_t *rs1, vuint64m4_t vs2,
                                    vint32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i32m4x2(int32_t *rs1, vuint64m8_t vs2,
                                    vint32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i64m1x2(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i64m1x3(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i64m1x4(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i64m1x5(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i64m1x6(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i64m1x7(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i64m1x8(int64_t *rs1, vuint8mf8_t vs2,
                                   vint64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i64m2x2(int64_t *rs1, vuint8mf4_t vs2,
                                   vint64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i64m2x3(int64_t *rs1, vuint8mf4_t vs2,
                                   vint64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i64m2x4(int64_t *rs1, vuint8mf4_t vs2,
                                   vint64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i64m4x2(int64_t *rs1, vuint8mf2_t vs2,
                                   vint64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i64m1x2(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i64m1x3(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i64m1x4(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i64m1x5(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i64m1x6(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i64m1x7(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i64m1x8(int64_t *rs1, vuint16mf4_t vs2,
                                    vint64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i64m2x2(int64_t *rs1, vuint16mf2_t vs2,
                                    vint64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i64m2x3(int64_t *rs1, vuint16mf2_t vs2,
                                    vint64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i64m2x4(int64_t *rs1, vuint16mf2_t vs2,
                                    vint64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i64m4x2(int64_t *rs1, vuint16m1_t vs2,
                                    vint64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i64m1x2(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i64m1x3(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i64m1x4(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i64m1x5(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i64m1x6(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i64m1x7(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i64m1x8(int64_t *rs1, vuint32mf2_t vs2,
                                    vint64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i64m2x2(int64_t *rs1, vuint32m1_t vs2,
                                    vint64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i64m2x3(int64_t *rs1, vuint32m1_t vs2,
                                    vint64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i64m2x4(int64_t *rs1, vuint32m1_t vs2,
                                    vint64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i64m4x2(int64_t *rs1, vuint32m2_t vs2,
                                    vint64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i64m1x2(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i64m1x3(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i64m1x4(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i64m1x5(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i64m1x6(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i64m1x7(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i64m1x8(int64_t *rs1, vuint64m1_t vs2,
                                    vint64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i64m2x2(int64_t *rs1, vuint64m2_t vs2,
                                    vint64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i64m2x3(int64_t *rs1, vuint64m2_t vs2,
                                    vint64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i64m2x4(int64_t *rs1, vuint64m2_t vs2,
                                    vint64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i64m4x2(int64_t *rs1, vuint64m4_t vs2,
                                    vint64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u8mf8x2(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u8mf8x3(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u8mf8x4(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u8mf8x5(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u8mf8x6(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u8mf8x7(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u8mf8x8(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u8mf4x2(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u8mf4x3(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u8mf4x4(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u8mf4x5(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u8mf4x6(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u8mf4x7(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u8mf4x8(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u8mf2x2(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u8mf2x3(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u8mf2x4(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u8mf2x5(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u8mf2x6(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u8mf2x7(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u8mf2x8(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u8m1x2(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u8m1x3(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u8m1x4(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u8m1x5(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u8m1x6(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u8m1x7(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u8m1x8(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u8m2x2(uint8_t *rs1, vuint8m2_t vs2,
                                  vuint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u8m2x3(uint8_t *rs1, vuint8m2_t vs2,
                                  vuint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u8m2x4(uint8_t *rs1, vuint8m2_t vs2,
                                  vuint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u8m4x2(uint8_t *rs1, vuint8m4_t vs2,
                                  vuint8m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u8mf8x2(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u8mf8x3(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u8mf8x4(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u8mf8x5(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u8mf8x6(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u8mf8x7(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u8mf8x8(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u8mf4x2(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u8mf4x3(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u8mf4x4(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u8mf4x5(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u8mf4x6(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u8mf4x7(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u8mf4x8(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u8mf2x2(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u8mf2x3(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u8mf2x4(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u8mf2x5(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u8mf2x6(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u8mf2x7(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u8mf2x8(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u8m1x2(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u8m1x3(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u8m1x4(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u8m1x5(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u8m1x6(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u8m1x7(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u8m1x8(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u8m2x2(uint8_t *rs1, vuint16m4_t vs2,
                                   vuint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u8m2x3(uint8_t *rs1, vuint16m4_t vs2,
                                   vuint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u8m2x4(uint8_t *rs1, vuint16m4_t vs2,
                                   vuint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u8m4x2(uint8_t *rs1, vuint16m8_t vs2,
                                   vuint8m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u8mf8x2(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u8mf8x3(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u8mf8x4(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u8mf8x5(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u8mf8x6(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u8mf8x7(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u8mf8x8(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u8mf4x2(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u8mf4x3(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u8mf4x4(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u8mf4x5(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u8mf4x6(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u8mf4x7(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u8mf4x8(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u8mf2x2(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u8mf2x3(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u8mf2x4(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u8mf2x5(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u8mf2x6(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u8mf2x7(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u8mf2x8(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u8m1x2(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u8m1x3(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u8m1x4(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u8m1x5(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u8m1x6(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u8m1x7(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u8m1x8(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u8m2x2(uint8_t *rs1, vuint32m8_t vs2,
                                   vuint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u8m2x3(uint8_t *rs1, vuint32m8_t vs2,
                                   vuint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u8m2x4(uint8_t *rs1, vuint32m8_t vs2,
                                   vuint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u8mf8x2(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u8mf8x3(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u8mf8x4(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u8mf8x5(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u8mf8x6(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u8mf8x7(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u8mf8x8(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u8mf4x2(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u8mf4x3(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u8mf4x4(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u8mf4x5(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u8mf4x6(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u8mf4x7(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u8mf4x8(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u8mf2x2(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u8mf2x3(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u8mf2x4(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u8mf2x5(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u8mf2x6(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u8mf2x7(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u8mf2x8(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u8m1x2(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u8m1x3(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u8m1x4(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u8m1x5(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u8m1x6(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u8m1x7(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u8m1x8(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u16mf4x2(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u16mf4x3(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u16mf4x4(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u16mf4x5(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u16mf4x6(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u16mf4x7(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u16mf4x8(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u16mf2x2(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u16mf2x3(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u16mf2x4(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u16mf2x5(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u16mf2x6(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u16mf2x7(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u16mf2x8(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u16m1x2(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u16m1x3(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u16m1x4(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u16m1x5(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u16m1x6(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u16m1x7(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u16m1x8(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u16m2x2(uint16_t *rs1, vuint8m1_t vs2,
                                   vuint16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u16m2x3(uint16_t *rs1, vuint8m1_t vs2,
                                   vuint16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u16m2x4(uint16_t *rs1, vuint8m1_t vs2,
                                   vuint16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u16m4x2(uint16_t *rs1, vuint8m2_t vs2,
                                   vuint16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u16mf4x2(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u16mf4x3(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u16mf4x4(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u16mf4x5(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u16mf4x6(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u16mf4x7(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u16mf4x8(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u16mf2x2(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u16mf2x3(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u16mf2x4(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u16mf2x5(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u16mf2x6(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u16mf2x7(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u16mf2x8(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u16m1x2(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u16m1x3(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u16m1x4(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u16m1x5(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u16m1x6(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u16m1x7(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u16m1x8(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u16m2x2(uint16_t *rs1, vuint16m2_t vs2,
                                    vuint16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u16m2x3(uint16_t *rs1, vuint16m2_t vs2,
                                    vuint16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u16m2x4(uint16_t *rs1, vuint16m2_t vs2,
                                    vuint16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u16m4x2(uint16_t *rs1, vuint16m4_t vs2,
                                    vuint16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u16mf4x2(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u16mf4x3(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u16mf4x4(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u16mf4x5(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u16mf4x6(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u16mf4x7(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u16mf4x8(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u16mf2x2(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u16mf2x3(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u16mf2x4(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u16mf2x5(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u16mf2x6(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u16mf2x7(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u16mf2x8(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u16m1x2(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u16m1x3(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u16m1x4(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u16m1x5(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u16m1x6(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u16m1x7(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u16m1x8(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u16m2x2(uint16_t *rs1, vuint32m4_t vs2,
                                    vuint16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u16m2x3(uint16_t *rs1, vuint32m4_t vs2,
                                    vuint16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u16m2x4(uint16_t *rs1, vuint32m4_t vs2,
                                    vuint16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u16m4x2(uint16_t *rs1, vuint32m8_t vs2,
                                    vuint16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u16mf4x2(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u16mf4x3(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u16mf4x4(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u16mf4x5(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u16mf4x6(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u16mf4x7(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u16mf4x8(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u16mf2x2(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u16mf2x3(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u16mf2x4(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u16mf2x5(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u16mf2x6(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u16mf2x7(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u16mf2x8(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u16m1x2(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u16m1x3(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u16m1x4(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u16m1x5(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u16m1x6(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u16m1x7(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u16m1x8(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u16m2x2(uint16_t *rs1, vuint64m8_t vs2,
                                    vuint16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u16m2x3(uint16_t *rs1, vuint64m8_t vs2,
                                    vuint16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u16m2x4(uint16_t *rs1, vuint64m8_t vs2,
                                    vuint16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u32mf2x2(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u32mf2x3(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u32mf2x4(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u32mf2x5(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u32mf2x6(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u32mf2x7(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u32mf2x8(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u32m1x2(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u32m1x3(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u32m1x4(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u32m1x5(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u32m1x6(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u32m1x7(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u32m1x8(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u32m2x2(uint32_t *rs1, vuint8mf2_t vs2,
                                   vuint32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u32m2x3(uint32_t *rs1, vuint8mf2_t vs2,
                                   vuint32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u32m2x4(uint32_t *rs1, vuint8mf2_t vs2,
                                   vuint32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u32m4x2(uint32_t *rs1, vuint8m1_t vs2,
                                   vuint32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u32mf2x2(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u32mf2x3(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u32mf2x4(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u32mf2x5(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u32mf2x6(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u32mf2x7(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u32mf2x8(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u32m1x2(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u32m1x3(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u32m1x4(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u32m1x5(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u32m1x6(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u32m1x7(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u32m1x8(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u32m2x2(uint32_t *rs1, vuint16m1_t vs2,
                                    vuint32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u32m2x3(uint32_t *rs1, vuint16m1_t vs2,
                                    vuint32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u32m2x4(uint32_t *rs1, vuint16m1_t vs2,
                                    vuint32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u32m4x2(uint32_t *rs1, vuint16m2_t vs2,
                                    vuint32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u32mf2x2(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u32mf2x3(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u32mf2x4(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u32mf2x5(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u32mf2x6(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u32mf2x7(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u32mf2x8(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u32m1x2(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u32m1x3(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u32m1x4(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u32m1x5(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u32m1x6(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u32m1x7(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u32m1x8(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u32m2x2(uint32_t *rs1, vuint32m2_t vs2,
                                    vuint32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u32m2x3(uint32_t *rs1, vuint32m2_t vs2,
                                    vuint32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u32m2x4(uint32_t *rs1, vuint32m2_t vs2,
                                    vuint32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u32m4x2(uint32_t *rs1, vuint32m4_t vs2,
                                    vuint32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u32mf2x2(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u32mf2x3(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u32mf2x4(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u32mf2x5(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u32mf2x6(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u32mf2x7(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u32mf2x8(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u32m1x2(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u32m1x3(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u32m1x4(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u32m1x5(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u32m1x6(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u32m1x7(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u32m1x8(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u32m2x2(uint32_t *rs1, vuint64m4_t vs2,
                                    vuint32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u32m2x3(uint32_t *rs1, vuint64m4_t vs2,
                                    vuint32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u32m2x4(uint32_t *rs1, vuint64m4_t vs2,
                                    vuint32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u32m4x2(uint32_t *rs1, vuint64m8_t vs2,
                                    vuint32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u64m1x2(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u64m1x3(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u64m1x4(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u64m1x5(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u64m1x6(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u64m1x7(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u64m1x8(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u64m2x2(uint64_t *rs1, vuint8mf4_t vs2,
                                   vuint64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u64m2x3(uint64_t *rs1, vuint8mf4_t vs2,
                                   vuint64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u64m2x4(uint64_t *rs1, vuint8mf4_t vs2,
                                   vuint64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u64m4x2(uint64_t *rs1, vuint8mf2_t vs2,
                                   vuint64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u64m1x2(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u64m1x3(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u64m1x4(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u64m1x5(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u64m1x6(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u64m1x7(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u64m1x8(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u64m2x2(uint64_t *rs1, vuint16mf2_t vs2,
                                    vuint64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u64m2x3(uint64_t *rs1, vuint16mf2_t vs2,
                                    vuint64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u64m2x4(uint64_t *rs1, vuint16mf2_t vs2,
                                    vuint64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u64m4x2(uint64_t *rs1, vuint16m1_t vs2,
                                    vuint64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u64m1x2(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u64m1x3(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u64m1x4(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u64m1x5(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u64m1x6(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u64m1x7(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u64m1x8(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u64m2x2(uint64_t *rs1, vuint32m1_t vs2,
                                    vuint64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u64m2x3(uint64_t *rs1, vuint32m1_t vs2,
                                    vuint64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u64m2x4(uint64_t *rs1, vuint32m1_t vs2,
                                    vuint64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u64m4x2(uint64_t *rs1, vuint32m2_t vs2,
                                    vuint64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u64m1x2(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u64m1x3(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u64m1x4(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u64m1x5(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u64m1x6(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u64m1x7(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u64m1x8(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u64m2x2(uint64_t *rs1, vuint64m2_t vs2,
                                    vuint64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u64m2x3(uint64_t *rs1, vuint64m2_t vs2,
                                    vuint64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u64m2x4(uint64_t *rs1, vuint64m2_t vs2,
                                    vuint64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u64m4x2(uint64_t *rs1, vuint64m4_t vs2,
                                    vuint64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u8mf8x2(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u8mf8x3(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u8mf8x4(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u8mf8x5(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u8mf8x6(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u8mf8x7(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u8mf8x8(uint8_t *rs1, vuint8mf8_t vs2,
                                   vuint8mf8x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u8mf4x2(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u8mf4x3(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u8mf4x4(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u8mf4x5(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u8mf4x6(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u8mf4x7(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u8mf4x8(uint8_t *rs1, vuint8mf4_t vs2,
                                   vuint8mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u8mf2x2(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u8mf2x3(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u8mf2x4(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u8mf2x5(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u8mf2x6(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u8mf2x7(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u8mf2x8(uint8_t *rs1, vuint8mf2_t vs2,
                                   vuint8mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u8m1x2(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u8m1x3(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u8m1x4(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u8m1x5(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u8m1x6(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u8m1x7(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u8m1x8(uint8_t *rs1, vuint8m1_t vs2,
                                  vuint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u8m2x2(uint8_t *rs1, vuint8m2_t vs2,
                                  vuint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u8m2x3(uint8_t *rs1, vuint8m2_t vs2,
                                  vuint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u8m2x4(uint8_t *rs1, vuint8m2_t vs2,
                                  vuint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u8m4x2(uint8_t *rs1, vuint8m4_t vs2,
                                  vuint8m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u8mf8x2(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u8mf8x3(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u8mf8x4(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u8mf8x5(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u8mf8x6(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u8mf8x7(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u8mf8x8(uint8_t *rs1, vuint16mf4_t vs2,
                                    vuint8mf8x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u8mf4x2(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u8mf4x3(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u8mf4x4(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u8mf4x5(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u8mf4x6(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u8mf4x7(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u8mf4x8(uint8_t *rs1, vuint16mf2_t vs2,
                                    vuint8mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u8mf2x2(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u8mf2x3(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u8mf2x4(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u8mf2x5(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u8mf2x6(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u8mf2x7(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u8mf2x8(uint8_t *rs1, vuint16m1_t vs2,
                                    vuint8mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u8m1x2(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u8m1x3(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u8m1x4(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u8m1x5(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u8m1x6(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u8m1x7(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u8m1x8(uint8_t *rs1, vuint16m2_t vs2,
                                   vuint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u8m2x2(uint8_t *rs1, vuint16m4_t vs2,
                                   vuint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u8m2x3(uint8_t *rs1, vuint16m4_t vs2,
                                   vuint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u8m2x4(uint8_t *rs1, vuint16m4_t vs2,
                                   vuint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u8m4x2(uint8_t *rs1, vuint16m8_t vs2,
                                   vuint8m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u8mf8x2(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u8mf8x3(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u8mf8x4(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u8mf8x5(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u8mf8x6(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u8mf8x7(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u8mf8x8(uint8_t *rs1, vuint32mf2_t vs2,
                                    vuint8mf8x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u8mf4x2(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u8mf4x3(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u8mf4x4(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u8mf4x5(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u8mf4x6(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u8mf4x7(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u8mf4x8(uint8_t *rs1, vuint32m1_t vs2,
                                    vuint8mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u8mf2x2(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u8mf2x3(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u8mf2x4(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u8mf2x5(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u8mf2x6(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u8mf2x7(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u8mf2x8(uint8_t *rs1, vuint32m2_t vs2,
                                    vuint8mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u8m1x2(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u8m1x3(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u8m1x4(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u8m1x5(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u8m1x6(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u8m1x7(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u8m1x8(uint8_t *rs1, vuint32m4_t vs2,
                                   vuint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u8m2x2(uint8_t *rs1, vuint32m8_t vs2,
                                   vuint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u8m2x3(uint8_t *rs1, vuint32m8_t vs2,
                                   vuint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u8m2x4(uint8_t *rs1, vuint32m8_t vs2,
                                   vuint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u8mf8x2(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u8mf8x3(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u8mf8x4(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u8mf8x5(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u8mf8x6(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u8mf8x7(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u8mf8x8(uint8_t *rs1, vuint64m1_t vs2,
                                    vuint8mf8x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u8mf4x2(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u8mf4x3(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u8mf4x4(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u8mf4x5(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u8mf4x6(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u8mf4x7(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u8mf4x8(uint8_t *rs1, vuint64m2_t vs2,
                                    vuint8mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u8mf2x2(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u8mf2x3(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u8mf2x4(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u8mf2x5(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u8mf2x6(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u8mf2x7(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u8mf2x8(uint8_t *rs1, vuint64m4_t vs2,
                                    vuint8mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u8m1x2(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u8m1x3(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u8m1x4(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u8m1x5(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u8m1x6(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u8m1x7(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u8m1x8(uint8_t *rs1, vuint64m8_t vs2,
                                   vuint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u16mf4x2(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u16mf4x3(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u16mf4x4(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u16mf4x5(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u16mf4x6(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u16mf4x7(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u16mf4x8(uint16_t *rs1, vuint8mf8_t vs2,
                                    vuint16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u16mf2x2(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u16mf2x3(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u16mf2x4(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u16mf2x5(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u16mf2x6(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u16mf2x7(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u16mf2x8(uint16_t *rs1, vuint8mf4_t vs2,
                                    vuint16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u16m1x2(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u16m1x3(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u16m1x4(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u16m1x5(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u16m1x6(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u16m1x7(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u16m1x8(uint16_t *rs1, vuint8mf2_t vs2,
                                   vuint16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u16m2x2(uint16_t *rs1, vuint8m1_t vs2,
                                   vuint16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u16m2x3(uint16_t *rs1, vuint8m1_t vs2,
                                   vuint16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u16m2x4(uint16_t *rs1, vuint8m1_t vs2,
                                   vuint16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u16m4x2(uint16_t *rs1, vuint8m2_t vs2,
                                   vuint16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u16mf4x2(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u16mf4x3(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u16mf4x4(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u16mf4x5(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u16mf4x6(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u16mf4x7(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u16mf4x8(uint16_t *rs1, vuint16mf4_t vs2,
                                     vuint16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u16mf2x2(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u16mf2x3(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u16mf2x4(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u16mf2x5(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u16mf2x6(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u16mf2x7(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u16mf2x8(uint16_t *rs1, vuint16mf2_t vs2,
                                     vuint16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u16m1x2(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u16m1x3(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u16m1x4(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u16m1x5(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u16m1x6(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u16m1x7(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u16m1x8(uint16_t *rs1, vuint16m1_t vs2,
                                    vuint16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u16m2x2(uint16_t *rs1, vuint16m2_t vs2,
                                    vuint16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u16m2x3(uint16_t *rs1, vuint16m2_t vs2,
                                    vuint16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u16m2x4(uint16_t *rs1, vuint16m2_t vs2,
                                    vuint16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u16m4x2(uint16_t *rs1, vuint16m4_t vs2,
                                    vuint16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u16mf4x2(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u16mf4x3(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u16mf4x4(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u16mf4x5(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u16mf4x6(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u16mf4x7(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u16mf4x8(uint16_t *rs1, vuint32mf2_t vs2,
                                     vuint16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u16mf2x2(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u16mf2x3(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u16mf2x4(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u16mf2x5(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u16mf2x6(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u16mf2x7(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u16mf2x8(uint16_t *rs1, vuint32m1_t vs2,
                                     vuint16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u16m1x2(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u16m1x3(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u16m1x4(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u16m1x5(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u16m1x6(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u16m1x7(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u16m1x8(uint16_t *rs1, vuint32m2_t vs2,
                                    vuint16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u16m2x2(uint16_t *rs1, vuint32m4_t vs2,
                                    vuint16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u16m2x3(uint16_t *rs1, vuint32m4_t vs2,
                                    vuint16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u16m2x4(uint16_t *rs1, vuint32m4_t vs2,
                                    vuint16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u16m4x2(uint16_t *rs1, vuint32m8_t vs2,
                                    vuint16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u16mf4x2(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u16mf4x3(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u16mf4x4(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u16mf4x5(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u16mf4x6(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u16mf4x7(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u16mf4x8(uint16_t *rs1, vuint64m1_t vs2,
                                     vuint16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u16mf2x2(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u16mf2x3(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u16mf2x4(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u16mf2x5(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u16mf2x6(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u16mf2x7(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u16mf2x8(uint16_t *rs1, vuint64m2_t vs2,
                                     vuint16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u16m1x2(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u16m1x3(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u16m1x4(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u16m1x5(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u16m1x6(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u16m1x7(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u16m1x8(uint16_t *rs1, vuint64m4_t vs2,
                                    vuint16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u16m2x2(uint16_t *rs1, vuint64m8_t vs2,
                                    vuint16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u16m2x3(uint16_t *rs1, vuint64m8_t vs2,
                                    vuint16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u16m2x4(uint16_t *rs1, vuint64m8_t vs2,
                                    vuint16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u32mf2x2(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u32mf2x3(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u32mf2x4(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u32mf2x5(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u32mf2x6(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u32mf2x7(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u32mf2x8(uint32_t *rs1, vuint8mf8_t vs2,
                                    vuint32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u32m1x2(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u32m1x3(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u32m1x4(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u32m1x5(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u32m1x6(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u32m1x7(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u32m1x8(uint32_t *rs1, vuint8mf4_t vs2,
                                   vuint32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u32m2x2(uint32_t *rs1, vuint8mf2_t vs2,
                                   vuint32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u32m2x3(uint32_t *rs1, vuint8mf2_t vs2,
                                   vuint32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u32m2x4(uint32_t *rs1, vuint8mf2_t vs2,
                                   vuint32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u32m4x2(uint32_t *rs1, vuint8m1_t vs2,
                                   vuint32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u32mf2x2(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u32mf2x3(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u32mf2x4(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u32mf2x5(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u32mf2x6(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u32mf2x7(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u32mf2x8(uint32_t *rs1, vuint16mf4_t vs2,
                                     vuint32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u32m1x2(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u32m1x3(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u32m1x4(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u32m1x5(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u32m1x6(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u32m1x7(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u32m1x8(uint32_t *rs1, vuint16mf2_t vs2,
                                    vuint32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u32m2x2(uint32_t *rs1, vuint16m1_t vs2,
                                    vuint32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u32m2x3(uint32_t *rs1, vuint16m1_t vs2,
                                    vuint32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u32m2x4(uint32_t *rs1, vuint16m1_t vs2,
                                    vuint32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u32m4x2(uint32_t *rs1, vuint16m2_t vs2,
                                    vuint32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u32mf2x2(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u32mf2x3(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u32mf2x4(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u32mf2x5(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u32mf2x6(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u32mf2x7(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u32mf2x8(uint32_t *rs1, vuint32mf2_t vs2,
                                     vuint32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u32m1x2(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u32m1x3(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u32m1x4(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u32m1x5(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u32m1x6(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u32m1x7(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u32m1x8(uint32_t *rs1, vuint32m1_t vs2,
                                    vuint32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u32m2x2(uint32_t *rs1, vuint32m2_t vs2,
                                    vuint32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u32m2x3(uint32_t *rs1, vuint32m2_t vs2,
                                    vuint32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u32m2x4(uint32_t *rs1, vuint32m2_t vs2,
                                    vuint32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u32m4x2(uint32_t *rs1, vuint32m4_t vs2,
                                    vuint32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u32mf2x2(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u32mf2x3(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u32mf2x4(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u32mf2x5(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u32mf2x6(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u32mf2x7(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u32mf2x8(uint32_t *rs1, vuint64m1_t vs2,
                                     vuint32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u32m1x2(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u32m1x3(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u32m1x4(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u32m1x5(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u32m1x6(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u32m1x7(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u32m1x8(uint32_t *rs1, vuint64m2_t vs2,
                                    vuint32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u32m2x2(uint32_t *rs1, vuint64m4_t vs2,
                                    vuint32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u32m2x3(uint32_t *rs1, vuint64m4_t vs2,
                                    vuint32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u32m2x4(uint32_t *rs1, vuint64m4_t vs2,
                                    vuint32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u32m4x2(uint32_t *rs1, vuint64m8_t vs2,
                                    vuint32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u64m1x2(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u64m1x3(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u64m1x4(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u64m1x5(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u64m1x6(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u64m1x7(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u64m1x8(uint64_t *rs1, vuint8mf8_t vs2,
                                   vuint64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u64m2x2(uint64_t *rs1, vuint8mf4_t vs2,
                                   vuint64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u64m2x3(uint64_t *rs1, vuint8mf4_t vs2,
                                   vuint64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u64m2x4(uint64_t *rs1, vuint8mf4_t vs2,
                                   vuint64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u64m4x2(uint64_t *rs1, vuint8mf2_t vs2,
                                   vuint64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u64m1x2(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u64m1x3(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u64m1x4(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u64m1x5(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u64m1x6(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u64m1x7(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u64m1x8(uint64_t *rs1, vuint16mf4_t vs2,
                                    vuint64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u64m2x2(uint64_t *rs1, vuint16mf2_t vs2,
                                    vuint64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u64m2x3(uint64_t *rs1, vuint16mf2_t vs2,
                                    vuint64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u64m2x4(uint64_t *rs1, vuint16mf2_t vs2,
                                    vuint64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u64m4x2(uint64_t *rs1, vuint16m1_t vs2,
                                    vuint64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u64m1x2(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u64m1x3(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u64m1x4(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u64m1x5(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u64m1x6(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u64m1x7(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u64m1x8(uint64_t *rs1, vuint32mf2_t vs2,
                                    vuint64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u64m2x2(uint64_t *rs1, vuint32m1_t vs2,
                                    vuint64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u64m2x3(uint64_t *rs1, vuint32m1_t vs2,
                                    vuint64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u64m2x4(uint64_t *rs1, vuint32m1_t vs2,
                                    vuint64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u64m4x2(uint64_t *rs1, vuint32m2_t vs2,
                                    vuint64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u64m1x2(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u64m1x3(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u64m1x4(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u64m1x5(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u64m1x6(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u64m1x7(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u64m1x8(uint64_t *rs1, vuint64m1_t vs2,
                                    vuint64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u64m2x2(uint64_t *rs1, vuint64m2_t vs2,
                                    vuint64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u64m2x3(uint64_t *rs1, vuint64m2_t vs2,
                                    vuint64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u64m2x4(uint64_t *rs1, vuint64m2_t vs2,
                                    vuint64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u64m4x2(uint64_t *rs1, vuint64m4_t vs2,
                                    vuint64m4x2_t vs3, size_t vl);
// masked functions
void __riscv_vsoxseg2ei8_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei8_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei8_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei8_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei8_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei8_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei8_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei8_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei8_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei8_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei8_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei8_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei8_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg5ei8_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x5_t vs3,
                                     size_t vl);
void __riscv_vsoxseg6ei8_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x6_t vs3,
                                     size_t vl);
void __riscv_vsoxseg7ei8_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x7_t vs3,
                                     size_t vl);
void __riscv_vsoxseg8ei8_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x8_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1, vuint8m1_t vs2,
                                     vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1, vuint8m1_t vs2,
                                     vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1, vuint8m1_t vs2,
                                     vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1, vuint8m2_t vs2,
                                     vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1,
                                      vuint16m4_t vs2, vfloat16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei32_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei32_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei32_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei32_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei32_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei32_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei32_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei32_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei32_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei32_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei32_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei32_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei32_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei32_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1,
                                      vuint32m4_t vs2, vfloat16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1,
                                      vuint32m4_t vs2, vfloat16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1,
                                      vuint32m4_t vs2, vfloat16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1,
                                      vuint32m8_t vs2, vfloat16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei64_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei64_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei64_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei64_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei64_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei64_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei64_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei64_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei64_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei64_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei64_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei64_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei64_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei64_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1,
                                      vuint64m8_t vs2, vfloat16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1,
                                      vuint64m8_t vs2, vfloat16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1,
                                      vuint64m8_t vs2, vfloat16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_f32mf2x2_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f32mf2x3_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f32mf2x4_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_f32mf2x5_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_f32mf2x6_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_f32mf2x7_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_f32mf2x8_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f32m1x2_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f32m1x3_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f32m1x4_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_f32m1x5_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_f32m1x6_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_f32m1x7_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_f32m1x8_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f32m2x2_m(vbool16_t vm, float *rs1, vuint8mf2_t vs2,
                                     vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f32m2x3_m(vbool16_t vm, float *rs1, vuint8mf2_t vs2,
                                     vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f32m2x4_m(vbool16_t vm, float *rs1, vuint8mf2_t vs2,
                                     vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f32m4x2_m(vbool8_t vm, float *rs1, vuint8m1_t vs2,
                                     vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f32mf2x2_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_f32mf2x3_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_f32mf2x4_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_f32mf2x5_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_f32mf2x6_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_f32mf2x7_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_f32mf2x8_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_f32m1x2_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_f32m1x3_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_f32m1x4_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_f32m1x5_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_f32m1x6_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_f32m1x7_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_f32m1x8_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_f32m2x2_m(vbool16_t vm, float *rs1, vuint16m1_t vs2,
                                      vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f32m2x3_m(vbool16_t vm, float *rs1, vuint16m1_t vs2,
                                      vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f32m2x4_m(vbool16_t vm, float *rs1, vuint16m1_t vs2,
                                      vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f32m4x2_m(vbool8_t vm, float *rs1, vuint16m2_t vs2,
                                      vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f32mf2x2_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei32_v_f32mf2x3_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei32_v_f32mf2x4_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei32_v_f32mf2x5_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei32_v_f32mf2x6_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei32_v_f32mf2x7_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei32_v_f32mf2x8_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei32_v_f32m1x2_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f32m1x3_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f32m1x4_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_f32m1x5_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_f32m1x6_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_f32m1x7_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_f32m1x8_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f32m2x2_m(vbool16_t vm, float *rs1, vuint32m2_t vs2,
                                      vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_f32m2x3_m(vbool16_t vm, float *rs1, vuint32m2_t vs2,
                                      vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_f32m2x4_m(vbool16_t vm, float *rs1, vuint32m2_t vs2,
                                      vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_f32m4x2_m(vbool8_t vm, float *rs1, vuint32m4_t vs2,
                                      vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f32mf2x2_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei64_v_f32mf2x3_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei64_v_f32mf2x4_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei64_v_f32mf2x5_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei64_v_f32mf2x6_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei64_v_f32mf2x7_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei64_v_f32mf2x8_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei64_v_f32m1x2_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f32m1x3_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f32m1x4_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_f32m1x5_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_f32m1x6_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_f32m1x7_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_f32m1x8_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f32m2x2_m(vbool16_t vm, float *rs1, vuint64m4_t vs2,
                                      vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_f32m2x3_m(vbool16_t vm, float *rs1, vuint64m4_t vs2,
                                      vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_f32m2x4_m(vbool16_t vm, float *rs1, vuint64m4_t vs2,
                                      vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_f32m4x2_m(vbool8_t vm, float *rs1, vuint64m8_t vs2,
                                      vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f64m1x2_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f64m1x3_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f64m1x4_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_f64m1x5_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_f64m1x6_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_f64m1x7_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_f64m1x8_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f64m2x2_m(vbool32_t vm, double *rs1, vuint8mf4_t vs2,
                                     vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_f64m2x3_m(vbool32_t vm, double *rs1, vuint8mf4_t vs2,
                                     vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_f64m2x4_m(vbool32_t vm, double *rs1, vuint8mf4_t vs2,
                                     vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_f64m4x2_m(vbool16_t vm, double *rs1, vuint8mf2_t vs2,
                                     vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f64m1x2_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_f64m1x3_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_f64m1x4_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_f64m1x5_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_f64m1x6_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_f64m1x7_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_f64m1x8_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_f64m2x2_m(vbool32_t vm, double *rs1,
                                      vuint16mf2_t vs2, vfloat64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_f64m2x3_m(vbool32_t vm, double *rs1,
                                      vuint16mf2_t vs2, vfloat64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_f64m2x4_m(vbool32_t vm, double *rs1,
                                      vuint16mf2_t vs2, vfloat64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_f64m4x2_m(vbool16_t vm, double *rs1,
                                      vuint16m1_t vs2, vfloat64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_f64m1x2_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_f64m1x3_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_f64m1x4_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_f64m1x5_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_f64m1x6_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_f64m1x7_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_f64m1x8_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_f64m2x2_m(vbool32_t vm, double *rs1,
                                      vuint32m1_t vs2, vfloat64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_f64m2x3_m(vbool32_t vm, double *rs1,
                                      vuint32m1_t vs2, vfloat64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_f64m2x4_m(vbool32_t vm, double *rs1,
                                      vuint32m1_t vs2, vfloat64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_f64m4x2_m(vbool16_t vm, double *rs1,
                                      vuint32m2_t vs2, vfloat64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_f64m1x2_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_f64m1x3_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_f64m1x4_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_f64m1x5_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_f64m1x6_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_f64m1x7_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_f64m1x8_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_f64m2x2_m(vbool32_t vm, double *rs1,
                                      vuint64m2_t vs2, vfloat64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_f64m2x3_m(vbool32_t vm, double *rs1,
                                      vuint64m2_t vs2, vfloat64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_f64m2x4_m(vbool32_t vm, double *rs1,
                                      vuint64m2_t vs2, vfloat64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_f64m4x2_m(vbool16_t vm, double *rs1,
                                      vuint64m4_t vs2, vfloat64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei8_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei8_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei8_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei8_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei8_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei8_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                      vuint8mf8_t vs2, vfloat16mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei8_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei8_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei8_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei8_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei8_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei8_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                      vuint8mf4_t vs2, vfloat16mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg5ei8_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x5_t vs3,
                                     size_t vl);
void __riscv_vsuxseg6ei8_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x6_t vs3,
                                     size_t vl);
void __riscv_vsuxseg7ei8_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x7_t vs3,
                                     size_t vl);
void __riscv_vsuxseg8ei8_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                     vuint8mf2_t vs2, vfloat16m1x8_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1, vuint8m1_t vs2,
                                     vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1, vuint8m1_t vs2,
                                     vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1, vuint8m1_t vs2,
                                     vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1, vuint8m2_t vs2,
                                     vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1,
                                      vuint16m4_t vs2, vfloat16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei32_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei32_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei32_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei32_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei32_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei32_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                       vuint32mf2_t vs2, vfloat16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei32_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei32_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei32_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei32_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei32_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei32_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei32_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                       vuint32m1_t vs2, vfloat16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei32_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                      vuint32m2_t vs2, vfloat16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1,
                                      vuint32m4_t vs2, vfloat16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1,
                                      vuint32m4_t vs2, vfloat16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1,
                                      vuint32m4_t vs2, vfloat16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1,
                                      vuint32m8_t vs2, vfloat16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei64_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei64_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei64_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei64_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei64_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei64_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                       vuint64m1_t vs2, vfloat16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei64_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei64_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei64_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei64_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei64_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei64_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei64_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                       vuint64m2_t vs2, vfloat16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei64_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                      vuint64m4_t vs2, vfloat16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1,
                                      vuint64m8_t vs2, vfloat16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1,
                                      vuint64m8_t vs2, vfloat16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1,
                                      vuint64m8_t vs2, vfloat16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_f32mf2x2_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f32mf2x3_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f32mf2x4_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_f32mf2x5_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_f32mf2x6_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_f32mf2x7_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_f32mf2x8_m(vbool64_t vm, float *rs1, vuint8mf8_t vs2,
                                      vfloat32mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f32m1x2_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f32m1x3_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f32m1x4_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_f32m1x5_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_f32m1x6_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_f32m1x7_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_f32m1x8_m(vbool32_t vm, float *rs1, vuint8mf4_t vs2,
                                     vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f32m2x2_m(vbool16_t vm, float *rs1, vuint8mf2_t vs2,
                                     vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f32m2x3_m(vbool16_t vm, float *rs1, vuint8mf2_t vs2,
                                     vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f32m2x4_m(vbool16_t vm, float *rs1, vuint8mf2_t vs2,
                                     vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f32m4x2_m(vbool8_t vm, float *rs1, vuint8m1_t vs2,
                                     vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f32mf2x2_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_f32mf2x3_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_f32mf2x4_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_f32mf2x5_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_f32mf2x6_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_f32mf2x7_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_f32mf2x8_m(vbool64_t vm, float *rs1,
                                       vuint16mf4_t vs2, vfloat32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_f32m1x2_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_f32m1x3_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_f32m1x4_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_f32m1x5_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_f32m1x6_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_f32m1x7_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_f32m1x8_m(vbool32_t vm, float *rs1,
                                      vuint16mf2_t vs2, vfloat32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_f32m2x2_m(vbool16_t vm, float *rs1, vuint16m1_t vs2,
                                      vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f32m2x3_m(vbool16_t vm, float *rs1, vuint16m1_t vs2,
                                      vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f32m2x4_m(vbool16_t vm, float *rs1, vuint16m1_t vs2,
                                      vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f32m4x2_m(vbool8_t vm, float *rs1, vuint16m2_t vs2,
                                      vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f32mf2x2_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei32_v_f32mf2x3_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei32_v_f32mf2x4_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei32_v_f32mf2x5_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei32_v_f32mf2x6_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei32_v_f32mf2x7_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei32_v_f32mf2x8_m(vbool64_t vm, float *rs1,
                                       vuint32mf2_t vs2, vfloat32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei32_v_f32m1x2_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f32m1x3_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f32m1x4_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_f32m1x5_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_f32m1x6_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_f32m1x7_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_f32m1x8_m(vbool32_t vm, float *rs1, vuint32m1_t vs2,
                                      vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f32m2x2_m(vbool16_t vm, float *rs1, vuint32m2_t vs2,
                                      vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_f32m2x3_m(vbool16_t vm, float *rs1, vuint32m2_t vs2,
                                      vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_f32m2x4_m(vbool16_t vm, float *rs1, vuint32m2_t vs2,
                                      vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_f32m4x2_m(vbool8_t vm, float *rs1, vuint32m4_t vs2,
                                      vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f32mf2x2_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei64_v_f32mf2x3_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei64_v_f32mf2x4_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei64_v_f32mf2x5_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei64_v_f32mf2x6_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei64_v_f32mf2x7_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei64_v_f32mf2x8_m(vbool64_t vm, float *rs1,
                                       vuint64m1_t vs2, vfloat32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei64_v_f32m1x2_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f32m1x3_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f32m1x4_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_f32m1x5_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_f32m1x6_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_f32m1x7_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_f32m1x8_m(vbool32_t vm, float *rs1, vuint64m2_t vs2,
                                      vfloat32m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f32m2x2_m(vbool16_t vm, float *rs1, vuint64m4_t vs2,
                                      vfloat32m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_f32m2x3_m(vbool16_t vm, float *rs1, vuint64m4_t vs2,
                                      vfloat32m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_f32m2x4_m(vbool16_t vm, float *rs1, vuint64m4_t vs2,
                                      vfloat32m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_f32m4x2_m(vbool8_t vm, float *rs1, vuint64m8_t vs2,
                                      vfloat32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f64m1x2_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f64m1x3_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f64m1x4_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_f64m1x5_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_f64m1x6_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_f64m1x7_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_f64m1x8_m(vbool64_t vm, double *rs1, vuint8mf8_t vs2,
                                     vfloat64m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f64m2x2_m(vbool32_t vm, double *rs1, vuint8mf4_t vs2,
                                     vfloat64m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_f64m2x3_m(vbool32_t vm, double *rs1, vuint8mf4_t vs2,
                                     vfloat64m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_f64m2x4_m(vbool32_t vm, double *rs1, vuint8mf4_t vs2,
                                     vfloat64m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_f64m4x2_m(vbool16_t vm, double *rs1, vuint8mf2_t vs2,
                                     vfloat64m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f64m1x2_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_f64m1x3_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_f64m1x4_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_f64m1x5_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_f64m1x6_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_f64m1x7_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_f64m1x8_m(vbool64_t vm, double *rs1,
                                      vuint16mf4_t vs2, vfloat64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_f64m2x2_m(vbool32_t vm, double *rs1,
                                      vuint16mf2_t vs2, vfloat64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_f64m2x3_m(vbool32_t vm, double *rs1,
                                      vuint16mf2_t vs2, vfloat64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_f64m2x4_m(vbool32_t vm, double *rs1,
                                      vuint16mf2_t vs2, vfloat64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_f64m4x2_m(vbool16_t vm, double *rs1,
                                      vuint16m1_t vs2, vfloat64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_f64m1x2_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_f64m1x3_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_f64m1x4_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_f64m1x5_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_f64m1x6_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_f64m1x7_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_f64m1x8_m(vbool64_t vm, double *rs1,
                                      vuint32mf2_t vs2, vfloat64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_f64m2x2_m(vbool32_t vm, double *rs1,
                                      vuint32m1_t vs2, vfloat64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_f64m2x3_m(vbool32_t vm, double *rs1,
                                      vuint32m1_t vs2, vfloat64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_f64m2x4_m(vbool32_t vm, double *rs1,
                                      vuint32m1_t vs2, vfloat64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_f64m4x2_m(vbool16_t vm, double *rs1,
                                      vuint32m2_t vs2, vfloat64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_f64m1x2_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_f64m1x3_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_f64m1x4_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_f64m1x5_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_f64m1x6_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_f64m1x7_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_f64m1x8_m(vbool64_t vm, double *rs1,
                                      vuint64m1_t vs2, vfloat64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_f64m2x2_m(vbool32_t vm, double *rs1,
                                      vuint64m2_t vs2, vfloat64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_f64m2x3_m(vbool32_t vm, double *rs1,
                                      vuint64m2_t vs2, vfloat64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_f64m2x4_m(vbool32_t vm, double *rs1,
                                      vuint64m2_t vs2, vfloat64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_f64m4x2_m(vbool16_t vm, double *rs1,
                                      vuint64m4_t vs2, vfloat64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_i8mf8x2_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i8mf8x3_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i8mf8x4_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i8mf8x5_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i8mf8x6_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i8mf8x7_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i8mf8x8_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i8mf4x2_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i8mf4x3_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i8mf4x4_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i8mf4x5_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i8mf4x6_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i8mf4x7_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i8mf4x8_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i8mf2x2_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i8mf2x3_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i8mf2x4_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i8mf2x5_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i8mf2x6_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i8mf2x7_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i8mf2x8_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i8m1x2_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i8m1x3_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i8m1x4_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_i8m1x5_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_i8m1x6_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_i8m1x7_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_i8m1x8_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i8m2x2_m(vbool4_t vm, int8_t *rs1, vuint8m2_t vs2,
                                    vint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i8m2x3_m(vbool4_t vm, int8_t *rs1, vuint8m2_t vs2,
                                    vint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i8m2x4_m(vbool4_t vm, int8_t *rs1, vuint8m2_t vs2,
                                    vint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i8m4x2_m(vbool2_t vm, int8_t *rs1, vuint8m4_t vs2,
                                    vint8m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i8mf8x2_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_i8mf8x3_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_i8mf8x4_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_i8mf8x5_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_i8mf8x6_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_i8mf8x7_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_i8mf8x8_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_i8mf4x2_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_i8mf4x3_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_i8mf4x4_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_i8mf4x5_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_i8mf4x6_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_i8mf4x7_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_i8mf4x8_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_i8mf2x2_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_i8mf2x3_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_i8mf2x4_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_i8mf2x5_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_i8mf2x6_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_i8mf2x7_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_i8mf2x8_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_i8m1x2_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i8m1x3_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i8m1x4_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_i8m1x5_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_i8m1x6_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_i8m1x7_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_i8m1x8_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i8m2x2_m(vbool4_t vm, int8_t *rs1, vuint16m4_t vs2,
                                     vint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_i8m2x3_m(vbool4_t vm, int8_t *rs1, vuint16m4_t vs2,
                                     vint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_i8m2x4_m(vbool4_t vm, int8_t *rs1, vuint16m4_t vs2,
                                     vint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i8m4x2_m(vbool2_t vm, int8_t *rs1, vuint16m8_t vs2,
                                     vint8m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i8mf8x2_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_i8mf8x3_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_i8mf8x4_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_i8mf8x5_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_i8mf8x6_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_i8mf8x7_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_i8mf8x8_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i8mf4x2_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_i8mf4x3_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_i8mf4x4_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_i8mf4x5_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_i8mf4x6_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_i8mf4x7_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_i8mf4x8_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i8mf2x2_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_i8mf2x3_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_i8mf2x4_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_i8mf2x5_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_i8mf2x6_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_i8mf2x7_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_i8mf2x8_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i8m1x2_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i8m1x3_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i8m1x4_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_i8m1x5_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_i8m1x6_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_i8m1x7_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_i8m1x8_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_i8m2x2_m(vbool4_t vm, int8_t *rs1, vuint32m8_t vs2,
                                     vint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_i8m2x3_m(vbool4_t vm, int8_t *rs1, vuint32m8_t vs2,
                                     vint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_i8m2x4_m(vbool4_t vm, int8_t *rs1, vuint32m8_t vs2,
                                     vint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_i8mf8x2_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_i8mf8x3_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_i8mf8x4_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_i8mf8x5_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_i8mf8x6_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_i8mf8x7_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_i8mf8x8_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i8mf4x2_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_i8mf4x3_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_i8mf4x4_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_i8mf4x5_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_i8mf4x6_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_i8mf4x7_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_i8mf4x8_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i8mf2x2_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_i8mf2x3_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_i8mf2x4_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_i8mf2x5_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_i8mf2x6_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_i8mf2x7_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_i8mf2x8_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i8m1x2_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_i8m1x3_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_i8m1x4_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_i8m1x5_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_i8m1x6_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_i8m1x7_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_i8m1x8_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i16mf4x2_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei8_v_i16mf4x3_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei8_v_i16mf4x4_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei8_v_i16mf4x5_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei8_v_i16mf4x6_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei8_v_i16mf4x7_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei8_v_i16mf4x8_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_i16mf2x2_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei8_v_i16mf2x3_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei8_v_i16mf2x4_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei8_v_i16mf2x5_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei8_v_i16mf2x6_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei8_v_i16mf2x7_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei8_v_i16mf2x8_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_i16m1x2_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_i16m1x3_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_i16m1x4_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg5ei8_v_i16m1x5_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x5_t vs3,
                                     size_t vl);
void __riscv_vsoxseg6ei8_v_i16m1x6_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x6_t vs3,
                                     size_t vl);
void __riscv_vsoxseg7ei8_v_i16m1x7_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x7_t vs3,
                                     size_t vl);
void __riscv_vsoxseg8ei8_v_i16m1x8_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x8_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_i16m2x2_m(vbool8_t vm, int16_t *rs1, vuint8m1_t vs2,
                                     vint16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_i16m2x3_m(vbool8_t vm, int16_t *rs1, vuint8m1_t vs2,
                                     vint16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_i16m2x4_m(vbool8_t vm, int16_t *rs1, vuint8m1_t vs2,
                                     vint16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_i16m4x2_m(vbool4_t vm, int16_t *rs1, vuint8m2_t vs2,
                                     vint16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i16mf4x2_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_i16mf4x3_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_i16mf4x4_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_i16mf4x5_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_i16mf4x6_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_i16mf4x7_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_i16mf4x8_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_i16mf2x2_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_i16mf2x3_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_i16mf2x4_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_i16mf2x5_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_i16mf2x6_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_i16mf2x7_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_i16mf2x8_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_i16m1x2_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_i16m1x3_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_i16m1x4_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_i16m1x5_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_i16m1x6_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_i16m1x7_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_i16m1x8_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_i16m2x2_m(vbool8_t vm, int16_t *rs1,
                                      vuint16m2_t vs2, vint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_i16m2x3_m(vbool8_t vm, int16_t *rs1,
                                      vuint16m2_t vs2, vint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_i16m2x4_m(vbool8_t vm, int16_t *rs1,
                                      vuint16m2_t vs2, vint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_i16m4x2_m(vbool4_t vm, int16_t *rs1,
                                      vuint16m4_t vs2, vint16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i16mf4x2_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei32_v_i16mf4x3_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei32_v_i16mf4x4_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei32_v_i16mf4x5_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei32_v_i16mf4x6_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei32_v_i16mf4x7_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei32_v_i16mf4x8_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei32_v_i16mf2x2_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei32_v_i16mf2x3_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei32_v_i16mf2x4_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei32_v_i16mf2x5_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei32_v_i16mf2x6_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei32_v_i16mf2x7_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei32_v_i16mf2x8_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei32_v_i16m1x2_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_i16m1x3_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_i16m1x4_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_i16m1x5_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_i16m1x6_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_i16m1x7_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_i16m1x8_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i16m2x2_m(vbool8_t vm, int16_t *rs1,
                                      vuint32m4_t vs2, vint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_i16m2x3_m(vbool8_t vm, int16_t *rs1,
                                      vuint32m4_t vs2, vint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_i16m2x4_m(vbool8_t vm, int16_t *rs1,
                                      vuint32m4_t vs2, vint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i16m4x2_m(vbool4_t vm, int16_t *rs1,
                                      vuint32m8_t vs2, vint16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i16mf4x2_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei64_v_i16mf4x3_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei64_v_i16mf4x4_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei64_v_i16mf4x5_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei64_v_i16mf4x6_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei64_v_i16mf4x7_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei64_v_i16mf4x8_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei64_v_i16mf2x2_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei64_v_i16mf2x3_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei64_v_i16mf2x4_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei64_v_i16mf2x5_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei64_v_i16mf2x6_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei64_v_i16mf2x7_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei64_v_i16mf2x8_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei64_v_i16m1x2_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_i16m1x3_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_i16m1x4_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_i16m1x5_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_i16m1x6_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_i16m1x7_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_i16m1x8_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i16m2x2_m(vbool8_t vm, int16_t *rs1,
                                      vuint64m8_t vs2, vint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_i16m2x3_m(vbool8_t vm, int16_t *rs1,
                                      vuint64m8_t vs2, vint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_i16m2x4_m(vbool8_t vm, int16_t *rs1,
                                      vuint64m8_t vs2, vint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_i32mf2x2_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei8_v_i32mf2x3_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei8_v_i32mf2x4_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei8_v_i32mf2x5_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei8_v_i32mf2x6_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei8_v_i32mf2x7_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei8_v_i32mf2x8_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_i32m1x2_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_i32m1x3_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_i32m1x4_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg5ei8_v_i32m1x5_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x5_t vs3,
                                     size_t vl);
void __riscv_vsoxseg6ei8_v_i32m1x6_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x6_t vs3,
                                     size_t vl);
void __riscv_vsoxseg7ei8_v_i32m1x7_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x7_t vs3,
                                     size_t vl);
void __riscv_vsoxseg8ei8_v_i32m1x8_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x8_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_i32m2x2_m(vbool16_t vm, int32_t *rs1,
                                     vuint8mf2_t vs2, vint32m2x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_i32m2x3_m(vbool16_t vm, int32_t *rs1,
                                     vuint8mf2_t vs2, vint32m2x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_i32m2x4_m(vbool16_t vm, int32_t *rs1,
                                     vuint8mf2_t vs2, vint32m2x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_i32m4x2_m(vbool8_t vm, int32_t *rs1, vuint8m1_t vs2,
                                     vint32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_i32mf2x2_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_i32mf2x3_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_i32mf2x4_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_i32mf2x5_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_i32mf2x6_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_i32mf2x7_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_i32mf2x8_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_i32m1x2_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_i32m1x3_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_i32m1x4_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_i32m1x5_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_i32m1x6_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_i32m1x7_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_i32m1x8_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_i32m2x2_m(vbool16_t vm, int32_t *rs1,
                                      vuint16m1_t vs2, vint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_i32m2x3_m(vbool16_t vm, int32_t *rs1,
                                      vuint16m1_t vs2, vint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_i32m2x4_m(vbool16_t vm, int32_t *rs1,
                                      vuint16m1_t vs2, vint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_i32m4x2_m(vbool8_t vm, int32_t *rs1,
                                      vuint16m2_t vs2, vint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i32mf2x2_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei32_v_i32mf2x3_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei32_v_i32mf2x4_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei32_v_i32mf2x5_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei32_v_i32mf2x6_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei32_v_i32mf2x7_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei32_v_i32mf2x8_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei32_v_i32m1x2_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_i32m1x3_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_i32m1x4_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_i32m1x5_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_i32m1x6_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_i32m1x7_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_i32m1x8_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i32m2x2_m(vbool16_t vm, int32_t *rs1,
                                      vuint32m2_t vs2, vint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_i32m2x3_m(vbool16_t vm, int32_t *rs1,
                                      vuint32m2_t vs2, vint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_i32m2x4_m(vbool16_t vm, int32_t *rs1,
                                      vuint32m2_t vs2, vint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i32m4x2_m(vbool8_t vm, int32_t *rs1,
                                      vuint32m4_t vs2, vint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i32mf2x2_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei64_v_i32mf2x3_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei64_v_i32mf2x4_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei64_v_i32mf2x5_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei64_v_i32mf2x6_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei64_v_i32mf2x7_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei64_v_i32mf2x8_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei64_v_i32m1x2_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_i32m1x3_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_i32m1x4_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_i32m1x5_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_i32m1x6_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_i32m1x7_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_i32m1x8_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i32m2x2_m(vbool16_t vm, int32_t *rs1,
                                      vuint64m4_t vs2, vint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_i32m2x3_m(vbool16_t vm, int32_t *rs1,
                                      vuint64m4_t vs2, vint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_i32m2x4_m(vbool16_t vm, int32_t *rs1,
                                      vuint64m4_t vs2, vint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i32m4x2_m(vbool8_t vm, int32_t *rs1,
                                      vuint64m8_t vs2, vint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_i64m1x2_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_i64m1x3_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_i64m1x4_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg5ei8_v_i64m1x5_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x5_t vs3,
                                     size_t vl);
void __riscv_vsoxseg6ei8_v_i64m1x6_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x6_t vs3,
                                     size_t vl);
void __riscv_vsoxseg7ei8_v_i64m1x7_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x7_t vs3,
                                     size_t vl);
void __riscv_vsoxseg8ei8_v_i64m1x8_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x8_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_i64m2x2_m(vbool32_t vm, int64_t *rs1,
                                     vuint8mf4_t vs2, vint64m2x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_i64m2x3_m(vbool32_t vm, int64_t *rs1,
                                     vuint8mf4_t vs2, vint64m2x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_i64m2x4_m(vbool32_t vm, int64_t *rs1,
                                     vuint8mf4_t vs2, vint64m2x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_i64m4x2_m(vbool16_t vm, int64_t *rs1,
                                     vuint8mf2_t vs2, vint64m4x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei16_v_i64m1x2_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_i64m1x3_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_i64m1x4_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_i64m1x5_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_i64m1x6_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_i64m1x7_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_i64m1x8_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_i64m2x2_m(vbool32_t vm, int64_t *rs1,
                                      vuint16mf2_t vs2, vint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_i64m2x3_m(vbool32_t vm, int64_t *rs1,
                                      vuint16mf2_t vs2, vint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_i64m2x4_m(vbool32_t vm, int64_t *rs1,
                                      vuint16mf2_t vs2, vint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_i64m4x2_m(vbool16_t vm, int64_t *rs1,
                                      vuint16m1_t vs2, vint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i64m1x2_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_i64m1x3_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_i64m1x4_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_i64m1x5_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_i64m1x6_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_i64m1x7_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_i64m1x8_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i64m2x2_m(vbool32_t vm, int64_t *rs1,
                                      vuint32m1_t vs2, vint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_i64m2x3_m(vbool32_t vm, int64_t *rs1,
                                      vuint32m1_t vs2, vint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_i64m2x4_m(vbool32_t vm, int64_t *rs1,
                                      vuint32m1_t vs2, vint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_i64m4x2_m(vbool16_t vm, int64_t *rs1,
                                      vuint32m2_t vs2, vint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i64m1x2_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_i64m1x3_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_i64m1x4_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_i64m1x5_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_i64m1x6_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_i64m1x7_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_i64m1x8_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i64m2x2_m(vbool32_t vm, int64_t *rs1,
                                      vuint64m2_t vs2, vint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_i64m2x3_m(vbool32_t vm, int64_t *rs1,
                                      vuint64m2_t vs2, vint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_i64m2x4_m(vbool32_t vm, int64_t *rs1,
                                      vuint64m2_t vs2, vint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_i64m4x2_m(vbool16_t vm, int64_t *rs1,
                                      vuint64m4_t vs2, vint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_i8mf8x2_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i8mf8x3_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i8mf8x4_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i8mf8x5_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i8mf8x6_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i8mf8x7_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i8mf8x8_m(vbool64_t vm, int8_t *rs1, vuint8mf8_t vs2,
                                     vint8mf8x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i8mf4x2_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i8mf4x3_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i8mf4x4_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i8mf4x5_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i8mf4x6_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i8mf4x7_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i8mf4x8_m(vbool32_t vm, int8_t *rs1, vuint8mf4_t vs2,
                                     vint8mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i8mf2x2_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i8mf2x3_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i8mf2x4_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i8mf2x5_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i8mf2x6_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i8mf2x7_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i8mf2x8_m(vbool16_t vm, int8_t *rs1, vuint8mf2_t vs2,
                                     vint8mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i8m1x2_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i8m1x3_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i8m1x4_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_i8m1x5_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_i8m1x6_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_i8m1x7_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_i8m1x8_m(vbool8_t vm, int8_t *rs1, vuint8m1_t vs2,
                                    vint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i8m2x2_m(vbool4_t vm, int8_t *rs1, vuint8m2_t vs2,
                                    vint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i8m2x3_m(vbool4_t vm, int8_t *rs1, vuint8m2_t vs2,
                                    vint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i8m2x4_m(vbool4_t vm, int8_t *rs1, vuint8m2_t vs2,
                                    vint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i8m4x2_m(vbool2_t vm, int8_t *rs1, vuint8m4_t vs2,
                                    vint8m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i8mf8x2_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_i8mf8x3_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_i8mf8x4_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_i8mf8x5_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_i8mf8x6_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_i8mf8x7_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_i8mf8x8_m(vbool64_t vm, int8_t *rs1,
                                      vuint16mf4_t vs2, vint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_i8mf4x2_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_i8mf4x3_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_i8mf4x4_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_i8mf4x5_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_i8mf4x6_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_i8mf4x7_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_i8mf4x8_m(vbool32_t vm, int8_t *rs1,
                                      vuint16mf2_t vs2, vint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_i8mf2x2_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_i8mf2x3_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_i8mf2x4_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_i8mf2x5_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_i8mf2x6_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_i8mf2x7_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_i8mf2x8_m(vbool16_t vm, int8_t *rs1,
                                      vuint16m1_t vs2, vint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_i8m1x2_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i8m1x3_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i8m1x4_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_i8m1x5_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_i8m1x6_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_i8m1x7_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_i8m1x8_m(vbool8_t vm, int8_t *rs1, vuint16m2_t vs2,
                                     vint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i8m2x2_m(vbool4_t vm, int8_t *rs1, vuint16m4_t vs2,
                                     vint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_i8m2x3_m(vbool4_t vm, int8_t *rs1, vuint16m4_t vs2,
                                     vint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_i8m2x4_m(vbool4_t vm, int8_t *rs1, vuint16m4_t vs2,
                                     vint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i8m4x2_m(vbool2_t vm, int8_t *rs1, vuint16m8_t vs2,
                                     vint8m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i8mf8x2_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_i8mf8x3_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_i8mf8x4_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_i8mf8x5_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_i8mf8x6_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_i8mf8x7_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_i8mf8x8_m(vbool64_t vm, int8_t *rs1,
                                      vuint32mf2_t vs2, vint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i8mf4x2_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_i8mf4x3_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_i8mf4x4_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_i8mf4x5_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_i8mf4x6_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_i8mf4x7_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_i8mf4x8_m(vbool32_t vm, int8_t *rs1,
                                      vuint32m1_t vs2, vint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i8mf2x2_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_i8mf2x3_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_i8mf2x4_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_i8mf2x5_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_i8mf2x6_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_i8mf2x7_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_i8mf2x8_m(vbool16_t vm, int8_t *rs1,
                                      vuint32m2_t vs2, vint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i8m1x2_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i8m1x3_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i8m1x4_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_i8m1x5_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_i8m1x6_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_i8m1x7_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_i8m1x8_m(vbool8_t vm, int8_t *rs1, vuint32m4_t vs2,
                                     vint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_i8m2x2_m(vbool4_t vm, int8_t *rs1, vuint32m8_t vs2,
                                     vint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_i8m2x3_m(vbool4_t vm, int8_t *rs1, vuint32m8_t vs2,
                                     vint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_i8m2x4_m(vbool4_t vm, int8_t *rs1, vuint32m8_t vs2,
                                     vint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_i8mf8x2_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_i8mf8x3_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_i8mf8x4_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_i8mf8x5_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_i8mf8x6_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_i8mf8x7_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_i8mf8x8_m(vbool64_t vm, int8_t *rs1,
                                      vuint64m1_t vs2, vint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i8mf4x2_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_i8mf4x3_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_i8mf4x4_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_i8mf4x5_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_i8mf4x6_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_i8mf4x7_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_i8mf4x8_m(vbool32_t vm, int8_t *rs1,
                                      vuint64m2_t vs2, vint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i8mf2x2_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_i8mf2x3_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_i8mf2x4_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_i8mf2x5_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_i8mf2x6_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_i8mf2x7_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_i8mf2x8_m(vbool16_t vm, int8_t *rs1,
                                      vuint64m4_t vs2, vint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i8m1x2_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_i8m1x3_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_i8m1x4_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_i8m1x5_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_i8m1x6_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_i8m1x7_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_i8m1x8_m(vbool8_t vm, int8_t *rs1, vuint64m8_t vs2,
                                     vint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i16mf4x2_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei8_v_i16mf4x3_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei8_v_i16mf4x4_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei8_v_i16mf4x5_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei8_v_i16mf4x6_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei8_v_i16mf4x7_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei8_v_i16mf4x8_m(vbool64_t vm, int16_t *rs1,
                                      vuint8mf8_t vs2, vint16mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_i16mf2x2_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei8_v_i16mf2x3_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei8_v_i16mf2x4_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei8_v_i16mf2x5_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei8_v_i16mf2x6_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei8_v_i16mf2x7_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei8_v_i16mf2x8_m(vbool32_t vm, int16_t *rs1,
                                      vuint8mf4_t vs2, vint16mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_i16m1x2_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_i16m1x3_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_i16m1x4_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg5ei8_v_i16m1x5_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x5_t vs3,
                                     size_t vl);
void __riscv_vsuxseg6ei8_v_i16m1x6_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x6_t vs3,
                                     size_t vl);
void __riscv_vsuxseg7ei8_v_i16m1x7_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x7_t vs3,
                                     size_t vl);
void __riscv_vsuxseg8ei8_v_i16m1x8_m(vbool16_t vm, int16_t *rs1,
                                     vuint8mf2_t vs2, vint16m1x8_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_i16m2x2_m(vbool8_t vm, int16_t *rs1, vuint8m1_t vs2,
                                     vint16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_i16m2x3_m(vbool8_t vm, int16_t *rs1, vuint8m1_t vs2,
                                     vint16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_i16m2x4_m(vbool8_t vm, int16_t *rs1, vuint8m1_t vs2,
                                     vint16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_i16m4x2_m(vbool4_t vm, int16_t *rs1, vuint8m2_t vs2,
                                     vint16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i16mf4x2_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_i16mf4x3_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_i16mf4x4_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_i16mf4x5_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_i16mf4x6_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_i16mf4x7_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_i16mf4x8_m(vbool64_t vm, int16_t *rs1,
                                       vuint16mf4_t vs2, vint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_i16mf2x2_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_i16mf2x3_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_i16mf2x4_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_i16mf2x5_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_i16mf2x6_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_i16mf2x7_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_i16mf2x8_m(vbool32_t vm, int16_t *rs1,
                                       vuint16mf2_t vs2, vint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_i16m1x2_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_i16m1x3_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_i16m1x4_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_i16m1x5_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_i16m1x6_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_i16m1x7_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_i16m1x8_m(vbool16_t vm, int16_t *rs1,
                                      vuint16m1_t vs2, vint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_i16m2x2_m(vbool8_t vm, int16_t *rs1,
                                      vuint16m2_t vs2, vint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_i16m2x3_m(vbool8_t vm, int16_t *rs1,
                                      vuint16m2_t vs2, vint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_i16m2x4_m(vbool8_t vm, int16_t *rs1,
                                      vuint16m2_t vs2, vint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_i16m4x2_m(vbool4_t vm, int16_t *rs1,
                                      vuint16m4_t vs2, vint16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i16mf4x2_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei32_v_i16mf4x3_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei32_v_i16mf4x4_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei32_v_i16mf4x5_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei32_v_i16mf4x6_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei32_v_i16mf4x7_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei32_v_i16mf4x8_m(vbool64_t vm, int16_t *rs1,
                                       vuint32mf2_t vs2, vint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei32_v_i16mf2x2_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei32_v_i16mf2x3_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei32_v_i16mf2x4_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei32_v_i16mf2x5_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei32_v_i16mf2x6_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei32_v_i16mf2x7_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei32_v_i16mf2x8_m(vbool32_t vm, int16_t *rs1,
                                       vuint32m1_t vs2, vint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei32_v_i16m1x2_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_i16m1x3_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_i16m1x4_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_i16m1x5_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_i16m1x6_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_i16m1x7_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_i16m1x8_m(vbool16_t vm, int16_t *rs1,
                                      vuint32m2_t vs2, vint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i16m2x2_m(vbool8_t vm, int16_t *rs1,
                                      vuint32m4_t vs2, vint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_i16m2x3_m(vbool8_t vm, int16_t *rs1,
                                      vuint32m4_t vs2, vint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_i16m2x4_m(vbool8_t vm, int16_t *rs1,
                                      vuint32m4_t vs2, vint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i16m4x2_m(vbool4_t vm, int16_t *rs1,
                                      vuint32m8_t vs2, vint16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i16mf4x2_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei64_v_i16mf4x3_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei64_v_i16mf4x4_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei64_v_i16mf4x5_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei64_v_i16mf4x6_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei64_v_i16mf4x7_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei64_v_i16mf4x8_m(vbool64_t vm, int16_t *rs1,
                                       vuint64m1_t vs2, vint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei64_v_i16mf2x2_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei64_v_i16mf2x3_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei64_v_i16mf2x4_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei64_v_i16mf2x5_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei64_v_i16mf2x6_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei64_v_i16mf2x7_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei64_v_i16mf2x8_m(vbool32_t vm, int16_t *rs1,
                                       vuint64m2_t vs2, vint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei64_v_i16m1x2_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_i16m1x3_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_i16m1x4_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_i16m1x5_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_i16m1x6_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_i16m1x7_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_i16m1x8_m(vbool16_t vm, int16_t *rs1,
                                      vuint64m4_t vs2, vint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i16m2x2_m(vbool8_t vm, int16_t *rs1,
                                      vuint64m8_t vs2, vint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_i16m2x3_m(vbool8_t vm, int16_t *rs1,
                                      vuint64m8_t vs2, vint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_i16m2x4_m(vbool8_t vm, int16_t *rs1,
                                      vuint64m8_t vs2, vint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_i32mf2x2_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei8_v_i32mf2x3_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei8_v_i32mf2x4_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei8_v_i32mf2x5_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei8_v_i32mf2x6_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei8_v_i32mf2x7_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei8_v_i32mf2x8_m(vbool64_t vm, int32_t *rs1,
                                      vuint8mf8_t vs2, vint32mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_i32m1x2_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_i32m1x3_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_i32m1x4_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg5ei8_v_i32m1x5_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x5_t vs3,
                                     size_t vl);
void __riscv_vsuxseg6ei8_v_i32m1x6_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x6_t vs3,
                                     size_t vl);
void __riscv_vsuxseg7ei8_v_i32m1x7_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x7_t vs3,
                                     size_t vl);
void __riscv_vsuxseg8ei8_v_i32m1x8_m(vbool32_t vm, int32_t *rs1,
                                     vuint8mf4_t vs2, vint32m1x8_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_i32m2x2_m(vbool16_t vm, int32_t *rs1,
                                     vuint8mf2_t vs2, vint32m2x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_i32m2x3_m(vbool16_t vm, int32_t *rs1,
                                     vuint8mf2_t vs2, vint32m2x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_i32m2x4_m(vbool16_t vm, int32_t *rs1,
                                     vuint8mf2_t vs2, vint32m2x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_i32m4x2_m(vbool8_t vm, int32_t *rs1, vuint8m1_t vs2,
                                     vint32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_i32mf2x2_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_i32mf2x3_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_i32mf2x4_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_i32mf2x5_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_i32mf2x6_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_i32mf2x7_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_i32mf2x8_m(vbool64_t vm, int32_t *rs1,
                                       vuint16mf4_t vs2, vint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_i32m1x2_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_i32m1x3_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_i32m1x4_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_i32m1x5_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_i32m1x6_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_i32m1x7_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_i32m1x8_m(vbool32_t vm, int32_t *rs1,
                                      vuint16mf2_t vs2, vint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_i32m2x2_m(vbool16_t vm, int32_t *rs1,
                                      vuint16m1_t vs2, vint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_i32m2x3_m(vbool16_t vm, int32_t *rs1,
                                      vuint16m1_t vs2, vint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_i32m2x4_m(vbool16_t vm, int32_t *rs1,
                                      vuint16m1_t vs2, vint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_i32m4x2_m(vbool8_t vm, int32_t *rs1,
                                      vuint16m2_t vs2, vint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i32mf2x2_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei32_v_i32mf2x3_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei32_v_i32mf2x4_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei32_v_i32mf2x5_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei32_v_i32mf2x6_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei32_v_i32mf2x7_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei32_v_i32mf2x8_m(vbool64_t vm, int32_t *rs1,
                                       vuint32mf2_t vs2, vint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei32_v_i32m1x2_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_i32m1x3_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_i32m1x4_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_i32m1x5_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_i32m1x6_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_i32m1x7_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_i32m1x8_m(vbool32_t vm, int32_t *rs1,
                                      vuint32m1_t vs2, vint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i32m2x2_m(vbool16_t vm, int32_t *rs1,
                                      vuint32m2_t vs2, vint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_i32m2x3_m(vbool16_t vm, int32_t *rs1,
                                      vuint32m2_t vs2, vint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_i32m2x4_m(vbool16_t vm, int32_t *rs1,
                                      vuint32m2_t vs2, vint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i32m4x2_m(vbool8_t vm, int32_t *rs1,
                                      vuint32m4_t vs2, vint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i32mf2x2_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei64_v_i32mf2x3_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei64_v_i32mf2x4_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei64_v_i32mf2x5_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei64_v_i32mf2x6_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei64_v_i32mf2x7_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei64_v_i32mf2x8_m(vbool64_t vm, int32_t *rs1,
                                       vuint64m1_t vs2, vint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei64_v_i32m1x2_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_i32m1x3_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_i32m1x4_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_i32m1x5_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_i32m1x6_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_i32m1x7_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_i32m1x8_m(vbool32_t vm, int32_t *rs1,
                                      vuint64m2_t vs2, vint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i32m2x2_m(vbool16_t vm, int32_t *rs1,
                                      vuint64m4_t vs2, vint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_i32m2x3_m(vbool16_t vm, int32_t *rs1,
                                      vuint64m4_t vs2, vint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_i32m2x4_m(vbool16_t vm, int32_t *rs1,
                                      vuint64m4_t vs2, vint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i32m4x2_m(vbool8_t vm, int32_t *rs1,
                                      vuint64m8_t vs2, vint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_i64m1x2_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_i64m1x3_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_i64m1x4_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg5ei8_v_i64m1x5_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x5_t vs3,
                                     size_t vl);
void __riscv_vsuxseg6ei8_v_i64m1x6_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x6_t vs3,
                                     size_t vl);
void __riscv_vsuxseg7ei8_v_i64m1x7_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x7_t vs3,
                                     size_t vl);
void __riscv_vsuxseg8ei8_v_i64m1x8_m(vbool64_t vm, int64_t *rs1,
                                     vuint8mf8_t vs2, vint64m1x8_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_i64m2x2_m(vbool32_t vm, int64_t *rs1,
                                     vuint8mf4_t vs2, vint64m2x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_i64m2x3_m(vbool32_t vm, int64_t *rs1,
                                     vuint8mf4_t vs2, vint64m2x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_i64m2x4_m(vbool32_t vm, int64_t *rs1,
                                     vuint8mf4_t vs2, vint64m2x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_i64m4x2_m(vbool16_t vm, int64_t *rs1,
                                     vuint8mf2_t vs2, vint64m4x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei16_v_i64m1x2_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_i64m1x3_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_i64m1x4_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_i64m1x5_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_i64m1x6_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_i64m1x7_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_i64m1x8_m(vbool64_t vm, int64_t *rs1,
                                      vuint16mf4_t vs2, vint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_i64m2x2_m(vbool32_t vm, int64_t *rs1,
                                      vuint16mf2_t vs2, vint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_i64m2x3_m(vbool32_t vm, int64_t *rs1,
                                      vuint16mf2_t vs2, vint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_i64m2x4_m(vbool32_t vm, int64_t *rs1,
                                      vuint16mf2_t vs2, vint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_i64m4x2_m(vbool16_t vm, int64_t *rs1,
                                      vuint16m1_t vs2, vint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i64m1x2_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_i64m1x3_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_i64m1x4_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_i64m1x5_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_i64m1x6_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_i64m1x7_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_i64m1x8_m(vbool64_t vm, int64_t *rs1,
                                      vuint32mf2_t vs2, vint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i64m2x2_m(vbool32_t vm, int64_t *rs1,
                                      vuint32m1_t vs2, vint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_i64m2x3_m(vbool32_t vm, int64_t *rs1,
                                      vuint32m1_t vs2, vint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_i64m2x4_m(vbool32_t vm, int64_t *rs1,
                                      vuint32m1_t vs2, vint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_i64m4x2_m(vbool16_t vm, int64_t *rs1,
                                      vuint32m2_t vs2, vint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i64m1x2_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_i64m1x3_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_i64m1x4_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_i64m1x5_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_i64m1x6_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_i64m1x7_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_i64m1x8_m(vbool64_t vm, int64_t *rs1,
                                      vuint64m1_t vs2, vint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i64m2x2_m(vbool32_t vm, int64_t *rs1,
                                      vuint64m2_t vs2, vint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_i64m2x3_m(vbool32_t vm, int64_t *rs1,
                                      vuint64m2_t vs2, vint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_i64m2x4_m(vbool32_t vm, int64_t *rs1,
                                      vuint64m2_t vs2, vint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_i64m4x2_m(vbool16_t vm, int64_t *rs1,
                                      vuint64m4_t vs2, vint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_u8mf8x2_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_u8mf8x3_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_u8mf8x4_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg5ei8_v_u8mf8x5_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x5_t vs3,
                                     size_t vl);
void __riscv_vsoxseg6ei8_v_u8mf8x6_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x6_t vs3,
                                     size_t vl);
void __riscv_vsoxseg7ei8_v_u8mf8x7_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x7_t vs3,
                                     size_t vl);
void __riscv_vsoxseg8ei8_v_u8mf8x8_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x8_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_u8mf4x2_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_u8mf4x3_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_u8mf4x4_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg5ei8_v_u8mf4x5_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x5_t vs3,
                                     size_t vl);
void __riscv_vsoxseg6ei8_v_u8mf4x6_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x6_t vs3,
                                     size_t vl);
void __riscv_vsoxseg7ei8_v_u8mf4x7_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x7_t vs3,
                                     size_t vl);
void __riscv_vsoxseg8ei8_v_u8mf4x8_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x8_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_u8mf2x2_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_u8mf2x3_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_u8mf2x4_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg5ei8_v_u8mf2x5_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x5_t vs3,
                                     size_t vl);
void __riscv_vsoxseg6ei8_v_u8mf2x6_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x6_t vs3,
                                     size_t vl);
void __riscv_vsoxseg7ei8_v_u8mf2x7_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x7_t vs3,
                                     size_t vl);
void __riscv_vsoxseg8ei8_v_u8mf2x8_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x8_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_u8m1x2_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u8m1x3_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u8m1x4_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei8_v_u8m1x5_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei8_v_u8m1x6_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei8_v_u8m1x7_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei8_v_u8m1x8_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u8m2x2_m(vbool4_t vm, uint8_t *rs1, vuint8m2_t vs2,
                                    vuint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u8m2x3_m(vbool4_t vm, uint8_t *rs1, vuint8m2_t vs2,
                                    vuint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u8m2x4_m(vbool4_t vm, uint8_t *rs1, vuint8m2_t vs2,
                                    vuint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u8m4x2_m(vbool2_t vm, uint8_t *rs1, vuint8m4_t vs2,
                                    vuint8m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u8mf8x2_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_u8mf8x3_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_u8mf8x4_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_u8mf8x5_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_u8mf8x6_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_u8mf8x7_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_u8mf8x8_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_u8mf4x2_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_u8mf4x3_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_u8mf4x4_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_u8mf4x5_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_u8mf4x6_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_u8mf4x7_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_u8mf4x8_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_u8mf2x2_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_u8mf2x3_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_u8mf2x4_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_u8mf2x5_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_u8mf2x6_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_u8mf2x7_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_u8mf2x8_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_u8m1x2_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u8m1x3_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u8m1x4_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_u8m1x5_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_u8m1x6_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_u8m1x7_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_u8m1x8_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u8m2x2_m(vbool4_t vm, uint8_t *rs1, vuint16m4_t vs2,
                                     vuint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_u8m2x3_m(vbool4_t vm, uint8_t *rs1, vuint16m4_t vs2,
                                     vuint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_u8m2x4_m(vbool4_t vm, uint8_t *rs1, vuint16m4_t vs2,
                                     vuint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u8m4x2_m(vbool2_t vm, uint8_t *rs1, vuint16m8_t vs2,
                                     vuint8m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u8mf8x2_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_u8mf8x3_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_u8mf8x4_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_u8mf8x5_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_u8mf8x6_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_u8mf8x7_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_u8mf8x8_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u8mf4x2_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_u8mf4x3_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_u8mf4x4_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_u8mf4x5_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_u8mf4x6_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_u8mf4x7_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_u8mf4x8_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u8mf2x2_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_u8mf2x3_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_u8mf2x4_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_u8mf2x5_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_u8mf2x6_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_u8mf2x7_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_u8mf2x8_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u8m1x2_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u8m1x3_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u8m1x4_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei32_v_u8m1x5_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei32_v_u8m1x6_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei32_v_u8m1x7_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei32_v_u8m1x8_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei32_v_u8m2x2_m(vbool4_t vm, uint8_t *rs1, vuint32m8_t vs2,
                                     vuint8m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei32_v_u8m2x3_m(vbool4_t vm, uint8_t *rs1, vuint32m8_t vs2,
                                     vuint8m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei32_v_u8m2x4_m(vbool4_t vm, uint8_t *rs1, vuint32m8_t vs2,
                                     vuint8m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei64_v_u8mf8x2_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_u8mf8x3_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_u8mf8x4_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_u8mf8x5_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_u8mf8x6_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_u8mf8x7_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_u8mf8x8_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u8mf4x2_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_u8mf4x3_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_u8mf4x4_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_u8mf4x5_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_u8mf4x6_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_u8mf4x7_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_u8mf4x8_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u8mf2x2_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_u8mf2x3_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_u8mf2x4_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_u8mf2x5_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_u8mf2x6_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_u8mf2x7_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_u8mf2x8_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u8m1x2_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei64_v_u8m1x3_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei64_v_u8m1x4_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei64_v_u8m1x5_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei64_v_u8m1x6_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei64_v_u8m1x7_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei64_v_u8m1x8_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u16mf4x2_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei8_v_u16mf4x3_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei8_v_u16mf4x4_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei8_v_u16mf4x5_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei8_v_u16mf4x6_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei8_v_u16mf4x7_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei8_v_u16mf4x8_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_u16mf2x2_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei8_v_u16mf2x3_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei8_v_u16mf2x4_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei8_v_u16mf2x5_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei8_v_u16mf2x6_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei8_v_u16mf2x7_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei8_v_u16mf2x8_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_u16m1x2_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_u16m1x3_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_u16m1x4_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg5ei8_v_u16m1x5_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x5_t vs3,
                                     size_t vl);
void __riscv_vsoxseg6ei8_v_u16m1x6_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x6_t vs3,
                                     size_t vl);
void __riscv_vsoxseg7ei8_v_u16m1x7_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x7_t vs3,
                                     size_t vl);
void __riscv_vsoxseg8ei8_v_u16m1x8_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x8_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_u16m2x2_m(vbool8_t vm, uint16_t *rs1, vuint8m1_t vs2,
                                     vuint16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei8_v_u16m2x3_m(vbool8_t vm, uint16_t *rs1, vuint8m1_t vs2,
                                     vuint16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei8_v_u16m2x4_m(vbool8_t vm, uint16_t *rs1, vuint8m1_t vs2,
                                     vuint16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei8_v_u16m4x2_m(vbool4_t vm, uint16_t *rs1, vuint8m2_t vs2,
                                     vuint16m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u16mf4x2_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_u16mf4x3_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_u16mf4x4_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_u16mf4x5_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_u16mf4x6_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_u16mf4x7_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_u16mf4x8_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_u16mf2x2_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_u16mf2x3_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_u16mf2x4_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_u16mf2x5_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_u16mf2x6_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_u16mf2x7_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_u16mf2x8_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_u16m1x2_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_u16m1x3_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_u16m1x4_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_u16m1x5_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_u16m1x6_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_u16m1x7_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_u16m1x8_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_u16m2x2_m(vbool8_t vm, uint16_t *rs1,
                                      vuint16m2_t vs2, vuint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_u16m2x3_m(vbool8_t vm, uint16_t *rs1,
                                      vuint16m2_t vs2, vuint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_u16m2x4_m(vbool8_t vm, uint16_t *rs1,
                                      vuint16m2_t vs2, vuint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_u16m4x2_m(vbool4_t vm, uint16_t *rs1,
                                      vuint16m4_t vs2, vuint16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u16mf4x2_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei32_v_u16mf4x3_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei32_v_u16mf4x4_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei32_v_u16mf4x5_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei32_v_u16mf4x6_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei32_v_u16mf4x7_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei32_v_u16mf4x8_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei32_v_u16mf2x2_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei32_v_u16mf2x3_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei32_v_u16mf2x4_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei32_v_u16mf2x5_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei32_v_u16mf2x6_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei32_v_u16mf2x7_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei32_v_u16mf2x8_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei32_v_u16m1x2_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_u16m1x3_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_u16m1x4_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_u16m1x5_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_u16m1x6_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_u16m1x7_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_u16m1x8_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u16m2x2_m(vbool8_t vm, uint16_t *rs1,
                                      vuint32m4_t vs2, vuint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_u16m2x3_m(vbool8_t vm, uint16_t *rs1,
                                      vuint32m4_t vs2, vuint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_u16m2x4_m(vbool8_t vm, uint16_t *rs1,
                                      vuint32m4_t vs2, vuint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u16m4x2_m(vbool4_t vm, uint16_t *rs1,
                                      vuint32m8_t vs2, vuint16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u16mf4x2_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei64_v_u16mf4x3_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei64_v_u16mf4x4_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei64_v_u16mf4x5_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei64_v_u16mf4x6_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei64_v_u16mf4x7_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei64_v_u16mf4x8_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei64_v_u16mf2x2_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei64_v_u16mf2x3_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei64_v_u16mf2x4_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei64_v_u16mf2x5_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei64_v_u16mf2x6_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei64_v_u16mf2x7_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei64_v_u16mf2x8_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei64_v_u16m1x2_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_u16m1x3_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_u16m1x4_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_u16m1x5_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_u16m1x6_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_u16m1x7_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_u16m1x8_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u16m2x2_m(vbool8_t vm, uint16_t *rs1,
                                      vuint64m8_t vs2, vuint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_u16m2x3_m(vbool8_t vm, uint16_t *rs1,
                                      vuint64m8_t vs2, vuint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_u16m2x4_m(vbool8_t vm, uint16_t *rs1,
                                      vuint64m8_t vs2, vuint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_u32mf2x2_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei8_v_u32mf2x3_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei8_v_u32mf2x4_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei8_v_u32mf2x5_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei8_v_u32mf2x6_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei8_v_u32mf2x7_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei8_v_u32mf2x8_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_u32m1x2_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_u32m1x3_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_u32m1x4_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg5ei8_v_u32m1x5_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x5_t vs3,
                                     size_t vl);
void __riscv_vsoxseg6ei8_v_u32m1x6_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x6_t vs3,
                                     size_t vl);
void __riscv_vsoxseg7ei8_v_u32m1x7_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x7_t vs3,
                                     size_t vl);
void __riscv_vsoxseg8ei8_v_u32m1x8_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x8_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_u32m2x2_m(vbool16_t vm, uint32_t *rs1,
                                     vuint8mf2_t vs2, vuint32m2x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_u32m2x3_m(vbool16_t vm, uint32_t *rs1,
                                     vuint8mf2_t vs2, vuint32m2x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_u32m2x4_m(vbool16_t vm, uint32_t *rs1,
                                     vuint8mf2_t vs2, vuint32m2x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_u32m4x2_m(vbool8_t vm, uint32_t *rs1, vuint8m1_t vs2,
                                     vuint32m4x2_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_u32mf2x2_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_u32mf2x3_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_u32mf2x4_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_u32mf2x5_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_u32mf2x6_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_u32mf2x7_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_u32mf2x8_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_u32m1x2_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_u32m1x3_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_u32m1x4_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_u32m1x5_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_u32m1x6_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_u32m1x7_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_u32m1x8_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_u32m2x2_m(vbool16_t vm, uint32_t *rs1,
                                      vuint16m1_t vs2, vuint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_u32m2x3_m(vbool16_t vm, uint32_t *rs1,
                                      vuint16m1_t vs2, vuint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_u32m2x4_m(vbool16_t vm, uint32_t *rs1,
                                      vuint16m1_t vs2, vuint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_u32m4x2_m(vbool8_t vm, uint32_t *rs1,
                                      vuint16m2_t vs2, vuint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u32mf2x2_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei32_v_u32mf2x3_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei32_v_u32mf2x4_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei32_v_u32mf2x5_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei32_v_u32mf2x6_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei32_v_u32mf2x7_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei32_v_u32mf2x8_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei32_v_u32m1x2_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_u32m1x3_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_u32m1x4_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_u32m1x5_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_u32m1x6_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_u32m1x7_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_u32m1x8_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u32m2x2_m(vbool16_t vm, uint32_t *rs1,
                                      vuint32m2_t vs2, vuint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_u32m2x3_m(vbool16_t vm, uint32_t *rs1,
                                      vuint32m2_t vs2, vuint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_u32m2x4_m(vbool16_t vm, uint32_t *rs1,
                                      vuint32m2_t vs2, vuint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u32m4x2_m(vbool8_t vm, uint32_t *rs1,
                                      vuint32m4_t vs2, vuint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u32mf2x2_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei64_v_u32mf2x3_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei64_v_u32mf2x4_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei64_v_u32mf2x5_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei64_v_u32mf2x6_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei64_v_u32mf2x7_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei64_v_u32mf2x8_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei64_v_u32m1x2_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_u32m1x3_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_u32m1x4_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_u32m1x5_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_u32m1x6_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_u32m1x7_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_u32m1x8_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u32m2x2_m(vbool16_t vm, uint32_t *rs1,
                                      vuint64m4_t vs2, vuint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_u32m2x3_m(vbool16_t vm, uint32_t *rs1,
                                      vuint64m4_t vs2, vuint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_u32m2x4_m(vbool16_t vm, uint32_t *rs1,
                                      vuint64m4_t vs2, vuint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u32m4x2_m(vbool8_t vm, uint32_t *rs1,
                                      vuint64m8_t vs2, vuint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei8_v_u64m1x2_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_u64m1x3_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_u64m1x4_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg5ei8_v_u64m1x5_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x5_t vs3,
                                     size_t vl);
void __riscv_vsoxseg6ei8_v_u64m1x6_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x6_t vs3,
                                     size_t vl);
void __riscv_vsoxseg7ei8_v_u64m1x7_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x7_t vs3,
                                     size_t vl);
void __riscv_vsoxseg8ei8_v_u64m1x8_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x8_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_u64m2x2_m(vbool32_t vm, uint64_t *rs1,
                                     vuint8mf4_t vs2, vuint64m2x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg3ei8_v_u64m2x3_m(vbool32_t vm, uint64_t *rs1,
                                     vuint8mf4_t vs2, vuint64m2x3_t vs3,
                                     size_t vl);
void __riscv_vsoxseg4ei8_v_u64m2x4_m(vbool32_t vm, uint64_t *rs1,
                                     vuint8mf4_t vs2, vuint64m2x4_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei8_v_u64m4x2_m(vbool16_t vm, uint64_t *rs1,
                                     vuint8mf2_t vs2, vuint64m4x2_t vs3,
                                     size_t vl);
void __riscv_vsoxseg2ei16_v_u64m1x2_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_u64m1x3_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_u64m1x4_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_u64m1x5_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_u64m1x6_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_u64m1x7_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_u64m1x8_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_u64m2x2_m(vbool32_t vm, uint64_t *rs1,
                                      vuint16mf2_t vs2, vuint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_u64m2x3_m(vbool32_t vm, uint64_t *rs1,
                                      vuint16mf2_t vs2, vuint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_u64m2x4_m(vbool32_t vm, uint64_t *rs1,
                                      vuint16mf2_t vs2, vuint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_u64m4x2_m(vbool16_t vm, uint64_t *rs1,
                                      vuint16m1_t vs2, vuint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u64m1x2_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_u64m1x3_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_u64m1x4_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei32_v_u64m1x5_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei32_v_u64m1x6_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei32_v_u64m1x7_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei32_v_u64m1x8_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u64m2x2_m(vbool32_t vm, uint64_t *rs1,
                                      vuint32m1_t vs2, vuint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei32_v_u64m2x3_m(vbool32_t vm, uint64_t *rs1,
                                      vuint32m1_t vs2, vuint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei32_v_u64m2x4_m(vbool32_t vm, uint64_t *rs1,
                                      vuint32m1_t vs2, vuint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei32_v_u64m4x2_m(vbool16_t vm, uint64_t *rs1,
                                      vuint32m2_t vs2, vuint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u64m1x2_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_u64m1x3_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_u64m1x4_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei64_v_u64m1x5_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei64_v_u64m1x6_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei64_v_u64m1x7_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei64_v_u64m1x8_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u64m2x2_m(vbool32_t vm, uint64_t *rs1,
                                      vuint64m2_t vs2, vuint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei64_v_u64m2x3_m(vbool32_t vm, uint64_t *rs1,
                                      vuint64m2_t vs2, vuint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei64_v_u64m2x4_m(vbool32_t vm, uint64_t *rs1,
                                      vuint64m2_t vs2, vuint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei64_v_u64m4x2_m(vbool16_t vm, uint64_t *rs1,
                                      vuint64m4_t vs2, vuint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_u8mf8x2_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_u8mf8x3_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_u8mf8x4_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg5ei8_v_u8mf8x5_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x5_t vs3,
                                     size_t vl);
void __riscv_vsuxseg6ei8_v_u8mf8x6_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x6_t vs3,
                                     size_t vl);
void __riscv_vsuxseg7ei8_v_u8mf8x7_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x7_t vs3,
                                     size_t vl);
void __riscv_vsuxseg8ei8_v_u8mf8x8_m(vbool64_t vm, uint8_t *rs1,
                                     vuint8mf8_t vs2, vuint8mf8x8_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_u8mf4x2_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_u8mf4x3_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_u8mf4x4_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg5ei8_v_u8mf4x5_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x5_t vs3,
                                     size_t vl);
void __riscv_vsuxseg6ei8_v_u8mf4x6_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x6_t vs3,
                                     size_t vl);
void __riscv_vsuxseg7ei8_v_u8mf4x7_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x7_t vs3,
                                     size_t vl);
void __riscv_vsuxseg8ei8_v_u8mf4x8_m(vbool32_t vm, uint8_t *rs1,
                                     vuint8mf4_t vs2, vuint8mf4x8_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_u8mf2x2_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_u8mf2x3_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_u8mf2x4_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg5ei8_v_u8mf2x5_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x5_t vs3,
                                     size_t vl);
void __riscv_vsuxseg6ei8_v_u8mf2x6_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x6_t vs3,
                                     size_t vl);
void __riscv_vsuxseg7ei8_v_u8mf2x7_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x7_t vs3,
                                     size_t vl);
void __riscv_vsuxseg8ei8_v_u8mf2x8_m(vbool16_t vm, uint8_t *rs1,
                                     vuint8mf2_t vs2, vuint8mf2x8_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_u8m1x2_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u8m1x3_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u8m1x4_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei8_v_u8m1x5_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei8_v_u8m1x6_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei8_v_u8m1x7_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei8_v_u8m1x8_m(vbool8_t vm, uint8_t *rs1, vuint8m1_t vs2,
                                    vuint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u8m2x2_m(vbool4_t vm, uint8_t *rs1, vuint8m2_t vs2,
                                    vuint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u8m2x3_m(vbool4_t vm, uint8_t *rs1, vuint8m2_t vs2,
                                    vuint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u8m2x4_m(vbool4_t vm, uint8_t *rs1, vuint8m2_t vs2,
                                    vuint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u8m4x2_m(vbool2_t vm, uint8_t *rs1, vuint8m4_t vs2,
                                    vuint8m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u8mf8x2_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_u8mf8x3_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_u8mf8x4_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_u8mf8x5_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_u8mf8x6_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_u8mf8x7_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_u8mf8x8_m(vbool64_t vm, uint8_t *rs1,
                                      vuint16mf4_t vs2, vuint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_u8mf4x2_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_u8mf4x3_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_u8mf4x4_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_u8mf4x5_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_u8mf4x6_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_u8mf4x7_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_u8mf4x8_m(vbool32_t vm, uint8_t *rs1,
                                      vuint16mf2_t vs2, vuint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_u8mf2x2_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_u8mf2x3_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_u8mf2x4_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_u8mf2x5_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_u8mf2x6_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_u8mf2x7_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_u8mf2x8_m(vbool16_t vm, uint8_t *rs1,
                                      vuint16m1_t vs2, vuint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_u8m1x2_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u8m1x3_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u8m1x4_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_u8m1x5_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_u8m1x6_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_u8m1x7_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_u8m1x8_m(vbool8_t vm, uint8_t *rs1, vuint16m2_t vs2,
                                     vuint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u8m2x2_m(vbool4_t vm, uint8_t *rs1, vuint16m4_t vs2,
                                     vuint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_u8m2x3_m(vbool4_t vm, uint8_t *rs1, vuint16m4_t vs2,
                                     vuint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_u8m2x4_m(vbool4_t vm, uint8_t *rs1, vuint16m4_t vs2,
                                     vuint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u8m4x2_m(vbool2_t vm, uint8_t *rs1, vuint16m8_t vs2,
                                     vuint8m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u8mf8x2_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_u8mf8x3_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_u8mf8x4_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_u8mf8x5_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_u8mf8x6_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_u8mf8x7_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_u8mf8x8_m(vbool64_t vm, uint8_t *rs1,
                                      vuint32mf2_t vs2, vuint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u8mf4x2_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_u8mf4x3_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_u8mf4x4_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_u8mf4x5_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_u8mf4x6_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_u8mf4x7_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_u8mf4x8_m(vbool32_t vm, uint8_t *rs1,
                                      vuint32m1_t vs2, vuint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u8mf2x2_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_u8mf2x3_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_u8mf2x4_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_u8mf2x5_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_u8mf2x6_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_u8mf2x7_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_u8mf2x8_m(vbool16_t vm, uint8_t *rs1,
                                      vuint32m2_t vs2, vuint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u8m1x2_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u8m1x3_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u8m1x4_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei32_v_u8m1x5_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei32_v_u8m1x6_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei32_v_u8m1x7_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei32_v_u8m1x8_m(vbool8_t vm, uint8_t *rs1, vuint32m4_t vs2,
                                     vuint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei32_v_u8m2x2_m(vbool4_t vm, uint8_t *rs1, vuint32m8_t vs2,
                                     vuint8m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei32_v_u8m2x3_m(vbool4_t vm, uint8_t *rs1, vuint32m8_t vs2,
                                     vuint8m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei32_v_u8m2x4_m(vbool4_t vm, uint8_t *rs1, vuint32m8_t vs2,
                                     vuint8m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei64_v_u8mf8x2_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_u8mf8x3_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_u8mf8x4_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_u8mf8x5_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_u8mf8x6_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_u8mf8x7_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_u8mf8x8_m(vbool64_t vm, uint8_t *rs1,
                                      vuint64m1_t vs2, vuint8mf8x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u8mf4x2_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_u8mf4x3_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_u8mf4x4_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_u8mf4x5_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_u8mf4x6_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_u8mf4x7_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_u8mf4x8_m(vbool32_t vm, uint8_t *rs1,
                                      vuint64m2_t vs2, vuint8mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u8mf2x2_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_u8mf2x3_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_u8mf2x4_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_u8mf2x5_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_u8mf2x6_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_u8mf2x7_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_u8mf2x8_m(vbool16_t vm, uint8_t *rs1,
                                      vuint64m4_t vs2, vuint8mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u8m1x2_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei64_v_u8m1x3_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei64_v_u8m1x4_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei64_v_u8m1x5_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei64_v_u8m1x6_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei64_v_u8m1x7_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei64_v_u8m1x8_m(vbool8_t vm, uint8_t *rs1, vuint64m8_t vs2,
                                     vuint8m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u16mf4x2_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei8_v_u16mf4x3_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei8_v_u16mf4x4_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei8_v_u16mf4x5_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei8_v_u16mf4x6_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei8_v_u16mf4x7_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei8_v_u16mf4x8_m(vbool64_t vm, uint16_t *rs1,
                                      vuint8mf8_t vs2, vuint16mf4x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_u16mf2x2_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei8_v_u16mf2x3_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei8_v_u16mf2x4_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei8_v_u16mf2x5_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei8_v_u16mf2x6_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei8_v_u16mf2x7_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei8_v_u16mf2x8_m(vbool32_t vm, uint16_t *rs1,
                                      vuint8mf4_t vs2, vuint16mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_u16m1x2_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_u16m1x3_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_u16m1x4_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg5ei8_v_u16m1x5_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x5_t vs3,
                                     size_t vl);
void __riscv_vsuxseg6ei8_v_u16m1x6_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x6_t vs3,
                                     size_t vl);
void __riscv_vsuxseg7ei8_v_u16m1x7_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x7_t vs3,
                                     size_t vl);
void __riscv_vsuxseg8ei8_v_u16m1x8_m(vbool16_t vm, uint16_t *rs1,
                                     vuint8mf2_t vs2, vuint16m1x8_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_u16m2x2_m(vbool8_t vm, uint16_t *rs1, vuint8m1_t vs2,
                                     vuint16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei8_v_u16m2x3_m(vbool8_t vm, uint16_t *rs1, vuint8m1_t vs2,
                                     vuint16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei8_v_u16m2x4_m(vbool8_t vm, uint16_t *rs1, vuint8m1_t vs2,
                                     vuint16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei8_v_u16m4x2_m(vbool4_t vm, uint16_t *rs1, vuint8m2_t vs2,
                                     vuint16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u16mf4x2_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_u16mf4x3_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_u16mf4x4_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_u16mf4x5_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_u16mf4x6_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_u16mf4x7_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_u16mf4x8_m(vbool64_t vm, uint16_t *rs1,
                                       vuint16mf4_t vs2, vuint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_u16mf2x2_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_u16mf2x3_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_u16mf2x4_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_u16mf2x5_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_u16mf2x6_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_u16mf2x7_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_u16mf2x8_m(vbool32_t vm, uint16_t *rs1,
                                       vuint16mf2_t vs2, vuint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_u16m1x2_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_u16m1x3_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_u16m1x4_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_u16m1x5_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_u16m1x6_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_u16m1x7_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_u16m1x8_m(vbool16_t vm, uint16_t *rs1,
                                      vuint16m1_t vs2, vuint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_u16m2x2_m(vbool8_t vm, uint16_t *rs1,
                                      vuint16m2_t vs2, vuint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_u16m2x3_m(vbool8_t vm, uint16_t *rs1,
                                      vuint16m2_t vs2, vuint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_u16m2x4_m(vbool8_t vm, uint16_t *rs1,
                                      vuint16m2_t vs2, vuint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_u16m4x2_m(vbool4_t vm, uint16_t *rs1,
                                      vuint16m4_t vs2, vuint16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u16mf4x2_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei32_v_u16mf4x3_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei32_v_u16mf4x4_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei32_v_u16mf4x5_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei32_v_u16mf4x6_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei32_v_u16mf4x7_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei32_v_u16mf4x8_m(vbool64_t vm, uint16_t *rs1,
                                       vuint32mf2_t vs2, vuint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei32_v_u16mf2x2_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei32_v_u16mf2x3_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei32_v_u16mf2x4_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei32_v_u16mf2x5_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei32_v_u16mf2x6_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei32_v_u16mf2x7_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei32_v_u16mf2x8_m(vbool32_t vm, uint16_t *rs1,
                                       vuint32m1_t vs2, vuint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei32_v_u16m1x2_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_u16m1x3_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_u16m1x4_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_u16m1x5_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_u16m1x6_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_u16m1x7_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_u16m1x8_m(vbool16_t vm, uint16_t *rs1,
                                      vuint32m2_t vs2, vuint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u16m2x2_m(vbool8_t vm, uint16_t *rs1,
                                      vuint32m4_t vs2, vuint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_u16m2x3_m(vbool8_t vm, uint16_t *rs1,
                                      vuint32m4_t vs2, vuint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_u16m2x4_m(vbool8_t vm, uint16_t *rs1,
                                      vuint32m4_t vs2, vuint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u16m4x2_m(vbool4_t vm, uint16_t *rs1,
                                      vuint32m8_t vs2, vuint16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u16mf4x2_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei64_v_u16mf4x3_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei64_v_u16mf4x4_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei64_v_u16mf4x5_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei64_v_u16mf4x6_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei64_v_u16mf4x7_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei64_v_u16mf4x8_m(vbool64_t vm, uint16_t *rs1,
                                       vuint64m1_t vs2, vuint16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei64_v_u16mf2x2_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei64_v_u16mf2x3_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei64_v_u16mf2x4_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei64_v_u16mf2x5_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei64_v_u16mf2x6_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei64_v_u16mf2x7_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei64_v_u16mf2x8_m(vbool32_t vm, uint16_t *rs1,
                                       vuint64m2_t vs2, vuint16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei64_v_u16m1x2_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_u16m1x3_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_u16m1x4_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_u16m1x5_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_u16m1x6_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_u16m1x7_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_u16m1x8_m(vbool16_t vm, uint16_t *rs1,
                                      vuint64m4_t vs2, vuint16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u16m2x2_m(vbool8_t vm, uint16_t *rs1,
                                      vuint64m8_t vs2, vuint16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_u16m2x3_m(vbool8_t vm, uint16_t *rs1,
                                      vuint64m8_t vs2, vuint16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_u16m2x4_m(vbool8_t vm, uint16_t *rs1,
                                      vuint64m8_t vs2, vuint16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_u32mf2x2_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei8_v_u32mf2x3_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei8_v_u32mf2x4_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei8_v_u32mf2x5_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei8_v_u32mf2x6_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei8_v_u32mf2x7_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei8_v_u32mf2x8_m(vbool64_t vm, uint32_t *rs1,
                                      vuint8mf8_t vs2, vuint32mf2x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_u32m1x2_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_u32m1x3_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_u32m1x4_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg5ei8_v_u32m1x5_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x5_t vs3,
                                     size_t vl);
void __riscv_vsuxseg6ei8_v_u32m1x6_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x6_t vs3,
                                     size_t vl);
void __riscv_vsuxseg7ei8_v_u32m1x7_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x7_t vs3,
                                     size_t vl);
void __riscv_vsuxseg8ei8_v_u32m1x8_m(vbool32_t vm, uint32_t *rs1,
                                     vuint8mf4_t vs2, vuint32m1x8_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_u32m2x2_m(vbool16_t vm, uint32_t *rs1,
                                     vuint8mf2_t vs2, vuint32m2x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_u32m2x3_m(vbool16_t vm, uint32_t *rs1,
                                     vuint8mf2_t vs2, vuint32m2x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_u32m2x4_m(vbool16_t vm, uint32_t *rs1,
                                     vuint8mf2_t vs2, vuint32m2x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_u32m4x2_m(vbool8_t vm, uint32_t *rs1, vuint8m1_t vs2,
                                     vuint32m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_u32mf2x2_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_u32mf2x3_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_u32mf2x4_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_u32mf2x5_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_u32mf2x6_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_u32mf2x7_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_u32mf2x8_m(vbool64_t vm, uint32_t *rs1,
                                       vuint16mf4_t vs2, vuint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_u32m1x2_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_u32m1x3_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_u32m1x4_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_u32m1x5_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_u32m1x6_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_u32m1x7_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_u32m1x8_m(vbool32_t vm, uint32_t *rs1,
                                      vuint16mf2_t vs2, vuint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_u32m2x2_m(vbool16_t vm, uint32_t *rs1,
                                      vuint16m1_t vs2, vuint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_u32m2x3_m(vbool16_t vm, uint32_t *rs1,
                                      vuint16m1_t vs2, vuint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_u32m2x4_m(vbool16_t vm, uint32_t *rs1,
                                      vuint16m1_t vs2, vuint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_u32m4x2_m(vbool8_t vm, uint32_t *rs1,
                                      vuint16m2_t vs2, vuint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u32mf2x2_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei32_v_u32mf2x3_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei32_v_u32mf2x4_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei32_v_u32mf2x5_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei32_v_u32mf2x6_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei32_v_u32mf2x7_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei32_v_u32mf2x8_m(vbool64_t vm, uint32_t *rs1,
                                       vuint32mf2_t vs2, vuint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei32_v_u32m1x2_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_u32m1x3_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_u32m1x4_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_u32m1x5_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_u32m1x6_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_u32m1x7_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_u32m1x8_m(vbool32_t vm, uint32_t *rs1,
                                      vuint32m1_t vs2, vuint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u32m2x2_m(vbool16_t vm, uint32_t *rs1,
                                      vuint32m2_t vs2, vuint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_u32m2x3_m(vbool16_t vm, uint32_t *rs1,
                                      vuint32m2_t vs2, vuint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_u32m2x4_m(vbool16_t vm, uint32_t *rs1,
                                      vuint32m2_t vs2, vuint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u32m4x2_m(vbool8_t vm, uint32_t *rs1,
                                      vuint32m4_t vs2, vuint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u32mf2x2_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei64_v_u32mf2x3_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei64_v_u32mf2x4_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei64_v_u32mf2x5_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei64_v_u32mf2x6_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei64_v_u32mf2x7_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei64_v_u32mf2x8_m(vbool64_t vm, uint32_t *rs1,
                                       vuint64m1_t vs2, vuint32mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei64_v_u32m1x2_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_u32m1x3_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_u32m1x4_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_u32m1x5_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_u32m1x6_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_u32m1x7_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_u32m1x8_m(vbool32_t vm, uint32_t *rs1,
                                      vuint64m2_t vs2, vuint32m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u32m2x2_m(vbool16_t vm, uint32_t *rs1,
                                      vuint64m4_t vs2, vuint32m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_u32m2x3_m(vbool16_t vm, uint32_t *rs1,
                                      vuint64m4_t vs2, vuint32m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_u32m2x4_m(vbool16_t vm, uint32_t *rs1,
                                      vuint64m4_t vs2, vuint32m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u32m4x2_m(vbool8_t vm, uint32_t *rs1,
                                      vuint64m8_t vs2, vuint32m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei8_v_u64m1x2_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_u64m1x3_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_u64m1x4_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg5ei8_v_u64m1x5_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x5_t vs3,
                                     size_t vl);
void __riscv_vsuxseg6ei8_v_u64m1x6_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x6_t vs3,
                                     size_t vl);
void __riscv_vsuxseg7ei8_v_u64m1x7_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x7_t vs3,
                                     size_t vl);
void __riscv_vsuxseg8ei8_v_u64m1x8_m(vbool64_t vm, uint64_t *rs1,
                                     vuint8mf8_t vs2, vuint64m1x8_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_u64m2x2_m(vbool32_t vm, uint64_t *rs1,
                                     vuint8mf4_t vs2, vuint64m2x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg3ei8_v_u64m2x3_m(vbool32_t vm, uint64_t *rs1,
                                     vuint8mf4_t vs2, vuint64m2x3_t vs3,
                                     size_t vl);
void __riscv_vsuxseg4ei8_v_u64m2x4_m(vbool32_t vm, uint64_t *rs1,
                                     vuint8mf4_t vs2, vuint64m2x4_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei8_v_u64m4x2_m(vbool16_t vm, uint64_t *rs1,
                                     vuint8mf2_t vs2, vuint64m4x2_t vs3,
                                     size_t vl);
void __riscv_vsuxseg2ei16_v_u64m1x2_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_u64m1x3_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_u64m1x4_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_u64m1x5_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_u64m1x6_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_u64m1x7_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_u64m1x8_m(vbool64_t vm, uint64_t *rs1,
                                      vuint16mf4_t vs2, vuint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_u64m2x2_m(vbool32_t vm, uint64_t *rs1,
                                      vuint16mf2_t vs2, vuint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_u64m2x3_m(vbool32_t vm, uint64_t *rs1,
                                      vuint16mf2_t vs2, vuint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_u64m2x4_m(vbool32_t vm, uint64_t *rs1,
                                      vuint16mf2_t vs2, vuint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_u64m4x2_m(vbool16_t vm, uint64_t *rs1,
                                      vuint16m1_t vs2, vuint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u64m1x2_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_u64m1x3_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_u64m1x4_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei32_v_u64m1x5_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei32_v_u64m1x6_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei32_v_u64m1x7_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei32_v_u64m1x8_m(vbool64_t vm, uint64_t *rs1,
                                      vuint32mf2_t vs2, vuint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u64m2x2_m(vbool32_t vm, uint64_t *rs1,
                                      vuint32m1_t vs2, vuint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei32_v_u64m2x3_m(vbool32_t vm, uint64_t *rs1,
                                      vuint32m1_t vs2, vuint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei32_v_u64m2x4_m(vbool32_t vm, uint64_t *rs1,
                                      vuint32m1_t vs2, vuint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei32_v_u64m4x2_m(vbool16_t vm, uint64_t *rs1,
                                      vuint32m2_t vs2, vuint64m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u64m1x2_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_u64m1x3_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_u64m1x4_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei64_v_u64m1x5_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei64_v_u64m1x6_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei64_v_u64m1x7_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei64_v_u64m1x8_m(vbool64_t vm, uint64_t *rs1,
                                      vuint64m1_t vs2, vuint64m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u64m2x2_m(vbool32_t vm, uint64_t *rs1,
                                      vuint64m2_t vs2, vuint64m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei64_v_u64m2x3_m(vbool32_t vm, uint64_t *rs1,
                                      vuint64m2_t vs2, vuint64m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei64_v_u64m2x4_m(vbool32_t vm, uint64_t *rs1,
                                      vuint64m2_t vs2, vuint64m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei64_v_u64m4x2_m(vbool16_t vm, uint64_t *rs1,
                                      vuint64m4_t vs2, vuint64m4x2_t vs3,
                                      size_t vl);
----

=== Vector Integer Arithmetic Intrinsics

[[vector-single-width-integer-add-and-subtract]]
==== Vector Single-Width Integer Add and Subtract Intrinsics

[,c]
----
vint8mf8_t __riscv_vadd_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vadd_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vadd_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vadd_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vadd_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vadd_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vadd_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vadd_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vadd_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vadd_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vadd_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vadd_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vadd_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vadd_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vadd_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vadd_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vadd_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vadd_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vadd_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vadd_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vadd_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vadd_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vadd_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vadd_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vadd_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vadd_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vadd_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vadd_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vadd_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vadd_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vadd_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vadd_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vadd_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vadd_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vadd_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vadd_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vadd_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vadd_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vadd_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vadd_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vadd_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vadd_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vadd_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vadd_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vsub_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vsub_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vsub_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vsub_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vsub_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vsub_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vsub_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vsub_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vsub_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vsub_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vsub_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vsub_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vsub_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vsub_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vsub_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vsub_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vsub_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vsub_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vsub_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vsub_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vsub_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vsub_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vsub_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vsub_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vsub_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vsub_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vsub_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vsub_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vsub_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vsub_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vsub_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vsub_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vsub_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vsub_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vsub_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vsub_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vsub_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vsub_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vsub_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vsub_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vsub_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vsub_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vsub_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vsub_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vrsub_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vrsub_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vrsub_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vrsub_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vrsub_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vrsub_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vrsub_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vrsub_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vrsub_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vrsub_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vrsub_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vrsub_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vrsub_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vrsub_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vrsub_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vrsub_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vrsub_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vrsub_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vrsub_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vrsub_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vrsub_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vrsub_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vneg_v_i8mf8(vint8mf8_t vs, size_t vl);
vint8mf4_t __riscv_vneg_v_i8mf4(vint8mf4_t vs, size_t vl);
vint8mf2_t __riscv_vneg_v_i8mf2(vint8mf2_t vs, size_t vl);
vint8m1_t __riscv_vneg_v_i8m1(vint8m1_t vs, size_t vl);
vint8m2_t __riscv_vneg_v_i8m2(vint8m2_t vs, size_t vl);
vint8m4_t __riscv_vneg_v_i8m4(vint8m4_t vs, size_t vl);
vint8m8_t __riscv_vneg_v_i8m8(vint8m8_t vs, size_t vl);
vint16mf4_t __riscv_vneg_v_i16mf4(vint16mf4_t vs, size_t vl);
vint16mf2_t __riscv_vneg_v_i16mf2(vint16mf2_t vs, size_t vl);
vint16m1_t __riscv_vneg_v_i16m1(vint16m1_t vs, size_t vl);
vint16m2_t __riscv_vneg_v_i16m2(vint16m2_t vs, size_t vl);
vint16m4_t __riscv_vneg_v_i16m4(vint16m4_t vs, size_t vl);
vint16m8_t __riscv_vneg_v_i16m8(vint16m8_t vs, size_t vl);
vint32mf2_t __riscv_vneg_v_i32mf2(vint32mf2_t vs, size_t vl);
vint32m1_t __riscv_vneg_v_i32m1(vint32m1_t vs, size_t vl);
vint32m2_t __riscv_vneg_v_i32m2(vint32m2_t vs, size_t vl);
vint32m4_t __riscv_vneg_v_i32m4(vint32m4_t vs, size_t vl);
vint32m8_t __riscv_vneg_v_i32m8(vint32m8_t vs, size_t vl);
vint64m1_t __riscv_vneg_v_i64m1(vint64m1_t vs, size_t vl);
vint64m2_t __riscv_vneg_v_i64m2(vint64m2_t vs, size_t vl);
vint64m4_t __riscv_vneg_v_i64m4(vint64m4_t vs, size_t vl);
vint64m8_t __riscv_vneg_v_i64m8(vint64m8_t vs, size_t vl);
vuint8mf8_t __riscv_vadd_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vadd_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vadd_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vadd_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vadd_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vadd_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vadd_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vadd_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vadd_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vadd_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vadd_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vadd_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vadd_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vadd_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vadd_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                    size_t vl);
vuint16mf4_t __riscv_vadd_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vadd_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint16mf2_t __riscv_vadd_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vadd_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vadd_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vadd_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vadd_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vadd_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vadd_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vadd_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vadd_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vadd_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint32mf2_t __riscv_vadd_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vadd_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vadd_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vadd_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vadd_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vadd_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vadd_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vadd_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vadd_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vadd_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vadd_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vadd_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vadd_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vadd_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vadd_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vadd_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vadd_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vsub_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vsub_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vsub_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vsub_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vsub_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vsub_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vsub_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vsub_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vsub_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vsub_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vsub_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vsub_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vsub_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vsub_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vsub_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                    size_t vl);
vuint16mf4_t __riscv_vsub_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vsub_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint16mf2_t __riscv_vsub_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vsub_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vsub_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vsub_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vsub_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vsub_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vsub_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vsub_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vsub_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vsub_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint32mf2_t __riscv_vsub_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vsub_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vsub_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vsub_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vsub_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vsub_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vsub_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vsub_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vsub_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vsub_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vsub_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vsub_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vsub_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vsub_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vsub_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vsub_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vsub_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vrsub_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vrsub_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vrsub_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vrsub_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vrsub_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vrsub_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vrsub_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vrsub_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vrsub_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vrsub_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vrsub_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vrsub_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vrsub_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vrsub_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vrsub_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vrsub_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vrsub_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vrsub_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vrsub_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vrsub_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vrsub_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vrsub_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vadd_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                                   size_t vl);
vint8mf8_t __riscv_vadd_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vadd_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                                   size_t vl);
vint8mf4_t __riscv_vadd_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vadd_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                                   size_t vl);
vint8mf2_t __riscv_vadd_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vadd_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vadd_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vadd_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vadd_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vadd_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vadd_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vadd_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vadd_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vadd_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vadd_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vadd_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vadd_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vadd_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                                   size_t vl);
vint16m1_t __riscv_vadd_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vadd_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vadd_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vadd_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vadd_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vadd_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vadd_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vadd_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vadd_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vadd_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                                   size_t vl);
vint32m1_t __riscv_vadd_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vadd_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                                   size_t vl);
vint32m2_t __riscv_vadd_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vadd_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vadd_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vadd_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vadd_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vadd_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                                   size_t vl);
vint64m1_t __riscv_vadd_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vadd_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                                   size_t vl);
vint64m2_t __riscv_vadd_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vadd_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                                   size_t vl);
vint64m4_t __riscv_vadd_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vadd_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vadd_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                   size_t vl);
vint8mf8_t __riscv_vsub_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                                   size_t vl);
vint8mf8_t __riscv_vsub_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vsub_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                                   size_t vl);
vint8mf4_t __riscv_vsub_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vsub_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                                   size_t vl);
vint8mf2_t __riscv_vsub_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vsub_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vsub_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vsub_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vsub_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vsub_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vsub_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vsub_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vsub_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vsub_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vsub_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vsub_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vsub_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vsub_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                                   size_t vl);
vint16m1_t __riscv_vsub_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vsub_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vsub_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vsub_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vsub_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vsub_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vsub_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vsub_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vsub_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vsub_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                                   size_t vl);
vint32m1_t __riscv_vsub_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vsub_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                                   size_t vl);
vint32m2_t __riscv_vsub_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vsub_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vsub_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vsub_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vsub_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vsub_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                                   size_t vl);
vint64m1_t __riscv_vsub_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vsub_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                                   size_t vl);
vint64m2_t __riscv_vsub_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vsub_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                                   size_t vl);
vint64m4_t __riscv_vsub_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vsub_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vsub_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                   size_t vl);
vint8mf8_t __riscv_vrsub_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                    size_t vl);
vint8mf4_t __riscv_vrsub_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                    size_t vl);
vint8mf2_t __riscv_vrsub_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                    size_t vl);
vint8m1_t __riscv_vrsub_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                  size_t vl);
vint8m2_t __riscv_vrsub_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                  size_t vl);
vint8m4_t __riscv_vrsub_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                  size_t vl);
vint8m8_t __riscv_vrsub_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                  size_t vl);
vint16mf4_t __riscv_vrsub_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      int16_t rs1, size_t vl);
vint16mf2_t __riscv_vrsub_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      int16_t rs1, size_t vl);
vint16m1_t __riscv_vrsub_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                    size_t vl);
vint16m2_t __riscv_vrsub_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                    size_t vl);
vint16m4_t __riscv_vrsub_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                    size_t vl);
vint16m8_t __riscv_vrsub_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                    size_t vl);
vint32mf2_t __riscv_vrsub_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      int32_t rs1, size_t vl);
vint32m1_t __riscv_vrsub_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                    size_t vl);
vint32m2_t __riscv_vrsub_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                    size_t vl);
vint32m4_t __riscv_vrsub_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                    size_t vl);
vint32m8_t __riscv_vrsub_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                    size_t vl);
vint64m1_t __riscv_vrsub_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                    size_t vl);
vint64m2_t __riscv_vrsub_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                    size_t vl);
vint64m4_t __riscv_vrsub_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                    size_t vl);
vint64m8_t __riscv_vrsub_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                    size_t vl);
vint8mf8_t __riscv_vneg_v_i8mf8_m(vbool64_t vm, vint8mf8_t vs, size_t vl);
vint8mf4_t __riscv_vneg_v_i8mf4_m(vbool32_t vm, vint8mf4_t vs, size_t vl);
vint8mf2_t __riscv_vneg_v_i8mf2_m(vbool16_t vm, vint8mf2_t vs, size_t vl);
vint8m1_t __riscv_vneg_v_i8m1_m(vbool8_t vm, vint8m1_t vs, size_t vl);
vint8m2_t __riscv_vneg_v_i8m2_m(vbool4_t vm, vint8m2_t vs, size_t vl);
vint8m4_t __riscv_vneg_v_i8m4_m(vbool2_t vm, vint8m4_t vs, size_t vl);
vint8m8_t __riscv_vneg_v_i8m8_m(vbool1_t vm, vint8m8_t vs, size_t vl);
vint16mf4_t __riscv_vneg_v_i16mf4_m(vbool64_t vm, vint16mf4_t vs, size_t vl);
vint16mf2_t __riscv_vneg_v_i16mf2_m(vbool32_t vm, vint16mf2_t vs, size_t vl);
vint16m1_t __riscv_vneg_v_i16m1_m(vbool16_t vm, vint16m1_t vs, size_t vl);
vint16m2_t __riscv_vneg_v_i16m2_m(vbool8_t vm, vint16m2_t vs, size_t vl);
vint16m4_t __riscv_vneg_v_i16m4_m(vbool4_t vm, vint16m4_t vs, size_t vl);
vint16m8_t __riscv_vneg_v_i16m8_m(vbool2_t vm, vint16m8_t vs, size_t vl);
vint32mf2_t __riscv_vneg_v_i32mf2_m(vbool64_t vm, vint32mf2_t vs, size_t vl);
vint32m1_t __riscv_vneg_v_i32m1_m(vbool32_t vm, vint32m1_t vs, size_t vl);
vint32m2_t __riscv_vneg_v_i32m2_m(vbool16_t vm, vint32m2_t vs, size_t vl);
vint32m4_t __riscv_vneg_v_i32m4_m(vbool8_t vm, vint32m4_t vs, size_t vl);
vint32m8_t __riscv_vneg_v_i32m8_m(vbool4_t vm, vint32m8_t vs, size_t vl);
vint64m1_t __riscv_vneg_v_i64m1_m(vbool64_t vm, vint64m1_t vs, size_t vl);
vint64m2_t __riscv_vneg_v_i64m2_m(vbool32_t vm, vint64m2_t vs, size_t vl);
vint64m4_t __riscv_vneg_v_i64m4_m(vbool16_t vm, vint64m4_t vs, size_t vl);
vint64m8_t __riscv_vneg_v_i64m8_m(vbool8_t vm, vint64m8_t vs, size_t vl);
vuint8mf8_t __riscv_vadd_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                    vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vadd_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8mf4_t __riscv_vadd_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                    vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vadd_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8mf2_t __riscv_vadd_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                    vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vadd_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m1_t __riscv_vadd_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                  size_t vl);
vuint8m1_t __riscv_vadd_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m2_t __riscv_vadd_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                  size_t vl);
vuint8m2_t __riscv_vadd_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m4_t __riscv_vadd_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                  size_t vl);
vuint8m4_t __riscv_vadd_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m8_t __riscv_vadd_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                  size_t vl);
vuint8m8_t __riscv_vadd_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                  size_t vl);
vuint16mf4_t __riscv_vadd_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vadd_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vadd_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vadd_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vadd_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                    vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vadd_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m2_t __riscv_vadd_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                    vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vadd_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m4_t __riscv_vadd_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                    vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vadd_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m8_t __riscv_vadd_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                    vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vadd_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                    size_t vl);
vuint32mf2_t __riscv_vadd_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vadd_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vadd_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                    vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vadd_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m2_t __riscv_vadd_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                    vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vadd_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m4_t __riscv_vadd_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                    vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vadd_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m8_t __riscv_vadd_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                    vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vadd_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                    size_t vl);
vuint64m1_t __riscv_vadd_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                    vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vadd_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m2_t __riscv_vadd_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                    vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vadd_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m4_t __riscv_vadd_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                    vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vadd_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m8_t __riscv_vadd_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                    vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vadd_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                    size_t vl);
vuint8mf8_t __riscv_vsub_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                    vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vsub_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8mf4_t __riscv_vsub_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                    vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vsub_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8mf2_t __riscv_vsub_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                    vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vsub_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m1_t __riscv_vsub_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                  size_t vl);
vuint8m1_t __riscv_vsub_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m2_t __riscv_vsub_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                  size_t vl);
vuint8m2_t __riscv_vsub_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m4_t __riscv_vsub_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                  size_t vl);
vuint8m4_t __riscv_vsub_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m8_t __riscv_vsub_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                  size_t vl);
vuint8m8_t __riscv_vsub_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                  size_t vl);
vuint16mf4_t __riscv_vsub_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vsub_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vsub_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vsub_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vsub_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                    vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vsub_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m2_t __riscv_vsub_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                    vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vsub_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m4_t __riscv_vsub_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                    vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vsub_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m8_t __riscv_vsub_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                    vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vsub_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                    size_t vl);
vuint32mf2_t __riscv_vsub_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vsub_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vsub_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                    vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vsub_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m2_t __riscv_vsub_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                    vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vsub_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m4_t __riscv_vsub_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                    vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vsub_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m8_t __riscv_vsub_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                    vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vsub_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                    size_t vl);
vuint64m1_t __riscv_vsub_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                    vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vsub_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m2_t __riscv_vsub_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                    vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vsub_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m4_t __riscv_vsub_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                    vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vsub_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m8_t __riscv_vsub_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                    vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vsub_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                    size_t vl);
vuint8mf8_t __riscv_vrsub_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8mf4_t __riscv_vrsub_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8mf2_t __riscv_vrsub_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8m1_t __riscv_vrsub_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m2_t __riscv_vrsub_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m4_t __riscv_vrsub_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m8_t __riscv_vrsub_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                   size_t vl);
vuint16mf4_t __riscv_vrsub_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vrsub_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vrsub_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                     uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vrsub_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                     size_t vl);
vuint16m4_t __riscv_vrsub_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                     size_t vl);
vuint16m8_t __riscv_vrsub_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                     size_t vl);
vuint32mf2_t __riscv_vrsub_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vrsub_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vrsub_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vrsub_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                     size_t vl);
vuint32m8_t __riscv_vrsub_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                     size_t vl);
vuint64m1_t __riscv_vrsub_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vrsub_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vrsub_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vrsub_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                     size_t vl);
----

[[vector-widening-integer-add-subtract]]
==== Vector Widening Integer Add/Subtract Intrinsics

[,c]
----
vint16mf4_t __riscv_vwadd_vv_i16mf4(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwadd_vx_i16mf4(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vwadd_wv_i16mf4(vint16mf4_t vs2, vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwadd_wx_i16mf4(vint16mf4_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwadd_vv_i16mf2(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwadd_vx_i16mf2(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwadd_wv_i16mf2(vint16mf2_t vs2, vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwadd_wx_i16mf2(vint16mf2_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwadd_vv_i16m1(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwadd_vx_i16m1(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwadd_wv_i16m1(vint16m1_t vs2, vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwadd_wx_i16m1(vint16m1_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwadd_vv_i16m2(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwadd_vx_i16m2(vint8m1_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwadd_wv_i16m2(vint16m2_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwadd_wx_i16m2(vint16m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwadd_vv_i16m4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwadd_vx_i16m4(vint8m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwadd_wv_i16m4(vint16m4_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwadd_wx_i16m4(vint16m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwadd_vv_i16m8(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwadd_vx_i16m8(vint8m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwadd_wv_i16m8(vint16m8_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwadd_wx_i16m8(vint16m8_t vs2, int8_t rs1, size_t vl);
vint32mf2_t __riscv_vwadd_vv_i32mf2(vint16mf4_t vs2, vint16mf4_t vs1,
                                    size_t vl);
vint32mf2_t __riscv_vwadd_vx_i32mf2(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vwadd_wv_i32mf2(vint32mf2_t vs2, vint16mf4_t vs1,
                                    size_t vl);
vint32mf2_t __riscv_vwadd_wx_i32mf2(vint32mf2_t vs2, int16_t rs1, size_t vl);
vint32m1_t __riscv_vwadd_vv_i32m1(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwadd_vx_i32m1(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint32m1_t __riscv_vwadd_wv_i32m1(vint32m1_t vs2, vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwadd_wx_i32m1(vint32m1_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwadd_vv_i32m2(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwadd_vx_i32m2(vint16m1_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwadd_wv_i32m2(vint32m2_t vs2, vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwadd_wx_i32m2(vint32m2_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwadd_vv_i32m4(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwadd_vx_i32m4(vint16m2_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwadd_wv_i32m4(vint32m4_t vs2, vint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwadd_wx_i32m4(vint32m4_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwadd_vv_i32m8(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwadd_vx_i32m8(vint16m4_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwadd_wv_i32m8(vint32m8_t vs2, vint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwadd_wx_i32m8(vint32m8_t vs2, int16_t rs1, size_t vl);
vint64m1_t __riscv_vwadd_vv_i64m1(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwadd_vx_i64m1(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vwadd_wv_i64m1(vint64m1_t vs2, vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwadd_wx_i64m1(vint64m1_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwadd_vv_i64m2(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwadd_vx_i64m2(vint32m1_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwadd_wv_i64m2(vint64m2_t vs2, vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwadd_wx_i64m2(vint64m2_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwadd_vv_i64m4(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwadd_vx_i64m4(vint32m2_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwadd_wv_i64m4(vint64m4_t vs2, vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwadd_wx_i64m4(vint64m4_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwadd_vv_i64m8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwadd_vx_i64m8(vint32m4_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwadd_wv_i64m8(vint64m8_t vs2, vint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwadd_wx_i64m8(vint64m8_t vs2, int32_t rs1, size_t vl);
vint16mf4_t __riscv_vwsub_vv_i16mf4(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwsub_vx_i16mf4(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vwsub_wv_i16mf4(vint16mf4_t vs2, vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwsub_wx_i16mf4(vint16mf4_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwsub_vv_i16mf2(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwsub_vx_i16mf2(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwsub_wv_i16mf2(vint16mf2_t vs2, vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwsub_wx_i16mf2(vint16mf2_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwsub_vv_i16m1(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwsub_vx_i16m1(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwsub_wv_i16m1(vint16m1_t vs2, vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwsub_wx_i16m1(vint16m1_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwsub_vv_i16m2(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwsub_vx_i16m2(vint8m1_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwsub_wv_i16m2(vint16m2_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwsub_wx_i16m2(vint16m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwsub_vv_i16m4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwsub_vx_i16m4(vint8m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwsub_wv_i16m4(vint16m4_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwsub_wx_i16m4(vint16m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwsub_vv_i16m8(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwsub_vx_i16m8(vint8m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwsub_wv_i16m8(vint16m8_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwsub_wx_i16m8(vint16m8_t vs2, int8_t rs1, size_t vl);
vint32mf2_t __riscv_vwsub_vv_i32mf2(vint16mf4_t vs2, vint16mf4_t vs1,
                                    size_t vl);
vint32mf2_t __riscv_vwsub_vx_i32mf2(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vwsub_wv_i32mf2(vint32mf2_t vs2, vint16mf4_t vs1,
                                    size_t vl);
vint32mf2_t __riscv_vwsub_wx_i32mf2(vint32mf2_t vs2, int16_t rs1, size_t vl);
vint32m1_t __riscv_vwsub_vv_i32m1(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwsub_vx_i32m1(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint32m1_t __riscv_vwsub_wv_i32m1(vint32m1_t vs2, vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwsub_wx_i32m1(vint32m1_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwsub_vv_i32m2(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwsub_vx_i32m2(vint16m1_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwsub_wv_i32m2(vint32m2_t vs2, vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwsub_wx_i32m2(vint32m2_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwsub_vv_i32m4(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwsub_vx_i32m4(vint16m2_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwsub_wv_i32m4(vint32m4_t vs2, vint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwsub_wx_i32m4(vint32m4_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwsub_vv_i32m8(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwsub_vx_i32m8(vint16m4_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwsub_wv_i32m8(vint32m8_t vs2, vint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwsub_wx_i32m8(vint32m8_t vs2, int16_t rs1, size_t vl);
vint64m1_t __riscv_vwsub_vv_i64m1(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwsub_vx_i64m1(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vwsub_wv_i64m1(vint64m1_t vs2, vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwsub_wx_i64m1(vint64m1_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwsub_vv_i64m2(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwsub_vx_i64m2(vint32m1_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwsub_wv_i64m2(vint64m2_t vs2, vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwsub_wx_i64m2(vint64m2_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwsub_vv_i64m4(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwsub_vx_i64m4(vint32m2_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwsub_wv_i64m4(vint64m4_t vs2, vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwsub_wx_i64m4(vint64m4_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwsub_vv_i64m8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwsub_vx_i64m8(vint32m4_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwsub_wv_i64m8(vint64m8_t vs2, vint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwsub_wx_i64m8(vint64m8_t vs2, int32_t rs1, size_t vl);
vuint16mf4_t __riscv_vwaddu_vv_u16mf4(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vuint16mf4_t __riscv_vwaddu_vx_u16mf4(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vwaddu_wv_u16mf4(vuint16mf4_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vuint16mf4_t __riscv_vwaddu_wx_u16mf4(vuint16mf4_t vs2, uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwaddu_vv_u16mf2(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vuint16mf2_t __riscv_vwaddu_vx_u16mf2(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwaddu_wv_u16mf2(vuint16mf2_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vuint16mf2_t __riscv_vwaddu_wx_u16mf2(vuint16mf2_t vs2, uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwaddu_vv_u16m1(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                    size_t vl);
vuint16m1_t __riscv_vwaddu_vx_u16m1(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwaddu_wv_u16m1(vuint16m1_t vs2, vuint8mf2_t vs1,
                                    size_t vl);
vuint16m1_t __riscv_vwaddu_wx_u16m1(vuint16m1_t vs2, uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwaddu_vv_u16m2(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwaddu_vx_u16m2(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwaddu_wv_u16m2(vuint16m2_t vs2, vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwaddu_wx_u16m2(vuint16m2_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwaddu_vv_u16m4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwaddu_vx_u16m4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwaddu_wv_u16m4(vuint16m4_t vs2, vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwaddu_wx_u16m4(vuint16m4_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwaddu_vv_u16m8(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwaddu_vx_u16m8(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwaddu_wv_u16m8(vuint16m8_t vs2, vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwaddu_wx_u16m8(vuint16m8_t vs2, uint8_t rs1, size_t vl);
vuint32mf2_t __riscv_vwaddu_vv_u32mf2(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vuint32mf2_t __riscv_vwaddu_vx_u32mf2(vuint16mf4_t vs2, uint16_t rs1,
                                      size_t vl);
vuint32mf2_t __riscv_vwaddu_wv_u32mf2(vuint32mf2_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vuint32mf2_t __riscv_vwaddu_wx_u32mf2(vuint32mf2_t vs2, uint16_t rs1,
                                      size_t vl);
vuint32m1_t __riscv_vwaddu_vv_u32m1(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint32m1_t __riscv_vwaddu_vx_u32m1(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwaddu_wv_u32m1(vuint32m1_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint32m1_t __riscv_vwaddu_wx_u32m1(vuint32m1_t vs2, uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwaddu_vv_u32m2(vuint16m1_t vs2, vuint16m1_t vs1,
                                    size_t vl);
vuint32m2_t __riscv_vwaddu_vx_u32m2(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwaddu_wv_u32m2(vuint32m2_t vs2, vuint16m1_t vs1,
                                    size_t vl);
vuint32m2_t __riscv_vwaddu_wx_u32m2(vuint32m2_t vs2, uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwaddu_vv_u32m4(vuint16m2_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vuint32m4_t __riscv_vwaddu_vx_u32m4(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwaddu_wv_u32m4(vuint32m4_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vuint32m4_t __riscv_vwaddu_wx_u32m4(vuint32m4_t vs2, uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwaddu_vv_u32m8(vuint16m4_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vuint32m8_t __riscv_vwaddu_vx_u32m8(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwaddu_wv_u32m8(vuint32m8_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vuint32m8_t __riscv_vwaddu_wx_u32m8(vuint32m8_t vs2, uint16_t rs1, size_t vl);
vuint64m1_t __riscv_vwaddu_vv_u64m1(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint64m1_t __riscv_vwaddu_vx_u64m1(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vwaddu_wv_u64m1(vuint64m1_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint64m1_t __riscv_vwaddu_wx_u64m1(vuint64m1_t vs2, uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwaddu_vv_u64m2(vuint32m1_t vs2, vuint32m1_t vs1,
                                    size_t vl);
vuint64m2_t __riscv_vwaddu_vx_u64m2(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwaddu_wv_u64m2(vuint64m2_t vs2, vuint32m1_t vs1,
                                    size_t vl);
vuint64m2_t __riscv_vwaddu_wx_u64m2(vuint64m2_t vs2, uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwaddu_vv_u64m4(vuint32m2_t vs2, vuint32m2_t vs1,
                                    size_t vl);
vuint64m4_t __riscv_vwaddu_vx_u64m4(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwaddu_wv_u64m4(vuint64m4_t vs2, vuint32m2_t vs1,
                                    size_t vl);
vuint64m4_t __riscv_vwaddu_wx_u64m4(vuint64m4_t vs2, uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwaddu_vv_u64m8(vuint32m4_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vuint64m8_t __riscv_vwaddu_vx_u64m8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwaddu_wv_u64m8(vuint64m8_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vuint64m8_t __riscv_vwaddu_wx_u64m8(vuint64m8_t vs2, uint32_t rs1, size_t vl);
vuint16mf4_t __riscv_vwsubu_vv_u16mf4(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vuint16mf4_t __riscv_vwsubu_vx_u16mf4(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vwsubu_wv_u16mf4(vuint16mf4_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vuint16mf4_t __riscv_vwsubu_wx_u16mf4(vuint16mf4_t vs2, uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwsubu_vv_u16mf2(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vuint16mf2_t __riscv_vwsubu_vx_u16mf2(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwsubu_wv_u16mf2(vuint16mf2_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vuint16mf2_t __riscv_vwsubu_wx_u16mf2(vuint16mf2_t vs2, uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwsubu_vv_u16m1(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                    size_t vl);
vuint16m1_t __riscv_vwsubu_vx_u16m1(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwsubu_wv_u16m1(vuint16m1_t vs2, vuint8mf2_t vs1,
                                    size_t vl);
vuint16m1_t __riscv_vwsubu_wx_u16m1(vuint16m1_t vs2, uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwsubu_vv_u16m2(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwsubu_vx_u16m2(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwsubu_wv_u16m2(vuint16m2_t vs2, vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwsubu_wx_u16m2(vuint16m2_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwsubu_vv_u16m4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwsubu_vx_u16m4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwsubu_wv_u16m4(vuint16m4_t vs2, vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwsubu_wx_u16m4(vuint16m4_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwsubu_vv_u16m8(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwsubu_vx_u16m8(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwsubu_wv_u16m8(vuint16m8_t vs2, vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwsubu_wx_u16m8(vuint16m8_t vs2, uint8_t rs1, size_t vl);
vuint32mf2_t __riscv_vwsubu_vv_u32mf2(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vuint32mf2_t __riscv_vwsubu_vx_u32mf2(vuint16mf4_t vs2, uint16_t rs1,
                                      size_t vl);
vuint32mf2_t __riscv_vwsubu_wv_u32mf2(vuint32mf2_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vuint32mf2_t __riscv_vwsubu_wx_u32mf2(vuint32mf2_t vs2, uint16_t rs1,
                                      size_t vl);
vuint32m1_t __riscv_vwsubu_vv_u32m1(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint32m1_t __riscv_vwsubu_vx_u32m1(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwsubu_wv_u32m1(vuint32m1_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint32m1_t __riscv_vwsubu_wx_u32m1(vuint32m1_t vs2, uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwsubu_vv_u32m2(vuint16m1_t vs2, vuint16m1_t vs1,
                                    size_t vl);
vuint32m2_t __riscv_vwsubu_vx_u32m2(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwsubu_wv_u32m2(vuint32m2_t vs2, vuint16m1_t vs1,
                                    size_t vl);
vuint32m2_t __riscv_vwsubu_wx_u32m2(vuint32m2_t vs2, uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwsubu_vv_u32m4(vuint16m2_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vuint32m4_t __riscv_vwsubu_vx_u32m4(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwsubu_wv_u32m4(vuint32m4_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vuint32m4_t __riscv_vwsubu_wx_u32m4(vuint32m4_t vs2, uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwsubu_vv_u32m8(vuint16m4_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vuint32m8_t __riscv_vwsubu_vx_u32m8(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwsubu_wv_u32m8(vuint32m8_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vuint32m8_t __riscv_vwsubu_wx_u32m8(vuint32m8_t vs2, uint16_t rs1, size_t vl);
vuint64m1_t __riscv_vwsubu_vv_u64m1(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint64m1_t __riscv_vwsubu_vx_u64m1(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vwsubu_wv_u64m1(vuint64m1_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint64m1_t __riscv_vwsubu_wx_u64m1(vuint64m1_t vs2, uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwsubu_vv_u64m2(vuint32m1_t vs2, vuint32m1_t vs1,
                                    size_t vl);
vuint64m2_t __riscv_vwsubu_vx_u64m2(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwsubu_wv_u64m2(vuint64m2_t vs2, vuint32m1_t vs1,
                                    size_t vl);
vuint64m2_t __riscv_vwsubu_wx_u64m2(vuint64m2_t vs2, uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwsubu_vv_u64m4(vuint32m2_t vs2, vuint32m2_t vs1,
                                    size_t vl);
vuint64m4_t __riscv_vwsubu_vx_u64m4(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwsubu_wv_u64m4(vuint64m4_t vs2, vuint32m2_t vs1,
                                    size_t vl);
vuint64m4_t __riscv_vwsubu_wx_u64m4(vuint64m4_t vs2, uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwsubu_vv_u64m8(vuint32m4_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vuint64m8_t __riscv_vwsubu_vx_u64m8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwsubu_wv_u64m8(vuint64m8_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vuint64m8_t __riscv_vwsubu_wx_u64m8(vuint64m8_t vs2, uint32_t rs1, size_t vl);
// masked functions
vint16mf4_t __riscv_vwadd_vv_i16mf4_m(vbool64_t vm, vint8mf8_t vs2,
                                      vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwadd_vx_i16mf4_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                      size_t vl);
vint16mf4_t __riscv_vwadd_wv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwadd_wx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int8_t rs1,
                                      size_t vl);
vint16mf2_t __riscv_vwadd_vv_i16mf2_m(vbool32_t vm, vint8mf4_t vs2,
                                      vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwadd_vx_i16mf2_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                      size_t vl);
vint16mf2_t __riscv_vwadd_wv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwadd_wx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int8_t rs1,
                                      size_t vl);
vint16m1_t __riscv_vwadd_vv_i16m1_m(vbool16_t vm, vint8mf2_t vs2,
                                    vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwadd_vx_i16m1_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                    size_t vl);
vint16m1_t __riscv_vwadd_wv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                    vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwadd_wx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int8_t rs1,
                                    size_t vl);
vint16m2_t __riscv_vwadd_vv_i16m2_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                    size_t vl);
vint16m2_t __riscv_vwadd_vx_i16m2_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                    size_t vl);
vint16m2_t __riscv_vwadd_wv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint8m1_t vs1,
                                    size_t vl);
vint16m2_t __riscv_vwadd_wx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int8_t rs1,
                                    size_t vl);
vint16m4_t __riscv_vwadd_vv_i16m4_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                    size_t vl);
vint16m4_t __riscv_vwadd_vx_i16m4_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                    size_t vl);
vint16m4_t __riscv_vwadd_wv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint8m2_t vs1,
                                    size_t vl);
vint16m4_t __riscv_vwadd_wx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int8_t rs1,
                                    size_t vl);
vint16m8_t __riscv_vwadd_vv_i16m8_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                    size_t vl);
vint16m8_t __riscv_vwadd_vx_i16m8_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                    size_t vl);
vint16m8_t __riscv_vwadd_wv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint8m4_t vs1,
                                    size_t vl);
vint16m8_t __riscv_vwadd_wx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int8_t rs1,
                                    size_t vl);
vint32mf2_t __riscv_vwadd_vv_i32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwadd_vx_i32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                      int16_t rs1, size_t vl);
vint32mf2_t __riscv_vwadd_wv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      vint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwadd_wx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      int16_t rs1, size_t vl);
vint32m1_t __riscv_vwadd_vv_i32m1_m(vbool32_t vm, vint16mf2_t vs2,
                                    vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwadd_vx_i32m1_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                    size_t vl);
vint32m1_t __riscv_vwadd_wv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                    vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwadd_wx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int16_t rs1,
                                    size_t vl);
vint32m2_t __riscv_vwadd_vv_i32m2_m(vbool16_t vm, vint16m1_t vs2,
                                    vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwadd_vx_i32m2_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                    size_t vl);
vint32m2_t __riscv_vwadd_wv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                    vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwadd_wx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int16_t rs1,
                                    size_t vl);
vint32m4_t __riscv_vwadd_vv_i32m4_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                    size_t vl);
vint32m4_t __riscv_vwadd_vx_i32m4_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                    size_t vl);
vint32m4_t __riscv_vwadd_wv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint16m2_t vs1,
                                    size_t vl);
vint32m4_t __riscv_vwadd_wx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int16_t rs1,
                                    size_t vl);
vint32m8_t __riscv_vwadd_vv_i32m8_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                    size_t vl);
vint32m8_t __riscv_vwadd_vx_i32m8_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                    size_t vl);
vint32m8_t __riscv_vwadd_wv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint16m4_t vs1,
                                    size_t vl);
vint32m8_t __riscv_vwadd_wx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int16_t rs1,
                                    size_t vl);
vint64m1_t __riscv_vwadd_vv_i64m1_m(vbool64_t vm, vint32mf2_t vs2,
                                    vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwadd_vx_i64m1_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                    size_t vl);
vint64m1_t __riscv_vwadd_wv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                    vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwadd_wx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int32_t rs1,
                                    size_t vl);
vint64m2_t __riscv_vwadd_vv_i64m2_m(vbool32_t vm, vint32m1_t vs2,
                                    vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwadd_vx_i64m2_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                    size_t vl);
vint64m2_t __riscv_vwadd_wv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                    vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwadd_wx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int32_t rs1,
                                    size_t vl);
vint64m4_t __riscv_vwadd_vv_i64m4_m(vbool16_t vm, vint32m2_t vs2,
                                    vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwadd_vx_i64m4_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                    size_t vl);
vint64m4_t __riscv_vwadd_wv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                    vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwadd_wx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int32_t rs1,
                                    size_t vl);
vint64m8_t __riscv_vwadd_vv_i64m8_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                    size_t vl);
vint64m8_t __riscv_vwadd_vx_i64m8_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                    size_t vl);
vint64m8_t __riscv_vwadd_wv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint32m4_t vs1,
                                    size_t vl);
vint64m8_t __riscv_vwadd_wx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int32_t rs1,
                                    size_t vl);
vint16mf4_t __riscv_vwsub_vv_i16mf4_m(vbool64_t vm, vint8mf8_t vs2,
                                      vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwsub_vx_i16mf4_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                      size_t vl);
vint16mf4_t __riscv_vwsub_wv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwsub_wx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int8_t rs1,
                                      size_t vl);
vint16mf2_t __riscv_vwsub_vv_i16mf2_m(vbool32_t vm, vint8mf4_t vs2,
                                      vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwsub_vx_i16mf2_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                      size_t vl);
vint16mf2_t __riscv_vwsub_wv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwsub_wx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int8_t rs1,
                                      size_t vl);
vint16m1_t __riscv_vwsub_vv_i16m1_m(vbool16_t vm, vint8mf2_t vs2,
                                    vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwsub_vx_i16m1_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                    size_t vl);
vint16m1_t __riscv_vwsub_wv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                    vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwsub_wx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int8_t rs1,
                                    size_t vl);
vint16m2_t __riscv_vwsub_vv_i16m2_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                    size_t vl);
vint16m2_t __riscv_vwsub_vx_i16m2_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                    size_t vl);
vint16m2_t __riscv_vwsub_wv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint8m1_t vs1,
                                    size_t vl);
vint16m2_t __riscv_vwsub_wx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int8_t rs1,
                                    size_t vl);
vint16m4_t __riscv_vwsub_vv_i16m4_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                    size_t vl);
vint16m4_t __riscv_vwsub_vx_i16m4_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                    size_t vl);
vint16m4_t __riscv_vwsub_wv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint8m2_t vs1,
                                    size_t vl);
vint16m4_t __riscv_vwsub_wx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int8_t rs1,
                                    size_t vl);
vint16m8_t __riscv_vwsub_vv_i16m8_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                    size_t vl);
vint16m8_t __riscv_vwsub_vx_i16m8_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                    size_t vl);
vint16m8_t __riscv_vwsub_wv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint8m4_t vs1,
                                    size_t vl);
vint16m8_t __riscv_vwsub_wx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int8_t rs1,
                                    size_t vl);
vint32mf2_t __riscv_vwsub_vv_i32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwsub_vx_i32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                      int16_t rs1, size_t vl);
vint32mf2_t __riscv_vwsub_wv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      vint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwsub_wx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      int16_t rs1, size_t vl);
vint32m1_t __riscv_vwsub_vv_i32m1_m(vbool32_t vm, vint16mf2_t vs2,
                                    vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwsub_vx_i32m1_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                    size_t vl);
vint32m1_t __riscv_vwsub_wv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                    vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwsub_wx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int16_t rs1,
                                    size_t vl);
vint32m2_t __riscv_vwsub_vv_i32m2_m(vbool16_t vm, vint16m1_t vs2,
                                    vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwsub_vx_i32m2_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                    size_t vl);
vint32m2_t __riscv_vwsub_wv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                    vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwsub_wx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int16_t rs1,
                                    size_t vl);
vint32m4_t __riscv_vwsub_vv_i32m4_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                    size_t vl);
vint32m4_t __riscv_vwsub_vx_i32m4_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                    size_t vl);
vint32m4_t __riscv_vwsub_wv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint16m2_t vs1,
                                    size_t vl);
vint32m4_t __riscv_vwsub_wx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int16_t rs1,
                                    size_t vl);
vint32m8_t __riscv_vwsub_vv_i32m8_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                    size_t vl);
vint32m8_t __riscv_vwsub_vx_i32m8_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                    size_t vl);
vint32m8_t __riscv_vwsub_wv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint16m4_t vs1,
                                    size_t vl);
vint32m8_t __riscv_vwsub_wx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int16_t rs1,
                                    size_t vl);
vint64m1_t __riscv_vwsub_vv_i64m1_m(vbool64_t vm, vint32mf2_t vs2,
                                    vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwsub_vx_i64m1_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                    size_t vl);
vint64m1_t __riscv_vwsub_wv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                    vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwsub_wx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int32_t rs1,
                                    size_t vl);
vint64m2_t __riscv_vwsub_vv_i64m2_m(vbool32_t vm, vint32m1_t vs2,
                                    vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwsub_vx_i64m2_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                    size_t vl);
vint64m2_t __riscv_vwsub_wv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                    vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwsub_wx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int32_t rs1,
                                    size_t vl);
vint64m4_t __riscv_vwsub_vv_i64m4_m(vbool16_t vm, vint32m2_t vs2,
                                    vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwsub_vx_i64m4_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                    size_t vl);
vint64m4_t __riscv_vwsub_wv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                    vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwsub_wx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int32_t rs1,
                                    size_t vl);
vint64m8_t __riscv_vwsub_vv_i64m8_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                    size_t vl);
vint64m8_t __riscv_vwsub_vx_i64m8_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                    size_t vl);
vint64m8_t __riscv_vwsub_wv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint32m4_t vs1,
                                    size_t vl);
vint64m8_t __riscv_vwsub_wx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int32_t rs1,
                                    size_t vl);
vuint16mf4_t __riscv_vwaddu_vv_u16mf4_m(vbool64_t vm, vuint8mf8_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vuint16mf4_t __riscv_vwaddu_vx_u16mf4_m(vbool64_t vm, vuint8mf8_t vs2,
                                        uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vwaddu_wv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vuint16mf4_t __riscv_vwaddu_wx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwaddu_vv_u16mf2_m(vbool32_t vm, vuint8mf4_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vwaddu_vx_u16mf2_m(vbool32_t vm, vuint8mf4_t vs2,
                                        uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwaddu_wv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vwaddu_wx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwaddu_vv_u16m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                      vuint8mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vwaddu_vx_u16m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                      uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwaddu_wv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      vuint8mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vwaddu_wx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwaddu_vv_u16m2_m(vbool8_t vm, vuint8m1_t vs2,
                                      vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwaddu_vx_u16m2_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m2_t __riscv_vwaddu_wv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwaddu_wx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m4_t __riscv_vwaddu_vv_u16m4_m(vbool4_t vm, vuint8m2_t vs2,
                                      vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwaddu_vx_u16m4_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m4_t __riscv_vwaddu_wv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwaddu_wx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m8_t __riscv_vwaddu_vv_u16m8_m(vbool2_t vm, vuint8m4_t vs2,
                                      vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwaddu_vx_u16m8_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m8_t __riscv_vwaddu_wv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwaddu_wx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint8_t rs1,
                                      size_t vl);
vuint32mf2_t __riscv_vwaddu_vv_u32mf2_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vuint32mf2_t __riscv_vwaddu_vx_u32mf2_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vwaddu_wv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vuint32mf2_t __riscv_vwaddu_wx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwaddu_vv_u32m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vwaddu_vx_u32m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwaddu_wv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vwaddu_wx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwaddu_vv_u32m2_m(vbool16_t vm, vuint16m1_t vs2,
                                      vuint16m1_t vs1, size_t vl);
vuint32m2_t __riscv_vwaddu_vx_u32m2_m(vbool16_t vm, vuint16m1_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwaddu_wv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      vuint16m1_t vs1, size_t vl);
vuint32m2_t __riscv_vwaddu_wx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwaddu_vv_u32m4_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vuint32m4_t __riscv_vwaddu_vx_u32m4_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwaddu_wv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vuint32m4_t __riscv_vwaddu_wx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwaddu_vv_u32m8_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vuint32m8_t __riscv_vwaddu_vx_u32m8_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwaddu_wv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vuint32m8_t __riscv_vwaddu_wx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint16_t rs1, size_t vl);
vuint64m1_t __riscv_vwaddu_vv_u64m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint64m1_t __riscv_vwaddu_vx_u64m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vwaddu_wv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint64m1_t __riscv_vwaddu_wx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwaddu_vv_u64m2_m(vbool32_t vm, vuint32m1_t vs2,
                                      vuint32m1_t vs1, size_t vl);
vuint64m2_t __riscv_vwaddu_vx_u64m2_m(vbool32_t vm, vuint32m1_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwaddu_wv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      vuint32m1_t vs1, size_t vl);
vuint64m2_t __riscv_vwaddu_wx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwaddu_vv_u64m4_m(vbool16_t vm, vuint32m2_t vs2,
                                      vuint32m2_t vs1, size_t vl);
vuint64m4_t __riscv_vwaddu_vx_u64m4_m(vbool16_t vm, vuint32m2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwaddu_wv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      vuint32m2_t vs1, size_t vl);
vuint64m4_t __riscv_vwaddu_wx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwaddu_vv_u64m8_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vuint64m8_t __riscv_vwaddu_vx_u64m8_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwaddu_wv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vuint64m8_t __riscv_vwaddu_wx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint32_t rs1, size_t vl);
vuint16mf4_t __riscv_vwsubu_vv_u16mf4_m(vbool64_t vm, vuint8mf8_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vuint16mf4_t __riscv_vwsubu_vx_u16mf4_m(vbool64_t vm, vuint8mf8_t vs2,
                                        uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vwsubu_wv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vuint16mf4_t __riscv_vwsubu_wx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwsubu_vv_u16mf2_m(vbool32_t vm, vuint8mf4_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vwsubu_vx_u16mf2_m(vbool32_t vm, vuint8mf4_t vs2,
                                        uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwsubu_wv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vwsubu_wx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwsubu_vv_u16m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                      vuint8mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vwsubu_vx_u16m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                      uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwsubu_wv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      vuint8mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vwsubu_wx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwsubu_vv_u16m2_m(vbool8_t vm, vuint8m1_t vs2,
                                      vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwsubu_vx_u16m2_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m2_t __riscv_vwsubu_wv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwsubu_wx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m4_t __riscv_vwsubu_vv_u16m4_m(vbool4_t vm, vuint8m2_t vs2,
                                      vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwsubu_vx_u16m4_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m4_t __riscv_vwsubu_wv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwsubu_wx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m8_t __riscv_vwsubu_vv_u16m8_m(vbool2_t vm, vuint8m4_t vs2,
                                      vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwsubu_vx_u16m8_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m8_t __riscv_vwsubu_wv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwsubu_wx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint8_t rs1,
                                      size_t vl);
vuint32mf2_t __riscv_vwsubu_vv_u32mf2_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vuint32mf2_t __riscv_vwsubu_vx_u32mf2_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vwsubu_wv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vuint32mf2_t __riscv_vwsubu_wx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwsubu_vv_u32m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vwsubu_vx_u32m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwsubu_wv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vwsubu_wx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwsubu_vv_u32m2_m(vbool16_t vm, vuint16m1_t vs2,
                                      vuint16m1_t vs1, size_t vl);
vuint32m2_t __riscv_vwsubu_vx_u32m2_m(vbool16_t vm, vuint16m1_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwsubu_wv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      vuint16m1_t vs1, size_t vl);
vuint32m2_t __riscv_vwsubu_wx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwsubu_vv_u32m4_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vuint32m4_t __riscv_vwsubu_vx_u32m4_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwsubu_wv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vuint32m4_t __riscv_vwsubu_wx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwsubu_vv_u32m8_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vuint32m8_t __riscv_vwsubu_vx_u32m8_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwsubu_wv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vuint32m8_t __riscv_vwsubu_wx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint16_t rs1, size_t vl);
vuint64m1_t __riscv_vwsubu_vv_u64m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint64m1_t __riscv_vwsubu_vx_u64m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vwsubu_wv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint64m1_t __riscv_vwsubu_wx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwsubu_vv_u64m2_m(vbool32_t vm, vuint32m1_t vs2,
                                      vuint32m1_t vs1, size_t vl);
vuint64m2_t __riscv_vwsubu_vx_u64m2_m(vbool32_t vm, vuint32m1_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwsubu_wv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      vuint32m1_t vs1, size_t vl);
vuint64m2_t __riscv_vwsubu_wx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwsubu_vv_u64m4_m(vbool16_t vm, vuint32m2_t vs2,
                                      vuint32m2_t vs1, size_t vl);
vuint64m4_t __riscv_vwsubu_vx_u64m4_m(vbool16_t vm, vuint32m2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwsubu_wv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      vuint32m2_t vs1, size_t vl);
vuint64m4_t __riscv_vwsubu_wx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwsubu_vv_u64m8_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vuint64m8_t __riscv_vwsubu_vx_u64m8_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwsubu_wv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vuint64m8_t __riscv_vwsubu_wx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint32_t rs1, size_t vl);
----

[[vector-integer-widening]]
==== Vector Integer Widening Intrinsics

[,c]
----
vint16mf4_t __riscv_vwcvt_x_x_v_i16mf4(vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwcvt_x_x_v_i16mf2(vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwcvt_x_x_v_i16m1(vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwcvt_x_x_v_i16m2(vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwcvt_x_x_v_i16m4(vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwcvt_x_x_v_i16m8(vint8m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwcvtu_x_x_v_u16mf4(vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vwcvtu_x_x_v_u16mf2(vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vwcvtu_x_x_v_u16m1(vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vwcvtu_x_x_v_u16m2(vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vwcvtu_x_x_v_u16m4(vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vwcvtu_x_x_v_u16m8(vuint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwcvt_x_x_v_i32mf2(vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwcvt_x_x_v_i32m1(vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwcvt_x_x_v_i32m2(vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwcvt_x_x_v_i32m4(vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwcvt_x_x_v_i32m8(vint16m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwcvtu_x_x_v_u32mf2(vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vwcvtu_x_x_v_u32m1(vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vwcvtu_x_x_v_u32m2(vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vwcvtu_x_x_v_u32m4(vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vwcvtu_x_x_v_u32m8(vuint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwcvt_x_x_v_i64m1(vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwcvt_x_x_v_i64m2(vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwcvt_x_x_v_i64m4(vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwcvt_x_x_v_i64m8(vint32m4_t vs2, size_t vl);
vuint64m1_t __riscv_vwcvtu_x_x_v_u64m1(vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vwcvtu_x_x_v_u64m2(vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vwcvtu_x_x_v_u64m4(vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vwcvtu_x_x_v_u64m8(vuint32m4_t vs2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwcvt_x_x_v_i16mf4_m(vbool64_t vm, vint8mf8_t vs2,
                                         size_t vl);
vint16mf2_t __riscv_vwcvt_x_x_v_i16mf2_m(vbool32_t vm, vint8mf4_t vs2,
                                         size_t vl);
vint16m1_t __riscv_vwcvt_x_x_v_i16m1_m(vbool16_t vm, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwcvt_x_x_v_i16m2_m(vbool8_t vm, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwcvt_x_x_v_i16m4_m(vbool4_t vm, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwcvt_x_x_v_i16m8_m(vbool2_t vm, vint8m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwcvtu_x_x_v_u16mf4_m(vbool64_t vm, vuint8mf8_t vs2,
                                           size_t vl);
vuint16mf2_t __riscv_vwcvtu_x_x_v_u16mf2_m(vbool32_t vm, vuint8mf4_t vs2,
                                           size_t vl);
vuint16m1_t __riscv_vwcvtu_x_x_v_u16m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                         size_t vl);
vuint16m2_t __riscv_vwcvtu_x_x_v_u16m2_m(vbool8_t vm, vuint8m1_t vs2,
                                         size_t vl);
vuint16m4_t __riscv_vwcvtu_x_x_v_u16m4_m(vbool4_t vm, vuint8m2_t vs2,
                                         size_t vl);
vuint16m8_t __riscv_vwcvtu_x_x_v_u16m8_m(vbool2_t vm, vuint8m4_t vs2,
                                         size_t vl);
vint32mf2_t __riscv_vwcvt_x_x_v_i32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                         size_t vl);
vint32m1_t __riscv_vwcvt_x_x_v_i32m1_m(vbool32_t vm, vint16mf2_t vs2,
                                       size_t vl);
vint32m2_t __riscv_vwcvt_x_x_v_i32m2_m(vbool16_t vm, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwcvt_x_x_v_i32m4_m(vbool8_t vm, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwcvt_x_x_v_i32m8_m(vbool4_t vm, vint16m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwcvtu_x_x_v_u32mf2_m(vbool64_t vm, vuint16mf4_t vs2,
                                           size_t vl);
vuint32m1_t __riscv_vwcvtu_x_x_v_u32m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                         size_t vl);
vuint32m2_t __riscv_vwcvtu_x_x_v_u32m2_m(vbool16_t vm, vuint16m1_t vs2,
                                         size_t vl);
vuint32m4_t __riscv_vwcvtu_x_x_v_u32m4_m(vbool8_t vm, vuint16m2_t vs2,
                                         size_t vl);
vuint32m8_t __riscv_vwcvtu_x_x_v_u32m8_m(vbool4_t vm, vuint16m4_t vs2,
                                         size_t vl);
vint64m1_t __riscv_vwcvt_x_x_v_i64m1_m(vbool64_t vm, vint32mf2_t vs2,
                                       size_t vl);
vint64m2_t __riscv_vwcvt_x_x_v_i64m2_m(vbool32_t vm, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwcvt_x_x_v_i64m4_m(vbool16_t vm, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwcvt_x_x_v_i64m8_m(vbool8_t vm, vint32m4_t vs2, size_t vl);
vuint64m1_t __riscv_vwcvtu_x_x_v_u64m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                         size_t vl);
vuint64m2_t __riscv_vwcvtu_x_x_v_u64m2_m(vbool32_t vm, vuint32m1_t vs2,
                                         size_t vl);
vuint64m4_t __riscv_vwcvtu_x_x_v_u64m4_m(vbool16_t vm, vuint32m2_t vs2,
                                         size_t vl);
vuint64m8_t __riscv_vwcvtu_x_x_v_u64m8_m(vbool8_t vm, vuint32m4_t vs2,
                                         size_t vl);
----

[[vector-integer-extension]]
==== Vector Integer Extension Intrinsics

[,c]
----
vint16mf4_t __riscv_vsext_vf2_i16mf4(vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vsext_vf2_i16mf2(vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vsext_vf2_i16m1(vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vsext_vf2_i16m2(vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vsext_vf2_i16m4(vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vsext_vf2_i16m8(vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vsext_vf4_i32mf2(vint8mf8_t vs2, size_t vl);
vint32m1_t __riscv_vsext_vf4_i32m1(vint8mf4_t vs2, size_t vl);
vint32m2_t __riscv_vsext_vf4_i32m2(vint8mf2_t vs2, size_t vl);
vint32m4_t __riscv_vsext_vf4_i32m4(vint8m1_t vs2, size_t vl);
vint32m8_t __riscv_vsext_vf4_i32m8(vint8m2_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf8_i64m1(vint8mf8_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf8_i64m2(vint8mf4_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf8_i64m4(vint8mf2_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf8_i64m8(vint8m1_t vs2, size_t vl);
vint32mf2_t __riscv_vsext_vf2_i32mf2(vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vsext_vf2_i32m1(vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vsext_vf2_i32m2(vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vsext_vf2_i32m4(vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vsext_vf2_i32m8(vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf4_i64m1(vint16mf4_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf4_i64m2(vint16mf2_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf4_i64m4(vint16m1_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf4_i64m8(vint16m2_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf2_i64m1(vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf2_i64m2(vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf2_i64m4(vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf2_i64m8(vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vzext_vf2_u16mf4(vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vzext_vf2_u16mf2(vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vzext_vf2_u16m1(vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vzext_vf2_u16m2(vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vzext_vf2_u16m4(vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vzext_vf2_u16m8(vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vzext_vf4_u32mf2(vuint8mf8_t vs2, size_t vl);
vuint32m1_t __riscv_vzext_vf4_u32m1(vuint8mf4_t vs2, size_t vl);
vuint32m2_t __riscv_vzext_vf4_u32m2(vuint8mf2_t vs2, size_t vl);
vuint32m4_t __riscv_vzext_vf4_u32m4(vuint8m1_t vs2, size_t vl);
vuint32m8_t __riscv_vzext_vf4_u32m8(vuint8m2_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf8_u64m1(vuint8mf8_t vs2, size_t vl);
vuint64m2_t __riscv_vzext_vf8_u64m2(vuint8mf4_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf8_u64m4(vuint8mf2_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf8_u64m8(vuint8m1_t vs2, size_t vl);
vuint32mf2_t __riscv_vzext_vf2_u32mf2(vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vzext_vf2_u32m1(vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vzext_vf2_u32m2(vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vzext_vf2_u32m4(vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vzext_vf2_u32m8(vuint16m4_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf4_u64m1(vuint16mf4_t vs2, size_t vl);
vuint64m2_t __riscv_vzext_vf4_u64m2(vuint16mf2_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf4_u64m4(vuint16m1_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf4_u64m8(vuint16m2_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf2_u64m1(vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vzext_vf2_u64m2(vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf2_u64m4(vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf2_u64m8(vuint32m4_t vs2, size_t vl);
// masked functions
vint16mf4_t __riscv_vsext_vf2_i16mf4_m(vbool64_t vm, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vsext_vf2_i16mf2_m(vbool32_t vm, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vsext_vf2_i16m1_m(vbool16_t vm, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vsext_vf2_i16m2_m(vbool8_t vm, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vsext_vf2_i16m4_m(vbool4_t vm, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vsext_vf2_i16m8_m(vbool2_t vm, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vsext_vf4_i32mf2_m(vbool64_t vm, vint8mf8_t vs2, size_t vl);
vint32m1_t __riscv_vsext_vf4_i32m1_m(vbool32_t vm, vint8mf4_t vs2, size_t vl);
vint32m2_t __riscv_vsext_vf4_i32m2_m(vbool16_t vm, vint8mf2_t vs2, size_t vl);
vint32m4_t __riscv_vsext_vf4_i32m4_m(vbool8_t vm, vint8m1_t vs2, size_t vl);
vint32m8_t __riscv_vsext_vf4_i32m8_m(vbool4_t vm, vint8m2_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf8_i64m1_m(vbool64_t vm, vint8mf8_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf8_i64m2_m(vbool32_t vm, vint8mf4_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf8_i64m4_m(vbool16_t vm, vint8mf2_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf8_i64m8_m(vbool8_t vm, vint8m1_t vs2, size_t vl);
vint32mf2_t __riscv_vsext_vf2_i32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                       size_t vl);
vint32m1_t __riscv_vsext_vf2_i32m1_m(vbool32_t vm, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vsext_vf2_i32m2_m(vbool16_t vm, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vsext_vf2_i32m4_m(vbool8_t vm, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vsext_vf2_i32m8_m(vbool4_t vm, vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf4_i64m1_m(vbool64_t vm, vint16mf4_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf4_i64m2_m(vbool32_t vm, vint16mf2_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf4_i64m4_m(vbool16_t vm, vint16m1_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf4_i64m8_m(vbool8_t vm, vint16m2_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf2_i64m1_m(vbool64_t vm, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf2_i64m2_m(vbool32_t vm, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf2_i64m4_m(vbool16_t vm, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf2_i64m8_m(vbool8_t vm, vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vzext_vf2_u16mf4_m(vbool64_t vm, vuint8mf8_t vs2,
                                        size_t vl);
vuint16mf2_t __riscv_vzext_vf2_u16mf2_m(vbool32_t vm, vuint8mf4_t vs2,
                                        size_t vl);
vuint16m1_t __riscv_vzext_vf2_u16m1_m(vbool16_t vm, vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vzext_vf2_u16m2_m(vbool8_t vm, vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vzext_vf2_u16m4_m(vbool4_t vm, vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vzext_vf2_u16m8_m(vbool2_t vm, vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vzext_vf4_u32mf2_m(vbool64_t vm, vuint8mf8_t vs2,
                                        size_t vl);
vuint32m1_t __riscv_vzext_vf4_u32m1_m(vbool32_t vm, vuint8mf4_t vs2, size_t vl);
vuint32m2_t __riscv_vzext_vf4_u32m2_m(vbool16_t vm, vuint8mf2_t vs2, size_t vl);
vuint32m4_t __riscv_vzext_vf4_u32m4_m(vbool8_t vm, vuint8m1_t vs2, size_t vl);
vuint32m8_t __riscv_vzext_vf4_u32m8_m(vbool4_t vm, vuint8m2_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf8_u64m1_m(vbool64_t vm, vuint8mf8_t vs2, size_t vl);
vuint64m2_t __riscv_vzext_vf8_u64m2_m(vbool32_t vm, vuint8mf4_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf8_u64m4_m(vbool16_t vm, vuint8mf2_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf8_u64m8_m(vbool8_t vm, vuint8m1_t vs2, size_t vl);
vuint32mf2_t __riscv_vzext_vf2_u32mf2_m(vbool64_t vm, vuint16mf4_t vs2,
                                        size_t vl);
vuint32m1_t __riscv_vzext_vf2_u32m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                      size_t vl);
vuint32m2_t __riscv_vzext_vf2_u32m2_m(vbool16_t vm, vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vzext_vf2_u32m4_m(vbool8_t vm, vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vzext_vf2_u32m8_m(vbool4_t vm, vuint16m4_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf4_u64m1_m(vbool64_t vm, vuint16mf4_t vs2,
                                      size_t vl);
vuint64m2_t __riscv_vzext_vf4_u64m2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      size_t vl);
vuint64m4_t __riscv_vzext_vf4_u64m4_m(vbool16_t vm, vuint16m1_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf4_u64m8_m(vbool8_t vm, vuint16m2_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf2_u64m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                      size_t vl);
vuint64m2_t __riscv_vzext_vf2_u64m2_m(vbool32_t vm, vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf2_u64m4_m(vbool16_t vm, vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf2_u64m8_m(vbool8_t vm, vuint32m4_t vs2, size_t vl);
----

[[vector-integer-add-with-carry-subtract-with-borrow]]
==== Vector Integer Add-with-Carry / Subtract-with-Borrow Intrinsics

[,c]
----
vint8mf8_t __riscv_vadc_vvm_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, vbool64_t v0,
                                  size_t vl);
vint8mf8_t __riscv_vadc_vxm_i8mf8(vint8mf8_t vs2, int8_t rs1, vbool64_t v0,
                                  size_t vl);
vint8mf4_t __riscv_vadc_vvm_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, vbool32_t v0,
                                  size_t vl);
vint8mf4_t __riscv_vadc_vxm_i8mf4(vint8mf4_t vs2, int8_t rs1, vbool32_t v0,
                                  size_t vl);
vint8mf2_t __riscv_vadc_vvm_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, vbool16_t v0,
                                  size_t vl);
vint8mf2_t __riscv_vadc_vxm_i8mf2(vint8mf2_t vs2, int8_t rs1, vbool16_t v0,
                                  size_t vl);
vint8m1_t __riscv_vadc_vvm_i8m1(vint8m1_t vs2, vint8m1_t vs1, vbool8_t v0,
                                size_t vl);
vint8m1_t __riscv_vadc_vxm_i8m1(vint8m1_t vs2, int8_t rs1, vbool8_t v0,
                                size_t vl);
vint8m2_t __riscv_vadc_vvm_i8m2(vint8m2_t vs2, vint8m2_t vs1, vbool4_t v0,
                                size_t vl);
vint8m2_t __riscv_vadc_vxm_i8m2(vint8m2_t vs2, int8_t rs1, vbool4_t v0,
                                size_t vl);
vint8m4_t __riscv_vadc_vvm_i8m4(vint8m4_t vs2, vint8m4_t vs1, vbool2_t v0,
                                size_t vl);
vint8m4_t __riscv_vadc_vxm_i8m4(vint8m4_t vs2, int8_t rs1, vbool2_t v0,
                                size_t vl);
vint8m8_t __riscv_vadc_vvm_i8m8(vint8m8_t vs2, vint8m8_t vs1, vbool1_t v0,
                                size_t vl);
vint8m8_t __riscv_vadc_vxm_i8m8(vint8m8_t vs2, int8_t rs1, vbool1_t v0,
                                size_t vl);
vint16mf4_t __riscv_vadc_vvm_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1,
                                    vbool64_t v0, size_t vl);
vint16mf4_t __riscv_vadc_vxm_i16mf4(vint16mf4_t vs2, int16_t rs1, vbool64_t v0,
                                    size_t vl);
vint16mf2_t __riscv_vadc_vvm_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1,
                                    vbool32_t v0, size_t vl);
vint16mf2_t __riscv_vadc_vxm_i16mf2(vint16mf2_t vs2, int16_t rs1, vbool32_t v0,
                                    size_t vl);
vint16m1_t __riscv_vadc_vvm_i16m1(vint16m1_t vs2, vint16m1_t vs1, vbool16_t v0,
                                  size_t vl);
vint16m1_t __riscv_vadc_vxm_i16m1(vint16m1_t vs2, int16_t rs1, vbool16_t v0,
                                  size_t vl);
vint16m2_t __riscv_vadc_vvm_i16m2(vint16m2_t vs2, vint16m2_t vs1, vbool8_t v0,
                                  size_t vl);
vint16m2_t __riscv_vadc_vxm_i16m2(vint16m2_t vs2, int16_t rs1, vbool8_t v0,
                                  size_t vl);
vint16m4_t __riscv_vadc_vvm_i16m4(vint16m4_t vs2, vint16m4_t vs1, vbool4_t v0,
                                  size_t vl);
vint16m4_t __riscv_vadc_vxm_i16m4(vint16m4_t vs2, int16_t rs1, vbool4_t v0,
                                  size_t vl);
vint16m8_t __riscv_vadc_vvm_i16m8(vint16m8_t vs2, vint16m8_t vs1, vbool2_t v0,
                                  size_t vl);
vint16m8_t __riscv_vadc_vxm_i16m8(vint16m8_t vs2, int16_t rs1, vbool2_t v0,
                                  size_t vl);
vint32mf2_t __riscv_vadc_vvm_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1,
                                    vbool64_t v0, size_t vl);
vint32mf2_t __riscv_vadc_vxm_i32mf2(vint32mf2_t vs2, int32_t rs1, vbool64_t v0,
                                    size_t vl);
vint32m1_t __riscv_vadc_vvm_i32m1(vint32m1_t vs2, vint32m1_t vs1, vbool32_t v0,
                                  size_t vl);
vint32m1_t __riscv_vadc_vxm_i32m1(vint32m1_t vs2, int32_t rs1, vbool32_t v0,
                                  size_t vl);
vint32m2_t __riscv_vadc_vvm_i32m2(vint32m2_t vs2, vint32m2_t vs1, vbool16_t v0,
                                  size_t vl);
vint32m2_t __riscv_vadc_vxm_i32m2(vint32m2_t vs2, int32_t rs1, vbool16_t v0,
                                  size_t vl);
vint32m4_t __riscv_vadc_vvm_i32m4(vint32m4_t vs2, vint32m4_t vs1, vbool8_t v0,
                                  size_t vl);
vint32m4_t __riscv_vadc_vxm_i32m4(vint32m4_t vs2, int32_t rs1, vbool8_t v0,
                                  size_t vl);
vint32m8_t __riscv_vadc_vvm_i32m8(vint32m8_t vs2, vint32m8_t vs1, vbool4_t v0,
                                  size_t vl);
vint32m8_t __riscv_vadc_vxm_i32m8(vint32m8_t vs2, int32_t rs1, vbool4_t v0,
                                  size_t vl);
vint64m1_t __riscv_vadc_vvm_i64m1(vint64m1_t vs2, vint64m1_t vs1, vbool64_t v0,
                                  size_t vl);
vint64m1_t __riscv_vadc_vxm_i64m1(vint64m1_t vs2, int64_t rs1, vbool64_t v0,
                                  size_t vl);
vint64m2_t __riscv_vadc_vvm_i64m2(vint64m2_t vs2, vint64m2_t vs1, vbool32_t v0,
                                  size_t vl);
vint64m2_t __riscv_vadc_vxm_i64m2(vint64m2_t vs2, int64_t rs1, vbool32_t v0,
                                  size_t vl);
vint64m4_t __riscv_vadc_vvm_i64m4(vint64m4_t vs2, vint64m4_t vs1, vbool16_t v0,
                                  size_t vl);
vint64m4_t __riscv_vadc_vxm_i64m4(vint64m4_t vs2, int64_t rs1, vbool16_t v0,
                                  size_t vl);
vint64m8_t __riscv_vadc_vvm_i64m8(vint64m8_t vs2, vint64m8_t vs1, vbool8_t v0,
                                  size_t vl);
vint64m8_t __riscv_vadc_vxm_i64m8(vint64m8_t vs2, int64_t rs1, vbool8_t v0,
                                  size_t vl);
vint8mf8_t __riscv_vsbc_vvm_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, vbool64_t v0,
                                  size_t vl);
vint8mf8_t __riscv_vsbc_vxm_i8mf8(vint8mf8_t vs2, int8_t rs1, vbool64_t v0,
                                  size_t vl);
vint8mf4_t __riscv_vsbc_vvm_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, vbool32_t v0,
                                  size_t vl);
vint8mf4_t __riscv_vsbc_vxm_i8mf4(vint8mf4_t vs2, int8_t rs1, vbool32_t v0,
                                  size_t vl);
vint8mf2_t __riscv_vsbc_vvm_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, vbool16_t v0,
                                  size_t vl);
vint8mf2_t __riscv_vsbc_vxm_i8mf2(vint8mf2_t vs2, int8_t rs1, vbool16_t v0,
                                  size_t vl);
vint8m1_t __riscv_vsbc_vvm_i8m1(vint8m1_t vs2, vint8m1_t vs1, vbool8_t v0,
                                size_t vl);
vint8m1_t __riscv_vsbc_vxm_i8m1(vint8m1_t vs2, int8_t rs1, vbool8_t v0,
                                size_t vl);
vint8m2_t __riscv_vsbc_vvm_i8m2(vint8m2_t vs2, vint8m2_t vs1, vbool4_t v0,
                                size_t vl);
vint8m2_t __riscv_vsbc_vxm_i8m2(vint8m2_t vs2, int8_t rs1, vbool4_t v0,
                                size_t vl);
vint8m4_t __riscv_vsbc_vvm_i8m4(vint8m4_t vs2, vint8m4_t vs1, vbool2_t v0,
                                size_t vl);
vint8m4_t __riscv_vsbc_vxm_i8m4(vint8m4_t vs2, int8_t rs1, vbool2_t v0,
                                size_t vl);
vint8m8_t __riscv_vsbc_vvm_i8m8(vint8m8_t vs2, vint8m8_t vs1, vbool1_t v0,
                                size_t vl);
vint8m8_t __riscv_vsbc_vxm_i8m8(vint8m8_t vs2, int8_t rs1, vbool1_t v0,
                                size_t vl);
vint16mf4_t __riscv_vsbc_vvm_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1,
                                    vbool64_t v0, size_t vl);
vint16mf4_t __riscv_vsbc_vxm_i16mf4(vint16mf4_t vs2, int16_t rs1, vbool64_t v0,
                                    size_t vl);
vint16mf2_t __riscv_vsbc_vvm_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1,
                                    vbool32_t v0, size_t vl);
vint16mf2_t __riscv_vsbc_vxm_i16mf2(vint16mf2_t vs2, int16_t rs1, vbool32_t v0,
                                    size_t vl);
vint16m1_t __riscv_vsbc_vvm_i16m1(vint16m1_t vs2, vint16m1_t vs1, vbool16_t v0,
                                  size_t vl);
vint16m1_t __riscv_vsbc_vxm_i16m1(vint16m1_t vs2, int16_t rs1, vbool16_t v0,
                                  size_t vl);
vint16m2_t __riscv_vsbc_vvm_i16m2(vint16m2_t vs2, vint16m2_t vs1, vbool8_t v0,
                                  size_t vl);
vint16m2_t __riscv_vsbc_vxm_i16m2(vint16m2_t vs2, int16_t rs1, vbool8_t v0,
                                  size_t vl);
vint16m4_t __riscv_vsbc_vvm_i16m4(vint16m4_t vs2, vint16m4_t vs1, vbool4_t v0,
                                  size_t vl);
vint16m4_t __riscv_vsbc_vxm_i16m4(vint16m4_t vs2, int16_t rs1, vbool4_t v0,
                                  size_t vl);
vint16m8_t __riscv_vsbc_vvm_i16m8(vint16m8_t vs2, vint16m8_t vs1, vbool2_t v0,
                                  size_t vl);
vint16m8_t __riscv_vsbc_vxm_i16m8(vint16m8_t vs2, int16_t rs1, vbool2_t v0,
                                  size_t vl);
vint32mf2_t __riscv_vsbc_vvm_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1,
                                    vbool64_t v0, size_t vl);
vint32mf2_t __riscv_vsbc_vxm_i32mf2(vint32mf2_t vs2, int32_t rs1, vbool64_t v0,
                                    size_t vl);
vint32m1_t __riscv_vsbc_vvm_i32m1(vint32m1_t vs2, vint32m1_t vs1, vbool32_t v0,
                                  size_t vl);
vint32m1_t __riscv_vsbc_vxm_i32m1(vint32m1_t vs2, int32_t rs1, vbool32_t v0,
                                  size_t vl);
vint32m2_t __riscv_vsbc_vvm_i32m2(vint32m2_t vs2, vint32m2_t vs1, vbool16_t v0,
                                  size_t vl);
vint32m2_t __riscv_vsbc_vxm_i32m2(vint32m2_t vs2, int32_t rs1, vbool16_t v0,
                                  size_t vl);
vint32m4_t __riscv_vsbc_vvm_i32m4(vint32m4_t vs2, vint32m4_t vs1, vbool8_t v0,
                                  size_t vl);
vint32m4_t __riscv_vsbc_vxm_i32m4(vint32m4_t vs2, int32_t rs1, vbool8_t v0,
                                  size_t vl);
vint32m8_t __riscv_vsbc_vvm_i32m8(vint32m8_t vs2, vint32m8_t vs1, vbool4_t v0,
                                  size_t vl);
vint32m8_t __riscv_vsbc_vxm_i32m8(vint32m8_t vs2, int32_t rs1, vbool4_t v0,
                                  size_t vl);
vint64m1_t __riscv_vsbc_vvm_i64m1(vint64m1_t vs2, vint64m1_t vs1, vbool64_t v0,
                                  size_t vl);
vint64m1_t __riscv_vsbc_vxm_i64m1(vint64m1_t vs2, int64_t rs1, vbool64_t v0,
                                  size_t vl);
vint64m2_t __riscv_vsbc_vvm_i64m2(vint64m2_t vs2, vint64m2_t vs1, vbool32_t v0,
                                  size_t vl);
vint64m2_t __riscv_vsbc_vxm_i64m2(vint64m2_t vs2, int64_t rs1, vbool32_t v0,
                                  size_t vl);
vint64m4_t __riscv_vsbc_vvm_i64m4(vint64m4_t vs2, vint64m4_t vs1, vbool16_t v0,
                                  size_t vl);
vint64m4_t __riscv_vsbc_vxm_i64m4(vint64m4_t vs2, int64_t rs1, vbool16_t v0,
                                  size_t vl);
vint64m8_t __riscv_vsbc_vvm_i64m8(vint64m8_t vs2, vint64m8_t vs1, vbool8_t v0,
                                  size_t vl);
vint64m8_t __riscv_vsbc_vxm_i64m8(vint64m8_t vs2, int64_t rs1, vbool8_t v0,
                                  size_t vl);
vuint8mf8_t __riscv_vadc_vvm_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                   vbool64_t v0, size_t vl);
vuint8mf8_t __riscv_vadc_vxm_u8mf8(vuint8mf8_t vs2, uint8_t rs1, vbool64_t v0,
                                   size_t vl);
vuint8mf4_t __riscv_vadc_vvm_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                   vbool32_t v0, size_t vl);
vuint8mf4_t __riscv_vadc_vxm_u8mf4(vuint8mf4_t vs2, uint8_t rs1, vbool32_t v0,
                                   size_t vl);
vuint8mf2_t __riscv_vadc_vvm_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                   vbool16_t v0, size_t vl);
vuint8mf2_t __riscv_vadc_vxm_u8mf2(vuint8mf2_t vs2, uint8_t rs1, vbool16_t v0,
                                   size_t vl);
vuint8m1_t __riscv_vadc_vvm_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, vbool8_t v0,
                                 size_t vl);
vuint8m1_t __riscv_vadc_vxm_u8m1(vuint8m1_t vs2, uint8_t rs1, vbool8_t v0,
                                 size_t vl);
vuint8m2_t __riscv_vadc_vvm_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, vbool4_t v0,
                                 size_t vl);
vuint8m2_t __riscv_vadc_vxm_u8m2(vuint8m2_t vs2, uint8_t rs1, vbool4_t v0,
                                 size_t vl);
vuint8m4_t __riscv_vadc_vvm_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, vbool2_t v0,
                                 size_t vl);
vuint8m4_t __riscv_vadc_vxm_u8m4(vuint8m4_t vs2, uint8_t rs1, vbool2_t v0,
                                 size_t vl);
vuint8m8_t __riscv_vadc_vvm_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, vbool1_t v0,
                                 size_t vl);
vuint8m8_t __riscv_vadc_vxm_u8m8(vuint8m8_t vs2, uint8_t rs1, vbool1_t v0,
                                 size_t vl);
vuint16mf4_t __riscv_vadc_vvm_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                     vbool64_t v0, size_t vl);
vuint16mf4_t __riscv_vadc_vxm_u16mf4(vuint16mf4_t vs2, uint16_t rs1,
                                     vbool64_t v0, size_t vl);
vuint16mf2_t __riscv_vadc_vvm_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                     vbool32_t v0, size_t vl);
vuint16mf2_t __riscv_vadc_vxm_u16mf2(vuint16mf2_t vs2, uint16_t rs1,
                                     vbool32_t v0, size_t vl);
vuint16m1_t __riscv_vadc_vvm_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                   vbool16_t v0, size_t vl);
vuint16m1_t __riscv_vadc_vxm_u16m1(vuint16m1_t vs2, uint16_t rs1, vbool16_t v0,
                                   size_t vl);
vuint16m2_t __riscv_vadc_vvm_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                   vbool8_t v0, size_t vl);
vuint16m2_t __riscv_vadc_vxm_u16m2(vuint16m2_t vs2, uint16_t rs1, vbool8_t v0,
                                   size_t vl);
vuint16m4_t __riscv_vadc_vvm_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                   vbool4_t v0, size_t vl);
vuint16m4_t __riscv_vadc_vxm_u16m4(vuint16m4_t vs2, uint16_t rs1, vbool4_t v0,
                                   size_t vl);
vuint16m8_t __riscv_vadc_vvm_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                   vbool2_t v0, size_t vl);
vuint16m8_t __riscv_vadc_vxm_u16m8(vuint16m8_t vs2, uint16_t rs1, vbool2_t v0,
                                   size_t vl);
vuint32mf2_t __riscv_vadc_vvm_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                     vbool64_t v0, size_t vl);
vuint32mf2_t __riscv_vadc_vxm_u32mf2(vuint32mf2_t vs2, uint32_t rs1,
                                     vbool64_t v0, size_t vl);
vuint32m1_t __riscv_vadc_vvm_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                   vbool32_t v0, size_t vl);
vuint32m1_t __riscv_vadc_vxm_u32m1(vuint32m1_t vs2, uint32_t rs1, vbool32_t v0,
                                   size_t vl);
vuint32m2_t __riscv_vadc_vvm_u32m2(vuint32m2_t vs2, vuint32m2_t vs1,
                                   vbool16_t v0, size_t vl);
vuint32m2_t __riscv_vadc_vxm_u32m2(vuint32m2_t vs2, uint32_t rs1, vbool16_t v0,
                                   size_t vl);
vuint32m4_t __riscv_vadc_vvm_u32m4(vuint32m4_t vs2, vuint32m4_t vs1,
                                   vbool8_t v0, size_t vl);
vuint32m4_t __riscv_vadc_vxm_u32m4(vuint32m4_t vs2, uint32_t rs1, vbool8_t v0,
                                   size_t vl);
vuint32m8_t __riscv_vadc_vvm_u32m8(vuint32m8_t vs2, vuint32m8_t vs1,
                                   vbool4_t v0, size_t vl);
vuint32m8_t __riscv_vadc_vxm_u32m8(vuint32m8_t vs2, uint32_t rs1, vbool4_t v0,
                                   size_t vl);
vuint64m1_t __riscv_vadc_vvm_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                   vbool64_t v0, size_t vl);
vuint64m1_t __riscv_vadc_vxm_u64m1(vuint64m1_t vs2, uint64_t rs1, vbool64_t v0,
                                   size_t vl);
vuint64m2_t __riscv_vadc_vvm_u64m2(vuint64m2_t vs2, vuint64m2_t vs1,
                                   vbool32_t v0, size_t vl);
vuint64m2_t __riscv_vadc_vxm_u64m2(vuint64m2_t vs2, uint64_t rs1, vbool32_t v0,
                                   size_t vl);
vuint64m4_t __riscv_vadc_vvm_u64m4(vuint64m4_t vs2, vuint64m4_t vs1,
                                   vbool16_t v0, size_t vl);
vuint64m4_t __riscv_vadc_vxm_u64m4(vuint64m4_t vs2, uint64_t rs1, vbool16_t v0,
                                   size_t vl);
vuint64m8_t __riscv_vadc_vvm_u64m8(vuint64m8_t vs2, vuint64m8_t vs1,
                                   vbool8_t v0, size_t vl);
vuint64m8_t __riscv_vadc_vxm_u64m8(vuint64m8_t vs2, uint64_t rs1, vbool8_t v0,
                                   size_t vl);
vuint8mf8_t __riscv_vsbc_vvm_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                   vbool64_t v0, size_t vl);
vuint8mf8_t __riscv_vsbc_vxm_u8mf8(vuint8mf8_t vs2, uint8_t rs1, vbool64_t v0,
                                   size_t vl);
vuint8mf4_t __riscv_vsbc_vvm_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                   vbool32_t v0, size_t vl);
vuint8mf4_t __riscv_vsbc_vxm_u8mf4(vuint8mf4_t vs2, uint8_t rs1, vbool32_t v0,
                                   size_t vl);
vuint8mf2_t __riscv_vsbc_vvm_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                   vbool16_t v0, size_t vl);
vuint8mf2_t __riscv_vsbc_vxm_u8mf2(vuint8mf2_t vs2, uint8_t rs1, vbool16_t v0,
                                   size_t vl);
vuint8m1_t __riscv_vsbc_vvm_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, vbool8_t v0,
                                 size_t vl);
vuint8m1_t __riscv_vsbc_vxm_u8m1(vuint8m1_t vs2, uint8_t rs1, vbool8_t v0,
                                 size_t vl);
vuint8m2_t __riscv_vsbc_vvm_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, vbool4_t v0,
                                 size_t vl);
vuint8m2_t __riscv_vsbc_vxm_u8m2(vuint8m2_t vs2, uint8_t rs1, vbool4_t v0,
                                 size_t vl);
vuint8m4_t __riscv_vsbc_vvm_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, vbool2_t v0,
                                 size_t vl);
vuint8m4_t __riscv_vsbc_vxm_u8m4(vuint8m4_t vs2, uint8_t rs1, vbool2_t v0,
                                 size_t vl);
vuint8m8_t __riscv_vsbc_vvm_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, vbool1_t v0,
                                 size_t vl);
vuint8m8_t __riscv_vsbc_vxm_u8m8(vuint8m8_t vs2, uint8_t rs1, vbool1_t v0,
                                 size_t vl);
vuint16mf4_t __riscv_vsbc_vvm_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                     vbool64_t v0, size_t vl);
vuint16mf4_t __riscv_vsbc_vxm_u16mf4(vuint16mf4_t vs2, uint16_t rs1,
                                     vbool64_t v0, size_t vl);
vuint16mf2_t __riscv_vsbc_vvm_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                     vbool32_t v0, size_t vl);
vuint16mf2_t __riscv_vsbc_vxm_u16mf2(vuint16mf2_t vs2, uint16_t rs1,
                                     vbool32_t v0, size_t vl);
vuint16m1_t __riscv_vsbc_vvm_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                   vbool16_t v0, size_t vl);
vuint16m1_t __riscv_vsbc_vxm_u16m1(vuint16m1_t vs2, uint16_t rs1, vbool16_t v0,
                                   size_t vl);
vuint16m2_t __riscv_vsbc_vvm_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                   vbool8_t v0, size_t vl);
vuint16m2_t __riscv_vsbc_vxm_u16m2(vuint16m2_t vs2, uint16_t rs1, vbool8_t v0,
                                   size_t vl);
vuint16m4_t __riscv_vsbc_vvm_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                   vbool4_t v0, size_t vl);
vuint16m4_t __riscv_vsbc_vxm_u16m4(vuint16m4_t vs2, uint16_t rs1, vbool4_t v0,
                                   size_t vl);
vuint16m8_t __riscv_vsbc_vvm_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                   vbool2_t v0, size_t vl);
vuint16m8_t __riscv_vsbc_vxm_u16m8(vuint16m8_t vs2, uint16_t rs1, vbool2_t v0,
                                   size_t vl);
vuint32mf2_t __riscv_vsbc_vvm_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                     vbool64_t v0, size_t vl);
vuint32mf2_t __riscv_vsbc_vxm_u32mf2(vuint32mf2_t vs2, uint32_t rs1,
                                     vbool64_t v0, size_t vl);
vuint32m1_t __riscv_vsbc_vvm_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                   vbool32_t v0, size_t vl);
vuint32m1_t __riscv_vsbc_vxm_u32m1(vuint32m1_t vs2, uint32_t rs1, vbool32_t v0,
                                   size_t vl);
vuint32m2_t __riscv_vsbc_vvm_u32m2(vuint32m2_t vs2, vuint32m2_t vs1,
                                   vbool16_t v0, size_t vl);
vuint32m2_t __riscv_vsbc_vxm_u32m2(vuint32m2_t vs2, uint32_t rs1, vbool16_t v0,
                                   size_t vl);
vuint32m4_t __riscv_vsbc_vvm_u32m4(vuint32m4_t vs2, vuint32m4_t vs1,
                                   vbool8_t v0, size_t vl);
vuint32m4_t __riscv_vsbc_vxm_u32m4(vuint32m4_t vs2, uint32_t rs1, vbool8_t v0,
                                   size_t vl);
vuint32m8_t __riscv_vsbc_vvm_u32m8(vuint32m8_t vs2, vuint32m8_t vs1,
                                   vbool4_t v0, size_t vl);
vuint32m8_t __riscv_vsbc_vxm_u32m8(vuint32m8_t vs2, uint32_t rs1, vbool4_t v0,
                                   size_t vl);
vuint64m1_t __riscv_vsbc_vvm_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                   vbool64_t v0, size_t vl);
vuint64m1_t __riscv_vsbc_vxm_u64m1(vuint64m1_t vs2, uint64_t rs1, vbool64_t v0,
                                   size_t vl);
vuint64m2_t __riscv_vsbc_vvm_u64m2(vuint64m2_t vs2, vuint64m2_t vs1,
                                   vbool32_t v0, size_t vl);
vuint64m2_t __riscv_vsbc_vxm_u64m2(vuint64m2_t vs2, uint64_t rs1, vbool32_t v0,
                                   size_t vl);
vuint64m4_t __riscv_vsbc_vvm_u64m4(vuint64m4_t vs2, vuint64m4_t vs1,
                                   vbool16_t v0, size_t vl);
vuint64m4_t __riscv_vsbc_vxm_u64m4(vuint64m4_t vs2, uint64_t rs1, vbool16_t v0,
                                   size_t vl);
vuint64m8_t __riscv_vsbc_vvm_u64m8(vuint64m8_t vs2, vuint64m8_t vs1,
                                   vbool8_t v0, size_t vl);
vuint64m8_t __riscv_vsbc_vxm_u64m8(vuint64m8_t vs2, uint64_t rs1, vbool8_t v0,
                                   size_t vl);
vbool64_t __riscv_vmadc_vvm_i8mf8_b64(vint8mf8_t vs2, vint8mf8_t vs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vxm_i8mf8_b64(vint8mf8_t vs2, int8_t rs1, vbool64_t v0,
                                      size_t vl);
vbool64_t __riscv_vmadc_vv_i8mf8_b64(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmadc_vx_i8mf8_b64(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmadc_vvm_i8mf4_b32(vint8mf4_t vs2, vint8mf4_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vxm_i8mf4_b32(vint8mf4_t vs2, int8_t rs1, vbool32_t v0,
                                      size_t vl);
vbool32_t __riscv_vmadc_vv_i8mf4_b32(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmadc_vx_i8mf4_b32(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmadc_vvm_i8mf2_b16(vint8mf2_t vs2, vint8mf2_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vxm_i8mf2_b16(vint8mf2_t vs2, int8_t rs1, vbool16_t v0,
                                      size_t vl);
vbool16_t __riscv_vmadc_vv_i8mf2_b16(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmadc_vx_i8mf2_b16(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmadc_vvm_i8m1_b8(vint8m1_t vs2, vint8m1_t vs1, vbool8_t v0,
                                   size_t vl);
vbool8_t __riscv_vmadc_vxm_i8m1_b8(vint8m1_t vs2, int8_t rs1, vbool8_t v0,
                                   size_t vl);
vbool8_t __riscv_vmadc_vv_i8m1_b8(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmadc_vx_i8m1_b8(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmadc_vvm_i8m2_b4(vint8m2_t vs2, vint8m2_t vs1, vbool4_t v0,
                                   size_t vl);
vbool4_t __riscv_vmadc_vxm_i8m2_b4(vint8m2_t vs2, int8_t rs1, vbool4_t v0,
                                   size_t vl);
vbool4_t __riscv_vmadc_vv_i8m2_b4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmadc_vx_i8m2_b4(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmadc_vvm_i8m4_b2(vint8m4_t vs2, vint8m4_t vs1, vbool2_t v0,
                                   size_t vl);
vbool2_t __riscv_vmadc_vxm_i8m4_b2(vint8m4_t vs2, int8_t rs1, vbool2_t v0,
                                   size_t vl);
vbool2_t __riscv_vmadc_vv_i8m4_b2(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmadc_vx_i8m4_b2(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmadc_vvm_i8m8_b1(vint8m8_t vs2, vint8m8_t vs1, vbool1_t v0,
                                   size_t vl);
vbool1_t __riscv_vmadc_vxm_i8m8_b1(vint8m8_t vs2, int8_t rs1, vbool1_t v0,
                                   size_t vl);
vbool1_t __riscv_vmadc_vv_i8m8_b1(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmadc_vx_i8m8_b1(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmadc_vvm_i16mf4_b64(vint16mf4_t vs2, vint16mf4_t vs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vxm_i16mf4_b64(vint16mf4_t vs2, int16_t rs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vv_i16mf4_b64(vint16mf4_t vs2, vint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmadc_vx_i16mf4_b64(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmadc_vvm_i16mf2_b32(vint16mf2_t vs2, vint16mf2_t vs1,
                                       vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vxm_i16mf2_b32(vint16mf2_t vs2, int16_t rs1,
                                       vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vv_i16mf2_b32(vint16mf2_t vs2, vint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmadc_vx_i16mf2_b32(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmadc_vvm_i16m1_b16(vint16m1_t vs2, vint16m1_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vxm_i16m1_b16(vint16m1_t vs2, int16_t rs1, vbool16_t v0,
                                      size_t vl);
vbool16_t __riscv_vmadc_vv_i16m1_b16(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmadc_vx_i16m1_b16(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmadc_vvm_i16m2_b8(vint16m2_t vs2, vint16m2_t vs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmadc_vxm_i16m2_b8(vint16m2_t vs2, int16_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmadc_vv_i16m2_b8(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmadc_vx_i16m2_b8(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmadc_vvm_i16m4_b4(vint16m4_t vs2, vint16m4_t vs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmadc_vxm_i16m4_b4(vint16m4_t vs2, int16_t rs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmadc_vv_i16m4_b4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmadc_vx_i16m4_b4(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmadc_vvm_i16m8_b2(vint16m8_t vs2, vint16m8_t vs1, vbool2_t v0,
                                    size_t vl);
vbool2_t __riscv_vmadc_vxm_i16m8_b2(vint16m8_t vs2, int16_t rs1, vbool2_t v0,
                                    size_t vl);
vbool2_t __riscv_vmadc_vv_i16m8_b2(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmadc_vx_i16m8_b2(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmadc_vvm_i32mf2_b64(vint32mf2_t vs2, vint32mf2_t vs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vxm_i32mf2_b64(vint32mf2_t vs2, int32_t rs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vv_i32mf2_b64(vint32mf2_t vs2, vint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmadc_vx_i32mf2_b64(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmadc_vvm_i32m1_b32(vint32m1_t vs2, vint32m1_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vxm_i32m1_b32(vint32m1_t vs2, int32_t rs1, vbool32_t v0,
                                      size_t vl);
vbool32_t __riscv_vmadc_vv_i32m1_b32(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmadc_vx_i32m1_b32(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmadc_vvm_i32m2_b16(vint32m2_t vs2, vint32m2_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vxm_i32m2_b16(vint32m2_t vs2, int32_t rs1, vbool16_t v0,
                                      size_t vl);
vbool16_t __riscv_vmadc_vv_i32m2_b16(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmadc_vx_i32m2_b16(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmadc_vvm_i32m4_b8(vint32m4_t vs2, vint32m4_t vs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmadc_vxm_i32m4_b8(vint32m4_t vs2, int32_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmadc_vv_i32m4_b8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmadc_vx_i32m4_b8(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmadc_vvm_i32m8_b4(vint32m8_t vs2, vint32m8_t vs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmadc_vxm_i32m8_b4(vint32m8_t vs2, int32_t rs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmadc_vv_i32m8_b4(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmadc_vx_i32m8_b4(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmadc_vvm_i64m1_b64(vint64m1_t vs2, vint64m1_t vs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vxm_i64m1_b64(vint64m1_t vs2, int64_t rs1, vbool64_t v0,
                                      size_t vl);
vbool64_t __riscv_vmadc_vv_i64m1_b64(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmadc_vx_i64m1_b64(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmadc_vvm_i64m2_b32(vint64m2_t vs2, vint64m2_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vxm_i64m2_b32(vint64m2_t vs2, int64_t rs1, vbool32_t v0,
                                      size_t vl);
vbool32_t __riscv_vmadc_vv_i64m2_b32(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmadc_vx_i64m2_b32(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmadc_vvm_i64m4_b16(vint64m4_t vs2, vint64m4_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vxm_i64m4_b16(vint64m4_t vs2, int64_t rs1, vbool16_t v0,
                                      size_t vl);
vbool16_t __riscv_vmadc_vv_i64m4_b16(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmadc_vx_i64m4_b16(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmadc_vvm_i64m8_b8(vint64m8_t vs2, vint64m8_t vs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmadc_vxm_i64m8_b8(vint64m8_t vs2, int64_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmadc_vv_i64m8_b8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmadc_vx_i64m8_b8(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsbc_vvm_i8mf8_b64(vint8mf8_t vs2, vint8mf8_t vs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vxm_i8mf8_b64(vint8mf8_t vs2, int8_t rs1, vbool64_t v0,
                                      size_t vl);
vbool64_t __riscv_vmsbc_vv_i8mf8_b64(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsbc_vx_i8mf8_b64(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsbc_vvm_i8mf4_b32(vint8mf4_t vs2, vint8mf4_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vxm_i8mf4_b32(vint8mf4_t vs2, int8_t rs1, vbool32_t v0,
                                      size_t vl);
vbool32_t __riscv_vmsbc_vv_i8mf4_b32(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsbc_vx_i8mf4_b32(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsbc_vvm_i8mf2_b16(vint8mf2_t vs2, vint8mf2_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vxm_i8mf2_b16(vint8mf2_t vs2, int8_t rs1, vbool16_t v0,
                                      size_t vl);
vbool16_t __riscv_vmsbc_vv_i8mf2_b16(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsbc_vx_i8mf2_b16(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsbc_vvm_i8m1_b8(vint8m1_t vs2, vint8m1_t vs1, vbool8_t v0,
                                   size_t vl);
vbool8_t __riscv_vmsbc_vxm_i8m1_b8(vint8m1_t vs2, int8_t rs1, vbool8_t v0,
                                   size_t vl);
vbool8_t __riscv_vmsbc_vv_i8m1_b8(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsbc_vx_i8m1_b8(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsbc_vvm_i8m2_b4(vint8m2_t vs2, vint8m2_t vs1, vbool4_t v0,
                                   size_t vl);
vbool4_t __riscv_vmsbc_vxm_i8m2_b4(vint8m2_t vs2, int8_t rs1, vbool4_t v0,
                                   size_t vl);
vbool4_t __riscv_vmsbc_vv_i8m2_b4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsbc_vx_i8m2_b4(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsbc_vvm_i8m4_b2(vint8m4_t vs2, vint8m4_t vs1, vbool2_t v0,
                                   size_t vl);
vbool2_t __riscv_vmsbc_vxm_i8m4_b2(vint8m4_t vs2, int8_t rs1, vbool2_t v0,
                                   size_t vl);
vbool2_t __riscv_vmsbc_vv_i8m4_b2(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsbc_vx_i8m4_b2(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsbc_vvm_i8m8_b1(vint8m8_t vs2, vint8m8_t vs1, vbool1_t v0,
                                   size_t vl);
vbool1_t __riscv_vmsbc_vxm_i8m8_b1(vint8m8_t vs2, int8_t rs1, vbool1_t v0,
                                   size_t vl);
vbool1_t __riscv_vmsbc_vv_i8m8_b1(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsbc_vx_i8m8_b1(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsbc_vvm_i16mf4_b64(vint16mf4_t vs2, vint16mf4_t vs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vxm_i16mf4_b64(vint16mf4_t vs2, int16_t rs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vv_i16mf4_b64(vint16mf4_t vs2, vint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsbc_vx_i16mf4_b64(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsbc_vvm_i16mf2_b32(vint16mf2_t vs2, vint16mf2_t vs1,
                                       vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vxm_i16mf2_b32(vint16mf2_t vs2, int16_t rs1,
                                       vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vv_i16mf2_b32(vint16mf2_t vs2, vint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsbc_vx_i16mf2_b32(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsbc_vvm_i16m1_b16(vint16m1_t vs2, vint16m1_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vxm_i16m1_b16(vint16m1_t vs2, int16_t rs1, vbool16_t v0,
                                      size_t vl);
vbool16_t __riscv_vmsbc_vv_i16m1_b16(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsbc_vx_i16m1_b16(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsbc_vvm_i16m2_b8(vint16m2_t vs2, vint16m2_t vs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmsbc_vxm_i16m2_b8(vint16m2_t vs2, int16_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmsbc_vv_i16m2_b8(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsbc_vx_i16m2_b8(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsbc_vvm_i16m4_b4(vint16m4_t vs2, vint16m4_t vs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmsbc_vxm_i16m4_b4(vint16m4_t vs2, int16_t rs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmsbc_vv_i16m4_b4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsbc_vx_i16m4_b4(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsbc_vvm_i16m8_b2(vint16m8_t vs2, vint16m8_t vs1, vbool2_t v0,
                                    size_t vl);
vbool2_t __riscv_vmsbc_vxm_i16m8_b2(vint16m8_t vs2, int16_t rs1, vbool2_t v0,
                                    size_t vl);
vbool2_t __riscv_vmsbc_vv_i16m8_b2(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsbc_vx_i16m8_b2(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsbc_vvm_i32mf2_b64(vint32mf2_t vs2, vint32mf2_t vs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vxm_i32mf2_b64(vint32mf2_t vs2, int32_t rs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vv_i32mf2_b64(vint32mf2_t vs2, vint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsbc_vx_i32mf2_b64(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsbc_vvm_i32m1_b32(vint32m1_t vs2, vint32m1_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vxm_i32m1_b32(vint32m1_t vs2, int32_t rs1, vbool32_t v0,
                                      size_t vl);
vbool32_t __riscv_vmsbc_vv_i32m1_b32(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsbc_vx_i32m1_b32(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsbc_vvm_i32m2_b16(vint32m2_t vs2, vint32m2_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vxm_i32m2_b16(vint32m2_t vs2, int32_t rs1, vbool16_t v0,
                                      size_t vl);
vbool16_t __riscv_vmsbc_vv_i32m2_b16(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsbc_vx_i32m2_b16(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsbc_vvm_i32m4_b8(vint32m4_t vs2, vint32m4_t vs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmsbc_vxm_i32m4_b8(vint32m4_t vs2, int32_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmsbc_vv_i32m4_b8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsbc_vx_i32m4_b8(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsbc_vvm_i32m8_b4(vint32m8_t vs2, vint32m8_t vs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmsbc_vxm_i32m8_b4(vint32m8_t vs2, int32_t rs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmsbc_vv_i32m8_b4(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsbc_vx_i32m8_b4(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsbc_vvm_i64m1_b64(vint64m1_t vs2, vint64m1_t vs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vxm_i64m1_b64(vint64m1_t vs2, int64_t rs1, vbool64_t v0,
                                      size_t vl);
vbool64_t __riscv_vmsbc_vv_i64m1_b64(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsbc_vx_i64m1_b64(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsbc_vvm_i64m2_b32(vint64m2_t vs2, vint64m2_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vxm_i64m2_b32(vint64m2_t vs2, int64_t rs1, vbool32_t v0,
                                      size_t vl);
vbool32_t __riscv_vmsbc_vv_i64m2_b32(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsbc_vx_i64m2_b32(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsbc_vvm_i64m4_b16(vint64m4_t vs2, vint64m4_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vxm_i64m4_b16(vint64m4_t vs2, int64_t rs1, vbool16_t v0,
                                      size_t vl);
vbool16_t __riscv_vmsbc_vv_i64m4_b16(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsbc_vx_i64m4_b16(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsbc_vvm_i64m8_b8(vint64m8_t vs2, vint64m8_t vs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmsbc_vxm_i64m8_b8(vint64m8_t vs2, int64_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmsbc_vv_i64m8_b8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsbc_vx_i64m8_b8(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmadc_vvm_u8mf8_b64(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vxm_u8mf8_b64(vuint8mf8_t vs2, uint8_t rs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vv_u8mf8_b64(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmadc_vx_u8mf8_b64(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmadc_vvm_u8mf4_b32(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vxm_u8mf4_b32(vuint8mf4_t vs2, uint8_t rs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vv_u8mf4_b32(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmadc_vx_u8mf4_b32(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmadc_vvm_u8mf2_b16(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vxm_u8mf2_b16(vuint8mf2_t vs2, uint8_t rs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vv_u8mf2_b16(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmadc_vx_u8mf2_b16(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmadc_vvm_u8m1_b8(vuint8m1_t vs2, vuint8m1_t vs1, vbool8_t v0,
                                   size_t vl);
vbool8_t __riscv_vmadc_vxm_u8m1_b8(vuint8m1_t vs2, uint8_t rs1, vbool8_t v0,
                                   size_t vl);
vbool8_t __riscv_vmadc_vv_u8m1_b8(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmadc_vx_u8m1_b8(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmadc_vvm_u8m2_b4(vuint8m2_t vs2, vuint8m2_t vs1, vbool4_t v0,
                                   size_t vl);
vbool4_t __riscv_vmadc_vxm_u8m2_b4(vuint8m2_t vs2, uint8_t rs1, vbool4_t v0,
                                   size_t vl);
vbool4_t __riscv_vmadc_vv_u8m2_b4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmadc_vx_u8m2_b4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmadc_vvm_u8m4_b2(vuint8m4_t vs2, vuint8m4_t vs1, vbool2_t v0,
                                   size_t vl);
vbool2_t __riscv_vmadc_vxm_u8m4_b2(vuint8m4_t vs2, uint8_t rs1, vbool2_t v0,
                                   size_t vl);
vbool2_t __riscv_vmadc_vv_u8m4_b2(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmadc_vx_u8m4_b2(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmadc_vvm_u8m8_b1(vuint8m8_t vs2, vuint8m8_t vs1, vbool1_t v0,
                                   size_t vl);
vbool1_t __riscv_vmadc_vxm_u8m8_b1(vuint8m8_t vs2, uint8_t rs1, vbool1_t v0,
                                   size_t vl);
vbool1_t __riscv_vmadc_vv_u8m8_b1(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmadc_vx_u8m8_b1(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmadc_vvm_u16mf4_b64(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vxm_u16mf4_b64(vuint16mf4_t vs2, uint16_t rs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vv_u16mf4_b64(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmadc_vx_u16mf4_b64(vuint16mf4_t vs2, uint16_t rs1,
                                      size_t vl);
vbool32_t __riscv_vmadc_vvm_u16mf2_b32(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                       vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vxm_u16mf2_b32(vuint16mf2_t vs2, uint16_t rs1,
                                       vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vv_u16mf2_b32(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmadc_vx_u16mf2_b32(vuint16mf2_t vs2, uint16_t rs1,
                                      size_t vl);
vbool16_t __riscv_vmadc_vvm_u16m1_b16(vuint16m1_t vs2, vuint16m1_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vxm_u16m1_b16(vuint16m1_t vs2, uint16_t rs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vv_u16m1_b16(vuint16m1_t vs2, vuint16m1_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmadc_vx_u16m1_b16(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmadc_vvm_u16m2_b8(vuint16m2_t vs2, vuint16m2_t vs1,
                                    vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc_vxm_u16m2_b8(vuint16m2_t vs2, uint16_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmadc_vv_u16m2_b8(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmadc_vx_u16m2_b8(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmadc_vvm_u16m4_b4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc_vxm_u16m4_b4(vuint16m4_t vs2, uint16_t rs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmadc_vv_u16m4_b4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmadc_vx_u16m4_b4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmadc_vvm_u16m8_b2(vuint16m8_t vs2, vuint16m8_t vs1,
                                    vbool2_t v0, size_t vl);
vbool2_t __riscv_vmadc_vxm_u16m8_b2(vuint16m8_t vs2, uint16_t rs1, vbool2_t v0,
                                    size_t vl);
vbool2_t __riscv_vmadc_vv_u16m8_b2(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmadc_vx_u16m8_b2(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmadc_vvm_u32mf2_b64(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vxm_u32mf2_b64(vuint32mf2_t vs2, uint32_t rs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vv_u32mf2_b64(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmadc_vx_u32mf2_b64(vuint32mf2_t vs2, uint32_t rs1,
                                      size_t vl);
vbool32_t __riscv_vmadc_vvm_u32m1_b32(vuint32m1_t vs2, vuint32m1_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vxm_u32m1_b32(vuint32m1_t vs2, uint32_t rs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vv_u32m1_b32(vuint32m1_t vs2, vuint32m1_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmadc_vx_u32m1_b32(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmadc_vvm_u32m2_b16(vuint32m2_t vs2, vuint32m2_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vxm_u32m2_b16(vuint32m2_t vs2, uint32_t rs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vv_u32m2_b16(vuint32m2_t vs2, vuint32m2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmadc_vx_u32m2_b16(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmadc_vvm_u32m4_b8(vuint32m4_t vs2, vuint32m4_t vs1,
                                    vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc_vxm_u32m4_b8(vuint32m4_t vs2, uint32_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmadc_vv_u32m4_b8(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmadc_vx_u32m4_b8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmadc_vvm_u32m8_b4(vuint32m8_t vs2, vuint32m8_t vs1,
                                    vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc_vxm_u32m8_b4(vuint32m8_t vs2, uint32_t rs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmadc_vv_u32m8_b4(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmadc_vx_u32m8_b4(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmadc_vvm_u64m1_b64(vuint64m1_t vs2, vuint64m1_t vs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vxm_u64m1_b64(vuint64m1_t vs2, uint64_t rs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc_vv_u64m1_b64(vuint64m1_t vs2, vuint64m1_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmadc_vx_u64m1_b64(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmadc_vvm_u64m2_b32(vuint64m2_t vs2, vuint64m2_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vxm_u64m2_b32(vuint64m2_t vs2, uint64_t rs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc_vv_u64m2_b32(vuint64m2_t vs2, vuint64m2_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmadc_vx_u64m2_b32(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmadc_vvm_u64m4_b16(vuint64m4_t vs2, vuint64m4_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vxm_u64m4_b16(vuint64m4_t vs2, uint64_t rs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc_vv_u64m4_b16(vuint64m4_t vs2, vuint64m4_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmadc_vx_u64m4_b16(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmadc_vvm_u64m8_b8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc_vxm_u64m8_b8(vuint64m8_t vs2, uint64_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmadc_vv_u64m8_b8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmadc_vx_u64m8_b8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsbc_vvm_u8mf8_b64(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vxm_u8mf8_b64(vuint8mf8_t vs2, uint8_t rs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vv_u8mf8_b64(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmsbc_vx_u8mf8_b64(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsbc_vvm_u8mf4_b32(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vxm_u8mf4_b32(vuint8mf4_t vs2, uint8_t rs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vv_u8mf4_b32(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmsbc_vx_u8mf4_b32(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsbc_vvm_u8mf2_b16(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vxm_u8mf2_b16(vuint8mf2_t vs2, uint8_t rs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vv_u8mf2_b16(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmsbc_vx_u8mf2_b16(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsbc_vvm_u8m1_b8(vuint8m1_t vs2, vuint8m1_t vs1, vbool8_t v0,
                                   size_t vl);
vbool8_t __riscv_vmsbc_vxm_u8m1_b8(vuint8m1_t vs2, uint8_t rs1, vbool8_t v0,
                                   size_t vl);
vbool8_t __riscv_vmsbc_vv_u8m1_b8(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsbc_vx_u8m1_b8(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsbc_vvm_u8m2_b4(vuint8m2_t vs2, vuint8m2_t vs1, vbool4_t v0,
                                   size_t vl);
vbool4_t __riscv_vmsbc_vxm_u8m2_b4(vuint8m2_t vs2, uint8_t rs1, vbool4_t v0,
                                   size_t vl);
vbool4_t __riscv_vmsbc_vv_u8m2_b4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsbc_vx_u8m2_b4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsbc_vvm_u8m4_b2(vuint8m4_t vs2, vuint8m4_t vs1, vbool2_t v0,
                                   size_t vl);
vbool2_t __riscv_vmsbc_vxm_u8m4_b2(vuint8m4_t vs2, uint8_t rs1, vbool2_t v0,
                                   size_t vl);
vbool2_t __riscv_vmsbc_vv_u8m4_b2(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsbc_vx_u8m4_b2(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsbc_vvm_u8m8_b1(vuint8m8_t vs2, vuint8m8_t vs1, vbool1_t v0,
                                   size_t vl);
vbool1_t __riscv_vmsbc_vxm_u8m8_b1(vuint8m8_t vs2, uint8_t rs1, vbool1_t v0,
                                   size_t vl);
vbool1_t __riscv_vmsbc_vv_u8m8_b1(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsbc_vx_u8m8_b1(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsbc_vvm_u16mf4_b64(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vxm_u16mf4_b64(vuint16mf4_t vs2, uint16_t rs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vv_u16mf4_b64(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsbc_vx_u16mf4_b64(vuint16mf4_t vs2, uint16_t rs1,
                                      size_t vl);
vbool32_t __riscv_vmsbc_vvm_u16mf2_b32(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                       vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vxm_u16mf2_b32(vuint16mf2_t vs2, uint16_t rs1,
                                       vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vv_u16mf2_b32(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsbc_vx_u16mf2_b32(vuint16mf2_t vs2, uint16_t rs1,
                                      size_t vl);
vbool16_t __riscv_vmsbc_vvm_u16m1_b16(vuint16m1_t vs2, vuint16m1_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vxm_u16m1_b16(vuint16m1_t vs2, uint16_t rs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vv_u16m1_b16(vuint16m1_t vs2, vuint16m1_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmsbc_vx_u16m1_b16(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsbc_vvm_u16m2_b8(vuint16m2_t vs2, vuint16m2_t vs1,
                                    vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc_vxm_u16m2_b8(vuint16m2_t vs2, uint16_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmsbc_vv_u16m2_b8(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsbc_vx_u16m2_b8(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsbc_vvm_u16m4_b4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc_vxm_u16m4_b4(vuint16m4_t vs2, uint16_t rs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmsbc_vv_u16m4_b4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsbc_vx_u16m4_b4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsbc_vvm_u16m8_b2(vuint16m8_t vs2, vuint16m8_t vs1,
                                    vbool2_t v0, size_t vl);
vbool2_t __riscv_vmsbc_vxm_u16m8_b2(vuint16m8_t vs2, uint16_t rs1, vbool2_t v0,
                                    size_t vl);
vbool2_t __riscv_vmsbc_vv_u16m8_b2(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsbc_vx_u16m8_b2(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsbc_vvm_u32mf2_b64(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vxm_u32mf2_b64(vuint32mf2_t vs2, uint32_t rs1,
                                       vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vv_u32mf2_b64(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsbc_vx_u32mf2_b64(vuint32mf2_t vs2, uint32_t rs1,
                                      size_t vl);
vbool32_t __riscv_vmsbc_vvm_u32m1_b32(vuint32m1_t vs2, vuint32m1_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vxm_u32m1_b32(vuint32m1_t vs2, uint32_t rs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vv_u32m1_b32(vuint32m1_t vs2, vuint32m1_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmsbc_vx_u32m1_b32(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsbc_vvm_u32m2_b16(vuint32m2_t vs2, vuint32m2_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vxm_u32m2_b16(vuint32m2_t vs2, uint32_t rs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vv_u32m2_b16(vuint32m2_t vs2, vuint32m2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmsbc_vx_u32m2_b16(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsbc_vvm_u32m4_b8(vuint32m4_t vs2, vuint32m4_t vs1,
                                    vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc_vxm_u32m4_b8(vuint32m4_t vs2, uint32_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmsbc_vv_u32m4_b8(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsbc_vx_u32m4_b8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsbc_vvm_u32m8_b4(vuint32m8_t vs2, vuint32m8_t vs1,
                                    vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc_vxm_u32m8_b4(vuint32m8_t vs2, uint32_t rs1, vbool4_t v0,
                                    size_t vl);
vbool4_t __riscv_vmsbc_vv_u32m8_b4(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsbc_vx_u32m8_b4(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsbc_vvm_u64m1_b64(vuint64m1_t vs2, vuint64m1_t vs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vxm_u64m1_b64(vuint64m1_t vs2, uint64_t rs1,
                                      vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc_vv_u64m1_b64(vuint64m1_t vs2, vuint64m1_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmsbc_vx_u64m1_b64(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsbc_vvm_u64m2_b32(vuint64m2_t vs2, vuint64m2_t vs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vxm_u64m2_b32(vuint64m2_t vs2, uint64_t rs1,
                                      vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc_vv_u64m2_b32(vuint64m2_t vs2, vuint64m2_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmsbc_vx_u64m2_b32(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsbc_vvm_u64m4_b16(vuint64m4_t vs2, vuint64m4_t vs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vxm_u64m4_b16(vuint64m4_t vs2, uint64_t rs1,
                                      vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc_vv_u64m4_b16(vuint64m4_t vs2, vuint64m4_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmsbc_vx_u64m4_b16(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsbc_vvm_u64m8_b8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc_vxm_u64m8_b8(vuint64m8_t vs2, uint64_t rs1, vbool8_t v0,
                                    size_t vl);
vbool8_t __riscv_vmsbc_vv_u64m8_b8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsbc_vx_u64m8_b8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
----

[[vector-bitwise-binary-logical]]
==== Vector Bitwise Binary Logical Intrinsics

[,c]
----
vint8mf8_t __riscv_vand_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vand_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vand_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vand_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vand_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vand_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vand_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vand_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vand_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vand_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vand_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vand_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vand_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vand_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vand_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vand_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vand_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vand_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vand_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vand_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vand_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vand_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vand_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vand_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vand_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vand_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vand_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vand_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vand_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vand_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vand_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vand_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vand_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vand_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vand_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vand_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vand_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vand_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vand_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vand_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vand_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vand_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vand_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vand_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vor_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vor_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vor_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vor_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vor_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vor_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vor_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vor_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vor_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vor_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vor_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vor_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vor_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vor_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vor_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vor_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vor_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vor_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vor_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vor_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vor_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vor_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vor_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vor_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vor_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vor_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vor_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vor_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vor_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vor_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vor_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vor_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vor_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vor_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vor_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vor_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vor_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vor_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vor_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vor_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vor_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vor_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vor_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vor_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vxor_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vxor_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vxor_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vxor_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vxor_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vxor_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vxor_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vxor_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vxor_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vxor_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vxor_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vxor_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vxor_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vxor_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vxor_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vxor_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vxor_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vxor_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vxor_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vxor_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vxor_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vxor_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vxor_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vxor_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vxor_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vxor_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vxor_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vxor_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vxor_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vxor_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vxor_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vxor_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vxor_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vxor_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vxor_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vxor_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vxor_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vxor_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vxor_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vxor_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vxor_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vxor_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vxor_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vxor_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vand_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vand_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vand_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vand_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vand_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vand_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vand_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vand_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vand_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vand_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vand_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vand_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vand_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vand_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vand_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                    size_t vl);
vuint16mf4_t __riscv_vand_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vand_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint16mf2_t __riscv_vand_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vand_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vand_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vand_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vand_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vand_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vand_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vand_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vand_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vand_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint32mf2_t __riscv_vand_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vand_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vand_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vand_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vand_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vand_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vand_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vand_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vand_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vand_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vand_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vand_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vand_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vand_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vand_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vand_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vand_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vor_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vor_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vor_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vor_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vor_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vor_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vor_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vor_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vor_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vor_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vor_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vor_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vor_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vor_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vor_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                   size_t vl);
vuint16mf4_t __riscv_vor_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vor_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                   size_t vl);
vuint16mf2_t __riscv_vor_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vor_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vor_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vor_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vor_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vor_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vor_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vor_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vor_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vor_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                   size_t vl);
vuint32mf2_t __riscv_vor_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vor_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vor_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vor_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vor_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vor_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vor_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vor_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vor_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vor_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vor_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vor_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vor_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vor_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vor_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vor_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vor_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vxor_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vxor_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vxor_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vxor_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vxor_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vxor_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vxor_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vxor_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vxor_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vxor_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vxor_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vxor_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vxor_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vxor_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vxor_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                    size_t vl);
vuint16mf4_t __riscv_vxor_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vxor_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint16mf2_t __riscv_vxor_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vxor_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vxor_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vxor_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vxor_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vxor_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vxor_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vxor_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vxor_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vxor_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint32mf2_t __riscv_vxor_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vxor_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vxor_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vxor_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vxor_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vxor_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vxor_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vxor_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vxor_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vxor_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vxor_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vxor_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vxor_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vxor_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vxor_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vxor_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vxor_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vand_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                                   size_t vl);
vint8mf8_t __riscv_vand_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vand_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                                   size_t vl);
vint8mf4_t __riscv_vand_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vand_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                                   size_t vl);
vint8mf2_t __riscv_vand_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vand_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vand_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vand_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vand_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vand_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vand_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vand_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vand_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vand_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vand_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vand_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vand_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vand_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                                   size_t vl);
vint16m1_t __riscv_vand_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vand_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vand_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vand_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vand_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vand_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vand_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vand_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vand_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vand_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                                   size_t vl);
vint32m1_t __riscv_vand_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vand_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                                   size_t vl);
vint32m2_t __riscv_vand_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vand_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vand_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vand_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vand_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vand_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                                   size_t vl);
vint64m1_t __riscv_vand_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vand_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                                   size_t vl);
vint64m2_t __riscv_vand_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vand_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                                   size_t vl);
vint64m4_t __riscv_vand_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vand_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vand_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                   size_t vl);
vint8mf8_t __riscv_vor_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                                  size_t vl);
vint8mf8_t __riscv_vor_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                  size_t vl);
vint8mf4_t __riscv_vor_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                                  size_t vl);
vint8mf4_t __riscv_vor_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                  size_t vl);
vint8mf2_t __riscv_vor_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                                  size_t vl);
vint8mf2_t __riscv_vor_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                  size_t vl);
vint8m1_t __riscv_vor_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                size_t vl);
vint8m1_t __riscv_vor_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                size_t vl);
vint8m2_t __riscv_vor_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                size_t vl);
vint8m2_t __riscv_vor_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                size_t vl);
vint8m4_t __riscv_vor_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                size_t vl);
vint8m4_t __riscv_vor_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                size_t vl);
vint8m8_t __riscv_vor_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                size_t vl);
vint8m8_t __riscv_vor_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                size_t vl);
vint16mf4_t __riscv_vor_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                    vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vor_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                                    size_t vl);
vint16mf2_t __riscv_vor_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                    vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vor_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                    size_t vl);
vint16m1_t __riscv_vor_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                                  size_t vl);
vint16m1_t __riscv_vor_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                  size_t vl);
vint16m2_t __riscv_vor_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                  size_t vl);
vint16m2_t __riscv_vor_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                  size_t vl);
vint16m4_t __riscv_vor_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                  size_t vl);
vint16m4_t __riscv_vor_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                  size_t vl);
vint16m8_t __riscv_vor_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                  size_t vl);
vint16m8_t __riscv_vor_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                  size_t vl);
vint32mf2_t __riscv_vor_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                    vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vor_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                    size_t vl);
vint32m1_t __riscv_vor_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                                  size_t vl);
vint32m1_t __riscv_vor_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                  size_t vl);
vint32m2_t __riscv_vor_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                                  size_t vl);
vint32m2_t __riscv_vor_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                  size_t vl);
vint32m4_t __riscv_vor_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                  size_t vl);
vint32m4_t __riscv_vor_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                  size_t vl);
vint32m8_t __riscv_vor_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                  size_t vl);
vint32m8_t __riscv_vor_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                  size_t vl);
vint64m1_t __riscv_vor_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                                  size_t vl);
vint64m1_t __riscv_vor_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                  size_t vl);
vint64m2_t __riscv_vor_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                                  size_t vl);
vint64m2_t __riscv_vor_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                  size_t vl);
vint64m4_t __riscv_vor_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                                  size_t vl);
vint64m4_t __riscv_vor_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                  size_t vl);
vint64m8_t __riscv_vor_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                  size_t vl);
vint64m8_t __riscv_vor_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                  size_t vl);
vint8mf8_t __riscv_vxor_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                                   size_t vl);
vint8mf8_t __riscv_vxor_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vxor_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                                   size_t vl);
vint8mf4_t __riscv_vxor_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vxor_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                                   size_t vl);
vint8mf2_t __riscv_vxor_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vxor_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vxor_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vxor_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vxor_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vxor_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vxor_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vxor_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vxor_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vxor_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vxor_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vxor_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vxor_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vxor_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                                   size_t vl);
vint16m1_t __riscv_vxor_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vxor_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vxor_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vxor_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vxor_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vxor_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vxor_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vxor_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vxor_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vxor_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                                   size_t vl);
vint32m1_t __riscv_vxor_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vxor_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                                   size_t vl);
vint32m2_t __riscv_vxor_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vxor_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vxor_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vxor_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vxor_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vxor_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                                   size_t vl);
vint64m1_t __riscv_vxor_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vxor_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                                   size_t vl);
vint64m2_t __riscv_vxor_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vxor_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                                   size_t vl);
vint64m4_t __riscv_vxor_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vxor_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vxor_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                   size_t vl);
vuint8mf8_t __riscv_vand_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                    vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vand_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8mf4_t __riscv_vand_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                    vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vand_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8mf2_t __riscv_vand_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                    vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vand_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m1_t __riscv_vand_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                  size_t vl);
vuint8m1_t __riscv_vand_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m2_t __riscv_vand_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                  size_t vl);
vuint8m2_t __riscv_vand_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m4_t __riscv_vand_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                  size_t vl);
vuint8m4_t __riscv_vand_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m8_t __riscv_vand_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                  size_t vl);
vuint8m8_t __riscv_vand_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                  size_t vl);
vuint16mf4_t __riscv_vand_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vand_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vand_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vand_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vand_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                    vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vand_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m2_t __riscv_vand_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                    vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vand_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m4_t __riscv_vand_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                    vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vand_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m8_t __riscv_vand_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                    vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vand_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                    size_t vl);
vuint32mf2_t __riscv_vand_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vand_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vand_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                    vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vand_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m2_t __riscv_vand_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                    vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vand_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m4_t __riscv_vand_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                    vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vand_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m8_t __riscv_vand_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                    vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vand_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                    size_t vl);
vuint64m1_t __riscv_vand_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                    vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vand_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m2_t __riscv_vand_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                    vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vand_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m4_t __riscv_vand_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                    vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vand_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m8_t __riscv_vand_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                    vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vand_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                    size_t vl);
vuint8mf8_t __riscv_vor_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                   vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vor_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8mf4_t __riscv_vor_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                   vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vor_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8mf2_t __riscv_vor_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                   vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vor_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m1_t __riscv_vor_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                 size_t vl);
vuint8m1_t __riscv_vor_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                 size_t vl);
vuint8m2_t __riscv_vor_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                 size_t vl);
vuint8m2_t __riscv_vor_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                 size_t vl);
vuint8m4_t __riscv_vor_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                 size_t vl);
vuint8m4_t __riscv_vor_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                 size_t vl);
vuint8m8_t __riscv_vor_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                 size_t vl);
vuint8m8_t __riscv_vor_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                 size_t vl);
vuint16mf4_t __riscv_vor_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                     vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vor_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                     uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vor_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                     vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vor_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                     uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vor_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                   vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vor_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                                   size_t vl);
vuint16m2_t __riscv_vor_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                   vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vor_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                   size_t vl);
vuint16m4_t __riscv_vor_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                   vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vor_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                   size_t vl);
vuint16m8_t __riscv_vor_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                   vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vor_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                   size_t vl);
vuint32mf2_t __riscv_vor_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                     vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vor_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vor_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                   vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vor_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                                   size_t vl);
vuint32m2_t __riscv_vor_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                   vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vor_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                                   size_t vl);
vuint32m4_t __riscv_vor_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                   vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vor_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                   size_t vl);
vuint32m8_t __riscv_vor_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                   vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vor_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                   size_t vl);
vuint64m1_t __riscv_vor_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                   vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vor_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                                   size_t vl);
vuint64m2_t __riscv_vor_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                   vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vor_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                                   size_t vl);
vuint64m4_t __riscv_vor_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                   vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vor_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                                   size_t vl);
vuint64m8_t __riscv_vor_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                   vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vor_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                   size_t vl);
vuint8mf8_t __riscv_vxor_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                    vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vxor_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8mf4_t __riscv_vxor_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                    vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vxor_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8mf2_t __riscv_vxor_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                    vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vxor_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m1_t __riscv_vxor_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                  size_t vl);
vuint8m1_t __riscv_vxor_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m2_t __riscv_vxor_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                  size_t vl);
vuint8m2_t __riscv_vxor_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m4_t __riscv_vxor_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                  size_t vl);
vuint8m4_t __riscv_vxor_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m8_t __riscv_vxor_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                  size_t vl);
vuint8m8_t __riscv_vxor_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                  size_t vl);
vuint16mf4_t __riscv_vxor_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vxor_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vxor_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vxor_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vxor_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                    vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vxor_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m2_t __riscv_vxor_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                    vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vxor_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m4_t __riscv_vxor_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                    vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vxor_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m8_t __riscv_vxor_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                    vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vxor_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                    size_t vl);
vuint32mf2_t __riscv_vxor_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vxor_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vxor_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                    vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vxor_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m2_t __riscv_vxor_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                    vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vxor_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m4_t __riscv_vxor_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                    vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vxor_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m8_t __riscv_vxor_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                    vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vxor_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                    size_t vl);
vuint64m1_t __riscv_vxor_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                    vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vxor_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m2_t __riscv_vxor_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                    vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vxor_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m4_t __riscv_vxor_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                    vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vxor_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m8_t __riscv_vxor_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                    vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vxor_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                    size_t vl);
----

[[vector-bitwise-unary-logical]]
==== Vector Bitwise Unary Logical Intrinsics

[,c]
----
vint8mf8_t __riscv_vnot_v_i8mf8(vint8mf8_t vs, size_t vl);
vint8mf4_t __riscv_vnot_v_i8mf4(vint8mf4_t vs, size_t vl);
vint8mf2_t __riscv_vnot_v_i8mf2(vint8mf2_t vs, size_t vl);
vint8m1_t __riscv_vnot_v_i8m1(vint8m1_t vs, size_t vl);
vint8m2_t __riscv_vnot_v_i8m2(vint8m2_t vs, size_t vl);
vint8m4_t __riscv_vnot_v_i8m4(vint8m4_t vs, size_t vl);
vint8m8_t __riscv_vnot_v_i8m8(vint8m8_t vs, size_t vl);
vint16mf4_t __riscv_vnot_v_i16mf4(vint16mf4_t vs, size_t vl);
vint16mf2_t __riscv_vnot_v_i16mf2(vint16mf2_t vs, size_t vl);
vint16m1_t __riscv_vnot_v_i16m1(vint16m1_t vs, size_t vl);
vint16m2_t __riscv_vnot_v_i16m2(vint16m2_t vs, size_t vl);
vint16m4_t __riscv_vnot_v_i16m4(vint16m4_t vs, size_t vl);
vint16m8_t __riscv_vnot_v_i16m8(vint16m8_t vs, size_t vl);
vint32mf2_t __riscv_vnot_v_i32mf2(vint32mf2_t vs, size_t vl);
vint32m1_t __riscv_vnot_v_i32m1(vint32m1_t vs, size_t vl);
vint32m2_t __riscv_vnot_v_i32m2(vint32m2_t vs, size_t vl);
vint32m4_t __riscv_vnot_v_i32m4(vint32m4_t vs, size_t vl);
vint32m8_t __riscv_vnot_v_i32m8(vint32m8_t vs, size_t vl);
vint64m1_t __riscv_vnot_v_i64m1(vint64m1_t vs, size_t vl);
vint64m2_t __riscv_vnot_v_i64m2(vint64m2_t vs, size_t vl);
vint64m4_t __riscv_vnot_v_i64m4(vint64m4_t vs, size_t vl);
vint64m8_t __riscv_vnot_v_i64m8(vint64m8_t vs, size_t vl);
vuint8mf8_t __riscv_vnot_v_u8mf8(vuint8mf8_t vs, size_t vl);
vuint8mf4_t __riscv_vnot_v_u8mf4(vuint8mf4_t vs, size_t vl);
vuint8mf2_t __riscv_vnot_v_u8mf2(vuint8mf2_t vs, size_t vl);
vuint8m1_t __riscv_vnot_v_u8m1(vuint8m1_t vs, size_t vl);
vuint8m2_t __riscv_vnot_v_u8m2(vuint8m2_t vs, size_t vl);
vuint8m4_t __riscv_vnot_v_u8m4(vuint8m4_t vs, size_t vl);
vuint8m8_t __riscv_vnot_v_u8m8(vuint8m8_t vs, size_t vl);
vuint16mf4_t __riscv_vnot_v_u16mf4(vuint16mf4_t vs, size_t vl);
vuint16mf2_t __riscv_vnot_v_u16mf2(vuint16mf2_t vs, size_t vl);
vuint16m1_t __riscv_vnot_v_u16m1(vuint16m1_t vs, size_t vl);
vuint16m2_t __riscv_vnot_v_u16m2(vuint16m2_t vs, size_t vl);
vuint16m4_t __riscv_vnot_v_u16m4(vuint16m4_t vs, size_t vl);
vuint16m8_t __riscv_vnot_v_u16m8(vuint16m8_t vs, size_t vl);
vuint32mf2_t __riscv_vnot_v_u32mf2(vuint32mf2_t vs, size_t vl);
vuint32m1_t __riscv_vnot_v_u32m1(vuint32m1_t vs, size_t vl);
vuint32m2_t __riscv_vnot_v_u32m2(vuint32m2_t vs, size_t vl);
vuint32m4_t __riscv_vnot_v_u32m4(vuint32m4_t vs, size_t vl);
vuint32m8_t __riscv_vnot_v_u32m8(vuint32m8_t vs, size_t vl);
vuint64m1_t __riscv_vnot_v_u64m1(vuint64m1_t vs, size_t vl);
vuint64m2_t __riscv_vnot_v_u64m2(vuint64m2_t vs, size_t vl);
vuint64m4_t __riscv_vnot_v_u64m4(vuint64m4_t vs, size_t vl);
vuint64m8_t __riscv_vnot_v_u64m8(vuint64m8_t vs, size_t vl);
// masked functions
vint8mf8_t __riscv_vnot_v_i8mf8_m(vbool64_t vm, vint8mf8_t vs, size_t vl);
vint8mf4_t __riscv_vnot_v_i8mf4_m(vbool32_t vm, vint8mf4_t vs, size_t vl);
vint8mf2_t __riscv_vnot_v_i8mf2_m(vbool16_t vm, vint8mf2_t vs, size_t vl);
vint8m1_t __riscv_vnot_v_i8m1_m(vbool8_t vm, vint8m1_t vs, size_t vl);
vint8m2_t __riscv_vnot_v_i8m2_m(vbool4_t vm, vint8m2_t vs, size_t vl);
vint8m4_t __riscv_vnot_v_i8m4_m(vbool2_t vm, vint8m4_t vs, size_t vl);
vint8m8_t __riscv_vnot_v_i8m8_m(vbool1_t vm, vint8m8_t vs, size_t vl);
vint16mf4_t __riscv_vnot_v_i16mf4_m(vbool64_t vm, vint16mf4_t vs, size_t vl);
vint16mf2_t __riscv_vnot_v_i16mf2_m(vbool32_t vm, vint16mf2_t vs, size_t vl);
vint16m1_t __riscv_vnot_v_i16m1_m(vbool16_t vm, vint16m1_t vs, size_t vl);
vint16m2_t __riscv_vnot_v_i16m2_m(vbool8_t vm, vint16m2_t vs, size_t vl);
vint16m4_t __riscv_vnot_v_i16m4_m(vbool4_t vm, vint16m4_t vs, size_t vl);
vint16m8_t __riscv_vnot_v_i16m8_m(vbool2_t vm, vint16m8_t vs, size_t vl);
vint32mf2_t __riscv_vnot_v_i32mf2_m(vbool64_t vm, vint32mf2_t vs, size_t vl);
vint32m1_t __riscv_vnot_v_i32m1_m(vbool32_t vm, vint32m1_t vs, size_t vl);
vint32m2_t __riscv_vnot_v_i32m2_m(vbool16_t vm, vint32m2_t vs, size_t vl);
vint32m4_t __riscv_vnot_v_i32m4_m(vbool8_t vm, vint32m4_t vs, size_t vl);
vint32m8_t __riscv_vnot_v_i32m8_m(vbool4_t vm, vint32m8_t vs, size_t vl);
vint64m1_t __riscv_vnot_v_i64m1_m(vbool64_t vm, vint64m1_t vs, size_t vl);
vint64m2_t __riscv_vnot_v_i64m2_m(vbool32_t vm, vint64m2_t vs, size_t vl);
vint64m4_t __riscv_vnot_v_i64m4_m(vbool16_t vm, vint64m4_t vs, size_t vl);
vint64m8_t __riscv_vnot_v_i64m8_m(vbool8_t vm, vint64m8_t vs, size_t vl);
vuint8mf8_t __riscv_vnot_v_u8mf8_m(vbool64_t vm, vuint8mf8_t vs, size_t vl);
vuint8mf4_t __riscv_vnot_v_u8mf4_m(vbool32_t vm, vuint8mf4_t vs, size_t vl);
vuint8mf2_t __riscv_vnot_v_u8mf2_m(vbool16_t vm, vuint8mf2_t vs, size_t vl);
vuint8m1_t __riscv_vnot_v_u8m1_m(vbool8_t vm, vuint8m1_t vs, size_t vl);
vuint8m2_t __riscv_vnot_v_u8m2_m(vbool4_t vm, vuint8m2_t vs, size_t vl);
vuint8m4_t __riscv_vnot_v_u8m4_m(vbool2_t vm, vuint8m4_t vs, size_t vl);
vuint8m8_t __riscv_vnot_v_u8m8_m(vbool1_t vm, vuint8m8_t vs, size_t vl);
vuint16mf4_t __riscv_vnot_v_u16mf4_m(vbool64_t vm, vuint16mf4_t vs, size_t vl);
vuint16mf2_t __riscv_vnot_v_u16mf2_m(vbool32_t vm, vuint16mf2_t vs, size_t vl);
vuint16m1_t __riscv_vnot_v_u16m1_m(vbool16_t vm, vuint16m1_t vs, size_t vl);
vuint16m2_t __riscv_vnot_v_u16m2_m(vbool8_t vm, vuint16m2_t vs, size_t vl);
vuint16m4_t __riscv_vnot_v_u16m4_m(vbool4_t vm, vuint16m4_t vs, size_t vl);
vuint16m8_t __riscv_vnot_v_u16m8_m(vbool2_t vm, vuint16m8_t vs, size_t vl);
vuint32mf2_t __riscv_vnot_v_u32mf2_m(vbool64_t vm, vuint32mf2_t vs, size_t vl);
vuint32m1_t __riscv_vnot_v_u32m1_m(vbool32_t vm, vuint32m1_t vs, size_t vl);
vuint32m2_t __riscv_vnot_v_u32m2_m(vbool16_t vm, vuint32m2_t vs, size_t vl);
vuint32m4_t __riscv_vnot_v_u32m4_m(vbool8_t vm, vuint32m4_t vs, size_t vl);
vuint32m8_t __riscv_vnot_v_u32m8_m(vbool4_t vm, vuint32m8_t vs, size_t vl);
vuint64m1_t __riscv_vnot_v_u64m1_m(vbool64_t vm, vuint64m1_t vs, size_t vl);
vuint64m2_t __riscv_vnot_v_u64m2_m(vbool32_t vm, vuint64m2_t vs, size_t vl);
vuint64m4_t __riscv_vnot_v_u64m4_m(vbool16_t vm, vuint64m4_t vs, size_t vl);
vuint64m8_t __riscv_vnot_v_u64m8_m(vbool8_t vm, vuint64m8_t vs, size_t vl);
----

[[vector-single-width-bit-shift]]
==== Vector Single-Width Bit Shift Intrinsics

[,c]
----
vint8mf8_t __riscv_vsll_vv_i8mf8(vint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vsll_vx_i8mf8(vint8mf8_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vsll_vv_i8mf4(vint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vsll_vx_i8mf4(vint8mf4_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vsll_vv_i8mf2(vint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vsll_vx_i8mf2(vint8mf2_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vsll_vv_i8m1(vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vsll_vx_i8m1(vint8m1_t vs2, size_t rs1, size_t vl);
vint8m2_t __riscv_vsll_vv_i8m2(vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vsll_vx_i8m2(vint8m2_t vs2, size_t rs1, size_t vl);
vint8m4_t __riscv_vsll_vv_i8m4(vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vsll_vx_i8m4(vint8m4_t vs2, size_t rs1, size_t vl);
vint8m8_t __riscv_vsll_vv_i8m8(vint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vsll_vx_i8m8(vint8m8_t vs2, size_t rs1, size_t vl);
vint16mf4_t __riscv_vsll_vv_i16mf4(vint16mf4_t vs2, vuint16mf4_t vs1,
                                   size_t vl);
vint16mf4_t __riscv_vsll_vx_i16mf4(vint16mf4_t vs2, size_t rs1, size_t vl);
vint16mf2_t __riscv_vsll_vv_i16mf2(vint16mf2_t vs2, vuint16mf2_t vs1,
                                   size_t vl);
vint16mf2_t __riscv_vsll_vx_i16mf2(vint16mf2_t vs2, size_t rs1, size_t vl);
vint16m1_t __riscv_vsll_vv_i16m1(vint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vsll_vx_i16m1(vint16m1_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vsll_vv_i16m2(vint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vsll_vx_i16m2(vint16m2_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vsll_vv_i16m4(vint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vsll_vx_i16m4(vint16m4_t vs2, size_t rs1, size_t vl);
vint16m8_t __riscv_vsll_vv_i16m8(vint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vsll_vx_i16m8(vint16m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vsll_vv_i32mf2(vint32mf2_t vs2, vuint32mf2_t vs1,
                                   size_t vl);
vint32mf2_t __riscv_vsll_vx_i32mf2(vint32mf2_t vs2, size_t rs1, size_t vl);
vint32m1_t __riscv_vsll_vv_i32m1(vint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vsll_vx_i32m1(vint32m1_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vsll_vv_i32m2(vint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vsll_vx_i32m2(vint32m2_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vsll_vv_i32m4(vint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vsll_vx_i32m4(vint32m4_t vs2, size_t rs1, size_t vl);
vint32m8_t __riscv_vsll_vv_i32m8(vint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vsll_vx_i32m8(vint32m8_t vs2, size_t rs1, size_t vl);
vint64m1_t __riscv_vsll_vv_i64m1(vint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vsll_vx_i64m1(vint64m1_t vs2, size_t rs1, size_t vl);
vint64m2_t __riscv_vsll_vv_i64m2(vint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vsll_vx_i64m2(vint64m2_t vs2, size_t rs1, size_t vl);
vint64m4_t __riscv_vsll_vv_i64m4(vint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vsll_vx_i64m4(vint64m4_t vs2, size_t rs1, size_t vl);
vint64m8_t __riscv_vsll_vv_i64m8(vint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vsll_vx_i64m8(vint64m8_t vs2, size_t rs1, size_t vl);
vint8mf8_t __riscv_vsra_vv_i8mf8(vint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vsra_vx_i8mf8(vint8mf8_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vsra_vv_i8mf4(vint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vsra_vx_i8mf4(vint8mf4_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vsra_vv_i8mf2(vint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vsra_vx_i8mf2(vint8mf2_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vsra_vv_i8m1(vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vsra_vx_i8m1(vint8m1_t vs2, size_t rs1, size_t vl);
vint8m2_t __riscv_vsra_vv_i8m2(vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vsra_vx_i8m2(vint8m2_t vs2, size_t rs1, size_t vl);
vint8m4_t __riscv_vsra_vv_i8m4(vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vsra_vx_i8m4(vint8m4_t vs2, size_t rs1, size_t vl);
vint8m8_t __riscv_vsra_vv_i8m8(vint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vsra_vx_i8m8(vint8m8_t vs2, size_t rs1, size_t vl);
vint16mf4_t __riscv_vsra_vv_i16mf4(vint16mf4_t vs2, vuint16mf4_t vs1,
                                   size_t vl);
vint16mf4_t __riscv_vsra_vx_i16mf4(vint16mf4_t vs2, size_t rs1, size_t vl);
vint16mf2_t __riscv_vsra_vv_i16mf2(vint16mf2_t vs2, vuint16mf2_t vs1,
                                   size_t vl);
vint16mf2_t __riscv_vsra_vx_i16mf2(vint16mf2_t vs2, size_t rs1, size_t vl);
vint16m1_t __riscv_vsra_vv_i16m1(vint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vsra_vx_i16m1(vint16m1_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vsra_vv_i16m2(vint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vsra_vx_i16m2(vint16m2_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vsra_vv_i16m4(vint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vsra_vx_i16m4(vint16m4_t vs2, size_t rs1, size_t vl);
vint16m8_t __riscv_vsra_vv_i16m8(vint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vsra_vx_i16m8(vint16m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vsra_vv_i32mf2(vint32mf2_t vs2, vuint32mf2_t vs1,
                                   size_t vl);
vint32mf2_t __riscv_vsra_vx_i32mf2(vint32mf2_t vs2, size_t rs1, size_t vl);
vint32m1_t __riscv_vsra_vv_i32m1(vint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vsra_vx_i32m1(vint32m1_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vsra_vv_i32m2(vint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vsra_vx_i32m2(vint32m2_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vsra_vv_i32m4(vint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vsra_vx_i32m4(vint32m4_t vs2, size_t rs1, size_t vl);
vint32m8_t __riscv_vsra_vv_i32m8(vint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vsra_vx_i32m8(vint32m8_t vs2, size_t rs1, size_t vl);
vint64m1_t __riscv_vsra_vv_i64m1(vint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vsra_vx_i64m1(vint64m1_t vs2, size_t rs1, size_t vl);
vint64m2_t __riscv_vsra_vv_i64m2(vint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vsra_vx_i64m2(vint64m2_t vs2, size_t rs1, size_t vl);
vint64m4_t __riscv_vsra_vv_i64m4(vint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vsra_vx_i64m4(vint64m4_t vs2, size_t rs1, size_t vl);
vint64m8_t __riscv_vsra_vv_i64m8(vint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vsra_vx_i64m8(vint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vsll_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vsll_vx_u8mf8(vuint8mf8_t vs2, size_t rs1, size_t vl);
vuint8mf4_t __riscv_vsll_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vsll_vx_u8mf4(vuint8mf4_t vs2, size_t rs1, size_t vl);
vuint8mf2_t __riscv_vsll_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vsll_vx_u8mf2(vuint8mf2_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vsll_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vsll_vx_u8m1(vuint8m1_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vsll_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vsll_vx_u8m2(vuint8m2_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vsll_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vsll_vx_u8m4(vuint8m4_t vs2, size_t rs1, size_t vl);
vuint8m8_t __riscv_vsll_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vsll_vx_u8m8(vuint8m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vsll_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                    size_t vl);
vuint16mf4_t __riscv_vsll_vx_u16mf4(vuint16mf4_t vs2, size_t rs1, size_t vl);
vuint16mf2_t __riscv_vsll_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint16mf2_t __riscv_vsll_vx_u16mf2(vuint16mf2_t vs2, size_t rs1, size_t vl);
vuint16m1_t __riscv_vsll_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vsll_vx_u16m1(vuint16m1_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vsll_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vsll_vx_u16m2(vuint16m2_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vsll_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vsll_vx_u16m4(vuint16m4_t vs2, size_t rs1, size_t vl);
vuint16m8_t __riscv_vsll_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vsll_vx_u16m8(vuint16m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vsll_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint32mf2_t __riscv_vsll_vx_u32mf2(vuint32mf2_t vs2, size_t rs1, size_t vl);
vuint32m1_t __riscv_vsll_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vsll_vx_u32m1(vuint32m1_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vsll_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vsll_vx_u32m2(vuint32m2_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vsll_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vsll_vx_u32m4(vuint32m4_t vs2, size_t rs1, size_t vl);
vuint32m8_t __riscv_vsll_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vsll_vx_u32m8(vuint32m8_t vs2, size_t rs1, size_t vl);
vuint64m1_t __riscv_vsll_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vsll_vx_u64m1(vuint64m1_t vs2, size_t rs1, size_t vl);
vuint64m2_t __riscv_vsll_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vsll_vx_u64m2(vuint64m2_t vs2, size_t rs1, size_t vl);
vuint64m4_t __riscv_vsll_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vsll_vx_u64m4(vuint64m4_t vs2, size_t rs1, size_t vl);
vuint64m8_t __riscv_vsll_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vsll_vx_u64m8(vuint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vsrl_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vsrl_vx_u8mf8(vuint8mf8_t vs2, size_t rs1, size_t vl);
vuint8mf4_t __riscv_vsrl_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vsrl_vx_u8mf4(vuint8mf4_t vs2, size_t rs1, size_t vl);
vuint8mf2_t __riscv_vsrl_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vsrl_vx_u8mf2(vuint8mf2_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vsrl_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vsrl_vx_u8m1(vuint8m1_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vsrl_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vsrl_vx_u8m2(vuint8m2_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vsrl_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vsrl_vx_u8m4(vuint8m4_t vs2, size_t rs1, size_t vl);
vuint8m8_t __riscv_vsrl_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vsrl_vx_u8m8(vuint8m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vsrl_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                    size_t vl);
vuint16mf4_t __riscv_vsrl_vx_u16mf4(vuint16mf4_t vs2, size_t rs1, size_t vl);
vuint16mf2_t __riscv_vsrl_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint16mf2_t __riscv_vsrl_vx_u16mf2(vuint16mf2_t vs2, size_t rs1, size_t vl);
vuint16m1_t __riscv_vsrl_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vsrl_vx_u16m1(vuint16m1_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vsrl_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vsrl_vx_u16m2(vuint16m2_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vsrl_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vsrl_vx_u16m4(vuint16m4_t vs2, size_t rs1, size_t vl);
vuint16m8_t __riscv_vsrl_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vsrl_vx_u16m8(vuint16m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vsrl_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint32mf2_t __riscv_vsrl_vx_u32mf2(vuint32mf2_t vs2, size_t rs1, size_t vl);
vuint32m1_t __riscv_vsrl_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vsrl_vx_u32m1(vuint32m1_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vsrl_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vsrl_vx_u32m2(vuint32m2_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vsrl_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vsrl_vx_u32m4(vuint32m4_t vs2, size_t rs1, size_t vl);
vuint32m8_t __riscv_vsrl_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vsrl_vx_u32m8(vuint32m8_t vs2, size_t rs1, size_t vl);
vuint64m1_t __riscv_vsrl_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vsrl_vx_u64m1(vuint64m1_t vs2, size_t rs1, size_t vl);
vuint64m2_t __riscv_vsrl_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vsrl_vx_u64m2(vuint64m2_t vs2, size_t rs1, size_t vl);
vuint64m4_t __riscv_vsrl_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vsrl_vx_u64m4(vuint64m4_t vs2, size_t rs1, size_t vl);
vuint64m8_t __riscv_vsrl_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vsrl_vx_u64m8(vuint64m8_t vs2, size_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vsll_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                   vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vsll_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, size_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vsll_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                   vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vsll_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, size_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vsll_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                   vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vsll_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, size_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vsll_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vuint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vsll_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, size_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vsll_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vuint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vsll_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, size_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vsll_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vuint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vsll_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, size_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vsll_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vuint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vsll_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, size_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vsll_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vuint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vsll_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, size_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vsll_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vuint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vsll_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, size_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vsll_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                   vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vsll_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, size_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vsll_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vuint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vsll_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, size_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vsll_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vuint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vsll_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, size_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vsll_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vuint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vsll_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, size_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vsll_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vuint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vsll_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, size_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vsll_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                   vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vsll_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, size_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vsll_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                   vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vsll_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, size_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vsll_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vuint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vsll_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, size_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vsll_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vuint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vsll_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, size_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vsll_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                   vuint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vsll_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, size_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vsll_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                   vuint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vsll_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, size_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vsll_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                   vuint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vsll_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, size_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vsll_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vuint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vsll_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, size_t rs1,
                                   size_t vl);
vint8mf8_t __riscv_vsra_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                   vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vsra_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, size_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vsra_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                   vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vsra_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, size_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vsra_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                   vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vsra_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, size_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vsra_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vuint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vsra_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, size_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vsra_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vuint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vsra_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, size_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vsra_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vuint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vsra_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, size_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vsra_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vuint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vsra_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, size_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vsra_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vuint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vsra_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, size_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vsra_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vuint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vsra_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, size_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vsra_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                   vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vsra_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, size_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vsra_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vuint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vsra_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, size_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vsra_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vuint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vsra_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, size_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vsra_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vuint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vsra_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, size_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vsra_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vuint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vsra_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, size_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vsra_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                   vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vsra_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, size_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vsra_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                   vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vsra_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, size_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vsra_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vuint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vsra_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, size_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vsra_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vuint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vsra_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, size_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vsra_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                   vuint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vsra_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, size_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vsra_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                   vuint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vsra_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, size_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vsra_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                   vuint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vsra_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, size_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vsra_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vuint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vsra_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, size_t rs1,
                                   size_t vl);
vuint8mf8_t __riscv_vsll_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                    vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vsll_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, size_t rs1,
                                    size_t vl);
vuint8mf4_t __riscv_vsll_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                    vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vsll_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, size_t rs1,
                                    size_t vl);
vuint8mf2_t __riscv_vsll_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                    vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vsll_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, size_t rs1,
                                    size_t vl);
vuint8m1_t __riscv_vsll_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                  size_t vl);
vuint8m1_t __riscv_vsll_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, size_t rs1,
                                  size_t vl);
vuint8m2_t __riscv_vsll_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                  size_t vl);
vuint8m2_t __riscv_vsll_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, size_t rs1,
                                  size_t vl);
vuint8m4_t __riscv_vsll_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                  size_t vl);
vuint8m4_t __riscv_vsll_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, size_t rs1,
                                  size_t vl);
vuint8m8_t __riscv_vsll_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                  size_t vl);
vuint8m8_t __riscv_vsll_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, size_t rs1,
                                  size_t vl);
vuint16mf4_t __riscv_vsll_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vsll_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      size_t rs1, size_t vl);
vuint16mf2_t __riscv_vsll_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vsll_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      size_t rs1, size_t vl);
vuint16m1_t __riscv_vsll_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                    vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vsll_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2, size_t rs1,
                                    size_t vl);
vuint16m2_t __riscv_vsll_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                    vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vsll_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, size_t rs1,
                                    size_t vl);
vuint16m4_t __riscv_vsll_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                    vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vsll_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, size_t rs1,
                                    size_t vl);
vuint16m8_t __riscv_vsll_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                    vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vsll_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, size_t rs1,
                                    size_t vl);
vuint32mf2_t __riscv_vsll_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vsll_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      size_t rs1, size_t vl);
vuint32m1_t __riscv_vsll_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                    vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vsll_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2, size_t rs1,
                                    size_t vl);
vuint32m2_t __riscv_vsll_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                    vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vsll_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2, size_t rs1,
                                    size_t vl);
vuint32m4_t __riscv_vsll_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                    vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vsll_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, size_t rs1,
                                    size_t vl);
vuint32m8_t __riscv_vsll_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                    vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vsll_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, size_t rs1,
                                    size_t vl);
vuint64m1_t __riscv_vsll_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                    vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vsll_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2, size_t rs1,
                                    size_t vl);
vuint64m2_t __riscv_vsll_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                    vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vsll_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2, size_t rs1,
                                    size_t vl);
vuint64m4_t __riscv_vsll_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                    vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vsll_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2, size_t rs1,
                                    size_t vl);
vuint64m8_t __riscv_vsll_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                    vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vsll_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, size_t rs1,
                                    size_t vl);
vuint8mf8_t __riscv_vsrl_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                    vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vsrl_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, size_t rs1,
                                    size_t vl);
vuint8mf4_t __riscv_vsrl_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                    vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vsrl_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, size_t rs1,
                                    size_t vl);
vuint8mf2_t __riscv_vsrl_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                    vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vsrl_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, size_t rs1,
                                    size_t vl);
vuint8m1_t __riscv_vsrl_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                  size_t vl);
vuint8m1_t __riscv_vsrl_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, size_t rs1,
                                  size_t vl);
vuint8m2_t __riscv_vsrl_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                  size_t vl);
vuint8m2_t __riscv_vsrl_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, size_t rs1,
                                  size_t vl);
vuint8m4_t __riscv_vsrl_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                  size_t vl);
vuint8m4_t __riscv_vsrl_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, size_t rs1,
                                  size_t vl);
vuint8m8_t __riscv_vsrl_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                  size_t vl);
vuint8m8_t __riscv_vsrl_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, size_t rs1,
                                  size_t vl);
vuint16mf4_t __riscv_vsrl_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vsrl_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      size_t rs1, size_t vl);
vuint16mf2_t __riscv_vsrl_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vsrl_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      size_t rs1, size_t vl);
vuint16m1_t __riscv_vsrl_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                    vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vsrl_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2, size_t rs1,
                                    size_t vl);
vuint16m2_t __riscv_vsrl_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                    vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vsrl_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, size_t rs1,
                                    size_t vl);
vuint16m4_t __riscv_vsrl_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                    vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vsrl_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, size_t rs1,
                                    size_t vl);
vuint16m8_t __riscv_vsrl_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                    vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vsrl_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, size_t rs1,
                                    size_t vl);
vuint32mf2_t __riscv_vsrl_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vsrl_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      size_t rs1, size_t vl);
vuint32m1_t __riscv_vsrl_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                    vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vsrl_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2, size_t rs1,
                                    size_t vl);
vuint32m2_t __riscv_vsrl_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                    vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vsrl_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2, size_t rs1,
                                    size_t vl);
vuint32m4_t __riscv_vsrl_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                    vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vsrl_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, size_t rs1,
                                    size_t vl);
vuint32m8_t __riscv_vsrl_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                    vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vsrl_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, size_t rs1,
                                    size_t vl);
vuint64m1_t __riscv_vsrl_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                    vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vsrl_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2, size_t rs1,
                                    size_t vl);
vuint64m2_t __riscv_vsrl_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                    vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vsrl_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2, size_t rs1,
                                    size_t vl);
vuint64m4_t __riscv_vsrl_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                    vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vsrl_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2, size_t rs1,
                                    size_t vl);
vuint64m8_t __riscv_vsrl_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                    vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vsrl_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, size_t rs1,
                                    size_t vl);
----

[[vector-narrowing-integer-right-shift]]
==== Vector Narrowing Integer Right Shift Intrinsics

[,c]
----
vint8mf8_t __riscv_vnsra_wv_i8mf8(vint16mf4_t vs2, vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vnsra_wx_i8mf8(vint16mf4_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vnsra_wv_i8mf4(vint16mf2_t vs2, vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vnsra_wx_i8mf4(vint16mf2_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vnsra_wv_i8mf2(vint16m1_t vs2, vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vnsra_wx_i8mf2(vint16m1_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vnsra_wv_i8m1(vint16m2_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vnsra_wx_i8m1(vint16m2_t vs2, size_t rs1, size_t vl);
vint8m2_t __riscv_vnsra_wv_i8m2(vint16m4_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vnsra_wx_i8m2(vint16m4_t vs2, size_t rs1, size_t vl);
vint8m4_t __riscv_vnsra_wv_i8m4(vint16m8_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vnsra_wx_i8m4(vint16m8_t vs2, size_t rs1, size_t vl);
vint16mf4_t __riscv_vnsra_wv_i16mf4(vint32mf2_t vs2, vuint16mf4_t vs1,
                                    size_t vl);
vint16mf4_t __riscv_vnsra_wx_i16mf4(vint32mf2_t vs2, size_t rs1, size_t vl);
vint16mf2_t __riscv_vnsra_wv_i16mf2(vint32m1_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vint16mf2_t __riscv_vnsra_wx_i16mf2(vint32m1_t vs2, size_t rs1, size_t vl);
vint16m1_t __riscv_vnsra_wv_i16m1(vint32m2_t vs2, vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vnsra_wx_i16m1(vint32m2_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vnsra_wv_i16m2(vint32m4_t vs2, vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vnsra_wx_i16m2(vint32m4_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vnsra_wv_i16m4(vint32m8_t vs2, vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vnsra_wx_i16m4(vint32m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vnsra_wv_i32mf2(vint64m1_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vint32mf2_t __riscv_vnsra_wx_i32mf2(vint64m1_t vs2, size_t rs1, size_t vl);
vint32m1_t __riscv_vnsra_wv_i32m1(vint64m2_t vs2, vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vnsra_wx_i32m1(vint64m2_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vnsra_wv_i32m2(vint64m4_t vs2, vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vnsra_wx_i32m2(vint64m4_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vnsra_wv_i32m4(vint64m8_t vs2, vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vnsra_wx_i32m4(vint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vnsrl_wv_u8mf8(vuint16mf4_t vs2, vuint8mf8_t vs1,
                                   size_t vl);
vuint8mf8_t __riscv_vnsrl_wx_u8mf8(vuint16mf4_t vs2, size_t rs1, size_t vl);
vuint8mf4_t __riscv_vnsrl_wv_u8mf4(vuint16mf2_t vs2, vuint8mf4_t vs1,
                                   size_t vl);
vuint8mf4_t __riscv_vnsrl_wx_u8mf4(vuint16mf2_t vs2, size_t rs1, size_t vl);
vuint8mf2_t __riscv_vnsrl_wv_u8mf2(vuint16m1_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vnsrl_wx_u8mf2(vuint16m1_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vnsrl_wv_u8m1(vuint16m2_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vnsrl_wx_u8m1(vuint16m2_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vnsrl_wv_u8m2(vuint16m4_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vnsrl_wx_u8m2(vuint16m4_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vnsrl_wv_u8m4(vuint16m8_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vnsrl_wx_u8m4(vuint16m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vnsrl_wv_u16mf4(vuint32mf2_t vs2, vuint16mf4_t vs1,
                                     size_t vl);
vuint16mf4_t __riscv_vnsrl_wx_u16mf4(vuint32mf2_t vs2, size_t rs1, size_t vl);
vuint16mf2_t __riscv_vnsrl_wv_u16mf2(vuint32m1_t vs2, vuint16mf2_t vs1,
                                     size_t vl);
vuint16mf2_t __riscv_vnsrl_wx_u16mf2(vuint32m1_t vs2, size_t rs1, size_t vl);
vuint16m1_t __riscv_vnsrl_wv_u16m1(vuint32m2_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vnsrl_wx_u16m1(vuint32m2_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vnsrl_wv_u16m2(vuint32m4_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vnsrl_wx_u16m2(vuint32m4_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vnsrl_wv_u16m4(vuint32m8_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vnsrl_wx_u16m4(vuint32m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vnsrl_wv_u32mf2(vuint64m1_t vs2, vuint32mf2_t vs1,
                                     size_t vl);
vuint32mf2_t __riscv_vnsrl_wx_u32mf2(vuint64m1_t vs2, size_t rs1, size_t vl);
vuint32m1_t __riscv_vnsrl_wv_u32m1(vuint64m2_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vnsrl_wx_u32m1(vuint64m2_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vnsrl_wv_u32m2(vuint64m4_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vnsrl_wx_u32m2(vuint64m4_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vnsrl_wv_u32m4(vuint64m8_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vnsrl_wx_u32m4(vuint64m8_t vs2, size_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vnsra_wv_i8mf8_m(vbool64_t vm, vint16mf4_t vs2,
                                    vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vnsra_wx_i8mf8_m(vbool64_t vm, vint16mf4_t vs2, size_t rs1,
                                    size_t vl);
vint8mf4_t __riscv_vnsra_wv_i8mf4_m(vbool32_t vm, vint16mf2_t vs2,
                                    vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vnsra_wx_i8mf4_m(vbool32_t vm, vint16mf2_t vs2, size_t rs1,
                                    size_t vl);
vint8mf2_t __riscv_vnsra_wv_i8mf2_m(vbool16_t vm, vint16m1_t vs2,
                                    vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vnsra_wx_i8mf2_m(vbool16_t vm, vint16m1_t vs2, size_t rs1,
                                    size_t vl);
vint8m1_t __riscv_vnsra_wv_i8m1_m(vbool8_t vm, vint16m2_t vs2, vuint8m1_t vs1,
                                  size_t vl);
vint8m1_t __riscv_vnsra_wx_i8m1_m(vbool8_t vm, vint16m2_t vs2, size_t rs1,
                                  size_t vl);
vint8m2_t __riscv_vnsra_wv_i8m2_m(vbool4_t vm, vint16m4_t vs2, vuint8m2_t vs1,
                                  size_t vl);
vint8m2_t __riscv_vnsra_wx_i8m2_m(vbool4_t vm, vint16m4_t vs2, size_t rs1,
                                  size_t vl);
vint8m4_t __riscv_vnsra_wv_i8m4_m(vbool2_t vm, vint16m8_t vs2, vuint8m4_t vs1,
                                  size_t vl);
vint8m4_t __riscv_vnsra_wx_i8m4_m(vbool2_t vm, vint16m8_t vs2, size_t rs1,
                                  size_t vl);
vint16mf4_t __riscv_vnsra_wv_i16mf4_m(vbool64_t vm, vint32mf2_t vs2,
                                      vuint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vnsra_wx_i16mf4_m(vbool64_t vm, vint32mf2_t vs2, size_t rs1,
                                      size_t vl);
vint16mf2_t __riscv_vnsra_wv_i16mf2_m(vbool32_t vm, vint32m1_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vnsra_wx_i16mf2_m(vbool32_t vm, vint32m1_t vs2, size_t rs1,
                                      size_t vl);
vint16m1_t __riscv_vnsra_wv_i16m1_m(vbool16_t vm, vint32m2_t vs2,
                                    vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vnsra_wx_i16m1_m(vbool16_t vm, vint32m2_t vs2, size_t rs1,
                                    size_t vl);
vint16m2_t __riscv_vnsra_wv_i16m2_m(vbool8_t vm, vint32m4_t vs2,
                                    vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vnsra_wx_i16m2_m(vbool8_t vm, vint32m4_t vs2, size_t rs1,
                                    size_t vl);
vint16m4_t __riscv_vnsra_wv_i16m4_m(vbool4_t vm, vint32m8_t vs2,
                                    vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vnsra_wx_i16m4_m(vbool4_t vm, vint32m8_t vs2, size_t rs1,
                                    size_t vl);
vint32mf2_t __riscv_vnsra_wv_i32mf2_m(vbool64_t vm, vint64m1_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vnsra_wx_i32mf2_m(vbool64_t vm, vint64m1_t vs2, size_t rs1,
                                      size_t vl);
vint32m1_t __riscv_vnsra_wv_i32m1_m(vbool32_t vm, vint64m2_t vs2,
                                    vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vnsra_wx_i32m1_m(vbool32_t vm, vint64m2_t vs2, size_t rs1,
                                    size_t vl);
vint32m2_t __riscv_vnsra_wv_i32m2_m(vbool16_t vm, vint64m4_t vs2,
                                    vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vnsra_wx_i32m2_m(vbool16_t vm, vint64m4_t vs2, size_t rs1,
                                    size_t vl);
vint32m4_t __riscv_vnsra_wv_i32m4_m(vbool8_t vm, vint64m8_t vs2,
                                    vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vnsra_wx_i32m4_m(vbool8_t vm, vint64m8_t vs2, size_t rs1,
                                    size_t vl);
vuint8mf8_t __riscv_vnsrl_wv_u8mf8_m(vbool64_t vm, vuint16mf4_t vs2,
                                     vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vnsrl_wx_u8mf8_m(vbool64_t vm, vuint16mf4_t vs2, size_t rs1,
                                     size_t vl);
vuint8mf4_t __riscv_vnsrl_wv_u8mf4_m(vbool32_t vm, vuint16mf2_t vs2,
                                     vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vnsrl_wx_u8mf4_m(vbool32_t vm, vuint16mf2_t vs2, size_t rs1,
                                     size_t vl);
vuint8mf2_t __riscv_vnsrl_wv_u8mf2_m(vbool16_t vm, vuint16m1_t vs2,
                                     vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vnsrl_wx_u8mf2_m(vbool16_t vm, vuint16m1_t vs2, size_t rs1,
                                     size_t vl);
vuint8m1_t __riscv_vnsrl_wv_u8m1_m(vbool8_t vm, vuint16m2_t vs2, vuint8m1_t vs1,
                                   size_t vl);
vuint8m1_t __riscv_vnsrl_wx_u8m1_m(vbool8_t vm, vuint16m2_t vs2, size_t rs1,
                                   size_t vl);
vuint8m2_t __riscv_vnsrl_wv_u8m2_m(vbool4_t vm, vuint16m4_t vs2, vuint8m2_t vs1,
                                   size_t vl);
vuint8m2_t __riscv_vnsrl_wx_u8m2_m(vbool4_t vm, vuint16m4_t vs2, size_t rs1,
                                   size_t vl);
vuint8m4_t __riscv_vnsrl_wv_u8m4_m(vbool2_t vm, vuint16m8_t vs2, vuint8m4_t vs1,
                                   size_t vl);
vuint8m4_t __riscv_vnsrl_wx_u8m4_m(vbool2_t vm, vuint16m8_t vs2, size_t rs1,
                                   size_t vl);
vuint16mf4_t __riscv_vnsrl_wv_u16mf4_m(vbool64_t vm, vuint32mf2_t vs2,
                                       vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vnsrl_wx_u16mf4_m(vbool64_t vm, vuint32mf2_t vs2,
                                       size_t rs1, size_t vl);
vuint16mf2_t __riscv_vnsrl_wv_u16mf2_m(vbool32_t vm, vuint32m1_t vs2,
                                       vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vnsrl_wx_u16mf2_m(vbool32_t vm, vuint32m1_t vs2,
                                       size_t rs1, size_t vl);
vuint16m1_t __riscv_vnsrl_wv_u16m1_m(vbool16_t vm, vuint32m2_t vs2,
                                     vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vnsrl_wx_u16m1_m(vbool16_t vm, vuint32m2_t vs2, size_t rs1,
                                     size_t vl);
vuint16m2_t __riscv_vnsrl_wv_u16m2_m(vbool8_t vm, vuint32m4_t vs2,
                                     vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vnsrl_wx_u16m2_m(vbool8_t vm, vuint32m4_t vs2, size_t rs1,
                                     size_t vl);
vuint16m4_t __riscv_vnsrl_wv_u16m4_m(vbool4_t vm, vuint32m8_t vs2,
                                     vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vnsrl_wx_u16m4_m(vbool4_t vm, vuint32m8_t vs2, size_t rs1,
                                     size_t vl);
vuint32mf2_t __riscv_vnsrl_wv_u32mf2_m(vbool64_t vm, vuint64m1_t vs2,
                                       vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vnsrl_wx_u32mf2_m(vbool64_t vm, vuint64m1_t vs2,
                                       size_t rs1, size_t vl);
vuint32m1_t __riscv_vnsrl_wv_u32m1_m(vbool32_t vm, vuint64m2_t vs2,
                                     vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vnsrl_wx_u32m1_m(vbool32_t vm, vuint64m2_t vs2, size_t rs1,
                                     size_t vl);
vuint32m2_t __riscv_vnsrl_wv_u32m2_m(vbool16_t vm, vuint64m4_t vs2,
                                     vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vnsrl_wx_u32m2_m(vbool16_t vm, vuint64m4_t vs2, size_t rs1,
                                     size_t vl);
vuint32m4_t __riscv_vnsrl_wv_u32m4_m(vbool8_t vm, vuint64m8_t vs2,
                                     vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vnsrl_wx_u32m4_m(vbool8_t vm, vuint64m8_t vs2, size_t rs1,
                                     size_t vl);
----

[[vector-integer-narrowing]]
==== Vector Integer Narrowing Intrinsics

[,c]
----
vint8mf8_t __riscv_vncvt_x_x_w_i8mf8(vint16mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vncvt_x_x_w_i8mf4(vint16mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vncvt_x_x_w_i8mf2(vint16m1_t vs2, size_t vl);
vint8m1_t __riscv_vncvt_x_x_w_i8m1(vint16m2_t vs2, size_t vl);
vint8m2_t __riscv_vncvt_x_x_w_i8m2(vint16m4_t vs2, size_t vl);
vint8m4_t __riscv_vncvt_x_x_w_i8m4(vint16m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vncvt_x_x_w_u8mf8(vuint16mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vncvt_x_x_w_u8mf4(vuint16mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vncvt_x_x_w_u8mf2(vuint16m1_t vs2, size_t vl);
vuint8m1_t __riscv_vncvt_x_x_w_u8m1(vuint16m2_t vs2, size_t vl);
vuint8m2_t __riscv_vncvt_x_x_w_u8m2(vuint16m4_t vs2, size_t vl);
vuint8m4_t __riscv_vncvt_x_x_w_u8m4(vuint16m8_t vs2, size_t vl);
vint16mf4_t __riscv_vncvt_x_x_w_i16mf4(vint32mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vncvt_x_x_w_i16mf2(vint32m1_t vs2, size_t vl);
vint16m1_t __riscv_vncvt_x_x_w_i16m1(vint32m2_t vs2, size_t vl);
vint16m2_t __riscv_vncvt_x_x_w_i16m2(vint32m4_t vs2, size_t vl);
vint16m4_t __riscv_vncvt_x_x_w_i16m4(vint32m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vncvt_x_x_w_u16mf4(vuint32mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vncvt_x_x_w_u16mf2(vuint32m1_t vs2, size_t vl);
vuint16m1_t __riscv_vncvt_x_x_w_u16m1(vuint32m2_t vs2, size_t vl);
vuint16m2_t __riscv_vncvt_x_x_w_u16m2(vuint32m4_t vs2, size_t vl);
vuint16m4_t __riscv_vncvt_x_x_w_u16m4(vuint32m8_t vs2, size_t vl);
vint32mf2_t __riscv_vncvt_x_x_w_i32mf2(vint64m1_t vs2, size_t vl);
vint32m1_t __riscv_vncvt_x_x_w_i32m1(vint64m2_t vs2, size_t vl);
vint32m2_t __riscv_vncvt_x_x_w_i32m2(vint64m4_t vs2, size_t vl);
vint32m4_t __riscv_vncvt_x_x_w_i32m4(vint64m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vncvt_x_x_w_u32mf2(vuint64m1_t vs2, size_t vl);
vuint32m1_t __riscv_vncvt_x_x_w_u32m1(vuint64m2_t vs2, size_t vl);
vuint32m2_t __riscv_vncvt_x_x_w_u32m2(vuint64m4_t vs2, size_t vl);
vuint32m4_t __riscv_vncvt_x_x_w_u32m4(vuint64m8_t vs2, size_t vl);
// masked functions
vint8mf8_t __riscv_vncvt_x_x_w_i8mf8_m(vbool64_t vm, vint16mf4_t vs2,
                                       size_t vl);
vint8mf4_t __riscv_vncvt_x_x_w_i8mf4_m(vbool32_t vm, vint16mf2_t vs2,
                                       size_t vl);
vint8mf2_t __riscv_vncvt_x_x_w_i8mf2_m(vbool16_t vm, vint16m1_t vs2, size_t vl);
vint8m1_t __riscv_vncvt_x_x_w_i8m1_m(vbool8_t vm, vint16m2_t vs2, size_t vl);
vint8m2_t __riscv_vncvt_x_x_w_i8m2_m(vbool4_t vm, vint16m4_t vs2, size_t vl);
vint8m4_t __riscv_vncvt_x_x_w_i8m4_m(vbool2_t vm, vint16m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vncvt_x_x_w_u8mf8_m(vbool64_t vm, vuint16mf4_t vs2,
                                        size_t vl);
vuint8mf4_t __riscv_vncvt_x_x_w_u8mf4_m(vbool32_t vm, vuint16mf2_t vs2,
                                        size_t vl);
vuint8mf2_t __riscv_vncvt_x_x_w_u8mf2_m(vbool16_t vm, vuint16m1_t vs2,
                                        size_t vl);
vuint8m1_t __riscv_vncvt_x_x_w_u8m1_m(vbool8_t vm, vuint16m2_t vs2, size_t vl);
vuint8m2_t __riscv_vncvt_x_x_w_u8m2_m(vbool4_t vm, vuint16m4_t vs2, size_t vl);
vuint8m4_t __riscv_vncvt_x_x_w_u8m4_m(vbool2_t vm, vuint16m8_t vs2, size_t vl);
vint16mf4_t __riscv_vncvt_x_x_w_i16mf4_m(vbool64_t vm, vint32mf2_t vs2,
                                         size_t vl);
vint16mf2_t __riscv_vncvt_x_x_w_i16mf2_m(vbool32_t vm, vint32m1_t vs2,
                                         size_t vl);
vint16m1_t __riscv_vncvt_x_x_w_i16m1_m(vbool16_t vm, vint32m2_t vs2, size_t vl);
vint16m2_t __riscv_vncvt_x_x_w_i16m2_m(vbool8_t vm, vint32m4_t vs2, size_t vl);
vint16m4_t __riscv_vncvt_x_x_w_i16m4_m(vbool4_t vm, vint32m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vncvt_x_x_w_u16mf4_m(vbool64_t vm, vuint32mf2_t vs2,
                                          size_t vl);
vuint16mf2_t __riscv_vncvt_x_x_w_u16mf2_m(vbool32_t vm, vuint32m1_t vs2,
                                          size_t vl);
vuint16m1_t __riscv_vncvt_x_x_w_u16m1_m(vbool16_t vm, vuint32m2_t vs2,
                                        size_t vl);
vuint16m2_t __riscv_vncvt_x_x_w_u16m2_m(vbool8_t vm, vuint32m4_t vs2,
                                        size_t vl);
vuint16m4_t __riscv_vncvt_x_x_w_u16m4_m(vbool4_t vm, vuint32m8_t vs2,
                                        size_t vl);
vint32mf2_t __riscv_vncvt_x_x_w_i32mf2_m(vbool64_t vm, vint64m1_t vs2,
                                         size_t vl);
vint32m1_t __riscv_vncvt_x_x_w_i32m1_m(vbool32_t vm, vint64m2_t vs2, size_t vl);
vint32m2_t __riscv_vncvt_x_x_w_i32m2_m(vbool16_t vm, vint64m4_t vs2, size_t vl);
vint32m4_t __riscv_vncvt_x_x_w_i32m4_m(vbool8_t vm, vint64m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vncvt_x_x_w_u32mf2_m(vbool64_t vm, vuint64m1_t vs2,
                                          size_t vl);
vuint32m1_t __riscv_vncvt_x_x_w_u32m1_m(vbool32_t vm, vuint64m2_t vs2,
                                        size_t vl);
vuint32m2_t __riscv_vncvt_x_x_w_u32m2_m(vbool16_t vm, vuint64m4_t vs2,
                                        size_t vl);
vuint32m4_t __riscv_vncvt_x_x_w_u32m4_m(vbool8_t vm, vuint64m8_t vs2,
                                        size_t vl);
----

[[vector-integer-comparison]]
==== Vector Integer Compare Intrinsics

[,c]
----
vbool64_t __riscv_vmseq_vv_i8mf8_b64(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmseq_vx_i8mf8_b64(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_i8mf4_b32(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_i8mf4_b32(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_i8mf2_b16(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_i8mf2_b16(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_i8m1_b8(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_i8m1_b8(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmseq_vv_i8m2_b4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmseq_vx_i8m2_b4(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmseq_vv_i8m4_b2(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmseq_vx_i8m4_b2(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmseq_vv_i8m8_b1(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmseq_vx_i8m8_b1(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmseq_vv_i16mf4_b64(vint16mf4_t vs2, vint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmseq_vx_i16mf4_b64(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_i16mf2_b32(vint16mf2_t vs2, vint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmseq_vx_i16mf2_b32(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_i16m1_b16(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_i16m1_b16(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_i16m2_b8(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_i16m2_b8(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmseq_vv_i16m4_b4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmseq_vx_i16m4_b4(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmseq_vv_i16m8_b2(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmseq_vx_i16m8_b2(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmseq_vv_i32mf2_b64(vint32mf2_t vs2, vint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmseq_vx_i32mf2_b64(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_i32m1_b32(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_i32m1_b32(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_i32m2_b16(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_i32m2_b16(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_i32m4_b8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_i32m4_b8(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmseq_vv_i32m8_b4(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmseq_vx_i32m8_b4(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmseq_vv_i64m1_b64(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmseq_vx_i64m1_b64(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_i64m2_b32(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_i64m2_b32(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_i64m4_b16(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_i64m4_b16(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_i64m8_b8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_i64m8_b8(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsne_vv_i8mf8_b64(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsne_vx_i8mf8_b64(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_i8mf4_b32(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_i8mf4_b32(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_i8mf2_b16(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_i8mf2_b16(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_i8m1_b8(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_i8m1_b8(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsne_vv_i8m2_b4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsne_vx_i8m2_b4(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsne_vv_i8m4_b2(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsne_vx_i8m4_b2(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsne_vv_i8m8_b1(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsne_vx_i8m8_b1(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsne_vv_i16mf4_b64(vint16mf4_t vs2, vint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsne_vx_i16mf4_b64(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_i16mf2_b32(vint16mf2_t vs2, vint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsne_vx_i16mf2_b32(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_i16m1_b16(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_i16m1_b16(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_i16m2_b8(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_i16m2_b8(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsne_vv_i16m4_b4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsne_vx_i16m4_b4(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsne_vv_i16m8_b2(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsne_vx_i16m8_b2(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsne_vv_i32mf2_b64(vint32mf2_t vs2, vint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsne_vx_i32mf2_b64(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_i32m1_b32(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_i32m1_b32(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_i32m2_b16(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_i32m2_b16(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_i32m4_b8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_i32m4_b8(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsne_vv_i32m8_b4(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsne_vx_i32m8_b4(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsne_vv_i64m1_b64(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsne_vx_i64m1_b64(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_i64m2_b32(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_i64m2_b32(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_i64m4_b16(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_i64m4_b16(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_i64m8_b8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_i64m8_b8(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmslt_vv_i8mf8_b64(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmslt_vx_i8mf8_b64(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmslt_vv_i8mf4_b32(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmslt_vx_i8mf4_b32(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmslt_vv_i8mf2_b16(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmslt_vx_i8mf2_b16(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmslt_vv_i8m1_b8(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmslt_vx_i8m1_b8(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmslt_vv_i8m2_b4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmslt_vx_i8m2_b4(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmslt_vv_i8m4_b2(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmslt_vx_i8m4_b2(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmslt_vv_i8m8_b1(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmslt_vx_i8m8_b1(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmslt_vv_i16mf4_b64(vint16mf4_t vs2, vint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmslt_vx_i16mf4_b64(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmslt_vv_i16mf2_b32(vint16mf2_t vs2, vint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmslt_vx_i16mf2_b32(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmslt_vv_i16m1_b16(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmslt_vx_i16m1_b16(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmslt_vv_i16m2_b8(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmslt_vx_i16m2_b8(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmslt_vv_i16m4_b4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmslt_vx_i16m4_b4(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmslt_vv_i16m8_b2(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmslt_vx_i16m8_b2(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmslt_vv_i32mf2_b64(vint32mf2_t vs2, vint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmslt_vx_i32mf2_b64(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmslt_vv_i32m1_b32(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmslt_vx_i32m1_b32(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmslt_vv_i32m2_b16(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmslt_vx_i32m2_b16(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmslt_vv_i32m4_b8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmslt_vx_i32m4_b8(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmslt_vv_i32m8_b4(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmslt_vx_i32m8_b4(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmslt_vv_i64m1_b64(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmslt_vx_i64m1_b64(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmslt_vv_i64m2_b32(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmslt_vx_i64m2_b32(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmslt_vv_i64m4_b16(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmslt_vx_i64m4_b16(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmslt_vv_i64m8_b8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmslt_vx_i64m8_b8(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsle_vv_i8mf8_b64(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsle_vx_i8mf8_b64(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsle_vv_i8mf4_b32(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsle_vx_i8mf4_b32(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsle_vv_i8mf2_b16(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsle_vx_i8mf2_b16(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsle_vv_i8m1_b8(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsle_vx_i8m1_b8(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsle_vv_i8m2_b4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsle_vx_i8m2_b4(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsle_vv_i8m4_b2(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsle_vx_i8m4_b2(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsle_vv_i8m8_b1(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsle_vx_i8m8_b1(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsle_vv_i16mf4_b64(vint16mf4_t vs2, vint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsle_vx_i16mf4_b64(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsle_vv_i16mf2_b32(vint16mf2_t vs2, vint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsle_vx_i16mf2_b32(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsle_vv_i16m1_b16(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsle_vx_i16m1_b16(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsle_vv_i16m2_b8(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsle_vx_i16m2_b8(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsle_vv_i16m4_b4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsle_vx_i16m4_b4(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsle_vv_i16m8_b2(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsle_vx_i16m8_b2(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsle_vv_i32mf2_b64(vint32mf2_t vs2, vint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsle_vx_i32mf2_b64(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsle_vv_i32m1_b32(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsle_vx_i32m1_b32(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsle_vv_i32m2_b16(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsle_vx_i32m2_b16(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsle_vv_i32m4_b8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsle_vx_i32m4_b8(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsle_vv_i32m8_b4(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsle_vx_i32m8_b4(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsle_vv_i64m1_b64(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsle_vx_i64m1_b64(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsle_vv_i64m2_b32(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsle_vx_i64m2_b32(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsle_vv_i64m4_b16(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsle_vx_i64m4_b16(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsle_vv_i64m8_b8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsle_vx_i64m8_b8(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsgt_vv_i8mf8_b64(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsgt_vx_i8mf8_b64(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsgt_vv_i8mf4_b32(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsgt_vx_i8mf4_b32(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsgt_vv_i8mf2_b16(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsgt_vx_i8mf2_b16(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsgt_vv_i8m1_b8(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgt_vx_i8m1_b8(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsgt_vv_i8m2_b4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgt_vx_i8m2_b4(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsgt_vv_i8m4_b2(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgt_vx_i8m4_b2(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsgt_vv_i8m8_b1(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgt_vx_i8m8_b1(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsgt_vv_i16mf4_b64(vint16mf4_t vs2, vint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsgt_vx_i16mf4_b64(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsgt_vv_i16mf2_b32(vint16mf2_t vs2, vint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsgt_vx_i16mf2_b32(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsgt_vv_i16m1_b16(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsgt_vx_i16m1_b16(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsgt_vv_i16m2_b8(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsgt_vx_i16m2_b8(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsgt_vv_i16m4_b4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsgt_vx_i16m4_b4(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsgt_vv_i16m8_b2(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsgt_vx_i16m8_b2(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsgt_vv_i32mf2_b64(vint32mf2_t vs2, vint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsgt_vx_i32mf2_b64(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsgt_vv_i32m1_b32(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsgt_vx_i32m1_b32(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsgt_vv_i32m2_b16(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsgt_vx_i32m2_b16(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsgt_vv_i32m4_b8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsgt_vx_i32m4_b8(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsgt_vv_i32m8_b4(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsgt_vx_i32m8_b4(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsgt_vv_i64m1_b64(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsgt_vx_i64m1_b64(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsgt_vv_i64m2_b32(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsgt_vx_i64m2_b32(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsgt_vv_i64m4_b16(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsgt_vx_i64m4_b16(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsgt_vv_i64m8_b8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsgt_vx_i64m8_b8(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsge_vv_i8mf8_b64(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsge_vx_i8mf8_b64(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsge_vv_i8mf4_b32(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsge_vx_i8mf4_b32(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsge_vv_i8mf2_b16(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsge_vx_i8mf2_b16(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsge_vv_i8m1_b8(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsge_vx_i8m1_b8(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsge_vv_i8m2_b4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsge_vx_i8m2_b4(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsge_vv_i8m4_b2(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsge_vx_i8m4_b2(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsge_vv_i8m8_b1(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsge_vx_i8m8_b1(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsge_vv_i16mf4_b64(vint16mf4_t vs2, vint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsge_vx_i16mf4_b64(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsge_vv_i16mf2_b32(vint16mf2_t vs2, vint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsge_vx_i16mf2_b32(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsge_vv_i16m1_b16(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsge_vx_i16m1_b16(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsge_vv_i16m2_b8(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsge_vx_i16m2_b8(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsge_vv_i16m4_b4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsge_vx_i16m4_b4(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsge_vv_i16m8_b2(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsge_vx_i16m8_b2(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsge_vv_i32mf2_b64(vint32mf2_t vs2, vint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsge_vx_i32mf2_b64(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsge_vv_i32m1_b32(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsge_vx_i32m1_b32(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsge_vv_i32m2_b16(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsge_vx_i32m2_b16(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsge_vv_i32m4_b8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsge_vx_i32m4_b8(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsge_vv_i32m8_b4(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsge_vx_i32m8_b4(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsge_vv_i64m1_b64(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsge_vx_i64m1_b64(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsge_vv_i64m2_b32(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsge_vx_i64m2_b32(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsge_vv_i64m4_b16(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsge_vx_i64m4_b16(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsge_vv_i64m8_b8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsge_vx_i64m8_b8(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmseq_vv_u8mf8_b64(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmseq_vx_u8mf8_b64(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_u8mf4_b32(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmseq_vx_u8mf4_b32(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_u8mf2_b16(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmseq_vx_u8mf2_b16(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_u8m1_b8(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_u8m1_b8(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmseq_vv_u8m2_b4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmseq_vx_u8m2_b4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmseq_vv_u8m4_b2(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmseq_vx_u8m4_b2(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmseq_vv_u8m8_b1(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmseq_vx_u8m8_b1(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmseq_vv_u16mf4_b64(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmseq_vx_u16mf4_b64(vuint16mf4_t vs2, uint16_t rs1,
                                      size_t vl);
vbool32_t __riscv_vmseq_vv_u16mf2_b32(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmseq_vx_u16mf2_b32(vuint16mf2_t vs2, uint16_t rs1,
                                      size_t vl);
vbool16_t __riscv_vmseq_vv_u16m1_b16(vuint16m1_t vs2, vuint16m1_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmseq_vx_u16m1_b16(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_u16m2_b8(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_u16m2_b8(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmseq_vv_u16m4_b4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmseq_vx_u16m4_b4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmseq_vv_u16m8_b2(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmseq_vx_u16m8_b2(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmseq_vv_u32mf2_b64(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmseq_vx_u32mf2_b64(vuint32mf2_t vs2, uint32_t rs1,
                                      size_t vl);
vbool32_t __riscv_vmseq_vv_u32m1_b32(vuint32m1_t vs2, vuint32m1_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmseq_vx_u32m1_b32(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_u32m2_b16(vuint32m2_t vs2, vuint32m2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmseq_vx_u32m2_b16(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_u32m4_b8(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_u32m4_b8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmseq_vv_u32m8_b4(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmseq_vx_u32m8_b4(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmseq_vv_u64m1_b64(vuint64m1_t vs2, vuint64m1_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmseq_vx_u64m1_b64(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_u64m2_b32(vuint64m2_t vs2, vuint64m2_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmseq_vx_u64m2_b32(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_u64m4_b16(vuint64m4_t vs2, vuint64m4_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmseq_vx_u64m4_b16(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_u64m8_b8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_u64m8_b8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsne_vv_u8mf8_b64(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmsne_vx_u8mf8_b64(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_u8mf4_b32(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmsne_vx_u8mf4_b32(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_u8mf2_b16(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmsne_vx_u8mf2_b16(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_u8m1_b8(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_u8m1_b8(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsne_vv_u8m2_b4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsne_vx_u8m2_b4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsne_vv_u8m4_b2(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsne_vx_u8m4_b2(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsne_vv_u8m8_b1(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsne_vx_u8m8_b1(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsne_vv_u16mf4_b64(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsne_vx_u16mf4_b64(vuint16mf4_t vs2, uint16_t rs1,
                                      size_t vl);
vbool32_t __riscv_vmsne_vv_u16mf2_b32(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsne_vx_u16mf2_b32(vuint16mf2_t vs2, uint16_t rs1,
                                      size_t vl);
vbool16_t __riscv_vmsne_vv_u16m1_b16(vuint16m1_t vs2, vuint16m1_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmsne_vx_u16m1_b16(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_u16m2_b8(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_u16m2_b8(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsne_vv_u16m4_b4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsne_vx_u16m4_b4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsne_vv_u16m8_b2(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsne_vx_u16m8_b2(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsne_vv_u32mf2_b64(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsne_vx_u32mf2_b64(vuint32mf2_t vs2, uint32_t rs1,
                                      size_t vl);
vbool32_t __riscv_vmsne_vv_u32m1_b32(vuint32m1_t vs2, vuint32m1_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmsne_vx_u32m1_b32(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_u32m2_b16(vuint32m2_t vs2, vuint32m2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmsne_vx_u32m2_b16(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_u32m4_b8(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_u32m4_b8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsne_vv_u32m8_b4(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsne_vx_u32m8_b4(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsne_vv_u64m1_b64(vuint64m1_t vs2, vuint64m1_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmsne_vx_u64m1_b64(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_u64m2_b32(vuint64m2_t vs2, vuint64m2_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmsne_vx_u64m2_b32(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_u64m4_b16(vuint64m4_t vs2, vuint64m4_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmsne_vx_u64m4_b16(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_u64m8_b8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_u64m8_b8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsltu_vv_u8mf8_b64(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsltu_vx_u8mf8_b64(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsltu_vv_u8mf4_b32(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsltu_vx_u8mf4_b32(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsltu_vv_u8mf2_b16(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsltu_vx_u8mf2_b16(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsltu_vv_u8m1_b8(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsltu_vx_u8m1_b8(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsltu_vv_u8m2_b4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsltu_vx_u8m2_b4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsltu_vv_u8m4_b2(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsltu_vx_u8m4_b2(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsltu_vv_u8m8_b1(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsltu_vx_u8m8_b1(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsltu_vv_u16mf4_b64(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                       size_t vl);
vbool64_t __riscv_vmsltu_vx_u16mf4_b64(vuint16mf4_t vs2, uint16_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsltu_vv_u16mf2_b32(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                       size_t vl);
vbool32_t __riscv_vmsltu_vx_u16mf2_b32(vuint16mf2_t vs2, uint16_t rs1,
                                       size_t vl);
vbool16_t __riscv_vmsltu_vv_u16m1_b16(vuint16m1_t vs2, vuint16m1_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsltu_vx_u16m1_b16(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsltu_vv_u16m2_b8(vuint16m2_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsltu_vx_u16m2_b8(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsltu_vv_u16m4_b4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsltu_vx_u16m4_b4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsltu_vv_u16m8_b2(vuint16m8_t vs2, vuint16m8_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmsltu_vx_u16m8_b2(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsltu_vv_u32mf2_b64(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                       size_t vl);
vbool64_t __riscv_vmsltu_vx_u32mf2_b64(vuint32mf2_t vs2, uint32_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsltu_vv_u32m1_b32(vuint32m1_t vs2, vuint32m1_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsltu_vx_u32m1_b32(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsltu_vv_u32m2_b16(vuint32m2_t vs2, vuint32m2_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsltu_vx_u32m2_b16(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsltu_vv_u32m4_b8(vuint32m4_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsltu_vx_u32m4_b8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsltu_vv_u32m8_b4(vuint32m8_t vs2, vuint32m8_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsltu_vx_u32m8_b4(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsltu_vv_u64m1_b64(vuint64m1_t vs2, vuint64m1_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsltu_vx_u64m1_b64(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsltu_vv_u64m2_b32(vuint64m2_t vs2, vuint64m2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsltu_vx_u64m2_b32(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsltu_vv_u64m4_b16(vuint64m4_t vs2, vuint64m4_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsltu_vx_u64m4_b16(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsltu_vv_u64m8_b8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsltu_vx_u64m8_b8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsleu_vv_u8mf8_b64(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsleu_vx_u8mf8_b64(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsleu_vv_u8mf4_b32(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsleu_vx_u8mf4_b32(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsleu_vv_u8mf2_b16(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsleu_vx_u8mf2_b16(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsleu_vv_u8m1_b8(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsleu_vx_u8m1_b8(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsleu_vv_u8m2_b4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsleu_vx_u8m2_b4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsleu_vv_u8m4_b2(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsleu_vx_u8m4_b2(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsleu_vv_u8m8_b1(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsleu_vx_u8m8_b1(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsleu_vv_u16mf4_b64(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                       size_t vl);
vbool64_t __riscv_vmsleu_vx_u16mf4_b64(vuint16mf4_t vs2, uint16_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsleu_vv_u16mf2_b32(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                       size_t vl);
vbool32_t __riscv_vmsleu_vx_u16mf2_b32(vuint16mf2_t vs2, uint16_t rs1,
                                       size_t vl);
vbool16_t __riscv_vmsleu_vv_u16m1_b16(vuint16m1_t vs2, vuint16m1_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsleu_vx_u16m1_b16(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsleu_vv_u16m2_b8(vuint16m2_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsleu_vx_u16m2_b8(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsleu_vv_u16m4_b4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsleu_vx_u16m4_b4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsleu_vv_u16m8_b2(vuint16m8_t vs2, vuint16m8_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmsleu_vx_u16m8_b2(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsleu_vv_u32mf2_b64(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                       size_t vl);
vbool64_t __riscv_vmsleu_vx_u32mf2_b64(vuint32mf2_t vs2, uint32_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsleu_vv_u32m1_b32(vuint32m1_t vs2, vuint32m1_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsleu_vx_u32m1_b32(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsleu_vv_u32m2_b16(vuint32m2_t vs2, vuint32m2_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsleu_vx_u32m2_b16(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsleu_vv_u32m4_b8(vuint32m4_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsleu_vx_u32m4_b8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsleu_vv_u32m8_b4(vuint32m8_t vs2, vuint32m8_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsleu_vx_u32m8_b4(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsleu_vv_u64m1_b64(vuint64m1_t vs2, vuint64m1_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsleu_vx_u64m1_b64(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsleu_vv_u64m2_b32(vuint64m2_t vs2, vuint64m2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsleu_vx_u64m2_b32(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsleu_vv_u64m4_b16(vuint64m4_t vs2, vuint64m4_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsleu_vx_u64m4_b16(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsleu_vv_u64m8_b8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsleu_vx_u64m8_b8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu_vv_u8mf8_b64(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsgtu_vx_u8mf8_b64(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu_vv_u8mf4_b32(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsgtu_vx_u8mf4_b32(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu_vv_u8mf2_b16(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsgtu_vx_u8mf2_b16(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu_vv_u8m1_b8(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgtu_vx_u8m1_b8(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu_vv_u8m2_b4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgtu_vx_u8m2_b4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsgtu_vv_u8m4_b2(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgtu_vx_u8m4_b2(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsgtu_vv_u8m8_b1(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgtu_vx_u8m8_b1(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu_vv_u16mf4_b64(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                       size_t vl);
vbool64_t __riscv_vmsgtu_vx_u16mf4_b64(vuint16mf4_t vs2, uint16_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsgtu_vv_u16mf2_b32(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                       size_t vl);
vbool32_t __riscv_vmsgtu_vx_u16mf2_b32(vuint16mf2_t vs2, uint16_t rs1,
                                       size_t vl);
vbool16_t __riscv_vmsgtu_vv_u16m1_b16(vuint16m1_t vs2, vuint16m1_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsgtu_vx_u16m1_b16(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu_vv_u16m2_b8(vuint16m2_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsgtu_vx_u16m2_b8(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu_vv_u16m4_b4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsgtu_vx_u16m4_b4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsgtu_vv_u16m8_b2(vuint16m8_t vs2, vuint16m8_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmsgtu_vx_u16m8_b2(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu_vv_u32mf2_b64(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                       size_t vl);
vbool64_t __riscv_vmsgtu_vx_u32mf2_b64(vuint32mf2_t vs2, uint32_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsgtu_vv_u32m1_b32(vuint32m1_t vs2, vuint32m1_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsgtu_vx_u32m1_b32(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu_vv_u32m2_b16(vuint32m2_t vs2, vuint32m2_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsgtu_vx_u32m2_b16(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu_vv_u32m4_b8(vuint32m4_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsgtu_vx_u32m4_b8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu_vv_u32m8_b4(vuint32m8_t vs2, vuint32m8_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsgtu_vx_u32m8_b4(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu_vv_u64m1_b64(vuint64m1_t vs2, vuint64m1_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsgtu_vx_u64m1_b64(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu_vv_u64m2_b32(vuint64m2_t vs2, vuint64m2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsgtu_vx_u64m2_b32(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu_vv_u64m4_b16(vuint64m4_t vs2, vuint64m4_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsgtu_vx_u64m4_b16(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu_vv_u64m8_b8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsgtu_vx_u64m8_b8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu_vv_u8mf8_b64(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsgeu_vx_u8mf8_b64(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu_vv_u8mf4_b32(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsgeu_vx_u8mf4_b32(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu_vv_u8mf2_b16(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsgeu_vx_u8mf2_b16(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu_vv_u8m1_b8(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgeu_vx_u8m1_b8(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu_vv_u8m2_b4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgeu_vx_u8m2_b4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsgeu_vv_u8m4_b2(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgeu_vx_u8m4_b2(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsgeu_vv_u8m8_b1(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgeu_vx_u8m8_b1(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu_vv_u16mf4_b64(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                       size_t vl);
vbool64_t __riscv_vmsgeu_vx_u16mf4_b64(vuint16mf4_t vs2, uint16_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsgeu_vv_u16mf2_b32(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                       size_t vl);
vbool32_t __riscv_vmsgeu_vx_u16mf2_b32(vuint16mf2_t vs2, uint16_t rs1,
                                       size_t vl);
vbool16_t __riscv_vmsgeu_vv_u16m1_b16(vuint16m1_t vs2, vuint16m1_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsgeu_vx_u16m1_b16(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu_vv_u16m2_b8(vuint16m2_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsgeu_vx_u16m2_b8(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu_vv_u16m4_b4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsgeu_vx_u16m4_b4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsgeu_vv_u16m8_b2(vuint16m8_t vs2, vuint16m8_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmsgeu_vx_u16m8_b2(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu_vv_u32mf2_b64(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                       size_t vl);
vbool64_t __riscv_vmsgeu_vx_u32mf2_b64(vuint32mf2_t vs2, uint32_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsgeu_vv_u32m1_b32(vuint32m1_t vs2, vuint32m1_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsgeu_vx_u32m1_b32(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu_vv_u32m2_b16(vuint32m2_t vs2, vuint32m2_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsgeu_vx_u32m2_b16(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu_vv_u32m4_b8(vuint32m4_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsgeu_vx_u32m4_b8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu_vv_u32m8_b4(vuint32m8_t vs2, vuint32m8_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsgeu_vx_u32m8_b4(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu_vv_u64m1_b64(vuint64m1_t vs2, vuint64m1_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmsgeu_vx_u64m1_b64(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu_vv_u64m2_b32(vuint64m2_t vs2, vuint64m2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmsgeu_vx_u64m2_b32(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu_vv_u64m4_b16(vuint64m4_t vs2, vuint64m4_t vs1,
                                      size_t vl);
vbool16_t __riscv_vmsgeu_vx_u64m4_b16(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu_vv_u64m8_b8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsgeu_vx_u64m8_b8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vbool64_t __riscv_vmseq_vv_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2,
                                       vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmseq_vx_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmseq_vv_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2,
                                       vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                       size_t vl);
vbool16_t __riscv_vmseq_vv_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2,
                                       vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                       size_t vl);
vbool8_t __riscv_vmseq_vv_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmseq_vx_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                    size_t vl);
vbool4_t __riscv_vmseq_vv_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmseq_vx_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                    size_t vl);
vbool2_t __riscv_vmseq_vv_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmseq_vx_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                    size_t vl);
vbool1_t __riscv_vmseq_vv_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                    size_t vl);
vbool1_t __riscv_vmseq_vx_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                    size_t vl);
vbool64_t __riscv_vmseq_vv_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmseq_vx_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        int16_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        int16_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       int16_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2,
                                     vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmseq_vv_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2,
                                     vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmseq_vx_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmseq_vv_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2,
                                     vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmseq_vx_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmseq_vv_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmseq_vx_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        int32_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       int32_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       int32_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2,
                                     vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmseq_vv_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2,
                                     vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmseq_vx_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmseq_vv_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmseq_vx_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       int64_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       int64_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       int64_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2,
                                     vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsne_vv_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2,
                                       vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsne_vx_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsne_vv_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2,
                                       vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                       size_t vl);
vbool16_t __riscv_vmsne_vv_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2,
                                       vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                       size_t vl);
vbool8_t __riscv_vmsne_vv_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsne_vx_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                    size_t vl);
vbool4_t __riscv_vmsne_vv_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsne_vx_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                    size_t vl);
vbool2_t __riscv_vmsne_vv_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmsne_vx_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                    size_t vl);
vbool1_t __riscv_vmsne_vv_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                    size_t vl);
vbool1_t __riscv_vmsne_vx_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                    size_t vl);
vbool64_t __riscv_vmsne_vv_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsne_vx_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        int16_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        int16_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       int16_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2,
                                     vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsne_vv_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2,
                                     vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsne_vx_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmsne_vv_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2,
                                     vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsne_vx_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsne_vv_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsne_vx_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        int32_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       int32_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       int32_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2,
                                     vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsne_vv_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2,
                                     vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsne_vx_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsne_vv_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsne_vx_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       int64_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       int64_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       int64_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2,
                                     vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmslt_vv_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2,
                                       vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmslt_vx_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmslt_vv_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2,
                                       vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmslt_vx_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                       size_t vl);
vbool16_t __riscv_vmslt_vv_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2,
                                       vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmslt_vx_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                       size_t vl);
vbool8_t __riscv_vmslt_vv_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmslt_vx_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                    size_t vl);
vbool4_t __riscv_vmslt_vv_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmslt_vx_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                    size_t vl);
vbool2_t __riscv_vmslt_vv_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmslt_vx_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                    size_t vl);
vbool1_t __riscv_vmslt_vv_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                    size_t vl);
vbool1_t __riscv_vmslt_vx_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                    size_t vl);
vbool64_t __riscv_vmslt_vv_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmslt_vx_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        int16_t rs1, size_t vl);
vbool32_t __riscv_vmslt_vv_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmslt_vx_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        int16_t rs1, size_t vl);
vbool16_t __riscv_vmslt_vv_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmslt_vx_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       int16_t rs1, size_t vl);
vbool8_t __riscv_vmslt_vv_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2,
                                     vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmslt_vx_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmslt_vv_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2,
                                     vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmslt_vx_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmslt_vv_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2,
                                     vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmslt_vx_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmslt_vv_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmslt_vx_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        int32_t rs1, size_t vl);
vbool32_t __riscv_vmslt_vv_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmslt_vx_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       int32_t rs1, size_t vl);
vbool16_t __riscv_vmslt_vv_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmslt_vx_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       int32_t rs1, size_t vl);
vbool8_t __riscv_vmslt_vv_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2,
                                     vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmslt_vx_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmslt_vv_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2,
                                     vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmslt_vx_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmslt_vv_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmslt_vx_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       int64_t rs1, size_t vl);
vbool32_t __riscv_vmslt_vv_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmslt_vx_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       int64_t rs1, size_t vl);
vbool16_t __riscv_vmslt_vv_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmslt_vx_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       int64_t rs1, size_t vl);
vbool8_t __riscv_vmslt_vv_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2,
                                     vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmslt_vx_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsle_vv_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2,
                                       vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsle_vx_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsle_vv_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2,
                                       vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsle_vx_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                       size_t vl);
vbool16_t __riscv_vmsle_vv_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2,
                                       vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsle_vx_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                       size_t vl);
vbool8_t __riscv_vmsle_vv_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsle_vx_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                    size_t vl);
vbool4_t __riscv_vmsle_vv_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsle_vx_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                    size_t vl);
vbool2_t __riscv_vmsle_vv_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmsle_vx_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                    size_t vl);
vbool1_t __riscv_vmsle_vv_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                    size_t vl);
vbool1_t __riscv_vmsle_vx_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                    size_t vl);
vbool64_t __riscv_vmsle_vv_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsle_vx_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        int16_t rs1, size_t vl);
vbool32_t __riscv_vmsle_vv_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsle_vx_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        int16_t rs1, size_t vl);
vbool16_t __riscv_vmsle_vv_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsle_vx_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       int16_t rs1, size_t vl);
vbool8_t __riscv_vmsle_vv_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2,
                                     vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsle_vx_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsle_vv_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2,
                                     vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsle_vx_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmsle_vv_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2,
                                     vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsle_vx_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsle_vv_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsle_vx_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        int32_t rs1, size_t vl);
vbool32_t __riscv_vmsle_vv_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsle_vx_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       int32_t rs1, size_t vl);
vbool16_t __riscv_vmsle_vv_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsle_vx_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       int32_t rs1, size_t vl);
vbool8_t __riscv_vmsle_vv_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2,
                                     vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsle_vx_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsle_vv_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2,
                                     vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsle_vx_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsle_vv_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsle_vx_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       int64_t rs1, size_t vl);
vbool32_t __riscv_vmsle_vv_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsle_vx_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       int64_t rs1, size_t vl);
vbool16_t __riscv_vmsle_vv_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsle_vx_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       int64_t rs1, size_t vl);
vbool8_t __riscv_vmsle_vv_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2,
                                     vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsle_vx_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsgt_vv_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2,
                                       vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsgt_vx_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsgt_vv_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2,
                                       vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsgt_vx_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                       size_t vl);
vbool16_t __riscv_vmsgt_vv_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2,
                                       vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsgt_vx_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                       size_t vl);
vbool8_t __riscv_vmsgt_vv_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsgt_vx_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                    size_t vl);
vbool4_t __riscv_vmsgt_vv_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsgt_vx_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                    size_t vl);
vbool2_t __riscv_vmsgt_vv_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmsgt_vx_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                    size_t vl);
vbool1_t __riscv_vmsgt_vv_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                    size_t vl);
vbool1_t __riscv_vmsgt_vx_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                    size_t vl);
vbool64_t __riscv_vmsgt_vv_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsgt_vx_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        int16_t rs1, size_t vl);
vbool32_t __riscv_vmsgt_vv_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsgt_vx_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        int16_t rs1, size_t vl);
vbool16_t __riscv_vmsgt_vv_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsgt_vx_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       int16_t rs1, size_t vl);
vbool8_t __riscv_vmsgt_vv_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2,
                                     vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsgt_vx_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsgt_vv_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2,
                                     vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsgt_vx_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmsgt_vv_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2,
                                     vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsgt_vx_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsgt_vv_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsgt_vx_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        int32_t rs1, size_t vl);
vbool32_t __riscv_vmsgt_vv_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsgt_vx_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       int32_t rs1, size_t vl);
vbool16_t __riscv_vmsgt_vv_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsgt_vx_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       int32_t rs1, size_t vl);
vbool8_t __riscv_vmsgt_vv_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2,
                                     vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsgt_vx_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsgt_vv_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2,
                                     vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsgt_vx_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsgt_vv_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsgt_vx_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       int64_t rs1, size_t vl);
vbool32_t __riscv_vmsgt_vv_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsgt_vx_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       int64_t rs1, size_t vl);
vbool16_t __riscv_vmsgt_vv_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsgt_vx_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       int64_t rs1, size_t vl);
vbool8_t __riscv_vmsgt_vv_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2,
                                     vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsgt_vx_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsge_vv_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2,
                                       vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsge_vx_i8mf8_b64_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                       size_t vl);
vbool32_t __riscv_vmsge_vv_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2,
                                       vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsge_vx_i8mf4_b32_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                       size_t vl);
vbool16_t __riscv_vmsge_vv_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2,
                                       vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsge_vx_i8mf2_b16_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                       size_t vl);
vbool8_t __riscv_vmsge_vv_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsge_vx_i8m1_b8_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                    size_t vl);
vbool4_t __riscv_vmsge_vv_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsge_vx_i8m2_b4_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                    size_t vl);
vbool2_t __riscv_vmsge_vv_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmsge_vx_i8m4_b2_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                    size_t vl);
vbool1_t __riscv_vmsge_vv_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                    size_t vl);
vbool1_t __riscv_vmsge_vx_i8m8_b1_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                    size_t vl);
vbool64_t __riscv_vmsge_vv_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsge_vx_i16mf4_b64_m(vbool64_t vm, vint16mf4_t vs2,
                                        int16_t rs1, size_t vl);
vbool32_t __riscv_vmsge_vv_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsge_vx_i16mf2_b32_m(vbool32_t vm, vint16mf2_t vs2,
                                        int16_t rs1, size_t vl);
vbool16_t __riscv_vmsge_vv_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsge_vx_i16m1_b16_m(vbool16_t vm, vint16m1_t vs2,
                                       int16_t rs1, size_t vl);
vbool8_t __riscv_vmsge_vv_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2,
                                     vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsge_vx_i16m2_b8_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsge_vv_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2,
                                     vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsge_vx_i16m4_b4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmsge_vv_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2,
                                     vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsge_vx_i16m8_b2_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsge_vv_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsge_vx_i32mf2_b64_m(vbool64_t vm, vint32mf2_t vs2,
                                        int32_t rs1, size_t vl);
vbool32_t __riscv_vmsge_vv_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsge_vx_i32m1_b32_m(vbool32_t vm, vint32m1_t vs2,
                                       int32_t rs1, size_t vl);
vbool16_t __riscv_vmsge_vv_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsge_vx_i32m2_b16_m(vbool16_t vm, vint32m2_t vs2,
                                       int32_t rs1, size_t vl);
vbool8_t __riscv_vmsge_vv_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2,
                                     vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsge_vx_i32m4_b8_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsge_vv_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2,
                                     vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsge_vx_i32m8_b4_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsge_vv_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsge_vx_i64m1_b64_m(vbool64_t vm, vint64m1_t vs2,
                                       int64_t rs1, size_t vl);
vbool32_t __riscv_vmsge_vv_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsge_vx_i64m2_b32_m(vbool32_t vm, vint64m2_t vs2,
                                       int64_t rs1, size_t vl);
vbool16_t __riscv_vmsge_vv_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsge_vx_i64m4_b16_m(vbool16_t vm, vint64m4_t vs2,
                                       int64_t rs1, size_t vl);
vbool8_t __riscv_vmsge_vv_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2,
                                     vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsge_vx_i64m8_b8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmseq_vv_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                       vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmseq_vx_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                       uint8_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                       vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                       uint8_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                       vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                       uint8_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmseq_vx_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                    size_t vl);
vbool4_t __riscv_vmseq_vv_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmseq_vx_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                    size_t vl);
vbool2_t __riscv_vmseq_vv_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmseq_vx_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                    size_t vl);
vbool1_t __riscv_vmseq_vv_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                    size_t vl);
vbool1_t __riscv_vmseq_vx_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                    size_t vl);
vbool64_t __riscv_vmseq_vv_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmseq_vx_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint16_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                        vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                        uint16_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                       vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                       uint16_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2,
                                     vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmseq_vv_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2,
                                     vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmseq_vx_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmseq_vv_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2,
                                     vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmseq_vx_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmseq_vv_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                        vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmseq_vx_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                        uint32_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                       vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                       uint32_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                       vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                       uint32_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2,
                                     vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmseq_vv_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2,
                                     vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmseq_vx_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmseq_vv_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                       vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmseq_vx_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                       uint64_t rs1, size_t vl);
vbool32_t __riscv_vmseq_vv_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                       vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmseq_vx_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                       uint64_t rs1, size_t vl);
vbool16_t __riscv_vmseq_vv_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                       vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmseq_vx_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                       uint64_t rs1, size_t vl);
vbool8_t __riscv_vmseq_vv_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2,
                                     vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmseq_vx_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsne_vv_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                       vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsne_vx_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                       uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                       vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                       uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                       vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                       uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                    size_t vl);
vbool8_t __riscv_vmsne_vx_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                    size_t vl);
vbool4_t __riscv_vmsne_vv_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                    size_t vl);
vbool4_t __riscv_vmsne_vx_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                    size_t vl);
vbool2_t __riscv_vmsne_vv_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                    size_t vl);
vbool2_t __riscv_vmsne_vx_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                    size_t vl);
vbool1_t __riscv_vmsne_vv_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                    size_t vl);
vbool1_t __riscv_vmsne_vx_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                    size_t vl);
vbool64_t __riscv_vmsne_vv_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsne_vx_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                        vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                        uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                       vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                       uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2,
                                     vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsne_vv_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2,
                                     vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsne_vx_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmsne_vv_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2,
                                     vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsne_vx_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsne_vv_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                        vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsne_vx_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                        uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                       vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                       uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                       vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                       uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2,
                                     vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsne_vv_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2,
                                     vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsne_vx_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsne_vv_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                       vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsne_vx_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                       uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsne_vv_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                       vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsne_vx_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                       uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsne_vv_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                       vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsne_vx_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                       uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsne_vv_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2,
                                     vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsne_vx_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsltu_vv_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsltu_vx_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                        uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsltu_vv_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsltu_vx_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                        uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsltu_vv_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                        vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsltu_vx_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                        uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsltu_vv_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2,
                                     vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsltu_vx_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsltu_vv_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2,
                                     vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsltu_vx_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmsltu_vv_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2,
                                     vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsltu_vx_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                     size_t vl);
vbool1_t __riscv_vmsltu_vv_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2,
                                     vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsltu_vx_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsltu_vv_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                         vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsltu_vx_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                         uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsltu_vv_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                         vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsltu_vx_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                         uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsltu_vv_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                        vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsltu_vx_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                        uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsltu_vv_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsltu_vx_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsltu_vv_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsltu_vx_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsltu_vv_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsltu_vx_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2,
                                      uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsltu_vv_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                         vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsltu_vx_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                         uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsltu_vv_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                        vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsltu_vx_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                        uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsltu_vv_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                        vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsltu_vx_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                        uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsltu_vv_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsltu_vx_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsltu_vv_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsltu_vx_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsltu_vv_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                        vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsltu_vx_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                        uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsltu_vv_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                        vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsltu_vx_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                        uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsltu_vv_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                        vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsltu_vx_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                        uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsltu_vv_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsltu_vx_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsleu_vv_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsleu_vx_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                        uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsleu_vv_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsleu_vx_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                        uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsleu_vv_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                        vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsleu_vx_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                        uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsleu_vv_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2,
                                     vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsleu_vx_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsleu_vv_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2,
                                     vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsleu_vx_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmsleu_vv_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2,
                                     vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsleu_vx_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                     size_t vl);
vbool1_t __riscv_vmsleu_vv_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2,
                                     vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsleu_vx_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsleu_vv_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                         vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsleu_vx_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                         uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsleu_vv_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                         vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsleu_vx_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                         uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsleu_vv_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                        vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsleu_vx_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                        uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsleu_vv_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsleu_vx_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsleu_vv_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsleu_vx_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsleu_vv_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsleu_vx_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2,
                                      uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsleu_vv_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                         vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsleu_vx_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                         uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsleu_vv_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                        vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsleu_vx_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                        uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsleu_vv_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                        vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsleu_vx_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                        uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsleu_vv_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsleu_vx_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsleu_vv_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsleu_vx_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsleu_vv_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                        vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsleu_vx_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                        uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsleu_vv_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                        vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsleu_vx_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                        uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsleu_vv_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                        vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsleu_vx_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                        uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsleu_vv_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsleu_vx_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu_vv_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsgtu_vx_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                        uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu_vv_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsgtu_vx_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                        uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu_vv_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                        vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsgtu_vx_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                        uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu_vv_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2,
                                     vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgtu_vx_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsgtu_vv_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2,
                                     vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgtu_vx_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmsgtu_vv_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2,
                                     vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgtu_vx_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                     size_t vl);
vbool1_t __riscv_vmsgtu_vv_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2,
                                     vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgtu_vx_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsgtu_vv_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                         vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsgtu_vx_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                         uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu_vv_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                         vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsgtu_vx_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                         uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu_vv_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                        vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsgtu_vx_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                        uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu_vv_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsgtu_vx_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu_vv_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsgtu_vx_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsgtu_vv_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsgtu_vx_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2,
                                      uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu_vv_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                         vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsgtu_vx_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                         uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu_vv_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                        vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsgtu_vx_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                        uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu_vv_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                        vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsgtu_vx_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                        uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu_vv_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsgtu_vx_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu_vv_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsgtu_vx_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu_vv_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                        vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsgtu_vx_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                        uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu_vv_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                        vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsgtu_vx_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                        uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu_vv_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                        vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsgtu_vx_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                        uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu_vv_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsgtu_vx_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu_vv_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsgeu_vx_u8mf8_b64_m(vbool64_t vm, vuint8mf8_t vs2,
                                        uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu_vv_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsgeu_vx_u8mf4_b32_m(vbool32_t vm, vuint8mf4_t vs2,
                                        uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu_vv_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                        vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsgeu_vx_u8mf2_b16_m(vbool16_t vm, vuint8mf2_t vs2,
                                        uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu_vv_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2,
                                     vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgeu_vx_u8m1_b8_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                     size_t vl);
vbool4_t __riscv_vmsgeu_vv_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2,
                                     vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgeu_vx_u8m2_b4_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                     size_t vl);
vbool2_t __riscv_vmsgeu_vv_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2,
                                     vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgeu_vx_u8m4_b2_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                     size_t vl);
vbool1_t __riscv_vmsgeu_vv_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2,
                                     vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgeu_vx_u8m8_b1_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                     size_t vl);
vbool64_t __riscv_vmsgeu_vv_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                         vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsgeu_vx_u16mf4_b64_m(vbool64_t vm, vuint16mf4_t vs2,
                                         uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu_vv_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                         vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsgeu_vx_u16mf2_b32_m(vbool32_t vm, vuint16mf2_t vs2,
                                         uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu_vv_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                        vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsgeu_vx_u16m1_b16_m(vbool16_t vm, vuint16m1_t vs2,
                                        uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu_vv_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsgeu_vx_u16m2_b8_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu_vv_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsgeu_vx_u16m4_b4_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsgeu_vv_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsgeu_vx_u16m8_b2_m(vbool2_t vm, vuint16m8_t vs2,
                                      uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu_vv_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                         vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsgeu_vx_u32mf2_b64_m(vbool64_t vm, vuint32mf2_t vs2,
                                         uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu_vv_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                        vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsgeu_vx_u32m1_b32_m(vbool32_t vm, vuint32m1_t vs2,
                                        uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu_vv_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                        vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsgeu_vx_u32m2_b16_m(vbool16_t vm, vuint32m2_t vs2,
                                        uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu_vv_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsgeu_vx_u32m4_b8_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu_vv_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsgeu_vx_u32m8_b4_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu_vv_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                        vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsgeu_vx_u64m1_b64_m(vbool64_t vm, vuint64m1_t vs2,
                                        uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu_vv_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                        vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsgeu_vx_u64m2_b32_m(vbool32_t vm, vuint64m2_t vs2,
                                        uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu_vv_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                        vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsgeu_vx_u64m4_b16_m(vbool16_t vm, vuint64m4_t vs2,
                                        uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu_vv_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsgeu_vx_u64m8_b8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint64_t rs1, size_t vl);
----

[[vector-integer-minmax]]
==== Vector Integer Min/Max Intrinsics

[,c]
----
vint8mf8_t __riscv_vmin_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmin_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmin_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmin_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmin_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmin_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmin_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmin_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmin_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmin_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmin_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmin_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmin_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmin_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmin_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmin_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmin_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmin_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmin_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmin_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmin_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmin_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmin_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmin_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmin_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmin_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmin_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmin_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmin_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmin_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmin_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmin_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmin_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmin_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmin_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmin_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmin_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmin_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmin_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmin_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmin_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmin_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmin_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmin_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vmax_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmax_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmax_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmax_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmax_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmax_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmax_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmax_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmax_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmax_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmax_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmax_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmax_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmax_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmax_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmax_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmax_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmax_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmax_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmax_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmax_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmax_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmax_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmax_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmax_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmax_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmax_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmax_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmax_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmax_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmax_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmax_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmax_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmax_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmax_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmax_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmax_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmax_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmax_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmax_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmax_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmax_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmax_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmax_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vminu_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vminu_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vminu_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vminu_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vminu_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vminu_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vminu_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vminu_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vminu_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vminu_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vminu_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vminu_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vminu_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vminu_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vminu_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                     size_t vl);
vuint16mf4_t __riscv_vminu_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vminu_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                     size_t vl);
vuint16mf2_t __riscv_vminu_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vminu_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vminu_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vminu_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vminu_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vminu_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vminu_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vminu_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vminu_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vminu_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                     size_t vl);
vuint32mf2_t __riscv_vminu_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vminu_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vminu_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vminu_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vminu_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vminu_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vminu_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vminu_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vminu_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vminu_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vminu_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vminu_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vminu_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vminu_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vminu_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vminu_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vminu_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vmaxu_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vmaxu_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vmaxu_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vmaxu_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vmaxu_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vmaxu_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vmaxu_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vmaxu_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vmaxu_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vmaxu_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vmaxu_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vmaxu_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vmaxu_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vmaxu_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vmaxu_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                     size_t vl);
vuint16mf4_t __riscv_vmaxu_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vmaxu_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                     size_t vl);
vuint16mf2_t __riscv_vmaxu_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vmaxu_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vmaxu_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vmaxu_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vmaxu_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vmaxu_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vmaxu_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vmaxu_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vmaxu_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vmaxu_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                     size_t vl);
vuint32mf2_t __riscv_vmaxu_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vmaxu_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vmaxu_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vmaxu_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vmaxu_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vmaxu_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vmaxu_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vmaxu_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vmaxu_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vmaxu_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vmaxu_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vmaxu_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vmaxu_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vmaxu_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vmaxu_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vmaxu_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vmaxu_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vmin_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                                   size_t vl);
vint8mf8_t __riscv_vmin_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vmin_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                                   size_t vl);
vint8mf4_t __riscv_vmin_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vmin_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                                   size_t vl);
vint8mf2_t __riscv_vmin_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vmin_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vmin_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vmin_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vmin_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vmin_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vmin_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vmin_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vmin_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vmin_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmin_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vmin_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmin_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vmin_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                                   size_t vl);
vint16m1_t __riscv_vmin_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vmin_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vmin_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vmin_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vmin_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vmin_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vmin_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vmin_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmin_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vmin_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                                   size_t vl);
vint32m1_t __riscv_vmin_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vmin_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                                   size_t vl);
vint32m2_t __riscv_vmin_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vmin_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vmin_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vmin_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vmin_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vmin_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                                   size_t vl);
vint64m1_t __riscv_vmin_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vmin_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                                   size_t vl);
vint64m2_t __riscv_vmin_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vmin_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                                   size_t vl);
vint64m4_t __riscv_vmin_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vmin_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vmin_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                   size_t vl);
vint8mf8_t __riscv_vmax_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                                   size_t vl);
vint8mf8_t __riscv_vmax_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vmax_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                                   size_t vl);
vint8mf4_t __riscv_vmax_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vmax_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                                   size_t vl);
vint8mf2_t __riscv_vmax_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vmax_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vmax_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vmax_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vmax_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vmax_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vmax_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vmax_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vmax_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vmax_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmax_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vmax_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmax_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vmax_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                                   size_t vl);
vint16m1_t __riscv_vmax_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vmax_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vmax_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vmax_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vmax_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vmax_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vmax_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vmax_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmax_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vmax_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                                   size_t vl);
vint32m1_t __riscv_vmax_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vmax_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                                   size_t vl);
vint32m2_t __riscv_vmax_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vmax_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vmax_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vmax_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vmax_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vmax_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                                   size_t vl);
vint64m1_t __riscv_vmax_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vmax_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                                   size_t vl);
vint64m2_t __riscv_vmax_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vmax_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                                   size_t vl);
vint64m4_t __riscv_vmax_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vmax_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vmax_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                   size_t vl);
vuint8mf8_t __riscv_vminu_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                     vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vminu_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8mf4_t __riscv_vminu_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                     vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vminu_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8mf2_t __riscv_vminu_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                     vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vminu_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8m1_t __riscv_vminu_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                   size_t vl);
vuint8m1_t __riscv_vminu_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m2_t __riscv_vminu_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                   size_t vl);
vuint8m2_t __riscv_vminu_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m4_t __riscv_vminu_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                   size_t vl);
vuint8m4_t __riscv_vminu_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m8_t __riscv_vminu_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                   size_t vl);
vuint8m8_t __riscv_vminu_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                   size_t vl);
vuint16mf4_t __riscv_vminu_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vminu_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vminu_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vminu_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vminu_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                     vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vminu_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                     uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vminu_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                     vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vminu_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                     size_t vl);
vuint16m4_t __riscv_vminu_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                     vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vminu_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                     size_t vl);
vuint16m8_t __riscv_vminu_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                     vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vminu_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                     size_t vl);
vuint32mf2_t __riscv_vminu_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vminu_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vminu_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                     vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vminu_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vminu_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                     vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vminu_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vminu_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                     vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vminu_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                     size_t vl);
vuint32m8_t __riscv_vminu_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                     vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vminu_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                     size_t vl);
vuint64m1_t __riscv_vminu_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                     vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vminu_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vminu_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                     vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vminu_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vminu_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                     vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vminu_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vminu_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                     vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vminu_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                     size_t vl);
vuint8mf8_t __riscv_vmaxu_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                     vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vmaxu_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8mf4_t __riscv_vmaxu_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                     vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vmaxu_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8mf2_t __riscv_vmaxu_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                     vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vmaxu_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8m1_t __riscv_vmaxu_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                   size_t vl);
vuint8m1_t __riscv_vmaxu_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m2_t __riscv_vmaxu_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                   size_t vl);
vuint8m2_t __riscv_vmaxu_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m4_t __riscv_vmaxu_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                   size_t vl);
vuint8m4_t __riscv_vmaxu_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m8_t __riscv_vmaxu_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                   size_t vl);
vuint8m8_t __riscv_vmaxu_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                   size_t vl);
vuint16mf4_t __riscv_vmaxu_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vmaxu_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vmaxu_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vmaxu_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vmaxu_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                     vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vmaxu_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                     uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vmaxu_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                     vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vmaxu_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                     size_t vl);
vuint16m4_t __riscv_vmaxu_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                     vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vmaxu_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                     size_t vl);
vuint16m8_t __riscv_vmaxu_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                     vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vmaxu_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                     size_t vl);
vuint32mf2_t __riscv_vmaxu_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vmaxu_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vmaxu_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                     vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vmaxu_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vmaxu_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                     vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vmaxu_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vmaxu_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                     vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vmaxu_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                     size_t vl);
vuint32m8_t __riscv_vmaxu_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                     vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vmaxu_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                     size_t vl);
vuint64m1_t __riscv_vmaxu_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                     vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vmaxu_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vmaxu_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                     vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vmaxu_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vmaxu_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                     vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vmaxu_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vmaxu_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                     vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vmaxu_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                     size_t vl);
----

[[vector-single-width-integer-multiply]]
==== Vector Single-Width Integer Multiply Intrinsics

[,c]
----
vint8mf8_t __riscv_vmul_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmul_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmul_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmul_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmul_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmul_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmul_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmul_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmul_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmul_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmul_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmul_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmul_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmul_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmul_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmul_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmul_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmul_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmul_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmul_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmul_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmul_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmul_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmul_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmul_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmul_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmul_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmul_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmul_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmul_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmul_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmul_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmul_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmul_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmul_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmul_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmul_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmul_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmul_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmul_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmul_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmul_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmul_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmul_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vmulh_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmulh_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmulh_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmulh_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmulh_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmulh_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmulh_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmulh_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmulh_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmulh_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmulh_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmulh_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmulh_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmulh_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmulh_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1,
                                    size_t vl);
vint16mf4_t __riscv_vmulh_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmulh_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1,
                                    size_t vl);
vint16mf2_t __riscv_vmulh_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmulh_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmulh_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmulh_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmulh_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmulh_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmulh_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmulh_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmulh_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmulh_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1,
                                    size_t vl);
vint32mf2_t __riscv_vmulh_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmulh_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmulh_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmulh_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmulh_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmulh_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmulh_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmulh_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmulh_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmulh_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmulh_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmulh_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmulh_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmulh_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmulh_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmulh_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmulh_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vmulhsu_vv_i8mf8(vint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmulhsu_vx_i8mf8(vint8mf8_t vs2, uint8_t rs1, size_t vl);
vint8mf4_t __riscv_vmulhsu_vv_i8mf4(vint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmulhsu_vx_i8mf4(vint8mf4_t vs2, uint8_t rs1, size_t vl);
vint8mf2_t __riscv_vmulhsu_vv_i8mf2(vint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmulhsu_vx_i8mf2(vint8mf2_t vs2, uint8_t rs1, size_t vl);
vint8m1_t __riscv_vmulhsu_vv_i8m1(vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmulhsu_vx_i8m1(vint8m1_t vs2, uint8_t rs1, size_t vl);
vint8m2_t __riscv_vmulhsu_vv_i8m2(vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmulhsu_vx_i8m2(vint8m2_t vs2, uint8_t rs1, size_t vl);
vint8m4_t __riscv_vmulhsu_vv_i8m4(vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmulhsu_vx_i8m4(vint8m4_t vs2, uint8_t rs1, size_t vl);
vint8m8_t __riscv_vmulhsu_vv_i8m8(vint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmulhsu_vx_i8m8(vint8m8_t vs2, uint8_t rs1, size_t vl);
vint16mf4_t __riscv_vmulhsu_vv_i16mf4(vint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vint16mf4_t __riscv_vmulhsu_vx_i16mf4(vint16mf4_t vs2, uint16_t rs1, size_t vl);
vint16mf2_t __riscv_vmulhsu_vv_i16mf2(vint16mf2_t vs2, vuint16mf2_t vs1,
                                      size_t vl);
vint16mf2_t __riscv_vmulhsu_vx_i16mf2(vint16mf2_t vs2, uint16_t rs1, size_t vl);
vint16m1_t __riscv_vmulhsu_vv_i16m1(vint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmulhsu_vx_i16m1(vint16m1_t vs2, uint16_t rs1, size_t vl);
vint16m2_t __riscv_vmulhsu_vv_i16m2(vint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmulhsu_vx_i16m2(vint16m2_t vs2, uint16_t rs1, size_t vl);
vint16m4_t __riscv_vmulhsu_vv_i16m4(vint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmulhsu_vx_i16m4(vint16m4_t vs2, uint16_t rs1, size_t vl);
vint16m8_t __riscv_vmulhsu_vv_i16m8(vint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmulhsu_vx_i16m8(vint16m8_t vs2, uint16_t rs1, size_t vl);
vint32mf2_t __riscv_vmulhsu_vv_i32mf2(vint32mf2_t vs2, vuint32mf2_t vs1,
                                      size_t vl);
vint32mf2_t __riscv_vmulhsu_vx_i32mf2(vint32mf2_t vs2, uint32_t rs1, size_t vl);
vint32m1_t __riscv_vmulhsu_vv_i32m1(vint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmulhsu_vx_i32m1(vint32m1_t vs2, uint32_t rs1, size_t vl);
vint32m2_t __riscv_vmulhsu_vv_i32m2(vint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmulhsu_vx_i32m2(vint32m2_t vs2, uint32_t rs1, size_t vl);
vint32m4_t __riscv_vmulhsu_vv_i32m4(vint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmulhsu_vx_i32m4(vint32m4_t vs2, uint32_t rs1, size_t vl);
vint32m8_t __riscv_vmulhsu_vv_i32m8(vint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmulhsu_vx_i32m8(vint32m8_t vs2, uint32_t rs1, size_t vl);
vint64m1_t __riscv_vmulhsu_vv_i64m1(vint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmulhsu_vx_i64m1(vint64m1_t vs2, uint64_t rs1, size_t vl);
vint64m2_t __riscv_vmulhsu_vv_i64m2(vint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmulhsu_vx_i64m2(vint64m2_t vs2, uint64_t rs1, size_t vl);
vint64m4_t __riscv_vmulhsu_vv_i64m4(vint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmulhsu_vx_i64m4(vint64m4_t vs2, uint64_t rs1, size_t vl);
vint64m8_t __riscv_vmulhsu_vv_i64m8(vint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmulhsu_vx_i64m8(vint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vmul_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vmul_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vmul_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vmul_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vmul_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vmul_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vmul_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vmul_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vmul_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vmul_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vmul_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vmul_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vmul_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vmul_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vmul_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                    size_t vl);
vuint16mf4_t __riscv_vmul_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vmul_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint16mf2_t __riscv_vmul_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vmul_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vmul_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vmul_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vmul_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vmul_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vmul_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vmul_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vmul_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vmul_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint32mf2_t __riscv_vmul_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vmul_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vmul_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vmul_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vmul_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vmul_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vmul_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vmul_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vmul_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vmul_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vmul_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vmul_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vmul_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vmul_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vmul_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vmul_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vmul_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vmulhu_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                    size_t vl);
vuint8mf8_t __riscv_vmulhu_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vmulhu_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                    size_t vl);
vuint8mf4_t __riscv_vmulhu_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vmulhu_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                    size_t vl);
vuint8mf2_t __riscv_vmulhu_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vmulhu_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vmulhu_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vmulhu_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vmulhu_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vmulhu_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vmulhu_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vmulhu_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vmulhu_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vmulhu_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vuint16mf4_t __riscv_vmulhu_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1,
                                      size_t vl);
vuint16mf2_t __riscv_vmulhu_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                      size_t vl);
vuint16mf2_t __riscv_vmulhu_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1,
                                      size_t vl);
vuint16m1_t __riscv_vmulhu_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                    size_t vl);
vuint16m1_t __riscv_vmulhu_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vmulhu_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vuint16m2_t __riscv_vmulhu_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vmulhu_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vuint16m4_t __riscv_vmulhu_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vmulhu_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                    size_t vl);
vuint16m8_t __riscv_vmulhu_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vmulhu_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                      size_t vl);
vuint32mf2_t __riscv_vmulhu_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1,
                                      size_t vl);
vuint32m1_t __riscv_vmulhu_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                    size_t vl);
vuint32m1_t __riscv_vmulhu_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vmulhu_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1,
                                    size_t vl);
vuint32m2_t __riscv_vmulhu_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vmulhu_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vuint32m4_t __riscv_vmulhu_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vmulhu_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1,
                                    size_t vl);
vuint32m8_t __riscv_vmulhu_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vmulhu_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                    size_t vl);
vuint64m1_t __riscv_vmulhu_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vmulhu_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1,
                                    size_t vl);
vuint64m2_t __riscv_vmulhu_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vmulhu_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1,
                                    size_t vl);
vuint64m4_t __riscv_vmulhu_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vmulhu_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    size_t vl);
vuint64m8_t __riscv_vmulhu_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vmul_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                                   size_t vl);
vint8mf8_t __riscv_vmul_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vmul_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                                   size_t vl);
vint8mf4_t __riscv_vmul_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vmul_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                                   size_t vl);
vint8mf2_t __riscv_vmul_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vmul_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vmul_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vmul_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vmul_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vmul_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vmul_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vmul_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vmul_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vmul_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmul_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vmul_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmul_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vmul_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                                   size_t vl);
vint16m1_t __riscv_vmul_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vmul_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vmul_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vmul_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vmul_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vmul_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vmul_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vmul_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmul_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vmul_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                                   size_t vl);
vint32m1_t __riscv_vmul_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vmul_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                                   size_t vl);
vint32m2_t __riscv_vmul_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vmul_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vmul_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vmul_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vmul_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vmul_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                                   size_t vl);
vint64m1_t __riscv_vmul_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vmul_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                                   size_t vl);
vint64m2_t __riscv_vmul_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vmul_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                                   size_t vl);
vint64m4_t __riscv_vmul_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vmul_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vmul_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                   size_t vl);
vint8mf8_t __riscv_vmulh_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                    vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmulh_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                    size_t vl);
vint8mf4_t __riscv_vmulh_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                    vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmulh_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                    size_t vl);
vint8mf2_t __riscv_vmulh_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                    vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmulh_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                    size_t vl);
vint8m1_t __riscv_vmulh_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                  size_t vl);
vint8m1_t __riscv_vmulh_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                  size_t vl);
vint8m2_t __riscv_vmulh_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                  size_t vl);
vint8m2_t __riscv_vmulh_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                  size_t vl);
vint8m4_t __riscv_vmulh_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                  size_t vl);
vint8m4_t __riscv_vmulh_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                  size_t vl);
vint8m8_t __riscv_vmulh_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                  size_t vl);
vint8m8_t __riscv_vmulh_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                  size_t vl);
vint16mf4_t __riscv_vmulh_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmulh_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmulh_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmulh_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      int16_t rs1, size_t vl);
vint16m1_t __riscv_vmulh_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                    vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmulh_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                    size_t vl);
vint16m2_t __riscv_vmulh_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                    size_t vl);
vint16m2_t __riscv_vmulh_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                    size_t vl);
vint16m4_t __riscv_vmulh_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                    size_t vl);
vint16m4_t __riscv_vmulh_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                    size_t vl);
vint16m8_t __riscv_vmulh_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                    size_t vl);
vint16m8_t __riscv_vmulh_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                    size_t vl);
vint32mf2_t __riscv_vmulh_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmulh_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      int32_t rs1, size_t vl);
vint32m1_t __riscv_vmulh_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                    vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmulh_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                    size_t vl);
vint32m2_t __riscv_vmulh_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                    vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmulh_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                    size_t vl);
vint32m4_t __riscv_vmulh_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                    size_t vl);
vint32m4_t __riscv_vmulh_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                    size_t vl);
vint32m8_t __riscv_vmulh_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                    size_t vl);
vint32m8_t __riscv_vmulh_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                    size_t vl);
vint64m1_t __riscv_vmulh_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                    vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmulh_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                    size_t vl);
vint64m2_t __riscv_vmulh_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                    vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmulh_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                    size_t vl);
vint64m4_t __riscv_vmulh_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                    vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmulh_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                    size_t vl);
vint64m8_t __riscv_vmulh_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                    size_t vl);
vint64m8_t __riscv_vmulh_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                    size_t vl);
vint8mf8_t __riscv_vmulhsu_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                      vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmulhsu_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, uint8_t rs1,
                                      size_t vl);
vint8mf4_t __riscv_vmulhsu_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                      vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmulhsu_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, uint8_t rs1,
                                      size_t vl);
vint8mf2_t __riscv_vmulhsu_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                      vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmulhsu_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, uint8_t rs1,
                                      size_t vl);
vint8m1_t __riscv_vmulhsu_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vuint8m1_t vs1,
                                    size_t vl);
vint8m1_t __riscv_vmulhsu_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, uint8_t rs1,
                                    size_t vl);
vint8m2_t __riscv_vmulhsu_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vuint8m2_t vs1,
                                    size_t vl);
vint8m2_t __riscv_vmulhsu_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, uint8_t rs1,
                                    size_t vl);
vint8m4_t __riscv_vmulhsu_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vuint8m4_t vs1,
                                    size_t vl);
vint8m4_t __riscv_vmulhsu_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, uint8_t rs1,
                                    size_t vl);
vint8m8_t __riscv_vmulhsu_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vuint8m8_t vs1,
                                    size_t vl);
vint8m8_t __riscv_vmulhsu_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, uint8_t rs1,
                                    size_t vl);
vint16mf4_t __riscv_vmulhsu_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmulhsu_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                        uint16_t rs1, size_t vl);
vint16mf2_t __riscv_vmulhsu_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                        vuint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmulhsu_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                        uint16_t rs1, size_t vl);
vint16m1_t __riscv_vmulhsu_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                      vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmulhsu_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                      uint16_t rs1, size_t vl);
vint16m2_t __riscv_vmulhsu_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmulhsu_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, uint16_t rs1,
                                      size_t vl);
vint16m4_t __riscv_vmulhsu_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmulhsu_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, uint16_t rs1,
                                      size_t vl);
vint16m8_t __riscv_vmulhsu_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2,
                                      vuint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmulhsu_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, uint16_t rs1,
                                      size_t vl);
vint32mf2_t __riscv_vmulhsu_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                        vuint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmulhsu_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                        uint32_t rs1, size_t vl);
vint32m1_t __riscv_vmulhsu_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                      vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmulhsu_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                      uint32_t rs1, size_t vl);
vint32m2_t __riscv_vmulhsu_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                      vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmulhsu_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                      uint32_t rs1, size_t vl);
vint32m4_t __riscv_vmulhsu_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmulhsu_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, uint32_t rs1,
                                      size_t vl);
vint32m8_t __riscv_vmulhsu_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2,
                                      vuint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmulhsu_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, uint32_t rs1,
                                      size_t vl);
vint64m1_t __riscv_vmulhsu_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                      vuint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmulhsu_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                      uint64_t rs1, size_t vl);
vint64m2_t __riscv_vmulhsu_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                      vuint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmulhsu_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                      uint64_t rs1, size_t vl);
vint64m4_t __riscv_vmulhsu_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                      vuint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmulhsu_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                      uint64_t rs1, size_t vl);
vint64m8_t __riscv_vmulhsu_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2,
                                      vuint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmulhsu_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, uint64_t rs1,
                                      size_t vl);
vuint8mf8_t __riscv_vmul_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                    vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vmul_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8mf4_t __riscv_vmul_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                    vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vmul_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8mf2_t __riscv_vmul_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                    vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vmul_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m1_t __riscv_vmul_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                  size_t vl);
vuint8m1_t __riscv_vmul_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m2_t __riscv_vmul_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                  size_t vl);
vuint8m2_t __riscv_vmul_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m4_t __riscv_vmul_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                  size_t vl);
vuint8m4_t __riscv_vmul_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                  size_t vl);
vuint8m8_t __riscv_vmul_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                  size_t vl);
vuint8m8_t __riscv_vmul_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                  size_t vl);
vuint16mf4_t __riscv_vmul_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vmul_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vmul_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vmul_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vmul_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                    vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vmul_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m2_t __riscv_vmul_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                    vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vmul_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m4_t __riscv_vmul_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                    vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vmul_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                    size_t vl);
vuint16m8_t __riscv_vmul_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                    vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vmul_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                    size_t vl);
vuint32mf2_t __riscv_vmul_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vmul_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vmul_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                    vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vmul_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m2_t __riscv_vmul_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                    vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vmul_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m4_t __riscv_vmul_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                    vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vmul_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                    size_t vl);
vuint32m8_t __riscv_vmul_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                    vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vmul_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                    size_t vl);
vuint64m1_t __riscv_vmul_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                    vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vmul_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m2_t __riscv_vmul_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                    vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vmul_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m4_t __riscv_vmul_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                    vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vmul_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                                    size_t vl);
vuint64m8_t __riscv_vmul_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                    vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vmul_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                    size_t vl);
vuint8mf8_t __riscv_vmulhu_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                      vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vmulhu_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                      uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vmulhu_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                      vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vmulhu_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                      uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vmulhu_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                      vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vmulhu_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                      uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vmulhu_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                    size_t vl);
vuint8m1_t __riscv_vmulhu_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m2_t __riscv_vmulhu_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                    size_t vl);
vuint8m2_t __riscv_vmulhu_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m4_t __riscv_vmulhu_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                    size_t vl);
vuint8m4_t __riscv_vmulhu_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m8_t __riscv_vmulhu_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                    size_t vl);
vuint8m8_t __riscv_vmulhu_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                    size_t vl);
vuint16mf4_t __riscv_vmulhu_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vmulhu_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vmulhu_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vmulhu_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vmulhu_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vmulhu_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vmulhu_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vmulhu_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vmulhu_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vmulhu_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vmulhu_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vmulhu_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vmulhu_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vmulhu_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vmulhu_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vmulhu_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vmulhu_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vmulhu_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vmulhu_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vmulhu_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vmulhu_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vmulhu_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vmulhu_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vmulhu_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vmulhu_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vmulhu_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vmulhu_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vmulhu_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vmulhu_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vmulhu_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint64_t rs1, size_t vl);
----

[[vector-integer-divide]]
==== Vector Integer Divide Intrinsics

[,c]
----
vint8mf8_t __riscv_vdiv_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vdiv_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vdiv_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vdiv_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vdiv_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vdiv_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vdiv_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vdiv_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vdiv_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vdiv_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vdiv_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vdiv_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vdiv_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vdiv_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vdiv_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vdiv_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vdiv_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vdiv_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vdiv_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vdiv_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vdiv_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vdiv_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vdiv_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vdiv_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vdiv_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vdiv_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vdiv_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vdiv_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vdiv_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vdiv_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vdiv_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vdiv_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vdiv_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vdiv_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vdiv_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vdiv_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vdiv_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vdiv_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vdiv_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vdiv_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vdiv_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vdiv_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vdiv_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vdiv_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vrem_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vrem_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vrem_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vrem_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vrem_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vrem_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vrem_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vrem_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vrem_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vrem_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vrem_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vrem_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vrem_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vrem_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vrem_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vrem_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vrem_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vrem_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vrem_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vrem_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vrem_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vrem_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vrem_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vrem_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vrem_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vrem_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vrem_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vrem_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vrem_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vrem_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vrem_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vrem_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vrem_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vrem_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vrem_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vrem_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vrem_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vrem_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vrem_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vrem_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vrem_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vrem_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vrem_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vrem_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vdivu_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vdivu_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vdivu_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vdivu_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vdivu_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vdivu_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vdivu_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vdivu_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vdivu_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vdivu_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vdivu_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vdivu_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vdivu_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vdivu_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vdivu_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                     size_t vl);
vuint16mf4_t __riscv_vdivu_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vdivu_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                     size_t vl);
vuint16mf2_t __riscv_vdivu_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vdivu_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vdivu_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vdivu_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vdivu_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vdivu_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vdivu_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vdivu_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vdivu_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vdivu_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                     size_t vl);
vuint32mf2_t __riscv_vdivu_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vdivu_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vdivu_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vdivu_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vdivu_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vdivu_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vdivu_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vdivu_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vdivu_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vdivu_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vdivu_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vdivu_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vdivu_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vdivu_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vdivu_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vdivu_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vdivu_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vremu_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vremu_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vremu_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vremu_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vremu_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vremu_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vremu_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vremu_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vremu_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vremu_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vremu_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vremu_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vremu_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vremu_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vremu_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                     size_t vl);
vuint16mf4_t __riscv_vremu_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vremu_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                     size_t vl);
vuint16mf2_t __riscv_vremu_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vremu_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vremu_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vremu_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vremu_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vremu_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vremu_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vremu_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vremu_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vremu_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                     size_t vl);
vuint32mf2_t __riscv_vremu_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vremu_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vremu_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vremu_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vremu_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vremu_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vremu_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vremu_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vremu_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vremu_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vremu_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vremu_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vremu_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vremu_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vremu_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vremu_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vremu_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vdiv_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                                   size_t vl);
vint8mf8_t __riscv_vdiv_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vdiv_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                                   size_t vl);
vint8mf4_t __riscv_vdiv_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vdiv_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                                   size_t vl);
vint8mf2_t __riscv_vdiv_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vdiv_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vdiv_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vdiv_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vdiv_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vdiv_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vdiv_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vdiv_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vdiv_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vdiv_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vdiv_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vdiv_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vdiv_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vdiv_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                                   size_t vl);
vint16m1_t __riscv_vdiv_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vdiv_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vdiv_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vdiv_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vdiv_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vdiv_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vdiv_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vdiv_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vdiv_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vdiv_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                                   size_t vl);
vint32m1_t __riscv_vdiv_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vdiv_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                                   size_t vl);
vint32m2_t __riscv_vdiv_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vdiv_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vdiv_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vdiv_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vdiv_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vdiv_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                                   size_t vl);
vint64m1_t __riscv_vdiv_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vdiv_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                                   size_t vl);
vint64m2_t __riscv_vdiv_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vdiv_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                                   size_t vl);
vint64m4_t __riscv_vdiv_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vdiv_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vdiv_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                   size_t vl);
vint8mf8_t __riscv_vrem_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                                   size_t vl);
vint8mf8_t __riscv_vrem_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf4_t __riscv_vrem_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                                   size_t vl);
vint8mf4_t __riscv_vrem_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                   size_t vl);
vint8mf2_t __riscv_vrem_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                                   size_t vl);
vint8mf2_t __riscv_vrem_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                   size_t vl);
vint8m1_t __riscv_vrem_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                 size_t vl);
vint8m1_t __riscv_vrem_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                 size_t vl);
vint8m2_t __riscv_vrem_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                 size_t vl);
vint8m2_t __riscv_vrem_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                 size_t vl);
vint8m4_t __riscv_vrem_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                 size_t vl);
vint8m4_t __riscv_vrem_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                 size_t vl);
vint8m8_t __riscv_vrem_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                 size_t vl);
vint8m8_t __riscv_vrem_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                 size_t vl);
vint16mf4_t __riscv_vrem_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                     vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vrem_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                                     size_t vl);
vint16mf2_t __riscv_vrem_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                     vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vrem_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                     size_t vl);
vint16m1_t __riscv_vrem_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                                   size_t vl);
vint16m1_t __riscv_vrem_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                   size_t vl);
vint16m2_t __riscv_vrem_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                   size_t vl);
vint16m2_t __riscv_vrem_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                   size_t vl);
vint16m4_t __riscv_vrem_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                   size_t vl);
vint16m4_t __riscv_vrem_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                   size_t vl);
vint16m8_t __riscv_vrem_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                   size_t vl);
vint16m8_t __riscv_vrem_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                   size_t vl);
vint32mf2_t __riscv_vrem_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                     vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vrem_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                     size_t vl);
vint32m1_t __riscv_vrem_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                                   size_t vl);
vint32m1_t __riscv_vrem_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                   size_t vl);
vint32m2_t __riscv_vrem_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                                   size_t vl);
vint32m2_t __riscv_vrem_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                   size_t vl);
vint32m4_t __riscv_vrem_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                   size_t vl);
vint32m4_t __riscv_vrem_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                   size_t vl);
vint32m8_t __riscv_vrem_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                   size_t vl);
vint32m8_t __riscv_vrem_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                   size_t vl);
vint64m1_t __riscv_vrem_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                                   size_t vl);
vint64m1_t __riscv_vrem_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                   size_t vl);
vint64m2_t __riscv_vrem_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                                   size_t vl);
vint64m2_t __riscv_vrem_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                   size_t vl);
vint64m4_t __riscv_vrem_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                                   size_t vl);
vint64m4_t __riscv_vrem_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                   size_t vl);
vint64m8_t __riscv_vrem_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                   size_t vl);
vint64m8_t __riscv_vrem_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                   size_t vl);
vuint8mf8_t __riscv_vdivu_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                     vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vdivu_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8mf4_t __riscv_vdivu_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                     vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vdivu_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8mf2_t __riscv_vdivu_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                     vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vdivu_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8m1_t __riscv_vdivu_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                   size_t vl);
vuint8m1_t __riscv_vdivu_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m2_t __riscv_vdivu_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                   size_t vl);
vuint8m2_t __riscv_vdivu_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m4_t __riscv_vdivu_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                   size_t vl);
vuint8m4_t __riscv_vdivu_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m8_t __riscv_vdivu_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                   size_t vl);
vuint8m8_t __riscv_vdivu_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                   size_t vl);
vuint16mf4_t __riscv_vdivu_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vdivu_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vdivu_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vdivu_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vdivu_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                     vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vdivu_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                     uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vdivu_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                     vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vdivu_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                     size_t vl);
vuint16m4_t __riscv_vdivu_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                     vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vdivu_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                     size_t vl);
vuint16m8_t __riscv_vdivu_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                     vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vdivu_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                     size_t vl);
vuint32mf2_t __riscv_vdivu_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vdivu_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vdivu_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                     vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vdivu_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vdivu_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                     vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vdivu_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vdivu_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                     vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vdivu_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                     size_t vl);
vuint32m8_t __riscv_vdivu_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                     vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vdivu_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                     size_t vl);
vuint64m1_t __riscv_vdivu_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                     vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vdivu_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vdivu_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                     vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vdivu_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vdivu_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                     vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vdivu_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vdivu_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                     vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vdivu_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                     size_t vl);
vuint8mf8_t __riscv_vremu_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                     vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vremu_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8mf4_t __riscv_vremu_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                     vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vremu_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8mf2_t __riscv_vremu_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                     vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vremu_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                                     size_t vl);
vuint8m1_t __riscv_vremu_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                   size_t vl);
vuint8m1_t __riscv_vremu_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m2_t __riscv_vremu_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                   size_t vl);
vuint8m2_t __riscv_vremu_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m4_t __riscv_vremu_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                   size_t vl);
vuint8m4_t __riscv_vremu_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                   size_t vl);
vuint8m8_t __riscv_vremu_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                   size_t vl);
vuint8m8_t __riscv_vremu_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                   size_t vl);
vuint16mf4_t __riscv_vremu_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vremu_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vremu_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vremu_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vremu_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                     vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vremu_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                     uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vremu_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                     vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vremu_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                                     size_t vl);
vuint16m4_t __riscv_vremu_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                     vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vremu_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                                     size_t vl);
vuint16m8_t __riscv_vremu_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                     vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vremu_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                                     size_t vl);
vuint32mf2_t __riscv_vremu_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vremu_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vremu_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                     vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vremu_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vremu_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                     vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vremu_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                     uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vremu_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                     vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vremu_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                                     size_t vl);
vuint32m8_t __riscv_vremu_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                     vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vremu_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                                     size_t vl);
vuint64m1_t __riscv_vremu_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                     vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vremu_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vremu_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                     vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vremu_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vremu_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                     vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vremu_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                     uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vremu_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                     vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vremu_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                                     size_t vl);
----

[[vector-widening-integer-multiply]]
==== Vector Widening Integer Multiply Intrinsics

[,c]
----
vint16mf4_t __riscv_vwmul_vv_i16mf4(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwmul_vx_i16mf4(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwmul_vv_i16mf2(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwmul_vx_i16mf2(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwmul_vv_i16m1(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwmul_vx_i16m1(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwmul_vv_i16m2(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwmul_vx_i16m2(vint8m1_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwmul_vv_i16m4(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwmul_vx_i16m4(vint8m2_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwmul_vv_i16m8(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwmul_vx_i16m8(vint8m4_t vs2, int8_t rs1, size_t vl);
vint32mf2_t __riscv_vwmul_vv_i32mf2(vint16mf4_t vs2, vint16mf4_t vs1,
                                    size_t vl);
vint32mf2_t __riscv_vwmul_vx_i32mf2(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint32m1_t __riscv_vwmul_vv_i32m1(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwmul_vx_i32m1(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwmul_vv_i32m2(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwmul_vx_i32m2(vint16m1_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwmul_vv_i32m4(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwmul_vx_i32m4(vint16m2_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwmul_vv_i32m8(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwmul_vx_i32m8(vint16m4_t vs2, int16_t rs1, size_t vl);
vint64m1_t __riscv_vwmul_vv_i64m1(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwmul_vx_i64m1(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwmul_vv_i64m2(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwmul_vx_i64m2(vint32m1_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwmul_vv_i64m4(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwmul_vx_i64m4(vint32m2_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwmul_vv_i64m8(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwmul_vx_i64m8(vint32m4_t vs2, int32_t rs1, size_t vl);
vint16mf4_t __riscv_vwmulsu_vv_i16mf4(vint8mf8_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vint16mf4_t __riscv_vwmulsu_vx_i16mf4(vint8mf8_t vs2, uint8_t rs1, size_t vl);
vint16mf2_t __riscv_vwmulsu_vv_i16mf2(vint8mf4_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vint16mf2_t __riscv_vwmulsu_vx_i16mf2(vint8mf4_t vs2, uint8_t rs1, size_t vl);
vint16m1_t __riscv_vwmulsu_vv_i16m1(vint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwmulsu_vx_i16m1(vint8mf2_t vs2, uint8_t rs1, size_t vl);
vint16m2_t __riscv_vwmulsu_vv_i16m2(vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwmulsu_vx_i16m2(vint8m1_t vs2, uint8_t rs1, size_t vl);
vint16m4_t __riscv_vwmulsu_vv_i16m4(vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwmulsu_vx_i16m4(vint8m2_t vs2, uint8_t rs1, size_t vl);
vint16m8_t __riscv_vwmulsu_vv_i16m8(vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwmulsu_vx_i16m8(vint8m4_t vs2, uint8_t rs1, size_t vl);
vint32mf2_t __riscv_vwmulsu_vv_i32mf2(vint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vint32mf2_t __riscv_vwmulsu_vx_i32mf2(vint16mf4_t vs2, uint16_t rs1, size_t vl);
vint32m1_t __riscv_vwmulsu_vv_i32m1(vint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vint32m1_t __riscv_vwmulsu_vx_i32m1(vint16mf2_t vs2, uint16_t rs1, size_t vl);
vint32m2_t __riscv_vwmulsu_vv_i32m2(vint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwmulsu_vx_i32m2(vint16m1_t vs2, uint16_t rs1, size_t vl);
vint32m4_t __riscv_vwmulsu_vv_i32m4(vint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwmulsu_vx_i32m4(vint16m2_t vs2, uint16_t rs1, size_t vl);
vint32m8_t __riscv_vwmulsu_vv_i32m8(vint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwmulsu_vx_i32m8(vint16m4_t vs2, uint16_t rs1, size_t vl);
vint64m1_t __riscv_vwmulsu_vv_i64m1(vint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vint64m1_t __riscv_vwmulsu_vx_i64m1(vint32mf2_t vs2, uint32_t rs1, size_t vl);
vint64m2_t __riscv_vwmulsu_vv_i64m2(vint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwmulsu_vx_i64m2(vint32m1_t vs2, uint32_t rs1, size_t vl);
vint64m4_t __riscv_vwmulsu_vv_i64m4(vint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwmulsu_vx_i64m4(vint32m2_t vs2, uint32_t rs1, size_t vl);
vint64m8_t __riscv_vwmulsu_vv_i64m8(vint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwmulsu_vx_i64m8(vint32m4_t vs2, uint32_t rs1, size_t vl);
vuint16mf4_t __riscv_vwmulu_vv_u16mf4(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vuint16mf4_t __riscv_vwmulu_vx_u16mf4(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwmulu_vv_u16mf2(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vuint16mf2_t __riscv_vwmulu_vx_u16mf2(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwmulu_vv_u16m1(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                    size_t vl);
vuint16m1_t __riscv_vwmulu_vx_u16m1(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwmulu_vv_u16m2(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwmulu_vx_u16m2(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwmulu_vv_u16m4(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwmulu_vx_u16m4(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwmulu_vv_u16m8(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwmulu_vx_u16m8(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint32mf2_t __riscv_vwmulu_vv_u32mf2(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vuint32mf2_t __riscv_vwmulu_vx_u32mf2(vuint16mf4_t vs2, uint16_t rs1,
                                      size_t vl);
vuint32m1_t __riscv_vwmulu_vv_u32m1(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                    size_t vl);
vuint32m1_t __riscv_vwmulu_vx_u32m1(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwmulu_vv_u32m2(vuint16m1_t vs2, vuint16m1_t vs1,
                                    size_t vl);
vuint32m2_t __riscv_vwmulu_vx_u32m2(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwmulu_vv_u32m4(vuint16m2_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vuint32m4_t __riscv_vwmulu_vx_u32m4(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwmulu_vv_u32m8(vuint16m4_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vuint32m8_t __riscv_vwmulu_vx_u32m8(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint64m1_t __riscv_vwmulu_vv_u64m1(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                    size_t vl);
vuint64m1_t __riscv_vwmulu_vx_u64m1(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwmulu_vv_u64m2(vuint32m1_t vs2, vuint32m1_t vs1,
                                    size_t vl);
vuint64m2_t __riscv_vwmulu_vx_u64m2(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwmulu_vv_u64m4(vuint32m2_t vs2, vuint32m2_t vs1,
                                    size_t vl);
vuint64m4_t __riscv_vwmulu_vx_u64m4(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwmulu_vv_u64m8(vuint32m4_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vuint64m8_t __riscv_vwmulu_vx_u64m8(vuint32m4_t vs2, uint32_t rs1, size_t vl);
// masked functions
vint16mf4_t __riscv_vwmul_vv_i16mf4_m(vbool64_t vm, vint8mf8_t vs2,
                                      vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwmul_vx_i16mf4_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                      size_t vl);
vint16mf2_t __riscv_vwmul_vv_i16mf2_m(vbool32_t vm, vint8mf4_t vs2,
                                      vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwmul_vx_i16mf2_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                      size_t vl);
vint16m1_t __riscv_vwmul_vv_i16m1_m(vbool16_t vm, vint8mf2_t vs2,
                                    vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwmul_vx_i16m1_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                    size_t vl);
vint16m2_t __riscv_vwmul_vv_i16m2_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                    size_t vl);
vint16m2_t __riscv_vwmul_vx_i16m2_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                    size_t vl);
vint16m4_t __riscv_vwmul_vv_i16m4_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                    size_t vl);
vint16m4_t __riscv_vwmul_vx_i16m4_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                    size_t vl);
vint16m8_t __riscv_vwmul_vv_i16m8_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                    size_t vl);
vint16m8_t __riscv_vwmul_vx_i16m8_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                    size_t vl);
vint32mf2_t __riscv_vwmul_vv_i32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwmul_vx_i32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                      int16_t rs1, size_t vl);
vint32m1_t __riscv_vwmul_vv_i32m1_m(vbool32_t vm, vint16mf2_t vs2,
                                    vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwmul_vx_i32m1_m(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                                    size_t vl);
vint32m2_t __riscv_vwmul_vv_i32m2_m(vbool16_t vm, vint16m1_t vs2,
                                    vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwmul_vx_i32m2_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                    size_t vl);
vint32m4_t __riscv_vwmul_vv_i32m4_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                    size_t vl);
vint32m4_t __riscv_vwmul_vx_i32m4_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                    size_t vl);
vint32m8_t __riscv_vwmul_vv_i32m8_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                    size_t vl);
vint32m8_t __riscv_vwmul_vx_i32m8_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                    size_t vl);
vint64m1_t __riscv_vwmul_vv_i64m1_m(vbool64_t vm, vint32mf2_t vs2,
                                    vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwmul_vx_i64m1_m(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                                    size_t vl);
vint64m2_t __riscv_vwmul_vv_i64m2_m(vbool32_t vm, vint32m1_t vs2,
                                    vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwmul_vx_i64m2_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                    size_t vl);
vint64m4_t __riscv_vwmul_vv_i64m4_m(vbool16_t vm, vint32m2_t vs2,
                                    vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwmul_vx_i64m4_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                    size_t vl);
vint64m8_t __riscv_vwmul_vv_i64m8_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                    size_t vl);
vint64m8_t __riscv_vwmul_vx_i64m8_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                    size_t vl);
vint16mf4_t __riscv_vwmulsu_vv_i16mf4_m(vbool64_t vm, vint8mf8_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwmulsu_vx_i16mf4_m(vbool64_t vm, vint8mf8_t vs2,
                                        uint8_t rs1, size_t vl);
vint16mf2_t __riscv_vwmulsu_vv_i16mf2_m(vbool32_t vm, vint8mf4_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwmulsu_vx_i16mf2_m(vbool32_t vm, vint8mf4_t vs2,
                                        uint8_t rs1, size_t vl);
vint16m1_t __riscv_vwmulsu_vv_i16m1_m(vbool16_t vm, vint8mf2_t vs2,
                                      vuint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwmulsu_vx_i16m1_m(vbool16_t vm, vint8mf2_t vs2, uint8_t rs1,
                                      size_t vl);
vint16m2_t __riscv_vwmulsu_vv_i16m2_m(vbool8_t vm, vint8m1_t vs2,
                                      vuint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwmulsu_vx_i16m2_m(vbool8_t vm, vint8m1_t vs2, uint8_t rs1,
                                      size_t vl);
vint16m4_t __riscv_vwmulsu_vv_i16m4_m(vbool4_t vm, vint8m2_t vs2,
                                      vuint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwmulsu_vx_i16m4_m(vbool4_t vm, vint8m2_t vs2, uint8_t rs1,
                                      size_t vl);
vint16m8_t __riscv_vwmulsu_vv_i16m8_m(vbool2_t vm, vint8m4_t vs2,
                                      vuint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwmulsu_vx_i16m8_m(vbool2_t vm, vint8m4_t vs2, uint8_t rs1,
                                      size_t vl);
vint32mf2_t __riscv_vwmulsu_vv_i32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwmulsu_vx_i32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                        uint16_t rs1, size_t vl);
vint32m1_t __riscv_vwmulsu_vv_i32m1_m(vbool32_t vm, vint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwmulsu_vx_i32m1_m(vbool32_t vm, vint16mf2_t vs2,
                                      uint16_t rs1, size_t vl);
vint32m2_t __riscv_vwmulsu_vv_i32m2_m(vbool16_t vm, vint16m1_t vs2,
                                      vuint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwmulsu_vx_i32m2_m(vbool16_t vm, vint16m1_t vs2,
                                      uint16_t rs1, size_t vl);
vint32m4_t __riscv_vwmulsu_vv_i32m4_m(vbool8_t vm, vint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwmulsu_vx_i32m4_m(vbool8_t vm, vint16m2_t vs2, uint16_t rs1,
                                      size_t vl);
vint32m8_t __riscv_vwmulsu_vv_i32m8_m(vbool4_t vm, vint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwmulsu_vx_i32m8_m(vbool4_t vm, vint16m4_t vs2, uint16_t rs1,
                                      size_t vl);
vint64m1_t __riscv_vwmulsu_vv_i64m1_m(vbool64_t vm, vint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwmulsu_vx_i64m1_m(vbool64_t vm, vint32mf2_t vs2,
                                      uint32_t rs1, size_t vl);
vint64m2_t __riscv_vwmulsu_vv_i64m2_m(vbool32_t vm, vint32m1_t vs2,
                                      vuint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwmulsu_vx_i64m2_m(vbool32_t vm, vint32m1_t vs2,
                                      uint32_t rs1, size_t vl);
vint64m4_t __riscv_vwmulsu_vv_i64m4_m(vbool16_t vm, vint32m2_t vs2,
                                      vuint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwmulsu_vx_i64m4_m(vbool16_t vm, vint32m2_t vs2,
                                      uint32_t rs1, size_t vl);
vint64m8_t __riscv_vwmulsu_vv_i64m8_m(vbool8_t vm, vint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwmulsu_vx_i64m8_m(vbool8_t vm, vint32m4_t vs2, uint32_t rs1,
                                      size_t vl);
vuint16mf4_t __riscv_vwmulu_vv_u16mf4_m(vbool64_t vm, vuint8mf8_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vuint16mf4_t __riscv_vwmulu_vx_u16mf4_m(vbool64_t vm, vuint8mf8_t vs2,
                                        uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwmulu_vv_u16mf2_m(vbool32_t vm, vuint8mf4_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vwmulu_vx_u16mf2_m(vbool32_t vm, vuint8mf4_t vs2,
                                        uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwmulu_vv_u16m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                      vuint8mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vwmulu_vx_u16m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                      uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwmulu_vv_u16m2_m(vbool8_t vm, vuint8m1_t vs2,
                                      vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwmulu_vx_u16m2_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m4_t __riscv_vwmulu_vv_u16m4_m(vbool4_t vm, vuint8m2_t vs2,
                                      vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwmulu_vx_u16m4_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                      size_t vl);
vuint16m8_t __riscv_vwmulu_vv_u16m8_m(vbool2_t vm, vuint8m4_t vs2,
                                      vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwmulu_vx_u16m8_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                      size_t vl);
vuint32mf2_t __riscv_vwmulu_vv_u32mf2_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vuint32mf2_t __riscv_vwmulu_vx_u32mf2_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwmulu_vv_u32m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                      vuint16mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vwmulu_vx_u32m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwmulu_vv_u32m2_m(vbool16_t vm, vuint16m1_t vs2,
                                      vuint16m1_t vs1, size_t vl);
vuint32m2_t __riscv_vwmulu_vx_u32m2_m(vbool16_t vm, vuint16m1_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwmulu_vv_u32m4_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vuint32m4_t __riscv_vwmulu_vx_u32m4_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwmulu_vv_u32m8_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vuint32m8_t __riscv_vwmulu_vx_u32m8_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint64m1_t __riscv_vwmulu_vv_u64m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                      vuint32mf2_t vs1, size_t vl);
vuint64m1_t __riscv_vwmulu_vx_u64m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwmulu_vv_u64m2_m(vbool32_t vm, vuint32m1_t vs2,
                                      vuint32m1_t vs1, size_t vl);
vuint64m2_t __riscv_vwmulu_vx_u64m2_m(vbool32_t vm, vuint32m1_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwmulu_vv_u64m4_m(vbool16_t vm, vuint32m2_t vs2,
                                      vuint32m2_t vs1, size_t vl);
vuint64m4_t __riscv_vwmulu_vx_u64m4_m(vbool16_t vm, vuint32m2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwmulu_vv_u64m8_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vuint64m8_t __riscv_vwmulu_vx_u64m8_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, size_t vl);
----

[[vector-single-width-integer-multiply-add]]
==== Vector Single-Width Integer Multiply-Add Intrinsics

[,c]
----
vint8mf8_t __riscv_vmacc_vv_i8mf8(vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2,
                                  size_t vl);
vint8mf8_t __riscv_vmacc_vx_i8mf8(vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2,
                                  size_t vl);
vint8mf4_t __riscv_vmacc_vv_i8mf4(vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2,
                                  size_t vl);
vint8mf4_t __riscv_vmacc_vx_i8mf4(vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2,
                                  size_t vl);
vint8mf2_t __riscv_vmacc_vv_i8mf2(vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2,
                                  size_t vl);
vint8mf2_t __riscv_vmacc_vx_i8mf2(vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2,
                                  size_t vl);
vint8m1_t __riscv_vmacc_vv_i8m1(vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2,
                                size_t vl);
vint8m1_t __riscv_vmacc_vx_i8m1(vint8m1_t vd, int8_t rs1, vint8m1_t vs2,
                                size_t vl);
vint8m2_t __riscv_vmacc_vv_i8m2(vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2,
                                size_t vl);
vint8m2_t __riscv_vmacc_vx_i8m2(vint8m2_t vd, int8_t rs1, vint8m2_t vs2,
                                size_t vl);
vint8m4_t __riscv_vmacc_vv_i8m4(vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2,
                                size_t vl);
vint8m4_t __riscv_vmacc_vx_i8m4(vint8m4_t vd, int8_t rs1, vint8m4_t vs2,
                                size_t vl);
vint8m8_t __riscv_vmacc_vv_i8m8(vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2,
                                size_t vl);
vint8m8_t __riscv_vmacc_vx_i8m8(vint8m8_t vd, int8_t rs1, vint8m8_t vs2,
                                size_t vl);
vint16mf4_t __riscv_vmacc_vv_i16mf4(vint16mf4_t vd, vint16mf4_t vs1,
                                    vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc_vx_i16mf4(vint16mf4_t vd, int16_t rs1,
                                    vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_vv_i16mf2(vint16mf2_t vd, vint16mf2_t vs1,
                                    vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_vx_i16mf2(vint16mf2_t vd, int16_t rs1,
                                    vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_vv_i16m1(vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2,
                                  size_t vl);
vint16m1_t __riscv_vmacc_vx_i16m1(vint16m1_t vd, int16_t rs1, vint16m1_t vs2,
                                  size_t vl);
vint16m2_t __riscv_vmacc_vv_i16m2(vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2,
                                  size_t vl);
vint16m2_t __riscv_vmacc_vx_i16m2(vint16m2_t vd, int16_t rs1, vint16m2_t vs2,
                                  size_t vl);
vint16m4_t __riscv_vmacc_vv_i16m4(vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2,
                                  size_t vl);
vint16m4_t __riscv_vmacc_vx_i16m4(vint16m4_t vd, int16_t rs1, vint16m4_t vs2,
                                  size_t vl);
vint16m8_t __riscv_vmacc_vv_i16m8(vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2,
                                  size_t vl);
vint16m8_t __riscv_vmacc_vx_i16m8(vint16m8_t vd, int16_t rs1, vint16m8_t vs2,
                                  size_t vl);
vint32mf2_t __riscv_vmacc_vv_i32mf2(vint32mf2_t vd, vint32mf2_t vs1,
                                    vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc_vx_i32mf2(vint32mf2_t vd, int32_t rs1,
                                    vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_vv_i32m1(vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2,
                                  size_t vl);
vint32m1_t __riscv_vmacc_vx_i32m1(vint32m1_t vd, int32_t rs1, vint32m1_t vs2,
                                  size_t vl);
vint32m2_t __riscv_vmacc_vv_i32m2(vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2,
                                  size_t vl);
vint32m2_t __riscv_vmacc_vx_i32m2(vint32m2_t vd, int32_t rs1, vint32m2_t vs2,
                                  size_t vl);
vint32m4_t __riscv_vmacc_vv_i32m4(vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2,
                                  size_t vl);
vint32m4_t __riscv_vmacc_vx_i32m4(vint32m4_t vd, int32_t rs1, vint32m4_t vs2,
                                  size_t vl);
vint32m8_t __riscv_vmacc_vv_i32m8(vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2,
                                  size_t vl);
vint32m8_t __riscv_vmacc_vx_i32m8(vint32m8_t vd, int32_t rs1, vint32m8_t vs2,
                                  size_t vl);
vint64m1_t __riscv_vmacc_vv_i64m1(vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2,
                                  size_t vl);
vint64m1_t __riscv_vmacc_vx_i64m1(vint64m1_t vd, int64_t rs1, vint64m1_t vs2,
                                  size_t vl);
vint64m2_t __riscv_vmacc_vv_i64m2(vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2,
                                  size_t vl);
vint64m2_t __riscv_vmacc_vx_i64m2(vint64m2_t vd, int64_t rs1, vint64m2_t vs2,
                                  size_t vl);
vint64m4_t __riscv_vmacc_vv_i64m4(vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2,
                                  size_t vl);
vint64m4_t __riscv_vmacc_vx_i64m4(vint64m4_t vd, int64_t rs1, vint64m4_t vs2,
                                  size_t vl);
vint64m8_t __riscv_vmacc_vv_i64m8(vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2,
                                  size_t vl);
vint64m8_t __riscv_vmacc_vx_i64m8(vint64m8_t vd, int64_t rs1, vint64m8_t vs2,
                                  size_t vl);
vint8mf8_t __riscv_vnmsac_vv_i8mf8(vint8mf8_t vd, vint8mf8_t vs1,
                                   vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_vx_i8mf8(vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2,
                                   size_t vl);
vint8mf4_t __riscv_vnmsac_vv_i8mf4(vint8mf4_t vd, vint8mf4_t vs1,
                                   vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_vx_i8mf4(vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2,
                                   size_t vl);
vint8mf2_t __riscv_vnmsac_vv_i8mf2(vint8mf2_t vd, vint8mf2_t vs1,
                                   vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_vx_i8mf2(vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2,
                                   size_t vl);
vint8m1_t __riscv_vnmsac_vv_i8m1(vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2,
                                 size_t vl);
vint8m1_t __riscv_vnmsac_vx_i8m1(vint8m1_t vd, int8_t rs1, vint8m1_t vs2,
                                 size_t vl);
vint8m2_t __riscv_vnmsac_vv_i8m2(vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2,
                                 size_t vl);
vint8m2_t __riscv_vnmsac_vx_i8m2(vint8m2_t vd, int8_t rs1, vint8m2_t vs2,
                                 size_t vl);
vint8m4_t __riscv_vnmsac_vv_i8m4(vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2,
                                 size_t vl);
vint8m4_t __riscv_vnmsac_vx_i8m4(vint8m4_t vd, int8_t rs1, vint8m4_t vs2,
                                 size_t vl);
vint8m8_t __riscv_vnmsac_vv_i8m8(vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2,
                                 size_t vl);
vint8m8_t __riscv_vnmsac_vx_i8m8(vint8m8_t vd, int8_t rs1, vint8m8_t vs2,
                                 size_t vl);
vint16mf4_t __riscv_vnmsac_vv_i16mf4(vint16mf4_t vd, vint16mf4_t vs1,
                                     vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac_vx_i16mf4(vint16mf4_t vd, int16_t rs1,
                                     vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_vv_i16mf2(vint16mf2_t vd, vint16mf2_t vs1,
                                     vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_vx_i16mf2(vint16mf2_t vd, int16_t rs1,
                                     vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_vv_i16m1(vint16m1_t vd, vint16m1_t vs1,
                                   vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_vx_i16m1(vint16m1_t vd, int16_t rs1, vint16m1_t vs2,
                                   size_t vl);
vint16m2_t __riscv_vnmsac_vv_i16m2(vint16m2_t vd, vint16m2_t vs1,
                                   vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_vx_i16m2(vint16m2_t vd, int16_t rs1, vint16m2_t vs2,
                                   size_t vl);
vint16m4_t __riscv_vnmsac_vv_i16m4(vint16m4_t vd, vint16m4_t vs1,
                                   vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_vx_i16m4(vint16m4_t vd, int16_t rs1, vint16m4_t vs2,
                                   size_t vl);
vint16m8_t __riscv_vnmsac_vv_i16m8(vint16m8_t vd, vint16m8_t vs1,
                                   vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_vx_i16m8(vint16m8_t vd, int16_t rs1, vint16m8_t vs2,
                                   size_t vl);
vint32mf2_t __riscv_vnmsac_vv_i32mf2(vint32mf2_t vd, vint32mf2_t vs1,
                                     vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac_vx_i32mf2(vint32mf2_t vd, int32_t rs1,
                                     vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_vv_i32m1(vint32m1_t vd, vint32m1_t vs1,
                                   vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_vx_i32m1(vint32m1_t vd, int32_t rs1, vint32m1_t vs2,
                                   size_t vl);
vint32m2_t __riscv_vnmsac_vv_i32m2(vint32m2_t vd, vint32m2_t vs1,
                                   vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_vx_i32m2(vint32m2_t vd, int32_t rs1, vint32m2_t vs2,
                                   size_t vl);
vint32m4_t __riscv_vnmsac_vv_i32m4(vint32m4_t vd, vint32m4_t vs1,
                                   vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_vx_i32m4(vint32m4_t vd, int32_t rs1, vint32m4_t vs2,
                                   size_t vl);
vint32m8_t __riscv_vnmsac_vv_i32m8(vint32m8_t vd, vint32m8_t vs1,
                                   vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_vx_i32m8(vint32m8_t vd, int32_t rs1, vint32m8_t vs2,
                                   size_t vl);
vint64m1_t __riscv_vnmsac_vv_i64m1(vint64m1_t vd, vint64m1_t vs1,
                                   vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_vx_i64m1(vint64m1_t vd, int64_t rs1, vint64m1_t vs2,
                                   size_t vl);
vint64m2_t __riscv_vnmsac_vv_i64m2(vint64m2_t vd, vint64m2_t vs1,
                                   vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_vx_i64m2(vint64m2_t vd, int64_t rs1, vint64m2_t vs2,
                                   size_t vl);
vint64m4_t __riscv_vnmsac_vv_i64m4(vint64m4_t vd, vint64m4_t vs1,
                                   vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_vx_i64m4(vint64m4_t vd, int64_t rs1, vint64m4_t vs2,
                                   size_t vl);
vint64m8_t __riscv_vnmsac_vv_i64m8(vint64m8_t vd, vint64m8_t vs1,
                                   vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_vx_i64m8(vint64m8_t vd, int64_t rs1, vint64m8_t vs2,
                                   size_t vl);
vint8mf8_t __riscv_vmadd_vv_i8mf8(vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2,
                                  size_t vl);
vint8mf8_t __riscv_vmadd_vx_i8mf8(vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2,
                                  size_t vl);
vint8mf4_t __riscv_vmadd_vv_i8mf4(vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2,
                                  size_t vl);
vint8mf4_t __riscv_vmadd_vx_i8mf4(vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2,
                                  size_t vl);
vint8mf2_t __riscv_vmadd_vv_i8mf2(vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2,
                                  size_t vl);
vint8mf2_t __riscv_vmadd_vx_i8mf2(vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2,
                                  size_t vl);
vint8m1_t __riscv_vmadd_vv_i8m1(vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2,
                                size_t vl);
vint8m1_t __riscv_vmadd_vx_i8m1(vint8m1_t vd, int8_t rs1, vint8m1_t vs2,
                                size_t vl);
vint8m2_t __riscv_vmadd_vv_i8m2(vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2,
                                size_t vl);
vint8m2_t __riscv_vmadd_vx_i8m2(vint8m2_t vd, int8_t rs1, vint8m2_t vs2,
                                size_t vl);
vint8m4_t __riscv_vmadd_vv_i8m4(vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2,
                                size_t vl);
vint8m4_t __riscv_vmadd_vx_i8m4(vint8m4_t vd, int8_t rs1, vint8m4_t vs2,
                                size_t vl);
vint8m8_t __riscv_vmadd_vv_i8m8(vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2,
                                size_t vl);
vint8m8_t __riscv_vmadd_vx_i8m8(vint8m8_t vd, int8_t rs1, vint8m8_t vs2,
                                size_t vl);
vint16mf4_t __riscv_vmadd_vv_i16mf4(vint16mf4_t vd, vint16mf4_t vs1,
                                    vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd_vx_i16mf4(vint16mf4_t vd, int16_t rs1,
                                    vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_vv_i16mf2(vint16mf2_t vd, vint16mf2_t vs1,
                                    vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_vx_i16mf2(vint16mf2_t vd, int16_t rs1,
                                    vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_vv_i16m1(vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2,
                                  size_t vl);
vint16m1_t __riscv_vmadd_vx_i16m1(vint16m1_t vd, int16_t rs1, vint16m1_t vs2,
                                  size_t vl);
vint16m2_t __riscv_vmadd_vv_i16m2(vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2,
                                  size_t vl);
vint16m2_t __riscv_vmadd_vx_i16m2(vint16m2_t vd, int16_t rs1, vint16m2_t vs2,
                                  size_t vl);
vint16m4_t __riscv_vmadd_vv_i16m4(vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2,
                                  size_t vl);
vint16m4_t __riscv_vmadd_vx_i16m4(vint16m4_t vd, int16_t rs1, vint16m4_t vs2,
                                  size_t vl);
vint16m8_t __riscv_vmadd_vv_i16m8(vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2,
                                  size_t vl);
vint16m8_t __riscv_vmadd_vx_i16m8(vint16m8_t vd, int16_t rs1, vint16m8_t vs2,
                                  size_t vl);
vint32mf2_t __riscv_vmadd_vv_i32mf2(vint32mf2_t vd, vint32mf2_t vs1,
                                    vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd_vx_i32mf2(vint32mf2_t vd, int32_t rs1,
                                    vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_vv_i32m1(vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2,
                                  size_t vl);
vint32m1_t __riscv_vmadd_vx_i32m1(vint32m1_t vd, int32_t rs1, vint32m1_t vs2,
                                  size_t vl);
vint32m2_t __riscv_vmadd_vv_i32m2(vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2,
                                  size_t vl);
vint32m2_t __riscv_vmadd_vx_i32m2(vint32m2_t vd, int32_t rs1, vint32m2_t vs2,
                                  size_t vl);
vint32m4_t __riscv_vmadd_vv_i32m4(vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2,
                                  size_t vl);
vint32m4_t __riscv_vmadd_vx_i32m4(vint32m4_t vd, int32_t rs1, vint32m4_t vs2,
                                  size_t vl);
vint32m8_t __riscv_vmadd_vv_i32m8(vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2,
                                  size_t vl);
vint32m8_t __riscv_vmadd_vx_i32m8(vint32m8_t vd, int32_t rs1, vint32m8_t vs2,
                                  size_t vl);
vint64m1_t __riscv_vmadd_vv_i64m1(vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2,
                                  size_t vl);
vint64m1_t __riscv_vmadd_vx_i64m1(vint64m1_t vd, int64_t rs1, vint64m1_t vs2,
                                  size_t vl);
vint64m2_t __riscv_vmadd_vv_i64m2(vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2,
                                  size_t vl);
vint64m2_t __riscv_vmadd_vx_i64m2(vint64m2_t vd, int64_t rs1, vint64m2_t vs2,
                                  size_t vl);
vint64m4_t __riscv_vmadd_vv_i64m4(vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2,
                                  size_t vl);
vint64m4_t __riscv_vmadd_vx_i64m4(vint64m4_t vd, int64_t rs1, vint64m4_t vs2,
                                  size_t vl);
vint64m8_t __riscv_vmadd_vv_i64m8(vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2,
                                  size_t vl);
vint64m8_t __riscv_vmadd_vx_i64m8(vint64m8_t vd, int64_t rs1, vint64m8_t vs2,
                                  size_t vl);
vint8mf8_t __riscv_vnmsub_vv_i8mf8(vint8mf8_t vd, vint8mf8_t vs1,
                                   vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_vx_i8mf8(vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2,
                                   size_t vl);
vint8mf4_t __riscv_vnmsub_vv_i8mf4(vint8mf4_t vd, vint8mf4_t vs1,
                                   vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_vx_i8mf4(vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2,
                                   size_t vl);
vint8mf2_t __riscv_vnmsub_vv_i8mf2(vint8mf2_t vd, vint8mf2_t vs1,
                                   vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_vx_i8mf2(vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2,
                                   size_t vl);
vint8m1_t __riscv_vnmsub_vv_i8m1(vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2,
                                 size_t vl);
vint8m1_t __riscv_vnmsub_vx_i8m1(vint8m1_t vd, int8_t rs1, vint8m1_t vs2,
                                 size_t vl);
vint8m2_t __riscv_vnmsub_vv_i8m2(vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2,
                                 size_t vl);
vint8m2_t __riscv_vnmsub_vx_i8m2(vint8m2_t vd, int8_t rs1, vint8m2_t vs2,
                                 size_t vl);
vint8m4_t __riscv_vnmsub_vv_i8m4(vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2,
                                 size_t vl);
vint8m4_t __riscv_vnmsub_vx_i8m4(vint8m4_t vd, int8_t rs1, vint8m4_t vs2,
                                 size_t vl);
vint8m8_t __riscv_vnmsub_vv_i8m8(vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2,
                                 size_t vl);
vint8m8_t __riscv_vnmsub_vx_i8m8(vint8m8_t vd, int8_t rs1, vint8m8_t vs2,
                                 size_t vl);
vint16mf4_t __riscv_vnmsub_vv_i16mf4(vint16mf4_t vd, vint16mf4_t vs1,
                                     vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub_vx_i16mf4(vint16mf4_t vd, int16_t rs1,
                                     vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_vv_i16mf2(vint16mf2_t vd, vint16mf2_t vs1,
                                     vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_vx_i16mf2(vint16mf2_t vd, int16_t rs1,
                                     vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_vv_i16m1(vint16m1_t vd, vint16m1_t vs1,
                                   vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_vx_i16m1(vint16m1_t vd, int16_t rs1, vint16m1_t vs2,
                                   size_t vl);
vint16m2_t __riscv_vnmsub_vv_i16m2(vint16m2_t vd, vint16m2_t vs1,
                                   vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_vx_i16m2(vint16m2_t vd, int16_t rs1, vint16m2_t vs2,
                                   size_t vl);
vint16m4_t __riscv_vnmsub_vv_i16m4(vint16m4_t vd, vint16m4_t vs1,
                                   vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_vx_i16m4(vint16m4_t vd, int16_t rs1, vint16m4_t vs2,
                                   size_t vl);
vint16m8_t __riscv_vnmsub_vv_i16m8(vint16m8_t vd, vint16m8_t vs1,
                                   vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_vx_i16m8(vint16m8_t vd, int16_t rs1, vint16m8_t vs2,
                                   size_t vl);
vint32mf2_t __riscv_vnmsub_vv_i32mf2(vint32mf2_t vd, vint32mf2_t vs1,
                                     vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub_vx_i32mf2(vint32mf2_t vd, int32_t rs1,
                                     vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_vv_i32m1(vint32m1_t vd, vint32m1_t vs1,
                                   vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_vx_i32m1(vint32m1_t vd, int32_t rs1, vint32m1_t vs2,
                                   size_t vl);
vint32m2_t __riscv_vnmsub_vv_i32m2(vint32m2_t vd, vint32m2_t vs1,
                                   vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_vx_i32m2(vint32m2_t vd, int32_t rs1, vint32m2_t vs2,
                                   size_t vl);
vint32m4_t __riscv_vnmsub_vv_i32m4(vint32m4_t vd, vint32m4_t vs1,
                                   vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_vx_i32m4(vint32m4_t vd, int32_t rs1, vint32m4_t vs2,
                                   size_t vl);
vint32m8_t __riscv_vnmsub_vv_i32m8(vint32m8_t vd, vint32m8_t vs1,
                                   vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_vx_i32m8(vint32m8_t vd, int32_t rs1, vint32m8_t vs2,
                                   size_t vl);
vint64m1_t __riscv_vnmsub_vv_i64m1(vint64m1_t vd, vint64m1_t vs1,
                                   vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_vx_i64m1(vint64m1_t vd, int64_t rs1, vint64m1_t vs2,
                                   size_t vl);
vint64m2_t __riscv_vnmsub_vv_i64m2(vint64m2_t vd, vint64m2_t vs1,
                                   vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_vx_i64m2(vint64m2_t vd, int64_t rs1, vint64m2_t vs2,
                                   size_t vl);
vint64m4_t __riscv_vnmsub_vv_i64m4(vint64m4_t vd, vint64m4_t vs1,
                                   vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_vx_i64m4(vint64m4_t vd, int64_t rs1, vint64m4_t vs2,
                                   size_t vl);
vint64m8_t __riscv_vnmsub_vv_i64m8(vint64m8_t vd, vint64m8_t vs1,
                                   vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_vx_i64m8(vint64m8_t vd, int64_t rs1, vint64m8_t vs2,
                                   size_t vl);
vuint8mf8_t __riscv_vmacc_vv_u8mf8(vuint8mf8_t vd, vuint8mf8_t vs1,
                                   vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc_vx_u8mf8(vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2,
                                   size_t vl);
vuint8mf4_t __riscv_vmacc_vv_u8mf4(vuint8mf4_t vd, vuint8mf4_t vs1,
                                   vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc_vx_u8mf4(vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2,
                                   size_t vl);
vuint8mf2_t __riscv_vmacc_vv_u8mf2(vuint8mf2_t vd, vuint8mf2_t vs1,
                                   vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc_vx_u8mf2(vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2,
                                   size_t vl);
vuint8m1_t __riscv_vmacc_vv_u8m1(vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2,
                                 size_t vl);
vuint8m1_t __riscv_vmacc_vx_u8m1(vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2,
                                 size_t vl);
vuint8m2_t __riscv_vmacc_vv_u8m2(vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2,
                                 size_t vl);
vuint8m2_t __riscv_vmacc_vx_u8m2(vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2,
                                 size_t vl);
vuint8m4_t __riscv_vmacc_vv_u8m4(vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2,
                                 size_t vl);
vuint8m4_t __riscv_vmacc_vx_u8m4(vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2,
                                 size_t vl);
vuint8m8_t __riscv_vmacc_vv_u8m8(vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2,
                                 size_t vl);
vuint8m8_t __riscv_vmacc_vx_u8m8(vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2,
                                 size_t vl);
vuint16mf4_t __riscv_vmacc_vv_u16mf4(vuint16mf4_t vd, vuint16mf4_t vs1,
                                     vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc_vx_u16mf4(vuint16mf4_t vd, uint16_t rs1,
                                     vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc_vv_u16mf2(vuint16mf2_t vd, vuint16mf2_t vs1,
                                     vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc_vx_u16mf2(vuint16mf2_t vd, uint16_t rs1,
                                     vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc_vv_u16m1(vuint16m1_t vd, vuint16m1_t vs1,
                                   vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc_vx_u16m1(vuint16m1_t vd, uint16_t rs1,
                                   vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_vv_u16m2(vuint16m2_t vd, vuint16m2_t vs1,
                                   vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_vx_u16m2(vuint16m2_t vd, uint16_t rs1,
                                   vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_vv_u16m4(vuint16m4_t vd, vuint16m4_t vs1,
                                   vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_vx_u16m4(vuint16m4_t vd, uint16_t rs1,
                                   vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_vv_u16m8(vuint16m8_t vd, vuint16m8_t vs1,
                                   vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_vx_u16m8(vuint16m8_t vd, uint16_t rs1,
                                   vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_vv_u32mf2(vuint32mf2_t vd, vuint32mf2_t vs1,
                                     vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_vx_u32mf2(vuint32mf2_t vd, uint32_t rs1,
                                     vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc_vv_u32m1(vuint32m1_t vd, vuint32m1_t vs1,
                                   vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc_vx_u32m1(vuint32m1_t vd, uint32_t rs1,
                                   vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_vv_u32m2(vuint32m2_t vd, vuint32m2_t vs1,
                                   vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_vx_u32m2(vuint32m2_t vd, uint32_t rs1,
                                   vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_vv_u32m4(vuint32m4_t vd, vuint32m4_t vs1,
                                   vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_vx_u32m4(vuint32m4_t vd, uint32_t rs1,
                                   vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_vv_u32m8(vuint32m8_t vd, vuint32m8_t vs1,
                                   vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_vx_u32m8(vuint32m8_t vd, uint32_t rs1,
                                   vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_vv_u64m1(vuint64m1_t vd, vuint64m1_t vs1,
                                   vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_vx_u64m1(vuint64m1_t vd, uint64_t rs1,
                                   vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_vv_u64m2(vuint64m2_t vd, vuint64m2_t vs1,
                                   vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_vx_u64m2(vuint64m2_t vd, uint64_t rs1,
                                   vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_vv_u64m4(vuint64m4_t vd, vuint64m4_t vs1,
                                   vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_vx_u64m4(vuint64m4_t vd, uint64_t rs1,
                                   vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_vv_u64m8(vuint64m8_t vd, vuint64m8_t vs1,
                                   vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_vx_u64m8(vuint64m8_t vd, uint64_t rs1,
                                   vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_vv_u8mf8(vuint8mf8_t vd, vuint8mf8_t vs1,
                                    vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_vx_u8mf8(vuint8mf8_t vd, uint8_t rs1,
                                    vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_vv_u8mf4(vuint8mf4_t vd, vuint8mf4_t vs1,
                                    vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_vx_u8mf4(vuint8mf4_t vd, uint8_t rs1,
                                    vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_vv_u8mf2(vuint8mf2_t vd, vuint8mf2_t vs1,
                                    vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_vx_u8mf2(vuint8mf2_t vd, uint8_t rs1,
                                    vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_vv_u8m1(vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2,
                                  size_t vl);
vuint8m1_t __riscv_vnmsac_vx_u8m1(vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2,
                                  size_t vl);
vuint8m2_t __riscv_vnmsac_vv_u8m2(vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2,
                                  size_t vl);
vuint8m2_t __riscv_vnmsac_vx_u8m2(vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2,
                                  size_t vl);
vuint8m4_t __riscv_vnmsac_vv_u8m4(vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2,
                                  size_t vl);
vuint8m4_t __riscv_vnmsac_vx_u8m4(vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2,
                                  size_t vl);
vuint8m8_t __riscv_vnmsac_vv_u8m8(vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2,
                                  size_t vl);
vuint8m8_t __riscv_vnmsac_vx_u8m8(vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2,
                                  size_t vl);
vuint16mf4_t __riscv_vnmsac_vv_u16mf4(vuint16mf4_t vd, vuint16mf4_t vs1,
                                      vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac_vx_u16mf4(vuint16mf4_t vd, uint16_t rs1,
                                      vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac_vv_u16mf2(vuint16mf2_t vd, vuint16mf2_t vs1,
                                      vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac_vx_u16mf2(vuint16mf2_t vd, uint16_t rs1,
                                      vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac_vv_u16m1(vuint16m1_t vd, vuint16m1_t vs1,
                                    vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac_vx_u16m1(vuint16m1_t vd, uint16_t rs1,
                                    vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_vv_u16m2(vuint16m2_t vd, vuint16m2_t vs1,
                                    vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_vx_u16m2(vuint16m2_t vd, uint16_t rs1,
                                    vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_vv_u16m4(vuint16m4_t vd, vuint16m4_t vs1,
                                    vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_vx_u16m4(vuint16m4_t vd, uint16_t rs1,
                                    vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_vv_u16m8(vuint16m8_t vd, vuint16m8_t vs1,
                                    vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_vx_u16m8(vuint16m8_t vd, uint16_t rs1,
                                    vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_vv_u32mf2(vuint32mf2_t vd, vuint32mf2_t vs1,
                                      vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_vx_u32mf2(vuint32mf2_t vd, uint32_t rs1,
                                      vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac_vv_u32m1(vuint32m1_t vd, vuint32m1_t vs1,
                                    vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac_vx_u32m1(vuint32m1_t vd, uint32_t rs1,
                                    vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_vv_u32m2(vuint32m2_t vd, vuint32m2_t vs1,
                                    vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_vx_u32m2(vuint32m2_t vd, uint32_t rs1,
                                    vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_vv_u32m4(vuint32m4_t vd, vuint32m4_t vs1,
                                    vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_vx_u32m4(vuint32m4_t vd, uint32_t rs1,
                                    vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_vv_u32m8(vuint32m8_t vd, vuint32m8_t vs1,
                                    vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_vx_u32m8(vuint32m8_t vd, uint32_t rs1,
                                    vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_vv_u64m1(vuint64m1_t vd, vuint64m1_t vs1,
                                    vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_vx_u64m1(vuint64m1_t vd, uint64_t rs1,
                                    vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_vv_u64m2(vuint64m2_t vd, vuint64m2_t vs1,
                                    vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_vx_u64m2(vuint64m2_t vd, uint64_t rs1,
                                    vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_vv_u64m4(vuint64m4_t vd, vuint64m4_t vs1,
                                    vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_vx_u64m4(vuint64m4_t vd, uint64_t rs1,
                                    vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_vv_u64m8(vuint64m8_t vd, vuint64m8_t vs1,
                                    vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_vx_u64m8(vuint64m8_t vd, uint64_t rs1,
                                    vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_vv_u8mf8(vuint8mf8_t vd, vuint8mf8_t vs1,
                                   vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_vx_u8mf8(vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2,
                                   size_t vl);
vuint8mf4_t __riscv_vmadd_vv_u8mf4(vuint8mf4_t vd, vuint8mf4_t vs1,
                                   vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd_vx_u8mf4(vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2,
                                   size_t vl);
vuint8mf2_t __riscv_vmadd_vv_u8mf2(vuint8mf2_t vd, vuint8mf2_t vs1,
                                   vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd_vx_u8mf2(vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2,
                                   size_t vl);
vuint8m1_t __riscv_vmadd_vv_u8m1(vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2,
                                 size_t vl);
vuint8m1_t __riscv_vmadd_vx_u8m1(vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2,
                                 size_t vl);
vuint8m2_t __riscv_vmadd_vv_u8m2(vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2,
                                 size_t vl);
vuint8m2_t __riscv_vmadd_vx_u8m2(vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2,
                                 size_t vl);
vuint8m4_t __riscv_vmadd_vv_u8m4(vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2,
                                 size_t vl);
vuint8m4_t __riscv_vmadd_vx_u8m4(vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2,
                                 size_t vl);
vuint8m8_t __riscv_vmadd_vv_u8m8(vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2,
                                 size_t vl);
vuint8m8_t __riscv_vmadd_vx_u8m8(vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2,
                                 size_t vl);
vuint16mf4_t __riscv_vmadd_vv_u16mf4(vuint16mf4_t vd, vuint16mf4_t vs1,
                                     vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd_vx_u16mf4(vuint16mf4_t vd, uint16_t rs1,
                                     vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd_vv_u16mf2(vuint16mf2_t vd, vuint16mf2_t vs1,
                                     vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd_vx_u16mf2(vuint16mf2_t vd, uint16_t rs1,
                                     vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd_vv_u16m1(vuint16m1_t vd, vuint16m1_t vs1,
                                   vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd_vx_u16m1(vuint16m1_t vd, uint16_t rs1,
                                   vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_vv_u16m2(vuint16m2_t vd, vuint16m2_t vs1,
                                   vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_vx_u16m2(vuint16m2_t vd, uint16_t rs1,
                                   vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_vv_u16m4(vuint16m4_t vd, vuint16m4_t vs1,
                                   vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_vx_u16m4(vuint16m4_t vd, uint16_t rs1,
                                   vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_vv_u16m8(vuint16m8_t vd, vuint16m8_t vs1,
                                   vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_vx_u16m8(vuint16m8_t vd, uint16_t rs1,
                                   vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_vv_u32mf2(vuint32mf2_t vd, vuint32mf2_t vs1,
                                     vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_vx_u32mf2(vuint32mf2_t vd, uint32_t rs1,
                                     vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd_vv_u32m1(vuint32m1_t vd, vuint32m1_t vs1,
                                   vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd_vx_u32m1(vuint32m1_t vd, uint32_t rs1,
                                   vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_vv_u32m2(vuint32m2_t vd, vuint32m2_t vs1,
                                   vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_vx_u32m2(vuint32m2_t vd, uint32_t rs1,
                                   vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_vv_u32m4(vuint32m4_t vd, vuint32m4_t vs1,
                                   vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_vx_u32m4(vuint32m4_t vd, uint32_t rs1,
                                   vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_vv_u32m8(vuint32m8_t vd, vuint32m8_t vs1,
                                   vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_vx_u32m8(vuint32m8_t vd, uint32_t rs1,
                                   vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_vv_u64m1(vuint64m1_t vd, vuint64m1_t vs1,
                                   vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_vx_u64m1(vuint64m1_t vd, uint64_t rs1,
                                   vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_vv_u64m2(vuint64m2_t vd, vuint64m2_t vs1,
                                   vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_vx_u64m2(vuint64m2_t vd, uint64_t rs1,
                                   vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_vv_u64m4(vuint64m4_t vd, vuint64m4_t vs1,
                                   vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_vx_u64m4(vuint64m4_t vd, uint64_t rs1,
                                   vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_vv_u64m8(vuint64m8_t vd, vuint64m8_t vs1,
                                   vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_vx_u64m8(vuint64m8_t vd, uint64_t rs1,
                                   vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_vv_u8mf8(vuint8mf8_t vd, vuint8mf8_t vs1,
                                    vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_vx_u8mf8(vuint8mf8_t vd, uint8_t rs1,
                                    vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_vv_u8mf4(vuint8mf4_t vd, vuint8mf4_t vs1,
                                    vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_vx_u8mf4(vuint8mf4_t vd, uint8_t rs1,
                                    vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_vv_u8mf2(vuint8mf2_t vd, vuint8mf2_t vs1,
                                    vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_vx_u8mf2(vuint8mf2_t vd, uint8_t rs1,
                                    vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_vv_u8m1(vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2,
                                  size_t vl);
vuint8m1_t __riscv_vnmsub_vx_u8m1(vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2,
                                  size_t vl);
vuint8m2_t __riscv_vnmsub_vv_u8m2(vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2,
                                  size_t vl);
vuint8m2_t __riscv_vnmsub_vx_u8m2(vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2,
                                  size_t vl);
vuint8m4_t __riscv_vnmsub_vv_u8m4(vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2,
                                  size_t vl);
vuint8m4_t __riscv_vnmsub_vx_u8m4(vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2,
                                  size_t vl);
vuint8m8_t __riscv_vnmsub_vv_u8m8(vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2,
                                  size_t vl);
vuint8m8_t __riscv_vnmsub_vx_u8m8(vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2,
                                  size_t vl);
vuint16mf4_t __riscv_vnmsub_vv_u16mf4(vuint16mf4_t vd, vuint16mf4_t vs1,
                                      vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub_vx_u16mf4(vuint16mf4_t vd, uint16_t rs1,
                                      vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub_vv_u16mf2(vuint16mf2_t vd, vuint16mf2_t vs1,
                                      vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub_vx_u16mf2(vuint16mf2_t vd, uint16_t rs1,
                                      vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub_vv_u16m1(vuint16m1_t vd, vuint16m1_t vs1,
                                    vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub_vx_u16m1(vuint16m1_t vd, uint16_t rs1,
                                    vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_vv_u16m2(vuint16m2_t vd, vuint16m2_t vs1,
                                    vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_vx_u16m2(vuint16m2_t vd, uint16_t rs1,
                                    vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_vv_u16m4(vuint16m4_t vd, vuint16m4_t vs1,
                                    vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_vx_u16m4(vuint16m4_t vd, uint16_t rs1,
                                    vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_vv_u16m8(vuint16m8_t vd, vuint16m8_t vs1,
                                    vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_vx_u16m8(vuint16m8_t vd, uint16_t rs1,
                                    vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_vv_u32mf2(vuint32mf2_t vd, vuint32mf2_t vs1,
                                      vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_vx_u32mf2(vuint32mf2_t vd, uint32_t rs1,
                                      vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub_vv_u32m1(vuint32m1_t vd, vuint32m1_t vs1,
                                    vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub_vx_u32m1(vuint32m1_t vd, uint32_t rs1,
                                    vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_vv_u32m2(vuint32m2_t vd, vuint32m2_t vs1,
                                    vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_vx_u32m2(vuint32m2_t vd, uint32_t rs1,
                                    vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_vv_u32m4(vuint32m4_t vd, vuint32m4_t vs1,
                                    vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_vx_u32m4(vuint32m4_t vd, uint32_t rs1,
                                    vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_vv_u32m8(vuint32m8_t vd, vuint32m8_t vs1,
                                    vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_vx_u32m8(vuint32m8_t vd, uint32_t rs1,
                                    vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_vv_u64m1(vuint64m1_t vd, vuint64m1_t vs1,
                                    vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_vx_u64m1(vuint64m1_t vd, uint64_t rs1,
                                    vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_vv_u64m2(vuint64m2_t vd, vuint64m2_t vs1,
                                    vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_vx_u64m2(vuint64m2_t vd, uint64_t rs1,
                                    vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_vv_u64m4(vuint64m4_t vd, vuint64m4_t vs1,
                                    vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_vx_u64m4(vuint64m4_t vd, uint64_t rs1,
                                    vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_vv_u64m8(vuint64m8_t vd, vuint64m8_t vs1,
                                    vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_vx_u64m8(vuint64m8_t vd, uint64_t rs1,
                                    vuint64m8_t vs2, size_t vl);
// masked functions
vint8mf8_t __riscv_vmacc_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vd, vint8mf8_t vs1,
                                    vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmacc_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vd, int8_t rs1,
                                    vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vd, vint8mf4_t vs1,
                                    vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vd, int8_t rs1,
                                    vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vd, vint8mf2_t vs1,
                                    vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vd, int8_t rs1,
                                    vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmacc_vv_i8m1_m(vbool8_t vm, vint8m1_t vd, vint8m1_t vs1,
                                  vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmacc_vx_i8m1_m(vbool8_t vm, vint8m1_t vd, int8_t rs1,
                                  vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmacc_vv_i8m2_m(vbool4_t vm, vint8m2_t vd, vint8m2_t vs1,
                                  vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmacc_vx_i8m2_m(vbool4_t vm, vint8m2_t vd, int8_t rs1,
                                  vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmacc_vv_i8m4_m(vbool2_t vm, vint8m4_t vd, vint8m4_t vs1,
                                  vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmacc_vx_i8m4_m(vbool2_t vm, vint8m4_t vd, int8_t rs1,
                                  vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmacc_vv_i8m8_m(vbool1_t vm, vint8m8_t vd, vint8m8_t vs1,
                                  vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmacc_vx_i8m8_m(vbool1_t vm, vint8m8_t vd, int8_t rs1,
                                  vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                      vint16mf4_t vs1, vint16mf4_t vs2,
                                      size_t vl);
vint16mf4_t __riscv_vmacc_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vd, int16_t rs1,
                                      vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                      vint16mf2_t vs1, vint16mf2_t vs2,
                                      size_t vl);
vint16mf2_t __riscv_vmacc_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vd, int16_t rs1,
                                      vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_vv_i16m1_m(vbool16_t vm, vint16m1_t vd, vint16m1_t vs1,
                                    vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_vx_i16m1_m(vbool16_t vm, vint16m1_t vd, int16_t rs1,
                                    vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmacc_vv_i16m2_m(vbool8_t vm, vint16m2_t vd, vint16m2_t vs1,
                                    vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmacc_vx_i16m2_m(vbool8_t vm, vint16m2_t vd, int16_t rs1,
                                    vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmacc_vv_i16m4_m(vbool4_t vm, vint16m4_t vd, vint16m4_t vs1,
                                    vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmacc_vx_i16m4_m(vbool4_t vm, vint16m4_t vd, int16_t rs1,
                                    vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmacc_vv_i16m8_m(vbool2_t vm, vint16m8_t vd, vint16m8_t vs1,
                                    vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmacc_vx_i16m8_m(vbool2_t vm, vint16m8_t vd, int16_t rs1,
                                    vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                      vint32mf2_t vs1, vint32mf2_t vs2,
                                      size_t vl);
vint32mf2_t __riscv_vmacc_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vd, int32_t rs1,
                                      vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_vv_i32m1_m(vbool32_t vm, vint32m1_t vd, vint32m1_t vs1,
                                    vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_vx_i32m1_m(vbool32_t vm, vint32m1_t vd, int32_t rs1,
                                    vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmacc_vv_i32m2_m(vbool16_t vm, vint32m2_t vd, vint32m2_t vs1,
                                    vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmacc_vx_i32m2_m(vbool16_t vm, vint32m2_t vd, int32_t rs1,
                                    vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmacc_vv_i32m4_m(vbool8_t vm, vint32m4_t vd, vint32m4_t vs1,
                                    vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmacc_vx_i32m4_m(vbool8_t vm, vint32m4_t vd, int32_t rs1,
                                    vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmacc_vv_i32m8_m(vbool4_t vm, vint32m8_t vd, vint32m8_t vs1,
                                    vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmacc_vx_i32m8_m(vbool4_t vm, vint32m8_t vd, int32_t rs1,
                                    vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmacc_vv_i64m1_m(vbool64_t vm, vint64m1_t vd, vint64m1_t vs1,
                                    vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmacc_vx_i64m1_m(vbool64_t vm, vint64m1_t vd, int64_t rs1,
                                    vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmacc_vv_i64m2_m(vbool32_t vm, vint64m2_t vd, vint64m2_t vs1,
                                    vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmacc_vx_i64m2_m(vbool32_t vm, vint64m2_t vd, int64_t rs1,
                                    vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmacc_vv_i64m4_m(vbool16_t vm, vint64m4_t vd, vint64m4_t vs1,
                                    vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmacc_vx_i64m4_m(vbool16_t vm, vint64m4_t vd, int64_t rs1,
                                    vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmacc_vv_i64m8_m(vbool8_t vm, vint64m8_t vd, vint64m8_t vs1,
                                    vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmacc_vx_i64m8_m(vbool8_t vm, vint64m8_t vd, int64_t rs1,
                                    vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vd,
                                     vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vd, int8_t rs1,
                                     vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vd,
                                     vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vd, int8_t rs1,
                                     vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vd,
                                     vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vd, int8_t rs1,
                                     vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac_vv_i8m1_m(vbool8_t vm, vint8m1_t vd, vint8m1_t vs1,
                                   vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac_vx_i8m1_m(vbool8_t vm, vint8m1_t vd, int8_t rs1,
                                   vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac_vv_i8m2_m(vbool4_t vm, vint8m2_t vd, vint8m2_t vs1,
                                   vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac_vx_i8m2_m(vbool4_t vm, vint8m2_t vd, int8_t rs1,
                                   vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac_vv_i8m4_m(vbool2_t vm, vint8m4_t vd, vint8m4_t vs1,
                                   vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac_vx_i8m4_m(vbool2_t vm, vint8m4_t vd, int8_t rs1,
                                   vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac_vv_i8m8_m(vbool1_t vm, vint8m8_t vd, vint8m8_t vs1,
                                   vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac_vx_i8m8_m(vbool1_t vm, vint8m8_t vd, int8_t rs1,
                                   vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                       vint16mf4_t vs1, vint16mf4_t vs2,
                                       size_t vl);
vint16mf4_t __riscv_vnmsac_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                       int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                       vint16mf2_t vs1, vint16mf2_t vs2,
                                       size_t vl);
vint16mf2_t __riscv_vnmsac_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                       int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_vv_i16m1_m(vbool16_t vm, vint16m1_t vd,
                                     vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_vx_i16m1_m(vbool16_t vm, vint16m1_t vd, int16_t rs1,
                                     vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_vv_i16m2_m(vbool8_t vm, vint16m2_t vd, vint16m2_t vs1,
                                     vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_vx_i16m2_m(vbool8_t vm, vint16m2_t vd, int16_t rs1,
                                     vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_vv_i16m4_m(vbool4_t vm, vint16m4_t vd, vint16m4_t vs1,
                                     vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_vx_i16m4_m(vbool4_t vm, vint16m4_t vd, int16_t rs1,
                                     vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_vv_i16m8_m(vbool2_t vm, vint16m8_t vd, vint16m8_t vs1,
                                     vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_vx_i16m8_m(vbool2_t vm, vint16m8_t vd, int16_t rs1,
                                     vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                       vint32mf2_t vs1, vint32mf2_t vs2,
                                       size_t vl);
vint32mf2_t __riscv_vnmsac_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                       int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_vv_i32m1_m(vbool32_t vm, vint32m1_t vd,
                                     vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_vx_i32m1_m(vbool32_t vm, vint32m1_t vd, int32_t rs1,
                                     vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_vv_i32m2_m(vbool16_t vm, vint32m2_t vd,
                                     vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_vx_i32m2_m(vbool16_t vm, vint32m2_t vd, int32_t rs1,
                                     vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_vv_i32m4_m(vbool8_t vm, vint32m4_t vd, vint32m4_t vs1,
                                     vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_vx_i32m4_m(vbool8_t vm, vint32m4_t vd, int32_t rs1,
                                     vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_vv_i32m8_m(vbool4_t vm, vint32m8_t vd, vint32m8_t vs1,
                                     vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_vx_i32m8_m(vbool4_t vm, vint32m8_t vd, int32_t rs1,
                                     vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_vv_i64m1_m(vbool64_t vm, vint64m1_t vd,
                                     vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_vx_i64m1_m(vbool64_t vm, vint64m1_t vd, int64_t rs1,
                                     vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_vv_i64m2_m(vbool32_t vm, vint64m2_t vd,
                                     vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_vx_i64m2_m(vbool32_t vm, vint64m2_t vd, int64_t rs1,
                                     vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_vv_i64m4_m(vbool16_t vm, vint64m4_t vd,
                                     vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_vx_i64m4_m(vbool16_t vm, vint64m4_t vd, int64_t rs1,
                                     vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_vv_i64m8_m(vbool8_t vm, vint64m8_t vd, vint64m8_t vs1,
                                     vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_vx_i64m8_m(vbool8_t vm, vint64m8_t vd, int64_t rs1,
                                     vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vd, vint8mf8_t vs1,
                                    vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vd, int8_t rs1,
                                    vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vd, vint8mf4_t vs1,
                                    vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vd, int8_t rs1,
                                    vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vd, vint8mf2_t vs1,
                                    vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vd, int8_t rs1,
                                    vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmadd_vv_i8m1_m(vbool8_t vm, vint8m1_t vd, vint8m1_t vs1,
                                  vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmadd_vx_i8m1_m(vbool8_t vm, vint8m1_t vd, int8_t rs1,
                                  vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmadd_vv_i8m2_m(vbool4_t vm, vint8m2_t vd, vint8m2_t vs1,
                                  vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmadd_vx_i8m2_m(vbool4_t vm, vint8m2_t vd, int8_t rs1,
                                  vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmadd_vv_i8m4_m(vbool2_t vm, vint8m4_t vd, vint8m4_t vs1,
                                  vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmadd_vx_i8m4_m(vbool2_t vm, vint8m4_t vd, int8_t rs1,
                                  vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmadd_vv_i8m8_m(vbool1_t vm, vint8m8_t vd, vint8m8_t vs1,
                                  vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmadd_vx_i8m8_m(vbool1_t vm, vint8m8_t vd, int8_t rs1,
                                  vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                      vint16mf4_t vs1, vint16mf4_t vs2,
                                      size_t vl);
vint16mf4_t __riscv_vmadd_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vd, int16_t rs1,
                                      vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                      vint16mf2_t vs1, vint16mf2_t vs2,
                                      size_t vl);
vint16mf2_t __riscv_vmadd_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vd, int16_t rs1,
                                      vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_vv_i16m1_m(vbool16_t vm, vint16m1_t vd, vint16m1_t vs1,
                                    vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_vx_i16m1_m(vbool16_t vm, vint16m1_t vd, int16_t rs1,
                                    vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmadd_vv_i16m2_m(vbool8_t vm, vint16m2_t vd, vint16m2_t vs1,
                                    vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmadd_vx_i16m2_m(vbool8_t vm, vint16m2_t vd, int16_t rs1,
                                    vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmadd_vv_i16m4_m(vbool4_t vm, vint16m4_t vd, vint16m4_t vs1,
                                    vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmadd_vx_i16m4_m(vbool4_t vm, vint16m4_t vd, int16_t rs1,
                                    vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmadd_vv_i16m8_m(vbool2_t vm, vint16m8_t vd, vint16m8_t vs1,
                                    vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmadd_vx_i16m8_m(vbool2_t vm, vint16m8_t vd, int16_t rs1,
                                    vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                      vint32mf2_t vs1, vint32mf2_t vs2,
                                      size_t vl);
vint32mf2_t __riscv_vmadd_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vd, int32_t rs1,
                                      vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_vv_i32m1_m(vbool32_t vm, vint32m1_t vd, vint32m1_t vs1,
                                    vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_vx_i32m1_m(vbool32_t vm, vint32m1_t vd, int32_t rs1,
                                    vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmadd_vv_i32m2_m(vbool16_t vm, vint32m2_t vd, vint32m2_t vs1,
                                    vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmadd_vx_i32m2_m(vbool16_t vm, vint32m2_t vd, int32_t rs1,
                                    vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmadd_vv_i32m4_m(vbool8_t vm, vint32m4_t vd, vint32m4_t vs1,
                                    vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmadd_vx_i32m4_m(vbool8_t vm, vint32m4_t vd, int32_t rs1,
                                    vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmadd_vv_i32m8_m(vbool4_t vm, vint32m8_t vd, vint32m8_t vs1,
                                    vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmadd_vx_i32m8_m(vbool4_t vm, vint32m8_t vd, int32_t rs1,
                                    vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmadd_vv_i64m1_m(vbool64_t vm, vint64m1_t vd, vint64m1_t vs1,
                                    vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmadd_vx_i64m1_m(vbool64_t vm, vint64m1_t vd, int64_t rs1,
                                    vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmadd_vv_i64m2_m(vbool32_t vm, vint64m2_t vd, vint64m2_t vs1,
                                    vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmadd_vx_i64m2_m(vbool32_t vm, vint64m2_t vd, int64_t rs1,
                                    vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmadd_vv_i64m4_m(vbool16_t vm, vint64m4_t vd, vint64m4_t vs1,
                                    vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmadd_vx_i64m4_m(vbool16_t vm, vint64m4_t vd, int64_t rs1,
                                    vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmadd_vv_i64m8_m(vbool8_t vm, vint64m8_t vd, vint64m8_t vs1,
                                    vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmadd_vx_i64m8_m(vbool8_t vm, vint64m8_t vd, int64_t rs1,
                                    vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vd,
                                     vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vd, int8_t rs1,
                                     vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vd,
                                     vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vd, int8_t rs1,
                                     vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vd,
                                     vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vd, int8_t rs1,
                                     vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub_vv_i8m1_m(vbool8_t vm, vint8m1_t vd, vint8m1_t vs1,
                                   vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub_vx_i8m1_m(vbool8_t vm, vint8m1_t vd, int8_t rs1,
                                   vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub_vv_i8m2_m(vbool4_t vm, vint8m2_t vd, vint8m2_t vs1,
                                   vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub_vx_i8m2_m(vbool4_t vm, vint8m2_t vd, int8_t rs1,
                                   vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub_vv_i8m4_m(vbool2_t vm, vint8m4_t vd, vint8m4_t vs1,
                                   vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub_vx_i8m4_m(vbool2_t vm, vint8m4_t vd, int8_t rs1,
                                   vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub_vv_i8m8_m(vbool1_t vm, vint8m8_t vd, vint8m8_t vs1,
                                   vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub_vx_i8m8_m(vbool1_t vm, vint8m8_t vd, int8_t rs1,
                                   vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                       vint16mf4_t vs1, vint16mf4_t vs2,
                                       size_t vl);
vint16mf4_t __riscv_vnmsub_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                       int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                       vint16mf2_t vs1, vint16mf2_t vs2,
                                       size_t vl);
vint16mf2_t __riscv_vnmsub_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                       int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_vv_i16m1_m(vbool16_t vm, vint16m1_t vd,
                                     vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_vx_i16m1_m(vbool16_t vm, vint16m1_t vd, int16_t rs1,
                                     vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_vv_i16m2_m(vbool8_t vm, vint16m2_t vd, vint16m2_t vs1,
                                     vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_vx_i16m2_m(vbool8_t vm, vint16m2_t vd, int16_t rs1,
                                     vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_vv_i16m4_m(vbool4_t vm, vint16m4_t vd, vint16m4_t vs1,
                                     vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_vx_i16m4_m(vbool4_t vm, vint16m4_t vd, int16_t rs1,
                                     vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_vv_i16m8_m(vbool2_t vm, vint16m8_t vd, vint16m8_t vs1,
                                     vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_vx_i16m8_m(vbool2_t vm, vint16m8_t vd, int16_t rs1,
                                     vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                       vint32mf2_t vs1, vint32mf2_t vs2,
                                       size_t vl);
vint32mf2_t __riscv_vnmsub_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                       int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_vv_i32m1_m(vbool32_t vm, vint32m1_t vd,
                                     vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_vx_i32m1_m(vbool32_t vm, vint32m1_t vd, int32_t rs1,
                                     vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_vv_i32m2_m(vbool16_t vm, vint32m2_t vd,
                                     vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_vx_i32m2_m(vbool16_t vm, vint32m2_t vd, int32_t rs1,
                                     vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_vv_i32m4_m(vbool8_t vm, vint32m4_t vd, vint32m4_t vs1,
                                     vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_vx_i32m4_m(vbool8_t vm, vint32m4_t vd, int32_t rs1,
                                     vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_vv_i32m8_m(vbool4_t vm, vint32m8_t vd, vint32m8_t vs1,
                                     vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_vx_i32m8_m(vbool4_t vm, vint32m8_t vd, int32_t rs1,
                                     vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_vv_i64m1_m(vbool64_t vm, vint64m1_t vd,
                                     vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_vx_i64m1_m(vbool64_t vm, vint64m1_t vd, int64_t rs1,
                                     vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_vv_i64m2_m(vbool32_t vm, vint64m2_t vd,
                                     vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_vx_i64m2_m(vbool32_t vm, vint64m2_t vd, int64_t rs1,
                                     vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_vv_i64m4_m(vbool16_t vm, vint64m4_t vd,
                                     vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_vx_i64m4_m(vbool16_t vm, vint64m4_t vd, int64_t rs1,
                                     vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_vv_i64m8_m(vbool8_t vm, vint64m8_t vd, vint64m8_t vs1,
                                     vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_vx_i64m8_m(vbool8_t vm, vint64m8_t vd, int64_t rs1,
                                     vint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vd,
                                     vuint8mf8_t vs1, vuint8mf8_t vs2,
                                     size_t vl);
vuint8mf8_t __riscv_vmacc_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vd, uint8_t rs1,
                                     vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vd,
                                     vuint8mf4_t vs1, vuint8mf4_t vs2,
                                     size_t vl);
vuint8mf4_t __riscv_vmacc_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vd, uint8_t rs1,
                                     vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vd,
                                     vuint8mf2_t vs1, vuint8mf2_t vs2,
                                     size_t vl);
vuint8mf2_t __riscv_vmacc_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vd, uint8_t rs1,
                                     vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc_vv_u8m1_m(vbool8_t vm, vuint8m1_t vd, vuint8m1_t vs1,
                                   vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc_vx_u8m1_m(vbool8_t vm, vuint8m1_t vd, uint8_t rs1,
                                   vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc_vv_u8m2_m(vbool4_t vm, vuint8m2_t vd, vuint8m2_t vs1,
                                   vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc_vx_u8m2_m(vbool4_t vm, vuint8m2_t vd, uint8_t rs1,
                                   vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc_vv_u8m4_m(vbool2_t vm, vuint8m4_t vd, vuint8m4_t vs1,
                                   vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc_vx_u8m4_m(vbool2_t vm, vuint8m4_t vd, uint8_t rs1,
                                   vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc_vv_u8m8_m(vbool1_t vm, vuint8m8_t vd, vuint8m8_t vs1,
                                   vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc_vx_u8m8_m(vbool1_t vm, vuint8m8_t vd, uint8_t rs1,
                                   vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                       vuint16mf4_t vs1, vuint16mf4_t vs2,
                                       size_t vl);
vuint16mf4_t __riscv_vmacc_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                       uint16_t rs1, vuint16mf4_t vs2,
                                       size_t vl);
vuint16mf2_t __riscv_vmacc_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                       vuint16mf2_t vs1, vuint16mf2_t vs2,
                                       size_t vl);
vuint16mf2_t __riscv_vmacc_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                       uint16_t rs1, vuint16mf2_t vs2,
                                       size_t vl);
vuint16m1_t __riscv_vmacc_vv_u16m1_m(vbool16_t vm, vuint16m1_t vd,
                                     vuint16m1_t vs1, vuint16m1_t vs2,
                                     size_t vl);
vuint16m1_t __riscv_vmacc_vx_u16m1_m(vbool16_t vm, vuint16m1_t vd, uint16_t rs1,
                                     vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_vv_u16m2_m(vbool8_t vm, vuint16m2_t vd,
                                     vuint16m2_t vs1, vuint16m2_t vs2,
                                     size_t vl);
vuint16m2_t __riscv_vmacc_vx_u16m2_m(vbool8_t vm, vuint16m2_t vd, uint16_t rs1,
                                     vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_vv_u16m4_m(vbool4_t vm, vuint16m4_t vd,
                                     vuint16m4_t vs1, vuint16m4_t vs2,
                                     size_t vl);
vuint16m4_t __riscv_vmacc_vx_u16m4_m(vbool4_t vm, vuint16m4_t vd, uint16_t rs1,
                                     vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_vv_u16m8_m(vbool2_t vm, vuint16m8_t vd,
                                     vuint16m8_t vs1, vuint16m8_t vs2,
                                     size_t vl);
vuint16m8_t __riscv_vmacc_vx_u16m8_m(vbool2_t vm, vuint16m8_t vd, uint16_t rs1,
                                     vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                       vuint32mf2_t vs1, vuint32mf2_t vs2,
                                       size_t vl);
vuint32mf2_t __riscv_vmacc_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                       uint32_t rs1, vuint32mf2_t vs2,
                                       size_t vl);
vuint32m1_t __riscv_vmacc_vv_u32m1_m(vbool32_t vm, vuint32m1_t vd,
                                     vuint32m1_t vs1, vuint32m1_t vs2,
                                     size_t vl);
vuint32m1_t __riscv_vmacc_vx_u32m1_m(vbool32_t vm, vuint32m1_t vd, uint32_t rs1,
                                     vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_vv_u32m2_m(vbool16_t vm, vuint32m2_t vd,
                                     vuint32m2_t vs1, vuint32m2_t vs2,
                                     size_t vl);
vuint32m2_t __riscv_vmacc_vx_u32m2_m(vbool16_t vm, vuint32m2_t vd, uint32_t rs1,
                                     vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_vv_u32m4_m(vbool8_t vm, vuint32m4_t vd,
                                     vuint32m4_t vs1, vuint32m4_t vs2,
                                     size_t vl);
vuint32m4_t __riscv_vmacc_vx_u32m4_m(vbool8_t vm, vuint32m4_t vd, uint32_t rs1,
                                     vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_vv_u32m8_m(vbool4_t vm, vuint32m8_t vd,
                                     vuint32m8_t vs1, vuint32m8_t vs2,
                                     size_t vl);
vuint32m8_t __riscv_vmacc_vx_u32m8_m(vbool4_t vm, vuint32m8_t vd, uint32_t rs1,
                                     vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_vv_u64m1_m(vbool64_t vm, vuint64m1_t vd,
                                     vuint64m1_t vs1, vuint64m1_t vs2,
                                     size_t vl);
vuint64m1_t __riscv_vmacc_vx_u64m1_m(vbool64_t vm, vuint64m1_t vd, uint64_t rs1,
                                     vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_vv_u64m2_m(vbool32_t vm, vuint64m2_t vd,
                                     vuint64m2_t vs1, vuint64m2_t vs2,
                                     size_t vl);
vuint64m2_t __riscv_vmacc_vx_u64m2_m(vbool32_t vm, vuint64m2_t vd, uint64_t rs1,
                                     vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_vv_u64m4_m(vbool16_t vm, vuint64m4_t vd,
                                     vuint64m4_t vs1, vuint64m4_t vs2,
                                     size_t vl);
vuint64m4_t __riscv_vmacc_vx_u64m4_m(vbool16_t vm, vuint64m4_t vd, uint64_t rs1,
                                     vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_vv_u64m8_m(vbool8_t vm, vuint64m8_t vd,
                                     vuint64m8_t vs1, vuint64m8_t vs2,
                                     size_t vl);
vuint64m8_t __riscv_vmacc_vx_u64m8_m(vbool8_t vm, vuint64m8_t vd, uint64_t rs1,
                                     vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vd,
                                      vuint8mf8_t vs1, vuint8mf8_t vs2,
                                      size_t vl);
vuint8mf8_t __riscv_vnmsac_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vd, uint8_t rs1,
                                      vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vd,
                                      vuint8mf4_t vs1, vuint8mf4_t vs2,
                                      size_t vl);
vuint8mf4_t __riscv_vnmsac_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vd, uint8_t rs1,
                                      vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vd,
                                      vuint8mf2_t vs1, vuint8mf2_t vs2,
                                      size_t vl);
vuint8mf2_t __riscv_vnmsac_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vd, uint8_t rs1,
                                      vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_vv_u8m1_m(vbool8_t vm, vuint8m1_t vd, vuint8m1_t vs1,
                                    vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_vx_u8m1_m(vbool8_t vm, vuint8m1_t vd, uint8_t rs1,
                                    vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac_vv_u8m2_m(vbool4_t vm, vuint8m2_t vd, vuint8m2_t vs1,
                                    vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac_vx_u8m2_m(vbool4_t vm, vuint8m2_t vd, uint8_t rs1,
                                    vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac_vv_u8m4_m(vbool2_t vm, vuint8m4_t vd, vuint8m4_t vs1,
                                    vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac_vx_u8m4_m(vbool2_t vm, vuint8m4_t vd, uint8_t rs1,
                                    vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac_vv_u8m8_m(vbool1_t vm, vuint8m8_t vd, vuint8m8_t vs1,
                                    vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac_vx_u8m8_m(vbool1_t vm, vuint8m8_t vd, uint8_t rs1,
                                    vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                        vuint16mf4_t vs1, vuint16mf4_t vs2,
                                        size_t vl);
vuint16mf4_t __riscv_vnmsac_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                        uint16_t rs1, vuint16mf4_t vs2,
                                        size_t vl);
vuint16mf2_t __riscv_vnmsac_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                        vuint16mf2_t vs1, vuint16mf2_t vs2,
                                        size_t vl);
vuint16mf2_t __riscv_vnmsac_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                        uint16_t rs1, vuint16mf2_t vs2,
                                        size_t vl);
vuint16m1_t __riscv_vnmsac_vv_u16m1_m(vbool16_t vm, vuint16m1_t vd,
                                      vuint16m1_t vs1, vuint16m1_t vs2,
                                      size_t vl);
vuint16m1_t __riscv_vnmsac_vx_u16m1_m(vbool16_t vm, vuint16m1_t vd,
                                      uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_vv_u16m2_m(vbool8_t vm, vuint16m2_t vd,
                                      vuint16m2_t vs1, vuint16m2_t vs2,
                                      size_t vl);
vuint16m2_t __riscv_vnmsac_vx_u16m2_m(vbool8_t vm, vuint16m2_t vd, uint16_t rs1,
                                      vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_vv_u16m4_m(vbool4_t vm, vuint16m4_t vd,
                                      vuint16m4_t vs1, vuint16m4_t vs2,
                                      size_t vl);
vuint16m4_t __riscv_vnmsac_vx_u16m4_m(vbool4_t vm, vuint16m4_t vd, uint16_t rs1,
                                      vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_vv_u16m8_m(vbool2_t vm, vuint16m8_t vd,
                                      vuint16m8_t vs1, vuint16m8_t vs2,
                                      size_t vl);
vuint16m8_t __riscv_vnmsac_vx_u16m8_m(vbool2_t vm, vuint16m8_t vd, uint16_t rs1,
                                      vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                        vuint32mf2_t vs1, vuint32mf2_t vs2,
                                        size_t vl);
vuint32mf2_t __riscv_vnmsac_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                        uint32_t rs1, vuint32mf2_t vs2,
                                        size_t vl);
vuint32m1_t __riscv_vnmsac_vv_u32m1_m(vbool32_t vm, vuint32m1_t vd,
                                      vuint32m1_t vs1, vuint32m1_t vs2,
                                      size_t vl);
vuint32m1_t __riscv_vnmsac_vx_u32m1_m(vbool32_t vm, vuint32m1_t vd,
                                      uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_vv_u32m2_m(vbool16_t vm, vuint32m2_t vd,
                                      vuint32m2_t vs1, vuint32m2_t vs2,
                                      size_t vl);
vuint32m2_t __riscv_vnmsac_vx_u32m2_m(vbool16_t vm, vuint32m2_t vd,
                                      uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_vv_u32m4_m(vbool8_t vm, vuint32m4_t vd,
                                      vuint32m4_t vs1, vuint32m4_t vs2,
                                      size_t vl);
vuint32m4_t __riscv_vnmsac_vx_u32m4_m(vbool8_t vm, vuint32m4_t vd, uint32_t rs1,
                                      vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_vv_u32m8_m(vbool4_t vm, vuint32m8_t vd,
                                      vuint32m8_t vs1, vuint32m8_t vs2,
                                      size_t vl);
vuint32m8_t __riscv_vnmsac_vx_u32m8_m(vbool4_t vm, vuint32m8_t vd, uint32_t rs1,
                                      vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_vv_u64m1_m(vbool64_t vm, vuint64m1_t vd,
                                      vuint64m1_t vs1, vuint64m1_t vs2,
                                      size_t vl);
vuint64m1_t __riscv_vnmsac_vx_u64m1_m(vbool64_t vm, vuint64m1_t vd,
                                      uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_vv_u64m2_m(vbool32_t vm, vuint64m2_t vd,
                                      vuint64m2_t vs1, vuint64m2_t vs2,
                                      size_t vl);
vuint64m2_t __riscv_vnmsac_vx_u64m2_m(vbool32_t vm, vuint64m2_t vd,
                                      uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_vv_u64m4_m(vbool16_t vm, vuint64m4_t vd,
                                      vuint64m4_t vs1, vuint64m4_t vs2,
                                      size_t vl);
vuint64m4_t __riscv_vnmsac_vx_u64m4_m(vbool16_t vm, vuint64m4_t vd,
                                      uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_vv_u64m8_m(vbool8_t vm, vuint64m8_t vd,
                                      vuint64m8_t vs1, vuint64m8_t vs2,
                                      size_t vl);
vuint64m8_t __riscv_vnmsac_vx_u64m8_m(vbool8_t vm, vuint64m8_t vd, uint64_t rs1,
                                      vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vd,
                                     vuint8mf8_t vs1, vuint8mf8_t vs2,
                                     size_t vl);
vuint8mf8_t __riscv_vmadd_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vd, uint8_t rs1,
                                     vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vd,
                                     vuint8mf4_t vs1, vuint8mf4_t vs2,
                                     size_t vl);
vuint8mf4_t __riscv_vmadd_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vd, uint8_t rs1,
                                     vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vd,
                                     vuint8mf2_t vs1, vuint8mf2_t vs2,
                                     size_t vl);
vuint8mf2_t __riscv_vmadd_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vd, uint8_t rs1,
                                     vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd_vv_u8m1_m(vbool8_t vm, vuint8m1_t vd, vuint8m1_t vs1,
                                   vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd_vx_u8m1_m(vbool8_t vm, vuint8m1_t vd, uint8_t rs1,
                                   vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd_vv_u8m2_m(vbool4_t vm, vuint8m2_t vd, vuint8m2_t vs1,
                                   vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd_vx_u8m2_m(vbool4_t vm, vuint8m2_t vd, uint8_t rs1,
                                   vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd_vv_u8m4_m(vbool2_t vm, vuint8m4_t vd, vuint8m4_t vs1,
                                   vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd_vx_u8m4_m(vbool2_t vm, vuint8m4_t vd, uint8_t rs1,
                                   vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd_vv_u8m8_m(vbool1_t vm, vuint8m8_t vd, vuint8m8_t vs1,
                                   vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd_vx_u8m8_m(vbool1_t vm, vuint8m8_t vd, uint8_t rs1,
                                   vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                       vuint16mf4_t vs1, vuint16mf4_t vs2,
                                       size_t vl);
vuint16mf4_t __riscv_vmadd_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                       uint16_t rs1, vuint16mf4_t vs2,
                                       size_t vl);
vuint16mf2_t __riscv_vmadd_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                       vuint16mf2_t vs1, vuint16mf2_t vs2,
                                       size_t vl);
vuint16mf2_t __riscv_vmadd_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                       uint16_t rs1, vuint16mf2_t vs2,
                                       size_t vl);
vuint16m1_t __riscv_vmadd_vv_u16m1_m(vbool16_t vm, vuint16m1_t vd,
                                     vuint16m1_t vs1, vuint16m1_t vs2,
                                     size_t vl);
vuint16m1_t __riscv_vmadd_vx_u16m1_m(vbool16_t vm, vuint16m1_t vd, uint16_t rs1,
                                     vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_vv_u16m2_m(vbool8_t vm, vuint16m2_t vd,
                                     vuint16m2_t vs1, vuint16m2_t vs2,
                                     size_t vl);
vuint16m2_t __riscv_vmadd_vx_u16m2_m(vbool8_t vm, vuint16m2_t vd, uint16_t rs1,
                                     vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_vv_u16m4_m(vbool4_t vm, vuint16m4_t vd,
                                     vuint16m4_t vs1, vuint16m4_t vs2,
                                     size_t vl);
vuint16m4_t __riscv_vmadd_vx_u16m4_m(vbool4_t vm, vuint16m4_t vd, uint16_t rs1,
                                     vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_vv_u16m8_m(vbool2_t vm, vuint16m8_t vd,
                                     vuint16m8_t vs1, vuint16m8_t vs2,
                                     size_t vl);
vuint16m8_t __riscv_vmadd_vx_u16m8_m(vbool2_t vm, vuint16m8_t vd, uint16_t rs1,
                                     vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                       vuint32mf2_t vs1, vuint32mf2_t vs2,
                                       size_t vl);
vuint32mf2_t __riscv_vmadd_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                       uint32_t rs1, vuint32mf2_t vs2,
                                       size_t vl);
vuint32m1_t __riscv_vmadd_vv_u32m1_m(vbool32_t vm, vuint32m1_t vd,
                                     vuint32m1_t vs1, vuint32m1_t vs2,
                                     size_t vl);
vuint32m1_t __riscv_vmadd_vx_u32m1_m(vbool32_t vm, vuint32m1_t vd, uint32_t rs1,
                                     vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_vv_u32m2_m(vbool16_t vm, vuint32m2_t vd,
                                     vuint32m2_t vs1, vuint32m2_t vs2,
                                     size_t vl);
vuint32m2_t __riscv_vmadd_vx_u32m2_m(vbool16_t vm, vuint32m2_t vd, uint32_t rs1,
                                     vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_vv_u32m4_m(vbool8_t vm, vuint32m4_t vd,
                                     vuint32m4_t vs1, vuint32m4_t vs2,
                                     size_t vl);
vuint32m4_t __riscv_vmadd_vx_u32m4_m(vbool8_t vm, vuint32m4_t vd, uint32_t rs1,
                                     vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_vv_u32m8_m(vbool4_t vm, vuint32m8_t vd,
                                     vuint32m8_t vs1, vuint32m8_t vs2,
                                     size_t vl);
vuint32m8_t __riscv_vmadd_vx_u32m8_m(vbool4_t vm, vuint32m8_t vd, uint32_t rs1,
                                     vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_vv_u64m1_m(vbool64_t vm, vuint64m1_t vd,
                                     vuint64m1_t vs1, vuint64m1_t vs2,
                                     size_t vl);
vuint64m1_t __riscv_vmadd_vx_u64m1_m(vbool64_t vm, vuint64m1_t vd, uint64_t rs1,
                                     vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_vv_u64m2_m(vbool32_t vm, vuint64m2_t vd,
                                     vuint64m2_t vs1, vuint64m2_t vs2,
                                     size_t vl);
vuint64m2_t __riscv_vmadd_vx_u64m2_m(vbool32_t vm, vuint64m2_t vd, uint64_t rs1,
                                     vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_vv_u64m4_m(vbool16_t vm, vuint64m4_t vd,
                                     vuint64m4_t vs1, vuint64m4_t vs2,
                                     size_t vl);
vuint64m4_t __riscv_vmadd_vx_u64m4_m(vbool16_t vm, vuint64m4_t vd, uint64_t rs1,
                                     vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_vv_u64m8_m(vbool8_t vm, vuint64m8_t vd,
                                     vuint64m8_t vs1, vuint64m8_t vs2,
                                     size_t vl);
vuint64m8_t __riscv_vmadd_vx_u64m8_m(vbool8_t vm, vuint64m8_t vd, uint64_t rs1,
                                     vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vd,
                                      vuint8mf8_t vs1, vuint8mf8_t vs2,
                                      size_t vl);
vuint8mf8_t __riscv_vnmsub_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vd, uint8_t rs1,
                                      vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vd,
                                      vuint8mf4_t vs1, vuint8mf4_t vs2,
                                      size_t vl);
vuint8mf4_t __riscv_vnmsub_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vd, uint8_t rs1,
                                      vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vd,
                                      vuint8mf2_t vs1, vuint8mf2_t vs2,
                                      size_t vl);
vuint8mf2_t __riscv_vnmsub_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vd, uint8_t rs1,
                                      vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_vv_u8m1_m(vbool8_t vm, vuint8m1_t vd, vuint8m1_t vs1,
                                    vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_vx_u8m1_m(vbool8_t vm, vuint8m1_t vd, uint8_t rs1,
                                    vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub_vv_u8m2_m(vbool4_t vm, vuint8m2_t vd, vuint8m2_t vs1,
                                    vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub_vx_u8m2_m(vbool4_t vm, vuint8m2_t vd, uint8_t rs1,
                                    vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub_vv_u8m4_m(vbool2_t vm, vuint8m4_t vd, vuint8m4_t vs1,
                                    vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub_vx_u8m4_m(vbool2_t vm, vuint8m4_t vd, uint8_t rs1,
                                    vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub_vv_u8m8_m(vbool1_t vm, vuint8m8_t vd, vuint8m8_t vs1,
                                    vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub_vx_u8m8_m(vbool1_t vm, vuint8m8_t vd, uint8_t rs1,
                                    vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                        vuint16mf4_t vs1, vuint16mf4_t vs2,
                                        size_t vl);
vuint16mf4_t __riscv_vnmsub_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                        uint16_t rs1, vuint16mf4_t vs2,
                                        size_t vl);
vuint16mf2_t __riscv_vnmsub_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                        vuint16mf2_t vs1, vuint16mf2_t vs2,
                                        size_t vl);
vuint16mf2_t __riscv_vnmsub_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                        uint16_t rs1, vuint16mf2_t vs2,
                                        size_t vl);
vuint16m1_t __riscv_vnmsub_vv_u16m1_m(vbool16_t vm, vuint16m1_t vd,
                                      vuint16m1_t vs1, vuint16m1_t vs2,
                                      size_t vl);
vuint16m1_t __riscv_vnmsub_vx_u16m1_m(vbool16_t vm, vuint16m1_t vd,
                                      uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_vv_u16m2_m(vbool8_t vm, vuint16m2_t vd,
                                      vuint16m2_t vs1, vuint16m2_t vs2,
                                      size_t vl);
vuint16m2_t __riscv_vnmsub_vx_u16m2_m(vbool8_t vm, vuint16m2_t vd, uint16_t rs1,
                                      vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_vv_u16m4_m(vbool4_t vm, vuint16m4_t vd,
                                      vuint16m4_t vs1, vuint16m4_t vs2,
                                      size_t vl);
vuint16m4_t __riscv_vnmsub_vx_u16m4_m(vbool4_t vm, vuint16m4_t vd, uint16_t rs1,
                                      vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_vv_u16m8_m(vbool2_t vm, vuint16m8_t vd,
                                      vuint16m8_t vs1, vuint16m8_t vs2,
                                      size_t vl);
vuint16m8_t __riscv_vnmsub_vx_u16m8_m(vbool2_t vm, vuint16m8_t vd, uint16_t rs1,
                                      vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                        vuint32mf2_t vs1, vuint32mf2_t vs2,
                                        size_t vl);
vuint32mf2_t __riscv_vnmsub_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                        uint32_t rs1, vuint32mf2_t vs2,
                                        size_t vl);
vuint32m1_t __riscv_vnmsub_vv_u32m1_m(vbool32_t vm, vuint32m1_t vd,
                                      vuint32m1_t vs1, vuint32m1_t vs2,
                                      size_t vl);
vuint32m1_t __riscv_vnmsub_vx_u32m1_m(vbool32_t vm, vuint32m1_t vd,
                                      uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_vv_u32m2_m(vbool16_t vm, vuint32m2_t vd,
                                      vuint32m2_t vs1, vuint32m2_t vs2,
                                      size_t vl);
vuint32m2_t __riscv_vnmsub_vx_u32m2_m(vbool16_t vm, vuint32m2_t vd,
                                      uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_vv_u32m4_m(vbool8_t vm, vuint32m4_t vd,
                                      vuint32m4_t vs1, vuint32m4_t vs2,
                                      size_t vl);
vuint32m4_t __riscv_vnmsub_vx_u32m4_m(vbool8_t vm, vuint32m4_t vd, uint32_t rs1,
                                      vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_vv_u32m8_m(vbool4_t vm, vuint32m8_t vd,
                                      vuint32m8_t vs1, vuint32m8_t vs2,
                                      size_t vl);
vuint32m8_t __riscv_vnmsub_vx_u32m8_m(vbool4_t vm, vuint32m8_t vd, uint32_t rs1,
                                      vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_vv_u64m1_m(vbool64_t vm, vuint64m1_t vd,
                                      vuint64m1_t vs1, vuint64m1_t vs2,
                                      size_t vl);
vuint64m1_t __riscv_vnmsub_vx_u64m1_m(vbool64_t vm, vuint64m1_t vd,
                                      uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_vv_u64m2_m(vbool32_t vm, vuint64m2_t vd,
                                      vuint64m2_t vs1, vuint64m2_t vs2,
                                      size_t vl);
vuint64m2_t __riscv_vnmsub_vx_u64m2_m(vbool32_t vm, vuint64m2_t vd,
                                      uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_vv_u64m4_m(vbool16_t vm, vuint64m4_t vd,
                                      vuint64m4_t vs1, vuint64m4_t vs2,
                                      size_t vl);
vuint64m4_t __riscv_vnmsub_vx_u64m4_m(vbool16_t vm, vuint64m4_t vd,
                                      uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_vv_u64m8_m(vbool8_t vm, vuint64m8_t vd,
                                      vuint64m8_t vs1, vuint64m8_t vs2,
                                      size_t vl);
vuint64m8_t __riscv_vnmsub_vx_u64m8_m(vbool8_t vm, vuint64m8_t vd, uint64_t rs1,
                                      vuint64m8_t vs2, size_t vl);
----

[[vector-widening-integer-multiply-add]]
==== Vector Widening Integer Multiply-Add Intrinsics

[,c]
----
vint16mf4_t __riscv_vwmacc_vv_i16mf4(vint16mf4_t vd, vint8mf8_t vs1,
                                     vint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmacc_vx_i16mf4(vint16mf4_t vd, int8_t rs1, vint8mf8_t vs2,
                                     size_t vl);
vint16mf2_t __riscv_vwmacc_vv_i16mf2(vint16mf2_t vd, vint8mf4_t vs1,
                                     vint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc_vx_i16mf2(vint16mf2_t vd, int8_t rs1, vint8mf4_t vs2,
                                     size_t vl);
vint16m1_t __riscv_vwmacc_vv_i16m1(vint16m1_t vd, vint8mf2_t vs1,
                                   vint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_vx_i16m1(vint16m1_t vd, int8_t rs1, vint8mf2_t vs2,
                                   size_t vl);
vint16m2_t __riscv_vwmacc_vv_i16m2(vint16m2_t vd, vint8m1_t vs1, vint8m1_t vs2,
                                   size_t vl);
vint16m2_t __riscv_vwmacc_vx_i16m2(vint16m2_t vd, int8_t rs1, vint8m1_t vs2,
                                   size_t vl);
vint16m4_t __riscv_vwmacc_vv_i16m4(vint16m4_t vd, vint8m2_t vs1, vint8m2_t vs2,
                                   size_t vl);
vint16m4_t __riscv_vwmacc_vx_i16m4(vint16m4_t vd, int8_t rs1, vint8m2_t vs2,
                                   size_t vl);
vint16m8_t __riscv_vwmacc_vv_i16m8(vint16m8_t vd, vint8m4_t vs1, vint8m4_t vs2,
                                   size_t vl);
vint16m8_t __riscv_vwmacc_vx_i16m8(vint16m8_t vd, int8_t rs1, vint8m4_t vs2,
                                   size_t vl);
vint32mf2_t __riscv_vwmacc_vv_i32mf2(vint32mf2_t vd, vint16mf4_t vs1,
                                     vint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc_vx_i32mf2(vint32mf2_t vd, int16_t rs1,
                                     vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_vv_i32m1(vint32m1_t vd, vint16mf2_t vs1,
                                   vint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_vx_i32m1(vint32m1_t vd, int16_t rs1, vint16mf2_t vs2,
                                   size_t vl);
vint32m2_t __riscv_vwmacc_vv_i32m2(vint32m2_t vd, vint16m1_t vs1,
                                   vint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_vx_i32m2(vint32m2_t vd, int16_t rs1, vint16m1_t vs2,
                                   size_t vl);
vint32m4_t __riscv_vwmacc_vv_i32m4(vint32m4_t vd, vint16m2_t vs1,
                                   vint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_vx_i32m4(vint32m4_t vd, int16_t rs1, vint16m2_t vs2,
                                   size_t vl);
vint32m8_t __riscv_vwmacc_vv_i32m8(vint32m8_t vd, vint16m4_t vs1,
                                   vint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_vx_i32m8(vint32m8_t vd, int16_t rs1, vint16m4_t vs2,
                                   size_t vl);
vint64m1_t __riscv_vwmacc_vv_i64m1(vint64m1_t vd, vint32mf2_t vs1,
                                   vint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc_vx_i64m1(vint64m1_t vd, int32_t rs1, vint32mf2_t vs2,
                                   size_t vl);
vint64m2_t __riscv_vwmacc_vv_i64m2(vint64m2_t vd, vint32m1_t vs1,
                                   vint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_vx_i64m2(vint64m2_t vd, int32_t rs1, vint32m1_t vs2,
                                   size_t vl);
vint64m4_t __riscv_vwmacc_vv_i64m4(vint64m4_t vd, vint32m2_t vs1,
                                   vint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_vx_i64m4(vint64m4_t vd, int32_t rs1, vint32m2_t vs2,
                                   size_t vl);
vint64m8_t __riscv_vwmacc_vv_i64m8(vint64m8_t vd, vint32m4_t vs1,
                                   vint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_vx_i64m8(vint64m8_t vd, int32_t rs1, vint32m4_t vs2,
                                   size_t vl);
vint16mf4_t __riscv_vwmaccsu_vv_i16mf4(vint16mf4_t vd, vint8mf8_t vs1,
                                       vuint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu_vx_i16mf4(vint16mf4_t vd, int8_t rs1,
                                       vuint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu_vv_i16mf2(vint16mf2_t vd, vint8mf4_t vs1,
                                       vuint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu_vx_i16mf2(vint16mf2_t vd, int8_t rs1,
                                       vuint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu_vv_i16m1(vint16m1_t vd, vint8mf2_t vs1,
                                     vuint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu_vx_i16m1(vint16m1_t vd, int8_t rs1, vuint8mf2_t vs2,
                                     size_t vl);
vint16m2_t __riscv_vwmaccsu_vv_i16m2(vint16m2_t vd, vint8m1_t vs1,
                                     vuint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu_vx_i16m2(vint16m2_t vd, int8_t rs1, vuint8m1_t vs2,
                                     size_t vl);
vint16m4_t __riscv_vwmaccsu_vv_i16m4(vint16m4_t vd, vint8m2_t vs1,
                                     vuint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu_vx_i16m4(vint16m4_t vd, int8_t rs1, vuint8m2_t vs2,
                                     size_t vl);
vint16m8_t __riscv_vwmaccsu_vv_i16m8(vint16m8_t vd, vint8m4_t vs1,
                                     vuint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu_vx_i16m8(vint16m8_t vd, int8_t rs1, vuint8m4_t vs2,
                                     size_t vl);
vint32mf2_t __riscv_vwmaccsu_vv_i32mf2(vint32mf2_t vd, vint16mf4_t vs1,
                                       vuint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu_vx_i32mf2(vint32mf2_t vd, int16_t rs1,
                                       vuint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu_vv_i32m1(vint32m1_t vd, vint16mf2_t vs1,
                                     vuint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu_vx_i32m1(vint32m1_t vd, int16_t rs1,
                                     vuint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_vv_i32m2(vint32m2_t vd, vint16m1_t vs1,
                                     vuint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_vx_i32m2(vint32m2_t vd, int16_t rs1,
                                     vuint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_vv_i32m4(vint32m4_t vd, vint16m2_t vs1,
                                     vuint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_vx_i32m4(vint32m4_t vd, int16_t rs1,
                                     vuint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_vv_i32m8(vint32m8_t vd, vint16m4_t vs1,
                                     vuint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_vx_i32m8(vint32m8_t vd, int16_t rs1,
                                     vuint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_vv_i64m1(vint64m1_t vd, vint32mf2_t vs1,
                                     vuint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_vx_i64m1(vint64m1_t vd, int32_t rs1,
                                     vuint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_vv_i64m2(vint64m2_t vd, vint32m1_t vs1,
                                     vuint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_vx_i64m2(vint64m2_t vd, int32_t rs1,
                                     vuint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_vv_i64m4(vint64m4_t vd, vint32m2_t vs1,
                                     vuint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_vx_i64m4(vint64m4_t vd, int32_t rs1,
                                     vuint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_vv_i64m8(vint64m8_t vd, vint32m4_t vs1,
                                     vuint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_vx_i64m8(vint64m8_t vd, int32_t rs1,
                                     vuint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccus_vx_i16mf4(vint16mf4_t vd, uint8_t rs1,
                                       vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccus_vx_i16mf2(vint16mf2_t vd, uint8_t rs1,
                                       vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccus_vx_i16m1(vint16m1_t vd, uint8_t rs1, vint8mf2_t vs2,
                                     size_t vl);
vint16m2_t __riscv_vwmaccus_vx_i16m2(vint16m2_t vd, uint8_t rs1, vint8m1_t vs2,
                                     size_t vl);
vint16m4_t __riscv_vwmaccus_vx_i16m4(vint16m4_t vd, uint8_t rs1, vint8m2_t vs2,
                                     size_t vl);
vint16m8_t __riscv_vwmaccus_vx_i16m8(vint16m8_t vd, uint8_t rs1, vint8m4_t vs2,
                                     size_t vl);
vint32mf2_t __riscv_vwmaccus_vx_i32mf2(vint32mf2_t vd, uint16_t rs1,
                                       vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccus_vx_i32m1(vint32m1_t vd, uint16_t rs1,
                                     vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccus_vx_i32m2(vint32m2_t vd, uint16_t rs1,
                                     vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccus_vx_i32m4(vint32m4_t vd, uint16_t rs1,
                                     vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccus_vx_i32m8(vint32m8_t vd, uint16_t rs1,
                                     vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccus_vx_i64m1(vint64m1_t vd, uint32_t rs1,
                                     vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccus_vx_i64m2(vint64m2_t vd, uint32_t rs1,
                                     vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccus_vx_i64m4(vint64m4_t vd, uint32_t rs1,
                                     vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccus_vx_i64m8(vint64m8_t vd, uint32_t rs1,
                                     vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_vv_u16mf4(vuint16mf4_t vd, vuint8mf8_t vs1,
                                       vuint8mf8_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_vx_u16mf4(vuint16mf4_t vd, uint8_t rs1,
                                       vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu_vv_u16mf2(vuint16mf2_t vd, vuint8mf4_t vs1,
                                       vuint8mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu_vx_u16mf2(vuint16mf2_t vd, uint8_t rs1,
                                       vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu_vv_u16m1(vuint16m1_t vd, vuint8mf2_t vs1,
                                     vuint8mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu_vx_u16m1(vuint16m1_t vd, uint8_t rs1,
                                     vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_vv_u16m2(vuint16m2_t vd, vuint8m1_t vs1,
                                     vuint8m1_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_vx_u16m2(vuint16m2_t vd, uint8_t rs1,
                                     vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_vv_u16m4(vuint16m4_t vd, vuint8m2_t vs1,
                                     vuint8m2_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_vx_u16m4(vuint16m4_t vd, uint8_t rs1,
                                     vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_vv_u16m8(vuint16m8_t vd, vuint8m4_t vs1,
                                     vuint8m4_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_vx_u16m8(vuint16m8_t vd, uint8_t rs1,
                                     vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_vv_u32mf2(vuint32mf2_t vd, vuint16mf4_t vs1,
                                       vuint16mf4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_vx_u32mf2(vuint32mf2_t vd, uint16_t rs1,
                                       vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu_vv_u32m1(vuint32m1_t vd, vuint16mf2_t vs1,
                                     vuint16mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu_vx_u32m1(vuint32m1_t vd, uint16_t rs1,
                                     vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu_vv_u32m2(vuint32m2_t vd, vuint16m1_t vs1,
                                     vuint16m1_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu_vx_u32m2(vuint32m2_t vd, uint16_t rs1,
                                     vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu_vv_u32m4(vuint32m4_t vd, vuint16m2_t vs1,
                                     vuint16m2_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu_vx_u32m4(vuint32m4_t vd, uint16_t rs1,
                                     vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu_vv_u32m8(vuint32m8_t vd, vuint16m4_t vs1,
                                     vuint16m4_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu_vx_u32m8(vuint32m8_t vd, uint16_t rs1,
                                     vuint16m4_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu_vv_u64m1(vuint64m1_t vd, vuint32mf2_t vs1,
                                     vuint32mf2_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu_vx_u64m1(vuint64m1_t vd, uint32_t rs1,
                                     vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu_vv_u64m2(vuint64m2_t vd, vuint32m1_t vs1,
                                     vuint32m1_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu_vx_u64m2(vuint64m2_t vd, uint32_t rs1,
                                     vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu_vv_u64m4(vuint64m4_t vd, vuint32m2_t vs1,
                                     vuint32m2_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu_vx_u64m4(vuint64m4_t vd, uint32_t rs1,
                                     vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu_vv_u64m8(vuint64m8_t vd, vuint32m4_t vs1,
                                     vuint32m4_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu_vx_u64m8(vuint64m8_t vd, uint32_t rs1,
                                     vuint32m4_t vs2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwmacc_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                       vint8mf8_t vs1, vint8mf8_t vs2,
                                       size_t vl);
vint16mf4_t __riscv_vwmacc_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vd, int8_t rs1,
                                       vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                       vint8mf4_t vs1, vint8mf4_t vs2,
                                       size_t vl);
vint16mf2_t __riscv_vwmacc_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vd, int8_t rs1,
                                       vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_vv_i16m1_m(vbool16_t vm, vint16m1_t vd,
                                     vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_vx_i16m1_m(vbool16_t vm, vint16m1_t vd, int8_t rs1,
                                     vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc_vv_i16m2_m(vbool8_t vm, vint16m2_t vd, vint8m1_t vs1,
                                     vint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc_vx_i16m2_m(vbool8_t vm, vint16m2_t vd, int8_t rs1,
                                     vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc_vv_i16m4_m(vbool4_t vm, vint16m4_t vd, vint8m2_t vs1,
                                     vint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc_vx_i16m4_m(vbool4_t vm, vint16m4_t vd, int8_t rs1,
                                     vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc_vv_i16m8_m(vbool2_t vm, vint16m8_t vd, vint8m4_t vs1,
                                     vint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc_vx_i16m8_m(vbool2_t vm, vint16m8_t vd, int8_t rs1,
                                     vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                       vint16mf4_t vs1, vint16mf4_t vs2,
                                       size_t vl);
vint32mf2_t __riscv_vwmacc_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                       int16_t rs1, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_vv_i32m1_m(vbool32_t vm, vint32m1_t vd,
                                     vint16mf2_t vs1, vint16mf2_t vs2,
                                     size_t vl);
vint32m1_t __riscv_vwmacc_vx_i32m1_m(vbool32_t vm, vint32m1_t vd, int16_t rs1,
                                     vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_vv_i32m2_m(vbool16_t vm, vint32m2_t vd,
                                     vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_vx_i32m2_m(vbool16_t vm, vint32m2_t vd, int16_t rs1,
                                     vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_vv_i32m4_m(vbool8_t vm, vint32m4_t vd, vint16m2_t vs1,
                                     vint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_vx_i32m4_m(vbool8_t vm, vint32m4_t vd, int16_t rs1,
                                     vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_vv_i32m8_m(vbool4_t vm, vint32m8_t vd, vint16m4_t vs1,
                                     vint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_vx_i32m8_m(vbool4_t vm, vint32m8_t vd, int16_t rs1,
                                     vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc_vv_i64m1_m(vbool64_t vm, vint64m1_t vd,
                                     vint32mf2_t vs1, vint32mf2_t vs2,
                                     size_t vl);
vint64m1_t __riscv_vwmacc_vx_i64m1_m(vbool64_t vm, vint64m1_t vd, int32_t rs1,
                                     vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_vv_i64m2_m(vbool32_t vm, vint64m2_t vd,
                                     vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_vx_i64m2_m(vbool32_t vm, vint64m2_t vd, int32_t rs1,
                                     vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_vv_i64m4_m(vbool16_t vm, vint64m4_t vd,
                                     vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_vx_i64m4_m(vbool16_t vm, vint64m4_t vd, int32_t rs1,
                                     vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_vv_i64m8_m(vbool8_t vm, vint64m8_t vd, vint32m4_t vs1,
                                     vint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_vx_i64m8_m(vbool8_t vm, vint64m8_t vd, int32_t rs1,
                                     vint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                         vint8mf8_t vs1, vuint8mf8_t vs2,
                                         size_t vl);
vint16mf4_t __riscv_vwmaccsu_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                         int8_t rs1, vuint8mf8_t vs2,
                                         size_t vl);
vint16mf2_t __riscv_vwmaccsu_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                         vint8mf4_t vs1, vuint8mf4_t vs2,
                                         size_t vl);
vint16mf2_t __riscv_vwmaccsu_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                         int8_t rs1, vuint8mf4_t vs2,
                                         size_t vl);
vint16m1_t __riscv_vwmaccsu_vv_i16m1_m(vbool16_t vm, vint16m1_t vd,
                                       vint8mf2_t vs1, vuint8mf2_t vs2,
                                       size_t vl);
vint16m1_t __riscv_vwmaccsu_vx_i16m1_m(vbool16_t vm, vint16m1_t vd, int8_t rs1,
                                       vuint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu_vv_i16m2_m(vbool8_t vm, vint16m2_t vd,
                                       vint8m1_t vs1, vuint8m1_t vs2,
                                       size_t vl);
vint16m2_t __riscv_vwmaccsu_vx_i16m2_m(vbool8_t vm, vint16m2_t vd, int8_t rs1,
                                       vuint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu_vv_i16m4_m(vbool4_t vm, vint16m4_t vd,
                                       vint8m2_t vs1, vuint8m2_t vs2,
                                       size_t vl);
vint16m4_t __riscv_vwmaccsu_vx_i16m4_m(vbool4_t vm, vint16m4_t vd, int8_t rs1,
                                       vuint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu_vv_i16m8_m(vbool2_t vm, vint16m8_t vd,
                                       vint8m4_t vs1, vuint8m4_t vs2,
                                       size_t vl);
vint16m8_t __riscv_vwmaccsu_vx_i16m8_m(vbool2_t vm, vint16m8_t vd, int8_t rs1,
                                       vuint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                         vint16mf4_t vs1, vuint16mf4_t vs2,
                                         size_t vl);
vint32mf2_t __riscv_vwmaccsu_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                         int16_t rs1, vuint16mf4_t vs2,
                                         size_t vl);
vint32m1_t __riscv_vwmaccsu_vv_i32m1_m(vbool32_t vm, vint32m1_t vd,
                                       vint16mf2_t vs1, vuint16mf2_t vs2,
                                       size_t vl);
vint32m1_t __riscv_vwmaccsu_vx_i32m1_m(vbool32_t vm, vint32m1_t vd, int16_t rs1,
                                       vuint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_vv_i32m2_m(vbool16_t vm, vint32m2_t vd,
                                       vint16m1_t vs1, vuint16m1_t vs2,
                                       size_t vl);
vint32m2_t __riscv_vwmaccsu_vx_i32m2_m(vbool16_t vm, vint32m2_t vd, int16_t rs1,
                                       vuint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_vv_i32m4_m(vbool8_t vm, vint32m4_t vd,
                                       vint16m2_t vs1, vuint16m2_t vs2,
                                       size_t vl);
vint32m4_t __riscv_vwmaccsu_vx_i32m4_m(vbool8_t vm, vint32m4_t vd, int16_t rs1,
                                       vuint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_vv_i32m8_m(vbool4_t vm, vint32m8_t vd,
                                       vint16m4_t vs1, vuint16m4_t vs2,
                                       size_t vl);
vint32m8_t __riscv_vwmaccsu_vx_i32m8_m(vbool4_t vm, vint32m8_t vd, int16_t rs1,
                                       vuint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_vv_i64m1_m(vbool64_t vm, vint64m1_t vd,
                                       vint32mf2_t vs1, vuint32mf2_t vs2,
                                       size_t vl);
vint64m1_t __riscv_vwmaccsu_vx_i64m1_m(vbool64_t vm, vint64m1_t vd, int32_t rs1,
                                       vuint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_vv_i64m2_m(vbool32_t vm, vint64m2_t vd,
                                       vint32m1_t vs1, vuint32m1_t vs2,
                                       size_t vl);
vint64m2_t __riscv_vwmaccsu_vx_i64m2_m(vbool32_t vm, vint64m2_t vd, int32_t rs1,
                                       vuint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_vv_i64m4_m(vbool16_t vm, vint64m4_t vd,
                                       vint32m2_t vs1, vuint32m2_t vs2,
                                       size_t vl);
vint64m4_t __riscv_vwmaccsu_vx_i64m4_m(vbool16_t vm, vint64m4_t vd, int32_t rs1,
                                       vuint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_vv_i64m8_m(vbool8_t vm, vint64m8_t vd,
                                       vint32m4_t vs1, vuint32m4_t vs2,
                                       size_t vl);
vint64m8_t __riscv_vwmaccsu_vx_i64m8_m(vbool8_t vm, vint64m8_t vd, int32_t rs1,
                                       vuint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccus_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                         uint8_t rs1, vint8mf8_t vs2,
                                         size_t vl);
vint16mf2_t __riscv_vwmaccus_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                         uint8_t rs1, vint8mf4_t vs2,
                                         size_t vl);
vint16m1_t __riscv_vwmaccus_vx_i16m1_m(vbool16_t vm, vint16m1_t vd, uint8_t rs1,
                                       vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccus_vx_i16m2_m(vbool8_t vm, vint16m2_t vd, uint8_t rs1,
                                       vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccus_vx_i16m4_m(vbool4_t vm, vint16m4_t vd, uint8_t rs1,
                                       vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccus_vx_i16m8_m(vbool2_t vm, vint16m8_t vd, uint8_t rs1,
                                       vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccus_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                         uint16_t rs1, vint16mf4_t vs2,
                                         size_t vl);
vint32m1_t __riscv_vwmaccus_vx_i32m1_m(vbool32_t vm, vint32m1_t vd,
                                       uint16_t rs1, vint16mf2_t vs2,
                                       size_t vl);
vint32m2_t __riscv_vwmaccus_vx_i32m2_m(vbool16_t vm, vint32m2_t vd,
                                       uint16_t rs1, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccus_vx_i32m4_m(vbool8_t vm, vint32m4_t vd, uint16_t rs1,
                                       vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccus_vx_i32m8_m(vbool4_t vm, vint32m8_t vd, uint16_t rs1,
                                       vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccus_vx_i64m1_m(vbool64_t vm, vint64m1_t vd,
                                       uint32_t rs1, vint32mf2_t vs2,
                                       size_t vl);
vint64m2_t __riscv_vwmaccus_vx_i64m2_m(vbool32_t vm, vint64m2_t vd,
                                       uint32_t rs1, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccus_vx_i64m4_m(vbool16_t vm, vint64m4_t vd,
                                       uint32_t rs1, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccus_vx_i64m8_m(vbool8_t vm, vint64m8_t vd, uint32_t rs1,
                                       vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                         vuint8mf8_t vs1, vuint8mf8_t vs2,
                                         size_t vl);
vuint16mf4_t __riscv_vwmaccu_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                         uint8_t rs1, vuint8mf8_t vs2,
                                         size_t vl);
vuint16mf2_t __riscv_vwmaccu_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                         vuint8mf4_t vs1, vuint8mf4_t vs2,
                                         size_t vl);
vuint16mf2_t __riscv_vwmaccu_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                         uint8_t rs1, vuint8mf4_t vs2,
                                         size_t vl);
vuint16m1_t __riscv_vwmaccu_vv_u16m1_m(vbool16_t vm, vuint16m1_t vd,
                                       vuint8mf2_t vs1, vuint8mf2_t vs2,
                                       size_t vl);
vuint16m1_t __riscv_vwmaccu_vx_u16m1_m(vbool16_t vm, vuint16m1_t vd,
                                       uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_vv_u16m2_m(vbool8_t vm, vuint16m2_t vd,
                                       vuint8m1_t vs1, vuint8m1_t vs2,
                                       size_t vl);
vuint16m2_t __riscv_vwmaccu_vx_u16m2_m(vbool8_t vm, vuint16m2_t vd, uint8_t rs1,
                                       vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_vv_u16m4_m(vbool4_t vm, vuint16m4_t vd,
                                       vuint8m2_t vs1, vuint8m2_t vs2,
                                       size_t vl);
vuint16m4_t __riscv_vwmaccu_vx_u16m4_m(vbool4_t vm, vuint16m4_t vd, uint8_t rs1,
                                       vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_vv_u16m8_m(vbool2_t vm, vuint16m8_t vd,
                                       vuint8m4_t vs1, vuint8m4_t vs2,
                                       size_t vl);
vuint16m8_t __riscv_vwmaccu_vx_u16m8_m(vbool2_t vm, vuint16m8_t vd, uint8_t rs1,
                                       vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                         vuint16mf4_t vs1, vuint16mf4_t vs2,
                                         size_t vl);
vuint32mf2_t __riscv_vwmaccu_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                         uint16_t rs1, vuint16mf4_t vs2,
                                         size_t vl);
vuint32m1_t __riscv_vwmaccu_vv_u32m1_m(vbool32_t vm, vuint32m1_t vd,
                                       vuint16mf2_t vs1, vuint16mf2_t vs2,
                                       size_t vl);
vuint32m1_t __riscv_vwmaccu_vx_u32m1_m(vbool32_t vm, vuint32m1_t vd,
                                       uint16_t rs1, vuint16mf2_t vs2,
                                       size_t vl);
vuint32m2_t __riscv_vwmaccu_vv_u32m2_m(vbool16_t vm, vuint32m2_t vd,
                                       vuint16m1_t vs1, vuint16m1_t vs2,
                                       size_t vl);
vuint32m2_t __riscv_vwmaccu_vx_u32m2_m(vbool16_t vm, vuint32m2_t vd,
                                       uint16_t rs1, vuint16m1_t vs2,
                                       size_t vl);
vuint32m4_t __riscv_vwmaccu_vv_u32m4_m(vbool8_t vm, vuint32m4_t vd,
                                       vuint16m2_t vs1, vuint16m2_t vs2,
                                       size_t vl);
vuint32m4_t __riscv_vwmaccu_vx_u32m4_m(vbool8_t vm, vuint32m4_t vd,
                                       uint16_t rs1, vuint16m2_t vs2,
                                       size_t vl);
vuint32m8_t __riscv_vwmaccu_vv_u32m8_m(vbool4_t vm, vuint32m8_t vd,
                                       vuint16m4_t vs1, vuint16m4_t vs2,
                                       size_t vl);
vuint32m8_t __riscv_vwmaccu_vx_u32m8_m(vbool4_t vm, vuint32m8_t vd,
                                       uint16_t rs1, vuint16m4_t vs2,
                                       size_t vl);
vuint64m1_t __riscv_vwmaccu_vv_u64m1_m(vbool64_t vm, vuint64m1_t vd,
                                       vuint32mf2_t vs1, vuint32mf2_t vs2,
                                       size_t vl);
vuint64m1_t __riscv_vwmaccu_vx_u64m1_m(vbool64_t vm, vuint64m1_t vd,
                                       uint32_t rs1, vuint32mf2_t vs2,
                                       size_t vl);
vuint64m2_t __riscv_vwmaccu_vv_u64m2_m(vbool32_t vm, vuint64m2_t vd,
                                       vuint32m1_t vs1, vuint32m1_t vs2,
                                       size_t vl);
vuint64m2_t __riscv_vwmaccu_vx_u64m2_m(vbool32_t vm, vuint64m2_t vd,
                                       uint32_t rs1, vuint32m1_t vs2,
                                       size_t vl);
vuint64m4_t __riscv_vwmaccu_vv_u64m4_m(vbool16_t vm, vuint64m4_t vd,
                                       vuint32m2_t vs1, vuint32m2_t vs2,
                                       size_t vl);
vuint64m4_t __riscv_vwmaccu_vx_u64m4_m(vbool16_t vm, vuint64m4_t vd,
                                       uint32_t rs1, vuint32m2_t vs2,
                                       size_t vl);
vuint64m8_t __riscv_vwmaccu_vv_u64m8_m(vbool8_t vm, vuint64m8_t vd,
                                       vuint32m4_t vs1, vuint32m4_t vs2,
                                       size_t vl);
vuint64m8_t __riscv_vwmaccu_vx_u64m8_m(vbool8_t vm, vuint64m8_t vd,
                                       uint32_t rs1, vuint32m4_t vs2,
                                       size_t vl);
----

[[vector-integer-merge]]
==== Vector Integer Merge Intrinsics

[,c]
----
vint8mf8_t __riscv_vmerge_vvm_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1,
                                    vbool64_t v0, size_t vl);
vint8mf8_t __riscv_vmerge_vxm_i8mf8(vint8mf8_t vs2, int8_t rs1, vbool64_t v0,
                                    size_t vl);
vint8mf4_t __riscv_vmerge_vvm_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1,
                                    vbool32_t v0, size_t vl);
vint8mf4_t __riscv_vmerge_vxm_i8mf4(vint8mf4_t vs2, int8_t rs1, vbool32_t v0,
                                    size_t vl);
vint8mf2_t __riscv_vmerge_vvm_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1,
                                    vbool16_t v0, size_t vl);
vint8mf2_t __riscv_vmerge_vxm_i8mf2(vint8mf2_t vs2, int8_t rs1, vbool16_t v0,
                                    size_t vl);
vint8m1_t __riscv_vmerge_vvm_i8m1(vint8m1_t vs2, vint8m1_t vs1, vbool8_t v0,
                                  size_t vl);
vint8m1_t __riscv_vmerge_vxm_i8m1(vint8m1_t vs2, int8_t rs1, vbool8_t v0,
                                  size_t vl);
vint8m2_t __riscv_vmerge_vvm_i8m2(vint8m2_t vs2, vint8m2_t vs1, vbool4_t v0,
                                  size_t vl);
vint8m2_t __riscv_vmerge_vxm_i8m2(vint8m2_t vs2, int8_t rs1, vbool4_t v0,
                                  size_t vl);
vint8m4_t __riscv_vmerge_vvm_i8m4(vint8m4_t vs2, vint8m4_t vs1, vbool2_t v0,
                                  size_t vl);
vint8m4_t __riscv_vmerge_vxm_i8m4(vint8m4_t vs2, int8_t rs1, vbool2_t v0,
                                  size_t vl);
vint8m8_t __riscv_vmerge_vvm_i8m8(vint8m8_t vs2, vint8m8_t vs1, vbool1_t v0,
                                  size_t vl);
vint8m8_t __riscv_vmerge_vxm_i8m8(vint8m8_t vs2, int8_t rs1, vbool1_t v0,
                                  size_t vl);
vint16mf4_t __riscv_vmerge_vvm_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1,
                                      vbool64_t v0, size_t vl);
vint16mf4_t __riscv_vmerge_vxm_i16mf4(vint16mf4_t vs2, int16_t rs1,
                                      vbool64_t v0, size_t vl);
vint16mf2_t __riscv_vmerge_vvm_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1,
                                      vbool32_t v0, size_t vl);
vint16mf2_t __riscv_vmerge_vxm_i16mf2(vint16mf2_t vs2, int16_t rs1,
                                      vbool32_t v0, size_t vl);
vint16m1_t __riscv_vmerge_vvm_i16m1(vint16m1_t vs2, vint16m1_t vs1,
                                    vbool16_t v0, size_t vl);
vint16m1_t __riscv_vmerge_vxm_i16m1(vint16m1_t vs2, int16_t rs1, vbool16_t v0,
                                    size_t vl);
vint16m2_t __riscv_vmerge_vvm_i16m2(vint16m2_t vs2, vint16m2_t vs1, vbool8_t v0,
                                    size_t vl);
vint16m2_t __riscv_vmerge_vxm_i16m2(vint16m2_t vs2, int16_t rs1, vbool8_t v0,
                                    size_t vl);
vint16m4_t __riscv_vmerge_vvm_i16m4(vint16m4_t vs2, vint16m4_t vs1, vbool4_t v0,
                                    size_t vl);
vint16m4_t __riscv_vmerge_vxm_i16m4(vint16m4_t vs2, int16_t rs1, vbool4_t v0,
                                    size_t vl);
vint16m8_t __riscv_vmerge_vvm_i16m8(vint16m8_t vs2, vint16m8_t vs1, vbool2_t v0,
                                    size_t vl);
vint16m8_t __riscv_vmerge_vxm_i16m8(vint16m8_t vs2, int16_t rs1, vbool2_t v0,
                                    size_t vl);
vint32mf2_t __riscv_vmerge_vvm_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1,
                                      vbool64_t v0, size_t vl);
vint32mf2_t __riscv_vmerge_vxm_i32mf2(vint32mf2_t vs2, int32_t rs1,
                                      vbool64_t v0, size_t vl);
vint32m1_t __riscv_vmerge_vvm_i32m1(vint32m1_t vs2, vint32m1_t vs1,
                                    vbool32_t v0, size_t vl);
vint32m1_t __riscv_vmerge_vxm_i32m1(vint32m1_t vs2, int32_t rs1, vbool32_t v0,
                                    size_t vl);
vint32m2_t __riscv_vmerge_vvm_i32m2(vint32m2_t vs2, vint32m2_t vs1,
                                    vbool16_t v0, size_t vl);
vint32m2_t __riscv_vmerge_vxm_i32m2(vint32m2_t vs2, int32_t rs1, vbool16_t v0,
                                    size_t vl);
vint32m4_t __riscv_vmerge_vvm_i32m4(vint32m4_t vs2, vint32m4_t vs1, vbool8_t v0,
                                    size_t vl);
vint32m4_t __riscv_vmerge_vxm_i32m4(vint32m4_t vs2, int32_t rs1, vbool8_t v0,
                                    size_t vl);
vint32m8_t __riscv_vmerge_vvm_i32m8(vint32m8_t vs2, vint32m8_t vs1, vbool4_t v0,
                                    size_t vl);
vint32m8_t __riscv_vmerge_vxm_i32m8(vint32m8_t vs2, int32_t rs1, vbool4_t v0,
                                    size_t vl);
vint64m1_t __riscv_vmerge_vvm_i64m1(vint64m1_t vs2, vint64m1_t vs1,
                                    vbool64_t v0, size_t vl);
vint64m1_t __riscv_vmerge_vxm_i64m1(vint64m1_t vs2, int64_t rs1, vbool64_t v0,
                                    size_t vl);
vint64m2_t __riscv_vmerge_vvm_i64m2(vint64m2_t vs2, vint64m2_t vs1,
                                    vbool32_t v0, size_t vl);
vint64m2_t __riscv_vmerge_vxm_i64m2(vint64m2_t vs2, int64_t rs1, vbool32_t v0,
                                    size_t vl);
vint64m4_t __riscv_vmerge_vvm_i64m4(vint64m4_t vs2, vint64m4_t vs1,
                                    vbool16_t v0, size_t vl);
vint64m4_t __riscv_vmerge_vxm_i64m4(vint64m4_t vs2, int64_t rs1, vbool16_t v0,
                                    size_t vl);
vint64m8_t __riscv_vmerge_vvm_i64m8(vint64m8_t vs2, vint64m8_t vs1, vbool8_t v0,
                                    size_t vl);
vint64m8_t __riscv_vmerge_vxm_i64m8(vint64m8_t vs2, int64_t rs1, vbool8_t v0,
                                    size_t vl);
vuint8mf8_t __riscv_vmerge_vvm_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                     vbool64_t v0, size_t vl);
vuint8mf8_t __riscv_vmerge_vxm_u8mf8(vuint8mf8_t vs2, uint8_t rs1, vbool64_t v0,
                                     size_t vl);
vuint8mf4_t __riscv_vmerge_vvm_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                     vbool32_t v0, size_t vl);
vuint8mf4_t __riscv_vmerge_vxm_u8mf4(vuint8mf4_t vs2, uint8_t rs1, vbool32_t v0,
                                     size_t vl);
vuint8mf2_t __riscv_vmerge_vvm_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                     vbool16_t v0, size_t vl);
vuint8mf2_t __riscv_vmerge_vxm_u8mf2(vuint8mf2_t vs2, uint8_t rs1, vbool16_t v0,
                                     size_t vl);
vuint8m1_t __riscv_vmerge_vvm_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, vbool8_t v0,
                                   size_t vl);
vuint8m1_t __riscv_vmerge_vxm_u8m1(vuint8m1_t vs2, uint8_t rs1, vbool8_t v0,
                                   size_t vl);
vuint8m2_t __riscv_vmerge_vvm_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, vbool4_t v0,
                                   size_t vl);
vuint8m2_t __riscv_vmerge_vxm_u8m2(vuint8m2_t vs2, uint8_t rs1, vbool4_t v0,
                                   size_t vl);
vuint8m4_t __riscv_vmerge_vvm_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, vbool2_t v0,
                                   size_t vl);
vuint8m4_t __riscv_vmerge_vxm_u8m4(vuint8m4_t vs2, uint8_t rs1, vbool2_t v0,
                                   size_t vl);
vuint8m8_t __riscv_vmerge_vvm_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, vbool1_t v0,
                                   size_t vl);
vuint8m8_t __riscv_vmerge_vxm_u8m8(vuint8m8_t vs2, uint8_t rs1, vbool1_t v0,
                                   size_t vl);
vuint16mf4_t __riscv_vmerge_vvm_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                       vbool64_t v0, size_t vl);
vuint16mf4_t __riscv_vmerge_vxm_u16mf4(vuint16mf4_t vs2, uint16_t rs1,
                                       vbool64_t v0, size_t vl);
vuint16mf2_t __riscv_vmerge_vvm_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                       vbool32_t v0, size_t vl);
vuint16mf2_t __riscv_vmerge_vxm_u16mf2(vuint16mf2_t vs2, uint16_t rs1,
                                       vbool32_t v0, size_t vl);
vuint16m1_t __riscv_vmerge_vvm_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                     vbool16_t v0, size_t vl);
vuint16m1_t __riscv_vmerge_vxm_u16m1(vuint16m1_t vs2, uint16_t rs1,
                                     vbool16_t v0, size_t vl);
vuint16m2_t __riscv_vmerge_vvm_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                     vbool8_t v0, size_t vl);
vuint16m2_t __riscv_vmerge_vxm_u16m2(vuint16m2_t vs2, uint16_t rs1, vbool8_t v0,
                                     size_t vl);
vuint16m4_t __riscv_vmerge_vvm_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                     vbool4_t v0, size_t vl);
vuint16m4_t __riscv_vmerge_vxm_u16m4(vuint16m4_t vs2, uint16_t rs1, vbool4_t v0,
                                     size_t vl);
vuint16m8_t __riscv_vmerge_vvm_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                     vbool2_t v0, size_t vl);
vuint16m8_t __riscv_vmerge_vxm_u16m8(vuint16m8_t vs2, uint16_t rs1, vbool2_t v0,
                                     size_t vl);
vuint32mf2_t __riscv_vmerge_vvm_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                       vbool64_t v0, size_t vl);
vuint32mf2_t __riscv_vmerge_vxm_u32mf2(vuint32mf2_t vs2, uint32_t rs1,
                                       vbool64_t v0, size_t vl);
vuint32m1_t __riscv_vmerge_vvm_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                     vbool32_t v0, size_t vl);
vuint32m1_t __riscv_vmerge_vxm_u32m1(vuint32m1_t vs2, uint32_t rs1,
                                     vbool32_t v0, size_t vl);
vuint32m2_t __riscv_vmerge_vvm_u32m2(vuint32m2_t vs2, vuint32m2_t vs1,
                                     vbool16_t v0, size_t vl);
vuint32m2_t __riscv_vmerge_vxm_u32m2(vuint32m2_t vs2, uint32_t rs1,
                                     vbool16_t v0, size_t vl);
vuint32m4_t __riscv_vmerge_vvm_u32m4(vuint32m4_t vs2, vuint32m4_t vs1,
                                     vbool8_t v0, size_t vl);
vuint32m4_t __riscv_vmerge_vxm_u32m4(vuint32m4_t vs2, uint32_t rs1, vbool8_t v0,
                                     size_t vl);
vuint32m8_t __riscv_vmerge_vvm_u32m8(vuint32m8_t vs2, vuint32m8_t vs1,
                                     vbool4_t v0, size_t vl);
vuint32m8_t __riscv_vmerge_vxm_u32m8(vuint32m8_t vs2, uint32_t rs1, vbool4_t v0,
                                     size_t vl);
vuint64m1_t __riscv_vmerge_vvm_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                     vbool64_t v0, size_t vl);
vuint64m1_t __riscv_vmerge_vxm_u64m1(vuint64m1_t vs2, uint64_t rs1,
                                     vbool64_t v0, size_t vl);
vuint64m2_t __riscv_vmerge_vvm_u64m2(vuint64m2_t vs2, vuint64m2_t vs1,
                                     vbool32_t v0, size_t vl);
vuint64m2_t __riscv_vmerge_vxm_u64m2(vuint64m2_t vs2, uint64_t rs1,
                                     vbool32_t v0, size_t vl);
vuint64m4_t __riscv_vmerge_vvm_u64m4(vuint64m4_t vs2, vuint64m4_t vs1,
                                     vbool16_t v0, size_t vl);
vuint64m4_t __riscv_vmerge_vxm_u64m4(vuint64m4_t vs2, uint64_t rs1,
                                     vbool16_t v0, size_t vl);
vuint64m8_t __riscv_vmerge_vvm_u64m8(vuint64m8_t vs2, vuint64m8_t vs1,
                                     vbool8_t v0, size_t vl);
vuint64m8_t __riscv_vmerge_vxm_u64m8(vuint64m8_t vs2, uint64_t rs1, vbool8_t v0,
                                     size_t vl);
----

[[vector-integer-move]]
==== Vector Integer Move Intrinsics

[,c]
----
vint8mf8_t __riscv_vmv_v_v_i8mf8(vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmv_v_x_i8mf8(int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmv_v_v_i8mf4(vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmv_v_x_i8mf4(int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmv_v_v_i8mf2(vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmv_v_x_i8mf2(int8_t rs1, size_t vl);
vint8m1_t __riscv_vmv_v_v_i8m1(vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmv_v_x_i8m1(int8_t rs1, size_t vl);
vint8m2_t __riscv_vmv_v_v_i8m2(vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmv_v_x_i8m2(int8_t rs1, size_t vl);
vint8m4_t __riscv_vmv_v_v_i8m4(vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmv_v_x_i8m4(int8_t rs1, size_t vl);
vint8m8_t __riscv_vmv_v_v_i8m8(vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmv_v_x_i8m8(int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmv_v_v_i16mf4(vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmv_v_x_i16mf4(int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmv_v_v_i16mf2(vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmv_v_x_i16mf2(int16_t rs1, size_t vl);
vint16m1_t __riscv_vmv_v_v_i16m1(vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmv_v_x_i16m1(int16_t rs1, size_t vl);
vint16m2_t __riscv_vmv_v_v_i16m2(vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmv_v_x_i16m2(int16_t rs1, size_t vl);
vint16m4_t __riscv_vmv_v_v_i16m4(vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmv_v_x_i16m4(int16_t rs1, size_t vl);
vint16m8_t __riscv_vmv_v_v_i16m8(vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmv_v_x_i16m8(int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmv_v_v_i32mf2(vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmv_v_x_i32mf2(int32_t rs1, size_t vl);
vint32m1_t __riscv_vmv_v_v_i32m1(vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmv_v_x_i32m1(int32_t rs1, size_t vl);
vint32m2_t __riscv_vmv_v_v_i32m2(vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmv_v_x_i32m2(int32_t rs1, size_t vl);
vint32m4_t __riscv_vmv_v_v_i32m4(vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmv_v_x_i32m4(int32_t rs1, size_t vl);
vint32m8_t __riscv_vmv_v_v_i32m8(vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmv_v_x_i32m8(int32_t rs1, size_t vl);
vint64m1_t __riscv_vmv_v_v_i64m1(vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmv_v_x_i64m1(int64_t rs1, size_t vl);
vint64m2_t __riscv_vmv_v_v_i64m2(vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmv_v_x_i64m2(int64_t rs1, size_t vl);
vint64m4_t __riscv_vmv_v_v_i64m4(vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmv_v_x_i64m4(int64_t rs1, size_t vl);
vint64m8_t __riscv_vmv_v_v_i64m8(vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmv_v_x_i64m8(int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vmv_v_v_u8mf8(vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vmv_v_x_u8mf8(uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vmv_v_v_u8mf4(vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vmv_v_x_u8mf4(uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vmv_v_v_u8mf2(vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vmv_v_x_u8mf2(uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vmv_v_v_u8m1(vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vmv_v_x_u8m1(uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vmv_v_v_u8m2(vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vmv_v_x_u8m2(uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vmv_v_v_u8m4(vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vmv_v_x_u8m4(uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vmv_v_v_u8m8(vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vmv_v_x_u8m8(uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vmv_v_v_u16mf4(vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vmv_v_x_u16mf4(uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vmv_v_v_u16mf2(vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vmv_v_x_u16mf2(uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vmv_v_v_u16m1(vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vmv_v_x_u16m1(uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vmv_v_v_u16m2(vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vmv_v_x_u16m2(uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vmv_v_v_u16m4(vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vmv_v_x_u16m4(uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vmv_v_v_u16m8(vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vmv_v_x_u16m8(uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vmv_v_v_u32mf2(vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vmv_v_x_u32mf2(uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vmv_v_v_u32m1(vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vmv_v_x_u32m1(uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vmv_v_v_u32m2(vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vmv_v_x_u32m2(uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vmv_v_v_u32m4(vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vmv_v_x_u32m4(uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vmv_v_v_u32m8(vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vmv_v_x_u32m8(uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vmv_v_v_u64m1(vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vmv_v_x_u64m1(uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vmv_v_v_u64m2(vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vmv_v_x_u64m2(uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vmv_v_v_u64m4(vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vmv_v_x_u64m4(uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vmv_v_v_u64m8(vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vmv_v_x_u64m8(uint64_t rs1, size_t vl);
----

=== Vector Fixed-Point Arithmetic Intrinsics

[[vector-single-width-saturating-add-and-subtract]]
==== Vector Single-Width Saturating Add and Subtract Intrinsics
After executing an intrinsic in this section, the `vxsat` CSR assumes an UNSPECIFIED value.

[,c]
----
vint8mf8_t __riscv_vsadd_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vsadd_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vsadd_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vsadd_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vsadd_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vsadd_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vsadd_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vsadd_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vsadd_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vsadd_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vsadd_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vsadd_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vsadd_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vsadd_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vsadd_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1,
                                    size_t vl);
vint16mf4_t __riscv_vsadd_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vsadd_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1,
                                    size_t vl);
vint16mf2_t __riscv_vsadd_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vsadd_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vsadd_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vsadd_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vsadd_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vsadd_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vsadd_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vsadd_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vsadd_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vsadd_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1,
                                    size_t vl);
vint32mf2_t __riscv_vsadd_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vsadd_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vsadd_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vsadd_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vsadd_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vsadd_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vsadd_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vsadd_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vsadd_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vsadd_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vsadd_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vsadd_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vsadd_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vsadd_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vsadd_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vsadd_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vsadd_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vssub_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vssub_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vssub_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vssub_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vssub_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vssub_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vssub_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vssub_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vssub_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vssub_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vssub_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vssub_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vssub_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vssub_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vssub_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1,
                                    size_t vl);
vint16mf4_t __riscv_vssub_vx_i16mf4(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vssub_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1,
                                    size_t vl);
vint16mf2_t __riscv_vssub_vx_i16mf2(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vssub_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vssub_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vssub_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vssub_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vssub_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vssub_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vssub_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vssub_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vssub_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1,
                                    size_t vl);
vint32mf2_t __riscv_vssub_vx_i32mf2(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vssub_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vssub_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vssub_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vssub_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vssub_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vssub_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vssub_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vssub_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vssub_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vssub_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vssub_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vssub_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vssub_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vssub_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vssub_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vssub_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vsaddu_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                    size_t vl);
vuint8mf8_t __riscv_vsaddu_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vsaddu_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                    size_t vl);
vuint8mf4_t __riscv_vsaddu_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vsaddu_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                    size_t vl);
vuint8mf2_t __riscv_vsaddu_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vsaddu_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vsaddu_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vsaddu_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vsaddu_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vsaddu_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vsaddu_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vsaddu_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vsaddu_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vsaddu_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vuint16mf4_t __riscv_vsaddu_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1,
                                      size_t vl);
vuint16mf2_t __riscv_vsaddu_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                      size_t vl);
vuint16mf2_t __riscv_vsaddu_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1,
                                      size_t vl);
vuint16m1_t __riscv_vsaddu_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                    size_t vl);
vuint16m1_t __riscv_vsaddu_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vsaddu_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vuint16m2_t __riscv_vsaddu_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vsaddu_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vuint16m4_t __riscv_vsaddu_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vsaddu_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                    size_t vl);
vuint16m8_t __riscv_vsaddu_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vsaddu_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                      size_t vl);
vuint32mf2_t __riscv_vsaddu_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1,
                                      size_t vl);
vuint32m1_t __riscv_vsaddu_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                    size_t vl);
vuint32m1_t __riscv_vsaddu_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vsaddu_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1,
                                    size_t vl);
vuint32m2_t __riscv_vsaddu_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vsaddu_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vuint32m4_t __riscv_vsaddu_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vsaddu_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1,
                                    size_t vl);
vuint32m8_t __riscv_vsaddu_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vsaddu_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                    size_t vl);
vuint64m1_t __riscv_vsaddu_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vsaddu_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1,
                                    size_t vl);
vuint64m2_t __riscv_vsaddu_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vsaddu_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1,
                                    size_t vl);
vuint64m4_t __riscv_vsaddu_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vsaddu_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    size_t vl);
vuint64m8_t __riscv_vsaddu_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vssubu_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                    size_t vl);
vuint8mf8_t __riscv_vssubu_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vssubu_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                    size_t vl);
vuint8mf4_t __riscv_vssubu_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vssubu_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                    size_t vl);
vuint8mf2_t __riscv_vssubu_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vssubu_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vssubu_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vssubu_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vssubu_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vssubu_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vssubu_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vssubu_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vssubu_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vssubu_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      size_t vl);
vuint16mf4_t __riscv_vssubu_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1,
                                      size_t vl);
vuint16mf2_t __riscv_vssubu_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                      size_t vl);
vuint16mf2_t __riscv_vssubu_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1,
                                      size_t vl);
vuint16m1_t __riscv_vssubu_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                    size_t vl);
vuint16m1_t __riscv_vssubu_vx_u16m1(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vssubu_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                    size_t vl);
vuint16m2_t __riscv_vssubu_vx_u16m2(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vssubu_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    size_t vl);
vuint16m4_t __riscv_vssubu_vx_u16m4(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vssubu_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                    size_t vl);
vuint16m8_t __riscv_vssubu_vx_u16m8(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vssubu_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                      size_t vl);
vuint32mf2_t __riscv_vssubu_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1,
                                      size_t vl);
vuint32m1_t __riscv_vssubu_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                    size_t vl);
vuint32m1_t __riscv_vssubu_vx_u32m1(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vssubu_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1,
                                    size_t vl);
vuint32m2_t __riscv_vssubu_vx_u32m2(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vssubu_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1,
                                    size_t vl);
vuint32m4_t __riscv_vssubu_vx_u32m4(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vssubu_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1,
                                    size_t vl);
vuint32m8_t __riscv_vssubu_vx_u32m8(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vssubu_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                    size_t vl);
vuint64m1_t __riscv_vssubu_vx_u64m1(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vssubu_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1,
                                    size_t vl);
vuint64m2_t __riscv_vssubu_vx_u64m2(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vssubu_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1,
                                    size_t vl);
vuint64m4_t __riscv_vssubu_vx_u64m4(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vssubu_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    size_t vl);
vuint64m8_t __riscv_vssubu_vx_u64m8(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vsadd_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                    vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vsadd_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                    size_t vl);
vint8mf4_t __riscv_vsadd_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                    vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vsadd_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                    size_t vl);
vint8mf2_t __riscv_vsadd_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                    vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vsadd_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                    size_t vl);
vint8m1_t __riscv_vsadd_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                  size_t vl);
vint8m1_t __riscv_vsadd_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                  size_t vl);
vint8m2_t __riscv_vsadd_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                  size_t vl);
vint8m2_t __riscv_vsadd_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                  size_t vl);
vint8m4_t __riscv_vsadd_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                  size_t vl);
vint8m4_t __riscv_vsadd_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                  size_t vl);
vint8m8_t __riscv_vsadd_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                  size_t vl);
vint8m8_t __riscv_vsadd_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                  size_t vl);
vint16mf4_t __riscv_vsadd_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vsadd_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      int16_t rs1, size_t vl);
vint16mf2_t __riscv_vsadd_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vsadd_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      int16_t rs1, size_t vl);
vint16m1_t __riscv_vsadd_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                    vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vsadd_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                    size_t vl);
vint16m2_t __riscv_vsadd_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                    size_t vl);
vint16m2_t __riscv_vsadd_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                    size_t vl);
vint16m4_t __riscv_vsadd_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                    size_t vl);
vint16m4_t __riscv_vsadd_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                    size_t vl);
vint16m8_t __riscv_vsadd_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                    size_t vl);
vint16m8_t __riscv_vsadd_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                    size_t vl);
vint32mf2_t __riscv_vsadd_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vsadd_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      int32_t rs1, size_t vl);
vint32m1_t __riscv_vsadd_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                    vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vsadd_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                    size_t vl);
vint32m2_t __riscv_vsadd_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                    vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vsadd_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                    size_t vl);
vint32m4_t __riscv_vsadd_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                    size_t vl);
vint32m4_t __riscv_vsadd_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                    size_t vl);
vint32m8_t __riscv_vsadd_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                    size_t vl);
vint32m8_t __riscv_vsadd_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                    size_t vl);
vint64m1_t __riscv_vsadd_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                    vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vsadd_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                    size_t vl);
vint64m2_t __riscv_vsadd_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                    vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vsadd_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                    size_t vl);
vint64m4_t __riscv_vsadd_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                    vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vsadd_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                    size_t vl);
vint64m8_t __riscv_vsadd_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                    size_t vl);
vint64m8_t __riscv_vsadd_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                    size_t vl);
vint8mf8_t __riscv_vssub_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                    vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vssub_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                    size_t vl);
vint8mf4_t __riscv_vssub_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                    vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vssub_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                    size_t vl);
vint8mf2_t __riscv_vssub_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                    vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vssub_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                    size_t vl);
vint8m1_t __riscv_vssub_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                  size_t vl);
vint8m1_t __riscv_vssub_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                  size_t vl);
vint8m2_t __riscv_vssub_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                  size_t vl);
vint8m2_t __riscv_vssub_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                  size_t vl);
vint8m4_t __riscv_vssub_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                  size_t vl);
vint8m4_t __riscv_vssub_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                  size_t vl);
vint8m8_t __riscv_vssub_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                  size_t vl);
vint8m8_t __riscv_vssub_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                  size_t vl);
vint16mf4_t __riscv_vssub_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vssub_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      int16_t rs1, size_t vl);
vint16mf2_t __riscv_vssub_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vssub_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      int16_t rs1, size_t vl);
vint16m1_t __riscv_vssub_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                    vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vssub_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                    size_t vl);
vint16m2_t __riscv_vssub_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                    size_t vl);
vint16m2_t __riscv_vssub_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                    size_t vl);
vint16m4_t __riscv_vssub_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                    size_t vl);
vint16m4_t __riscv_vssub_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                    size_t vl);
vint16m8_t __riscv_vssub_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                    size_t vl);
vint16m8_t __riscv_vssub_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                    size_t vl);
vint32mf2_t __riscv_vssub_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vssub_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      int32_t rs1, size_t vl);
vint32m1_t __riscv_vssub_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                    vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vssub_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                    size_t vl);
vint32m2_t __riscv_vssub_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                    vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vssub_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                    size_t vl);
vint32m4_t __riscv_vssub_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                    size_t vl);
vint32m4_t __riscv_vssub_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                    size_t vl);
vint32m8_t __riscv_vssub_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                    size_t vl);
vint32m8_t __riscv_vssub_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                    size_t vl);
vint64m1_t __riscv_vssub_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                    vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vssub_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                    size_t vl);
vint64m2_t __riscv_vssub_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                    vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vssub_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                    size_t vl);
vint64m4_t __riscv_vssub_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                    vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vssub_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                    size_t vl);
vint64m8_t __riscv_vssub_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                    size_t vl);
vint64m8_t __riscv_vssub_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                    size_t vl);
vuint8mf8_t __riscv_vsaddu_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                      vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vsaddu_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                      uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vsaddu_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                      vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vsaddu_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                      uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vsaddu_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                      vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vsaddu_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                      uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vsaddu_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                    size_t vl);
vuint8m1_t __riscv_vsaddu_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m2_t __riscv_vsaddu_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                    size_t vl);
vuint8m2_t __riscv_vsaddu_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m4_t __riscv_vsaddu_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                    size_t vl);
vuint8m4_t __riscv_vsaddu_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m8_t __riscv_vsaddu_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                    size_t vl);
vuint8m8_t __riscv_vsaddu_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                    size_t vl);
vuint16mf4_t __riscv_vsaddu_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vsaddu_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vsaddu_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vsaddu_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vsaddu_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vsaddu_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vsaddu_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vsaddu_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vsaddu_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vsaddu_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vsaddu_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vsaddu_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vsaddu_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vsaddu_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vsaddu_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vsaddu_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vsaddu_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vsaddu_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vsaddu_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vsaddu_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vsaddu_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vsaddu_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vsaddu_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vsaddu_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vsaddu_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vsaddu_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vsaddu_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vsaddu_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vsaddu_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vsaddu_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vssubu_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                      vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vssubu_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                      uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vssubu_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                      vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vssubu_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                      uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vssubu_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                      vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vssubu_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                      uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vssubu_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                    size_t vl);
vuint8m1_t __riscv_vssubu_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m2_t __riscv_vssubu_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                    size_t vl);
vuint8m2_t __riscv_vssubu_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m4_t __riscv_vssubu_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                    size_t vl);
vuint8m4_t __riscv_vssubu_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                    size_t vl);
vuint8m8_t __riscv_vssubu_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                    size_t vl);
vuint8m8_t __riscv_vssubu_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                    size_t vl);
vuint16mf4_t __riscv_vssubu_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vssubu_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vssubu_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vssubu_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vssubu_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vssubu_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vssubu_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vssubu_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vssubu_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vssubu_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vssubu_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vssubu_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vssubu_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vssubu_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vssubu_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vssubu_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vssubu_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vssubu_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vssubu_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vssubu_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vssubu_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vssubu_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vssubu_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vssubu_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vssubu_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vssubu_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vssubu_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vssubu_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vssubu_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vssubu_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint64_t rs1, size_t vl);
----

[[vector-single-width-averaging-add-and-subtract]]
==== Vector Single-Width Averaging Add and Subtract Intrinsics

[,c]
----
vint8mf8_t __riscv_vaadd_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vaadd_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8mf4_t __riscv_vaadd_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8mf2_t __riscv_vaadd_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8m1_t __riscv_vaadd_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m1_t __riscv_vaadd_vx_i8m1(vint8m1_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m2_t __riscv_vaadd_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m2_t __riscv_vaadd_vx_i8m2(vint8m2_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m4_t __riscv_vaadd_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m4_t __riscv_vaadd_vx_i8m4(vint8m4_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m8_t __riscv_vaadd_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m8_t __riscv_vaadd_vx_i8m8(vint8m8_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint16mf4_t __riscv_vaadd_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_vx_i16mf4(vint16mf4_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_vx_i16mf2(vint16mf2_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_vx_i16m1(vint16m1_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_vx_i16m2(vint16m2_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_vx_i16m4(vint16m4_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_vx_i16m8(vint16m8_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_vx_i32mf2(vint32mf2_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_vx_i32m1(vint32m1_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_vx_i32m2(vint32m2_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_vx_i32m4(vint32m4_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_vx_i32m8(vint32m8_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_vx_i64m1(vint64m1_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_vx_i64m2(vint64m2_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_vx_i64m4(vint64m4_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_vx_i64m8(vint64m8_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8mf4_t __riscv_vasub_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8mf2_t __riscv_vasub_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8m1_t __riscv_vasub_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m1_t __riscv_vasub_vx_i8m1(vint8m1_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m2_t __riscv_vasub_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m2_t __riscv_vasub_vx_i8m2(vint8m2_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m4_t __riscv_vasub_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m4_t __riscv_vasub_vx_i8m4(vint8m4_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m8_t __riscv_vasub_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m8_t __riscv_vasub_vx_i8m8(vint8m8_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint16mf4_t __riscv_vasub_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_vx_i16mf4(vint16mf4_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_vx_i16mf2(vint16mf2_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_vx_i16m1(vint16m1_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_vx_i16m2(vint16m2_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_vx_i16m4(vint16m4_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_vx_i16m8(vint16m8_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_vx_i32mf2(vint32mf2_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_vx_i32m1(vint32m1_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_vx_i32m2(vint32m2_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_vx_i32m4(vint32m4_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_vx_i32m8(vint32m8_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_vx_i64m1(vint64m1_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_vx_i64m2(vint64m2_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_vx_i64m4(vint64m4_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_vx_i64m8(vint64m8_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_vx_u8m1(vuint8m1_t vs2, uint8_t rs1,
                                  unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_vx_u8m2(vuint8m2_t vs2, uint8_t rs1,
                                  unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_vx_u8m4(vuint8m4_t vs2, uint8_t rs1,
                                  unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_vx_u8m8(vuint8m8_t vs2, uint8_t rs1,
                                  unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1,
                                      unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                      unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1,
                                      unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_vx_u16m1(vuint16m1_t vs2, uint16_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_vx_u16m2(vuint16m2_t vs2, uint16_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_vx_u16m4(vuint16m4_t vs2, uint16_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_vx_u16m8(vuint16m8_t vs2, uint16_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                      unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1,
                                      unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_vx_u32m1(vuint32m1_t vs2, uint32_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_vx_u32m2(vuint32m2_t vs2, uint32_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_vx_u32m4(vuint32m4_t vs2, uint32_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_vx_u32m8(vuint32m8_t vs2, uint32_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_vx_u64m1(vuint64m1_t vs2, uint64_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_vx_u64m2(vuint64m2_t vs2, uint64_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_vx_u64m4(vuint64m4_t vs2, uint64_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_vx_u64m8(vuint64m8_t vs2, uint64_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_vx_u8m1(vuint8m1_t vs2, uint8_t rs1,
                                  unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_vx_u8m2(vuint8m2_t vs2, uint8_t rs1,
                                  unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_vx_u8m4(vuint8m4_t vs2, uint8_t rs1,
                                  unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_vx_u8m8(vuint8m8_t vs2, uint8_t rs1,
                                  unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                      unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1,
                                      unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                      unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1,
                                      unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_vx_u16m1(vuint16m1_t vs2, uint16_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_vx_u16m2(vuint16m2_t vs2, uint16_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_vx_u16m4(vuint16m4_t vs2, uint16_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_vx_u16m8(vuint16m8_t vs2, uint16_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                      unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1,
                                      unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_vx_u32m1(vuint32m1_t vs2, uint32_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_vx_u32m2(vuint32m2_t vs2, uint32_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_vx_u32m4(vuint32m4_t vs2, uint32_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_vx_u32m8(vuint32m8_t vs2, uint32_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_vx_u64m1(vuint64m1_t vs2, uint64_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_vx_u64m2(vuint64m2_t vs2, uint64_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_vx_u64m4(vuint64m4_t vs2, uint64_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_vx_u64m8(vuint64m8_t vs2, uint64_t rs1,
                                    unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vaadd_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                    vint8mf8_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf8_t __riscv_vaadd_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                    vint8mf4_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf4_t __riscv_vaadd_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                    vint8mf2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf2_t __riscv_vaadd_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint16mf4_t vs1, unsigned int vxrm,
                                      size_t vl);
vint16mf4_t __riscv_vaadd_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      int16_t rs1, unsigned int vxrm,
                                      size_t vl);
vint16mf2_t __riscv_vaadd_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      vint16mf2_t vs1, unsigned int vxrm,
                                      size_t vl);
vint16mf2_t __riscv_vaadd_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      int16_t rs1, unsigned int vxrm,
                                      size_t vl);
vint16m1_t __riscv_vaadd_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                    vint16m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint16m1_t __riscv_vaadd_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      vint32mf2_t vs1, unsigned int vxrm,
                                      size_t vl);
vint32mf2_t __riscv_vaadd_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      int32_t rs1, unsigned int vxrm,
                                      size_t vl);
vint32m1_t __riscv_vaadd_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                    vint32m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint32m1_t __riscv_vaadd_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                    vint32m2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint32m2_t __riscv_vaadd_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                    vint64m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m1_t __riscv_vaadd_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                    vint64m2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m2_t __riscv_vaadd_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                    vint64m4_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m4_t __riscv_vaadd_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                    vint8mf8_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf8_t __riscv_vasub_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                    vint8mf4_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf4_t __riscv_vasub_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                    vint8mf2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf2_t __riscv_vasub_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint16mf4_t vs1, unsigned int vxrm,
                                      size_t vl);
vint16mf4_t __riscv_vasub_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      int16_t rs1, unsigned int vxrm,
                                      size_t vl);
vint16mf2_t __riscv_vasub_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      vint16mf2_t vs1, unsigned int vxrm,
                                      size_t vl);
vint16mf2_t __riscv_vasub_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      int16_t rs1, unsigned int vxrm,
                                      size_t vl);
vint16m1_t __riscv_vasub_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                    vint16m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint16m1_t __riscv_vasub_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      vint32mf2_t vs1, unsigned int vxrm,
                                      size_t vl);
vint32mf2_t __riscv_vasub_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      int32_t rs1, unsigned int vxrm,
                                      size_t vl);
vint32m1_t __riscv_vasub_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                    vint32m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint32m1_t __riscv_vasub_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                    vint32m2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint32m2_t __riscv_vasub_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                    vint64m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m1_t __riscv_vasub_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                    vint64m2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m2_t __riscv_vasub_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                    vint64m4_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m4_t __riscv_vasub_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                      vuint8mf8_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf8_t __riscv_vaaddu_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                      uint8_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf4_t __riscv_vaaddu_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                      vuint8mf4_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf4_t __riscv_vaaddu_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                      uint8_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf2_t __riscv_vaaddu_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                      vuint8mf2_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf2_t __riscv_vaaddu_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                      uint8_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint8m1_t __riscv_vaaddu_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint16mf4_t vs1, unsigned int vxrm,
                                        size_t vl);
vuint16mf4_t __riscv_vaaddu_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint16_t rs1, unsigned int vxrm,
                                        size_t vl);
vuint16mf2_t __riscv_vaaddu_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        vuint16mf2_t vs1, unsigned int vxrm,
                                        size_t vl);
vuint16mf2_t __riscv_vaaddu_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        uint16_t rs1, unsigned int vxrm,
                                        size_t vl);
vuint16m1_t __riscv_vaaddu_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      vuint16m1_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint16m1_t __riscv_vaaddu_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      uint16_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint16m2_t __riscv_vaaddu_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint16m2_t __riscv_vaaddu_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint16m4_t __riscv_vaaddu_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint16m4_t __riscv_vaaddu_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint16m8_t __riscv_vaaddu_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint16m8_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint16m8_t __riscv_vaaddu_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      uint16_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint32mf2_t __riscv_vaaddu_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        vuint32mf2_t vs1, unsigned int vxrm,
                                        size_t vl);
vuint32mf2_t __riscv_vaaddu_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        uint32_t rs1, unsigned int vxrm,
                                        size_t vl);
vuint32m1_t __riscv_vaaddu_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      vuint32m1_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint32m1_t __riscv_vaaddu_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      uint32_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint32m2_t __riscv_vaaddu_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      vuint32m2_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint32m2_t __riscv_vaaddu_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      uint32_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint32m4_t __riscv_vaaddu_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint32m4_t __riscv_vaaddu_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint32m8_t __riscv_vaaddu_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint32m8_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint32m8_t __riscv_vaaddu_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint32_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint64m1_t __riscv_vaaddu_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      vuint64m1_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint64m1_t __riscv_vaaddu_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      uint64_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint64m2_t __riscv_vaaddu_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      vuint64m2_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint64m2_t __riscv_vaaddu_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      uint64_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint64m4_t __riscv_vaaddu_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      vuint64m4_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint64m4_t __riscv_vaaddu_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      uint64_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint64m8_t __riscv_vaaddu_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint64m8_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint64m8_t __riscv_vaaddu_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint64_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf8_t __riscv_vasubu_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                      vuint8mf8_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf8_t __riscv_vasubu_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                      uint8_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf4_t __riscv_vasubu_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                      vuint8mf4_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf4_t __riscv_vasubu_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                      uint8_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf2_t __riscv_vasubu_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                      vuint8mf2_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint8mf2_t __riscv_vasubu_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                      uint8_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint8m1_t __riscv_vasubu_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        vuint16mf4_t vs1, unsigned int vxrm,
                                        size_t vl);
vuint16mf4_t __riscv_vasubu_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                        uint16_t rs1, unsigned int vxrm,
                                        size_t vl);
vuint16mf2_t __riscv_vasubu_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        vuint16mf2_t vs1, unsigned int vxrm,
                                        size_t vl);
vuint16mf2_t __riscv_vasubu_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                        uint16_t rs1, unsigned int vxrm,
                                        size_t vl);
vuint16m1_t __riscv_vasubu_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      vuint16m1_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint16m1_t __riscv_vasubu_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                      uint16_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint16m2_t __riscv_vasubu_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      vuint16m2_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint16m2_t __riscv_vasubu_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                      uint16_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint16m4_t __riscv_vasubu_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      vuint16m4_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint16m4_t __riscv_vasubu_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                      uint16_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint16m8_t __riscv_vasubu_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      vuint16m8_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint16m8_t __riscv_vasubu_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                      uint16_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint32mf2_t __riscv_vasubu_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        vuint32mf2_t vs1, unsigned int vxrm,
                                        size_t vl);
vuint32mf2_t __riscv_vasubu_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                        uint32_t rs1, unsigned int vxrm,
                                        size_t vl);
vuint32m1_t __riscv_vasubu_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      vuint32m1_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint32m1_t __riscv_vasubu_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                      uint32_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint32m2_t __riscv_vasubu_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      vuint32m2_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint32m2_t __riscv_vasubu_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                      uint32_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint32m4_t __riscv_vasubu_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      vuint32m4_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint32m4_t __riscv_vasubu_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                      uint32_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint32m8_t __riscv_vasubu_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      vuint32m8_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint32m8_t __riscv_vasubu_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                      uint32_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint64m1_t __riscv_vasubu_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      vuint64m1_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint64m1_t __riscv_vasubu_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                      uint64_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint64m2_t __riscv_vasubu_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      vuint64m2_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint64m2_t __riscv_vasubu_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                      uint64_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint64m4_t __riscv_vasubu_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      vuint64m4_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint64m4_t __riscv_vasubu_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                      uint64_t rs1, unsigned int vxrm,
                                      size_t vl);
vuint64m8_t __riscv_vasubu_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      vuint64m8_t vs1, unsigned int vxrm,
                                      size_t vl);
vuint64m8_t __riscv_vasubu_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                      uint64_t rs1, unsigned int vxrm,
                                      size_t vl);
----

[[vector-single-width-fractional-multiply-with-rounding-and-saturation]]
==== Vector Single-Width Fractional Multiply with Rounding and SaturationIntrinsics
After executing an intrinsic in this section, the `vxsat` CSR assumes an UNSPECIFIED value.

[,c]
----
vint8mf8_t __riscv_vsmul_vv_i8mf8(vint8mf8_t vs2, vint8mf8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vsmul_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8mf4_t __riscv_vsmul_vv_i8mf4(vint8mf4_t vs2, vint8mf4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8mf2_t __riscv_vsmul_vv_i8mf2(vint8mf2_t vs2, vint8mf2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8m1_t __riscv_vsmul_vv_i8m1(vint8m1_t vs2, vint8m1_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m1_t __riscv_vsmul_vx_i8m1(vint8m1_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m2_t __riscv_vsmul_vv_i8m2(vint8m2_t vs2, vint8m2_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m2_t __riscv_vsmul_vx_i8m2(vint8m2_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m4_t __riscv_vsmul_vv_i8m4(vint8m4_t vs2, vint8m4_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m4_t __riscv_vsmul_vx_i8m4(vint8m4_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m8_t __riscv_vsmul_vv_i8m8(vint8m8_t vs2, vint8m8_t vs1, unsigned int vxrm,
                                size_t vl);
vint8m8_t __riscv_vsmul_vx_i8m8(vint8m8_t vs2, int8_t rs1, unsigned int vxrm,
                                size_t vl);
vint16mf4_t __riscv_vsmul_vv_i16mf4(vint16mf4_t vs2, vint16mf4_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_vx_i16mf4(vint16mf4_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_vv_i16mf2(vint16mf2_t vs2, vint16mf2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_vx_i16mf2(vint16mf2_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_vv_i16m1(vint16m1_t vs2, vint16m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_vx_i16m1(vint16m1_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_vv_i16m2(vint16m2_t vs2, vint16m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_vx_i16m2(vint16m2_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_vv_i16m4(vint16m4_t vs2, vint16m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_vx_i16m4(vint16m4_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_vv_i16m8(vint16m8_t vs2, vint16m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_vx_i16m8(vint16m8_t vs2, int16_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_vv_i32mf2(vint32mf2_t vs2, vint32mf2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_vx_i32mf2(vint32mf2_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_vv_i32m1(vint32m1_t vs2, vint32m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_vx_i32m1(vint32m1_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_vv_i32m2(vint32m2_t vs2, vint32m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_vx_i32m2(vint32m2_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_vv_i32m4(vint32m4_t vs2, vint32m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_vx_i32m4(vint32m4_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_vv_i32m8(vint32m8_t vs2, vint32m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_vx_i32m8(vint32m8_t vs2, int32_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_vv_i64m1(vint64m1_t vs2, vint64m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_vx_i64m1(vint64m1_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_vv_i64m2(vint64m2_t vs2, vint64m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_vx_i64m2(vint64m2_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_vv_i64m4(vint64m4_t vs2, vint64m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_vx_i64m4(vint64m4_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_vv_i64m8(vint64m8_t vs2, vint64m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_vx_i64m8(vint64m8_t vs2, int64_t rs1,
                                  unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vsmul_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                    vint8mf8_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf8_t __riscv_vsmul_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                    vint8mf4_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf4_t __riscv_vsmul_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                    vint8mf2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf2_t __riscv_vsmul_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      vint16mf4_t vs1, unsigned int vxrm,
                                      size_t vl);
vint16mf4_t __riscv_vsmul_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      int16_t rs1, unsigned int vxrm,
                                      size_t vl);
vint16mf2_t __riscv_vsmul_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      vint16mf2_t vs1, unsigned int vxrm,
                                      size_t vl);
vint16mf2_t __riscv_vsmul_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      int16_t rs1, unsigned int vxrm,
                                      size_t vl);
vint16m1_t __riscv_vsmul_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                    vint16m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint16m1_t __riscv_vsmul_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, int16_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      vint32mf2_t vs1, unsigned int vxrm,
                                      size_t vl);
vint32mf2_t __riscv_vsmul_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      int32_t rs1, unsigned int vxrm,
                                      size_t vl);
vint32m1_t __riscv_vsmul_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                    vint32m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint32m1_t __riscv_vsmul_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                    vint32m2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint32m2_t __riscv_vsmul_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                                    unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, int32_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                    vint64m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m1_t __riscv_vsmul_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                    vint64m2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m2_t __riscv_vsmul_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                    vint64m4_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m4_t __riscv_vsmul_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                                    unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, int64_t rs1,
                                    unsigned int vxrm, size_t vl);
----

[[vector-single-width-scaling-shift]]
==== Vector Single-Width Scaling Shift Intrinsics

[,c]
----
vint8mf8_t __riscv_vssra_vv_i8mf8(vint8mf8_t vs2, vuint8mf8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vssra_vx_i8mf8(vint8mf8_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8mf4_t __riscv_vssra_vv_i8mf4(vint8mf4_t vs2, vuint8mf4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_vx_i8mf4(vint8mf4_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8mf2_t __riscv_vssra_vv_i8mf2(vint8mf2_t vs2, vuint8mf2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_vx_i8mf2(vint8mf2_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint8m1_t __riscv_vssra_vv_i8m1(vint8m1_t vs2, vuint8m1_t vs1,
                                unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_vx_i8m1(vint8m1_t vs2, size_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m2_t __riscv_vssra_vv_i8m2(vint8m2_t vs2, vuint8m2_t vs1,
                                unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_vx_i8m2(vint8m2_t vs2, size_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m4_t __riscv_vssra_vv_i8m4(vint8m4_t vs2, vuint8m4_t vs1,
                                unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_vx_i8m4(vint8m4_t vs2, size_t rs1, unsigned int vxrm,
                                size_t vl);
vint8m8_t __riscv_vssra_vv_i8m8(vint8m8_t vs2, vuint8m8_t vs1,
                                unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_vx_i8m8(vint8m8_t vs2, size_t rs1, unsigned int vxrm,
                                size_t vl);
vint16mf4_t __riscv_vssra_vv_i16mf4(vint16mf4_t vs2, vuint16mf4_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_vx_i16mf4(vint16mf4_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_vv_i16mf2(vint16mf2_t vs2, vuint16mf2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_vx_i16mf2(vint16mf2_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_vv_i16m1(vint16m1_t vs2, vuint16m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_vx_i16m1(vint16m1_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint16m2_t __riscv_vssra_vv_i16m2(vint16m2_t vs2, vuint16m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_vx_i16m2(vint16m2_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint16m4_t __riscv_vssra_vv_i16m4(vint16m4_t vs2, vuint16m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_vx_i16m4(vint16m4_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint16m8_t __riscv_vssra_vv_i16m8(vint16m8_t vs2, vuint16m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_vx_i16m8(vint16m8_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint32mf2_t __riscv_vssra_vv_i32mf2(vint32mf2_t vs2, vuint32mf2_t vs1,
                                    unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_vx_i32mf2(vint32mf2_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_vv_i32m1(vint32m1_t vs2, vuint32m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_vx_i32m1(vint32m1_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint32m2_t __riscv_vssra_vv_i32m2(vint32m2_t vs2, vuint32m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_vx_i32m2(vint32m2_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint32m4_t __riscv_vssra_vv_i32m4(vint32m4_t vs2, vuint32m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_vx_i32m4(vint32m4_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint32m8_t __riscv_vssra_vv_i32m8(vint32m8_t vs2, vuint32m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_vx_i32m8(vint32m8_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint64m1_t __riscv_vssra_vv_i64m1(vint64m1_t vs2, vuint64m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_vx_i64m1(vint64m1_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint64m2_t __riscv_vssra_vv_i64m2(vint64m2_t vs2, vuint64m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_vx_i64m2(vint64m2_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint64m4_t __riscv_vssra_vv_i64m4(vint64m4_t vs2, vuint64m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_vx_i64m4(vint64m4_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vint64m8_t __riscv_vssra_vv_i64m8(vint64m8_t vs2, vuint64m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_vx_i64m8(vint64m8_t vs2, size_t rs1, unsigned int vxrm,
                                  size_t vl);
vuint8mf8_t __riscv_vssrl_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_vx_u8mf8(vuint8mf8_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_vx_u8mf4(vuint8mf4_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_vx_u8mf2(vuint8mf2_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1,
                                 unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_vx_u8m1(vuint8m1_t vs2, size_t rs1, unsigned int vxrm,
                                 size_t vl);
vuint8m2_t __riscv_vssrl_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1,
                                 unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_vx_u8m2(vuint8m2_t vs2, size_t rs1, unsigned int vxrm,
                                 size_t vl);
vuint8m4_t __riscv_vssrl_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1,
                                 unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_vx_u8m4(vuint8m4_t vs2, size_t rs1, unsigned int vxrm,
                                 size_t vl);
vuint8m8_t __riscv_vssrl_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1,
                                 unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_vx_u8m8(vuint8m8_t vs2, size_t rs1, unsigned int vxrm,
                                 size_t vl);
vuint16mf4_t __riscv_vssrl_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_vx_u16mf4(vuint16mf4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_vx_u16mf2(vuint16mf2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_vx_u16m1(vuint16m1_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_vx_u16m2(vuint16m2_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_vx_u16m4(vuint16m4_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_vx_u16m8(vuint16m8_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_vx_u32mf2(vuint32mf2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_vx_u32m1(vuint32m1_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_vx_u32m2(vuint32m2_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_vx_u32m4(vuint32m4_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_vx_u32m8(vuint32m8_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_vx_u64m1(vuint64m1_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_vx_u64m2(vuint64m2_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_vx_u64m4(vuint64m4_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_vx_u64m8(vuint64m8_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vssra_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                    vuint8mf8_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf8_t __riscv_vssra_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                    vuint8mf4_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf4_t __riscv_vssra_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                    vuint8mf2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint8mf2_t __riscv_vssra_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vuint8m1_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, size_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vuint8m2_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, size_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vuint8m4_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, size_t rs1,
                                  unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vuint8m8_t vs1,
                                  unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, size_t rs1,
                                  unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                      vuint16mf4_t vs1, unsigned int vxrm,
                                      size_t vl);
vint16mf4_t __riscv_vssra_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2, size_t rs1,
                                      unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                      vuint16mf2_t vs1, unsigned int vxrm,
                                      size_t vl);
vint16mf2_t __riscv_vssra_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2, size_t rs1,
                                      unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                    vuint16m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint16m1_t __riscv_vssra_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2,
                                    vuint16m2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint16m2_t __riscv_vssra_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2,
                                    vuint16m4_t vs1, unsigned int vxrm,
                                    size_t vl);
vint16m4_t __riscv_vssra_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2,
                                    vuint16m8_t vs1, unsigned int vxrm,
                                    size_t vl);
vint16m8_t __riscv_vssra_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                      vuint32mf2_t vs1, unsigned int vxrm,
                                      size_t vl);
vint32mf2_t __riscv_vssra_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2, size_t rs1,
                                      unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                    vuint32m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint32m1_t __riscv_vssra_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                    vuint32m2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint32m2_t __riscv_vssra_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2,
                                    vuint32m4_t vs1, unsigned int vxrm,
                                    size_t vl);
vint32m4_t __riscv_vssra_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2,
                                    vuint32m8_t vs1, unsigned int vxrm,
                                    size_t vl);
vint32m8_t __riscv_vssra_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                    vuint64m1_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m1_t __riscv_vssra_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                    vuint64m2_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m2_t __riscv_vssra_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                    vuint64m4_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m4_t __riscv_vssra_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2,
                                    vuint64m8_t vs1, unsigned int vxrm,
                                    size_t vl);
vint64m8_t __riscv_vssra_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, size_t rs1,
                                    unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                     vuint8mf8_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint8mf8_t __riscv_vssrl_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                     vuint8mf4_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint8mf4_t __riscv_vssrl_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                     vuint8mf2_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint8mf2_t __riscv_vssrl_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       vuint16mf4_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint16mf4_t __riscv_vssrl_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                       size_t rs1, unsigned int vxrm,
                                       size_t vl);
vuint16mf2_t __riscv_vssrl_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       vuint16mf2_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint16mf2_t __riscv_vssrl_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                       size_t rs1, unsigned int vxrm,
                                       size_t vl);
vuint16m1_t __riscv_vssrl_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                     vuint16m1_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint16m1_t __riscv_vssrl_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                     vuint16m2_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint16m2_t __riscv_vssrl_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                     vuint16m4_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint16m4_t __riscv_vssrl_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                     vuint16m8_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint16m8_t __riscv_vssrl_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       vuint32mf2_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint32mf2_t __riscv_vssrl_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                       size_t rs1, unsigned int vxrm,
                                       size_t vl);
vuint32m1_t __riscv_vssrl_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                     vuint32m1_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint32m1_t __riscv_vssrl_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                     vuint32m2_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint32m2_t __riscv_vssrl_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                     vuint32m4_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint32m4_t __riscv_vssrl_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                     vuint32m8_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint32m8_t __riscv_vssrl_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                     vuint64m1_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint64m1_t __riscv_vssrl_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                     vuint64m2_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint64m2_t __riscv_vssrl_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                     vuint64m4_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint64m4_t __riscv_vssrl_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                     vuint64m8_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint64m8_t __riscv_vssrl_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
----

[[vector-narrowing-fixed-point-clip]]
==== Vector Narrowing Fixed-Point Clip Intrinsics
After executing an intrinsic in this section, the `vxsat` CSR assumes an UNSPECIFIED value.

[,c]
----
vint8mf8_t __riscv_vnclip_wv_i8mf8(vint16mf4_t vs2, vuint8mf8_t vs1,
                                   unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vnclip_wx_i8mf8(vint16mf4_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_wv_i8mf4(vint16mf2_t vs2, vuint8mf4_t vs1,
                                   unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_wx_i8mf4(vint16mf2_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_wv_i8mf2(vint16m1_t vs2, vuint8mf2_t vs1,
                                   unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_wx_i8mf2(vint16m1_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_wv_i8m1(vint16m2_t vs2, vuint8m1_t vs1,
                                 unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_wx_i8m1(vint16m2_t vs2, size_t rs1, unsigned int vxrm,
                                 size_t vl);
vint8m2_t __riscv_vnclip_wv_i8m2(vint16m4_t vs2, vuint8m2_t vs1,
                                 unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_wx_i8m2(vint16m4_t vs2, size_t rs1, unsigned int vxrm,
                                 size_t vl);
vint8m4_t __riscv_vnclip_wv_i8m4(vint16m8_t vs2, vuint8m4_t vs1,
                                 unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_wx_i8m4(vint16m8_t vs2, size_t rs1, unsigned int vxrm,
                                 size_t vl);
vint16mf4_t __riscv_vnclip_wv_i16mf4(vint32mf2_t vs2, vuint16mf4_t vs1,
                                     unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_wx_i16mf4(vint32mf2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_wv_i16mf2(vint32m1_t vs2, vuint16mf2_t vs1,
                                     unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_wx_i16mf2(vint32m1_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_wv_i16m1(vint32m2_t vs2, vuint16m1_t vs1,
                                   unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_wx_i16m1(vint32m2_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_wv_i16m2(vint32m4_t vs2, vuint16m2_t vs1,
                                   unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_wx_i16m2(vint32m4_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_wv_i16m4(vint32m8_t vs2, vuint16m4_t vs1,
                                   unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_wx_i16m4(vint32m8_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_wv_i32mf2(vint64m1_t vs2, vuint32mf2_t vs1,
                                     unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_wx_i32mf2(vint64m1_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_wv_i32m1(vint64m2_t vs2, vuint32m1_t vs1,
                                   unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_wx_i32m1(vint64m2_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_wv_i32m2(vint64m4_t vs2, vuint32m2_t vs1,
                                   unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_wx_i32m2(vint64m4_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_wv_i32m4(vint64m8_t vs2, vuint32m4_t vs1,
                                   unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_wx_i32m4(vint64m8_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_wv_u8mf8(vuint16mf4_t vs2, vuint8mf8_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_wx_u8mf8(vuint16mf4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_wv_u8mf4(vuint16mf2_t vs2, vuint8mf4_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_wx_u8mf4(vuint16mf2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_wv_u8mf2(vuint16m1_t vs2, vuint8mf2_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_wx_u8mf2(vuint16m1_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_wv_u8m1(vuint16m2_t vs2, vuint8m1_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_wx_u8m1(vuint16m2_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_wv_u8m2(vuint16m4_t vs2, vuint8m2_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_wx_u8m2(vuint16m4_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_wv_u8m4(vuint16m8_t vs2, vuint8m4_t vs1,
                                   unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_wx_u8m4(vuint16m8_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_wv_u16mf4(vuint32mf2_t vs2, vuint16mf4_t vs1,
                                       unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_wx_u16mf4(vuint32mf2_t vs2, size_t rs1,
                                       unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_wv_u16mf2(vuint32m1_t vs2, vuint16mf2_t vs1,
                                       unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_wx_u16mf2(vuint32m1_t vs2, size_t rs1,
                                       unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_wv_u16m1(vuint32m2_t vs2, vuint16m1_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_wx_u16m1(vuint32m2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_wv_u16m2(vuint32m4_t vs2, vuint16m2_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_wx_u16m2(vuint32m4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_wv_u16m4(vuint32m8_t vs2, vuint16m4_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_wx_u16m4(vuint32m8_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_wv_u32mf2(vuint64m1_t vs2, vuint32mf2_t vs1,
                                       unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_wx_u32mf2(vuint64m1_t vs2, size_t rs1,
                                       unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_wv_u32m1(vuint64m2_t vs2, vuint32m1_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_wx_u32m1(vuint64m2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_wv_u32m2(vuint64m4_t vs2, vuint32m2_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_wx_u32m2(vuint64m4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_wv_u32m4(vuint64m8_t vs2, vuint32m4_t vs1,
                                     unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_wx_u32m4(vuint64m8_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vnclip_wv_i8mf8_m(vbool64_t vm, vint16mf4_t vs2,
                                     vuint8mf8_t vs1, unsigned int vxrm,
                                     size_t vl);
vint8mf8_t __riscv_vnclip_wx_i8mf8_m(vbool64_t vm, vint16mf4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_wv_i8mf4_m(vbool32_t vm, vint16mf2_t vs2,
                                     vuint8mf4_t vs1, unsigned int vxrm,
                                     size_t vl);
vint8mf4_t __riscv_vnclip_wx_i8mf4_m(vbool32_t vm, vint16mf2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_wv_i8mf2_m(vbool16_t vm, vint16m1_t vs2,
                                     vuint8mf2_t vs1, unsigned int vxrm,
                                     size_t vl);
vint8mf2_t __riscv_vnclip_wx_i8mf2_m(vbool16_t vm, vint16m1_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_wv_i8m1_m(vbool8_t vm, vint16m2_t vs2, vuint8m1_t vs1,
                                   unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_wx_i8m1_m(vbool8_t vm, vint16m2_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_wv_i8m2_m(vbool4_t vm, vint16m4_t vs2, vuint8m2_t vs1,
                                   unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_wx_i8m2_m(vbool4_t vm, vint16m4_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_wv_i8m4_m(vbool2_t vm, vint16m8_t vs2, vuint8m4_t vs1,
                                   unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_wx_i8m4_m(vbool2_t vm, vint16m8_t vs2, size_t rs1,
                                   unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_wv_i16mf4_m(vbool64_t vm, vint32mf2_t vs2,
                                       vuint16mf4_t vs1, unsigned int vxrm,
                                       size_t vl);
vint16mf4_t __riscv_vnclip_wx_i16mf4_m(vbool64_t vm, vint32mf2_t vs2,
                                       size_t rs1, unsigned int vxrm,
                                       size_t vl);
vint16mf2_t __riscv_vnclip_wv_i16mf2_m(vbool32_t vm, vint32m1_t vs2,
                                       vuint16mf2_t vs1, unsigned int vxrm,
                                       size_t vl);
vint16mf2_t __riscv_vnclip_wx_i16mf2_m(vbool32_t vm, vint32m1_t vs2, size_t rs1,
                                       unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_wv_i16m1_m(vbool16_t vm, vint32m2_t vs2,
                                     vuint16m1_t vs1, unsigned int vxrm,
                                     size_t vl);
vint16m1_t __riscv_vnclip_wx_i16m1_m(vbool16_t vm, vint32m2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_wv_i16m2_m(vbool8_t vm, vint32m4_t vs2,
                                     vuint16m2_t vs1, unsigned int vxrm,
                                     size_t vl);
vint16m2_t __riscv_vnclip_wx_i16m2_m(vbool8_t vm, vint32m4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_wv_i16m4_m(vbool4_t vm, vint32m8_t vs2,
                                     vuint16m4_t vs1, unsigned int vxrm,
                                     size_t vl);
vint16m4_t __riscv_vnclip_wx_i16m4_m(vbool4_t vm, vint32m8_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_wv_i32mf2_m(vbool64_t vm, vint64m1_t vs2,
                                       vuint32mf2_t vs1, unsigned int vxrm,
                                       size_t vl);
vint32mf2_t __riscv_vnclip_wx_i32mf2_m(vbool64_t vm, vint64m1_t vs2, size_t rs1,
                                       unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_wv_i32m1_m(vbool32_t vm, vint64m2_t vs2,
                                     vuint32m1_t vs1, unsigned int vxrm,
                                     size_t vl);
vint32m1_t __riscv_vnclip_wx_i32m1_m(vbool32_t vm, vint64m2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_wv_i32m2_m(vbool16_t vm, vint64m4_t vs2,
                                     vuint32m2_t vs1, unsigned int vxrm,
                                     size_t vl);
vint32m2_t __riscv_vnclip_wx_i32m2_m(vbool16_t vm, vint64m4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_wv_i32m4_m(vbool8_t vm, vint64m8_t vs2,
                                     vuint32m4_t vs1, unsigned int vxrm,
                                     size_t vl);
vint32m4_t __riscv_vnclip_wx_i32m4_m(vbool8_t vm, vint64m8_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_wv_u8mf8_m(vbool64_t vm, vuint16mf4_t vs2,
                                       vuint8mf8_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint8mf8_t __riscv_vnclipu_wx_u8mf8_m(vbool64_t vm, vuint16mf4_t vs2,
                                       size_t rs1, unsigned int vxrm,
                                       size_t vl);
vuint8mf4_t __riscv_vnclipu_wv_u8mf4_m(vbool32_t vm, vuint16mf2_t vs2,
                                       vuint8mf4_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint8mf4_t __riscv_vnclipu_wx_u8mf4_m(vbool32_t vm, vuint16mf2_t vs2,
                                       size_t rs1, unsigned int vxrm,
                                       size_t vl);
vuint8mf2_t __riscv_vnclipu_wv_u8mf2_m(vbool16_t vm, vuint16m1_t vs2,
                                       vuint8mf2_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint8mf2_t __riscv_vnclipu_wx_u8mf2_m(vbool16_t vm, vuint16m1_t vs2,
                                       size_t rs1, unsigned int vxrm,
                                       size_t vl);
vuint8m1_t __riscv_vnclipu_wv_u8m1_m(vbool8_t vm, vuint16m2_t vs2,
                                     vuint8m1_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint8m1_t __riscv_vnclipu_wx_u8m1_m(vbool8_t vm, vuint16m2_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_wv_u8m2_m(vbool4_t vm, vuint16m4_t vs2,
                                     vuint8m2_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint8m2_t __riscv_vnclipu_wx_u8m2_m(vbool4_t vm, vuint16m4_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_wv_u8m4_m(vbool2_t vm, vuint16m8_t vs2,
                                     vuint8m4_t vs1, unsigned int vxrm,
                                     size_t vl);
vuint8m4_t __riscv_vnclipu_wx_u8m4_m(vbool2_t vm, vuint16m8_t vs2, size_t rs1,
                                     unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_wv_u16mf4_m(vbool64_t vm, vuint32mf2_t vs2,
                                         vuint16mf4_t vs1, unsigned int vxrm,
                                         size_t vl);
vuint16mf4_t __riscv_vnclipu_wx_u16mf4_m(vbool64_t vm, vuint32mf2_t vs2,
                                         size_t rs1, unsigned int vxrm,
                                         size_t vl);
vuint16mf2_t __riscv_vnclipu_wv_u16mf2_m(vbool32_t vm, vuint32m1_t vs2,
                                         vuint16mf2_t vs1, unsigned int vxrm,
                                         size_t vl);
vuint16mf2_t __riscv_vnclipu_wx_u16mf2_m(vbool32_t vm, vuint32m1_t vs2,
                                         size_t rs1, unsigned int vxrm,
                                         size_t vl);
vuint16m1_t __riscv_vnclipu_wv_u16m1_m(vbool16_t vm, vuint32m2_t vs2,
                                       vuint16m1_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint16m1_t __riscv_vnclipu_wx_u16m1_m(vbool16_t vm, vuint32m2_t vs2,
                                       size_t rs1, unsigned int vxrm,
                                       size_t vl);
vuint16m2_t __riscv_vnclipu_wv_u16m2_m(vbool8_t vm, vuint32m4_t vs2,
                                       vuint16m2_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint16m2_t __riscv_vnclipu_wx_u16m2_m(vbool8_t vm, vuint32m4_t vs2, size_t rs1,
                                       unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_wv_u16m4_m(vbool4_t vm, vuint32m8_t vs2,
                                       vuint16m4_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint16m4_t __riscv_vnclipu_wx_u16m4_m(vbool4_t vm, vuint32m8_t vs2, size_t rs1,
                                       unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_wv_u32mf2_m(vbool64_t vm, vuint64m1_t vs2,
                                         vuint32mf2_t vs1, unsigned int vxrm,
                                         size_t vl);
vuint32mf2_t __riscv_vnclipu_wx_u32mf2_m(vbool64_t vm, vuint64m1_t vs2,
                                         size_t rs1, unsigned int vxrm,
                                         size_t vl);
vuint32m1_t __riscv_vnclipu_wv_u32m1_m(vbool32_t vm, vuint64m2_t vs2,
                                       vuint32m1_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint32m1_t __riscv_vnclipu_wx_u32m1_m(vbool32_t vm, vuint64m2_t vs2,
                                       size_t rs1, unsigned int vxrm,
                                       size_t vl);
vuint32m2_t __riscv_vnclipu_wv_u32m2_m(vbool16_t vm, vuint64m4_t vs2,
                                       vuint32m2_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint32m2_t __riscv_vnclipu_wx_u32m2_m(vbool16_t vm, vuint64m4_t vs2,
                                       size_t rs1, unsigned int vxrm,
                                       size_t vl);
vuint32m4_t __riscv_vnclipu_wv_u32m4_m(vbool8_t vm, vuint64m8_t vs2,
                                       vuint32m4_t vs1, unsigned int vxrm,
                                       size_t vl);
vuint32m4_t __riscv_vnclipu_wx_u32m4_m(vbool8_t vm, vuint64m8_t vs2, size_t rs1,
                                       unsigned int vxrm, size_t vl);
----

=== Vector Floating-Point Intrinsics

[[vector-single-width-floating-point-add-subtract]]
==== Vector Single-Width Floating-Point Add/Subtract Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfadd_vv_f16mf4(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfadd_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfadd_vv_f16mf2(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfadd_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m1_t __riscv_vfadd_vv_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                    size_t vl);
vfloat16m1_t __riscv_vfadd_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfadd_vv_f16m2(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                    size_t vl);
vfloat16m2_t __riscv_vfadd_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfadd_vv_f16m4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                    size_t vl);
vfloat16m4_t __riscv_vfadd_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfadd_vv_f16m8(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                    size_t vl);
vfloat16m8_t __riscv_vfadd_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfadd_vv_f32mf2(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vfloat32mf2_t __riscv_vfadd_vf_f32mf2(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat32m1_t __riscv_vfadd_vv_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                    size_t vl);
vfloat32m1_t __riscv_vfadd_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfadd_vv_f32m2(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                    size_t vl);
vfloat32m2_t __riscv_vfadd_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfadd_vv_f32m4(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                    size_t vl);
vfloat32m4_t __riscv_vfadd_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfadd_vv_f32m8(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                    size_t vl);
vfloat32m8_t __riscv_vfadd_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfadd_vv_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                    size_t vl);
vfloat64m1_t __riscv_vfadd_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfadd_vv_f64m2(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                    size_t vl);
vfloat64m2_t __riscv_vfadd_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfadd_vv_f64m4(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                    size_t vl);
vfloat64m4_t __riscv_vfadd_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfadd_vv_f64m8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                    size_t vl);
vfloat64m8_t __riscv_vfadd_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
vfloat16mf4_t __riscv_vfsub_vv_f16mf4(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfsub_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfsub_vv_f16mf2(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfsub_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m1_t __riscv_vfsub_vv_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                    size_t vl);
vfloat16m1_t __riscv_vfsub_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfsub_vv_f16m2(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                    size_t vl);
vfloat16m2_t __riscv_vfsub_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfsub_vv_f16m4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                    size_t vl);
vfloat16m4_t __riscv_vfsub_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfsub_vv_f16m8(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                    size_t vl);
vfloat16m8_t __riscv_vfsub_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfsub_vv_f32mf2(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vfloat32mf2_t __riscv_vfsub_vf_f32mf2(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat32m1_t __riscv_vfsub_vv_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                    size_t vl);
vfloat32m1_t __riscv_vfsub_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfsub_vv_f32m2(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                    size_t vl);
vfloat32m2_t __riscv_vfsub_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfsub_vv_f32m4(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                    size_t vl);
vfloat32m4_t __riscv_vfsub_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfsub_vv_f32m8(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                    size_t vl);
vfloat32m8_t __riscv_vfsub_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfsub_vv_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                    size_t vl);
vfloat64m1_t __riscv_vfsub_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfsub_vv_f64m2(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                    size_t vl);
vfloat64m2_t __riscv_vfsub_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfsub_vv_f64m4(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                    size_t vl);
vfloat64m4_t __riscv_vfsub_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfsub_vv_f64m8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                    size_t vl);
vfloat64m8_t __riscv_vfsub_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
vfloat16mf4_t __riscv_vfrsub_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat16mf2_t __riscv_vfrsub_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat16m1_t __riscv_vfrsub_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfrsub_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfrsub_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfrsub_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfrsub_vf_f32mf2(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat32m1_t __riscv_vfrsub_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfrsub_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfrsub_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfrsub_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfrsub_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfrsub_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfrsub_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfrsub_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
vfloat16mf4_t __riscv_vfneg_v_f16mf4(vfloat16mf4_t vs, size_t vl);
vfloat16mf2_t __riscv_vfneg_v_f16mf2(vfloat16mf2_t vs, size_t vl);
vfloat16m1_t __riscv_vfneg_v_f16m1(vfloat16m1_t vs, size_t vl);
vfloat16m2_t __riscv_vfneg_v_f16m2(vfloat16m2_t vs, size_t vl);
vfloat16m4_t __riscv_vfneg_v_f16m4(vfloat16m4_t vs, size_t vl);
vfloat16m8_t __riscv_vfneg_v_f16m8(vfloat16m8_t vs, size_t vl);
vfloat32mf2_t __riscv_vfneg_v_f32mf2(vfloat32mf2_t vs, size_t vl);
vfloat32m1_t __riscv_vfneg_v_f32m1(vfloat32m1_t vs, size_t vl);
vfloat32m2_t __riscv_vfneg_v_f32m2(vfloat32m2_t vs, size_t vl);
vfloat32m4_t __riscv_vfneg_v_f32m4(vfloat32m4_t vs, size_t vl);
vfloat32m8_t __riscv_vfneg_v_f32m8(vfloat32m8_t vs, size_t vl);
vfloat64m1_t __riscv_vfneg_v_f64m1(vfloat64m1_t vs, size_t vl);
vfloat64m2_t __riscv_vfneg_v_f64m2(vfloat64m2_t vs, size_t vl);
vfloat64m4_t __riscv_vfneg_v_f64m4(vfloat64m4_t vs, size_t vl);
vfloat64m8_t __riscv_vfneg_v_f64m8(vfloat64m8_t vs, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfadd_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vfadd_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfadd_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vfadd_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfadd_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfadd_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfadd_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      vfloat16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vfadd_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfadd_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      vfloat16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vfadd_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfadd_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      vfloat16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vfadd_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfadd_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfadd_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vfloat32m1_t __riscv_vfadd_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                      vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfadd_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2, float rs1,
                                      size_t vl);
vfloat32m2_t __riscv_vfadd_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                      vfloat32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vfadd_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2, float rs1,
                                      size_t vl);
vfloat32m4_t __riscv_vfadd_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                      vfloat32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vfadd_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                      size_t vl);
vfloat32m8_t __riscv_vfadd_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                      vfloat32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vfadd_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                      size_t vl);
vfloat64m1_t __riscv_vfadd_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfadd_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      double rs1, size_t vl);
vfloat64m2_t __riscv_vfadd_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      vfloat64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vfadd_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      double rs1, size_t vl);
vfloat64m4_t __riscv_vfadd_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      vfloat64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vfadd_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      double rs1, size_t vl);
vfloat64m8_t __riscv_vfadd_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                      vfloat64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vfadd_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfsub_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vfsub_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfsub_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vfsub_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfsub_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfsub_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfsub_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      vfloat16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vfsub_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfsub_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      vfloat16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vfsub_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfsub_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      vfloat16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vfsub_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfsub_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfsub_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vfloat32m1_t __riscv_vfsub_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                      vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfsub_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2, float rs1,
                                      size_t vl);
vfloat32m2_t __riscv_vfsub_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                      vfloat32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vfsub_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2, float rs1,
                                      size_t vl);
vfloat32m4_t __riscv_vfsub_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                      vfloat32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vfsub_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                      size_t vl);
vfloat32m8_t __riscv_vfsub_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                      vfloat32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vfsub_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                      size_t vl);
vfloat64m1_t __riscv_vfsub_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfsub_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      double rs1, size_t vl);
vfloat64m2_t __riscv_vfsub_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      vfloat64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vfsub_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      double rs1, size_t vl);
vfloat64m4_t __riscv_vfsub_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      vfloat64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vfsub_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      double rs1, size_t vl);
vfloat64m8_t __riscv_vfsub_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                      vfloat64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vfsub_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfrsub_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfrsub_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfrsub_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfrsub_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfrsub_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfrsub_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfrsub_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                         float rs1, size_t vl);
vfloat32m1_t __riscv_vfrsub_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vfloat32m2_t __riscv_vfrsub_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vfloat32m4_t __riscv_vfrsub_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                       size_t vl);
vfloat32m8_t __riscv_vfrsub_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                       size_t vl);
vfloat64m1_t __riscv_vfrsub_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                       double rs1, size_t vl);
vfloat64m2_t __riscv_vfrsub_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                       double rs1, size_t vl);
vfloat64m4_t __riscv_vfrsub_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                       double rs1, size_t vl);
vfloat64m8_t __riscv_vfrsub_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                       double rs1, size_t vl);
vfloat16mf4_t __riscv_vfneg_v_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs,
                                       size_t vl);
vfloat16mf2_t __riscv_vfneg_v_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs,
                                       size_t vl);
vfloat16m1_t __riscv_vfneg_v_f16m1_m(vbool16_t vm, vfloat16m1_t vs, size_t vl);
vfloat16m2_t __riscv_vfneg_v_f16m2_m(vbool8_t vm, vfloat16m2_t vs, size_t vl);
vfloat16m4_t __riscv_vfneg_v_f16m4_m(vbool4_t vm, vfloat16m4_t vs, size_t vl);
vfloat16m8_t __riscv_vfneg_v_f16m8_m(vbool2_t vm, vfloat16m8_t vs, size_t vl);
vfloat32mf2_t __riscv_vfneg_v_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs,
                                       size_t vl);
vfloat32m1_t __riscv_vfneg_v_f32m1_m(vbool32_t vm, vfloat32m1_t vs, size_t vl);
vfloat32m2_t __riscv_vfneg_v_f32m2_m(vbool16_t vm, vfloat32m2_t vs, size_t vl);
vfloat32m4_t __riscv_vfneg_v_f32m4_m(vbool8_t vm, vfloat32m4_t vs, size_t vl);
vfloat32m8_t __riscv_vfneg_v_f32m8_m(vbool4_t vm, vfloat32m8_t vs, size_t vl);
vfloat64m1_t __riscv_vfneg_v_f64m1_m(vbool64_t vm, vfloat64m1_t vs, size_t vl);
vfloat64m2_t __riscv_vfneg_v_f64m2_m(vbool32_t vm, vfloat64m2_t vs, size_t vl);
vfloat64m4_t __riscv_vfneg_v_f64m4_m(vbool16_t vm, vfloat64m4_t vs, size_t vl);
vfloat64m8_t __riscv_vfneg_v_f64m8_m(vbool8_t vm, vfloat64m8_t vs, size_t vl);
vfloat16mf4_t __riscv_vfadd_vv_f16mf4_rm(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                         unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfadd_vf_f16mf4_rm(vfloat16mf4_t vs2, _Float16 rs1,
                                         unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfadd_vv_f16mf2_rm(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                         unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfadd_vf_f16mf2_rm(vfloat16mf2_t vs2, _Float16 rs1,
                                         unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfadd_vv_f16m1_rm(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfadd_vf_f16m1_rm(vfloat16m1_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfadd_vv_f16m2_rm(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfadd_vf_f16m2_rm(vfloat16m2_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfadd_vv_f16m4_rm(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfadd_vf_f16m4_rm(vfloat16m4_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfadd_vv_f16m8_rm(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfadd_vf_f16m8_rm(vfloat16m8_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfadd_vv_f32mf2_rm(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                         unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfadd_vf_f32mf2_rm(vfloat32mf2_t vs2, float rs1,
                                         unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfadd_vv_f32m1_rm(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfadd_vf_f32m1_rm(vfloat32m1_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfadd_vv_f32m2_rm(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfadd_vf_f32m2_rm(vfloat32m2_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfadd_vv_f32m4_rm(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfadd_vf_f32m4_rm(vfloat32m4_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfadd_vv_f32m8_rm(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfadd_vf_f32m8_rm(vfloat32m8_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfadd_vv_f64m1_rm(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfadd_vf_f64m1_rm(vfloat64m1_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfadd_vv_f64m2_rm(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfadd_vf_f64m2_rm(vfloat64m2_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfadd_vv_f64m4_rm(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfadd_vf_f64m4_rm(vfloat64m4_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfadd_vv_f64m8_rm(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfadd_vf_f64m8_rm(vfloat64m8_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfsub_vv_f16mf4_rm(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                         unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfsub_vf_f16mf4_rm(vfloat16mf4_t vs2, _Float16 rs1,
                                         unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsub_vv_f16mf2_rm(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                         unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsub_vf_f16mf2_rm(vfloat16mf2_t vs2, _Float16 rs1,
                                         unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsub_vv_f16m1_rm(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsub_vf_f16m1_rm(vfloat16m1_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsub_vv_f16m2_rm(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsub_vf_f16m2_rm(vfloat16m2_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsub_vv_f16m4_rm(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsub_vf_f16m4_rm(vfloat16m4_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsub_vv_f16m8_rm(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsub_vf_f16m8_rm(vfloat16m8_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsub_vv_f32mf2_rm(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                         unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsub_vf_f32mf2_rm(vfloat32mf2_t vs2, float rs1,
                                         unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsub_vv_f32m1_rm(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsub_vf_f32m1_rm(vfloat32m1_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsub_vv_f32m2_rm(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsub_vf_f32m2_rm(vfloat32m2_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsub_vv_f32m4_rm(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsub_vf_f32m4_rm(vfloat32m4_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsub_vv_f32m8_rm(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsub_vf_f32m8_rm(vfloat32m8_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsub_vv_f64m1_rm(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsub_vf_f64m1_rm(vfloat64m1_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsub_vv_f64m2_rm(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsub_vf_f64m2_rm(vfloat64m2_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsub_vv_f64m4_rm(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsub_vf_f64m4_rm(vfloat64m4_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsub_vv_f64m8_rm(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsub_vf_f64m8_rm(vfloat64m8_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfrsub_vf_f16mf4_rm(vfloat16mf4_t vs2, _Float16 rs1,
                                          unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrsub_vf_f16mf2_rm(vfloat16mf2_t vs2, _Float16 rs1,
                                          unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrsub_vf_f16m1_rm(vfloat16m1_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrsub_vf_f16m2_rm(vfloat16m2_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrsub_vf_f16m4_rm(vfloat16m4_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrsub_vf_f16m8_rm(vfloat16m8_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrsub_vf_f32mf2_rm(vfloat32mf2_t vs2, float rs1,
                                          unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrsub_vf_f32m1_rm(vfloat32m1_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrsub_vf_f32m2_rm(vfloat32m2_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrsub_vf_f32m4_rm(vfloat32m4_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrsub_vf_f32m8_rm(vfloat32m8_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrsub_vf_f64m1_rm(vfloat64m1_t vs2, double rs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrsub_vf_f64m2_rm(vfloat64m2_t vs2, double rs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrsub_vf_f64m4_rm(vfloat64m4_t vs2, double rs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrsub_vf_f64m8_rm(vfloat64m8_t vs2, double rs1,
                                        unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfadd_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           vfloat16mf4_t vs1, unsigned int frm,
                                           size_t vl);
vfloat16mf4_t __riscv_vfadd_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           _Float16 rs1, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfadd_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           vfloat16mf2_t vs1, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfadd_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           _Float16 rs1, unsigned int frm,
                                           size_t vl);
vfloat16m1_t __riscv_vfadd_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                         vfloat16m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m1_t __riscv_vfadd_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfadd_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         vfloat16m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfadd_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfadd_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         vfloat16m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfadd_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfadd_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         vfloat16m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfadd_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat32mf2_t __riscv_vfadd_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           vfloat32mf2_t vs1, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfadd_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           float rs1, unsigned int frm,
                                           size_t vl);
vfloat32m1_t __riscv_vfadd_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                         vfloat32m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfadd_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfadd_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                         vfloat32m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfadd_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfadd_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                         vfloat32m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfadd_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfadd_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                         vfloat32m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfadd_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfadd_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                         vfloat64m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfadd_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfadd_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                         vfloat64m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfadd_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfadd_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                         vfloat64m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfadd_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfadd_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                         vfloat64m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfadd_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat16mf4_t __riscv_vfsub_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           vfloat16mf4_t vs1, unsigned int frm,
                                           size_t vl);
vfloat16mf4_t __riscv_vfsub_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           _Float16 rs1, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfsub_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           vfloat16mf2_t vs1, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfsub_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           _Float16 rs1, unsigned int frm,
                                           size_t vl);
vfloat16m1_t __riscv_vfsub_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                         vfloat16m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m1_t __riscv_vfsub_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfsub_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         vfloat16m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfsub_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfsub_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         vfloat16m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfsub_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfsub_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         vfloat16m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfsub_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat32mf2_t __riscv_vfsub_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           vfloat32mf2_t vs1, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfsub_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           float rs1, unsigned int frm,
                                           size_t vl);
vfloat32m1_t __riscv_vfsub_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                         vfloat32m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfsub_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfsub_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                         vfloat32m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfsub_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfsub_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                         vfloat32m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfsub_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfsub_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                         vfloat32m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfsub_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfsub_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                         vfloat64m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfsub_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfsub_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                         vfloat64m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfsub_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfsub_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                         vfloat64m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfsub_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfsub_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                         vfloat64m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfsub_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat16mf4_t __riscv_vfrsub_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            _Float16 rs1, unsigned int frm,
                                            size_t vl);
vfloat16mf2_t __riscv_vfrsub_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                            _Float16 rs1, unsigned int frm,
                                            size_t vl);
vfloat16m1_t __riscv_vfrsub_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat16m2_t __riscv_vfrsub_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat16m4_t __riscv_vfrsub_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat16m8_t __riscv_vfrsub_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32mf2_t __riscv_vfrsub_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            float rs1, unsigned int frm,
                                            size_t vl);
vfloat32m1_t __riscv_vfrsub_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfrsub_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfrsub_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfrsub_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfrsub_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                          double rs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfrsub_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                          double rs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfrsub_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                          double rs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfrsub_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                          double rs1, unsigned int frm,
                                          size_t vl);
----

[[vector-widening-floating-point-add-subtract]]
==== Vector Widening Floating-Point Add/Subtract Intrinsics

[,c]
----
vfloat32mf2_t __riscv_vfwadd_vv_f32mf2(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_f32mf2(vfloat16mf4_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_f32mf2(vfloat32mf2_t vs2, vfloat16mf4_t vs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_f32mf2(vfloat32mf2_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_f32m1(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                     size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_f32m1(vfloat16mf2_t vs2, _Float16 rs1,
                                     size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_f32m1(vfloat32m1_t vs2, vfloat16mf2_t vs1,
                                     size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_f32m1(vfloat32m1_t vs2, _Float16 rs1, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_f32m2(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_f32m2(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_f32m2(vfloat32m2_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_f32m2(vfloat32m2_t vs2, _Float16 rs1, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_f32m4(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                     size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_f32m4(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_f32m4(vfloat32m4_t vs2, vfloat16m2_t vs1,
                                     size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_f32m4(vfloat32m4_t vs2, _Float16 rs1, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_f32m8(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                     size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_f32m8(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_f32m8(vfloat32m8_t vs2, vfloat16m4_t vs1,
                                     size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_f32m8(vfloat32m8_t vs2, _Float16 rs1, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_f64m1(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                     size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_f64m1(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_f64m1(vfloat64m1_t vs2, vfloat32mf2_t vs1,
                                     size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_f64m1(vfloat64m1_t vs2, float rs1, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_f64m2(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_f64m2(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_f64m2(vfloat64m2_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_f64m2(vfloat64m2_t vs2, float rs1, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_f64m4(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_f64m4(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_f64m4(vfloat64m4_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_f64m4(vfloat64m4_t vs2, float rs1, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_f64m8(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                     size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_f64m8(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_f64m8(vfloat64m8_t vs2, vfloat32m4_t vs1,
                                     size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_f64m8(vfloat64m8_t vs2, float rs1, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_f32mf2(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_f32mf2(vfloat16mf4_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_f32mf2(vfloat32mf2_t vs2, vfloat16mf4_t vs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_f32mf2(vfloat32mf2_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_f32m1(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                     size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_f32m1(vfloat16mf2_t vs2, _Float16 rs1,
                                     size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_f32m1(vfloat32m1_t vs2, vfloat16mf2_t vs1,
                                     size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_f32m1(vfloat32m1_t vs2, _Float16 rs1, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_f32m2(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_f32m2(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_f32m2(vfloat32m2_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_f32m2(vfloat32m2_t vs2, _Float16 rs1, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_f32m4(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                     size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_f32m4(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_f32m4(vfloat32m4_t vs2, vfloat16m2_t vs1,
                                     size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_f32m4(vfloat32m4_t vs2, _Float16 rs1, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_f32m8(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                     size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_f32m8(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_f32m8(vfloat32m8_t vs2, vfloat16m4_t vs1,
                                     size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_f32m8(vfloat32m8_t vs2, _Float16 rs1, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_f64m1(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                     size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_f64m1(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_f64m1(vfloat64m1_t vs2, vfloat32mf2_t vs1,
                                     size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_f64m1(vfloat64m1_t vs2, float rs1, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_f64m2(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_f64m2(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_f64m2(vfloat64m2_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_f64m2(vfloat64m2_t vs2, float rs1, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_f64m4(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_f64m4(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_f64m4(vfloat64m4_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_f64m4(vfloat64m4_t vs2, float rs1, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_f64m8(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                     size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_f64m8(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_f64m8(vfloat64m8_t vs2, vfloat32m4_t vs1,
                                     size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_f64m8(vfloat64m8_t vs2, float rs1, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwadd_vv_f32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         vfloat16mf4_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_f32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                         vfloat16mf4_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_f32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                       vfloat16mf2_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_f32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat16mf2_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_f32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_f32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_f32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                       vfloat16m2_t vs1, size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_f32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                       vfloat16m2_t vs1, size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_f32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                       vfloat16m4_t vs1, size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_f32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                       vfloat16m4_t vs1, size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_f64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                       vfloat32mf2_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_f64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                       float rs1, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                       vfloat32mf2_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                       float rs1, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_f64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_f64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                       float rs1, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_f64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_f64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                       float rs1, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_f64m8_m(vbool8_t vm, vfloat32m4_t vs2,
                                       vfloat32m4_t vs1, size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_f64m8_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                       size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                       vfloat32m4_t vs1, size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, float rs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_f32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         vfloat16mf4_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_f32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                         vfloat16mf4_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_f32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                       vfloat16mf2_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_f32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat16mf2_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_f32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_f32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_f32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                       vfloat16m2_t vs1, size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_f32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                       vfloat16m2_t vs1, size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_f32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                       vfloat16m4_t vs1, size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_f32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                       vfloat16m4_t vs1, size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_f64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                       vfloat32mf2_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_f64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                       float rs1, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                       vfloat32mf2_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                       float rs1, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_f64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_f64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                       float rs1, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_f64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_f64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                       float rs1, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_f64m8_m(vbool8_t vm, vfloat32m4_t vs2,
                                       vfloat32m4_t vs1, size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_f64m8_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                       size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                       vfloat32m4_t vs1, size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, float rs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfwadd_vv_f32mf2_rm(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_f32mf2_rm(vfloat16mf4_t vs2, _Float16 rs1,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_f32mf2_rm(vfloat32mf2_t vs2, vfloat16mf4_t vs1,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_f32mf2_rm(vfloat32mf2_t vs2, _Float16 rs1,
                                          unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_f32m1_rm(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_f32m1_rm(vfloat16mf2_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_f32m1_rm(vfloat32m1_t vs2, vfloat16mf2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_f32m1_rm(vfloat32m1_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_f32m2_rm(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_f32m2_rm(vfloat16m1_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_f32m2_rm(vfloat32m2_t vs2, vfloat16m1_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_f32m2_rm(vfloat32m2_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_f32m4_rm(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_f32m4_rm(vfloat16m2_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_f32m4_rm(vfloat32m4_t vs2, vfloat16m2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_f32m4_rm(vfloat32m4_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_f32m8_rm(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_f32m8_rm(vfloat16m4_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_f32m8_rm(vfloat32m8_t vs2, vfloat16m4_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_f32m8_rm(vfloat32m8_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_f64m1_rm(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_f64m1_rm(vfloat32mf2_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_f64m1_rm(vfloat64m1_t vs2, vfloat32mf2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_f64m1_rm(vfloat64m1_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_f64m2_rm(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_f64m2_rm(vfloat32m1_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_f64m2_rm(vfloat64m2_t vs2, vfloat32m1_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_f64m2_rm(vfloat64m2_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_f64m4_rm(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_f64m4_rm(vfloat32m2_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_f64m4_rm(vfloat64m4_t vs2, vfloat32m2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_f64m4_rm(vfloat64m4_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_f64m8_rm(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_f64m8_rm(vfloat32m4_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_f64m8_rm(vfloat64m8_t vs2, vfloat32m4_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_f64m8_rm(vfloat64m8_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_f32mf2_rm(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_f32mf2_rm(vfloat16mf4_t vs2, _Float16 rs1,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_f32mf2_rm(vfloat32mf2_t vs2, vfloat16mf4_t vs1,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_f32mf2_rm(vfloat32mf2_t vs2, _Float16 rs1,
                                          unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_f32m1_rm(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_f32m1_rm(vfloat16mf2_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_f32m1_rm(vfloat32m1_t vs2, vfloat16mf2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_f32m1_rm(vfloat32m1_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_f32m2_rm(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_f32m2_rm(vfloat16m1_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_f32m2_rm(vfloat32m2_t vs2, vfloat16m1_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_f32m2_rm(vfloat32m2_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_f32m4_rm(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_f32m4_rm(vfloat16m2_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_f32m4_rm(vfloat32m4_t vs2, vfloat16m2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_f32m4_rm(vfloat32m4_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_f32m8_rm(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_f32m8_rm(vfloat16m4_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_f32m8_rm(vfloat32m8_t vs2, vfloat16m4_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_f32m8_rm(vfloat32m8_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_f64m1_rm(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_f64m1_rm(vfloat32mf2_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_f64m1_rm(vfloat64m1_t vs2, vfloat32mf2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_f64m1_rm(vfloat64m1_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_f64m2_rm(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_f64m2_rm(vfloat32m1_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_f64m2_rm(vfloat64m2_t vs2, vfloat32m1_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_f64m2_rm(vfloat64m2_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_f64m4_rm(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_f64m4_rm(vfloat32m2_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_f64m4_rm(vfloat64m4_t vs2, vfloat32m2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_f64m4_rm(vfloat64m4_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_f64m8_rm(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_f64m8_rm(vfloat32m4_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_f64m8_rm(vfloat64m8_t vs2, vfloat32m4_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_f64m8_rm(vfloat64m8_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwadd_vv_f32mf2_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            vfloat16mf4_t vs1, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_f32mf2_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            _Float16 rs1, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            vfloat16mf4_t vs1, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            _Float16 rs1, unsigned int frm,
                                            size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_f32m1_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          vfloat16mf2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_f32m1_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          vfloat16mf2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_f32m2_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                          vfloat16m1_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_f32m2_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          vfloat16m1_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_f32m4_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                          vfloat16m2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_f32m4_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          vfloat16m2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_f32m8_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                          vfloat16m4_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_f32m8_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                          vfloat16m4_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_f64m1_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          vfloat32mf2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_f64m1_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                          vfloat32mf2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_f64m2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          vfloat32m1_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_f64m2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                          vfloat32m1_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_f64m4_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          vfloat32m2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_f64m4_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                          vfloat32m2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_f64m8_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          vfloat32m4_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_f64m8_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                          vfloat32m4_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_f32mf2_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            vfloat16mf4_t vs1, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_f32mf2_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            _Float16 rs1, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            vfloat16mf4_t vs1, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            _Float16 rs1, unsigned int frm,
                                            size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_f32m1_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          vfloat16mf2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_f32m1_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          vfloat16mf2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_f32m2_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                          vfloat16m1_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_f32m2_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          vfloat16m1_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_f32m4_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                          vfloat16m2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_f32m4_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          vfloat16m2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_f32m8_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                          vfloat16m4_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_f32m8_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                          vfloat16m4_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_f64m1_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          vfloat32mf2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_f64m1_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                          vfloat32mf2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_f64m2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          vfloat32m1_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_f64m2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                          vfloat32m1_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_f64m4_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          vfloat32m2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_f64m4_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                          vfloat32m2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_f64m8_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          vfloat32m4_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_f64m8_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                          vfloat32m4_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
----

[[vector-single-width-floating-point-multiply-divide]]
==== Vector Single-Width Floating-Point Multiply/Divide Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfmul_vv_f16mf4(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfmul_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfmul_vv_f16mf2(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfmul_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m1_t __riscv_vfmul_vv_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                    size_t vl);
vfloat16m1_t __riscv_vfmul_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfmul_vv_f16m2(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                    size_t vl);
vfloat16m2_t __riscv_vfmul_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfmul_vv_f16m4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                    size_t vl);
vfloat16m4_t __riscv_vfmul_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfmul_vv_f16m8(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                    size_t vl);
vfloat16m8_t __riscv_vfmul_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfmul_vv_f32mf2(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vfloat32mf2_t __riscv_vfmul_vf_f32mf2(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat32m1_t __riscv_vfmul_vv_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                    size_t vl);
vfloat32m1_t __riscv_vfmul_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfmul_vv_f32m2(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                    size_t vl);
vfloat32m2_t __riscv_vfmul_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfmul_vv_f32m4(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                    size_t vl);
vfloat32m4_t __riscv_vfmul_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfmul_vv_f32m8(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                    size_t vl);
vfloat32m8_t __riscv_vfmul_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfmul_vv_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                    size_t vl);
vfloat64m1_t __riscv_vfmul_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfmul_vv_f64m2(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                    size_t vl);
vfloat64m2_t __riscv_vfmul_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfmul_vv_f64m4(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                    size_t vl);
vfloat64m4_t __riscv_vfmul_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfmul_vv_f64m8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                    size_t vl);
vfloat64m8_t __riscv_vfmul_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
vfloat16mf4_t __riscv_vfdiv_vv_f16mf4(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfdiv_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfdiv_vv_f16mf2(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfdiv_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m1_t __riscv_vfdiv_vv_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                    size_t vl);
vfloat16m1_t __riscv_vfdiv_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfdiv_vv_f16m2(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                    size_t vl);
vfloat16m2_t __riscv_vfdiv_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfdiv_vv_f16m4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                    size_t vl);
vfloat16m4_t __riscv_vfdiv_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfdiv_vv_f16m8(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                    size_t vl);
vfloat16m8_t __riscv_vfdiv_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfdiv_vv_f32mf2(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vfloat32mf2_t __riscv_vfdiv_vf_f32mf2(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat32m1_t __riscv_vfdiv_vv_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                    size_t vl);
vfloat32m1_t __riscv_vfdiv_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfdiv_vv_f32m2(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                    size_t vl);
vfloat32m2_t __riscv_vfdiv_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfdiv_vv_f32m4(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                    size_t vl);
vfloat32m4_t __riscv_vfdiv_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfdiv_vv_f32m8(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                    size_t vl);
vfloat32m8_t __riscv_vfdiv_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfdiv_vv_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                    size_t vl);
vfloat64m1_t __riscv_vfdiv_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfdiv_vv_f64m2(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                    size_t vl);
vfloat64m2_t __riscv_vfdiv_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfdiv_vv_f64m4(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                    size_t vl);
vfloat64m4_t __riscv_vfdiv_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfdiv_vv_f64m8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                    size_t vl);
vfloat64m8_t __riscv_vfdiv_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
vfloat16mf4_t __riscv_vfrdiv_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat16mf2_t __riscv_vfrdiv_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat16m1_t __riscv_vfrdiv_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfrdiv_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfrdiv_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfrdiv_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_vf_f32mf2(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat32m1_t __riscv_vfrdiv_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfrdiv_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfrdiv_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfrdiv_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfrdiv_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfrdiv_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfrdiv_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfrdiv_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmul_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vfmul_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfmul_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vfmul_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfmul_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfmul_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfmul_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      vfloat16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vfmul_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfmul_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      vfloat16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vfmul_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfmul_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      vfloat16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vfmul_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfmul_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfmul_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vfloat32m1_t __riscv_vfmul_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                      vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfmul_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2, float rs1,
                                      size_t vl);
vfloat32m2_t __riscv_vfmul_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                      vfloat32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vfmul_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2, float rs1,
                                      size_t vl);
vfloat32m4_t __riscv_vfmul_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                      vfloat32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vfmul_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                      size_t vl);
vfloat32m8_t __riscv_vfmul_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                      vfloat32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vfmul_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                      size_t vl);
vfloat64m1_t __riscv_vfmul_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfmul_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      double rs1, size_t vl);
vfloat64m2_t __riscv_vfmul_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      vfloat64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vfmul_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      double rs1, size_t vl);
vfloat64m4_t __riscv_vfmul_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      vfloat64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vfmul_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      double rs1, size_t vl);
vfloat64m8_t __riscv_vfmul_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                      vfloat64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vfmul_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfdiv_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vfdiv_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfdiv_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vfdiv_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfdiv_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfdiv_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfdiv_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      vfloat16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vfdiv_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfdiv_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      vfloat16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vfdiv_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfdiv_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      vfloat16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vfdiv_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfdiv_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfdiv_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vfloat32m1_t __riscv_vfdiv_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                      vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfdiv_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2, float rs1,
                                      size_t vl);
vfloat32m2_t __riscv_vfdiv_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                      vfloat32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vfdiv_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2, float rs1,
                                      size_t vl);
vfloat32m4_t __riscv_vfdiv_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                      vfloat32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vfdiv_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                      size_t vl);
vfloat32m8_t __riscv_vfdiv_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                      vfloat32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vfdiv_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                      size_t vl);
vfloat64m1_t __riscv_vfdiv_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfdiv_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      double rs1, size_t vl);
vfloat64m2_t __riscv_vfdiv_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      vfloat64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vfdiv_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      double rs1, size_t vl);
vfloat64m4_t __riscv_vfdiv_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      vfloat64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vfdiv_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      double rs1, size_t vl);
vfloat64m8_t __riscv_vfdiv_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                      vfloat64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vfdiv_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfrdiv_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfrdiv_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfrdiv_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfrdiv_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfrdiv_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfrdiv_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                         float rs1, size_t vl);
vfloat32m1_t __riscv_vfrdiv_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vfloat32m2_t __riscv_vfrdiv_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vfloat32m4_t __riscv_vfrdiv_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                       size_t vl);
vfloat32m8_t __riscv_vfrdiv_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                       size_t vl);
vfloat64m1_t __riscv_vfrdiv_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                       double rs1, size_t vl);
vfloat64m2_t __riscv_vfrdiv_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                       double rs1, size_t vl);
vfloat64m4_t __riscv_vfrdiv_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                       double rs1, size_t vl);
vfloat64m8_t __riscv_vfrdiv_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                       double rs1, size_t vl);
vfloat16mf4_t __riscv_vfmul_vv_f16mf4_rm(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                         unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmul_vf_f16mf4_rm(vfloat16mf4_t vs2, _Float16 rs1,
                                         unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmul_vv_f16mf2_rm(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                         unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmul_vf_f16mf2_rm(vfloat16mf2_t vs2, _Float16 rs1,
                                         unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmul_vv_f16m1_rm(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmul_vf_f16m1_rm(vfloat16m1_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmul_vv_f16m2_rm(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmul_vf_f16m2_rm(vfloat16m2_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmul_vv_f16m4_rm(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmul_vf_f16m4_rm(vfloat16m4_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmul_vv_f16m8_rm(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmul_vf_f16m8_rm(vfloat16m8_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmul_vv_f32mf2_rm(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                         unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmul_vf_f32mf2_rm(vfloat32mf2_t vs2, float rs1,
                                         unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmul_vv_f32m1_rm(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmul_vf_f32m1_rm(vfloat32m1_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmul_vv_f32m2_rm(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmul_vf_f32m2_rm(vfloat32m2_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmul_vv_f32m4_rm(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmul_vf_f32m4_rm(vfloat32m4_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmul_vv_f32m8_rm(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmul_vf_f32m8_rm(vfloat32m8_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmul_vv_f64m1_rm(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmul_vf_f64m1_rm(vfloat64m1_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmul_vv_f64m2_rm(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmul_vf_f64m2_rm(vfloat64m2_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmul_vv_f64m4_rm(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmul_vf_f64m4_rm(vfloat64m4_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmul_vv_f64m8_rm(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmul_vf_f64m8_rm(vfloat64m8_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfdiv_vv_f16mf4_rm(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                         unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfdiv_vf_f16mf4_rm(vfloat16mf4_t vs2, _Float16 rs1,
                                         unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfdiv_vv_f16mf2_rm(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                         unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfdiv_vf_f16mf2_rm(vfloat16mf2_t vs2, _Float16 rs1,
                                         unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfdiv_vv_f16m1_rm(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfdiv_vf_f16m1_rm(vfloat16m1_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfdiv_vv_f16m2_rm(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfdiv_vf_f16m2_rm(vfloat16m2_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfdiv_vv_f16m4_rm(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfdiv_vf_f16m4_rm(vfloat16m4_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfdiv_vv_f16m8_rm(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfdiv_vf_f16m8_rm(vfloat16m8_t vs2, _Float16 rs1,
                                       unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfdiv_vv_f32mf2_rm(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                         unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfdiv_vf_f32mf2_rm(vfloat32mf2_t vs2, float rs1,
                                         unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfdiv_vv_f32m1_rm(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfdiv_vf_f32m1_rm(vfloat32m1_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfdiv_vv_f32m2_rm(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfdiv_vf_f32m2_rm(vfloat32m2_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfdiv_vv_f32m4_rm(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfdiv_vf_f32m4_rm(vfloat32m4_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfdiv_vv_f32m8_rm(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfdiv_vf_f32m8_rm(vfloat32m8_t vs2, float rs1,
                                       unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfdiv_vv_f64m1_rm(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfdiv_vf_f64m1_rm(vfloat64m1_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfdiv_vv_f64m2_rm(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfdiv_vf_f64m2_rm(vfloat64m2_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfdiv_vv_f64m4_rm(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfdiv_vf_f64m4_rm(vfloat64m4_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfdiv_vv_f64m8_rm(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                       unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfdiv_vf_f64m8_rm(vfloat64m8_t vs2, double rs1,
                                       unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfrdiv_vf_f16mf4_rm(vfloat16mf4_t vs2, _Float16 rs1,
                                          unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrdiv_vf_f16mf2_rm(vfloat16mf2_t vs2, _Float16 rs1,
                                          unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrdiv_vf_f16m1_rm(vfloat16m1_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrdiv_vf_f16m2_rm(vfloat16m2_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrdiv_vf_f16m4_rm(vfloat16m4_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrdiv_vf_f16m8_rm(vfloat16m8_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_vf_f32mf2_rm(vfloat32mf2_t vs2, float rs1,
                                          unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrdiv_vf_f32m1_rm(vfloat32m1_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrdiv_vf_f32m2_rm(vfloat32m2_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrdiv_vf_f32m4_rm(vfloat32m4_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrdiv_vf_f32m8_rm(vfloat32m8_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrdiv_vf_f64m1_rm(vfloat64m1_t vs2, double rs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrdiv_vf_f64m2_rm(vfloat64m2_t vs2, double rs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrdiv_vf_f64m4_rm(vfloat64m4_t vs2, double rs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrdiv_vf_f64m8_rm(vfloat64m8_t vs2, double rs1,
                                        unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmul_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           vfloat16mf4_t vs1, unsigned int frm,
                                           size_t vl);
vfloat16mf4_t __riscv_vfmul_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           _Float16 rs1, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfmul_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           vfloat16mf2_t vs1, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfmul_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           _Float16 rs1, unsigned int frm,
                                           size_t vl);
vfloat16m1_t __riscv_vfmul_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                         vfloat16m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m1_t __riscv_vfmul_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfmul_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         vfloat16m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfmul_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfmul_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         vfloat16m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfmul_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfmul_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         vfloat16m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfmul_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat32mf2_t __riscv_vfmul_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           vfloat32mf2_t vs1, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfmul_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           float rs1, unsigned int frm,
                                           size_t vl);
vfloat32m1_t __riscv_vfmul_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                         vfloat32m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfmul_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfmul_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                         vfloat32m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfmul_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfmul_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                         vfloat32m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfmul_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfmul_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                         vfloat32m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfmul_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfmul_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                         vfloat64m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfmul_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfmul_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                         vfloat64m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfmul_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfmul_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                         vfloat64m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfmul_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfmul_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                         vfloat64m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfmul_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat16mf4_t __riscv_vfdiv_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           vfloat16mf4_t vs1, unsigned int frm,
                                           size_t vl);
vfloat16mf4_t __riscv_vfdiv_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           _Float16 rs1, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfdiv_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           vfloat16mf2_t vs1, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfdiv_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           _Float16 rs1, unsigned int frm,
                                           size_t vl);
vfloat16m1_t __riscv_vfdiv_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                         vfloat16m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m1_t __riscv_vfdiv_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfdiv_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         vfloat16m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfdiv_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfdiv_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         vfloat16m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfdiv_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfdiv_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         vfloat16m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfdiv_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         _Float16 rs1, unsigned int frm,
                                         size_t vl);
vfloat32mf2_t __riscv_vfdiv_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           vfloat32mf2_t vs1, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfdiv_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           float rs1, unsigned int frm,
                                           size_t vl);
vfloat32m1_t __riscv_vfdiv_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                         vfloat32m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfdiv_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfdiv_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                         vfloat32m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfdiv_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfdiv_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                         vfloat32m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfdiv_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfdiv_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                         vfloat32m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfdiv_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                         float rs1, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfdiv_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                         vfloat64m1_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfdiv_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfdiv_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                         vfloat64m2_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfdiv_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfdiv_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                         vfloat64m4_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfdiv_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfdiv_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                         vfloat64m8_t vs1, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfdiv_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                         double rs1, unsigned int frm,
                                         size_t vl);
vfloat16mf4_t __riscv_vfrdiv_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            _Float16 rs1, unsigned int frm,
                                            size_t vl);
vfloat16mf2_t __riscv_vfrdiv_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                            _Float16 rs1, unsigned int frm,
                                            size_t vl);
vfloat16m1_t __riscv_vfrdiv_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat16m2_t __riscv_vfrdiv_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat16m4_t __riscv_vfrdiv_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat16m8_t __riscv_vfrdiv_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32mf2_t __riscv_vfrdiv_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            float rs1, unsigned int frm,
                                            size_t vl);
vfloat32m1_t __riscv_vfrdiv_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfrdiv_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfrdiv_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfrdiv_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfrdiv_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                          double rs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfrdiv_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                          double rs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfrdiv_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                          double rs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfrdiv_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                          double rs1, unsigned int frm,
                                          size_t vl);
----

[[vector-widening-floating-point-multiply]]
==== Vector Widening Floating-Point Multiply Intrinsics

[,c]
----
vfloat32mf2_t __riscv_vfwmul_vv_f32mf2(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfwmul_vf_f32mf2(vfloat16mf4_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat32m1_t __riscv_vfwmul_vv_f32m1(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                     size_t vl);
vfloat32m1_t __riscv_vfwmul_vf_f32m1(vfloat16mf2_t vs2, _Float16 rs1,
                                     size_t vl);
vfloat32m2_t __riscv_vfwmul_vv_f32m2(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vfloat32m2_t __riscv_vfwmul_vf_f32m2(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat32m4_t __riscv_vfwmul_vv_f32m4(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                     size_t vl);
vfloat32m4_t __riscv_vfwmul_vf_f32m4(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat32m8_t __riscv_vfwmul_vv_f32m8(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                     size_t vl);
vfloat32m8_t __riscv_vfwmul_vf_f32m8(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat64m1_t __riscv_vfwmul_vv_f64m1(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                     size_t vl);
vfloat64m1_t __riscv_vfwmul_vf_f64m1(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat64m2_t __riscv_vfwmul_vv_f64m2(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vfloat64m2_t __riscv_vfwmul_vf_f64m2(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat64m4_t __riscv_vfwmul_vv_f64m4(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vfloat64m4_t __riscv_vfwmul_vf_f64m4(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat64m8_t __riscv_vfwmul_vv_f64m8(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                     size_t vl);
vfloat64m8_t __riscv_vfwmul_vf_f64m8(vfloat32m4_t vs2, float rs1, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmul_vv_f32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         vfloat16mf4_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfwmul_vf_f32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat32m1_t __riscv_vfwmul_vv_f32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                       vfloat16mf2_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwmul_vf_f32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m2_t __riscv_vfwmul_vv_f32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vfloat32m2_t __riscv_vfwmul_vf_f32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m4_t __riscv_vfwmul_vv_f32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                       vfloat16m2_t vs1, size_t vl);
vfloat32m4_t __riscv_vfwmul_vf_f32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32m8_t __riscv_vfwmul_vv_f32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                       vfloat16m4_t vs1, size_t vl);
vfloat32m8_t __riscv_vfwmul_vf_f32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat64m1_t __riscv_vfwmul_vv_f64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                       vfloat32mf2_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwmul_vf_f64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                       float rs1, size_t vl);
vfloat64m2_t __riscv_vfwmul_vv_f64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vfloat64m2_t __riscv_vfwmul_vf_f64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vfloat64m4_t __riscv_vfwmul_vv_f64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vfloat64m4_t __riscv_vfwmul_vf_f64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vfloat64m8_t __riscv_vfwmul_vv_f64m8_m(vbool8_t vm, vfloat32m4_t vs2,
                                       vfloat32m4_t vs1, size_t vl);
vfloat64m8_t __riscv_vfwmul_vf_f64m8_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfwmul_vv_f32mf2_rm(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmul_vf_f32mf2_rm(vfloat16mf4_t vs2, _Float16 rs1,
                                          unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmul_vv_f32m1_rm(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmul_vf_f32m1_rm(vfloat16mf2_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmul_vv_f32m2_rm(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmul_vf_f32m2_rm(vfloat16m1_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmul_vv_f32m4_rm(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmul_vf_f32m4_rm(vfloat16m2_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmul_vv_f32m8_rm(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                        unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmul_vf_f32m8_rm(vfloat16m4_t vs2, _Float16 rs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmul_vv_f64m1_rm(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmul_vf_f64m1_rm(vfloat32mf2_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmul_vv_f64m2_rm(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmul_vf_f64m2_rm(vfloat32m1_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmul_vv_f64m4_rm(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmul_vf_f64m4_rm(vfloat32m2_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmul_vv_f64m8_rm(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                        unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmul_vf_f64m8_rm(vfloat32m4_t vs2, float rs1,
                                        unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmul_vv_f32mf2_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            vfloat16mf4_t vs1, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfwmul_vf_f32mf2_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            _Float16 rs1, unsigned int frm,
                                            size_t vl);
vfloat32m1_t __riscv_vfwmul_vv_f32m1_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          vfloat16mf2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfwmul_vf_f32m1_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwmul_vv_f32m2_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                          vfloat16m1_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwmul_vf_f32m2_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwmul_vv_f32m4_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                          vfloat16m2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwmul_vf_f32m4_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwmul_vv_f32m8_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                          vfloat16m4_t vs1, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwmul_vf_f32m8_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                          _Float16 rs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwmul_vv_f64m1_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          vfloat32mf2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwmul_vf_f64m1_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwmul_vv_f64m2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          vfloat32m1_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwmul_vf_f64m2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwmul_vv_f64m4_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          vfloat32m2_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwmul_vf_f64m4_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwmul_vv_f64m8_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          vfloat32m4_t vs1, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwmul_vf_f64m8_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          float rs1, unsigned int frm,
                                          size_t vl);
----

[[vector-single-width-floating-point-fused-multiply-add]]
==== Vector Single-Width Floating-Point Fused Multiply-Add Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfmacc_vv_f16mf4(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                       vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmacc_vf_f16mf4(vfloat16mf4_t vd, _Float16 rs1,
                                       vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmacc_vv_f16mf2(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmacc_vf_f16mf2(vfloat16mf2_t vd, _Float16 rs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmacc_vv_f16m1(vfloat16m1_t vd, vfloat16m1_t vs1,
                                     vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmacc_vf_f16m1(vfloat16m1_t vd, _Float16 rs1,
                                     vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmacc_vv_f16m2(vfloat16m2_t vd, vfloat16m2_t vs1,
                                     vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmacc_vf_f16m2(vfloat16m2_t vd, _Float16 rs1,
                                     vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmacc_vv_f16m4(vfloat16m4_t vd, vfloat16m4_t vs1,
                                     vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmacc_vf_f16m4(vfloat16m4_t vd, _Float16 rs1,
                                     vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmacc_vv_f16m8(vfloat16m8_t vd, vfloat16m8_t vs1,
                                     vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmacc_vf_f16m8(vfloat16m8_t vd, _Float16 rs1,
                                     vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmacc_vv_f32mf2(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmacc_vf_f32mf2(vfloat32mf2_t vd, float rs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmacc_vv_f32m1(vfloat32m1_t vd, vfloat32m1_t vs1,
                                     vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmacc_vf_f32m1(vfloat32m1_t vd, float rs1,
                                     vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_vv_f32m2(vfloat32m2_t vd, vfloat32m2_t vs1,
                                     vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_vf_f32m2(vfloat32m2_t vd, float rs1,
                                     vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_vv_f32m4(vfloat32m4_t vd, vfloat32m4_t vs1,
                                     vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_vf_f32m4(vfloat32m4_t vd, float rs1,
                                     vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_vv_f32m8(vfloat32m8_t vd, vfloat32m8_t vs1,
                                     vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_vf_f32m8(vfloat32m8_t vd, float rs1,
                                     vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_vv_f64m1(vfloat64m1_t vd, vfloat64m1_t vs1,
                                     vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_vf_f64m1(vfloat64m1_t vd, double rs1,
                                     vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_vv_f64m2(vfloat64m2_t vd, vfloat64m2_t vs1,
                                     vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_vf_f64m2(vfloat64m2_t vd, double rs1,
                                     vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_vv_f64m4(vfloat64m4_t vd, vfloat64m4_t vs1,
                                     vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_vf_f64m4(vfloat64m4_t vd, double rs1,
                                     vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_vv_f64m8(vfloat64m8_t vd, vfloat64m8_t vs1,
                                     vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_vf_f64m8(vfloat64m8_t vd, double rs1,
                                     vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_vv_f16mf4(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_vf_f16mf4(vfloat16mf4_t vd, _Float16 rs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_vv_f16mf2(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                        vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_vf_f16mf2(vfloat16mf2_t vd, _Float16 rs1,
                                        vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmacc_vv_f16m1(vfloat16m1_t vd, vfloat16m1_t vs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmacc_vf_f16m1(vfloat16m1_t vd, _Float16 rs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmacc_vv_f16m2(vfloat16m2_t vd, vfloat16m2_t vs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmacc_vf_f16m2(vfloat16m2_t vd, _Float16 rs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmacc_vv_f16m4(vfloat16m4_t vd, vfloat16m4_t vs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmacc_vf_f16m4(vfloat16m4_t vd, _Float16 rs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmacc_vv_f16m8(vfloat16m8_t vd, vfloat16m8_t vs1,
                                      vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmacc_vf_f16m8(vfloat16m8_t vd, _Float16 rs1,
                                      vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_vv_f32mf2(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                        vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_vf_f32mf2(vfloat32mf2_t vd, float rs1,
                                        vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmacc_vv_f32m1(vfloat32m1_t vd, vfloat32m1_t vs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmacc_vf_f32m1(vfloat32m1_t vd, float rs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_vv_f32m2(vfloat32m2_t vd, vfloat32m2_t vs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_vf_f32m2(vfloat32m2_t vd, float rs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_vv_f32m4(vfloat32m4_t vd, vfloat32m4_t vs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_vf_f32m4(vfloat32m4_t vd, float rs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_vv_f32m8(vfloat32m8_t vd, vfloat32m8_t vs1,
                                      vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_vf_f32m8(vfloat32m8_t vd, float rs1,
                                      vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_vv_f64m1(vfloat64m1_t vd, vfloat64m1_t vs1,
                                      vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_vf_f64m1(vfloat64m1_t vd, double rs1,
                                      vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmacc_vv_f64m2(vfloat64m2_t vd, vfloat64m2_t vs1,
                                      vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmacc_vf_f64m2(vfloat64m2_t vd, double rs1,
                                      vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmacc_vv_f64m4(vfloat64m4_t vd, vfloat64m4_t vs1,
                                      vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmacc_vf_f64m4(vfloat64m4_t vd, double rs1,
                                      vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmacc_vv_f64m8(vfloat64m8_t vd, vfloat64m8_t vs1,
                                      vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmacc_vf_f64m8(vfloat64m8_t vd, double rs1,
                                      vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsac_vv_f16mf4(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                       vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsac_vf_f16mf4(vfloat16mf4_t vd, _Float16 rs1,
                                       vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsac_vv_f16mf2(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsac_vf_f16mf2(vfloat16mf2_t vd, _Float16 rs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsac_vv_f16m1(vfloat16m1_t vd, vfloat16m1_t vs1,
                                     vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsac_vf_f16m1(vfloat16m1_t vd, _Float16 rs1,
                                     vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsac_vv_f16m2(vfloat16m2_t vd, vfloat16m2_t vs1,
                                     vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsac_vf_f16m2(vfloat16m2_t vd, _Float16 rs1,
                                     vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsac_vv_f16m4(vfloat16m4_t vd, vfloat16m4_t vs1,
                                     vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsac_vf_f16m4(vfloat16m4_t vd, _Float16 rs1,
                                     vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsac_vv_f16m8(vfloat16m8_t vd, vfloat16m8_t vs1,
                                     vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsac_vf_f16m8(vfloat16m8_t vd, _Float16 rs1,
                                     vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsac_vv_f32mf2(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsac_vf_f32mf2(vfloat32mf2_t vd, float rs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsac_vv_f32m1(vfloat32m1_t vd, vfloat32m1_t vs1,
                                     vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsac_vf_f32m1(vfloat32m1_t vd, float rs1,
                                     vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_vv_f32m2(vfloat32m2_t vd, vfloat32m2_t vs1,
                                     vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_vf_f32m2(vfloat32m2_t vd, float rs1,
                                     vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_vv_f32m4(vfloat32m4_t vd, vfloat32m4_t vs1,
                                     vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_vf_f32m4(vfloat32m4_t vd, float rs1,
                                     vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_vv_f32m8(vfloat32m8_t vd, vfloat32m8_t vs1,
                                     vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_vf_f32m8(vfloat32m8_t vd, float rs1,
                                     vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_vv_f64m1(vfloat64m1_t vd, vfloat64m1_t vs1,
                                     vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_vf_f64m1(vfloat64m1_t vd, double rs1,
                                     vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_vv_f64m2(vfloat64m2_t vd, vfloat64m2_t vs1,
                                     vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_vf_f64m2(vfloat64m2_t vd, double rs1,
                                     vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_vv_f64m4(vfloat64m4_t vd, vfloat64m4_t vs1,
                                     vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_vf_f64m4(vfloat64m4_t vd, double rs1,
                                     vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_vv_f64m8(vfloat64m8_t vd, vfloat64m8_t vs1,
                                     vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_vf_f64m8(vfloat64m8_t vd, double rs1,
                                     vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_vv_f16mf4(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_vf_f16mf4(vfloat16mf4_t vd, _Float16 rs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_vv_f16mf2(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                        vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_vf_f16mf2(vfloat16mf2_t vd, _Float16 rs1,
                                        vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsac_vv_f16m1(vfloat16m1_t vd, vfloat16m1_t vs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsac_vf_f16m1(vfloat16m1_t vd, _Float16 rs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsac_vv_f16m2(vfloat16m2_t vd, vfloat16m2_t vs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsac_vf_f16m2(vfloat16m2_t vd, _Float16 rs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsac_vv_f16m4(vfloat16m4_t vd, vfloat16m4_t vs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsac_vf_f16m4(vfloat16m4_t vd, _Float16 rs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsac_vv_f16m8(vfloat16m8_t vd, vfloat16m8_t vs1,
                                      vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsac_vf_f16m8(vfloat16m8_t vd, _Float16 rs1,
                                      vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_vv_f32mf2(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                        vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_vf_f32mf2(vfloat32mf2_t vd, float rs1,
                                        vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsac_vv_f32m1(vfloat32m1_t vd, vfloat32m1_t vs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsac_vf_f32m1(vfloat32m1_t vd, float rs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_vv_f32m2(vfloat32m2_t vd, vfloat32m2_t vs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_vf_f32m2(vfloat32m2_t vd, float rs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_vv_f32m4(vfloat32m4_t vd, vfloat32m4_t vs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_vf_f32m4(vfloat32m4_t vd, float rs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_vv_f32m8(vfloat32m8_t vd, vfloat32m8_t vs1,
                                      vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_vf_f32m8(vfloat32m8_t vd, float rs1,
                                      vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_vv_f64m1(vfloat64m1_t vd, vfloat64m1_t vs1,
                                      vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_vf_f64m1(vfloat64m1_t vd, double rs1,
                                      vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsac_vv_f64m2(vfloat64m2_t vd, vfloat64m2_t vs1,
                                      vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsac_vf_f64m2(vfloat64m2_t vd, double rs1,
                                      vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsac_vv_f64m4(vfloat64m4_t vd, vfloat64m4_t vs1,
                                      vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsac_vf_f64m4(vfloat64m4_t vd, double rs1,
                                      vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsac_vv_f64m8(vfloat64m8_t vd, vfloat64m8_t vs1,
                                      vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsac_vf_f64m8(vfloat64m8_t vd, double rs1,
                                      vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmadd_vv_f16mf4(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                       vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmadd_vf_f16mf4(vfloat16mf4_t vd, _Float16 rs1,
                                       vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmadd_vv_f16mf2(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmadd_vf_f16mf2(vfloat16mf2_t vd, _Float16 rs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmadd_vv_f16m1(vfloat16m1_t vd, vfloat16m1_t vs1,
                                     vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmadd_vf_f16m1(vfloat16m1_t vd, _Float16 rs1,
                                     vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmadd_vv_f16m2(vfloat16m2_t vd, vfloat16m2_t vs1,
                                     vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmadd_vf_f16m2(vfloat16m2_t vd, _Float16 rs1,
                                     vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmadd_vv_f16m4(vfloat16m4_t vd, vfloat16m4_t vs1,
                                     vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmadd_vf_f16m4(vfloat16m4_t vd, _Float16 rs1,
                                     vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmadd_vv_f16m8(vfloat16m8_t vd, vfloat16m8_t vs1,
                                     vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmadd_vf_f16m8(vfloat16m8_t vd, _Float16 rs1,
                                     vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmadd_vv_f32mf2(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmadd_vf_f32mf2(vfloat32mf2_t vd, float rs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmadd_vv_f32m1(vfloat32m1_t vd, vfloat32m1_t vs1,
                                     vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmadd_vf_f32m1(vfloat32m1_t vd, float rs1,
                                     vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_vv_f32m2(vfloat32m2_t vd, vfloat32m2_t vs1,
                                     vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_vf_f32m2(vfloat32m2_t vd, float rs1,
                                     vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_vv_f32m4(vfloat32m4_t vd, vfloat32m4_t vs1,
                                     vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_vf_f32m4(vfloat32m4_t vd, float rs1,
                                     vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_vv_f32m8(vfloat32m8_t vd, vfloat32m8_t vs1,
                                     vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_vf_f32m8(vfloat32m8_t vd, float rs1,
                                     vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_vv_f64m1(vfloat64m1_t vd, vfloat64m1_t vs1,
                                     vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_vf_f64m1(vfloat64m1_t vd, double rs1,
                                     vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_vv_f64m2(vfloat64m2_t vd, vfloat64m2_t vs1,
                                     vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_vf_f64m2(vfloat64m2_t vd, double rs1,
                                     vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_vv_f64m4(vfloat64m4_t vd, vfloat64m4_t vs1,
                                     vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_vf_f64m4(vfloat64m4_t vd, double rs1,
                                     vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_vv_f64m8(vfloat64m8_t vd, vfloat64m8_t vs1,
                                     vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_vf_f64m8(vfloat64m8_t vd, double rs1,
                                     vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_vv_f16mf4(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_vf_f16mf4(vfloat16mf4_t vd, _Float16 rs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_vv_f16mf2(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                        vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_vf_f16mf2(vfloat16mf2_t vd, _Float16 rs1,
                                        vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmadd_vv_f16m1(vfloat16m1_t vd, vfloat16m1_t vs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmadd_vf_f16m1(vfloat16m1_t vd, _Float16 rs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmadd_vv_f16m2(vfloat16m2_t vd, vfloat16m2_t vs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmadd_vf_f16m2(vfloat16m2_t vd, _Float16 rs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmadd_vv_f16m4(vfloat16m4_t vd, vfloat16m4_t vs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmadd_vf_f16m4(vfloat16m4_t vd, _Float16 rs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmadd_vv_f16m8(vfloat16m8_t vd, vfloat16m8_t vs1,
                                      vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmadd_vf_f16m8(vfloat16m8_t vd, _Float16 rs1,
                                      vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_vv_f32mf2(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                        vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_vf_f32mf2(vfloat32mf2_t vd, float rs1,
                                        vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmadd_vv_f32m1(vfloat32m1_t vd, vfloat32m1_t vs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmadd_vf_f32m1(vfloat32m1_t vd, float rs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_vv_f32m2(vfloat32m2_t vd, vfloat32m2_t vs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_vf_f32m2(vfloat32m2_t vd, float rs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_vv_f32m4(vfloat32m4_t vd, vfloat32m4_t vs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_vf_f32m4(vfloat32m4_t vd, float rs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_vv_f32m8(vfloat32m8_t vd, vfloat32m8_t vs1,
                                      vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_vf_f32m8(vfloat32m8_t vd, float rs1,
                                      vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_vv_f64m1(vfloat64m1_t vd, vfloat64m1_t vs1,
                                      vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_vf_f64m1(vfloat64m1_t vd, double rs1,
                                      vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmadd_vv_f64m2(vfloat64m2_t vd, vfloat64m2_t vs1,
                                      vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmadd_vf_f64m2(vfloat64m2_t vd, double rs1,
                                      vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmadd_vv_f64m4(vfloat64m4_t vd, vfloat64m4_t vs1,
                                      vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmadd_vf_f64m4(vfloat64m4_t vd, double rs1,
                                      vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmadd_vv_f64m8(vfloat64m8_t vd, vfloat64m8_t vs1,
                                      vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmadd_vf_f64m8(vfloat64m8_t vd, double rs1,
                                      vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsub_vv_f16mf4(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                       vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsub_vf_f16mf4(vfloat16mf4_t vd, _Float16 rs1,
                                       vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsub_vv_f16mf2(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsub_vf_f16mf2(vfloat16mf2_t vd, _Float16 rs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsub_vv_f16m1(vfloat16m1_t vd, vfloat16m1_t vs1,
                                     vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsub_vf_f16m1(vfloat16m1_t vd, _Float16 rs1,
                                     vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsub_vv_f16m2(vfloat16m2_t vd, vfloat16m2_t vs1,
                                     vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsub_vf_f16m2(vfloat16m2_t vd, _Float16 rs1,
                                     vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsub_vv_f16m4(vfloat16m4_t vd, vfloat16m4_t vs1,
                                     vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsub_vf_f16m4(vfloat16m4_t vd, _Float16 rs1,
                                     vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsub_vv_f16m8(vfloat16m8_t vd, vfloat16m8_t vs1,
                                     vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsub_vf_f16m8(vfloat16m8_t vd, _Float16 rs1,
                                     vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsub_vv_f32mf2(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsub_vf_f32mf2(vfloat32mf2_t vd, float rs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsub_vv_f32m1(vfloat32m1_t vd, vfloat32m1_t vs1,
                                     vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsub_vf_f32m1(vfloat32m1_t vd, float rs1,
                                     vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_vv_f32m2(vfloat32m2_t vd, vfloat32m2_t vs1,
                                     vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_vf_f32m2(vfloat32m2_t vd, float rs1,
                                     vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_vv_f32m4(vfloat32m4_t vd, vfloat32m4_t vs1,
                                     vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_vf_f32m4(vfloat32m4_t vd, float rs1,
                                     vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_vv_f32m8(vfloat32m8_t vd, vfloat32m8_t vs1,
                                     vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_vf_f32m8(vfloat32m8_t vd, float rs1,
                                     vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_vv_f64m1(vfloat64m1_t vd, vfloat64m1_t vs1,
                                     vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_vf_f64m1(vfloat64m1_t vd, double rs1,
                                     vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_vv_f64m2(vfloat64m2_t vd, vfloat64m2_t vs1,
                                     vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_vf_f64m2(vfloat64m2_t vd, double rs1,
                                     vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_vv_f64m4(vfloat64m4_t vd, vfloat64m4_t vs1,
                                     vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_vf_f64m4(vfloat64m4_t vd, double rs1,
                                     vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_vv_f64m8(vfloat64m8_t vd, vfloat64m8_t vs1,
                                     vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_vf_f64m8(vfloat64m8_t vd, double rs1,
                                     vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_vv_f16mf4(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_vf_f16mf4(vfloat16mf4_t vd, _Float16 rs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_vv_f16mf2(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                        vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_vf_f16mf2(vfloat16mf2_t vd, _Float16 rs1,
                                        vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsub_vv_f16m1(vfloat16m1_t vd, vfloat16m1_t vs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsub_vf_f16m1(vfloat16m1_t vd, _Float16 rs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsub_vv_f16m2(vfloat16m2_t vd, vfloat16m2_t vs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsub_vf_f16m2(vfloat16m2_t vd, _Float16 rs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsub_vv_f16m4(vfloat16m4_t vd, vfloat16m4_t vs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsub_vf_f16m4(vfloat16m4_t vd, _Float16 rs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsub_vv_f16m8(vfloat16m8_t vd, vfloat16m8_t vs1,
                                      vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsub_vf_f16m8(vfloat16m8_t vd, _Float16 rs1,
                                      vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_vv_f32mf2(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                        vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_vf_f32mf2(vfloat32mf2_t vd, float rs1,
                                        vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsub_vv_f32m1(vfloat32m1_t vd, vfloat32m1_t vs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsub_vf_f32m1(vfloat32m1_t vd, float rs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_vv_f32m2(vfloat32m2_t vd, vfloat32m2_t vs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_vf_f32m2(vfloat32m2_t vd, float rs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_vv_f32m4(vfloat32m4_t vd, vfloat32m4_t vs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_vf_f32m4(vfloat32m4_t vd, float rs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_vv_f32m8(vfloat32m8_t vd, vfloat32m8_t vs1,
                                      vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_vf_f32m8(vfloat32m8_t vd, float rs1,
                                      vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_vv_f64m1(vfloat64m1_t vd, vfloat64m1_t vs1,
                                      vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_vf_f64m1(vfloat64m1_t vd, double rs1,
                                      vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsub_vv_f64m2(vfloat64m2_t vd, vfloat64m2_t vs1,
                                      vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsub_vf_f64m2(vfloat64m2_t vd, double rs1,
                                      vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsub_vv_f64m4(vfloat64m4_t vd, vfloat64m4_t vs1,
                                      vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsub_vf_f64m4(vfloat64m4_t vd, double rs1,
                                      vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsub_vv_f64m8(vfloat64m8_t vd, vfloat64m8_t vs1,
                                      vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsub_vf_f64m8(vfloat64m8_t vd, double rs1,
                                      vfloat64m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmacc_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                         vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                         size_t vl);
vfloat16mf4_t __riscv_vfmacc_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                         _Float16 rs1, vfloat16mf4_t vs2,
                                         size_t vl);
vfloat16mf2_t __riscv_vfmacc_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                         vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat16mf2_t __riscv_vfmacc_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                         _Float16 rs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat16m1_t __riscv_vfmacc_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                       vfloat16m1_t vs1, vfloat16m1_t vs2,
                                       size_t vl);
vfloat16m1_t __riscv_vfmacc_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                       _Float16 rs1, vfloat16m1_t vs2,
                                       size_t vl);
vfloat16m2_t __riscv_vfmacc_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                       vfloat16m2_t vs1, vfloat16m2_t vs2,
                                       size_t vl);
vfloat16m2_t __riscv_vfmacc_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                       _Float16 rs1, vfloat16m2_t vs2,
                                       size_t vl);
vfloat16m4_t __riscv_vfmacc_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                       vfloat16m4_t vs1, vfloat16m4_t vs2,
                                       size_t vl);
vfloat16m4_t __riscv_vfmacc_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                       _Float16 rs1, vfloat16m4_t vs2,
                                       size_t vl);
vfloat16m8_t __riscv_vfmacc_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                       vfloat16m8_t vs1, vfloat16m8_t vs2,
                                       size_t vl);
vfloat16m8_t __riscv_vfmacc_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                       _Float16 rs1, vfloat16m8_t vs2,
                                       size_t vl);
vfloat32mf2_t __riscv_vfmacc_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                         vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat32mf2_t __riscv_vfmacc_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                         float rs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat32m1_t __riscv_vfmacc_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                       vfloat32m1_t vs1, vfloat32m1_t vs2,
                                       size_t vl);
vfloat32m1_t __riscv_vfmacc_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd, float rs1,
                                       vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                       vfloat32m2_t vs1, vfloat32m2_t vs2,
                                       size_t vl);
vfloat32m2_t __riscv_vfmacc_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd, float rs1,
                                       vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                       vfloat32m4_t vs1, vfloat32m4_t vs2,
                                       size_t vl);
vfloat32m4_t __riscv_vfmacc_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd, float rs1,
                                       vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                       vfloat32m8_t vs1, vfloat32m8_t vs2,
                                       size_t vl);
vfloat32m8_t __riscv_vfmacc_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd, float rs1,
                                       vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                       vfloat64m1_t vs1, vfloat64m1_t vs2,
                                       size_t vl);
vfloat64m1_t __riscv_vfmacc_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                       double rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                       vfloat64m2_t vs1, vfloat64m2_t vs2,
                                       size_t vl);
vfloat64m2_t __riscv_vfmacc_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                       double rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                       vfloat64m4_t vs1, vfloat64m4_t vs2,
                                       size_t vl);
vfloat64m4_t __riscv_vfmacc_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                       double rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                       vfloat64m8_t vs1, vfloat64m8_t vs2,
                                       size_t vl);
vfloat64m8_t __riscv_vfmacc_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd, double rs1,
                                       vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                          vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat16mf4_t __riscv_vfnmacc_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                          _Float16 rs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat16mf2_t __riscv_vfnmacc_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                          vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat16mf2_t __riscv_vfnmacc_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                          _Float16 rs1, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat16m1_t __riscv_vfnmacc_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                        vfloat16m1_t vs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat16m1_t __riscv_vfnmacc_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                        _Float16 rs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat16m2_t __riscv_vfnmacc_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                        vfloat16m2_t vs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat16m2_t __riscv_vfnmacc_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                        _Float16 rs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat16m4_t __riscv_vfnmacc_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                        vfloat16m4_t vs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat16m4_t __riscv_vfnmacc_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                        _Float16 rs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat16m8_t __riscv_vfnmacc_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                        vfloat16m8_t vs1, vfloat16m8_t vs2,
                                        size_t vl);
vfloat16m8_t __riscv_vfnmacc_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                        _Float16 rs1, vfloat16m8_t vs2,
                                        size_t vl);
vfloat32mf2_t __riscv_vfnmacc_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                          size_t vl);
vfloat32mf2_t __riscv_vfnmacc_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          float rs1, vfloat32mf2_t vs2,
                                          size_t vl);
vfloat32m1_t __riscv_vfnmacc_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        vfloat32m1_t vs1, vfloat32m1_t vs2,
                                        size_t vl);
vfloat32m1_t __riscv_vfnmacc_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        float rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        vfloat32m2_t vs1, vfloat32m2_t vs2,
                                        size_t vl);
vfloat32m2_t __riscv_vfnmacc_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        float rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                        vfloat32m4_t vs1, vfloat32m4_t vs2,
                                        size_t vl);
vfloat32m4_t __riscv_vfnmacc_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd, float rs1,
                                        vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                        vfloat32m8_t vs1, vfloat32m8_t vs2,
                                        size_t vl);
vfloat32m8_t __riscv_vfnmacc_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd, float rs1,
                                        vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        vfloat64m1_t vs1, vfloat64m1_t vs2,
                                        size_t vl);
vfloat64m1_t __riscv_vfnmacc_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        double rs1, vfloat64m1_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfnmacc_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        vfloat64m2_t vs1, vfloat64m2_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfnmacc_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        double rs1, vfloat64m2_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfnmacc_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        vfloat64m4_t vs1, vfloat64m4_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfnmacc_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        double rs1, vfloat64m4_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfnmacc_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                        vfloat64m8_t vs1, vfloat64m8_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfnmacc_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                        double rs1, vfloat64m8_t vs2,
                                        size_t vl);
vfloat16mf4_t __riscv_vfmsac_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                         vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                         size_t vl);
vfloat16mf4_t __riscv_vfmsac_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                         _Float16 rs1, vfloat16mf4_t vs2,
                                         size_t vl);
vfloat16mf2_t __riscv_vfmsac_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                         vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat16mf2_t __riscv_vfmsac_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                         _Float16 rs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat16m1_t __riscv_vfmsac_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                       vfloat16m1_t vs1, vfloat16m1_t vs2,
                                       size_t vl);
vfloat16m1_t __riscv_vfmsac_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                       _Float16 rs1, vfloat16m1_t vs2,
                                       size_t vl);
vfloat16m2_t __riscv_vfmsac_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                       vfloat16m2_t vs1, vfloat16m2_t vs2,
                                       size_t vl);
vfloat16m2_t __riscv_vfmsac_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                       _Float16 rs1, vfloat16m2_t vs2,
                                       size_t vl);
vfloat16m4_t __riscv_vfmsac_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                       vfloat16m4_t vs1, vfloat16m4_t vs2,
                                       size_t vl);
vfloat16m4_t __riscv_vfmsac_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                       _Float16 rs1, vfloat16m4_t vs2,
                                       size_t vl);
vfloat16m8_t __riscv_vfmsac_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                       vfloat16m8_t vs1, vfloat16m8_t vs2,
                                       size_t vl);
vfloat16m8_t __riscv_vfmsac_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                       _Float16 rs1, vfloat16m8_t vs2,
                                       size_t vl);
vfloat32mf2_t __riscv_vfmsac_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                         vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat32mf2_t __riscv_vfmsac_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                         float rs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat32m1_t __riscv_vfmsac_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                       vfloat32m1_t vs1, vfloat32m1_t vs2,
                                       size_t vl);
vfloat32m1_t __riscv_vfmsac_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd, float rs1,
                                       vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                       vfloat32m2_t vs1, vfloat32m2_t vs2,
                                       size_t vl);
vfloat32m2_t __riscv_vfmsac_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd, float rs1,
                                       vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                       vfloat32m4_t vs1, vfloat32m4_t vs2,
                                       size_t vl);
vfloat32m4_t __riscv_vfmsac_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd, float rs1,
                                       vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                       vfloat32m8_t vs1, vfloat32m8_t vs2,
                                       size_t vl);
vfloat32m8_t __riscv_vfmsac_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd, float rs1,
                                       vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                       vfloat64m1_t vs1, vfloat64m1_t vs2,
                                       size_t vl);
vfloat64m1_t __riscv_vfmsac_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                       double rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                       vfloat64m2_t vs1, vfloat64m2_t vs2,
                                       size_t vl);
vfloat64m2_t __riscv_vfmsac_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                       double rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                       vfloat64m4_t vs1, vfloat64m4_t vs2,
                                       size_t vl);
vfloat64m4_t __riscv_vfmsac_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                       double rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                       vfloat64m8_t vs1, vfloat64m8_t vs2,
                                       size_t vl);
vfloat64m8_t __riscv_vfmsac_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd, double rs1,
                                       vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                          vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat16mf4_t __riscv_vfnmsac_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                          _Float16 rs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat16mf2_t __riscv_vfnmsac_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                          vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat16mf2_t __riscv_vfnmsac_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                          _Float16 rs1, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat16m1_t __riscv_vfnmsac_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                        vfloat16m1_t vs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat16m1_t __riscv_vfnmsac_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                        _Float16 rs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat16m2_t __riscv_vfnmsac_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                        vfloat16m2_t vs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat16m2_t __riscv_vfnmsac_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                        _Float16 rs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat16m4_t __riscv_vfnmsac_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                        vfloat16m4_t vs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat16m4_t __riscv_vfnmsac_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                        _Float16 rs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat16m8_t __riscv_vfnmsac_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                        vfloat16m8_t vs1, vfloat16m8_t vs2,
                                        size_t vl);
vfloat16m8_t __riscv_vfnmsac_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                        _Float16 rs1, vfloat16m8_t vs2,
                                        size_t vl);
vfloat32mf2_t __riscv_vfnmsac_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                          size_t vl);
vfloat32mf2_t __riscv_vfnmsac_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          float rs1, vfloat32mf2_t vs2,
                                          size_t vl);
vfloat32m1_t __riscv_vfnmsac_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        vfloat32m1_t vs1, vfloat32m1_t vs2,
                                        size_t vl);
vfloat32m1_t __riscv_vfnmsac_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        float rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        vfloat32m2_t vs1, vfloat32m2_t vs2,
                                        size_t vl);
vfloat32m2_t __riscv_vfnmsac_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        float rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                        vfloat32m4_t vs1, vfloat32m4_t vs2,
                                        size_t vl);
vfloat32m4_t __riscv_vfnmsac_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd, float rs1,
                                        vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                        vfloat32m8_t vs1, vfloat32m8_t vs2,
                                        size_t vl);
vfloat32m8_t __riscv_vfnmsac_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd, float rs1,
                                        vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        vfloat64m1_t vs1, vfloat64m1_t vs2,
                                        size_t vl);
vfloat64m1_t __riscv_vfnmsac_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        double rs1, vfloat64m1_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfnmsac_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        vfloat64m2_t vs1, vfloat64m2_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfnmsac_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        double rs1, vfloat64m2_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfnmsac_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        vfloat64m4_t vs1, vfloat64m4_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfnmsac_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        double rs1, vfloat64m4_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfnmsac_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                        vfloat64m8_t vs1, vfloat64m8_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfnmsac_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                        double rs1, vfloat64m8_t vs2,
                                        size_t vl);
vfloat16mf4_t __riscv_vfmadd_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                         vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                         size_t vl);
vfloat16mf4_t __riscv_vfmadd_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                         _Float16 rs1, vfloat16mf4_t vs2,
                                         size_t vl);
vfloat16mf2_t __riscv_vfmadd_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                         vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat16mf2_t __riscv_vfmadd_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                         _Float16 rs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat16m1_t __riscv_vfmadd_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                       vfloat16m1_t vs1, vfloat16m1_t vs2,
                                       size_t vl);
vfloat16m1_t __riscv_vfmadd_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                       _Float16 rs1, vfloat16m1_t vs2,
                                       size_t vl);
vfloat16m2_t __riscv_vfmadd_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                       vfloat16m2_t vs1, vfloat16m2_t vs2,
                                       size_t vl);
vfloat16m2_t __riscv_vfmadd_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                       _Float16 rs1, vfloat16m2_t vs2,
                                       size_t vl);
vfloat16m4_t __riscv_vfmadd_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                       vfloat16m4_t vs1, vfloat16m4_t vs2,
                                       size_t vl);
vfloat16m4_t __riscv_vfmadd_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                       _Float16 rs1, vfloat16m4_t vs2,
                                       size_t vl);
vfloat16m8_t __riscv_vfmadd_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                       vfloat16m8_t vs1, vfloat16m8_t vs2,
                                       size_t vl);
vfloat16m8_t __riscv_vfmadd_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                       _Float16 rs1, vfloat16m8_t vs2,
                                       size_t vl);
vfloat32mf2_t __riscv_vfmadd_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                         vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat32mf2_t __riscv_vfmadd_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                         float rs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat32m1_t __riscv_vfmadd_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                       vfloat32m1_t vs1, vfloat32m1_t vs2,
                                       size_t vl);
vfloat32m1_t __riscv_vfmadd_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd, float rs1,
                                       vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                       vfloat32m2_t vs1, vfloat32m2_t vs2,
                                       size_t vl);
vfloat32m2_t __riscv_vfmadd_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd, float rs1,
                                       vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                       vfloat32m4_t vs1, vfloat32m4_t vs2,
                                       size_t vl);
vfloat32m4_t __riscv_vfmadd_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd, float rs1,
                                       vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                       vfloat32m8_t vs1, vfloat32m8_t vs2,
                                       size_t vl);
vfloat32m8_t __riscv_vfmadd_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd, float rs1,
                                       vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                       vfloat64m1_t vs1, vfloat64m1_t vs2,
                                       size_t vl);
vfloat64m1_t __riscv_vfmadd_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                       double rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                       vfloat64m2_t vs1, vfloat64m2_t vs2,
                                       size_t vl);
vfloat64m2_t __riscv_vfmadd_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                       double rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                       vfloat64m4_t vs1, vfloat64m4_t vs2,
                                       size_t vl);
vfloat64m4_t __riscv_vfmadd_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                       double rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                       vfloat64m8_t vs1, vfloat64m8_t vs2,
                                       size_t vl);
vfloat64m8_t __riscv_vfmadd_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd, double rs1,
                                       vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                          vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat16mf4_t __riscv_vfnmadd_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                          _Float16 rs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat16mf2_t __riscv_vfnmadd_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                          vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat16mf2_t __riscv_vfnmadd_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                          _Float16 rs1, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat16m1_t __riscv_vfnmadd_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                        vfloat16m1_t vs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat16m1_t __riscv_vfnmadd_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                        _Float16 rs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat16m2_t __riscv_vfnmadd_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                        vfloat16m2_t vs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat16m2_t __riscv_vfnmadd_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                        _Float16 rs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat16m4_t __riscv_vfnmadd_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                        vfloat16m4_t vs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat16m4_t __riscv_vfnmadd_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                        _Float16 rs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat16m8_t __riscv_vfnmadd_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                        vfloat16m8_t vs1, vfloat16m8_t vs2,
                                        size_t vl);
vfloat16m8_t __riscv_vfnmadd_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                        _Float16 rs1, vfloat16m8_t vs2,
                                        size_t vl);
vfloat32mf2_t __riscv_vfnmadd_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                          size_t vl);
vfloat32mf2_t __riscv_vfnmadd_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          float rs1, vfloat32mf2_t vs2,
                                          size_t vl);
vfloat32m1_t __riscv_vfnmadd_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        vfloat32m1_t vs1, vfloat32m1_t vs2,
                                        size_t vl);
vfloat32m1_t __riscv_vfnmadd_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        float rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        vfloat32m2_t vs1, vfloat32m2_t vs2,
                                        size_t vl);
vfloat32m2_t __riscv_vfnmadd_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        float rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                        vfloat32m4_t vs1, vfloat32m4_t vs2,
                                        size_t vl);
vfloat32m4_t __riscv_vfnmadd_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd, float rs1,
                                        vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                        vfloat32m8_t vs1, vfloat32m8_t vs2,
                                        size_t vl);
vfloat32m8_t __riscv_vfnmadd_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd, float rs1,
                                        vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        vfloat64m1_t vs1, vfloat64m1_t vs2,
                                        size_t vl);
vfloat64m1_t __riscv_vfnmadd_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        double rs1, vfloat64m1_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfnmadd_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        vfloat64m2_t vs1, vfloat64m2_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfnmadd_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        double rs1, vfloat64m2_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfnmadd_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        vfloat64m4_t vs1, vfloat64m4_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfnmadd_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        double rs1, vfloat64m4_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfnmadd_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                        vfloat64m8_t vs1, vfloat64m8_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfnmadd_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                        double rs1, vfloat64m8_t vs2,
                                        size_t vl);
vfloat16mf4_t __riscv_vfmsub_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                         vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                         size_t vl);
vfloat16mf4_t __riscv_vfmsub_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                         _Float16 rs1, vfloat16mf4_t vs2,
                                         size_t vl);
vfloat16mf2_t __riscv_vfmsub_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                         vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat16mf2_t __riscv_vfmsub_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                         _Float16 rs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat16m1_t __riscv_vfmsub_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                       vfloat16m1_t vs1, vfloat16m1_t vs2,
                                       size_t vl);
vfloat16m1_t __riscv_vfmsub_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                       _Float16 rs1, vfloat16m1_t vs2,
                                       size_t vl);
vfloat16m2_t __riscv_vfmsub_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                       vfloat16m2_t vs1, vfloat16m2_t vs2,
                                       size_t vl);
vfloat16m2_t __riscv_vfmsub_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                       _Float16 rs1, vfloat16m2_t vs2,
                                       size_t vl);
vfloat16m4_t __riscv_vfmsub_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                       vfloat16m4_t vs1, vfloat16m4_t vs2,
                                       size_t vl);
vfloat16m4_t __riscv_vfmsub_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                       _Float16 rs1, vfloat16m4_t vs2,
                                       size_t vl);
vfloat16m8_t __riscv_vfmsub_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                       vfloat16m8_t vs1, vfloat16m8_t vs2,
                                       size_t vl);
vfloat16m8_t __riscv_vfmsub_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                       _Float16 rs1, vfloat16m8_t vs2,
                                       size_t vl);
vfloat32mf2_t __riscv_vfmsub_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                         vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat32mf2_t __riscv_vfmsub_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                         float rs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat32m1_t __riscv_vfmsub_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                       vfloat32m1_t vs1, vfloat32m1_t vs2,
                                       size_t vl);
vfloat32m1_t __riscv_vfmsub_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd, float rs1,
                                       vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                       vfloat32m2_t vs1, vfloat32m2_t vs2,
                                       size_t vl);
vfloat32m2_t __riscv_vfmsub_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd, float rs1,
                                       vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                       vfloat32m4_t vs1, vfloat32m4_t vs2,
                                       size_t vl);
vfloat32m4_t __riscv_vfmsub_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd, float rs1,
                                       vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                       vfloat32m8_t vs1, vfloat32m8_t vs2,
                                       size_t vl);
vfloat32m8_t __riscv_vfmsub_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd, float rs1,
                                       vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                       vfloat64m1_t vs1, vfloat64m1_t vs2,
                                       size_t vl);
vfloat64m1_t __riscv_vfmsub_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                       double rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                       vfloat64m2_t vs1, vfloat64m2_t vs2,
                                       size_t vl);
vfloat64m2_t __riscv_vfmsub_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                       double rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                       vfloat64m4_t vs1, vfloat64m4_t vs2,
                                       size_t vl);
vfloat64m4_t __riscv_vfmsub_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                       double rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                       vfloat64m8_t vs1, vfloat64m8_t vs2,
                                       size_t vl);
vfloat64m8_t __riscv_vfmsub_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd, double rs1,
                                       vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                          vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat16mf4_t __riscv_vfnmsub_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                          _Float16 rs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat16mf2_t __riscv_vfnmsub_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                          vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat16mf2_t __riscv_vfnmsub_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                          _Float16 rs1, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat16m1_t __riscv_vfnmsub_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                        vfloat16m1_t vs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat16m1_t __riscv_vfnmsub_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                        _Float16 rs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat16m2_t __riscv_vfnmsub_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                        vfloat16m2_t vs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat16m2_t __riscv_vfnmsub_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                        _Float16 rs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat16m4_t __riscv_vfnmsub_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                        vfloat16m4_t vs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat16m4_t __riscv_vfnmsub_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                        _Float16 rs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat16m8_t __riscv_vfnmsub_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                        vfloat16m8_t vs1, vfloat16m8_t vs2,
                                        size_t vl);
vfloat16m8_t __riscv_vfnmsub_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                        _Float16 rs1, vfloat16m8_t vs2,
                                        size_t vl);
vfloat32mf2_t __riscv_vfnmsub_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                          size_t vl);
vfloat32mf2_t __riscv_vfnmsub_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          float rs1, vfloat32mf2_t vs2,
                                          size_t vl);
vfloat32m1_t __riscv_vfnmsub_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        vfloat32m1_t vs1, vfloat32m1_t vs2,
                                        size_t vl);
vfloat32m1_t __riscv_vfnmsub_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        float rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        vfloat32m2_t vs1, vfloat32m2_t vs2,
                                        size_t vl);
vfloat32m2_t __riscv_vfnmsub_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        float rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                        vfloat32m4_t vs1, vfloat32m4_t vs2,
                                        size_t vl);
vfloat32m4_t __riscv_vfnmsub_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd, float rs1,
                                        vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                        vfloat32m8_t vs1, vfloat32m8_t vs2,
                                        size_t vl);
vfloat32m8_t __riscv_vfnmsub_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd, float rs1,
                                        vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        vfloat64m1_t vs1, vfloat64m1_t vs2,
                                        size_t vl);
vfloat64m1_t __riscv_vfnmsub_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        double rs1, vfloat64m1_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfnmsub_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        vfloat64m2_t vs1, vfloat64m2_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfnmsub_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        double rs1, vfloat64m2_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfnmsub_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        vfloat64m4_t vs1, vfloat64m4_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfnmsub_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        double rs1, vfloat64m4_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfnmsub_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                        vfloat64m8_t vs1, vfloat64m8_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfnmsub_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                        double rs1, vfloat64m8_t vs2,
                                        size_t vl);
vfloat16mf4_t __riscv_vfmacc_vv_f16mf4_rm(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                          vfloat16mf4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf4_t __riscv_vfmacc_vf_f16mf4_rm(vfloat16mf4_t vd, _Float16 rs1,
                                          vfloat16mf4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf2_t __riscv_vfmacc_vv_f16mf2_rm(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf2_t __riscv_vfmacc_vf_f16mf2_rm(vfloat16mf2_t vd, _Float16 rs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16m1_t __riscv_vfmacc_vv_f16m1_rm(vfloat16m1_t vd, vfloat16m1_t vs1,
                                        vfloat16m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m1_t __riscv_vfmacc_vf_f16m1_rm(vfloat16m1_t vd, _Float16 rs1,
                                        vfloat16m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m2_t __riscv_vfmacc_vv_f16m2_rm(vfloat16m2_t vd, vfloat16m2_t vs1,
                                        vfloat16m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m2_t __riscv_vfmacc_vf_f16m2_rm(vfloat16m2_t vd, _Float16 rs1,
                                        vfloat16m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m4_t __riscv_vfmacc_vv_f16m4_rm(vfloat16m4_t vd, vfloat16m4_t vs1,
                                        vfloat16m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m4_t __riscv_vfmacc_vf_f16m4_rm(vfloat16m4_t vd, _Float16 rs1,
                                        vfloat16m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m8_t __riscv_vfmacc_vv_f16m8_rm(vfloat16m8_t vd, vfloat16m8_t vs1,
                                        vfloat16m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m8_t __riscv_vfmacc_vf_f16m8_rm(vfloat16m8_t vd, _Float16 rs1,
                                        vfloat16m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32mf2_t __riscv_vfmacc_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32mf2_t __riscv_vfmacc_vf_f32mf2_rm(vfloat32mf2_t vd, float rs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfmacc_vv_f32m1_rm(vfloat32m1_t vd, vfloat32m1_t vs1,
                                        vfloat32m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m1_t __riscv_vfmacc_vf_f32m1_rm(vfloat32m1_t vd, float rs1,
                                        vfloat32m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m2_t __riscv_vfmacc_vv_f32m2_rm(vfloat32m2_t vd, vfloat32m2_t vs1,
                                        vfloat32m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m2_t __riscv_vfmacc_vf_f32m2_rm(vfloat32m2_t vd, float rs1,
                                        vfloat32m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m4_t __riscv_vfmacc_vv_f32m4_rm(vfloat32m4_t vd, vfloat32m4_t vs1,
                                        vfloat32m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m4_t __riscv_vfmacc_vf_f32m4_rm(vfloat32m4_t vd, float rs1,
                                        vfloat32m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m8_t __riscv_vfmacc_vv_f32m8_rm(vfloat32m8_t vd, vfloat32m8_t vs1,
                                        vfloat32m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m8_t __riscv_vfmacc_vf_f32m8_rm(vfloat32m8_t vd, float rs1,
                                        vfloat32m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m1_t __riscv_vfmacc_vv_f64m1_rm(vfloat64m1_t vd, vfloat64m1_t vs1,
                                        vfloat64m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m1_t __riscv_vfmacc_vf_f64m1_rm(vfloat64m1_t vd, double rs1,
                                        vfloat64m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m2_t __riscv_vfmacc_vv_f64m2_rm(vfloat64m2_t vd, vfloat64m2_t vs1,
                                        vfloat64m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m2_t __riscv_vfmacc_vf_f64m2_rm(vfloat64m2_t vd, double rs1,
                                        vfloat64m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m4_t __riscv_vfmacc_vv_f64m4_rm(vfloat64m4_t vd, vfloat64m4_t vs1,
                                        vfloat64m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m4_t __riscv_vfmacc_vf_f64m4_rm(vfloat64m4_t vd, double rs1,
                                        vfloat64m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m8_t __riscv_vfmacc_vv_f64m8_rm(vfloat64m8_t vd, vfloat64m8_t vs1,
                                        vfloat64m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m8_t __riscv_vfmacc_vf_f64m8_rm(vfloat64m8_t vd, double rs1,
                                        vfloat64m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16mf4_t __riscv_vfnmacc_vv_f16mf4_rm(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf4_t __riscv_vfnmacc_vf_f16mf4_rm(vfloat16mf4_t vd, _Float16 rs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfnmacc_vv_f16mf2_rm(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                           vfloat16mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfnmacc_vf_f16mf2_rm(vfloat16mf2_t vd, _Float16 rs1,
                                           vfloat16mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m1_t __riscv_vfnmacc_vv_f16m1_rm(vfloat16m1_t vd, vfloat16m1_t vs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m1_t __riscv_vfnmacc_vf_f16m1_rm(vfloat16m1_t vd, _Float16 rs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfnmacc_vv_f16m2_rm(vfloat16m2_t vd, vfloat16m2_t vs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfnmacc_vf_f16m2_rm(vfloat16m2_t vd, _Float16 rs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfnmacc_vv_f16m4_rm(vfloat16m4_t vd, vfloat16m4_t vs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfnmacc_vf_f16m4_rm(vfloat16m4_t vd, _Float16 rs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfnmacc_vv_f16m8_rm(vfloat16m8_t vd, vfloat16m8_t vs1,
                                         vfloat16m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfnmacc_vf_f16m8_rm(vfloat16m8_t vd, _Float16 rs1,
                                         vfloat16m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32mf2_t __riscv_vfnmacc_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                           vfloat32mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfnmacc_vf_f32mf2_rm(vfloat32mf2_t vd, float rs1,
                                           vfloat32mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m1_t __riscv_vfnmacc_vv_f32m1_rm(vfloat32m1_t vd, vfloat32m1_t vs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfnmacc_vf_f32m1_rm(vfloat32m1_t vd, float rs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfnmacc_vv_f32m2_rm(vfloat32m2_t vd, vfloat32m2_t vs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfnmacc_vf_f32m2_rm(vfloat32m2_t vd, float rs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfnmacc_vv_f32m4_rm(vfloat32m4_t vd, vfloat32m4_t vs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfnmacc_vf_f32m4_rm(vfloat32m4_t vd, float rs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfnmacc_vv_f32m8_rm(vfloat32m8_t vd, vfloat32m8_t vs1,
                                         vfloat32m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfnmacc_vf_f32m8_rm(vfloat32m8_t vd, float rs1,
                                         vfloat32m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfnmacc_vv_f64m1_rm(vfloat64m1_t vd, vfloat64m1_t vs1,
                                         vfloat64m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfnmacc_vf_f64m1_rm(vfloat64m1_t vd, double rs1,
                                         vfloat64m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfnmacc_vv_f64m2_rm(vfloat64m2_t vd, vfloat64m2_t vs1,
                                         vfloat64m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfnmacc_vf_f64m2_rm(vfloat64m2_t vd, double rs1,
                                         vfloat64m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfnmacc_vv_f64m4_rm(vfloat64m4_t vd, vfloat64m4_t vs1,
                                         vfloat64m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfnmacc_vf_f64m4_rm(vfloat64m4_t vd, double rs1,
                                         vfloat64m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfnmacc_vv_f64m8_rm(vfloat64m8_t vd, vfloat64m8_t vs1,
                                         vfloat64m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfnmacc_vf_f64m8_rm(vfloat64m8_t vd, double rs1,
                                         vfloat64m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16mf4_t __riscv_vfmsac_vv_f16mf4_rm(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                          vfloat16mf4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf4_t __riscv_vfmsac_vf_f16mf4_rm(vfloat16mf4_t vd, _Float16 rs1,
                                          vfloat16mf4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf2_t __riscv_vfmsac_vv_f16mf2_rm(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf2_t __riscv_vfmsac_vf_f16mf2_rm(vfloat16mf2_t vd, _Float16 rs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16m1_t __riscv_vfmsac_vv_f16m1_rm(vfloat16m1_t vd, vfloat16m1_t vs1,
                                        vfloat16m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m1_t __riscv_vfmsac_vf_f16m1_rm(vfloat16m1_t vd, _Float16 rs1,
                                        vfloat16m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m2_t __riscv_vfmsac_vv_f16m2_rm(vfloat16m2_t vd, vfloat16m2_t vs1,
                                        vfloat16m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m2_t __riscv_vfmsac_vf_f16m2_rm(vfloat16m2_t vd, _Float16 rs1,
                                        vfloat16m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m4_t __riscv_vfmsac_vv_f16m4_rm(vfloat16m4_t vd, vfloat16m4_t vs1,
                                        vfloat16m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m4_t __riscv_vfmsac_vf_f16m4_rm(vfloat16m4_t vd, _Float16 rs1,
                                        vfloat16m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m8_t __riscv_vfmsac_vv_f16m8_rm(vfloat16m8_t vd, vfloat16m8_t vs1,
                                        vfloat16m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m8_t __riscv_vfmsac_vf_f16m8_rm(vfloat16m8_t vd, _Float16 rs1,
                                        vfloat16m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32mf2_t __riscv_vfmsac_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32mf2_t __riscv_vfmsac_vf_f32mf2_rm(vfloat32mf2_t vd, float rs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfmsac_vv_f32m1_rm(vfloat32m1_t vd, vfloat32m1_t vs1,
                                        vfloat32m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m1_t __riscv_vfmsac_vf_f32m1_rm(vfloat32m1_t vd, float rs1,
                                        vfloat32m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m2_t __riscv_vfmsac_vv_f32m2_rm(vfloat32m2_t vd, vfloat32m2_t vs1,
                                        vfloat32m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m2_t __riscv_vfmsac_vf_f32m2_rm(vfloat32m2_t vd, float rs1,
                                        vfloat32m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m4_t __riscv_vfmsac_vv_f32m4_rm(vfloat32m4_t vd, vfloat32m4_t vs1,
                                        vfloat32m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m4_t __riscv_vfmsac_vf_f32m4_rm(vfloat32m4_t vd, float rs1,
                                        vfloat32m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m8_t __riscv_vfmsac_vv_f32m8_rm(vfloat32m8_t vd, vfloat32m8_t vs1,
                                        vfloat32m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m8_t __riscv_vfmsac_vf_f32m8_rm(vfloat32m8_t vd, float rs1,
                                        vfloat32m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m1_t __riscv_vfmsac_vv_f64m1_rm(vfloat64m1_t vd, vfloat64m1_t vs1,
                                        vfloat64m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m1_t __riscv_vfmsac_vf_f64m1_rm(vfloat64m1_t vd, double rs1,
                                        vfloat64m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m2_t __riscv_vfmsac_vv_f64m2_rm(vfloat64m2_t vd, vfloat64m2_t vs1,
                                        vfloat64m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m2_t __riscv_vfmsac_vf_f64m2_rm(vfloat64m2_t vd, double rs1,
                                        vfloat64m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m4_t __riscv_vfmsac_vv_f64m4_rm(vfloat64m4_t vd, vfloat64m4_t vs1,
                                        vfloat64m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m4_t __riscv_vfmsac_vf_f64m4_rm(vfloat64m4_t vd, double rs1,
                                        vfloat64m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m8_t __riscv_vfmsac_vv_f64m8_rm(vfloat64m8_t vd, vfloat64m8_t vs1,
                                        vfloat64m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m8_t __riscv_vfmsac_vf_f64m8_rm(vfloat64m8_t vd, double rs1,
                                        vfloat64m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16mf4_t __riscv_vfnmsac_vv_f16mf4_rm(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf4_t __riscv_vfnmsac_vf_f16mf4_rm(vfloat16mf4_t vd, _Float16 rs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfnmsac_vv_f16mf2_rm(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                           vfloat16mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfnmsac_vf_f16mf2_rm(vfloat16mf2_t vd, _Float16 rs1,
                                           vfloat16mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m1_t __riscv_vfnmsac_vv_f16m1_rm(vfloat16m1_t vd, vfloat16m1_t vs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m1_t __riscv_vfnmsac_vf_f16m1_rm(vfloat16m1_t vd, _Float16 rs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfnmsac_vv_f16m2_rm(vfloat16m2_t vd, vfloat16m2_t vs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfnmsac_vf_f16m2_rm(vfloat16m2_t vd, _Float16 rs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfnmsac_vv_f16m4_rm(vfloat16m4_t vd, vfloat16m4_t vs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfnmsac_vf_f16m4_rm(vfloat16m4_t vd, _Float16 rs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfnmsac_vv_f16m8_rm(vfloat16m8_t vd, vfloat16m8_t vs1,
                                         vfloat16m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfnmsac_vf_f16m8_rm(vfloat16m8_t vd, _Float16 rs1,
                                         vfloat16m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32mf2_t __riscv_vfnmsac_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                           vfloat32mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfnmsac_vf_f32mf2_rm(vfloat32mf2_t vd, float rs1,
                                           vfloat32mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m1_t __riscv_vfnmsac_vv_f32m1_rm(vfloat32m1_t vd, vfloat32m1_t vs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfnmsac_vf_f32m1_rm(vfloat32m1_t vd, float rs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfnmsac_vv_f32m2_rm(vfloat32m2_t vd, vfloat32m2_t vs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfnmsac_vf_f32m2_rm(vfloat32m2_t vd, float rs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfnmsac_vv_f32m4_rm(vfloat32m4_t vd, vfloat32m4_t vs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfnmsac_vf_f32m4_rm(vfloat32m4_t vd, float rs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfnmsac_vv_f32m8_rm(vfloat32m8_t vd, vfloat32m8_t vs1,
                                         vfloat32m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfnmsac_vf_f32m8_rm(vfloat32m8_t vd, float rs1,
                                         vfloat32m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfnmsac_vv_f64m1_rm(vfloat64m1_t vd, vfloat64m1_t vs1,
                                         vfloat64m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfnmsac_vf_f64m1_rm(vfloat64m1_t vd, double rs1,
                                         vfloat64m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfnmsac_vv_f64m2_rm(vfloat64m2_t vd, vfloat64m2_t vs1,
                                         vfloat64m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfnmsac_vf_f64m2_rm(vfloat64m2_t vd, double rs1,
                                         vfloat64m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfnmsac_vv_f64m4_rm(vfloat64m4_t vd, vfloat64m4_t vs1,
                                         vfloat64m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfnmsac_vf_f64m4_rm(vfloat64m4_t vd, double rs1,
                                         vfloat64m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfnmsac_vv_f64m8_rm(vfloat64m8_t vd, vfloat64m8_t vs1,
                                         vfloat64m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfnmsac_vf_f64m8_rm(vfloat64m8_t vd, double rs1,
                                         vfloat64m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16mf4_t __riscv_vfmadd_vv_f16mf4_rm(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                          vfloat16mf4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf4_t __riscv_vfmadd_vf_f16mf4_rm(vfloat16mf4_t vd, _Float16 rs1,
                                          vfloat16mf4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf2_t __riscv_vfmadd_vv_f16mf2_rm(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf2_t __riscv_vfmadd_vf_f16mf2_rm(vfloat16mf2_t vd, _Float16 rs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16m1_t __riscv_vfmadd_vv_f16m1_rm(vfloat16m1_t vd, vfloat16m1_t vs1,
                                        vfloat16m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m1_t __riscv_vfmadd_vf_f16m1_rm(vfloat16m1_t vd, _Float16 rs1,
                                        vfloat16m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m2_t __riscv_vfmadd_vv_f16m2_rm(vfloat16m2_t vd, vfloat16m2_t vs1,
                                        vfloat16m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m2_t __riscv_vfmadd_vf_f16m2_rm(vfloat16m2_t vd, _Float16 rs1,
                                        vfloat16m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m4_t __riscv_vfmadd_vv_f16m4_rm(vfloat16m4_t vd, vfloat16m4_t vs1,
                                        vfloat16m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m4_t __riscv_vfmadd_vf_f16m4_rm(vfloat16m4_t vd, _Float16 rs1,
                                        vfloat16m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m8_t __riscv_vfmadd_vv_f16m8_rm(vfloat16m8_t vd, vfloat16m8_t vs1,
                                        vfloat16m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m8_t __riscv_vfmadd_vf_f16m8_rm(vfloat16m8_t vd, _Float16 rs1,
                                        vfloat16m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32mf2_t __riscv_vfmadd_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32mf2_t __riscv_vfmadd_vf_f32mf2_rm(vfloat32mf2_t vd, float rs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfmadd_vv_f32m1_rm(vfloat32m1_t vd, vfloat32m1_t vs1,
                                        vfloat32m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m1_t __riscv_vfmadd_vf_f32m1_rm(vfloat32m1_t vd, float rs1,
                                        vfloat32m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m2_t __riscv_vfmadd_vv_f32m2_rm(vfloat32m2_t vd, vfloat32m2_t vs1,
                                        vfloat32m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m2_t __riscv_vfmadd_vf_f32m2_rm(vfloat32m2_t vd, float rs1,
                                        vfloat32m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m4_t __riscv_vfmadd_vv_f32m4_rm(vfloat32m4_t vd, vfloat32m4_t vs1,
                                        vfloat32m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m4_t __riscv_vfmadd_vf_f32m4_rm(vfloat32m4_t vd, float rs1,
                                        vfloat32m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m8_t __riscv_vfmadd_vv_f32m8_rm(vfloat32m8_t vd, vfloat32m8_t vs1,
                                        vfloat32m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m8_t __riscv_vfmadd_vf_f32m8_rm(vfloat32m8_t vd, float rs1,
                                        vfloat32m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m1_t __riscv_vfmadd_vv_f64m1_rm(vfloat64m1_t vd, vfloat64m1_t vs1,
                                        vfloat64m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m1_t __riscv_vfmadd_vf_f64m1_rm(vfloat64m1_t vd, double rs1,
                                        vfloat64m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m2_t __riscv_vfmadd_vv_f64m2_rm(vfloat64m2_t vd, vfloat64m2_t vs1,
                                        vfloat64m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m2_t __riscv_vfmadd_vf_f64m2_rm(vfloat64m2_t vd, double rs1,
                                        vfloat64m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m4_t __riscv_vfmadd_vv_f64m4_rm(vfloat64m4_t vd, vfloat64m4_t vs1,
                                        vfloat64m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m4_t __riscv_vfmadd_vf_f64m4_rm(vfloat64m4_t vd, double rs1,
                                        vfloat64m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m8_t __riscv_vfmadd_vv_f64m8_rm(vfloat64m8_t vd, vfloat64m8_t vs1,
                                        vfloat64m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m8_t __riscv_vfmadd_vf_f64m8_rm(vfloat64m8_t vd, double rs1,
                                        vfloat64m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16mf4_t __riscv_vfnmadd_vv_f16mf4_rm(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf4_t __riscv_vfnmadd_vf_f16mf4_rm(vfloat16mf4_t vd, _Float16 rs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfnmadd_vv_f16mf2_rm(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                           vfloat16mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfnmadd_vf_f16mf2_rm(vfloat16mf2_t vd, _Float16 rs1,
                                           vfloat16mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m1_t __riscv_vfnmadd_vv_f16m1_rm(vfloat16m1_t vd, vfloat16m1_t vs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m1_t __riscv_vfnmadd_vf_f16m1_rm(vfloat16m1_t vd, _Float16 rs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfnmadd_vv_f16m2_rm(vfloat16m2_t vd, vfloat16m2_t vs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfnmadd_vf_f16m2_rm(vfloat16m2_t vd, _Float16 rs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfnmadd_vv_f16m4_rm(vfloat16m4_t vd, vfloat16m4_t vs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfnmadd_vf_f16m4_rm(vfloat16m4_t vd, _Float16 rs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfnmadd_vv_f16m8_rm(vfloat16m8_t vd, vfloat16m8_t vs1,
                                         vfloat16m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfnmadd_vf_f16m8_rm(vfloat16m8_t vd, _Float16 rs1,
                                         vfloat16m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32mf2_t __riscv_vfnmadd_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                           vfloat32mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfnmadd_vf_f32mf2_rm(vfloat32mf2_t vd, float rs1,
                                           vfloat32mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m1_t __riscv_vfnmadd_vv_f32m1_rm(vfloat32m1_t vd, vfloat32m1_t vs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfnmadd_vf_f32m1_rm(vfloat32m1_t vd, float rs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfnmadd_vv_f32m2_rm(vfloat32m2_t vd, vfloat32m2_t vs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfnmadd_vf_f32m2_rm(vfloat32m2_t vd, float rs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfnmadd_vv_f32m4_rm(vfloat32m4_t vd, vfloat32m4_t vs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfnmadd_vf_f32m4_rm(vfloat32m4_t vd, float rs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfnmadd_vv_f32m8_rm(vfloat32m8_t vd, vfloat32m8_t vs1,
                                         vfloat32m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfnmadd_vf_f32m8_rm(vfloat32m8_t vd, float rs1,
                                         vfloat32m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfnmadd_vv_f64m1_rm(vfloat64m1_t vd, vfloat64m1_t vs1,
                                         vfloat64m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfnmadd_vf_f64m1_rm(vfloat64m1_t vd, double rs1,
                                         vfloat64m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfnmadd_vv_f64m2_rm(vfloat64m2_t vd, vfloat64m2_t vs1,
                                         vfloat64m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfnmadd_vf_f64m2_rm(vfloat64m2_t vd, double rs1,
                                         vfloat64m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfnmadd_vv_f64m4_rm(vfloat64m4_t vd, vfloat64m4_t vs1,
                                         vfloat64m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfnmadd_vf_f64m4_rm(vfloat64m4_t vd, double rs1,
                                         vfloat64m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfnmadd_vv_f64m8_rm(vfloat64m8_t vd, vfloat64m8_t vs1,
                                         vfloat64m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfnmadd_vf_f64m8_rm(vfloat64m8_t vd, double rs1,
                                         vfloat64m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16mf4_t __riscv_vfmsub_vv_f16mf4_rm(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                          vfloat16mf4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf4_t __riscv_vfmsub_vf_f16mf4_rm(vfloat16mf4_t vd, _Float16 rs1,
                                          vfloat16mf4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf2_t __riscv_vfmsub_vv_f16mf2_rm(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf2_t __riscv_vfmsub_vf_f16mf2_rm(vfloat16mf2_t vd, _Float16 rs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16m1_t __riscv_vfmsub_vv_f16m1_rm(vfloat16m1_t vd, vfloat16m1_t vs1,
                                        vfloat16m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m1_t __riscv_vfmsub_vf_f16m1_rm(vfloat16m1_t vd, _Float16 rs1,
                                        vfloat16m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m2_t __riscv_vfmsub_vv_f16m2_rm(vfloat16m2_t vd, vfloat16m2_t vs1,
                                        vfloat16m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m2_t __riscv_vfmsub_vf_f16m2_rm(vfloat16m2_t vd, _Float16 rs1,
                                        vfloat16m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m4_t __riscv_vfmsub_vv_f16m4_rm(vfloat16m4_t vd, vfloat16m4_t vs1,
                                        vfloat16m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m4_t __riscv_vfmsub_vf_f16m4_rm(vfloat16m4_t vd, _Float16 rs1,
                                        vfloat16m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m8_t __riscv_vfmsub_vv_f16m8_rm(vfloat16m8_t vd, vfloat16m8_t vs1,
                                        vfloat16m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16m8_t __riscv_vfmsub_vf_f16m8_rm(vfloat16m8_t vd, _Float16 rs1,
                                        vfloat16m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32mf2_t __riscv_vfmsub_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32mf2_t __riscv_vfmsub_vf_f32mf2_rm(vfloat32mf2_t vd, float rs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfmsub_vv_f32m1_rm(vfloat32m1_t vd, vfloat32m1_t vs1,
                                        vfloat32m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m1_t __riscv_vfmsub_vf_f32m1_rm(vfloat32m1_t vd, float rs1,
                                        vfloat32m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m2_t __riscv_vfmsub_vv_f32m2_rm(vfloat32m2_t vd, vfloat32m2_t vs1,
                                        vfloat32m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m2_t __riscv_vfmsub_vf_f32m2_rm(vfloat32m2_t vd, float rs1,
                                        vfloat32m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m4_t __riscv_vfmsub_vv_f32m4_rm(vfloat32m4_t vd, vfloat32m4_t vs1,
                                        vfloat32m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m4_t __riscv_vfmsub_vf_f32m4_rm(vfloat32m4_t vd, float rs1,
                                        vfloat32m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m8_t __riscv_vfmsub_vv_f32m8_rm(vfloat32m8_t vd, vfloat32m8_t vs1,
                                        vfloat32m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat32m8_t __riscv_vfmsub_vf_f32m8_rm(vfloat32m8_t vd, float rs1,
                                        vfloat32m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m1_t __riscv_vfmsub_vv_f64m1_rm(vfloat64m1_t vd, vfloat64m1_t vs1,
                                        vfloat64m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m1_t __riscv_vfmsub_vf_f64m1_rm(vfloat64m1_t vd, double rs1,
                                        vfloat64m1_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m2_t __riscv_vfmsub_vv_f64m2_rm(vfloat64m2_t vd, vfloat64m2_t vs1,
                                        vfloat64m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m2_t __riscv_vfmsub_vf_f64m2_rm(vfloat64m2_t vd, double rs1,
                                        vfloat64m2_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m4_t __riscv_vfmsub_vv_f64m4_rm(vfloat64m4_t vd, vfloat64m4_t vs1,
                                        vfloat64m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m4_t __riscv_vfmsub_vf_f64m4_rm(vfloat64m4_t vd, double rs1,
                                        vfloat64m4_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m8_t __riscv_vfmsub_vv_f64m8_rm(vfloat64m8_t vd, vfloat64m8_t vs1,
                                        vfloat64m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat64m8_t __riscv_vfmsub_vf_f64m8_rm(vfloat64m8_t vd, double rs1,
                                        vfloat64m8_t vs2, unsigned int frm,
                                        size_t vl);
vfloat16mf4_t __riscv_vfnmsub_vv_f16mf4_rm(vfloat16mf4_t vd, vfloat16mf4_t vs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf4_t __riscv_vfnmsub_vf_f16mf4_rm(vfloat16mf4_t vd, _Float16 rs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfnmsub_vv_f16mf2_rm(vfloat16mf2_t vd, vfloat16mf2_t vs1,
                                           vfloat16mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf2_t __riscv_vfnmsub_vf_f16mf2_rm(vfloat16mf2_t vd, _Float16 rs1,
                                           vfloat16mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m1_t __riscv_vfnmsub_vv_f16m1_rm(vfloat16m1_t vd, vfloat16m1_t vs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m1_t __riscv_vfnmsub_vf_f16m1_rm(vfloat16m1_t vd, _Float16 rs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfnmsub_vv_f16m2_rm(vfloat16m2_t vd, vfloat16m2_t vs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m2_t __riscv_vfnmsub_vf_f16m2_rm(vfloat16m2_t vd, _Float16 rs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfnmsub_vv_f16m4_rm(vfloat16m4_t vd, vfloat16m4_t vs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m4_t __riscv_vfnmsub_vf_f16m4_rm(vfloat16m4_t vd, _Float16 rs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfnmsub_vv_f16m8_rm(vfloat16m8_t vd, vfloat16m8_t vs1,
                                         vfloat16m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m8_t __riscv_vfnmsub_vf_f16m8_rm(vfloat16m8_t vd, _Float16 rs1,
                                         vfloat16m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32mf2_t __riscv_vfnmsub_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat32mf2_t vs1,
                                           vfloat32mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfnmsub_vf_f32mf2_rm(vfloat32mf2_t vd, float rs1,
                                           vfloat32mf2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m1_t __riscv_vfnmsub_vv_f32m1_rm(vfloat32m1_t vd, vfloat32m1_t vs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfnmsub_vf_f32m1_rm(vfloat32m1_t vd, float rs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfnmsub_vv_f32m2_rm(vfloat32m2_t vd, vfloat32m2_t vs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfnmsub_vf_f32m2_rm(vfloat32m2_t vd, float rs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfnmsub_vv_f32m4_rm(vfloat32m4_t vd, vfloat32m4_t vs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfnmsub_vf_f32m4_rm(vfloat32m4_t vd, float rs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfnmsub_vv_f32m8_rm(vfloat32m8_t vd, vfloat32m8_t vs1,
                                         vfloat32m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfnmsub_vf_f32m8_rm(vfloat32m8_t vd, float rs1,
                                         vfloat32m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfnmsub_vv_f64m1_rm(vfloat64m1_t vd, vfloat64m1_t vs1,
                                         vfloat64m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfnmsub_vf_f64m1_rm(vfloat64m1_t vd, double rs1,
                                         vfloat64m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfnmsub_vv_f64m2_rm(vfloat64m2_t vd, vfloat64m2_t vs1,
                                         vfloat64m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfnmsub_vf_f64m2_rm(vfloat64m2_t vd, double rs1,
                                         vfloat64m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfnmsub_vv_f64m4_rm(vfloat64m4_t vd, vfloat64m4_t vs1,
                                         vfloat64m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfnmsub_vf_f64m4_rm(vfloat64m4_t vd, double rs1,
                                         vfloat64m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfnmsub_vv_f64m8_rm(vfloat64m8_t vd, vfloat64m8_t vs1,
                                         vfloat64m8_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfnmsub_vf_f64m8_rm(vfloat64m8_t vd, double rs1,
                                         vfloat64m8_t vs2, unsigned int frm,
                                         size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmacc_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                            vfloat16mf4_t vs1,
                                            vfloat16mf4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16mf4_t __riscv_vfmacc_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                            _Float16 rs1, vfloat16mf4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmacc_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                            vfloat16mf2_t vs1,
                                            vfloat16mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16mf2_t __riscv_vfmacc_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                            _Float16 rs1, vfloat16mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmacc_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                          vfloat16m1_t vs1, vfloat16m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmacc_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                          _Float16 rs1, vfloat16m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmacc_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                          vfloat16m2_t vs1, vfloat16m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmacc_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                          _Float16 rs1, vfloat16m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmacc_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                          vfloat16m4_t vs1, vfloat16m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmacc_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                          _Float16 rs1, vfloat16m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmacc_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                          vfloat16m8_t vs1, vfloat16m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmacc_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                          _Float16 rs1, vfloat16m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmacc_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                            vfloat32mf2_t vs1,
                                            vfloat32mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfmacc_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                            float rs1, vfloat32mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmacc_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                          vfloat32m1_t vs1, vfloat32m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmacc_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                          float rs1, vfloat32m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmacc_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                          vfloat32m2_t vs1, vfloat32m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmacc_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                          float rs1, vfloat32m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmacc_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                          vfloat32m4_t vs1, vfloat32m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmacc_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                          float rs1, vfloat32m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmacc_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                          vfloat32m8_t vs1, vfloat32m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmacc_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                          float rs1, vfloat32m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmacc_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                          vfloat64m1_t vs1, vfloat64m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmacc_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                          double rs1, vfloat64m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmacc_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                          vfloat64m2_t vs1, vfloat64m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmacc_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                          double rs1, vfloat64m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmacc_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                          vfloat64m4_t vs1, vfloat64m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmacc_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                          double rs1, vfloat64m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmacc_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                          vfloat64m8_t vs1, vfloat64m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmacc_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                          double rs1, vfloat64m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                             vfloat16mf4_t vs1,
                                             vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                             _Float16 rs1, vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                             vfloat16mf2_t vs1,
                                             vfloat16mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                             _Float16 rs1, vfloat16mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmacc_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                           vfloat16m1_t vs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmacc_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                           _Float16 rs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmacc_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                           vfloat16m2_t vs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmacc_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                           _Float16 rs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmacc_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                           vfloat16m4_t vs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmacc_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                           _Float16 rs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmacc_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                           vfloat16m8_t vs1, vfloat16m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmacc_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                           _Float16 rs1, vfloat16m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             vfloat32mf2_t vs1,
                                             vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             float rs1, vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmacc_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           vfloat32m1_t vs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmacc_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           float rs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmacc_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           vfloat32m2_t vs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmacc_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           float rs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmacc_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           vfloat32m4_t vs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmacc_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           float rs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmacc_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           vfloat32m8_t vs1, vfloat32m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmacc_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           float rs1, vfloat32m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmacc_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           vfloat64m1_t vs1, vfloat64m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmacc_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           double rs1, vfloat64m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmacc_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           vfloat64m2_t vs1, vfloat64m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmacc_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           double rs1, vfloat64m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmacc_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           vfloat64m4_t vs1, vfloat64m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmacc_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           double rs1, vfloat64m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmacc_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           vfloat64m8_t vs1, vfloat64m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmacc_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           double rs1, vfloat64m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsac_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                            vfloat16mf4_t vs1,
                                            vfloat16mf4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16mf4_t __riscv_vfmsac_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                            _Float16 rs1, vfloat16mf4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsac_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                            vfloat16mf2_t vs1,
                                            vfloat16mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16mf2_t __riscv_vfmsac_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                            _Float16 rs1, vfloat16mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsac_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                          vfloat16m1_t vs1, vfloat16m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsac_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                          _Float16 rs1, vfloat16m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsac_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                          vfloat16m2_t vs1, vfloat16m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsac_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                          _Float16 rs1, vfloat16m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsac_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                          vfloat16m4_t vs1, vfloat16m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsac_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                          _Float16 rs1, vfloat16m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsac_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                          vfloat16m8_t vs1, vfloat16m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsac_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                          _Float16 rs1, vfloat16m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsac_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                            vfloat32mf2_t vs1,
                                            vfloat32mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfmsac_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                            float rs1, vfloat32mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsac_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                          vfloat32m1_t vs1, vfloat32m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsac_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                          float rs1, vfloat32m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsac_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                          vfloat32m2_t vs1, vfloat32m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsac_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                          float rs1, vfloat32m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsac_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                          vfloat32m4_t vs1, vfloat32m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsac_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                          float rs1, vfloat32m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsac_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                          vfloat32m8_t vs1, vfloat32m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsac_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                          float rs1, vfloat32m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsac_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                          vfloat64m1_t vs1, vfloat64m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsac_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                          double rs1, vfloat64m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsac_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                          vfloat64m2_t vs1, vfloat64m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsac_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                          double rs1, vfloat64m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsac_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                          vfloat64m4_t vs1, vfloat64m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsac_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                          double rs1, vfloat64m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsac_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                          vfloat64m8_t vs1, vfloat64m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsac_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                          double rs1, vfloat64m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                             vfloat16mf4_t vs1,
                                             vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                             _Float16 rs1, vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                             vfloat16mf2_t vs1,
                                             vfloat16mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                             _Float16 rs1, vfloat16mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsac_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                           vfloat16m1_t vs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsac_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                           _Float16 rs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsac_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                           vfloat16m2_t vs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsac_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                           _Float16 rs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsac_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                           vfloat16m4_t vs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsac_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                           _Float16 rs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsac_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                           vfloat16m8_t vs1, vfloat16m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsac_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                           _Float16 rs1, vfloat16m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             vfloat32mf2_t vs1,
                                             vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             float rs1, vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsac_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           vfloat32m1_t vs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsac_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           float rs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsac_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           vfloat32m2_t vs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsac_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           float rs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsac_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           vfloat32m4_t vs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsac_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           float rs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsac_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           vfloat32m8_t vs1, vfloat32m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsac_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           float rs1, vfloat32m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsac_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           vfloat64m1_t vs1, vfloat64m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsac_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           double rs1, vfloat64m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsac_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           vfloat64m2_t vs1, vfloat64m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsac_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           double rs1, vfloat64m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsac_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           vfloat64m4_t vs1, vfloat64m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsac_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           double rs1, vfloat64m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsac_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           vfloat64m8_t vs1, vfloat64m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsac_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           double rs1, vfloat64m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmadd_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                            vfloat16mf4_t vs1,
                                            vfloat16mf4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16mf4_t __riscv_vfmadd_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                            _Float16 rs1, vfloat16mf4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmadd_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                            vfloat16mf2_t vs1,
                                            vfloat16mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16mf2_t __riscv_vfmadd_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                            _Float16 rs1, vfloat16mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmadd_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                          vfloat16m1_t vs1, vfloat16m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmadd_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                          _Float16 rs1, vfloat16m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmadd_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                          vfloat16m2_t vs1, vfloat16m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmadd_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                          _Float16 rs1, vfloat16m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmadd_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                          vfloat16m4_t vs1, vfloat16m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmadd_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                          _Float16 rs1, vfloat16m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmadd_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                          vfloat16m8_t vs1, vfloat16m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmadd_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                          _Float16 rs1, vfloat16m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmadd_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                            vfloat32mf2_t vs1,
                                            vfloat32mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfmadd_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                            float rs1, vfloat32mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmadd_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                          vfloat32m1_t vs1, vfloat32m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmadd_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                          float rs1, vfloat32m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmadd_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                          vfloat32m2_t vs1, vfloat32m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmadd_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                          float rs1, vfloat32m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmadd_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                          vfloat32m4_t vs1, vfloat32m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmadd_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                          float rs1, vfloat32m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmadd_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                          vfloat32m8_t vs1, vfloat32m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmadd_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                          float rs1, vfloat32m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmadd_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                          vfloat64m1_t vs1, vfloat64m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmadd_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                          double rs1, vfloat64m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmadd_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                          vfloat64m2_t vs1, vfloat64m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmadd_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                          double rs1, vfloat64m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmadd_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                          vfloat64m4_t vs1, vfloat64m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmadd_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                          double rs1, vfloat64m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmadd_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                          vfloat64m8_t vs1, vfloat64m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmadd_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                          double rs1, vfloat64m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                             vfloat16mf4_t vs1,
                                             vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                             _Float16 rs1, vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                             vfloat16mf2_t vs1,
                                             vfloat16mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                             _Float16 rs1, vfloat16mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmadd_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                           vfloat16m1_t vs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmadd_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                           _Float16 rs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmadd_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                           vfloat16m2_t vs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmadd_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                           _Float16 rs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmadd_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                           vfloat16m4_t vs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmadd_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                           _Float16 rs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmadd_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                           vfloat16m8_t vs1, vfloat16m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmadd_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                           _Float16 rs1, vfloat16m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             vfloat32mf2_t vs1,
                                             vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             float rs1, vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmadd_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           vfloat32m1_t vs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmadd_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           float rs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmadd_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           vfloat32m2_t vs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmadd_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           float rs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmadd_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           vfloat32m4_t vs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmadd_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           float rs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmadd_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           vfloat32m8_t vs1, vfloat32m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmadd_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           float rs1, vfloat32m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmadd_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           vfloat64m1_t vs1, vfloat64m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmadd_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           double rs1, vfloat64m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmadd_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           vfloat64m2_t vs1, vfloat64m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmadd_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           double rs1, vfloat64m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmadd_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           vfloat64m4_t vs1, vfloat64m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmadd_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           double rs1, vfloat64m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmadd_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           vfloat64m8_t vs1, vfloat64m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmadd_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           double rs1, vfloat64m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsub_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                            vfloat16mf4_t vs1,
                                            vfloat16mf4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16mf4_t __riscv_vfmsub_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                            _Float16 rs1, vfloat16mf4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsub_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                            vfloat16mf2_t vs1,
                                            vfloat16mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16mf2_t __riscv_vfmsub_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                            _Float16 rs1, vfloat16mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsub_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                          vfloat16m1_t vs1, vfloat16m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsub_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                          _Float16 rs1, vfloat16m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsub_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                          vfloat16m2_t vs1, vfloat16m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsub_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                          _Float16 rs1, vfloat16m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsub_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                          vfloat16m4_t vs1, vfloat16m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsub_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                          _Float16 rs1, vfloat16m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsub_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                          vfloat16m8_t vs1, vfloat16m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsub_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                          _Float16 rs1, vfloat16m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsub_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                            vfloat32mf2_t vs1,
                                            vfloat32mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfmsub_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                            float rs1, vfloat32mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsub_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                          vfloat32m1_t vs1, vfloat32m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsub_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                          float rs1, vfloat32m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsub_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                          vfloat32m2_t vs1, vfloat32m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsub_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                          float rs1, vfloat32m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsub_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                          vfloat32m4_t vs1, vfloat32m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsub_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                          float rs1, vfloat32m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsub_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                          vfloat32m8_t vs1, vfloat32m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsub_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                          float rs1, vfloat32m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsub_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                          vfloat64m1_t vs1, vfloat64m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsub_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                          double rs1, vfloat64m1_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsub_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                          vfloat64m2_t vs1, vfloat64m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsub_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                          double rs1, vfloat64m2_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsub_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                          vfloat64m4_t vs1, vfloat64m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsub_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                          double rs1, vfloat64m4_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsub_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                          vfloat64m8_t vs1, vfloat64m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsub_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                          double rs1, vfloat64m8_t vs2,
                                          unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_vv_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                             vfloat16mf4_t vs1,
                                             vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_vf_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vd,
                                             _Float16 rs1, vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_vv_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                             vfloat16mf2_t vs1,
                                             vfloat16mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_vf_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vd,
                                             _Float16 rs1, vfloat16mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsub_vv_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                           vfloat16m1_t vs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsub_vf_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vd,
                                           _Float16 rs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsub_vv_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                           vfloat16m2_t vs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsub_vf_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vd,
                                           _Float16 rs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsub_vv_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                           vfloat16m4_t vs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsub_vf_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vd,
                                           _Float16 rs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsub_vv_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                           vfloat16m8_t vs1, vfloat16m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsub_vf_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vd,
                                           _Float16 rs1, vfloat16m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             vfloat32mf2_t vs1,
                                             vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             float rs1, vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsub_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           vfloat32m1_t vs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsub_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           float rs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsub_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           vfloat32m2_t vs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsub_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           float rs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsub_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           vfloat32m4_t vs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsub_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           float rs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsub_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           vfloat32m8_t vs1, vfloat32m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsub_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           float rs1, vfloat32m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsub_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           vfloat64m1_t vs1, vfloat64m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsub_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           double rs1, vfloat64m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsub_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           vfloat64m2_t vs1, vfloat64m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsub_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           double rs1, vfloat64m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsub_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           vfloat64m4_t vs1, vfloat64m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsub_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           double rs1, vfloat64m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsub_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           vfloat64m8_t vs1, vfloat64m8_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsub_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           double rs1, vfloat64m8_t vs2,
                                           unsigned int frm, size_t vl);
----

[[vector-widening-floating-point-fused-multiply-add]]
==== Vector Widening Floating-Point Fused Multiply-Add Intrinsics

[,c]
----
vfloat32mf2_t __riscv_vfwmacc_vv_f32mf2(vfloat32mf2_t vd, vfloat16mf4_t vs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_vf_f32mf2(vfloat32mf2_t vd, _Float16 vs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmacc_vv_f32m1(vfloat32m1_t vd, vfloat16mf2_t vs1,
                                      vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmacc_vf_f32m1(vfloat32m1_t vd, _Float16 vs1,
                                      vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmacc_vv_f32m2(vfloat32m2_t vd, vfloat16m1_t vs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmacc_vf_f32m2(vfloat32m2_t vd, _Float16 vs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmacc_vv_f32m4(vfloat32m4_t vd, vfloat16m2_t vs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmacc_vf_f32m4(vfloat32m4_t vd, _Float16 vs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmacc_vv_f32m8(vfloat32m8_t vd, vfloat16m4_t vs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmacc_vf_f32m8(vfloat32m8_t vd, _Float16 vs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmacc_vv_f64m1(vfloat64m1_t vd, vfloat32mf2_t vs1,
                                      vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmacc_vf_f64m1(vfloat64m1_t vd, float vs1,
                                      vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmacc_vv_f64m2(vfloat64m2_t vd, vfloat32m1_t vs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmacc_vf_f64m2(vfloat64m2_t vd, float vs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_vv_f64m4(vfloat64m4_t vd, vfloat32m2_t vs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_vf_f64m4(vfloat64m4_t vd, float vs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_vv_f64m8(vfloat64m8_t vd, vfloat32m4_t vs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_vf_f64m8(vfloat64m8_t vd, float vs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_vv_f32mf2(vfloat32mf2_t vd, vfloat16mf4_t vs1,
                                         vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_vf_f32mf2(vfloat32mf2_t vd, _Float16 vs1,
                                         vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_vv_f32m1(vfloat32m1_t vd, vfloat16mf2_t vs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_vf_f32m1(vfloat32m1_t vd, _Float16 vs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_vv_f32m2(vfloat32m2_t vd, vfloat16m1_t vs1,
                                       vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_vf_f32m2(vfloat32m2_t vd, _Float16 vs1,
                                       vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_vv_f32m4(vfloat32m4_t vd, vfloat16m2_t vs1,
                                       vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_vf_f32m4(vfloat32m4_t vd, _Float16 vs1,
                                       vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_vv_f32m8(vfloat32m8_t vd, vfloat16m4_t vs1,
                                       vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_vf_f32m8(vfloat32m8_t vd, _Float16 vs1,
                                       vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_vv_f64m1(vfloat64m1_t vd, vfloat32mf2_t vs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_vf_f64m1(vfloat64m1_t vd, float vs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_vv_f64m2(vfloat64m2_t vd, vfloat32m1_t vs1,
                                       vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_vf_f64m2(vfloat64m2_t vd, float vs1,
                                       vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_vv_f64m4(vfloat64m4_t vd, vfloat32m2_t vs1,
                                       vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_vf_f64m4(vfloat64m4_t vd, float vs1,
                                       vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_vv_f64m8(vfloat64m8_t vd, vfloat32m4_t vs1,
                                       vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_vf_f64m8(vfloat64m8_t vd, float vs1,
                                       vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_vv_f32mf2(vfloat32mf2_t vd, vfloat16mf4_t vs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_vf_f32mf2(vfloat32mf2_t vd, _Float16 vs1,
                                        vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmsac_vv_f32m1(vfloat32m1_t vd, vfloat16mf2_t vs1,
                                      vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmsac_vf_f32m1(vfloat32m1_t vd, _Float16 vs1,
                                      vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmsac_vv_f32m2(vfloat32m2_t vd, vfloat16m1_t vs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmsac_vf_f32m2(vfloat32m2_t vd, _Float16 vs1,
                                      vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmsac_vv_f32m4(vfloat32m4_t vd, vfloat16m2_t vs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmsac_vf_f32m4(vfloat32m4_t vd, _Float16 vs1,
                                      vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmsac_vv_f32m8(vfloat32m8_t vd, vfloat16m4_t vs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmsac_vf_f32m8(vfloat32m8_t vd, _Float16 vs1,
                                      vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmsac_vv_f64m1(vfloat64m1_t vd, vfloat32mf2_t vs1,
                                      vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmsac_vf_f64m1(vfloat64m1_t vd, float vs1,
                                      vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmsac_vv_f64m2(vfloat64m2_t vd, vfloat32m1_t vs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmsac_vf_f64m2(vfloat64m2_t vd, float vs1,
                                      vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_vv_f64m4(vfloat64m4_t vd, vfloat32m2_t vs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_vf_f64m4(vfloat64m4_t vd, float vs1,
                                      vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_vv_f64m8(vfloat64m8_t vd, vfloat32m4_t vs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_vf_f64m8(vfloat64m8_t vd, float vs1,
                                      vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_vv_f32mf2(vfloat32mf2_t vd, vfloat16mf4_t vs1,
                                         vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_vf_f32mf2(vfloat32mf2_t vd, _Float16 vs1,
                                         vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_vv_f32m1(vfloat32m1_t vd, vfloat16mf2_t vs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_vf_f32m1(vfloat32m1_t vd, _Float16 vs1,
                                       vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_vv_f32m2(vfloat32m2_t vd, vfloat16m1_t vs1,
                                       vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_vf_f32m2(vfloat32m2_t vd, _Float16 vs1,
                                       vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_vv_f32m4(vfloat32m4_t vd, vfloat16m2_t vs1,
                                       vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_vf_f32m4(vfloat32m4_t vd, _Float16 vs1,
                                       vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_vv_f32m8(vfloat32m8_t vd, vfloat16m4_t vs1,
                                       vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_vf_f32m8(vfloat32m8_t vd, _Float16 vs1,
                                       vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_vv_f64m1(vfloat64m1_t vd, vfloat32mf2_t vs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_vf_f64m1(vfloat64m1_t vd, float vs1,
                                       vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_vv_f64m2(vfloat64m2_t vd, vfloat32m1_t vs1,
                                       vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_vf_f64m2(vfloat64m2_t vd, float vs1,
                                       vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_vv_f64m4(vfloat64m4_t vd, vfloat32m2_t vs1,
                                       vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_vf_f64m4(vfloat64m4_t vd, float vs1,
                                       vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_vv_f64m8(vfloat64m8_t vd, vfloat32m4_t vs1,
                                       vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_vf_f64m8(vfloat64m8_t vd, float vs1,
                                       vfloat32m4_t vs2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmacc_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat32mf2_t __riscv_vfwmacc_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          _Float16 vs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat32m1_t __riscv_vfwmacc_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                        size_t vl);
vfloat32m1_t __riscv_vfwmacc_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        _Float16 vs1, vfloat16mf2_t vs2,
                                        size_t vl);
vfloat32m2_t __riscv_vfwmacc_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        vfloat16m1_t vs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat32m2_t __riscv_vfwmacc_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        _Float16 vs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat32m4_t __riscv_vfwmacc_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                        vfloat16m2_t vs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat32m4_t __riscv_vfwmacc_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                        _Float16 vs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat32m8_t __riscv_vfwmacc_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                        vfloat16m4_t vs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat32m8_t __riscv_vfwmacc_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                        _Float16 vs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat64m1_t __riscv_vfwmacc_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                        size_t vl);
vfloat64m1_t __riscv_vfwmacc_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        float vs1, vfloat32mf2_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfwmacc_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        vfloat32m1_t vs1, vfloat32m1_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfwmacc_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        float vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        vfloat32m2_t vs1, vfloat32m2_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfwmacc_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        float vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                        vfloat32m4_t vs1, vfloat32m4_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfwmacc_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd, float vs1,
                                        vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                           vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                           size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                           _Float16 vs1, vfloat16mf4_t vs2,
                                           size_t vl);
vfloat32m1_t __riscv_vfwnmacc_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                         vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat32m1_t __riscv_vfwnmacc_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                         _Float16 vs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat32m2_t __riscv_vfwnmacc_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                         vfloat16m1_t vs1, vfloat16m1_t vs2,
                                         size_t vl);
vfloat32m2_t __riscv_vfwnmacc_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                         _Float16 vs1, vfloat16m1_t vs2,
                                         size_t vl);
vfloat32m4_t __riscv_vfwnmacc_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                         vfloat16m2_t vs1, vfloat16m2_t vs2,
                                         size_t vl);
vfloat32m4_t __riscv_vfwnmacc_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                         _Float16 vs1, vfloat16m2_t vs2,
                                         size_t vl);
vfloat32m8_t __riscv_vfwnmacc_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                         vfloat16m4_t vs1, vfloat16m4_t vs2,
                                         size_t vl);
vfloat32m8_t __riscv_vfwnmacc_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                         _Float16 vs1, vfloat16m4_t vs2,
                                         size_t vl);
vfloat64m1_t __riscv_vfwnmacc_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                         vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat64m1_t __riscv_vfwnmacc_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                         float vs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat64m2_t __riscv_vfwnmacc_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                         vfloat32m1_t vs1, vfloat32m1_t vs2,
                                         size_t vl);
vfloat64m2_t __riscv_vfwnmacc_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                         float vs1, vfloat32m1_t vs2,
                                         size_t vl);
vfloat64m4_t __riscv_vfwnmacc_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                         vfloat32m2_t vs1, vfloat32m2_t vs2,
                                         size_t vl);
vfloat64m4_t __riscv_vfwnmacc_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                         float vs1, vfloat32m2_t vs2,
                                         size_t vl);
vfloat64m8_t __riscv_vfwnmacc_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                         vfloat32m4_t vs1, vfloat32m4_t vs2,
                                         size_t vl);
vfloat64m8_t __riscv_vfwnmacc_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                         float vs1, vfloat32m4_t vs2,
                                         size_t vl);
vfloat32mf2_t __riscv_vfwmsac_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat32mf2_t __riscv_vfwmsac_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                          _Float16 vs1, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat32m1_t __riscv_vfwmsac_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                        size_t vl);
vfloat32m1_t __riscv_vfwmsac_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                        _Float16 vs1, vfloat16mf2_t vs2,
                                        size_t vl);
vfloat32m2_t __riscv_vfwmsac_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        vfloat16m1_t vs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat32m2_t __riscv_vfwmsac_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                        _Float16 vs1, vfloat16m1_t vs2,
                                        size_t vl);
vfloat32m4_t __riscv_vfwmsac_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                        vfloat16m2_t vs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat32m4_t __riscv_vfwmsac_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                        _Float16 vs1, vfloat16m2_t vs2,
                                        size_t vl);
vfloat32m8_t __riscv_vfwmsac_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                        vfloat16m4_t vs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat32m8_t __riscv_vfwmsac_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                        _Float16 vs1, vfloat16m4_t vs2,
                                        size_t vl);
vfloat64m1_t __riscv_vfwmsac_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                        size_t vl);
vfloat64m1_t __riscv_vfwmsac_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                        float vs1, vfloat32mf2_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfwmsac_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        vfloat32m1_t vs1, vfloat32m1_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfwmsac_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                        float vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        vfloat32m2_t vs1, vfloat32m2_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfwmsac_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                        float vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                        vfloat32m4_t vs1, vfloat32m4_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfwmsac_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd, float vs1,
                                        vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                           vfloat16mf4_t vs1, vfloat16mf4_t vs2,
                                           size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                           _Float16 vs1, vfloat16mf4_t vs2,
                                           size_t vl);
vfloat32m1_t __riscv_vfwnmsac_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                         vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat32m1_t __riscv_vfwnmsac_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                         _Float16 vs1, vfloat16mf2_t vs2,
                                         size_t vl);
vfloat32m2_t __riscv_vfwnmsac_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                         vfloat16m1_t vs1, vfloat16m1_t vs2,
                                         size_t vl);
vfloat32m2_t __riscv_vfwnmsac_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                         _Float16 vs1, vfloat16m1_t vs2,
                                         size_t vl);
vfloat32m4_t __riscv_vfwnmsac_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                         vfloat16m2_t vs1, vfloat16m2_t vs2,
                                         size_t vl);
vfloat32m4_t __riscv_vfwnmsac_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                         _Float16 vs1, vfloat16m2_t vs2,
                                         size_t vl);
vfloat32m8_t __riscv_vfwnmsac_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                         vfloat16m4_t vs1, vfloat16m4_t vs2,
                                         size_t vl);
vfloat32m8_t __riscv_vfwnmsac_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                         _Float16 vs1, vfloat16m4_t vs2,
                                         size_t vl);
vfloat64m1_t __riscv_vfwnmsac_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                         vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat64m1_t __riscv_vfwnmsac_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                         float vs1, vfloat32mf2_t vs2,
                                         size_t vl);
vfloat64m2_t __riscv_vfwnmsac_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                         vfloat32m1_t vs1, vfloat32m1_t vs2,
                                         size_t vl);
vfloat64m2_t __riscv_vfwnmsac_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                         float vs1, vfloat32m1_t vs2,
                                         size_t vl);
vfloat64m4_t __riscv_vfwnmsac_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                         vfloat32m2_t vs1, vfloat32m2_t vs2,
                                         size_t vl);
vfloat64m4_t __riscv_vfwnmsac_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                         float vs1, vfloat32m2_t vs2,
                                         size_t vl);
vfloat64m8_t __riscv_vfwnmsac_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                         vfloat32m4_t vs1, vfloat32m4_t vs2,
                                         size_t vl);
vfloat64m8_t __riscv_vfwnmsac_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                         float vs1, vfloat32m4_t vs2,
                                         size_t vl);
vfloat32mf2_t __riscv_vfwmacc_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat16mf4_t vs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfwmacc_vf_f32mf2_rm(vfloat32mf2_t vd, _Float16 vs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m1_t __riscv_vfwmacc_vv_f32m1_rm(vfloat32m1_t vd, vfloat16mf2_t vs1,
                                         vfloat16mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfwmacc_vf_f32m1_rm(vfloat32m1_t vd, _Float16 vs1,
                                         vfloat16mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfwmacc_vv_f32m2_rm(vfloat32m2_t vd, vfloat16m1_t vs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfwmacc_vf_f32m2_rm(vfloat32m2_t vd, _Float16 vs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfwmacc_vv_f32m4_rm(vfloat32m4_t vd, vfloat16m2_t vs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfwmacc_vf_f32m4_rm(vfloat32m4_t vd, _Float16 vs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfwmacc_vv_f32m8_rm(vfloat32m8_t vd, vfloat16m4_t vs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfwmacc_vf_f32m8_rm(vfloat32m8_t vd, _Float16 vs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfwmacc_vv_f64m1_rm(vfloat64m1_t vd, vfloat32mf2_t vs1,
                                         vfloat32mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfwmacc_vf_f64m1_rm(vfloat64m1_t vd, float vs1,
                                         vfloat32mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfwmacc_vv_f64m2_rm(vfloat64m2_t vd, vfloat32m1_t vs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfwmacc_vf_f64m2_rm(vfloat64m2_t vd, float vs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfwmacc_vv_f64m4_rm(vfloat64m4_t vd, vfloat32m2_t vs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfwmacc_vf_f64m4_rm(vfloat64m4_t vd, float vs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfwmacc_vv_f64m8_rm(vfloat64m8_t vd, vfloat32m4_t vs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfwmacc_vf_f64m8_rm(vfloat64m8_t vd, float vs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat16mf4_t vs1,
                                            vfloat16mf4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_vf_f32mf2_rm(vfloat32mf2_t vd, _Float16 vs1,
                                            vfloat16mf4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32m1_t __riscv_vfwnmacc_vv_f32m1_rm(vfloat32m1_t vd, vfloat16mf2_t vs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfwnmacc_vf_f32m1_rm(vfloat32m1_t vd, _Float16 vs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwnmacc_vv_f32m2_rm(vfloat32m2_t vd, vfloat16m1_t vs1,
                                          vfloat16m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwnmacc_vf_f32m2_rm(vfloat32m2_t vd, _Float16 vs1,
                                          vfloat16m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwnmacc_vv_f32m4_rm(vfloat32m4_t vd, vfloat16m2_t vs1,
                                          vfloat16m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwnmacc_vf_f32m4_rm(vfloat32m4_t vd, _Float16 vs1,
                                          vfloat16m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwnmacc_vv_f32m8_rm(vfloat32m8_t vd, vfloat16m4_t vs1,
                                          vfloat16m4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwnmacc_vf_f32m8_rm(vfloat32m8_t vd, _Float16 vs1,
                                          vfloat16m4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwnmacc_vv_f64m1_rm(vfloat64m1_t vd, vfloat32mf2_t vs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwnmacc_vf_f64m1_rm(vfloat64m1_t vd, float vs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwnmacc_vv_f64m2_rm(vfloat64m2_t vd, vfloat32m1_t vs1,
                                          vfloat32m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwnmacc_vf_f64m2_rm(vfloat64m2_t vd, float vs1,
                                          vfloat32m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwnmacc_vv_f64m4_rm(vfloat64m4_t vd, vfloat32m2_t vs1,
                                          vfloat32m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwnmacc_vf_f64m4_rm(vfloat64m4_t vd, float vs1,
                                          vfloat32m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwnmacc_vv_f64m8_rm(vfloat64m8_t vd, vfloat32m4_t vs1,
                                          vfloat32m4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwnmacc_vf_f64m8_rm(vfloat64m8_t vd, float vs1,
                                          vfloat32m4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32mf2_t __riscv_vfwmsac_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat16mf4_t vs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfwmsac_vf_f32mf2_rm(vfloat32mf2_t vd, _Float16 vs1,
                                           vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m1_t __riscv_vfwmsac_vv_f32m1_rm(vfloat32m1_t vd, vfloat16mf2_t vs1,
                                         vfloat16mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfwmsac_vf_f32m1_rm(vfloat32m1_t vd, _Float16 vs1,
                                         vfloat16mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfwmsac_vv_f32m2_rm(vfloat32m2_t vd, vfloat16m1_t vs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m2_t __riscv_vfwmsac_vf_f32m2_rm(vfloat32m2_t vd, _Float16 vs1,
                                         vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfwmsac_vv_f32m4_rm(vfloat32m4_t vd, vfloat16m2_t vs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m4_t __riscv_vfwmsac_vf_f32m4_rm(vfloat32m4_t vd, _Float16 vs1,
                                         vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfwmsac_vv_f32m8_rm(vfloat32m8_t vd, vfloat16m4_t vs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m8_t __riscv_vfwmsac_vf_f32m8_rm(vfloat32m8_t vd, _Float16 vs1,
                                         vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfwmsac_vv_f64m1_rm(vfloat64m1_t vd, vfloat32mf2_t vs1,
                                         vfloat32mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m1_t __riscv_vfwmsac_vf_f64m1_rm(vfloat64m1_t vd, float vs1,
                                         vfloat32mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfwmsac_vv_f64m2_rm(vfloat64m2_t vd, vfloat32m1_t vs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m2_t __riscv_vfwmsac_vf_f64m2_rm(vfloat64m2_t vd, float vs1,
                                         vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfwmsac_vv_f64m4_rm(vfloat64m4_t vd, vfloat32m2_t vs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m4_t __riscv_vfwmsac_vf_f64m4_rm(vfloat64m4_t vd, float vs1,
                                         vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfwmsac_vv_f64m8_rm(vfloat64m8_t vd, vfloat32m4_t vs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat64m8_t __riscv_vfwmsac_vf_f64m8_rm(vfloat64m8_t vd, float vs1,
                                         vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_vv_f32mf2_rm(vfloat32mf2_t vd, vfloat16mf4_t vs1,
                                            vfloat16mf4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_vf_f32mf2_rm(vfloat32mf2_t vd, _Float16 vs1,
                                            vfloat16mf4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32m1_t __riscv_vfwnmsac_vv_f32m1_rm(vfloat32m1_t vd, vfloat16mf2_t vs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m1_t __riscv_vfwnmsac_vf_f32m1_rm(vfloat32m1_t vd, _Float16 vs1,
                                          vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwnmsac_vv_f32m2_rm(vfloat32m2_t vd, vfloat16m1_t vs1,
                                          vfloat16m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfwnmsac_vf_f32m2_rm(vfloat32m2_t vd, _Float16 vs1,
                                          vfloat16m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwnmsac_vv_f32m4_rm(vfloat32m4_t vd, vfloat16m2_t vs1,
                                          vfloat16m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfwnmsac_vf_f32m4_rm(vfloat32m4_t vd, _Float16 vs1,
                                          vfloat16m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwnmsac_vv_f32m8_rm(vfloat32m8_t vd, vfloat16m4_t vs1,
                                          vfloat16m4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfwnmsac_vf_f32m8_rm(vfloat32m8_t vd, _Float16 vs1,
                                          vfloat16m4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwnmsac_vv_f64m1_rm(vfloat64m1_t vd, vfloat32mf2_t vs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfwnmsac_vf_f64m1_rm(vfloat64m1_t vd, float vs1,
                                          vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwnmsac_vv_f64m2_rm(vfloat64m2_t vd, vfloat32m1_t vs1,
                                          vfloat32m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfwnmsac_vf_f64m2_rm(vfloat64m2_t vd, float vs1,
                                          vfloat32m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwnmsac_vv_f64m4_rm(vfloat64m4_t vd, vfloat32m2_t vs1,
                                          vfloat32m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfwnmsac_vf_f64m4_rm(vfloat64m4_t vd, float vs1,
                                          vfloat32m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwnmsac_vv_f64m8_rm(vfloat64m8_t vd, vfloat32m4_t vs1,
                                          vfloat32m4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfwnmsac_vf_f64m8_rm(vfloat64m8_t vd, float vs1,
                                          vfloat32m4_t vs2, unsigned int frm,
                                          size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmacc_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             vfloat16mf4_t vs1,
                                             vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             _Float16 vs1, vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmacc_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmacc_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           _Float16 vs1, vfloat16mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmacc_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           vfloat16m1_t vs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmacc_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           _Float16 vs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmacc_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           vfloat16m2_t vs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmacc_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           _Float16 vs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmacc_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           vfloat16m4_t vs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmacc_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           _Float16 vs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmacc_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmacc_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           float vs1, vfloat32mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmacc_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           vfloat32m1_t vs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmacc_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           float vs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmacc_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           vfloat32m2_t vs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmacc_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           float vs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmacc_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           vfloat32m4_t vs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmacc_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           float vs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                              vfloat16mf4_t vs1,
                                              vfloat16mf4_t vs2,
                                              unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                              _Float16 vs1, vfloat16mf4_t vs2,
                                              unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                            vfloat16mf2_t vs1,
                                            vfloat16mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32m1_t __riscv_vfwnmacc_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                            _Float16 vs1, vfloat16mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                            vfloat16m1_t vs1, vfloat16m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                            _Float16 vs1, vfloat16m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                            vfloat16m2_t vs1, vfloat16m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                            _Float16 vs1, vfloat16m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                            vfloat16m4_t vs1, vfloat16m4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                            _Float16 vs1, vfloat16m4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                            vfloat32mf2_t vs1,
                                            vfloat32mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat64m1_t __riscv_vfwnmacc_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                            float vs1, vfloat32mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                            vfloat32m1_t vs1, vfloat32m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                            float vs1, vfloat32m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                            vfloat32m2_t vs1, vfloat32m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                            float vs1, vfloat32m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                            vfloat32m4_t vs1, vfloat32m4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                            float vs1, vfloat32m4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             vfloat16mf4_t vs1,
                                             vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                             _Float16 vs1, vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmsac_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           vfloat16mf2_t vs1, vfloat16mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmsac_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                           _Float16 vs1, vfloat16mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmsac_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           vfloat16m1_t vs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmsac_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                           _Float16 vs1, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmsac_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           vfloat16m2_t vs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmsac_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                           _Float16 vs1, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmsac_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           vfloat16m4_t vs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmsac_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                           _Float16 vs1, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmsac_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           vfloat32mf2_t vs1, vfloat32mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmsac_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                           float vs1, vfloat32mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmsac_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           vfloat32m1_t vs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmsac_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                           float vs1, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmsac_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           vfloat32m2_t vs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmsac_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                           float vs1, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmsac_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           vfloat32m4_t vs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmsac_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                           float vs1, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_vv_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                              vfloat16mf4_t vs1,
                                              vfloat16mf4_t vs2,
                                              unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_vf_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vd,
                                              _Float16 vs1, vfloat16mf4_t vs2,
                                              unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_vv_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                            vfloat16mf2_t vs1,
                                            vfloat16mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32m1_t __riscv_vfwnmsac_vf_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vd,
                                            _Float16 vs1, vfloat16mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_vv_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                            vfloat16m1_t vs1, vfloat16m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_vf_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vd,
                                            _Float16 vs1, vfloat16m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_vv_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                            vfloat16m2_t vs1, vfloat16m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_vf_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vd,
                                            _Float16 vs1, vfloat16m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_vv_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                            vfloat16m4_t vs1, vfloat16m4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_vf_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vd,
                                            _Float16 vs1, vfloat16m4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_vv_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                            vfloat32mf2_t vs1,
                                            vfloat32mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat64m1_t __riscv_vfwnmsac_vf_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vd,
                                            float vs1, vfloat32mf2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_vv_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                            vfloat32m1_t vs1, vfloat32m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_vf_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vd,
                                            float vs1, vfloat32m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_vv_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                            vfloat32m2_t vs1, vfloat32m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_vf_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vd,
                                            float vs1, vfloat32m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_vv_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                            vfloat32m4_t vs1, vfloat32m4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_vf_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vd,
                                            float vs1, vfloat32m4_t vs2,
                                            unsigned int frm, size_t vl);
----

[[vector-floating-point-square-root]]
==== Vector Floating-Point Square-Root Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfsqrt_v_f16mf4(vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfsqrt_v_f16mf2(vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfsqrt_v_f16m1(vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfsqrt_v_f16m2(vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfsqrt_v_f16m4(vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfsqrt_v_f16m8(vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_v_f32mf2(vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfsqrt_v_f32m1(vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfsqrt_v_f32m2(vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfsqrt_v_f32m4(vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfsqrt_v_f32m8(vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfsqrt_v_f64m1(vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfsqrt_v_f64m2(vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfsqrt_v_f64m4(vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfsqrt_v_f64m8(vfloat64m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsqrt_v_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vfsqrt_v_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        size_t vl);
vfloat16m1_t __riscv_vfsqrt_v_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      size_t vl);
vfloat16m2_t __riscv_vfsqrt_v_f16m2_m(vbool8_t vm, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfsqrt_v_f16m4_m(vbool4_t vm, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfsqrt_v_f16m8_m(vbool2_t vm, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_v_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        size_t vl);
vfloat32m1_t __riscv_vfsqrt_v_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                      size_t vl);
vfloat32m2_t __riscv_vfsqrt_v_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                      size_t vl);
vfloat32m4_t __riscv_vfsqrt_v_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfsqrt_v_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfsqrt_v_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      size_t vl);
vfloat64m2_t __riscv_vfsqrt_v_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      size_t vl);
vfloat64m4_t __riscv_vfsqrt_v_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      size_t vl);
vfloat64m8_t __riscv_vfsqrt_v_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfsqrt_v_f16mf4_rm(vfloat16mf4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16mf2_t __riscv_vfsqrt_v_f16mf2_rm(vfloat16mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m1_t __riscv_vfsqrt_v_f16m1_rm(vfloat16m1_t vs2, unsigned int frm,
                                       size_t vl);
vfloat16m2_t __riscv_vfsqrt_v_f16m2_rm(vfloat16m2_t vs2, unsigned int frm,
                                       size_t vl);
vfloat16m4_t __riscv_vfsqrt_v_f16m4_rm(vfloat16m4_t vs2, unsigned int frm,
                                       size_t vl);
vfloat16m8_t __riscv_vfsqrt_v_f16m8_rm(vfloat16m8_t vs2, unsigned int frm,
                                       size_t vl);
vfloat32mf2_t __riscv_vfsqrt_v_f32mf2_rm(vfloat32mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfsqrt_v_f32m1_rm(vfloat32m1_t vs2, unsigned int frm,
                                       size_t vl);
vfloat32m2_t __riscv_vfsqrt_v_f32m2_rm(vfloat32m2_t vs2, unsigned int frm,
                                       size_t vl);
vfloat32m4_t __riscv_vfsqrt_v_f32m4_rm(vfloat32m4_t vs2, unsigned int frm,
                                       size_t vl);
vfloat32m8_t __riscv_vfsqrt_v_f32m8_rm(vfloat32m8_t vs2, unsigned int frm,
                                       size_t vl);
vfloat64m1_t __riscv_vfsqrt_v_f64m1_rm(vfloat64m1_t vs2, unsigned int frm,
                                       size_t vl);
vfloat64m2_t __riscv_vfsqrt_v_f64m2_rm(vfloat64m2_t vs2, unsigned int frm,
                                       size_t vl);
vfloat64m4_t __riscv_vfsqrt_v_f64m4_rm(vfloat64m4_t vs2, unsigned int frm,
                                       size_t vl);
vfloat64m8_t __riscv_vfsqrt_v_f64m8_rm(vfloat64m8_t vs2, unsigned int frm,
                                       size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsqrt_v_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsqrt_v_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsqrt_v_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                         unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsqrt_v_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsqrt_v_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsqrt_v_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_v_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsqrt_v_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                         unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsqrt_v_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                         unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsqrt_v_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                         unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsqrt_v_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                         unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsqrt_v_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                         unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsqrt_v_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                         unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsqrt_v_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                         unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsqrt_v_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                         unsigned int frm, size_t vl);
----

[[vector-floating-point-reciprocal-square-root-estimate]]
==== Vector Floating-Point Reciprocal Square-Root Estimate Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfrsqrt7_v_f16mf4(vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfrsqrt7_v_f16mf2(vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfrsqrt7_v_f16m1(vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfrsqrt7_v_f16m2(vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfrsqrt7_v_f16m4(vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfrsqrt7_v_f16m8(vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfrsqrt7_v_f32mf2(vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfrsqrt7_v_f32m1(vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfrsqrt7_v_f32m2(vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfrsqrt7_v_f32m4(vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfrsqrt7_v_f32m8(vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfrsqrt7_v_f64m1(vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfrsqrt7_v_f64m2(vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfrsqrt7_v_f64m4(vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfrsqrt7_v_f64m8(vfloat64m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrsqrt7_v_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                          size_t vl);
vfloat16mf2_t __riscv_vfrsqrt7_v_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat16m1_t __riscv_vfrsqrt7_v_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                        size_t vl);
vfloat16m2_t __riscv_vfrsqrt7_v_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                        size_t vl);
vfloat16m4_t __riscv_vfrsqrt7_v_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                        size_t vl);
vfloat16m8_t __riscv_vfrsqrt7_v_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                        size_t vl);
vfloat32mf2_t __riscv_vfrsqrt7_v_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          size_t vl);
vfloat32m1_t __riscv_vfrsqrt7_v_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                        size_t vl);
vfloat32m2_t __riscv_vfrsqrt7_v_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                        size_t vl);
vfloat32m4_t __riscv_vfrsqrt7_v_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                        size_t vl);
vfloat32m8_t __riscv_vfrsqrt7_v_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                        size_t vl);
vfloat64m1_t __riscv_vfrsqrt7_v_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                        size_t vl);
vfloat64m2_t __riscv_vfrsqrt7_v_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                        size_t vl);
vfloat64m4_t __riscv_vfrsqrt7_v_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                        size_t vl);
vfloat64m8_t __riscv_vfrsqrt7_v_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                        size_t vl);
----

[[#1410-vector-floating-point-reciprocal-estimate]]
==== Vector Floating-Point Reciprocal Estimate Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfrec7_v_f16mf4(vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfrec7_v_f16mf2(vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfrec7_v_f16m1(vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfrec7_v_f16m2(vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfrec7_v_f16m4(vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfrec7_v_f16m8(vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfrec7_v_f32mf2(vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfrec7_v_f32m1(vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfrec7_v_f32m2(vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfrec7_v_f32m4(vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfrec7_v_f32m8(vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfrec7_v_f64m1(vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfrec7_v_f64m2(vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfrec7_v_f64m4(vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfrec7_v_f64m8(vfloat64m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrec7_v_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vfrec7_v_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        size_t vl);
vfloat16m1_t __riscv_vfrec7_v_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      size_t vl);
vfloat16m2_t __riscv_vfrec7_v_f16m2_m(vbool8_t vm, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfrec7_v_f16m4_m(vbool4_t vm, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfrec7_v_f16m8_m(vbool2_t vm, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfrec7_v_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        size_t vl);
vfloat32m1_t __riscv_vfrec7_v_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                      size_t vl);
vfloat32m2_t __riscv_vfrec7_v_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                      size_t vl);
vfloat32m4_t __riscv_vfrec7_v_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfrec7_v_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfrec7_v_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      size_t vl);
vfloat64m2_t __riscv_vfrec7_v_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      size_t vl);
vfloat64m4_t __riscv_vfrec7_v_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      size_t vl);
vfloat64m8_t __riscv_vfrec7_v_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfrec7_v_f16mf4_rm(vfloat16mf4_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16mf2_t __riscv_vfrec7_v_f16mf2_rm(vfloat16mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat16m1_t __riscv_vfrec7_v_f16m1_rm(vfloat16m1_t vs2, unsigned int frm,
                                       size_t vl);
vfloat16m2_t __riscv_vfrec7_v_f16m2_rm(vfloat16m2_t vs2, unsigned int frm,
                                       size_t vl);
vfloat16m4_t __riscv_vfrec7_v_f16m4_rm(vfloat16m4_t vs2, unsigned int frm,
                                       size_t vl);
vfloat16m8_t __riscv_vfrec7_v_f16m8_rm(vfloat16m8_t vs2, unsigned int frm,
                                       size_t vl);
vfloat32mf2_t __riscv_vfrec7_v_f32mf2_rm(vfloat32mf2_t vs2, unsigned int frm,
                                         size_t vl);
vfloat32m1_t __riscv_vfrec7_v_f32m1_rm(vfloat32m1_t vs2, unsigned int frm,
                                       size_t vl);
vfloat32m2_t __riscv_vfrec7_v_f32m2_rm(vfloat32m2_t vs2, unsigned int frm,
                                       size_t vl);
vfloat32m4_t __riscv_vfrec7_v_f32m4_rm(vfloat32m4_t vs2, unsigned int frm,
                                       size_t vl);
vfloat32m8_t __riscv_vfrec7_v_f32m8_rm(vfloat32m8_t vs2, unsigned int frm,
                                       size_t vl);
vfloat64m1_t __riscv_vfrec7_v_f64m1_rm(vfloat64m1_t vs2, unsigned int frm,
                                       size_t vl);
vfloat64m2_t __riscv_vfrec7_v_f64m2_rm(vfloat64m2_t vs2, unsigned int frm,
                                       size_t vl);
vfloat64m4_t __riscv_vfrec7_v_f64m4_rm(vfloat64m4_t vs2, unsigned int frm,
                                       size_t vl);
vfloat64m8_t __riscv_vfrec7_v_f64m8_rm(vfloat64m8_t vs2, unsigned int frm,
                                       size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrec7_v_f16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrec7_v_f16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrec7_v_f16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                         unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrec7_v_f16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrec7_v_f16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrec7_v_f16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrec7_v_f32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrec7_v_f32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                         unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrec7_v_f32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                         unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrec7_v_f32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                         unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrec7_v_f32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                         unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrec7_v_f64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                         unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrec7_v_f64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                         unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrec7_v_f64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                         unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrec7_v_f64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                         unsigned int frm, size_t vl);
----

[[vector-floating-point-minmax]]
==== Vector Floating-Point MIN/MAX Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfmin_vv_f16mf4(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfmin_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfmin_vv_f16mf2(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfmin_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m1_t __riscv_vfmin_vv_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                    size_t vl);
vfloat16m1_t __riscv_vfmin_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfmin_vv_f16m2(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                    size_t vl);
vfloat16m2_t __riscv_vfmin_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfmin_vv_f16m4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                    size_t vl);
vfloat16m4_t __riscv_vfmin_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfmin_vv_f16m8(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                    size_t vl);
vfloat16m8_t __riscv_vfmin_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfmin_vv_f32mf2(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vfloat32mf2_t __riscv_vfmin_vf_f32mf2(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat32m1_t __riscv_vfmin_vv_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                    size_t vl);
vfloat32m1_t __riscv_vfmin_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfmin_vv_f32m2(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                    size_t vl);
vfloat32m2_t __riscv_vfmin_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfmin_vv_f32m4(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                    size_t vl);
vfloat32m4_t __riscv_vfmin_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfmin_vv_f32m8(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                    size_t vl);
vfloat32m8_t __riscv_vfmin_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfmin_vv_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                    size_t vl);
vfloat64m1_t __riscv_vfmin_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfmin_vv_f64m2(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                    size_t vl);
vfloat64m2_t __riscv_vfmin_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfmin_vv_f64m4(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                    size_t vl);
vfloat64m4_t __riscv_vfmin_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfmin_vv_f64m8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                    size_t vl);
vfloat64m8_t __riscv_vfmin_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
vfloat16mf4_t __riscv_vfmax_vv_f16mf4(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfmax_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfmax_vv_f16mf2(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vfloat16mf2_t __riscv_vfmax_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m1_t __riscv_vfmax_vv_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                    size_t vl);
vfloat16m1_t __riscv_vfmax_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfmax_vv_f16m2(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                    size_t vl);
vfloat16m2_t __riscv_vfmax_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfmax_vv_f16m4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                    size_t vl);
vfloat16m4_t __riscv_vfmax_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfmax_vv_f16m8(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                    size_t vl);
vfloat16m8_t __riscv_vfmax_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfmax_vv_f32mf2(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vfloat32mf2_t __riscv_vfmax_vf_f32mf2(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat32m1_t __riscv_vfmax_vv_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                    size_t vl);
vfloat32m1_t __riscv_vfmax_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfmax_vv_f32m2(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                    size_t vl);
vfloat32m2_t __riscv_vfmax_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfmax_vv_f32m4(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                    size_t vl);
vfloat32m4_t __riscv_vfmax_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfmax_vv_f32m8(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                    size_t vl);
vfloat32m8_t __riscv_vfmax_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfmax_vv_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                    size_t vl);
vfloat64m1_t __riscv_vfmax_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfmax_vv_f64m2(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                    size_t vl);
vfloat64m2_t __riscv_vfmax_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfmax_vv_f64m4(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                    size_t vl);
vfloat64m4_t __riscv_vfmax_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfmax_vv_f64m8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                    size_t vl);
vfloat64m8_t __riscv_vfmax_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmin_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vfmin_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfmin_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vfmin_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfmin_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfmin_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfmin_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      vfloat16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vfmin_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfmin_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      vfloat16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vfmin_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfmin_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      vfloat16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vfmin_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfmin_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfmin_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vfloat32m1_t __riscv_vfmin_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                      vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfmin_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2, float rs1,
                                      size_t vl);
vfloat32m2_t __riscv_vfmin_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                      vfloat32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vfmin_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2, float rs1,
                                      size_t vl);
vfloat32m4_t __riscv_vfmin_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                      vfloat32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vfmin_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                      size_t vl);
vfloat32m8_t __riscv_vfmin_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                      vfloat32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vfmin_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                      size_t vl);
vfloat64m1_t __riscv_vfmin_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfmin_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      double rs1, size_t vl);
vfloat64m2_t __riscv_vfmin_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      vfloat64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vfmin_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      double rs1, size_t vl);
vfloat64m4_t __riscv_vfmin_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      vfloat64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vfmin_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      double rs1, size_t vl);
vfloat64m8_t __riscv_vfmin_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                      vfloat64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vfmin_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                      size_t vl);
vfloat16mf4_t __riscv_vfmax_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vfmax_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfmax_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vfmax_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfmax_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfmax_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfmax_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      vfloat16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vfmax_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfmax_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      vfloat16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vfmax_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfmax_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      vfloat16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vfmax_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                      _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfmax_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfmax_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vfloat32m1_t __riscv_vfmax_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                      vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfmax_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2, float rs1,
                                      size_t vl);
vfloat32m2_t __riscv_vfmax_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                      vfloat32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vfmax_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2, float rs1,
                                      size_t vl);
vfloat32m4_t __riscv_vfmax_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                      vfloat32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vfmax_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                      size_t vl);
vfloat32m8_t __riscv_vfmax_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                      vfloat32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vfmax_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                      size_t vl);
vfloat64m1_t __riscv_vfmax_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfmax_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      double rs1, size_t vl);
vfloat64m2_t __riscv_vfmax_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      vfloat64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vfmax_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      double rs1, size_t vl);
vfloat64m4_t __riscv_vfmax_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      vfloat64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vfmax_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      double rs1, size_t vl);
vfloat64m8_t __riscv_vfmax_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                      vfloat64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vfmax_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                      size_t vl);
----

[[vector-floating-point-sign-injection]]
==== Vector Floating-Point Sign-Injection Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfsgnj_vv_f16mf4(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                       size_t vl);
vfloat16mf4_t __riscv_vfsgnj_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat16mf2_t __riscv_vfsgnj_vv_f16mf2(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                       size_t vl);
vfloat16mf2_t __riscv_vfsgnj_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                       size_t vl);
vfloat16m1_t __riscv_vfsgnj_vv_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vfloat16m1_t __riscv_vfsgnj_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfsgnj_vv_f16m2(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                     size_t vl);
vfloat16m2_t __riscv_vfsgnj_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfsgnj_vv_f16m4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                     size_t vl);
vfloat16m4_t __riscv_vfsgnj_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfsgnj_vv_f16m8(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                     size_t vl);
vfloat16m8_t __riscv_vfsgnj_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_vv_f32mf2(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                       size_t vl);
vfloat32mf2_t __riscv_vfsgnj_vf_f32mf2(vfloat32mf2_t vs2, float rs1, size_t vl);
vfloat32m1_t __riscv_vfsgnj_vv_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vfloat32m1_t __riscv_vfsgnj_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfsgnj_vv_f32m2(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vfloat32m2_t __riscv_vfsgnj_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfsgnj_vv_f32m4(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                     size_t vl);
vfloat32m4_t __riscv_vfsgnj_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfsgnj_vv_f32m8(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                     size_t vl);
vfloat32m8_t __riscv_vfsgnj_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfsgnj_vv_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                     size_t vl);
vfloat64m1_t __riscv_vfsgnj_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfsgnj_vv_f64m2(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                     size_t vl);
vfloat64m2_t __riscv_vfsgnj_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfsgnj_vv_f64m4(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                     size_t vl);
vfloat64m4_t __riscv_vfsgnj_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfsgnj_vv_f64m8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                     size_t vl);
vfloat64m8_t __riscv_vfsgnj_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_vv_f16mf4(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                        size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                        size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_vv_f16mf2(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                        size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                        size_t vl);
vfloat16m1_t __riscv_vfsgnjn_vv_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                      size_t vl);
vfloat16m1_t __riscv_vfsgnjn_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m2_t __riscv_vfsgnjn_vv_f16m2(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                      size_t vl);
vfloat16m2_t __riscv_vfsgnjn_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m4_t __riscv_vfsgnjn_vv_f16m4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                      size_t vl);
vfloat16m4_t __riscv_vfsgnjn_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m8_t __riscv_vfsgnjn_vv_f16m8(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                      size_t vl);
vfloat16m8_t __riscv_vfsgnjn_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_vv_f32mf2(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                        size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_vf_f32mf2(vfloat32mf2_t vs2, float rs1,
                                        size_t vl);
vfloat32m1_t __riscv_vfsgnjn_vv_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                      size_t vl);
vfloat32m1_t __riscv_vfsgnjn_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_vv_f32m2(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                      size_t vl);
vfloat32m2_t __riscv_vfsgnjn_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_vv_f32m4(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                      size_t vl);
vfloat32m4_t __riscv_vfsgnjn_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_vv_f32m8(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                      size_t vl);
vfloat32m8_t __riscv_vfsgnjn_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_vv_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                      size_t vl);
vfloat64m1_t __riscv_vfsgnjn_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_vv_f64m2(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                      size_t vl);
vfloat64m2_t __riscv_vfsgnjn_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_vv_f64m4(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                      size_t vl);
vfloat64m4_t __riscv_vfsgnjn_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_vv_f64m8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                      size_t vl);
vfloat64m8_t __riscv_vfsgnjn_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_vv_f16mf4(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                        size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                        size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_vv_f16mf2(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                        size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                        size_t vl);
vfloat16m1_t __riscv_vfsgnjx_vv_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                      size_t vl);
vfloat16m1_t __riscv_vfsgnjx_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m2_t __riscv_vfsgnjx_vv_f16m2(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                      size_t vl);
vfloat16m2_t __riscv_vfsgnjx_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m4_t __riscv_vfsgnjx_vv_f16m4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                      size_t vl);
vfloat16m4_t __riscv_vfsgnjx_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat16m8_t __riscv_vfsgnjx_vv_f16m8(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                      size_t vl);
vfloat16m8_t __riscv_vfsgnjx_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1,
                                      size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_vv_f32mf2(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                        size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_vf_f32mf2(vfloat32mf2_t vs2, float rs1,
                                        size_t vl);
vfloat32m1_t __riscv_vfsgnjx_vv_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                      size_t vl);
vfloat32m1_t __riscv_vfsgnjx_vf_f32m1(vfloat32m1_t vs2, float rs1, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_vv_f32m2(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                      size_t vl);
vfloat32m2_t __riscv_vfsgnjx_vf_f32m2(vfloat32m2_t vs2, float rs1, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_vv_f32m4(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                      size_t vl);
vfloat32m4_t __riscv_vfsgnjx_vf_f32m4(vfloat32m4_t vs2, float rs1, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_vv_f32m8(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                      size_t vl);
vfloat32m8_t __riscv_vfsgnjx_vf_f32m8(vfloat32m8_t vs2, float rs1, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_vv_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                      size_t vl);
vfloat64m1_t __riscv_vfsgnjx_vf_f64m1(vfloat64m1_t vs2, double rs1, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_vv_f64m2(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                      size_t vl);
vfloat64m2_t __riscv_vfsgnjx_vf_f64m2(vfloat64m2_t vs2, double rs1, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_vv_f64m4(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                      size_t vl);
vfloat64m4_t __riscv_vfsgnjx_vf_f64m4(vfloat64m4_t vs2, double rs1, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_vv_f64m8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                      size_t vl);
vfloat64m8_t __riscv_vfsgnjx_vf_f64m8(vfloat64m8_t vs2, double rs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsgnj_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         vfloat16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vfsgnj_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfsgnj_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                         vfloat16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vfsgnj_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                         _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfsgnj_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfsgnj_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfsgnj_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                       vfloat16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vfsgnj_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfsgnj_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                       vfloat16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vfsgnj_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfsgnj_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                       vfloat16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vfsgnj_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                       _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                         vfloat32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                         float rs1, size_t vl);
vfloat32m1_t __riscv_vfsgnj_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfsgnj_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vfloat32m2_t __riscv_vfsgnj_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vfsgnj_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vfloat32m4_t __riscv_vfsgnj_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                       vfloat32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vfsgnj_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                       size_t vl);
vfloat32m8_t __riscv_vfsgnj_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                       vfloat32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vfsgnj_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                       size_t vl);
vfloat64m1_t __riscv_vfsgnj_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                       vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfsgnj_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                       double rs1, size_t vl);
vfloat64m2_t __riscv_vfsgnj_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                       vfloat64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vfsgnj_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                       double rs1, size_t vl);
vfloat64m4_t __riscv_vfsgnj_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                       vfloat64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vfsgnj_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                       double rs1, size_t vl);
vfloat64m8_t __riscv_vfsgnj_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                       vfloat64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vfsgnj_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                       double rs1, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                          vfloat16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                          _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          vfloat16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfsgnjn_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                        vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfsgnjn_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfsgnjn_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                        vfloat16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vfsgnjn_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfsgnjn_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                        vfloat16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vfsgnjn_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfsgnjn_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                        vfloat16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vfsgnjn_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          vfloat32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          float rs1, size_t vl);
vfloat32m1_t __riscv_vfsgnjn_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                        vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfsgnjn_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                        float rs1, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                        vfloat32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                        float rs1, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                        vfloat32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                        float rs1, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                        vfloat32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                        float rs1, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                        vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                        double rs1, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                        vfloat64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                        double rs1, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                        vfloat64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                        double rs1, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                        vfloat64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                        double rs1, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                          vfloat16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                          _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          vfloat16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfsgnjx_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                        vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfsgnjx_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfsgnjx_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                        vfloat16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vfsgnjx_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfsgnjx_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                        vfloat16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vfsgnjx_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfsgnjx_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                        vfloat16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vfsgnjx_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                        _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          vfloat32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          float rs1, size_t vl);
vfloat32m1_t __riscv_vfsgnjx_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                        vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfsgnjx_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                        float rs1, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                        vfloat32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                        float rs1, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                        vfloat32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                        float rs1, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                        vfloat32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                        float rs1, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                        vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                        double rs1, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                        vfloat64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                        double rs1, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                        vfloat64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                        double rs1, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                        vfloat64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                        double rs1, size_t vl);
----

[[vector-floating-point-absolute-value]]
==== Vector Floating-Point Absolute Value Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfabs_v_f16mf4(vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfabs_v_f16mf2(vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfabs_v_f16m1(vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfabs_v_f16m2(vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfabs_v_f16m4(vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfabs_v_f16m8(vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfabs_v_f32mf2(vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfabs_v_f32m1(vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfabs_v_f32m2(vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfabs_v_f32m4(vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfabs_v_f32m8(vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfabs_v_f64m1(vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfabs_v_f64m2(vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfabs_v_f64m4(vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfabs_v_f64m8(vfloat64m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfabs_v_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                       size_t vl);
vfloat16mf2_t __riscv_vfabs_v_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                       size_t vl);
vfloat16m1_t __riscv_vfabs_v_f16m1_m(vbool16_t vm, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfabs_v_f16m2_m(vbool8_t vm, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfabs_v_f16m4_m(vbool4_t vm, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfabs_v_f16m8_m(vbool2_t vm, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfabs_v_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                       size_t vl);
vfloat32m1_t __riscv_vfabs_v_f32m1_m(vbool32_t vm, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfabs_v_f32m2_m(vbool16_t vm, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfabs_v_f32m4_m(vbool8_t vm, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfabs_v_f32m8_m(vbool4_t vm, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfabs_v_f64m1_m(vbool64_t vm, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfabs_v_f64m2_m(vbool32_t vm, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfabs_v_f64m4_m(vbool16_t vm, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfabs_v_f64m8_m(vbool8_t vm, vfloat64m8_t vs2, size_t vl);
----

[[vector-floating-point-compare]]
==== Vector Floating-Point Compare Intrinsics

[,c]
----
vbool64_t __riscv_vmfeq_vv_f16mf4_b64(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmfeq_vf_f16mf4_b64(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vbool32_t __riscv_vmfeq_vv_f16mf2_b32(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmfeq_vf_f16mf2_b32(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vbool16_t __riscv_vmfeq_vv_f16m1_b16(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfeq_vf_f16m1_b16(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vbool8_t __riscv_vmfeq_vv_f16m2_b8(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfeq_vf_f16m2_b8(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vbool4_t __riscv_vmfeq_vv_f16m4_b4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmfeq_vf_f16m4_b4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vbool2_t __riscv_vmfeq_vv_f16m8_b2(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                   size_t vl);
vbool2_t __riscv_vmfeq_vf_f16m8_b2(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vbool64_t __riscv_vmfeq_vv_f32mf2_b64(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmfeq_vf_f32mf2_b64(vfloat32mf2_t vs2, float rs1, size_t vl);
vbool32_t __riscv_vmfeq_vv_f32m1_b32(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmfeq_vf_f32m1_b32(vfloat32m1_t vs2, float rs1, size_t vl);
vbool16_t __riscv_vmfeq_vv_f32m2_b16(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfeq_vf_f32m2_b16(vfloat32m2_t vs2, float rs1, size_t vl);
vbool8_t __riscv_vmfeq_vv_f32m4_b8(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfeq_vf_f32m4_b8(vfloat32m4_t vs2, float rs1, size_t vl);
vbool4_t __riscv_vmfeq_vv_f32m8_b4(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmfeq_vf_f32m8_b4(vfloat32m8_t vs2, float rs1, size_t vl);
vbool64_t __riscv_vmfeq_vv_f64m1_b64(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmfeq_vf_f64m1_b64(vfloat64m1_t vs2, double rs1, size_t vl);
vbool32_t __riscv_vmfeq_vv_f64m2_b32(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmfeq_vf_f64m2_b32(vfloat64m2_t vs2, double rs1, size_t vl);
vbool16_t __riscv_vmfeq_vv_f64m4_b16(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfeq_vf_f64m4_b16(vfloat64m4_t vs2, double rs1, size_t vl);
vbool8_t __riscv_vmfeq_vv_f64m8_b8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfeq_vf_f64m8_b8(vfloat64m8_t vs2, double rs1, size_t vl);
vbool64_t __riscv_vmfne_vv_f16mf4_b64(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmfne_vf_f16mf4_b64(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vbool32_t __riscv_vmfne_vv_f16mf2_b32(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmfne_vf_f16mf2_b32(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vbool16_t __riscv_vmfne_vv_f16m1_b16(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfne_vf_f16m1_b16(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vbool8_t __riscv_vmfne_vv_f16m2_b8(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfne_vf_f16m2_b8(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vbool4_t __riscv_vmfne_vv_f16m4_b4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmfne_vf_f16m4_b4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vbool2_t __riscv_vmfne_vv_f16m8_b2(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                   size_t vl);
vbool2_t __riscv_vmfne_vf_f16m8_b2(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vbool64_t __riscv_vmfne_vv_f32mf2_b64(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmfne_vf_f32mf2_b64(vfloat32mf2_t vs2, float rs1, size_t vl);
vbool32_t __riscv_vmfne_vv_f32m1_b32(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmfne_vf_f32m1_b32(vfloat32m1_t vs2, float rs1, size_t vl);
vbool16_t __riscv_vmfne_vv_f32m2_b16(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfne_vf_f32m2_b16(vfloat32m2_t vs2, float rs1, size_t vl);
vbool8_t __riscv_vmfne_vv_f32m4_b8(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfne_vf_f32m4_b8(vfloat32m4_t vs2, float rs1, size_t vl);
vbool4_t __riscv_vmfne_vv_f32m8_b4(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmfne_vf_f32m8_b4(vfloat32m8_t vs2, float rs1, size_t vl);
vbool64_t __riscv_vmfne_vv_f64m1_b64(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmfne_vf_f64m1_b64(vfloat64m1_t vs2, double rs1, size_t vl);
vbool32_t __riscv_vmfne_vv_f64m2_b32(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmfne_vf_f64m2_b32(vfloat64m2_t vs2, double rs1, size_t vl);
vbool16_t __riscv_vmfne_vv_f64m4_b16(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfne_vf_f64m4_b16(vfloat64m4_t vs2, double rs1, size_t vl);
vbool8_t __riscv_vmfne_vv_f64m8_b8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfne_vf_f64m8_b8(vfloat64m8_t vs2, double rs1, size_t vl);
vbool64_t __riscv_vmflt_vv_f16mf4_b64(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmflt_vf_f16mf4_b64(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vbool32_t __riscv_vmflt_vv_f16mf2_b32(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmflt_vf_f16mf2_b32(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vbool16_t __riscv_vmflt_vv_f16m1_b16(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmflt_vf_f16m1_b16(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vbool8_t __riscv_vmflt_vv_f16m2_b8(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmflt_vf_f16m2_b8(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vbool4_t __riscv_vmflt_vv_f16m4_b4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmflt_vf_f16m4_b4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vbool2_t __riscv_vmflt_vv_f16m8_b2(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                   size_t vl);
vbool2_t __riscv_vmflt_vf_f16m8_b2(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vbool64_t __riscv_vmflt_vv_f32mf2_b64(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmflt_vf_f32mf2_b64(vfloat32mf2_t vs2, float rs1, size_t vl);
vbool32_t __riscv_vmflt_vv_f32m1_b32(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmflt_vf_f32m1_b32(vfloat32m1_t vs2, float rs1, size_t vl);
vbool16_t __riscv_vmflt_vv_f32m2_b16(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmflt_vf_f32m2_b16(vfloat32m2_t vs2, float rs1, size_t vl);
vbool8_t __riscv_vmflt_vv_f32m4_b8(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmflt_vf_f32m4_b8(vfloat32m4_t vs2, float rs1, size_t vl);
vbool4_t __riscv_vmflt_vv_f32m8_b4(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmflt_vf_f32m8_b4(vfloat32m8_t vs2, float rs1, size_t vl);
vbool64_t __riscv_vmflt_vv_f64m1_b64(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmflt_vf_f64m1_b64(vfloat64m1_t vs2, double rs1, size_t vl);
vbool32_t __riscv_vmflt_vv_f64m2_b32(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmflt_vf_f64m2_b32(vfloat64m2_t vs2, double rs1, size_t vl);
vbool16_t __riscv_vmflt_vv_f64m4_b16(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmflt_vf_f64m4_b16(vfloat64m4_t vs2, double rs1, size_t vl);
vbool8_t __riscv_vmflt_vv_f64m8_b8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmflt_vf_f64m8_b8(vfloat64m8_t vs2, double rs1, size_t vl);
vbool64_t __riscv_vmfle_vv_f16mf4_b64(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmfle_vf_f16mf4_b64(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vbool32_t __riscv_vmfle_vv_f16mf2_b32(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmfle_vf_f16mf2_b32(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vbool16_t __riscv_vmfle_vv_f16m1_b16(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfle_vf_f16m1_b16(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vbool8_t __riscv_vmfle_vv_f16m2_b8(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfle_vf_f16m2_b8(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vbool4_t __riscv_vmfle_vv_f16m4_b4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmfle_vf_f16m4_b4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vbool2_t __riscv_vmfle_vv_f16m8_b2(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                   size_t vl);
vbool2_t __riscv_vmfle_vf_f16m8_b2(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vbool64_t __riscv_vmfle_vv_f32mf2_b64(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmfle_vf_f32mf2_b64(vfloat32mf2_t vs2, float rs1, size_t vl);
vbool32_t __riscv_vmfle_vv_f32m1_b32(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmfle_vf_f32m1_b32(vfloat32m1_t vs2, float rs1, size_t vl);
vbool16_t __riscv_vmfle_vv_f32m2_b16(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfle_vf_f32m2_b16(vfloat32m2_t vs2, float rs1, size_t vl);
vbool8_t __riscv_vmfle_vv_f32m4_b8(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfle_vf_f32m4_b8(vfloat32m4_t vs2, float rs1, size_t vl);
vbool4_t __riscv_vmfle_vv_f32m8_b4(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmfle_vf_f32m8_b4(vfloat32m8_t vs2, float rs1, size_t vl);
vbool64_t __riscv_vmfle_vv_f64m1_b64(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmfle_vf_f64m1_b64(vfloat64m1_t vs2, double rs1, size_t vl);
vbool32_t __riscv_vmfle_vv_f64m2_b32(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmfle_vf_f64m2_b32(vfloat64m2_t vs2, double rs1, size_t vl);
vbool16_t __riscv_vmfle_vv_f64m4_b16(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfle_vf_f64m4_b16(vfloat64m4_t vs2, double rs1, size_t vl);
vbool8_t __riscv_vmfle_vv_f64m8_b8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfle_vf_f64m8_b8(vfloat64m8_t vs2, double rs1, size_t vl);
vbool64_t __riscv_vmfgt_vv_f16mf4_b64(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmfgt_vf_f16mf4_b64(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vbool32_t __riscv_vmfgt_vv_f16mf2_b32(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmfgt_vf_f16mf2_b32(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vbool16_t __riscv_vmfgt_vv_f16m1_b16(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfgt_vf_f16m1_b16(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vbool8_t __riscv_vmfgt_vv_f16m2_b8(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfgt_vf_f16m2_b8(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vbool4_t __riscv_vmfgt_vv_f16m4_b4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmfgt_vf_f16m4_b4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vbool2_t __riscv_vmfgt_vv_f16m8_b2(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                   size_t vl);
vbool2_t __riscv_vmfgt_vf_f16m8_b2(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vbool64_t __riscv_vmfgt_vv_f32mf2_b64(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmfgt_vf_f32mf2_b64(vfloat32mf2_t vs2, float rs1, size_t vl);
vbool32_t __riscv_vmfgt_vv_f32m1_b32(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmfgt_vf_f32m1_b32(vfloat32m1_t vs2, float rs1, size_t vl);
vbool16_t __riscv_vmfgt_vv_f32m2_b16(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfgt_vf_f32m2_b16(vfloat32m2_t vs2, float rs1, size_t vl);
vbool8_t __riscv_vmfgt_vv_f32m4_b8(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfgt_vf_f32m4_b8(vfloat32m4_t vs2, float rs1, size_t vl);
vbool4_t __riscv_vmfgt_vv_f32m8_b4(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmfgt_vf_f32m8_b4(vfloat32m8_t vs2, float rs1, size_t vl);
vbool64_t __riscv_vmfgt_vv_f64m1_b64(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmfgt_vf_f64m1_b64(vfloat64m1_t vs2, double rs1, size_t vl);
vbool32_t __riscv_vmfgt_vv_f64m2_b32(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmfgt_vf_f64m2_b32(vfloat64m2_t vs2, double rs1, size_t vl);
vbool16_t __riscv_vmfgt_vv_f64m4_b16(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfgt_vf_f64m4_b16(vfloat64m4_t vs2, double rs1, size_t vl);
vbool8_t __riscv_vmfgt_vv_f64m8_b8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfgt_vf_f64m8_b8(vfloat64m8_t vs2, double rs1, size_t vl);
vbool64_t __riscv_vmfge_vv_f16mf4_b64(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmfge_vf_f16mf4_b64(vfloat16mf4_t vs2, _Float16 rs1,
                                      size_t vl);
vbool32_t __riscv_vmfge_vv_f16mf2_b32(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                      size_t vl);
vbool32_t __riscv_vmfge_vf_f16mf2_b32(vfloat16mf2_t vs2, _Float16 rs1,
                                      size_t vl);
vbool16_t __riscv_vmfge_vv_f16m1_b16(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfge_vf_f16m1_b16(vfloat16m1_t vs2, _Float16 rs1, size_t vl);
vbool8_t __riscv_vmfge_vv_f16m2_b8(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfge_vf_f16m2_b8(vfloat16m2_t vs2, _Float16 rs1, size_t vl);
vbool4_t __riscv_vmfge_vv_f16m4_b4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmfge_vf_f16m4_b4(vfloat16m4_t vs2, _Float16 rs1, size_t vl);
vbool2_t __riscv_vmfge_vv_f16m8_b2(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                   size_t vl);
vbool2_t __riscv_vmfge_vf_f16m8_b2(vfloat16m8_t vs2, _Float16 rs1, size_t vl);
vbool64_t __riscv_vmfge_vv_f32mf2_b64(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                      size_t vl);
vbool64_t __riscv_vmfge_vf_f32mf2_b64(vfloat32mf2_t vs2, float rs1, size_t vl);
vbool32_t __riscv_vmfge_vv_f32m1_b32(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmfge_vf_f32m1_b32(vfloat32m1_t vs2, float rs1, size_t vl);
vbool16_t __riscv_vmfge_vv_f32m2_b16(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfge_vf_f32m2_b16(vfloat32m2_t vs2, float rs1, size_t vl);
vbool8_t __riscv_vmfge_vv_f32m4_b8(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfge_vf_f32m4_b8(vfloat32m4_t vs2, float rs1, size_t vl);
vbool4_t __riscv_vmfge_vv_f32m8_b4(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                   size_t vl);
vbool4_t __riscv_vmfge_vf_f32m8_b4(vfloat32m8_t vs2, float rs1, size_t vl);
vbool64_t __riscv_vmfge_vv_f64m1_b64(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                     size_t vl);
vbool64_t __riscv_vmfge_vf_f64m1_b64(vfloat64m1_t vs2, double rs1, size_t vl);
vbool32_t __riscv_vmfge_vv_f64m2_b32(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                     size_t vl);
vbool32_t __riscv_vmfge_vf_f64m2_b32(vfloat64m2_t vs2, double rs1, size_t vl);
vbool16_t __riscv_vmfge_vv_f64m4_b16(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                     size_t vl);
vbool16_t __riscv_vmfge_vf_f64m4_b16(vfloat64m4_t vs2, double rs1, size_t vl);
vbool8_t __riscv_vmfge_vv_f64m8_b8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                   size_t vl);
vbool8_t __riscv_vmfge_vf_f64m8_b8(vfloat64m8_t vs2, double rs1, size_t vl);
// masked functions
vbool64_t __riscv_vmfeq_vv_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmfeq_vf_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vbool32_t __riscv_vmfeq_vv_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmfeq_vf_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vbool16_t __riscv_vmfeq_vv_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vbool16_t __riscv_vmfeq_vf_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vbool8_t __riscv_vmfeq_vv_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     vfloat16m2_t vs1, size_t vl);
vbool8_t __riscv_vmfeq_vf_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     _Float16 rs1, size_t vl);
vbool4_t __riscv_vmfeq_vv_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     vfloat16m4_t vs1, size_t vl);
vbool4_t __riscv_vmfeq_vf_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     _Float16 rs1, size_t vl);
vbool2_t __riscv_vmfeq_vv_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     vfloat16m8_t vs1, size_t vl);
vbool2_t __riscv_vmfeq_vf_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     _Float16 rs1, size_t vl);
vbool64_t __riscv_vmfeq_vv_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmfeq_vf_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vbool32_t __riscv_vmfeq_vv_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vbool32_t __riscv_vmfeq_vf_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vbool16_t __riscv_vmfeq_vv_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vbool16_t __riscv_vmfeq_vf_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vbool8_t __riscv_vmfeq_vv_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2,
                                     vfloat32m4_t vs1, size_t vl);
vbool8_t __riscv_vmfeq_vf_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                     size_t vl);
vbool4_t __riscv_vmfeq_vv_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2,
                                     vfloat32m8_t vs1, size_t vl);
vbool4_t __riscv_vmfeq_vf_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                     size_t vl);
vbool64_t __riscv_vmfeq_vv_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       vfloat64m1_t vs1, size_t vl);
vbool64_t __riscv_vmfeq_vf_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       double rs1, size_t vl);
vbool32_t __riscv_vmfeq_vv_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       vfloat64m2_t vs1, size_t vl);
vbool32_t __riscv_vmfeq_vf_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       double rs1, size_t vl);
vbool16_t __riscv_vmfeq_vv_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       vfloat64m4_t vs1, size_t vl);
vbool16_t __riscv_vmfeq_vf_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       double rs1, size_t vl);
vbool8_t __riscv_vmfeq_vv_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2,
                                     vfloat64m8_t vs1, size_t vl);
vbool8_t __riscv_vmfeq_vf_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                     size_t vl);
vbool64_t __riscv_vmfne_vv_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmfne_vf_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vbool32_t __riscv_vmfne_vv_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmfne_vf_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vbool16_t __riscv_vmfne_vv_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vbool16_t __riscv_vmfne_vf_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vbool8_t __riscv_vmfne_vv_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     vfloat16m2_t vs1, size_t vl);
vbool8_t __riscv_vmfne_vf_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     _Float16 rs1, size_t vl);
vbool4_t __riscv_vmfne_vv_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     vfloat16m4_t vs1, size_t vl);
vbool4_t __riscv_vmfne_vf_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     _Float16 rs1, size_t vl);
vbool2_t __riscv_vmfne_vv_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     vfloat16m8_t vs1, size_t vl);
vbool2_t __riscv_vmfne_vf_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     _Float16 rs1, size_t vl);
vbool64_t __riscv_vmfne_vv_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmfne_vf_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vbool32_t __riscv_vmfne_vv_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vbool32_t __riscv_vmfne_vf_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vbool16_t __riscv_vmfne_vv_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vbool16_t __riscv_vmfne_vf_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vbool8_t __riscv_vmfne_vv_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2,
                                     vfloat32m4_t vs1, size_t vl);
vbool8_t __riscv_vmfne_vf_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                     size_t vl);
vbool4_t __riscv_vmfne_vv_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2,
                                     vfloat32m8_t vs1, size_t vl);
vbool4_t __riscv_vmfne_vf_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                     size_t vl);
vbool64_t __riscv_vmfne_vv_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       vfloat64m1_t vs1, size_t vl);
vbool64_t __riscv_vmfne_vf_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       double rs1, size_t vl);
vbool32_t __riscv_vmfne_vv_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       vfloat64m2_t vs1, size_t vl);
vbool32_t __riscv_vmfne_vf_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       double rs1, size_t vl);
vbool16_t __riscv_vmfne_vv_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       vfloat64m4_t vs1, size_t vl);
vbool16_t __riscv_vmfne_vf_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       double rs1, size_t vl);
vbool8_t __riscv_vmfne_vv_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2,
                                     vfloat64m8_t vs1, size_t vl);
vbool8_t __riscv_vmfne_vf_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                     size_t vl);
vbool64_t __riscv_vmflt_vv_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmflt_vf_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vbool32_t __riscv_vmflt_vv_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmflt_vf_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vbool16_t __riscv_vmflt_vv_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vbool16_t __riscv_vmflt_vf_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vbool8_t __riscv_vmflt_vv_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     vfloat16m2_t vs1, size_t vl);
vbool8_t __riscv_vmflt_vf_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     _Float16 rs1, size_t vl);
vbool4_t __riscv_vmflt_vv_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     vfloat16m4_t vs1, size_t vl);
vbool4_t __riscv_vmflt_vf_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     _Float16 rs1, size_t vl);
vbool2_t __riscv_vmflt_vv_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     vfloat16m8_t vs1, size_t vl);
vbool2_t __riscv_vmflt_vf_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     _Float16 rs1, size_t vl);
vbool64_t __riscv_vmflt_vv_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmflt_vf_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vbool32_t __riscv_vmflt_vv_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vbool32_t __riscv_vmflt_vf_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vbool16_t __riscv_vmflt_vv_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vbool16_t __riscv_vmflt_vf_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vbool8_t __riscv_vmflt_vv_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2,
                                     vfloat32m4_t vs1, size_t vl);
vbool8_t __riscv_vmflt_vf_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                     size_t vl);
vbool4_t __riscv_vmflt_vv_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2,
                                     vfloat32m8_t vs1, size_t vl);
vbool4_t __riscv_vmflt_vf_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                     size_t vl);
vbool64_t __riscv_vmflt_vv_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       vfloat64m1_t vs1, size_t vl);
vbool64_t __riscv_vmflt_vf_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       double rs1, size_t vl);
vbool32_t __riscv_vmflt_vv_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       vfloat64m2_t vs1, size_t vl);
vbool32_t __riscv_vmflt_vf_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       double rs1, size_t vl);
vbool16_t __riscv_vmflt_vv_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       vfloat64m4_t vs1, size_t vl);
vbool16_t __riscv_vmflt_vf_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       double rs1, size_t vl);
vbool8_t __riscv_vmflt_vv_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2,
                                     vfloat64m8_t vs1, size_t vl);
vbool8_t __riscv_vmflt_vf_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                     size_t vl);
vbool64_t __riscv_vmfle_vv_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmfle_vf_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vbool32_t __riscv_vmfle_vv_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmfle_vf_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vbool16_t __riscv_vmfle_vv_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vbool16_t __riscv_vmfle_vf_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vbool8_t __riscv_vmfle_vv_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     vfloat16m2_t vs1, size_t vl);
vbool8_t __riscv_vmfle_vf_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     _Float16 rs1, size_t vl);
vbool4_t __riscv_vmfle_vv_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     vfloat16m4_t vs1, size_t vl);
vbool4_t __riscv_vmfle_vf_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     _Float16 rs1, size_t vl);
vbool2_t __riscv_vmfle_vv_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     vfloat16m8_t vs1, size_t vl);
vbool2_t __riscv_vmfle_vf_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     _Float16 rs1, size_t vl);
vbool64_t __riscv_vmfle_vv_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmfle_vf_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vbool32_t __riscv_vmfle_vv_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vbool32_t __riscv_vmfle_vf_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vbool16_t __riscv_vmfle_vv_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vbool16_t __riscv_vmfle_vf_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vbool8_t __riscv_vmfle_vv_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2,
                                     vfloat32m4_t vs1, size_t vl);
vbool8_t __riscv_vmfle_vf_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                     size_t vl);
vbool4_t __riscv_vmfle_vv_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2,
                                     vfloat32m8_t vs1, size_t vl);
vbool4_t __riscv_vmfle_vf_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                     size_t vl);
vbool64_t __riscv_vmfle_vv_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       vfloat64m1_t vs1, size_t vl);
vbool64_t __riscv_vmfle_vf_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       double rs1, size_t vl);
vbool32_t __riscv_vmfle_vv_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       vfloat64m2_t vs1, size_t vl);
vbool32_t __riscv_vmfle_vf_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       double rs1, size_t vl);
vbool16_t __riscv_vmfle_vv_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       vfloat64m4_t vs1, size_t vl);
vbool16_t __riscv_vmfle_vf_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       double rs1, size_t vl);
vbool8_t __riscv_vmfle_vv_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2,
                                     vfloat64m8_t vs1, size_t vl);
vbool8_t __riscv_vmfle_vf_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                     size_t vl);
vbool64_t __riscv_vmfgt_vv_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmfgt_vf_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vbool32_t __riscv_vmfgt_vv_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmfgt_vf_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vbool16_t __riscv_vmfgt_vv_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vbool16_t __riscv_vmfgt_vf_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vbool8_t __riscv_vmfgt_vv_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     vfloat16m2_t vs1, size_t vl);
vbool8_t __riscv_vmfgt_vf_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     _Float16 rs1, size_t vl);
vbool4_t __riscv_vmfgt_vv_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     vfloat16m4_t vs1, size_t vl);
vbool4_t __riscv_vmfgt_vf_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     _Float16 rs1, size_t vl);
vbool2_t __riscv_vmfgt_vv_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     vfloat16m8_t vs1, size_t vl);
vbool2_t __riscv_vmfgt_vf_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     _Float16 rs1, size_t vl);
vbool64_t __riscv_vmfgt_vv_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmfgt_vf_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vbool32_t __riscv_vmfgt_vv_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vbool32_t __riscv_vmfgt_vf_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vbool16_t __riscv_vmfgt_vv_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vbool16_t __riscv_vmfgt_vf_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vbool8_t __riscv_vmfgt_vv_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2,
                                     vfloat32m4_t vs1, size_t vl);
vbool8_t __riscv_vmfgt_vf_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                     size_t vl);
vbool4_t __riscv_vmfgt_vv_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2,
                                     vfloat32m8_t vs1, size_t vl);
vbool4_t __riscv_vmfgt_vf_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                     size_t vl);
vbool64_t __riscv_vmfgt_vv_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       vfloat64m1_t vs1, size_t vl);
vbool64_t __riscv_vmfgt_vf_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       double rs1, size_t vl);
vbool32_t __riscv_vmfgt_vv_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       vfloat64m2_t vs1, size_t vl);
vbool32_t __riscv_vmfgt_vf_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       double rs1, size_t vl);
vbool16_t __riscv_vmfgt_vv_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       vfloat64m4_t vs1, size_t vl);
vbool16_t __riscv_vmfgt_vf_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       double rs1, size_t vl);
vbool8_t __riscv_vmfgt_vv_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2,
                                     vfloat64m8_t vs1, size_t vl);
vbool8_t __riscv_vmfgt_vf_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                     size_t vl);
vbool64_t __riscv_vmfge_vv_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        vfloat16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmfge_vf_f16mf4_b64_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        _Float16 rs1, size_t vl);
vbool32_t __riscv_vmfge_vv_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        vfloat16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmfge_vf_f16mf2_b32_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        _Float16 rs1, size_t vl);
vbool16_t __riscv_vmfge_vv_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       vfloat16m1_t vs1, size_t vl);
vbool16_t __riscv_vmfge_vf_f16m1_b16_m(vbool16_t vm, vfloat16m1_t vs2,
                                       _Float16 rs1, size_t vl);
vbool8_t __riscv_vmfge_vv_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     vfloat16m2_t vs1, size_t vl);
vbool8_t __riscv_vmfge_vf_f16m2_b8_m(vbool8_t vm, vfloat16m2_t vs2,
                                     _Float16 rs1, size_t vl);
vbool4_t __riscv_vmfge_vv_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     vfloat16m4_t vs1, size_t vl);
vbool4_t __riscv_vmfge_vf_f16m4_b4_m(vbool4_t vm, vfloat16m4_t vs2,
                                     _Float16 rs1, size_t vl);
vbool2_t __riscv_vmfge_vv_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     vfloat16m8_t vs1, size_t vl);
vbool2_t __riscv_vmfge_vf_f16m8_b2_m(vbool2_t vm, vfloat16m8_t vs2,
                                     _Float16 rs1, size_t vl);
vbool64_t __riscv_vmfge_vv_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        vfloat32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmfge_vf_f32mf2_b64_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        float rs1, size_t vl);
vbool32_t __riscv_vmfge_vv_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       vfloat32m1_t vs1, size_t vl);
vbool32_t __riscv_vmfge_vf_f32m1_b32_m(vbool32_t vm, vfloat32m1_t vs2,
                                       float rs1, size_t vl);
vbool16_t __riscv_vmfge_vv_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       vfloat32m2_t vs1, size_t vl);
vbool16_t __riscv_vmfge_vf_f32m2_b16_m(vbool16_t vm, vfloat32m2_t vs2,
                                       float rs1, size_t vl);
vbool8_t __riscv_vmfge_vv_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2,
                                     vfloat32m4_t vs1, size_t vl);
vbool8_t __riscv_vmfge_vf_f32m4_b8_m(vbool8_t vm, vfloat32m4_t vs2, float rs1,
                                     size_t vl);
vbool4_t __riscv_vmfge_vv_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2,
                                     vfloat32m8_t vs1, size_t vl);
vbool4_t __riscv_vmfge_vf_f32m8_b4_m(vbool4_t vm, vfloat32m8_t vs2, float rs1,
                                     size_t vl);
vbool64_t __riscv_vmfge_vv_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       vfloat64m1_t vs1, size_t vl);
vbool64_t __riscv_vmfge_vf_f64m1_b64_m(vbool64_t vm, vfloat64m1_t vs2,
                                       double rs1, size_t vl);
vbool32_t __riscv_vmfge_vv_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       vfloat64m2_t vs1, size_t vl);
vbool32_t __riscv_vmfge_vf_f64m2_b32_m(vbool32_t vm, vfloat64m2_t vs2,
                                       double rs1, size_t vl);
vbool16_t __riscv_vmfge_vv_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       vfloat64m4_t vs1, size_t vl);
vbool16_t __riscv_vmfge_vf_f64m4_b16_m(vbool16_t vm, vfloat64m4_t vs2,
                                       double rs1, size_t vl);
vbool8_t __riscv_vmfge_vv_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2,
                                     vfloat64m8_t vs1, size_t vl);
vbool8_t __riscv_vmfge_vf_f64m8_b8_m(vbool8_t vm, vfloat64m8_t vs2, double rs1,
                                     size_t vl);
----

[[vector-floating-point-classify]]
==== Vector Floating-Point Classify Intrinsics

[,c]
----
vuint16mf4_t __riscv_vfclass_v_u16mf4(vfloat16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vfclass_v_u16mf2(vfloat16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vfclass_v_u16m1(vfloat16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vfclass_v_u16m2(vfloat16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vfclass_v_u16m4(vfloat16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vfclass_v_u16m8(vfloat16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vfclass_v_u32mf2(vfloat32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vfclass_v_u32m1(vfloat32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vfclass_v_u32m2(vfloat32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vfclass_v_u32m4(vfloat32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vfclass_v_u32m8(vfloat32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vfclass_v_u64m1(vfloat64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vfclass_v_u64m2(vfloat64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vfclass_v_u64m4(vfloat64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vfclass_v_u64m8(vfloat64m8_t vs2, size_t vl);
// masked functions
vuint16mf4_t __riscv_vfclass_v_u16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        size_t vl);
vuint16mf2_t __riscv_vfclass_v_u16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        size_t vl);
vuint16m1_t __riscv_vfclass_v_u16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                      size_t vl);
vuint16m2_t __riscv_vfclass_v_u16m2_m(vbool8_t vm, vfloat16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vfclass_v_u16m4_m(vbool4_t vm, vfloat16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vfclass_v_u16m8_m(vbool2_t vm, vfloat16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vfclass_v_u32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        size_t vl);
vuint32m1_t __riscv_vfclass_v_u32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                      size_t vl);
vuint32m2_t __riscv_vfclass_v_u32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                      size_t vl);
vuint32m4_t __riscv_vfclass_v_u32m4_m(vbool8_t vm, vfloat32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vfclass_v_u32m8_m(vbool4_t vm, vfloat32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vfclass_v_u64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                      size_t vl);
vuint64m2_t __riscv_vfclass_v_u64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                      size_t vl);
vuint64m4_t __riscv_vfclass_v_u64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                      size_t vl);
vuint64m8_t __riscv_vfclass_v_u64m8_m(vbool8_t vm, vfloat64m8_t vs2, size_t vl);
----

[[vector-floating-point-merge]]
==== Vector Floating-Point Merge Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vmerge_vvm_f16mf4(vfloat16mf4_t vs2, vfloat16mf4_t vs1,
                                        vbool64_t v0, size_t vl);
vfloat16mf4_t __riscv_vfmerge_vfm_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                         vbool64_t v0, size_t vl);
vfloat16mf2_t __riscv_vmerge_vvm_f16mf2(vfloat16mf2_t vs2, vfloat16mf2_t vs1,
                                        vbool32_t v0, size_t vl);
vfloat16mf2_t __riscv_vfmerge_vfm_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                         vbool32_t v0, size_t vl);
vfloat16m1_t __riscv_vmerge_vvm_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                      vbool16_t v0, size_t vl);
vfloat16m1_t __riscv_vfmerge_vfm_f16m1(vfloat16m1_t vs2, _Float16 rs1,
                                       vbool16_t v0, size_t vl);
vfloat16m2_t __riscv_vmerge_vvm_f16m2(vfloat16m2_t vs2, vfloat16m2_t vs1,
                                      vbool8_t v0, size_t vl);
vfloat16m2_t __riscv_vfmerge_vfm_f16m2(vfloat16m2_t vs2, _Float16 rs1,
                                       vbool8_t v0, size_t vl);
vfloat16m4_t __riscv_vmerge_vvm_f16m4(vfloat16m4_t vs2, vfloat16m4_t vs1,
                                      vbool4_t v0, size_t vl);
vfloat16m4_t __riscv_vfmerge_vfm_f16m4(vfloat16m4_t vs2, _Float16 rs1,
                                       vbool4_t v0, size_t vl);
vfloat16m8_t __riscv_vmerge_vvm_f16m8(vfloat16m8_t vs2, vfloat16m8_t vs1,
                                      vbool2_t v0, size_t vl);
vfloat16m8_t __riscv_vfmerge_vfm_f16m8(vfloat16m8_t vs2, _Float16 rs1,
                                       vbool2_t v0, size_t vl);
vfloat32mf2_t __riscv_vmerge_vvm_f32mf2(vfloat32mf2_t vs2, vfloat32mf2_t vs1,
                                        vbool64_t v0, size_t vl);
vfloat32mf2_t __riscv_vfmerge_vfm_f32mf2(vfloat32mf2_t vs2, float rs1,
                                         vbool64_t v0, size_t vl);
vfloat32m1_t __riscv_vmerge_vvm_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                      vbool32_t v0, size_t vl);
vfloat32m1_t __riscv_vfmerge_vfm_f32m1(vfloat32m1_t vs2, float rs1,
                                       vbool32_t v0, size_t vl);
vfloat32m2_t __riscv_vmerge_vvm_f32m2(vfloat32m2_t vs2, vfloat32m2_t vs1,
                                      vbool16_t v0, size_t vl);
vfloat32m2_t __riscv_vfmerge_vfm_f32m2(vfloat32m2_t vs2, float rs1,
                                       vbool16_t v0, size_t vl);
vfloat32m4_t __riscv_vmerge_vvm_f32m4(vfloat32m4_t vs2, vfloat32m4_t vs1,
                                      vbool8_t v0, size_t vl);
vfloat32m4_t __riscv_vfmerge_vfm_f32m4(vfloat32m4_t vs2, float rs1, vbool8_t v0,
                                       size_t vl);
vfloat32m8_t __riscv_vmerge_vvm_f32m8(vfloat32m8_t vs2, vfloat32m8_t vs1,
                                      vbool4_t v0, size_t vl);
vfloat32m8_t __riscv_vfmerge_vfm_f32m8(vfloat32m8_t vs2, float rs1, vbool4_t v0,
                                       size_t vl);
vfloat64m1_t __riscv_vmerge_vvm_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                      vbool64_t v0, size_t vl);
vfloat64m1_t __riscv_vfmerge_vfm_f64m1(vfloat64m1_t vs2, double rs1,
                                       vbool64_t v0, size_t vl);
vfloat64m2_t __riscv_vmerge_vvm_f64m2(vfloat64m2_t vs2, vfloat64m2_t vs1,
                                      vbool32_t v0, size_t vl);
vfloat64m2_t __riscv_vfmerge_vfm_f64m2(vfloat64m2_t vs2, double rs1,
                                       vbool32_t v0, size_t vl);
vfloat64m4_t __riscv_vmerge_vvm_f64m4(vfloat64m4_t vs2, vfloat64m4_t vs1,
                                      vbool16_t v0, size_t vl);
vfloat64m4_t __riscv_vfmerge_vfm_f64m4(vfloat64m4_t vs2, double rs1,
                                       vbool16_t v0, size_t vl);
vfloat64m8_t __riscv_vmerge_vvm_f64m8(vfloat64m8_t vs2, vfloat64m8_t vs1,
                                      vbool8_t v0, size_t vl);
vfloat64m8_t __riscv_vfmerge_vfm_f64m8(vfloat64m8_t vs2, double rs1,
                                       vbool8_t v0, size_t vl);
----

[[vector-floating-point-move]]
==== Vector Floating-Point Move Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vmv_v_v_f16mf4(vfloat16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vfmv_v_f_f16mf4(_Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vmv_v_v_f16mf2(vfloat16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vfmv_v_f_f16mf2(_Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vmv_v_v_f16m1(vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfmv_v_f_f16m1(_Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vmv_v_v_f16m2(vfloat16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vfmv_v_f_f16m2(_Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vmv_v_v_f16m4(vfloat16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vfmv_v_f_f16m4(_Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vmv_v_v_f16m8(vfloat16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vfmv_v_f_f16m8(_Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vmv_v_v_f32mf2(vfloat32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vfmv_v_f_f32mf2(float rs1, size_t vl);
vfloat32m1_t __riscv_vmv_v_v_f32m1(vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfmv_v_f_f32m1(float rs1, size_t vl);
vfloat32m2_t __riscv_vmv_v_v_f32m2(vfloat32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vfmv_v_f_f32m2(float rs1, size_t vl);
vfloat32m4_t __riscv_vmv_v_v_f32m4(vfloat32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vfmv_v_f_f32m4(float rs1, size_t vl);
vfloat32m8_t __riscv_vmv_v_v_f32m8(vfloat32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vfmv_v_f_f32m8(float rs1, size_t vl);
vfloat64m1_t __riscv_vmv_v_v_f64m1(vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfmv_v_f_f64m1(double rs1, size_t vl);
vfloat64m2_t __riscv_vmv_v_v_f64m2(vfloat64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vfmv_v_f_f64m2(double rs1, size_t vl);
vfloat64m4_t __riscv_vmv_v_v_f64m4(vfloat64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vfmv_v_f_f64m4(double rs1, size_t vl);
vfloat64m8_t __riscv_vmv_v_v_f64m8(vfloat64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vfmv_v_f_f64m8(double rs1, size_t vl);
----

[[single-width-floating-pointinteger-type-convert]]
==== Single-Width Floating-Point/Integer Type-Convert Intrinsics

[,c]
----
vint16mf4_t __riscv_vfcvt_x_f_v_i16mf4(vfloat16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vfcvt_rtz_x_f_v_i16mf4(vfloat16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vfcvt_x_f_v_i16mf2(vfloat16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vfcvt_rtz_x_f_v_i16mf2(vfloat16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vfcvt_x_f_v_i16m1(vfloat16m1_t vs2, size_t vl);
vint16m1_t __riscv_vfcvt_rtz_x_f_v_i16m1(vfloat16m1_t vs2, size_t vl);
vint16m2_t __riscv_vfcvt_x_f_v_i16m2(vfloat16m2_t vs2, size_t vl);
vint16m2_t __riscv_vfcvt_rtz_x_f_v_i16m2(vfloat16m2_t vs2, size_t vl);
vint16m4_t __riscv_vfcvt_x_f_v_i16m4(vfloat16m4_t vs2, size_t vl);
vint16m4_t __riscv_vfcvt_rtz_x_f_v_i16m4(vfloat16m4_t vs2, size_t vl);
vint16m8_t __riscv_vfcvt_x_f_v_i16m8(vfloat16m8_t vs2, size_t vl);
vint16m8_t __riscv_vfcvt_rtz_x_f_v_i16m8(vfloat16m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_f_v_u16mf4(vfloat16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vfcvt_rtz_xu_f_v_u16mf4(vfloat16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_f_v_u16mf2(vfloat16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vfcvt_rtz_xu_f_v_u16mf2(vfloat16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vfcvt_xu_f_v_u16m1(vfloat16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vfcvt_rtz_xu_f_v_u16m1(vfloat16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vfcvt_xu_f_v_u16m2(vfloat16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vfcvt_rtz_xu_f_v_u16m2(vfloat16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vfcvt_xu_f_v_u16m4(vfloat16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vfcvt_rtz_xu_f_v_u16m4(vfloat16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vfcvt_xu_f_v_u16m8(vfloat16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vfcvt_rtz_xu_f_v_u16m8(vfloat16m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_x_v_f16mf4(vint16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_x_v_f16mf2(vint16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_x_v_f16m1(vint16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_x_v_f16m2(vint16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_x_v_f16m4(vint16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_x_v_f16m8(vint16m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_xu_v_f16mf4(vuint16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_xu_v_f16mf2(vuint16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_xu_v_f16m1(vuint16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_xu_v_f16m2(vuint16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_xu_v_f16m4(vuint16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_xu_v_f16m8(vuint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vfcvt_x_f_v_i32mf2(vfloat32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vfcvt_rtz_x_f_v_i32mf2(vfloat32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vfcvt_x_f_v_i32m1(vfloat32m1_t vs2, size_t vl);
vint32m1_t __riscv_vfcvt_rtz_x_f_v_i32m1(vfloat32m1_t vs2, size_t vl);
vint32m2_t __riscv_vfcvt_x_f_v_i32m2(vfloat32m2_t vs2, size_t vl);
vint32m2_t __riscv_vfcvt_rtz_x_f_v_i32m2(vfloat32m2_t vs2, size_t vl);
vint32m4_t __riscv_vfcvt_x_f_v_i32m4(vfloat32m4_t vs2, size_t vl);
vint32m4_t __riscv_vfcvt_rtz_x_f_v_i32m4(vfloat32m4_t vs2, size_t vl);
vint32m8_t __riscv_vfcvt_x_f_v_i32m8(vfloat32m8_t vs2, size_t vl);
vint32m8_t __riscv_vfcvt_rtz_x_f_v_i32m8(vfloat32m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_f_v_u32mf2(vfloat32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vfcvt_rtz_xu_f_v_u32mf2(vfloat32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vfcvt_xu_f_v_u32m1(vfloat32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vfcvt_rtz_xu_f_v_u32m1(vfloat32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vfcvt_xu_f_v_u32m2(vfloat32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vfcvt_rtz_xu_f_v_u32m2(vfloat32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vfcvt_xu_f_v_u32m4(vfloat32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vfcvt_rtz_xu_f_v_u32m4(vfloat32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vfcvt_xu_f_v_u32m8(vfloat32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vfcvt_rtz_xu_f_v_u32m8(vfloat32m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_x_v_f32mf2(vint32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_x_v_f32m1(vint32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_x_v_f32m2(vint32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_x_v_f32m4(vint32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_x_v_f32m8(vint32m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_xu_v_f32mf2(vuint32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_xu_v_f32m1(vuint32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_xu_v_f32m2(vuint32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_xu_v_f32m4(vuint32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_xu_v_f32m8(vuint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vfcvt_x_f_v_i64m1(vfloat64m1_t vs2, size_t vl);
vint64m1_t __riscv_vfcvt_rtz_x_f_v_i64m1(vfloat64m1_t vs2, size_t vl);
vint64m2_t __riscv_vfcvt_x_f_v_i64m2(vfloat64m2_t vs2, size_t vl);
vint64m2_t __riscv_vfcvt_rtz_x_f_v_i64m2(vfloat64m2_t vs2, size_t vl);
vint64m4_t __riscv_vfcvt_x_f_v_i64m4(vfloat64m4_t vs2, size_t vl);
vint64m4_t __riscv_vfcvt_rtz_x_f_v_i64m4(vfloat64m4_t vs2, size_t vl);
vint64m8_t __riscv_vfcvt_x_f_v_i64m8(vfloat64m8_t vs2, size_t vl);
vint64m8_t __riscv_vfcvt_rtz_x_f_v_i64m8(vfloat64m8_t vs2, size_t vl);
vuint64m1_t __riscv_vfcvt_xu_f_v_u64m1(vfloat64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vfcvt_rtz_xu_f_v_u64m1(vfloat64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vfcvt_xu_f_v_u64m2(vfloat64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vfcvt_rtz_xu_f_v_u64m2(vfloat64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vfcvt_xu_f_v_u64m4(vfloat64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vfcvt_rtz_xu_f_v_u64m4(vfloat64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vfcvt_xu_f_v_u64m8(vfloat64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vfcvt_rtz_xu_f_v_u64m8(vfloat64m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_x_v_f64m1(vint64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_x_v_f64m2(vint64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_x_v_f64m4(vint64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_x_v_f64m8(vint64m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_xu_v_f64m1(vuint64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_xu_v_f64m2(vuint64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_xu_v_f64m4(vuint64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_xu_v_f64m8(vuint64m8_t vs2, size_t vl);
// masked functions
vint16mf4_t __riscv_vfcvt_x_f_v_i16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                         size_t vl);
vint16mf4_t __riscv_vfcvt_rtz_x_f_v_i16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                             size_t vl);
vint16mf2_t __riscv_vfcvt_x_f_v_i16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                         size_t vl);
vint16mf2_t __riscv_vfcvt_rtz_x_f_v_i16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                             size_t vl);
vint16m1_t __riscv_vfcvt_x_f_v_i16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                       size_t vl);
vint16m1_t __riscv_vfcvt_rtz_x_f_v_i16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                           size_t vl);
vint16m2_t __riscv_vfcvt_x_f_v_i16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                       size_t vl);
vint16m2_t __riscv_vfcvt_rtz_x_f_v_i16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                           size_t vl);
vint16m4_t __riscv_vfcvt_x_f_v_i16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                       size_t vl);
vint16m4_t __riscv_vfcvt_rtz_x_f_v_i16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                           size_t vl);
vint16m8_t __riscv_vfcvt_x_f_v_i16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                       size_t vl);
vint16m8_t __riscv_vfcvt_rtz_x_f_v_i16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                           size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_f_v_u16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           size_t vl);
vuint16mf4_t __riscv_vfcvt_rtz_xu_f_v_u16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                               size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_f_v_u16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           size_t vl);
vuint16mf2_t __riscv_vfcvt_rtz_xu_f_v_u16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                               size_t vl);
vuint16m1_t __riscv_vfcvt_xu_f_v_u16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                         size_t vl);
vuint16m1_t __riscv_vfcvt_rtz_xu_f_v_u16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                             size_t vl);
vuint16m2_t __riscv_vfcvt_xu_f_v_u16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                         size_t vl);
vuint16m2_t __riscv_vfcvt_rtz_xu_f_v_u16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                             size_t vl);
vuint16m4_t __riscv_vfcvt_xu_f_v_u16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                         size_t vl);
vuint16m4_t __riscv_vfcvt_rtz_xu_f_v_u16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                             size_t vl);
vuint16m8_t __riscv_vfcvt_xu_f_v_u16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                         size_t vl);
vuint16m8_t __riscv_vfcvt_rtz_xu_f_v_u16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                             size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_x_v_f16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                           size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_x_v_f16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                           size_t vl);
vfloat16m1_t __riscv_vfcvt_f_x_v_f16m1_m(vbool16_t vm, vint16m1_t vs2,
                                         size_t vl);
vfloat16m2_t __riscv_vfcvt_f_x_v_f16m2_m(vbool8_t vm, vint16m2_t vs2,
                                         size_t vl);
vfloat16m4_t __riscv_vfcvt_f_x_v_f16m4_m(vbool4_t vm, vint16m4_t vs2,
                                         size_t vl);
vfloat16m8_t __riscv_vfcvt_f_x_v_f16m8_m(vbool2_t vm, vint16m8_t vs2,
                                         size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_xu_v_f16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                            size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_xu_v_f16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                            size_t vl);
vfloat16m1_t __riscv_vfcvt_f_xu_v_f16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                          size_t vl);
vfloat16m2_t __riscv_vfcvt_f_xu_v_f16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                          size_t vl);
vfloat16m4_t __riscv_vfcvt_f_xu_v_f16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                          size_t vl);
vfloat16m8_t __riscv_vfcvt_f_xu_v_f16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                          size_t vl);
vint32mf2_t __riscv_vfcvt_x_f_v_i32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                         size_t vl);
vint32mf2_t __riscv_vfcvt_rtz_x_f_v_i32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                             size_t vl);
vint32m1_t __riscv_vfcvt_x_f_v_i32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                       size_t vl);
vint32m1_t __riscv_vfcvt_rtz_x_f_v_i32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                           size_t vl);
vint32m2_t __riscv_vfcvt_x_f_v_i32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                       size_t vl);
vint32m2_t __riscv_vfcvt_rtz_x_f_v_i32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                           size_t vl);
vint32m4_t __riscv_vfcvt_x_f_v_i32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                       size_t vl);
vint32m4_t __riscv_vfcvt_rtz_x_f_v_i32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                           size_t vl);
vint32m8_t __riscv_vfcvt_x_f_v_i32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                       size_t vl);
vint32m8_t __riscv_vfcvt_rtz_x_f_v_i32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                           size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_f_v_u32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           size_t vl);
vuint32mf2_t __riscv_vfcvt_rtz_xu_f_v_u32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                               size_t vl);
vuint32m1_t __riscv_vfcvt_xu_f_v_u32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                         size_t vl);
vuint32m1_t __riscv_vfcvt_rtz_xu_f_v_u32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                             size_t vl);
vuint32m2_t __riscv_vfcvt_xu_f_v_u32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                         size_t vl);
vuint32m2_t __riscv_vfcvt_rtz_xu_f_v_u32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                             size_t vl);
vuint32m4_t __riscv_vfcvt_xu_f_v_u32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                         size_t vl);
vuint32m4_t __riscv_vfcvt_rtz_xu_f_v_u32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                             size_t vl);
vuint32m8_t __riscv_vfcvt_xu_f_v_u32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                         size_t vl);
vuint32m8_t __riscv_vfcvt_rtz_xu_f_v_u32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                             size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_x_v_f32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                           size_t vl);
vfloat32m1_t __riscv_vfcvt_f_x_v_f32m1_m(vbool32_t vm, vint32m1_t vs2,
                                         size_t vl);
vfloat32m2_t __riscv_vfcvt_f_x_v_f32m2_m(vbool16_t vm, vint32m2_t vs2,
                                         size_t vl);
vfloat32m4_t __riscv_vfcvt_f_x_v_f32m4_m(vbool8_t vm, vint32m4_t vs2,
                                         size_t vl);
vfloat32m8_t __riscv_vfcvt_f_x_v_f32m8_m(vbool4_t vm, vint32m8_t vs2,
                                         size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_xu_v_f32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                            size_t vl);
vfloat32m1_t __riscv_vfcvt_f_xu_v_f32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                          size_t vl);
vfloat32m2_t __riscv_vfcvt_f_xu_v_f32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                          size_t vl);
vfloat32m4_t __riscv_vfcvt_f_xu_v_f32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                          size_t vl);
vfloat32m8_t __riscv_vfcvt_f_xu_v_f32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                          size_t vl);
vint64m1_t __riscv_vfcvt_x_f_v_i64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                       size_t vl);
vint64m1_t __riscv_vfcvt_rtz_x_f_v_i64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                           size_t vl);
vint64m2_t __riscv_vfcvt_x_f_v_i64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                       size_t vl);
vint64m2_t __riscv_vfcvt_rtz_x_f_v_i64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                           size_t vl);
vint64m4_t __riscv_vfcvt_x_f_v_i64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                       size_t vl);
vint64m4_t __riscv_vfcvt_rtz_x_f_v_i64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                           size_t vl);
vint64m8_t __riscv_vfcvt_x_f_v_i64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                       size_t vl);
vint64m8_t __riscv_vfcvt_rtz_x_f_v_i64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                           size_t vl);
vuint64m1_t __riscv_vfcvt_xu_f_v_u64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                         size_t vl);
vuint64m1_t __riscv_vfcvt_rtz_xu_f_v_u64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                             size_t vl);
vuint64m2_t __riscv_vfcvt_xu_f_v_u64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                         size_t vl);
vuint64m2_t __riscv_vfcvt_rtz_xu_f_v_u64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                             size_t vl);
vuint64m4_t __riscv_vfcvt_xu_f_v_u64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                         size_t vl);
vuint64m4_t __riscv_vfcvt_rtz_xu_f_v_u64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                             size_t vl);
vuint64m8_t __riscv_vfcvt_xu_f_v_u64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                         size_t vl);
vuint64m8_t __riscv_vfcvt_rtz_xu_f_v_u64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                             size_t vl);
vfloat64m1_t __riscv_vfcvt_f_x_v_f64m1_m(vbool64_t vm, vint64m1_t vs2,
                                         size_t vl);
vfloat64m2_t __riscv_vfcvt_f_x_v_f64m2_m(vbool32_t vm, vint64m2_t vs2,
                                         size_t vl);
vfloat64m4_t __riscv_vfcvt_f_x_v_f64m4_m(vbool16_t vm, vint64m4_t vs2,
                                         size_t vl);
vfloat64m8_t __riscv_vfcvt_f_x_v_f64m8_m(vbool8_t vm, vint64m8_t vs2,
                                         size_t vl);
vfloat64m1_t __riscv_vfcvt_f_xu_v_f64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                          size_t vl);
vfloat64m2_t __riscv_vfcvt_f_xu_v_f64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                          size_t vl);
vfloat64m4_t __riscv_vfcvt_f_xu_v_f64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                          size_t vl);
vfloat64m8_t __riscv_vfcvt_f_xu_v_f64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                          size_t vl);
vint16mf4_t __riscv_vfcvt_x_f_v_i16mf4_rm(vfloat16mf4_t vs2, unsigned int frm,
                                          size_t vl);
vint16mf2_t __riscv_vfcvt_x_f_v_i16mf2_rm(vfloat16mf2_t vs2, unsigned int frm,
                                          size_t vl);
vint16m1_t __riscv_vfcvt_x_f_v_i16m1_rm(vfloat16m1_t vs2, unsigned int frm,
                                        size_t vl);
vint16m2_t __riscv_vfcvt_x_f_v_i16m2_rm(vfloat16m2_t vs2, unsigned int frm,
                                        size_t vl);
vint16m4_t __riscv_vfcvt_x_f_v_i16m4_rm(vfloat16m4_t vs2, unsigned int frm,
                                        size_t vl);
vint16m8_t __riscv_vfcvt_x_f_v_i16m8_rm(vfloat16m8_t vs2, unsigned int frm,
                                        size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_f_v_u16mf4_rm(vfloat16mf4_t vs2, unsigned int frm,
                                            size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_f_v_u16mf2_rm(vfloat16mf2_t vs2, unsigned int frm,
                                            size_t vl);
vuint16m1_t __riscv_vfcvt_xu_f_v_u16m1_rm(vfloat16m1_t vs2, unsigned int frm,
                                          size_t vl);
vuint16m2_t __riscv_vfcvt_xu_f_v_u16m2_rm(vfloat16m2_t vs2, unsigned int frm,
                                          size_t vl);
vuint16m4_t __riscv_vfcvt_xu_f_v_u16m4_rm(vfloat16m4_t vs2, unsigned int frm,
                                          size_t vl);
vuint16m8_t __riscv_vfcvt_xu_f_v_u16m8_rm(vfloat16m8_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_x_v_f16mf4_rm(vint16mf4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_x_v_f16mf2_rm(vint16mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16m1_t __riscv_vfcvt_f_x_v_f16m1_rm(vint16m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16m2_t __riscv_vfcvt_f_x_v_f16m2_rm(vint16m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16m4_t __riscv_vfcvt_f_x_v_f16m4_rm(vint16m4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16m8_t __riscv_vfcvt_f_x_v_f16m8_rm(vint16m8_t vs2, unsigned int frm,
                                          size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_xu_v_f16mf4_rm(vuint16mf4_t vs2, unsigned int frm,
                                             size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_xu_v_f16mf2_rm(vuint16mf2_t vs2, unsigned int frm,
                                             size_t vl);
vfloat16m1_t __riscv_vfcvt_f_xu_v_f16m1_rm(vuint16m1_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m2_t __riscv_vfcvt_f_xu_v_f16m2_rm(vuint16m2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m4_t __riscv_vfcvt_f_xu_v_f16m4_rm(vuint16m4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m8_t __riscv_vfcvt_f_xu_v_f16m8_rm(vuint16m8_t vs2, unsigned int frm,
                                           size_t vl);
vint32mf2_t __riscv_vfcvt_x_f_v_i32mf2_rm(vfloat32mf2_t vs2, unsigned int frm,
                                          size_t vl);
vint32m1_t __riscv_vfcvt_x_f_v_i32m1_rm(vfloat32m1_t vs2, unsigned int frm,
                                        size_t vl);
vint32m2_t __riscv_vfcvt_x_f_v_i32m2_rm(vfloat32m2_t vs2, unsigned int frm,
                                        size_t vl);
vint32m4_t __riscv_vfcvt_x_f_v_i32m4_rm(vfloat32m4_t vs2, unsigned int frm,
                                        size_t vl);
vint32m8_t __riscv_vfcvt_x_f_v_i32m8_rm(vfloat32m8_t vs2, unsigned int frm,
                                        size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_f_v_u32mf2_rm(vfloat32mf2_t vs2, unsigned int frm,
                                            size_t vl);
vuint32m1_t __riscv_vfcvt_xu_f_v_u32m1_rm(vfloat32m1_t vs2, unsigned int frm,
                                          size_t vl);
vuint32m2_t __riscv_vfcvt_xu_f_v_u32m2_rm(vfloat32m2_t vs2, unsigned int frm,
                                          size_t vl);
vuint32m4_t __riscv_vfcvt_xu_f_v_u32m4_rm(vfloat32m4_t vs2, unsigned int frm,
                                          size_t vl);
vuint32m8_t __riscv_vfcvt_xu_f_v_u32m8_rm(vfloat32m8_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_x_v_f32mf2_rm(vint32mf2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32m1_t __riscv_vfcvt_f_x_v_f32m1_rm(vint32m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m2_t __riscv_vfcvt_f_x_v_f32m2_rm(vint32m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m4_t __riscv_vfcvt_f_x_v_f32m4_rm(vint32m4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32m8_t __riscv_vfcvt_f_x_v_f32m8_rm(vint32m8_t vs2, unsigned int frm,
                                          size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_xu_v_f32mf2_rm(vuint32mf2_t vs2, unsigned int frm,
                                             size_t vl);
vfloat32m1_t __riscv_vfcvt_f_xu_v_f32m1_rm(vuint32m1_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m2_t __riscv_vfcvt_f_xu_v_f32m2_rm(vuint32m2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m4_t __riscv_vfcvt_f_xu_v_f32m4_rm(vuint32m4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m8_t __riscv_vfcvt_f_xu_v_f32m8_rm(vuint32m8_t vs2, unsigned int frm,
                                           size_t vl);
vint64m1_t __riscv_vfcvt_x_f_v_i64m1_rm(vfloat64m1_t vs2, unsigned int frm,
                                        size_t vl);
vint64m2_t __riscv_vfcvt_x_f_v_i64m2_rm(vfloat64m2_t vs2, unsigned int frm,
                                        size_t vl);
vint64m4_t __riscv_vfcvt_x_f_v_i64m4_rm(vfloat64m4_t vs2, unsigned int frm,
                                        size_t vl);
vint64m8_t __riscv_vfcvt_x_f_v_i64m8_rm(vfloat64m8_t vs2, unsigned int frm,
                                        size_t vl);
vuint64m1_t __riscv_vfcvt_xu_f_v_u64m1_rm(vfloat64m1_t vs2, unsigned int frm,
                                          size_t vl);
vuint64m2_t __riscv_vfcvt_xu_f_v_u64m2_rm(vfloat64m2_t vs2, unsigned int frm,
                                          size_t vl);
vuint64m4_t __riscv_vfcvt_xu_f_v_u64m4_rm(vfloat64m4_t vs2, unsigned int frm,
                                          size_t vl);
vuint64m8_t __riscv_vfcvt_xu_f_v_u64m8_rm(vfloat64m8_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfcvt_f_x_v_f64m1_rm(vint64m1_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m2_t __riscv_vfcvt_f_x_v_f64m2_rm(vint64m2_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m4_t __riscv_vfcvt_f_x_v_f64m4_rm(vint64m4_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m8_t __riscv_vfcvt_f_x_v_f64m8_rm(vint64m8_t vs2, unsigned int frm,
                                          size_t vl);
vfloat64m1_t __riscv_vfcvt_f_xu_v_f64m1_rm(vuint64m1_t vs2, unsigned int frm,
                                           size_t vl);
vfloat64m2_t __riscv_vfcvt_f_xu_v_f64m2_rm(vuint64m2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat64m4_t __riscv_vfcvt_f_xu_v_f64m4_rm(vuint64m4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat64m8_t __riscv_vfcvt_f_xu_v_f64m8_rm(vuint64m8_t vs2, unsigned int frm,
                                           size_t vl);
// masked functions
vint16mf4_t __riscv_vfcvt_x_f_v_i16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            unsigned int frm, size_t vl);
vint16mf2_t __riscv_vfcvt_x_f_v_i16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                            unsigned int frm, size_t vl);
vint16m1_t __riscv_vfcvt_x_f_v_i16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                          unsigned int frm, size_t vl);
vint16m2_t __riscv_vfcvt_x_f_v_i16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                          unsigned int frm, size_t vl);
vint16m4_t __riscv_vfcvt_x_f_v_i16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                          unsigned int frm, size_t vl);
vint16m8_t __riscv_vfcvt_x_f_v_i16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                          unsigned int frm, size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_f_v_u16mf4_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                              unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_f_v_u16mf2_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                              unsigned int frm, size_t vl);
vuint16m1_t __riscv_vfcvt_xu_f_v_u16m1_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                            unsigned int frm, size_t vl);
vuint16m2_t __riscv_vfcvt_xu_f_v_u16m2_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                            unsigned int frm, size_t vl);
vuint16m4_t __riscv_vfcvt_xu_f_v_u16m4_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                            unsigned int frm, size_t vl);
vuint16m8_t __riscv_vfcvt_xu_f_v_u16m8_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_x_v_f16mf4_rm_m(vbool64_t vm, vint16mf4_t vs2,
                                              unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_x_v_f16mf2_rm_m(vbool32_t vm, vint16mf2_t vs2,
                                              unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_x_v_f16m1_rm_m(vbool16_t vm, vint16m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_x_v_f16m2_rm_m(vbool8_t vm, vint16m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_x_v_f16m4_rm_m(vbool4_t vm, vint16m4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_x_v_f16m8_rm_m(vbool2_t vm, vint16m8_t vs2,
                                            unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_xu_v_f16mf4_rm_m(vbool64_t vm, vuint16mf4_t vs2,
                                               unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_xu_v_f16mf2_rm_m(vbool32_t vm, vuint16mf2_t vs2,
                                               unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_xu_v_f16m1_rm_m(vbool16_t vm, vuint16m1_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_xu_v_f16m2_rm_m(vbool8_t vm, vuint16m2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_xu_v_f16m4_rm_m(vbool4_t vm, vuint16m4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_xu_v_f16m8_rm_m(vbool2_t vm, vuint16m8_t vs2,
                                             unsigned int frm, size_t vl);
vint32mf2_t __riscv_vfcvt_x_f_v_i32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            unsigned int frm, size_t vl);
vint32m1_t __riscv_vfcvt_x_f_v_i32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                          unsigned int frm, size_t vl);
vint32m2_t __riscv_vfcvt_x_f_v_i32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                          unsigned int frm, size_t vl);
vint32m4_t __riscv_vfcvt_x_f_v_i32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                          unsigned int frm, size_t vl);
vint32m8_t __riscv_vfcvt_x_f_v_i32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                          unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_f_v_u32mf2_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                              unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfcvt_xu_f_v_u32m1_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                            unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfcvt_xu_f_v_u32m2_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                            unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfcvt_xu_f_v_u32m4_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                            unsigned int frm, size_t vl);
vuint32m8_t __riscv_vfcvt_xu_f_v_u32m8_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_x_v_f32mf2_rm_m(vbool64_t vm, vint32mf2_t vs2,
                                              unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_x_v_f32m1_rm_m(vbool32_t vm, vint32m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_x_v_f32m2_rm_m(vbool16_t vm, vint32m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_x_v_f32m4_rm_m(vbool8_t vm, vint32m4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_x_v_f32m8_rm_m(vbool4_t vm, vint32m8_t vs2,
                                            unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_xu_v_f32mf2_rm_m(vbool64_t vm, vuint32mf2_t vs2,
                                               unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_xu_v_f32m1_rm_m(vbool32_t vm, vuint32m1_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_xu_v_f32m2_rm_m(vbool16_t vm, vuint32m2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_xu_v_f32m4_rm_m(vbool8_t vm, vuint32m4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_xu_v_f32m8_rm_m(vbool4_t vm, vuint32m8_t vs2,
                                             unsigned int frm, size_t vl);
vint64m1_t __riscv_vfcvt_x_f_v_i64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                          unsigned int frm, size_t vl);
vint64m2_t __riscv_vfcvt_x_f_v_i64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                          unsigned int frm, size_t vl);
vint64m4_t __riscv_vfcvt_x_f_v_i64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                          unsigned int frm, size_t vl);
vint64m8_t __riscv_vfcvt_x_f_v_i64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                          unsigned int frm, size_t vl);
vuint64m1_t __riscv_vfcvt_xu_f_v_u64m1_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                            unsigned int frm, size_t vl);
vuint64m2_t __riscv_vfcvt_xu_f_v_u64m2_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                            unsigned int frm, size_t vl);
vuint64m4_t __riscv_vfcvt_xu_f_v_u64m4_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                            unsigned int frm, size_t vl);
vuint64m8_t __riscv_vfcvt_xu_f_v_u64m8_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_x_v_f64m1_rm_m(vbool64_t vm, vint64m1_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_x_v_f64m2_rm_m(vbool32_t vm, vint64m2_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_x_v_f64m4_rm_m(vbool16_t vm, vint64m4_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_x_v_f64m8_rm_m(vbool8_t vm, vint64m8_t vs2,
                                            unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_xu_v_f64m1_rm_m(vbool64_t vm, vuint64m1_t vs2,
                                             unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_xu_v_f64m2_rm_m(vbool32_t vm, vuint64m2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_xu_v_f64m4_rm_m(vbool16_t vm, vuint64m4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_xu_v_f64m8_rm_m(vbool8_t vm, vuint64m8_t vs2,
                                             unsigned int frm, size_t vl);
----

[[widening-floating-pointinteger-type-convert]]
==== Widening Floating-Point/Integer Type-Convert Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfwcvt_f_x_v_f16mf4(vint8mf8_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_x_v_f16mf2(vint8mf4_t vs2, size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_x_v_f16m1(vint8mf2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_x_v_f16m2(vint8m1_t vs2, size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_x_v_f16m4(vint8m2_t vs2, size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_x_v_f16m8(vint8m4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfwcvt_f_xu_v_f16mf4(vuint8mf8_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_xu_v_f16mf2(vuint8mf4_t vs2, size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_xu_v_f16m1(vuint8mf2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_xu_v_f16m2(vuint8m1_t vs2, size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_xu_v_f16m4(vuint8m2_t vs2, size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_xu_v_f16m8(vuint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vfwcvt_x_f_v_i32mf2(vfloat16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vfwcvt_rtz_x_f_v_i32mf2(vfloat16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vfwcvt_x_f_v_i32m1(vfloat16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vfwcvt_rtz_x_f_v_i32m1(vfloat16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vfwcvt_x_f_v_i32m2(vfloat16m1_t vs2, size_t vl);
vint32m2_t __riscv_vfwcvt_rtz_x_f_v_i32m2(vfloat16m1_t vs2, size_t vl);
vint32m4_t __riscv_vfwcvt_x_f_v_i32m4(vfloat16m2_t vs2, size_t vl);
vint32m4_t __riscv_vfwcvt_rtz_x_f_v_i32m4(vfloat16m2_t vs2, size_t vl);
vint32m8_t __riscv_vfwcvt_x_f_v_i32m8(vfloat16m4_t vs2, size_t vl);
vint32m8_t __riscv_vfwcvt_rtz_x_f_v_i32m8(vfloat16m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_f_v_u32mf2(vfloat16mf4_t vs2, size_t vl);
vuint32mf2_t __riscv_vfwcvt_rtz_xu_f_v_u32mf2(vfloat16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_f_v_u32m1(vfloat16mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vfwcvt_rtz_xu_f_v_u32m1(vfloat16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_f_v_u32m2(vfloat16m1_t vs2, size_t vl);
vuint32m2_t __riscv_vfwcvt_rtz_xu_f_v_u32m2(vfloat16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_f_v_u32m4(vfloat16m2_t vs2, size_t vl);
vuint32m4_t __riscv_vfwcvt_rtz_xu_f_v_u32m4(vfloat16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_f_v_u32m8(vfloat16m4_t vs2, size_t vl);
vuint32m8_t __riscv_vfwcvt_rtz_xu_f_v_u32m8(vfloat16m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_x_v_f32mf2(vint16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_x_v_f32m1(vint16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_x_v_f32m2(vint16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_x_v_f32m4(vint16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_x_v_f32m8(vint16m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_xu_v_f32mf2(vuint16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_xu_v_f32m1(vuint16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_xu_v_f32m2(vuint16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_xu_v_f32m4(vuint16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_xu_v_f32m8(vuint16m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_f_v_f32mf2(vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_f_v_f32m1(vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_f_v_f32m2(vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_f_v_f32m4(vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_f_v_f32m8(vfloat16m4_t vs2, size_t vl);
vint64m1_t __riscv_vfwcvt_x_f_v_i64m1(vfloat32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vfwcvt_rtz_x_f_v_i64m1(vfloat32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vfwcvt_x_f_v_i64m2(vfloat32m1_t vs2, size_t vl);
vint64m2_t __riscv_vfwcvt_rtz_x_f_v_i64m2(vfloat32m1_t vs2, size_t vl);
vint64m4_t __riscv_vfwcvt_x_f_v_i64m4(vfloat32m2_t vs2, size_t vl);
vint64m4_t __riscv_vfwcvt_rtz_x_f_v_i64m4(vfloat32m2_t vs2, size_t vl);
vint64m8_t __riscv_vfwcvt_x_f_v_i64m8(vfloat32m4_t vs2, size_t vl);
vint64m8_t __riscv_vfwcvt_rtz_x_f_v_i64m8(vfloat32m4_t vs2, size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_f_v_u64m1(vfloat32mf2_t vs2, size_t vl);
vuint64m1_t __riscv_vfwcvt_rtz_xu_f_v_u64m1(vfloat32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_f_v_u64m2(vfloat32m1_t vs2, size_t vl);
vuint64m2_t __riscv_vfwcvt_rtz_xu_f_v_u64m2(vfloat32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_f_v_u64m4(vfloat32m2_t vs2, size_t vl);
vuint64m4_t __riscv_vfwcvt_rtz_xu_f_v_u64m4(vfloat32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_f_v_u64m8(vfloat32m4_t vs2, size_t vl);
vuint64m8_t __riscv_vfwcvt_rtz_xu_f_v_u64m8(vfloat32m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_x_v_f64m1(vint32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_x_v_f64m2(vint32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_x_v_f64m4(vint32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_x_v_f64m8(vint32m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_xu_v_f64m1(vuint32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_xu_v_f64m2(vuint32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_xu_v_f64m4(vuint32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_xu_v_f64m8(vuint32m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_f_v_f64m1(vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_f_v_f64m2(vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_f_v_f64m4(vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_f_v_f64m8(vfloat32m4_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfwcvt_f_x_v_f16mf4_m(vbool64_t vm, vint8mf8_t vs2,
                                            size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_x_v_f16mf2_m(vbool32_t vm, vint8mf4_t vs2,
                                            size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_x_v_f16m1_m(vbool16_t vm, vint8mf2_t vs2,
                                          size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_x_v_f16m2_m(vbool8_t vm, vint8m1_t vs2,
                                          size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_x_v_f16m4_m(vbool4_t vm, vint8m2_t vs2,
                                          size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_x_v_f16m8_m(vbool2_t vm, vint8m4_t vs2,
                                          size_t vl);
vfloat16mf4_t __riscv_vfwcvt_f_xu_v_f16mf4_m(vbool64_t vm, vuint8mf8_t vs2,
                                             size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_xu_v_f16mf2_m(vbool32_t vm, vuint8mf4_t vs2,
                                             size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_xu_v_f16m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                           size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_xu_v_f16m2_m(vbool8_t vm, vuint8m1_t vs2,
                                           size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_xu_v_f16m4_m(vbool4_t vm, vuint8m2_t vs2,
                                           size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_xu_v_f16m8_m(vbool2_t vm, vuint8m4_t vs2,
                                           size_t vl);
vint32mf2_t __riscv_vfwcvt_x_f_v_i32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                          size_t vl);
vint32mf2_t __riscv_vfwcvt_rtz_x_f_v_i32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                              size_t vl);
vint32m1_t __riscv_vfwcvt_x_f_v_i32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        size_t vl);
vint32m1_t __riscv_vfwcvt_rtz_x_f_v_i32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                            size_t vl);
vint32m2_t __riscv_vfwcvt_x_f_v_i32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                        size_t vl);
vint32m2_t __riscv_vfwcvt_rtz_x_f_v_i32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                            size_t vl);
vint32m4_t __riscv_vfwcvt_x_f_v_i32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                        size_t vl);
vint32m4_t __riscv_vfwcvt_rtz_x_f_v_i32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                            size_t vl);
vint32m8_t __riscv_vfwcvt_x_f_v_i32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                        size_t vl);
vint32m8_t __riscv_vfwcvt_rtz_x_f_v_i32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                            size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_f_v_u32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            size_t vl);
vuint32mf2_t __riscv_vfwcvt_rtz_xu_f_v_u32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                                size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_f_v_u32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          size_t vl);
vuint32m1_t __riscv_vfwcvt_rtz_xu_f_v_u32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                              size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_f_v_u32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                          size_t vl);
vuint32m2_t __riscv_vfwcvt_rtz_xu_f_v_u32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                              size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_f_v_u32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                          size_t vl);
vuint32m4_t __riscv_vfwcvt_rtz_xu_f_v_u32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                              size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_f_v_u32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                          size_t vl);
vuint32m8_t __riscv_vfwcvt_rtz_xu_f_v_u32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                              size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_x_v_f32mf2_m(vbool64_t vm, vint16mf4_t vs2,
                                            size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_x_v_f32m1_m(vbool32_t vm, vint16mf2_t vs2,
                                          size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_x_v_f32m2_m(vbool16_t vm, vint16m1_t vs2,
                                          size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_x_v_f32m4_m(vbool8_t vm, vint16m2_t vs2,
                                          size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_x_v_f32m8_m(vbool4_t vm, vint16m4_t vs2,
                                          size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_xu_v_f32mf2_m(vbool64_t vm, vuint16mf4_t vs2,
                                             size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_xu_v_f32m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                           size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_xu_v_f32m2_m(vbool16_t vm, vuint16m1_t vs2,
                                           size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_xu_v_f32m4_m(vbool8_t vm, vuint16m2_t vs2,
                                           size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_xu_v_f32m8_m(vbool4_t vm, vuint16m4_t vs2,
                                           size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_f_v_f32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_f_v_f32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_f_v_f32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                          size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_f_v_f32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                          size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_f_v_f32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                          size_t vl);
vint64m1_t __riscv_vfwcvt_x_f_v_i64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                        size_t vl);
vint64m1_t __riscv_vfwcvt_rtz_x_f_v_i64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            size_t vl);
vint64m2_t __riscv_vfwcvt_x_f_v_i64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                        size_t vl);
vint64m2_t __riscv_vfwcvt_rtz_x_f_v_i64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                            size_t vl);
vint64m4_t __riscv_vfwcvt_x_f_v_i64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                        size_t vl);
vint64m4_t __riscv_vfwcvt_rtz_x_f_v_i64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                            size_t vl);
vint64m8_t __riscv_vfwcvt_x_f_v_i64m8_m(vbool8_t vm, vfloat32m4_t vs2,
                                        size_t vl);
vint64m8_t __riscv_vfwcvt_rtz_x_f_v_i64m8_m(vbool8_t vm, vfloat32m4_t vs2,
                                            size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_f_v_u64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          size_t vl);
vuint64m1_t __riscv_vfwcvt_rtz_xu_f_v_u64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                              size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_f_v_u64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                          size_t vl);
vuint64m2_t __riscv_vfwcvt_rtz_xu_f_v_u64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                              size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_f_v_u64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                          size_t vl);
vuint64m4_t __riscv_vfwcvt_rtz_xu_f_v_u64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                              size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_f_v_u64m8_m(vbool8_t vm, vfloat32m4_t vs2,
                                          size_t vl);
vuint64m8_t __riscv_vfwcvt_rtz_xu_f_v_u64m8_m(vbool8_t vm, vfloat32m4_t vs2,
                                              size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_x_v_f64m1_m(vbool64_t vm, vint32mf2_t vs2,
                                          size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_x_v_f64m2_m(vbool32_t vm, vint32m1_t vs2,
                                          size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_x_v_f64m4_m(vbool16_t vm, vint32m2_t vs2,
                                          size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_x_v_f64m8_m(vbool8_t vm, vint32m4_t vs2,
                                          size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_xu_v_f64m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                           size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_xu_v_f64m2_m(vbool32_t vm, vuint32m1_t vs2,
                                           size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_xu_v_f64m4_m(vbool16_t vm, vuint32m2_t vs2,
                                           size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_xu_v_f64m8_m(vbool8_t vm, vuint32m4_t vs2,
                                           size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_f_v_f64m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_f_v_f64m2_m(vbool32_t vm, vfloat32m1_t vs2,
                                          size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_f_v_f64m4_m(vbool16_t vm, vfloat32m2_t vs2,
                                          size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_f_v_f64m8_m(vbool8_t vm, vfloat32m4_t vs2,
                                          size_t vl);
vint32mf2_t __riscv_vfwcvt_x_f_v_i32mf2_rm(vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vint32m1_t __riscv_vfwcvt_x_f_v_i32m1_rm(vfloat16mf2_t vs2, unsigned int frm,
                                         size_t vl);
vint32m2_t __riscv_vfwcvt_x_f_v_i32m2_rm(vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vint32m4_t __riscv_vfwcvt_x_f_v_i32m4_rm(vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vint32m8_t __riscv_vfwcvt_x_f_v_i32m8_rm(vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_f_v_u32mf2_rm(vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_f_v_u32m1_rm(vfloat16mf2_t vs2, unsigned int frm,
                                           size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_f_v_u32m2_rm(vfloat16m1_t vs2, unsigned int frm,
                                           size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_f_v_u32m4_rm(vfloat16m2_t vs2, unsigned int frm,
                                           size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_f_v_u32m8_rm(vfloat16m4_t vs2, unsigned int frm,
                                           size_t vl);
vint64m1_t __riscv_vfwcvt_x_f_v_i64m1_rm(vfloat32mf2_t vs2, unsigned int frm,
                                         size_t vl);
vint64m2_t __riscv_vfwcvt_x_f_v_i64m2_rm(vfloat32m1_t vs2, unsigned int frm,
                                         size_t vl);
vint64m4_t __riscv_vfwcvt_x_f_v_i64m4_rm(vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vint64m8_t __riscv_vfwcvt_x_f_v_i64m8_rm(vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_f_v_u64m1_rm(vfloat32mf2_t vs2, unsigned int frm,
                                           size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_f_v_u64m2_rm(vfloat32m1_t vs2, unsigned int frm,
                                           size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_f_v_u64m4_rm(vfloat32m2_t vs2, unsigned int frm,
                                           size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_f_v_u64m8_rm(vfloat32m4_t vs2, unsigned int frm,
                                           size_t vl);
// masked functions
vint32mf2_t __riscv_vfwcvt_x_f_v_i32mf2_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vint32m1_t __riscv_vfwcvt_x_f_v_i32m1_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           unsigned int frm, size_t vl);
vint32m2_t __riscv_vfwcvt_x_f_v_i32m2_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vint32m4_t __riscv_vfwcvt_x_f_v_i32m4_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vint32m8_t __riscv_vfwcvt_x_f_v_i32m8_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_f_v_u32mf2_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                               unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_f_v_u32m1_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                             unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_f_v_u32m2_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                             unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_f_v_u32m4_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                             unsigned int frm, size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_f_v_u32m8_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                             unsigned int frm, size_t vl);
vint64m1_t __riscv_vfwcvt_x_f_v_i64m1_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           unsigned int frm, size_t vl);
vint64m2_t __riscv_vfwcvt_x_f_v_i64m2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                           unsigned int frm, size_t vl);
vint64m4_t __riscv_vfwcvt_x_f_v_i64m4_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vint64m8_t __riscv_vfwcvt_x_f_v_i64m8_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_f_v_u64m1_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_f_v_u64m2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                             unsigned int frm, size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_f_v_u64m4_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                             unsigned int frm, size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_f_v_u64m8_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                             unsigned int frm, size_t vl);
----

[[narrowing-floating-pointinteger-type-convert]]
==== Narrowing Floating-Point/Integer Type-Convert Intrinsics

[,c]
----
vint8mf8_t __riscv_vfncvt_x_f_w_i8mf8(vfloat16mf4_t vs2, size_t vl);
vint8mf8_t __riscv_vfncvt_rtz_x_f_w_i8mf8(vfloat16mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vfncvt_x_f_w_i8mf4(vfloat16mf2_t vs2, size_t vl);
vint8mf4_t __riscv_vfncvt_rtz_x_f_w_i8mf4(vfloat16mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vfncvt_x_f_w_i8mf2(vfloat16m1_t vs2, size_t vl);
vint8mf2_t __riscv_vfncvt_rtz_x_f_w_i8mf2(vfloat16m1_t vs2, size_t vl);
vint8m1_t __riscv_vfncvt_x_f_w_i8m1(vfloat16m2_t vs2, size_t vl);
vint8m1_t __riscv_vfncvt_rtz_x_f_w_i8m1(vfloat16m2_t vs2, size_t vl);
vint8m2_t __riscv_vfncvt_x_f_w_i8m2(vfloat16m4_t vs2, size_t vl);
vint8m2_t __riscv_vfncvt_rtz_x_f_w_i8m2(vfloat16m4_t vs2, size_t vl);
vint8m4_t __riscv_vfncvt_x_f_w_i8m4(vfloat16m8_t vs2, size_t vl);
vint8m4_t __riscv_vfncvt_rtz_x_f_w_i8m4(vfloat16m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_f_w_u8mf8(vfloat16mf4_t vs2, size_t vl);
vuint8mf8_t __riscv_vfncvt_rtz_xu_f_w_u8mf8(vfloat16mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_f_w_u8mf4(vfloat16mf2_t vs2, size_t vl);
vuint8mf4_t __riscv_vfncvt_rtz_xu_f_w_u8mf4(vfloat16mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_f_w_u8mf2(vfloat16m1_t vs2, size_t vl);
vuint8mf2_t __riscv_vfncvt_rtz_xu_f_w_u8mf2(vfloat16m1_t vs2, size_t vl);
vuint8m1_t __riscv_vfncvt_xu_f_w_u8m1(vfloat16m2_t vs2, size_t vl);
vuint8m1_t __riscv_vfncvt_rtz_xu_f_w_u8m1(vfloat16m2_t vs2, size_t vl);
vuint8m2_t __riscv_vfncvt_xu_f_w_u8m2(vfloat16m4_t vs2, size_t vl);
vuint8m2_t __riscv_vfncvt_rtz_xu_f_w_u8m2(vfloat16m4_t vs2, size_t vl);
vuint8m4_t __riscv_vfncvt_xu_f_w_u8m4(vfloat16m8_t vs2, size_t vl);
vuint8m4_t __riscv_vfncvt_rtz_xu_f_w_u8m4(vfloat16m8_t vs2, size_t vl);
vint16mf4_t __riscv_vfncvt_x_f_w_i16mf4(vfloat32mf2_t vs2, size_t vl);
vint16mf4_t __riscv_vfncvt_rtz_x_f_w_i16mf4(vfloat32mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vfncvt_x_f_w_i16mf2(vfloat32m1_t vs2, size_t vl);
vint16mf2_t __riscv_vfncvt_rtz_x_f_w_i16mf2(vfloat32m1_t vs2, size_t vl);
vint16m1_t __riscv_vfncvt_x_f_w_i16m1(vfloat32m2_t vs2, size_t vl);
vint16m1_t __riscv_vfncvt_rtz_x_f_w_i16m1(vfloat32m2_t vs2, size_t vl);
vint16m2_t __riscv_vfncvt_x_f_w_i16m2(vfloat32m4_t vs2, size_t vl);
vint16m2_t __riscv_vfncvt_rtz_x_f_w_i16m2(vfloat32m4_t vs2, size_t vl);
vint16m4_t __riscv_vfncvt_x_f_w_i16m4(vfloat32m8_t vs2, size_t vl);
vint16m4_t __riscv_vfncvt_rtz_x_f_w_i16m4(vfloat32m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_f_w_u16mf4(vfloat32mf2_t vs2, size_t vl);
vuint16mf4_t __riscv_vfncvt_rtz_xu_f_w_u16mf4(vfloat32mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_f_w_u16mf2(vfloat32m1_t vs2, size_t vl);
vuint16mf2_t __riscv_vfncvt_rtz_xu_f_w_u16mf2(vfloat32m1_t vs2, size_t vl);
vuint16m1_t __riscv_vfncvt_xu_f_w_u16m1(vfloat32m2_t vs2, size_t vl);
vuint16m1_t __riscv_vfncvt_rtz_xu_f_w_u16m1(vfloat32m2_t vs2, size_t vl);
vuint16m2_t __riscv_vfncvt_xu_f_w_u16m2(vfloat32m4_t vs2, size_t vl);
vuint16m2_t __riscv_vfncvt_rtz_xu_f_w_u16m2(vfloat32m4_t vs2, size_t vl);
vuint16m4_t __riscv_vfncvt_xu_f_w_u16m4(vfloat32m8_t vs2, size_t vl);
vuint16m4_t __riscv_vfncvt_rtz_xu_f_w_u16m4(vfloat32m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_x_w_f16mf4(vint32mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_x_w_f16mf2(vint32m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_x_w_f16m1(vint32m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_x_w_f16m2(vint32m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_x_w_f16m4(vint32m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_xu_w_f16mf4(vuint32mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_xu_w_f16mf2(vuint32m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_xu_w_f16m1(vuint32m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_xu_w_f16m2(vuint32m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_xu_w_f16m4(vuint32m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4(vfloat32mf2_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_f_w_f16mf4(vfloat32mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2(vfloat32m1_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_f_w_f16mf2(vfloat32m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1(vfloat32m2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_f_w_f16m1(vfloat32m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2(vfloat32m4_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_f_w_f16m2(vfloat32m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4(vfloat32m8_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_f_w_f16m4(vfloat32m8_t vs2, size_t vl);
vint32mf2_t __riscv_vfncvt_x_f_w_i32mf2(vfloat64m1_t vs2, size_t vl);
vint32mf2_t __riscv_vfncvt_rtz_x_f_w_i32mf2(vfloat64m1_t vs2, size_t vl);
vint32m1_t __riscv_vfncvt_x_f_w_i32m1(vfloat64m2_t vs2, size_t vl);
vint32m1_t __riscv_vfncvt_rtz_x_f_w_i32m1(vfloat64m2_t vs2, size_t vl);
vint32m2_t __riscv_vfncvt_x_f_w_i32m2(vfloat64m4_t vs2, size_t vl);
vint32m2_t __riscv_vfncvt_rtz_x_f_w_i32m2(vfloat64m4_t vs2, size_t vl);
vint32m4_t __riscv_vfncvt_x_f_w_i32m4(vfloat64m8_t vs2, size_t vl);
vint32m4_t __riscv_vfncvt_rtz_x_f_w_i32m4(vfloat64m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_f_w_u32mf2(vfloat64m1_t vs2, size_t vl);
vuint32mf2_t __riscv_vfncvt_rtz_xu_f_w_u32mf2(vfloat64m1_t vs2, size_t vl);
vuint32m1_t __riscv_vfncvt_xu_f_w_u32m1(vfloat64m2_t vs2, size_t vl);
vuint32m1_t __riscv_vfncvt_rtz_xu_f_w_u32m1(vfloat64m2_t vs2, size_t vl);
vuint32m2_t __riscv_vfncvt_xu_f_w_u32m2(vfloat64m4_t vs2, size_t vl);
vuint32m2_t __riscv_vfncvt_rtz_xu_f_w_u32m2(vfloat64m4_t vs2, size_t vl);
vuint32m4_t __riscv_vfncvt_xu_f_w_u32m4(vfloat64m8_t vs2, size_t vl);
vuint32m4_t __riscv_vfncvt_rtz_xu_f_w_u32m4(vfloat64m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_x_w_f32mf2(vint64m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_x_w_f32m1(vint64m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_x_w_f32m2(vint64m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_x_w_f32m4(vint64m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_xu_w_f32mf2(vuint64m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_xu_w_f32m1(vuint64m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_xu_w_f32m2(vuint64m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_xu_w_f32m4(vuint64m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_f_w_f32mf2(vfloat64m1_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfncvt_rod_f_f_w_f32mf2(vfloat64m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_f_w_f32m1(vfloat64m2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfncvt_rod_f_f_w_f32m1(vfloat64m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_f_w_f32m2(vfloat64m4_t vs2, size_t vl);
vfloat32m2_t __riscv_vfncvt_rod_f_f_w_f32m2(vfloat64m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_f_w_f32m4(vfloat64m8_t vs2, size_t vl);
vfloat32m4_t __riscv_vfncvt_rod_f_f_w_f32m4(vfloat64m8_t vs2, size_t vl);
// masked functions
vint8mf8_t __riscv_vfncvt_x_f_w_i8mf8_m(vbool64_t vm, vfloat16mf4_t vs2,
                                        size_t vl);
vint8mf8_t __riscv_vfncvt_rtz_x_f_w_i8mf8_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            size_t vl);
vint8mf4_t __riscv_vfncvt_x_f_w_i8mf4_m(vbool32_t vm, vfloat16mf2_t vs2,
                                        size_t vl);
vint8mf4_t __riscv_vfncvt_rtz_x_f_w_i8mf4_m(vbool32_t vm, vfloat16mf2_t vs2,
                                            size_t vl);
vint8mf2_t __riscv_vfncvt_x_f_w_i8mf2_m(vbool16_t vm, vfloat16m1_t vs2,
                                        size_t vl);
vint8mf2_t __riscv_vfncvt_rtz_x_f_w_i8mf2_m(vbool16_t vm, vfloat16m1_t vs2,
                                            size_t vl);
vint8m1_t __riscv_vfncvt_x_f_w_i8m1_m(vbool8_t vm, vfloat16m2_t vs2, size_t vl);
vint8m1_t __riscv_vfncvt_rtz_x_f_w_i8m1_m(vbool8_t vm, vfloat16m2_t vs2,
                                          size_t vl);
vint8m2_t __riscv_vfncvt_x_f_w_i8m2_m(vbool4_t vm, vfloat16m4_t vs2, size_t vl);
vint8m2_t __riscv_vfncvt_rtz_x_f_w_i8m2_m(vbool4_t vm, vfloat16m4_t vs2,
                                          size_t vl);
vint8m4_t __riscv_vfncvt_x_f_w_i8m4_m(vbool2_t vm, vfloat16m8_t vs2, size_t vl);
vint8m4_t __riscv_vfncvt_rtz_x_f_w_i8m4_m(vbool2_t vm, vfloat16m8_t vs2,
                                          size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_f_w_u8mf8_m(vbool64_t vm, vfloat16mf4_t vs2,
                                          size_t vl);
vuint8mf8_t __riscv_vfncvt_rtz_xu_f_w_u8mf8_m(vbool64_t vm, vfloat16mf4_t vs2,
                                              size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_f_w_u8mf4_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          size_t vl);
vuint8mf4_t __riscv_vfncvt_rtz_xu_f_w_u8mf4_m(vbool32_t vm, vfloat16mf2_t vs2,
                                              size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_f_w_u8mf2_m(vbool16_t vm, vfloat16m1_t vs2,
                                          size_t vl);
vuint8mf2_t __riscv_vfncvt_rtz_xu_f_w_u8mf2_m(vbool16_t vm, vfloat16m1_t vs2,
                                              size_t vl);
vuint8m1_t __riscv_vfncvt_xu_f_w_u8m1_m(vbool8_t vm, vfloat16m2_t vs2,
                                        size_t vl);
vuint8m1_t __riscv_vfncvt_rtz_xu_f_w_u8m1_m(vbool8_t vm, vfloat16m2_t vs2,
                                            size_t vl);
vuint8m2_t __riscv_vfncvt_xu_f_w_u8m2_m(vbool4_t vm, vfloat16m4_t vs2,
                                        size_t vl);
vuint8m2_t __riscv_vfncvt_rtz_xu_f_w_u8m2_m(vbool4_t vm, vfloat16m4_t vs2,
                                            size_t vl);
vuint8m4_t __riscv_vfncvt_xu_f_w_u8m4_m(vbool2_t vm, vfloat16m8_t vs2,
                                        size_t vl);
vuint8m4_t __riscv_vfncvt_rtz_xu_f_w_u8m4_m(vbool2_t vm, vfloat16m8_t vs2,
                                            size_t vl);
vint16mf4_t __riscv_vfncvt_x_f_w_i16mf4_m(vbool64_t vm, vfloat32mf2_t vs2,
                                          size_t vl);
vint16mf4_t __riscv_vfncvt_rtz_x_f_w_i16mf4_m(vbool64_t vm, vfloat32mf2_t vs2,
                                              size_t vl);
vint16mf2_t __riscv_vfncvt_x_f_w_i16mf2_m(vbool32_t vm, vfloat32m1_t vs2,
                                          size_t vl);
vint16mf2_t __riscv_vfncvt_rtz_x_f_w_i16mf2_m(vbool32_t vm, vfloat32m1_t vs2,
                                              size_t vl);
vint16m1_t __riscv_vfncvt_x_f_w_i16m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                        size_t vl);
vint16m1_t __riscv_vfncvt_rtz_x_f_w_i16m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                            size_t vl);
vint16m2_t __riscv_vfncvt_x_f_w_i16m2_m(vbool8_t vm, vfloat32m4_t vs2,
                                        size_t vl);
vint16m2_t __riscv_vfncvt_rtz_x_f_w_i16m2_m(vbool8_t vm, vfloat32m4_t vs2,
                                            size_t vl);
vint16m4_t __riscv_vfncvt_x_f_w_i16m4_m(vbool4_t vm, vfloat32m8_t vs2,
                                        size_t vl);
vint16m4_t __riscv_vfncvt_rtz_x_f_w_i16m4_m(vbool4_t vm, vfloat32m8_t vs2,
                                            size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_f_w_u16mf4_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            size_t vl);
vuint16mf4_t __riscv_vfncvt_rtz_xu_f_w_u16mf4_m(vbool64_t vm, vfloat32mf2_t vs2,
                                                size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_f_w_u16mf2_m(vbool32_t vm, vfloat32m1_t vs2,
                                            size_t vl);
vuint16mf2_t __riscv_vfncvt_rtz_xu_f_w_u16mf2_m(vbool32_t vm, vfloat32m1_t vs2,
                                                size_t vl);
vuint16m1_t __riscv_vfncvt_xu_f_w_u16m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                          size_t vl);
vuint16m1_t __riscv_vfncvt_rtz_xu_f_w_u16m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                              size_t vl);
vuint16m2_t __riscv_vfncvt_xu_f_w_u16m2_m(vbool8_t vm, vfloat32m4_t vs2,
                                          size_t vl);
vuint16m2_t __riscv_vfncvt_rtz_xu_f_w_u16m2_m(vbool8_t vm, vfloat32m4_t vs2,
                                              size_t vl);
vuint16m4_t __riscv_vfncvt_xu_f_w_u16m4_m(vbool4_t vm, vfloat32m8_t vs2,
                                          size_t vl);
vuint16m4_t __riscv_vfncvt_rtz_xu_f_w_u16m4_m(vbool4_t vm, vfloat32m8_t vs2,
                                              size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_x_w_f16mf4_m(vbool64_t vm, vint32mf2_t vs2,
                                            size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_x_w_f16mf2_m(vbool32_t vm, vint32m1_t vs2,
                                            size_t vl);
vfloat16m1_t __riscv_vfncvt_f_x_w_f16m1_m(vbool16_t vm, vint32m2_t vs2,
                                          size_t vl);
vfloat16m2_t __riscv_vfncvt_f_x_w_f16m2_m(vbool8_t vm, vint32m4_t vs2,
                                          size_t vl);
vfloat16m4_t __riscv_vfncvt_f_x_w_f16m4_m(vbool4_t vm, vint32m8_t vs2,
                                          size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_xu_w_f16mf4_m(vbool64_t vm, vuint32mf2_t vs2,
                                             size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_xu_w_f16mf2_m(vbool32_t vm, vuint32m1_t vs2,
                                             size_t vl);
vfloat16m1_t __riscv_vfncvt_f_xu_w_f16m1_m(vbool16_t vm, vuint32m2_t vs2,
                                           size_t vl);
vfloat16m2_t __riscv_vfncvt_f_xu_w_f16m2_m(vbool8_t vm, vuint32m4_t vs2,
                                           size_t vl);
vfloat16m4_t __riscv_vfncvt_f_xu_w_f16m4_m(vbool4_t vm, vuint32m8_t vs2,
                                           size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_f_w_f16mf4_m(vbool64_t vm, vfloat32mf2_t vs2,
                                                size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_m(vbool32_t vm, vfloat32m1_t vs2,
                                            size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_f_w_f16mf2_m(vbool32_t vm, vfloat32m1_t vs2,
                                                size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                          size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_f_w_f16m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                              size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_m(vbool8_t vm, vfloat32m4_t vs2,
                                          size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_f_w_f16m2_m(vbool8_t vm, vfloat32m4_t vs2,
                                              size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_m(vbool4_t vm, vfloat32m8_t vs2,
                                          size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_f_w_f16m4_m(vbool4_t vm, vfloat32m8_t vs2,
                                              size_t vl);
vint32mf2_t __riscv_vfncvt_x_f_w_i32mf2_m(vbool64_t vm, vfloat64m1_t vs2,
                                          size_t vl);
vint32mf2_t __riscv_vfncvt_rtz_x_f_w_i32mf2_m(vbool64_t vm, vfloat64m1_t vs2,
                                              size_t vl);
vint32m1_t __riscv_vfncvt_x_f_w_i32m1_m(vbool32_t vm, vfloat64m2_t vs2,
                                        size_t vl);
vint32m1_t __riscv_vfncvt_rtz_x_f_w_i32m1_m(vbool32_t vm, vfloat64m2_t vs2,
                                            size_t vl);
vint32m2_t __riscv_vfncvt_x_f_w_i32m2_m(vbool16_t vm, vfloat64m4_t vs2,
                                        size_t vl);
vint32m2_t __riscv_vfncvt_rtz_x_f_w_i32m2_m(vbool16_t vm, vfloat64m4_t vs2,
                                            size_t vl);
vint32m4_t __riscv_vfncvt_x_f_w_i32m4_m(vbool8_t vm, vfloat64m8_t vs2,
                                        size_t vl);
vint32m4_t __riscv_vfncvt_rtz_x_f_w_i32m4_m(vbool8_t vm, vfloat64m8_t vs2,
                                            size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_f_w_u32mf2_m(vbool64_t vm, vfloat64m1_t vs2,
                                            size_t vl);
vuint32mf2_t __riscv_vfncvt_rtz_xu_f_w_u32mf2_m(vbool64_t vm, vfloat64m1_t vs2,
                                                size_t vl);
vuint32m1_t __riscv_vfncvt_xu_f_w_u32m1_m(vbool32_t vm, vfloat64m2_t vs2,
                                          size_t vl);
vuint32m1_t __riscv_vfncvt_rtz_xu_f_w_u32m1_m(vbool32_t vm, vfloat64m2_t vs2,
                                              size_t vl);
vuint32m2_t __riscv_vfncvt_xu_f_w_u32m2_m(vbool16_t vm, vfloat64m4_t vs2,
                                          size_t vl);
vuint32m2_t __riscv_vfncvt_rtz_xu_f_w_u32m2_m(vbool16_t vm, vfloat64m4_t vs2,
                                              size_t vl);
vuint32m4_t __riscv_vfncvt_xu_f_w_u32m4_m(vbool8_t vm, vfloat64m8_t vs2,
                                          size_t vl);
vuint32m4_t __riscv_vfncvt_rtz_xu_f_w_u32m4_m(vbool8_t vm, vfloat64m8_t vs2,
                                              size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_x_w_f32mf2_m(vbool64_t vm, vint64m1_t vs2,
                                            size_t vl);
vfloat32m1_t __riscv_vfncvt_f_x_w_f32m1_m(vbool32_t vm, vint64m2_t vs2,
                                          size_t vl);
vfloat32m2_t __riscv_vfncvt_f_x_w_f32m2_m(vbool16_t vm, vint64m4_t vs2,
                                          size_t vl);
vfloat32m4_t __riscv_vfncvt_f_x_w_f32m4_m(vbool8_t vm, vint64m8_t vs2,
                                          size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_xu_w_f32mf2_m(vbool64_t vm, vuint64m1_t vs2,
                                             size_t vl);
vfloat32m1_t __riscv_vfncvt_f_xu_w_f32m1_m(vbool32_t vm, vuint64m2_t vs2,
                                           size_t vl);
vfloat32m2_t __riscv_vfncvt_f_xu_w_f32m2_m(vbool16_t vm, vuint64m4_t vs2,
                                           size_t vl);
vfloat32m4_t __riscv_vfncvt_f_xu_w_f32m4_m(vbool8_t vm, vuint64m8_t vs2,
                                           size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_f_w_f32mf2_m(vbool64_t vm, vfloat64m1_t vs2,
                                            size_t vl);
vfloat32mf2_t __riscv_vfncvt_rod_f_f_w_f32mf2_m(vbool64_t vm, vfloat64m1_t vs2,
                                                size_t vl);
vfloat32m1_t __riscv_vfncvt_f_f_w_f32m1_m(vbool32_t vm, vfloat64m2_t vs2,
                                          size_t vl);
vfloat32m1_t __riscv_vfncvt_rod_f_f_w_f32m1_m(vbool32_t vm, vfloat64m2_t vs2,
                                              size_t vl);
vfloat32m2_t __riscv_vfncvt_f_f_w_f32m2_m(vbool16_t vm, vfloat64m4_t vs2,
                                          size_t vl);
vfloat32m2_t __riscv_vfncvt_rod_f_f_w_f32m2_m(vbool16_t vm, vfloat64m4_t vs2,
                                              size_t vl);
vfloat32m4_t __riscv_vfncvt_f_f_w_f32m4_m(vbool8_t vm, vfloat64m8_t vs2,
                                          size_t vl);
vfloat32m4_t __riscv_vfncvt_rod_f_f_w_f32m4_m(vbool8_t vm, vfloat64m8_t vs2,
                                              size_t vl);
vint8mf8_t __riscv_vfncvt_x_f_w_i8mf8_rm(vfloat16mf4_t vs2, unsigned int frm,
                                         size_t vl);
vint8mf4_t __riscv_vfncvt_x_f_w_i8mf4_rm(vfloat16mf2_t vs2, unsigned int frm,
                                         size_t vl);
vint8mf2_t __riscv_vfncvt_x_f_w_i8mf2_rm(vfloat16m1_t vs2, unsigned int frm,
                                         size_t vl);
vint8m1_t __riscv_vfncvt_x_f_w_i8m1_rm(vfloat16m2_t vs2, unsigned int frm,
                                       size_t vl);
vint8m2_t __riscv_vfncvt_x_f_w_i8m2_rm(vfloat16m4_t vs2, unsigned int frm,
                                       size_t vl);
vint8m4_t __riscv_vfncvt_x_f_w_i8m4_rm(vfloat16m8_t vs2, unsigned int frm,
                                       size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_f_w_u8mf8_rm(vfloat16mf4_t vs2, unsigned int frm,
                                           size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_f_w_u8mf4_rm(vfloat16mf2_t vs2, unsigned int frm,
                                           size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_f_w_u8mf2_rm(vfloat16m1_t vs2, unsigned int frm,
                                           size_t vl);
vuint8m1_t __riscv_vfncvt_xu_f_w_u8m1_rm(vfloat16m2_t vs2, unsigned int frm,
                                         size_t vl);
vuint8m2_t __riscv_vfncvt_xu_f_w_u8m2_rm(vfloat16m4_t vs2, unsigned int frm,
                                         size_t vl);
vuint8m4_t __riscv_vfncvt_xu_f_w_u8m4_rm(vfloat16m8_t vs2, unsigned int frm,
                                         size_t vl);
vint16mf4_t __riscv_vfncvt_x_f_w_i16mf4_rm(vfloat32mf2_t vs2, unsigned int frm,
                                           size_t vl);
vint16mf2_t __riscv_vfncvt_x_f_w_i16mf2_rm(vfloat32m1_t vs2, unsigned int frm,
                                           size_t vl);
vint16m1_t __riscv_vfncvt_x_f_w_i16m1_rm(vfloat32m2_t vs2, unsigned int frm,
                                         size_t vl);
vint16m2_t __riscv_vfncvt_x_f_w_i16m2_rm(vfloat32m4_t vs2, unsigned int frm,
                                         size_t vl);
vint16m4_t __riscv_vfncvt_x_f_w_i16m4_rm(vfloat32m8_t vs2, unsigned int frm,
                                         size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_f_w_u16mf4_rm(vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_f_w_u16mf2_rm(vfloat32m1_t vs2, unsigned int frm,
                                             size_t vl);
vuint16m1_t __riscv_vfncvt_xu_f_w_u16m1_rm(vfloat32m2_t vs2, unsigned int frm,
                                           size_t vl);
vuint16m2_t __riscv_vfncvt_xu_f_w_u16m2_rm(vfloat32m4_t vs2, unsigned int frm,
                                           size_t vl);
vuint16m4_t __riscv_vfncvt_xu_f_w_u16m4_rm(vfloat32m8_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_x_w_f16mf4_rm(vint32mf2_t vs2, unsigned int frm,
                                             size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_x_w_f16mf2_rm(vint32m1_t vs2, unsigned int frm,
                                             size_t vl);
vfloat16m1_t __riscv_vfncvt_f_x_w_f16m1_rm(vint32m2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m2_t __riscv_vfncvt_f_x_w_f16m2_rm(vint32m4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m4_t __riscv_vfncvt_f_x_w_f16m4_rm(vint32m8_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_xu_w_f16mf4_rm(vuint32mf2_t vs2,
                                              unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_xu_w_f16mf2_rm(vuint32m1_t vs2, unsigned int frm,
                                              size_t vl);
vfloat16m1_t __riscv_vfncvt_f_xu_w_f16m1_rm(vuint32m2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16m2_t __riscv_vfncvt_f_xu_w_f16m2_rm(vuint32m4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16m4_t __riscv_vfncvt_f_xu_w_f16m4_rm(vuint32m8_t vs2, unsigned int frm,
                                            size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_rm(vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_rm(vfloat32m1_t vs2, unsigned int frm,
                                             size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_rm(vfloat32m2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_rm(vfloat32m4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_rm(vfloat32m8_t vs2, unsigned int frm,
                                           size_t vl);
vint32mf2_t __riscv_vfncvt_x_f_w_i32mf2_rm(vfloat64m1_t vs2, unsigned int frm,
                                           size_t vl);
vint32m1_t __riscv_vfncvt_x_f_w_i32m1_rm(vfloat64m2_t vs2, unsigned int frm,
                                         size_t vl);
vint32m2_t __riscv_vfncvt_x_f_w_i32m2_rm(vfloat64m4_t vs2, unsigned int frm,
                                         size_t vl);
vint32m4_t __riscv_vfncvt_x_f_w_i32m4_rm(vfloat64m8_t vs2, unsigned int frm,
                                         size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_f_w_u32mf2_rm(vfloat64m1_t vs2, unsigned int frm,
                                             size_t vl);
vuint32m1_t __riscv_vfncvt_xu_f_w_u32m1_rm(vfloat64m2_t vs2, unsigned int frm,
                                           size_t vl);
vuint32m2_t __riscv_vfncvt_xu_f_w_u32m2_rm(vfloat64m4_t vs2, unsigned int frm,
                                           size_t vl);
vuint32m4_t __riscv_vfncvt_xu_f_w_u32m4_rm(vfloat64m8_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_x_w_f32mf2_rm(vint64m1_t vs2, unsigned int frm,
                                             size_t vl);
vfloat32m1_t __riscv_vfncvt_f_x_w_f32m1_rm(vint64m2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m2_t __riscv_vfncvt_f_x_w_f32m2_rm(vint64m4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m4_t __riscv_vfncvt_f_x_w_f32m4_rm(vint64m8_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_xu_w_f32mf2_rm(vuint64m1_t vs2, unsigned int frm,
                                              size_t vl);
vfloat32m1_t __riscv_vfncvt_f_xu_w_f32m1_rm(vuint64m2_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32m2_t __riscv_vfncvt_f_xu_w_f32m2_rm(vuint64m4_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32m4_t __riscv_vfncvt_f_xu_w_f32m4_rm(vuint64m8_t vs2, unsigned int frm,
                                            size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_f_w_f32mf2_rm(vfloat64m1_t vs2, unsigned int frm,
                                             size_t vl);
vfloat32m1_t __riscv_vfncvt_f_f_w_f32m1_rm(vfloat64m2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m2_t __riscv_vfncvt_f_f_w_f32m2_rm(vfloat64m4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat32m4_t __riscv_vfncvt_f_f_w_f32m4_rm(vfloat64m8_t vs2, unsigned int frm,
                                           size_t vl);
// masked functions
vint8mf8_t __riscv_vfncvt_x_f_w_i8mf8_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           unsigned int frm, size_t vl);
vint8mf4_t __riscv_vfncvt_x_f_w_i8mf4_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           unsigned int frm, size_t vl);
vint8mf2_t __riscv_vfncvt_x_f_w_i8mf2_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                           unsigned int frm, size_t vl);
vint8m1_t __riscv_vfncvt_x_f_w_i8m1_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                         unsigned int frm, size_t vl);
vint8m2_t __riscv_vfncvt_x_f_w_i8m2_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                         unsigned int frm, size_t vl);
vint8m4_t __riscv_vfncvt_x_f_w_i8m4_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                         unsigned int frm, size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_f_w_u8mf8_rm_m(vbool64_t vm, vfloat16mf4_t vs2,
                                             unsigned int frm, size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_f_w_u8mf4_rm_m(vbool32_t vm, vfloat16mf2_t vs2,
                                             unsigned int frm, size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_f_w_u8mf2_rm_m(vbool16_t vm, vfloat16m1_t vs2,
                                             unsigned int frm, size_t vl);
vuint8m1_t __riscv_vfncvt_xu_f_w_u8m1_rm_m(vbool8_t vm, vfloat16m2_t vs2,
                                           unsigned int frm, size_t vl);
vuint8m2_t __riscv_vfncvt_xu_f_w_u8m2_rm_m(vbool4_t vm, vfloat16m4_t vs2,
                                           unsigned int frm, size_t vl);
vuint8m4_t __riscv_vfncvt_xu_f_w_u8m4_rm_m(vbool2_t vm, vfloat16m8_t vs2,
                                           unsigned int frm, size_t vl);
vint16mf4_t __riscv_vfncvt_x_f_w_i16mf4_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vint16mf2_t __riscv_vfncvt_x_f_w_i16mf2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                             unsigned int frm, size_t vl);
vint16m1_t __riscv_vfncvt_x_f_w_i16m1_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                           unsigned int frm, size_t vl);
vint16m2_t __riscv_vfncvt_x_f_w_i16m2_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                           unsigned int frm, size_t vl);
vint16m4_t __riscv_vfncvt_x_f_w_i16m4_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                           unsigned int frm, size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_f_w_u16mf4_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                               unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_f_w_u16mf2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                               unsigned int frm, size_t vl);
vuint16m1_t __riscv_vfncvt_xu_f_w_u16m1_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                             unsigned int frm, size_t vl);
vuint16m2_t __riscv_vfncvt_xu_f_w_u16m2_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                             unsigned int frm, size_t vl);
vuint16m4_t __riscv_vfncvt_xu_f_w_u16m4_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_x_w_f16mf4_rm_m(vbool64_t vm, vint32mf2_t vs2,
                                               unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_x_w_f16mf2_rm_m(vbool32_t vm, vint32m1_t vs2,
                                               unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_x_w_f16m1_rm_m(vbool16_t vm, vint32m2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_x_w_f16m2_rm_m(vbool8_t vm, vint32m4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_x_w_f16m4_rm_m(vbool4_t vm, vint32m8_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_xu_w_f16mf4_rm_m(vbool64_t vm, vuint32mf2_t vs2,
                                                unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_xu_w_f16mf2_rm_m(vbool32_t vm, vuint32m1_t vs2,
                                                unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_xu_w_f16m1_rm_m(vbool16_t vm, vuint32m2_t vs2,
                                              unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_xu_w_f16m2_rm_m(vbool8_t vm, vuint32m4_t vs2,
                                              unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_xu_w_f16m4_rm_m(vbool4_t vm, vuint32m8_t vs2,
                                              unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                               unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                               unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                             unsigned int frm, size_t vl);
vint32mf2_t __riscv_vfncvt_x_f_w_i32mf2_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                             unsigned int frm, size_t vl);
vint32m1_t __riscv_vfncvt_x_f_w_i32m1_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                           unsigned int frm, size_t vl);
vint32m2_t __riscv_vfncvt_x_f_w_i32m2_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                           unsigned int frm, size_t vl);
vint32m4_t __riscv_vfncvt_x_f_w_i32m4_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                           unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_f_w_u32mf2_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                               unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfncvt_xu_f_w_u32m1_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                             unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfncvt_xu_f_w_u32m2_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                             unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfncvt_xu_f_w_u32m4_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_x_w_f32mf2_rm_m(vbool64_t vm, vint64m1_t vs2,
                                               unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_x_w_f32m1_rm_m(vbool32_t vm, vint64m2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_x_w_f32m2_rm_m(vbool16_t vm, vint64m4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_x_w_f32m4_rm_m(vbool8_t vm, vint64m8_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_xu_w_f32mf2_rm_m(vbool64_t vm, vuint64m1_t vs2,
                                                unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_xu_w_f32m1_rm_m(vbool32_t vm, vuint64m2_t vs2,
                                              unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_xu_w_f32m2_rm_m(vbool16_t vm, vuint64m4_t vs2,
                                              unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_xu_w_f32m4_rm_m(vbool8_t vm, vuint64m8_t vs2,
                                              unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_f_w_f32mf2_rm_m(vbool64_t vm, vfloat64m1_t vs2,
                                               unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_f_w_f32m1_rm_m(vbool32_t vm, vfloat64m2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_f_w_f32m2_rm_m(vbool16_t vm, vfloat64m4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_f_w_f32m4_rm_m(vbool8_t vm, vfloat64m8_t vs2,
                                             unsigned int frm, size_t vl);
----

=== Vector Reduction Operations

[[vector-single-width-integer-reduction]]
==== Vector Single-Width Integer Reduction Intrinsics

[,c]
----
vint8m1_t __riscv_vredsum_vs_i8mf8_i8m1(vint8mf8_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredsum_vs_i8mf4_i8m1(vint8mf4_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredsum_vs_i8mf2_i8m1(vint8mf2_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredsum_vs_i8m1_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredsum_vs_i8m2_i8m1(vint8m2_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredsum_vs_i8m4_i8m1(vint8m4_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredsum_vs_i8m8_i8m1(vint8m8_t vs2, vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredsum_vs_i16mf4_i16m1(vint16mf4_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vredsum_vs_i16mf2_i16m1(vint16mf2_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vredsum_vs_i16m1_i16m1(vint16m1_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredsum_vs_i16m2_i16m1(vint16m2_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredsum_vs_i16m4_i16m1(vint16m4_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredsum_vs_i16m8_i16m1(vint16m8_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredsum_vs_i32mf2_i32m1(vint32mf2_t vs2, vint32m1_t vs1,
                                           size_t vl);
vint32m1_t __riscv_vredsum_vs_i32m1_i32m1(vint32m1_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredsum_vs_i32m2_i32m1(vint32m2_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredsum_vs_i32m4_i32m1(vint32m4_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredsum_vs_i32m8_i32m1(vint32m8_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredsum_vs_i64m1_i64m1(vint64m1_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredsum_vs_i64m2_i64m1(vint64m2_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredsum_vs_i64m4_i64m1(vint64m4_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredsum_vs_i64m8_i64m1(vint64m8_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint8m1_t __riscv_vredmax_vs_i8mf8_i8m1(vint8mf8_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredmax_vs_i8mf4_i8m1(vint8mf4_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredmax_vs_i8mf2_i8m1(vint8mf2_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredmax_vs_i8m1_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmax_vs_i8m2_i8m1(vint8m2_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmax_vs_i8m4_i8m1(vint8m4_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmax_vs_i8m8_i8m1(vint8m8_t vs2, vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmax_vs_i16mf4_i16m1(vint16mf4_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vredmax_vs_i16mf2_i16m1(vint16mf2_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vredmax_vs_i16m1_i16m1(vint16m1_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredmax_vs_i16m2_i16m1(vint16m2_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredmax_vs_i16m4_i16m1(vint16m4_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredmax_vs_i16m8_i16m1(vint16m8_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredmax_vs_i32mf2_i32m1(vint32mf2_t vs2, vint32m1_t vs1,
                                           size_t vl);
vint32m1_t __riscv_vredmax_vs_i32m1_i32m1(vint32m1_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredmax_vs_i32m2_i32m1(vint32m2_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredmax_vs_i32m4_i32m1(vint32m4_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredmax_vs_i32m8_i32m1(vint32m8_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredmax_vs_i64m1_i64m1(vint64m1_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredmax_vs_i64m2_i64m1(vint64m2_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredmax_vs_i64m4_i64m1(vint64m4_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredmax_vs_i64m8_i64m1(vint64m8_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint8m1_t __riscv_vredmin_vs_i8mf8_i8m1(vint8mf8_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredmin_vs_i8mf4_i8m1(vint8mf4_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredmin_vs_i8mf2_i8m1(vint8mf2_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredmin_vs_i8m1_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmin_vs_i8m2_i8m1(vint8m2_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmin_vs_i8m4_i8m1(vint8m4_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmin_vs_i8m8_i8m1(vint8m8_t vs2, vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmin_vs_i16mf4_i16m1(vint16mf4_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vredmin_vs_i16mf2_i16m1(vint16mf2_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vredmin_vs_i16m1_i16m1(vint16m1_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredmin_vs_i16m2_i16m1(vint16m2_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredmin_vs_i16m4_i16m1(vint16m4_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredmin_vs_i16m8_i16m1(vint16m8_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredmin_vs_i32mf2_i32m1(vint32mf2_t vs2, vint32m1_t vs1,
                                           size_t vl);
vint32m1_t __riscv_vredmin_vs_i32m1_i32m1(vint32m1_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredmin_vs_i32m2_i32m1(vint32m2_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredmin_vs_i32m4_i32m1(vint32m4_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredmin_vs_i32m8_i32m1(vint32m8_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredmin_vs_i64m1_i64m1(vint64m1_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredmin_vs_i64m2_i64m1(vint64m2_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredmin_vs_i64m4_i64m1(vint64m4_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredmin_vs_i64m8_i64m1(vint64m8_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint8m1_t __riscv_vredand_vs_i8mf8_i8m1(vint8mf8_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredand_vs_i8mf4_i8m1(vint8mf4_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredand_vs_i8mf2_i8m1(vint8mf2_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredand_vs_i8m1_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredand_vs_i8m2_i8m1(vint8m2_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredand_vs_i8m4_i8m1(vint8m4_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredand_vs_i8m8_i8m1(vint8m8_t vs2, vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredand_vs_i16mf4_i16m1(vint16mf4_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vredand_vs_i16mf2_i16m1(vint16mf2_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vredand_vs_i16m1_i16m1(vint16m1_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredand_vs_i16m2_i16m1(vint16m2_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredand_vs_i16m4_i16m1(vint16m4_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredand_vs_i16m8_i16m1(vint16m8_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredand_vs_i32mf2_i32m1(vint32mf2_t vs2, vint32m1_t vs1,
                                           size_t vl);
vint32m1_t __riscv_vredand_vs_i32m1_i32m1(vint32m1_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredand_vs_i32m2_i32m1(vint32m2_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredand_vs_i32m4_i32m1(vint32m4_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredand_vs_i32m8_i32m1(vint32m8_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredand_vs_i64m1_i64m1(vint64m1_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredand_vs_i64m2_i64m1(vint64m2_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredand_vs_i64m4_i64m1(vint64m4_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredand_vs_i64m8_i64m1(vint64m8_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint8m1_t __riscv_vredor_vs_i8mf8_i8m1(vint8mf8_t vs2, vint8m1_t vs1,
                                       size_t vl);
vint8m1_t __riscv_vredor_vs_i8mf4_i8m1(vint8mf4_t vs2, vint8m1_t vs1,
                                       size_t vl);
vint8m1_t __riscv_vredor_vs_i8mf2_i8m1(vint8mf2_t vs2, vint8m1_t vs1,
                                       size_t vl);
vint8m1_t __riscv_vredor_vs_i8m1_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredor_vs_i8m2_i8m1(vint8m2_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredor_vs_i8m4_i8m1(vint8m4_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredor_vs_i8m8_i8m1(vint8m8_t vs2, vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredor_vs_i16mf4_i16m1(vint16mf4_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredor_vs_i16mf2_i16m1(vint16mf2_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredor_vs_i16m1_i16m1(vint16m1_t vs2, vint16m1_t vs1,
                                         size_t vl);
vint16m1_t __riscv_vredor_vs_i16m2_i16m1(vint16m2_t vs2, vint16m1_t vs1,
                                         size_t vl);
vint16m1_t __riscv_vredor_vs_i16m4_i16m1(vint16m4_t vs2, vint16m1_t vs1,
                                         size_t vl);
vint16m1_t __riscv_vredor_vs_i16m8_i16m1(vint16m8_t vs2, vint16m1_t vs1,
                                         size_t vl);
vint32m1_t __riscv_vredor_vs_i32mf2_i32m1(vint32mf2_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredor_vs_i32m1_i32m1(vint32m1_t vs2, vint32m1_t vs1,
                                         size_t vl);
vint32m1_t __riscv_vredor_vs_i32m2_i32m1(vint32m2_t vs2, vint32m1_t vs1,
                                         size_t vl);
vint32m1_t __riscv_vredor_vs_i32m4_i32m1(vint32m4_t vs2, vint32m1_t vs1,
                                         size_t vl);
vint32m1_t __riscv_vredor_vs_i32m8_i32m1(vint32m8_t vs2, vint32m1_t vs1,
                                         size_t vl);
vint64m1_t __riscv_vredor_vs_i64m1_i64m1(vint64m1_t vs2, vint64m1_t vs1,
                                         size_t vl);
vint64m1_t __riscv_vredor_vs_i64m2_i64m1(vint64m2_t vs2, vint64m1_t vs1,
                                         size_t vl);
vint64m1_t __riscv_vredor_vs_i64m4_i64m1(vint64m4_t vs2, vint64m1_t vs1,
                                         size_t vl);
vint64m1_t __riscv_vredor_vs_i64m8_i64m1(vint64m8_t vs2, vint64m1_t vs1,
                                         size_t vl);
vint8m1_t __riscv_vredxor_vs_i8mf8_i8m1(vint8mf8_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredxor_vs_i8mf4_i8m1(vint8mf4_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredxor_vs_i8mf2_i8m1(vint8mf2_t vs2, vint8m1_t vs1,
                                        size_t vl);
vint8m1_t __riscv_vredxor_vs_i8m1_i8m1(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredxor_vs_i8m2_i8m1(vint8m2_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredxor_vs_i8m4_i8m1(vint8m4_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredxor_vs_i8m8_i8m1(vint8m8_t vs2, vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredxor_vs_i16mf4_i16m1(vint16mf4_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vredxor_vs_i16mf2_i16m1(vint16mf2_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vredxor_vs_i16m1_i16m1(vint16m1_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredxor_vs_i16m2_i16m1(vint16m2_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredxor_vs_i16m4_i16m1(vint16m4_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vredxor_vs_i16m8_i16m1(vint16m8_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredxor_vs_i32mf2_i32m1(vint32mf2_t vs2, vint32m1_t vs1,
                                           size_t vl);
vint32m1_t __riscv_vredxor_vs_i32m1_i32m1(vint32m1_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredxor_vs_i32m2_i32m1(vint32m2_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredxor_vs_i32m4_i32m1(vint32m4_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vredxor_vs_i32m8_i32m1(vint32m8_t vs2, vint32m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredxor_vs_i64m1_i64m1(vint64m1_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredxor_vs_i64m2_i64m1(vint64m2_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredxor_vs_i64m4_i64m1(vint64m4_t vs2, vint64m1_t vs1,
                                          size_t vl);
vint64m1_t __riscv_vredxor_vs_i64m8_i64m1(vint64m8_t vs2, vint64m1_t vs1,
                                          size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8mf8_u8m1(vuint8mf8_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8mf4_u8m1(vuint8mf4_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8mf2_u8m1(vuint8mf2_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8m1_u8m1(vuint8m1_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8m2_u8m1(vuint8m2_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8m4_u8m1(vuint8m4_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8m8_u8m1(vuint8m8_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16mf4_u16m1(vuint16mf4_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16mf2_u16m1(vuint16mf2_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16m1_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16m2_u16m1(vuint16m2_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16m4_u16m1(vuint16m4_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16m8_u16m1(vuint16m8_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredsum_vs_u32mf2_u32m1(vuint32mf2_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredsum_vs_u32m1_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredsum_vs_u32m2_u32m1(vuint32m2_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredsum_vs_u32m4_u32m1(vuint32m4_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredsum_vs_u32m8_u32m1(vuint32m8_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredsum_vs_u64m1_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredsum_vs_u64m2_u64m1(vuint64m2_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredsum_vs_u64m4_u64m1(vuint64m4_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredsum_vs_u64m8_u64m1(vuint64m8_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8mf8_u8m1(vuint8mf8_t vs2, vuint8m1_t vs1,
                                          size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8mf4_u8m1(vuint8mf4_t vs2, vuint8m1_t vs1,
                                          size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8mf2_u8m1(vuint8mf2_t vs2, vuint8m1_t vs1,
                                          size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8m1_u8m1(vuint8m1_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8m2_u8m1(vuint8m2_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8m4_u8m1(vuint8m4_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8m8_u8m1(vuint8m8_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16mf4_u16m1(vuint16mf4_t vs2, vuint16m1_t vs1,
                                             size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16mf2_u16m1(vuint16mf2_t vs2, vuint16m1_t vs1,
                                             size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16m1_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16m2_u16m1(vuint16m2_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16m4_u16m1(vuint16m4_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16m8_u16m1(vuint16m8_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredmaxu_vs_u32mf2_u32m1(vuint32mf2_t vs2, vuint32m1_t vs1,
                                             size_t vl);
vuint32m1_t __riscv_vredmaxu_vs_u32m1_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredmaxu_vs_u32m2_u32m1(vuint32m2_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredmaxu_vs_u32m4_u32m1(vuint32m4_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredmaxu_vs_u32m8_u32m1(vuint32m8_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint64m1_t __riscv_vredmaxu_vs_u64m1_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                            size_t vl);
vuint64m1_t __riscv_vredmaxu_vs_u64m2_u64m1(vuint64m2_t vs2, vuint64m1_t vs1,
                                            size_t vl);
vuint64m1_t __riscv_vredmaxu_vs_u64m4_u64m1(vuint64m4_t vs2, vuint64m1_t vs1,
                                            size_t vl);
vuint64m1_t __riscv_vredmaxu_vs_u64m8_u64m1(vuint64m8_t vs2, vuint64m1_t vs1,
                                            size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8mf8_u8m1(vuint8mf8_t vs2, vuint8m1_t vs1,
                                          size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8mf4_u8m1(vuint8mf4_t vs2, vuint8m1_t vs1,
                                          size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8mf2_u8m1(vuint8mf2_t vs2, vuint8m1_t vs1,
                                          size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8m1_u8m1(vuint8m1_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8m2_u8m1(vuint8m2_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8m4_u8m1(vuint8m4_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8m8_u8m1(vuint8m8_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16mf4_u16m1(vuint16mf4_t vs2, vuint16m1_t vs1,
                                             size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16mf2_u16m1(vuint16mf2_t vs2, vuint16m1_t vs1,
                                             size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16m1_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16m2_u16m1(vuint16m2_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16m4_u16m1(vuint16m4_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16m8_u16m1(vuint16m8_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredminu_vs_u32mf2_u32m1(vuint32mf2_t vs2, vuint32m1_t vs1,
                                             size_t vl);
vuint32m1_t __riscv_vredminu_vs_u32m1_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredminu_vs_u32m2_u32m1(vuint32m2_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredminu_vs_u32m4_u32m1(vuint32m4_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredminu_vs_u32m8_u32m1(vuint32m8_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint64m1_t __riscv_vredminu_vs_u64m1_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                            size_t vl);
vuint64m1_t __riscv_vredminu_vs_u64m2_u64m1(vuint64m2_t vs2, vuint64m1_t vs1,
                                            size_t vl);
vuint64m1_t __riscv_vredminu_vs_u64m4_u64m1(vuint64m4_t vs2, vuint64m1_t vs1,
                                            size_t vl);
vuint64m1_t __riscv_vredminu_vs_u64m8_u64m1(vuint64m8_t vs2, vuint64m1_t vs1,
                                            size_t vl);
vuint8m1_t __riscv_vredand_vs_u8mf8_u8m1(vuint8mf8_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredand_vs_u8mf4_u8m1(vuint8mf4_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredand_vs_u8mf2_u8m1(vuint8mf2_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredand_vs_u8m1_u8m1(vuint8m1_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredand_vs_u8m2_u8m1(vuint8m2_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredand_vs_u8m4_u8m1(vuint8m4_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredand_vs_u8m8_u8m1(vuint8m8_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint16m1_t __riscv_vredand_vs_u16mf4_u16m1(vuint16mf4_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredand_vs_u16mf2_u16m1(vuint16mf2_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredand_vs_u16m1_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredand_vs_u16m2_u16m1(vuint16m2_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredand_vs_u16m4_u16m1(vuint16m4_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredand_vs_u16m8_u16m1(vuint16m8_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredand_vs_u32mf2_u32m1(vuint32mf2_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredand_vs_u32m1_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredand_vs_u32m2_u32m1(vuint32m2_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredand_vs_u32m4_u32m1(vuint32m4_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredand_vs_u32m8_u32m1(vuint32m8_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredand_vs_u64m1_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredand_vs_u64m2_u64m1(vuint64m2_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredand_vs_u64m4_u64m1(vuint64m4_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredand_vs_u64m8_u64m1(vuint64m8_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint8m1_t __riscv_vredor_vs_u8mf8_u8m1(vuint8mf8_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredor_vs_u8mf4_u8m1(vuint8mf4_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredor_vs_u8mf2_u8m1(vuint8mf2_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredor_vs_u8m1_u8m1(vuint8m1_t vs2, vuint8m1_t vs1,
                                       size_t vl);
vuint8m1_t __riscv_vredor_vs_u8m2_u8m1(vuint8m2_t vs2, vuint8m1_t vs1,
                                       size_t vl);
vuint8m1_t __riscv_vredor_vs_u8m4_u8m1(vuint8m4_t vs2, vuint8m1_t vs1,
                                       size_t vl);
vuint8m1_t __riscv_vredor_vs_u8m8_u8m1(vuint8m8_t vs2, vuint8m1_t vs1,
                                       size_t vl);
vuint16m1_t __riscv_vredor_vs_u16mf4_u16m1(vuint16mf4_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredor_vs_u16mf2_u16m1(vuint16mf2_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredor_vs_u16m1_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                          size_t vl);
vuint16m1_t __riscv_vredor_vs_u16m2_u16m1(vuint16m2_t vs2, vuint16m1_t vs1,
                                          size_t vl);
vuint16m1_t __riscv_vredor_vs_u16m4_u16m1(vuint16m4_t vs2, vuint16m1_t vs1,
                                          size_t vl);
vuint16m1_t __riscv_vredor_vs_u16m8_u16m1(vuint16m8_t vs2, vuint16m1_t vs1,
                                          size_t vl);
vuint32m1_t __riscv_vredor_vs_u32mf2_u32m1(vuint32mf2_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredor_vs_u32m1_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                          size_t vl);
vuint32m1_t __riscv_vredor_vs_u32m2_u32m1(vuint32m2_t vs2, vuint32m1_t vs1,
                                          size_t vl);
vuint32m1_t __riscv_vredor_vs_u32m4_u32m1(vuint32m4_t vs2, vuint32m1_t vs1,
                                          size_t vl);
vuint32m1_t __riscv_vredor_vs_u32m8_u32m1(vuint32m8_t vs2, vuint32m1_t vs1,
                                          size_t vl);
vuint64m1_t __riscv_vredor_vs_u64m1_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                          size_t vl);
vuint64m1_t __riscv_vredor_vs_u64m2_u64m1(vuint64m2_t vs2, vuint64m1_t vs1,
                                          size_t vl);
vuint64m1_t __riscv_vredor_vs_u64m4_u64m1(vuint64m4_t vs2, vuint64m1_t vs1,
                                          size_t vl);
vuint64m1_t __riscv_vredor_vs_u64m8_u64m1(vuint64m8_t vs2, vuint64m1_t vs1,
                                          size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8mf8_u8m1(vuint8mf8_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8mf4_u8m1(vuint8mf4_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8mf2_u8m1(vuint8mf2_t vs2, vuint8m1_t vs1,
                                         size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8m1_u8m1(vuint8m1_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8m2_u8m1(vuint8m2_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8m4_u8m1(vuint8m4_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8m8_u8m1(vuint8m8_t vs2, vuint8m1_t vs1,
                                        size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16mf4_u16m1(vuint16mf4_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16mf2_u16m1(vuint16mf2_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16m1_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16m2_u16m1(vuint16m2_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16m4_u16m1(vuint16m4_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16m8_u16m1(vuint16m8_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredxor_vs_u32mf2_u32m1(vuint32mf2_t vs2, vuint32m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vredxor_vs_u32m1_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredxor_vs_u32m2_u32m1(vuint32m2_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredxor_vs_u32m4_u32m1(vuint32m4_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint32m1_t __riscv_vredxor_vs_u32m8_u32m1(vuint32m8_t vs2, vuint32m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredxor_vs_u64m1_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredxor_vs_u64m2_u64m1(vuint64m2_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredxor_vs_u64m4_u64m1(vuint64m4_t vs2, vuint64m1_t vs1,
                                           size_t vl);
vuint64m1_t __riscv_vredxor_vs_u64m8_u64m1(vuint64m8_t vs2, vuint64m1_t vs1,
                                           size_t vl);
// masked functions
vint8m1_t __riscv_vredsum_vs_i8mf8_i8m1_m(vbool64_t vm, vint8mf8_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredsum_vs_i8mf4_i8m1_m(vbool32_t vm, vint8mf4_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredsum_vs_i8mf2_i8m1_m(vbool16_t vm, vint8mf2_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredsum_vs_i8m1_i8m1_m(vbool8_t vm, vint8m1_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredsum_vs_i8m2_i8m1_m(vbool4_t vm, vint8m2_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredsum_vs_i8m4_i8m1_m(vbool2_t vm, vint8m4_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredsum_vs_i8m8_i8m1_m(vbool1_t vm, vint8m8_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredsum_vs_i16mf4_i16m1_m(vbool64_t vm, vint16mf4_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredsum_vs_i16mf2_i16m1_m(vbool32_t vm, vint16mf2_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredsum_vs_i16m1_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredsum_vs_i16m2_i16m1_m(vbool8_t vm, vint16m2_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredsum_vs_i16m4_i16m1_m(vbool4_t vm, vint16m4_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredsum_vs_i16m8_i16m1_m(vbool2_t vm, vint16m8_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint32m1_t __riscv_vredsum_vs_i32mf2_i32m1_m(vbool64_t vm, vint32mf2_t vs2,
                                             vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredsum_vs_i32m1_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredsum_vs_i32m2_i32m1_m(vbool16_t vm, vint32m2_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredsum_vs_i32m4_i32m1_m(vbool8_t vm, vint32m4_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredsum_vs_i32m8_i32m1_m(vbool4_t vm, vint32m8_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint64m1_t __riscv_vredsum_vs_i64m1_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredsum_vs_i64m2_i64m1_m(vbool32_t vm, vint64m2_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredsum_vs_i64m4_i64m1_m(vbool16_t vm, vint64m4_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredsum_vs_i64m8_i64m1_m(vbool8_t vm, vint64m8_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmax_vs_i8mf8_i8m1_m(vbool64_t vm, vint8mf8_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmax_vs_i8mf4_i8m1_m(vbool32_t vm, vint8mf4_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmax_vs_i8mf2_i8m1_m(vbool16_t vm, vint8mf2_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmax_vs_i8m1_i8m1_m(vbool8_t vm, vint8m1_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmax_vs_i8m2_i8m1_m(vbool4_t vm, vint8m2_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmax_vs_i8m4_i8m1_m(vbool2_t vm, vint8m4_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmax_vs_i8m8_i8m1_m(vbool1_t vm, vint8m8_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmax_vs_i16mf4_i16m1_m(vbool64_t vm, vint16mf4_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmax_vs_i16mf2_i16m1_m(vbool32_t vm, vint16mf2_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmax_vs_i16m1_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmax_vs_i16m2_i16m1_m(vbool8_t vm, vint16m2_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmax_vs_i16m4_i16m1_m(vbool4_t vm, vint16m4_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmax_vs_i16m8_i16m1_m(vbool2_t vm, vint16m8_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint32m1_t __riscv_vredmax_vs_i32mf2_i32m1_m(vbool64_t vm, vint32mf2_t vs2,
                                             vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredmax_vs_i32m1_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredmax_vs_i32m2_i32m1_m(vbool16_t vm, vint32m2_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredmax_vs_i32m4_i32m1_m(vbool8_t vm, vint32m4_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredmax_vs_i32m8_i32m1_m(vbool4_t vm, vint32m8_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint64m1_t __riscv_vredmax_vs_i64m1_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredmax_vs_i64m2_i64m1_m(vbool32_t vm, vint64m2_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredmax_vs_i64m4_i64m1_m(vbool16_t vm, vint64m4_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredmax_vs_i64m8_i64m1_m(vbool8_t vm, vint64m8_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmin_vs_i8mf8_i8m1_m(vbool64_t vm, vint8mf8_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmin_vs_i8mf4_i8m1_m(vbool32_t vm, vint8mf4_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmin_vs_i8mf2_i8m1_m(vbool16_t vm, vint8mf2_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmin_vs_i8m1_i8m1_m(vbool8_t vm, vint8m1_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmin_vs_i8m2_i8m1_m(vbool4_t vm, vint8m2_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmin_vs_i8m4_i8m1_m(vbool2_t vm, vint8m4_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredmin_vs_i8m8_i8m1_m(vbool1_t vm, vint8m8_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmin_vs_i16mf4_i16m1_m(vbool64_t vm, vint16mf4_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmin_vs_i16mf2_i16m1_m(vbool32_t vm, vint16mf2_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmin_vs_i16m1_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmin_vs_i16m2_i16m1_m(vbool8_t vm, vint16m2_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmin_vs_i16m4_i16m1_m(vbool4_t vm, vint16m4_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredmin_vs_i16m8_i16m1_m(vbool2_t vm, vint16m8_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint32m1_t __riscv_vredmin_vs_i32mf2_i32m1_m(vbool64_t vm, vint32mf2_t vs2,
                                             vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredmin_vs_i32m1_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredmin_vs_i32m2_i32m1_m(vbool16_t vm, vint32m2_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredmin_vs_i32m4_i32m1_m(vbool8_t vm, vint32m4_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredmin_vs_i32m8_i32m1_m(vbool4_t vm, vint32m8_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint64m1_t __riscv_vredmin_vs_i64m1_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredmin_vs_i64m2_i64m1_m(vbool32_t vm, vint64m2_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredmin_vs_i64m4_i64m1_m(vbool16_t vm, vint64m4_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredmin_vs_i64m8_i64m1_m(vbool8_t vm, vint64m8_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint8m1_t __riscv_vredand_vs_i8mf8_i8m1_m(vbool64_t vm, vint8mf8_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredand_vs_i8mf4_i8m1_m(vbool32_t vm, vint8mf4_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredand_vs_i8mf2_i8m1_m(vbool16_t vm, vint8mf2_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredand_vs_i8m1_i8m1_m(vbool8_t vm, vint8m1_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredand_vs_i8m2_i8m1_m(vbool4_t vm, vint8m2_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredand_vs_i8m4_i8m1_m(vbool2_t vm, vint8m4_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredand_vs_i8m8_i8m1_m(vbool1_t vm, vint8m8_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredand_vs_i16mf4_i16m1_m(vbool64_t vm, vint16mf4_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredand_vs_i16mf2_i16m1_m(vbool32_t vm, vint16mf2_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredand_vs_i16m1_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredand_vs_i16m2_i16m1_m(vbool8_t vm, vint16m2_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredand_vs_i16m4_i16m1_m(vbool4_t vm, vint16m4_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredand_vs_i16m8_i16m1_m(vbool2_t vm, vint16m8_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint32m1_t __riscv_vredand_vs_i32mf2_i32m1_m(vbool64_t vm, vint32mf2_t vs2,
                                             vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredand_vs_i32m1_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredand_vs_i32m2_i32m1_m(vbool16_t vm, vint32m2_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredand_vs_i32m4_i32m1_m(vbool8_t vm, vint32m4_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredand_vs_i32m8_i32m1_m(vbool4_t vm, vint32m8_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint64m1_t __riscv_vredand_vs_i64m1_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredand_vs_i64m2_i64m1_m(vbool32_t vm, vint64m2_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredand_vs_i64m4_i64m1_m(vbool16_t vm, vint64m4_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredand_vs_i64m8_i64m1_m(vbool8_t vm, vint64m8_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint8m1_t __riscv_vredor_vs_i8mf8_i8m1_m(vbool64_t vm, vint8mf8_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredor_vs_i8mf4_i8m1_m(vbool32_t vm, vint8mf4_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredor_vs_i8mf2_i8m1_m(vbool16_t vm, vint8mf2_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredor_vs_i8m1_i8m1_m(vbool8_t vm, vint8m1_t vs2,
                                        vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredor_vs_i8m2_i8m1_m(vbool4_t vm, vint8m2_t vs2,
                                        vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredor_vs_i8m4_i8m1_m(vbool2_t vm, vint8m4_t vs2,
                                        vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredor_vs_i8m8_i8m1_m(vbool1_t vm, vint8m8_t vs2,
                                        vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredor_vs_i16mf4_i16m1_m(vbool64_t vm, vint16mf4_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredor_vs_i16mf2_i16m1_m(vbool32_t vm, vint16mf2_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredor_vs_i16m1_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                           vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredor_vs_i16m2_i16m1_m(vbool8_t vm, vint16m2_t vs2,
                                           vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredor_vs_i16m4_i16m1_m(vbool4_t vm, vint16m4_t vs2,
                                           vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredor_vs_i16m8_i16m1_m(vbool2_t vm, vint16m8_t vs2,
                                           vint16m1_t vs1, size_t vl);
vint32m1_t __riscv_vredor_vs_i32mf2_i32m1_m(vbool64_t vm, vint32mf2_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredor_vs_i32m1_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                           vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredor_vs_i32m2_i32m1_m(vbool16_t vm, vint32m2_t vs2,
                                           vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredor_vs_i32m4_i32m1_m(vbool8_t vm, vint32m4_t vs2,
                                           vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredor_vs_i32m8_i32m1_m(vbool4_t vm, vint32m8_t vs2,
                                           vint32m1_t vs1, size_t vl);
vint64m1_t __riscv_vredor_vs_i64m1_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                           vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredor_vs_i64m2_i64m1_m(vbool32_t vm, vint64m2_t vs2,
                                           vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredor_vs_i64m4_i64m1_m(vbool16_t vm, vint64m4_t vs2,
                                           vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredor_vs_i64m8_i64m1_m(vbool8_t vm, vint64m8_t vs2,
                                           vint64m1_t vs1, size_t vl);
vint8m1_t __riscv_vredxor_vs_i8mf8_i8m1_m(vbool64_t vm, vint8mf8_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredxor_vs_i8mf4_i8m1_m(vbool32_t vm, vint8mf4_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredxor_vs_i8mf2_i8m1_m(vbool16_t vm, vint8mf2_t vs2,
                                          vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredxor_vs_i8m1_i8m1_m(vbool8_t vm, vint8m1_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredxor_vs_i8m2_i8m1_m(vbool4_t vm, vint8m2_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredxor_vs_i8m4_i8m1_m(vbool2_t vm, vint8m4_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vredxor_vs_i8m8_i8m1_m(vbool1_t vm, vint8m8_t vs2,
                                         vint8m1_t vs1, size_t vl);
vint16m1_t __riscv_vredxor_vs_i16mf4_i16m1_m(vbool64_t vm, vint16mf4_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredxor_vs_i16mf2_i16m1_m(vbool32_t vm, vint16mf2_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredxor_vs_i16m1_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredxor_vs_i16m2_i16m1_m(vbool8_t vm, vint16m2_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredxor_vs_i16m4_i16m1_m(vbool4_t vm, vint16m4_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vredxor_vs_i16m8_i16m1_m(vbool2_t vm, vint16m8_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint32m1_t __riscv_vredxor_vs_i32mf2_i32m1_m(vbool64_t vm, vint32mf2_t vs2,
                                             vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredxor_vs_i32m1_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredxor_vs_i32m2_i32m1_m(vbool16_t vm, vint32m2_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredxor_vs_i32m4_i32m1_m(vbool8_t vm, vint32m4_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vredxor_vs_i32m8_i32m1_m(vbool4_t vm, vint32m8_t vs2,
                                            vint32m1_t vs1, size_t vl);
vint64m1_t __riscv_vredxor_vs_i64m1_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredxor_vs_i64m2_i64m1_m(vbool32_t vm, vint64m2_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredxor_vs_i64m4_i64m1_m(vbool16_t vm, vint64m4_t vs2,
                                            vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vredxor_vs_i64m8_i64m1_m(vbool8_t vm, vint64m8_t vs2,
                                            vint64m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8mf8_u8m1_m(vbool64_t vm, vuint8mf8_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8mf4_u8m1_m(vbool32_t vm, vuint8mf4_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8mf2_u8m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8m1_u8m1_m(vbool8_t vm, vuint8m1_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8m2_u8m1_m(vbool4_t vm, vuint8m2_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8m4_u8m1_m(vbool2_t vm, vuint8m4_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredsum_vs_u8m8_u8m1_m(vbool1_t vm, vuint8m8_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16mf4_u16m1_m(vbool64_t vm, vuint16mf4_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16mf2_u16m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16m1_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16m2_u16m1_m(vbool8_t vm, vuint16m2_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16m4_u16m1_m(vbool4_t vm, vuint16m4_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredsum_vs_u16m8_u16m1_m(vbool2_t vm, vuint16m8_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredsum_vs_u32mf2_u32m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredsum_vs_u32m1_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredsum_vs_u32m2_u32m1_m(vbool16_t vm, vuint32m2_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredsum_vs_u32m4_u32m1_m(vbool8_t vm, vuint32m4_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredsum_vs_u32m8_u32m1_m(vbool4_t vm, vuint32m8_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredsum_vs_u64m1_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredsum_vs_u64m2_u64m1_m(vbool32_t vm, vuint64m2_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredsum_vs_u64m4_u64m1_m(vbool16_t vm, vuint64m4_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredsum_vs_u64m8_u64m1_m(vbool8_t vm, vuint64m8_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8mf8_u8m1_m(vbool64_t vm, vuint8mf8_t vs2,
                                            vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8mf4_u8m1_m(vbool32_t vm, vuint8mf4_t vs2,
                                            vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8mf2_u8m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                            vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8m1_u8m1_m(vbool8_t vm, vuint8m1_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8m2_u8m1_m(vbool4_t vm, vuint8m2_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8m4_u8m1_m(vbool2_t vm, vuint8m4_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredmaxu_vs_u8m8_u8m1_m(vbool1_t vm, vuint8m8_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16mf4_u16m1_m(vbool64_t vm, vuint16mf4_t vs2,
                                               vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16mf2_u16m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                               vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16m1_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16m2_u16m1_m(vbool8_t vm, vuint16m2_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16m4_u16m1_m(vbool4_t vm, vuint16m4_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredmaxu_vs_u16m8_u16m1_m(vbool2_t vm, vuint16m8_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredmaxu_vs_u32mf2_u32m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                               vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredmaxu_vs_u32m1_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredmaxu_vs_u32m2_u32m1_m(vbool16_t vm, vuint32m2_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredmaxu_vs_u32m4_u32m1_m(vbool8_t vm, vuint32m4_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredmaxu_vs_u32m8_u32m1_m(vbool4_t vm, vuint32m8_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredmaxu_vs_u64m1_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                              vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredmaxu_vs_u64m2_u64m1_m(vbool32_t vm, vuint64m2_t vs2,
                                              vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredmaxu_vs_u64m4_u64m1_m(vbool16_t vm, vuint64m4_t vs2,
                                              vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredmaxu_vs_u64m8_u64m1_m(vbool8_t vm, vuint64m8_t vs2,
                                              vuint64m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8mf8_u8m1_m(vbool64_t vm, vuint8mf8_t vs2,
                                            vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8mf4_u8m1_m(vbool32_t vm, vuint8mf4_t vs2,
                                            vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8mf2_u8m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                            vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8m1_u8m1_m(vbool8_t vm, vuint8m1_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8m2_u8m1_m(vbool4_t vm, vuint8m2_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8m4_u8m1_m(vbool2_t vm, vuint8m4_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredminu_vs_u8m8_u8m1_m(vbool1_t vm, vuint8m8_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16mf4_u16m1_m(vbool64_t vm, vuint16mf4_t vs2,
                                               vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16mf2_u16m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                               vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16m1_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16m2_u16m1_m(vbool8_t vm, vuint16m2_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16m4_u16m1_m(vbool4_t vm, vuint16m4_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredminu_vs_u16m8_u16m1_m(vbool2_t vm, vuint16m8_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredminu_vs_u32mf2_u32m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                               vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredminu_vs_u32m1_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredminu_vs_u32m2_u32m1_m(vbool16_t vm, vuint32m2_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredminu_vs_u32m4_u32m1_m(vbool8_t vm, vuint32m4_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredminu_vs_u32m8_u32m1_m(vbool4_t vm, vuint32m8_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredminu_vs_u64m1_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                              vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredminu_vs_u64m2_u64m1_m(vbool32_t vm, vuint64m2_t vs2,
                                              vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredminu_vs_u64m4_u64m1_m(vbool16_t vm, vuint64m4_t vs2,
                                              vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredminu_vs_u64m8_u64m1_m(vbool8_t vm, vuint64m8_t vs2,
                                              vuint64m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredand_vs_u8mf8_u8m1_m(vbool64_t vm, vuint8mf8_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredand_vs_u8mf4_u8m1_m(vbool32_t vm, vuint8mf4_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredand_vs_u8mf2_u8m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredand_vs_u8m1_u8m1_m(vbool8_t vm, vuint8m1_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredand_vs_u8m2_u8m1_m(vbool4_t vm, vuint8m2_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredand_vs_u8m4_u8m1_m(vbool2_t vm, vuint8m4_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredand_vs_u8m8_u8m1_m(vbool1_t vm, vuint8m8_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredand_vs_u16mf4_u16m1_m(vbool64_t vm, vuint16mf4_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredand_vs_u16mf2_u16m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredand_vs_u16m1_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredand_vs_u16m2_u16m1_m(vbool8_t vm, vuint16m2_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredand_vs_u16m4_u16m1_m(vbool4_t vm, vuint16m4_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredand_vs_u16m8_u16m1_m(vbool2_t vm, vuint16m8_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredand_vs_u32mf2_u32m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredand_vs_u32m1_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredand_vs_u32m2_u32m1_m(vbool16_t vm, vuint32m2_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredand_vs_u32m4_u32m1_m(vbool8_t vm, vuint32m4_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredand_vs_u32m8_u32m1_m(vbool4_t vm, vuint32m8_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredand_vs_u64m1_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredand_vs_u64m2_u64m1_m(vbool32_t vm, vuint64m2_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredand_vs_u64m4_u64m1_m(vbool16_t vm, vuint64m4_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredand_vs_u64m8_u64m1_m(vbool8_t vm, vuint64m8_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredor_vs_u8mf8_u8m1_m(vbool64_t vm, vuint8mf8_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredor_vs_u8mf4_u8m1_m(vbool32_t vm, vuint8mf4_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredor_vs_u8mf2_u8m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredor_vs_u8m1_u8m1_m(vbool8_t vm, vuint8m1_t vs2,
                                         vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredor_vs_u8m2_u8m1_m(vbool4_t vm, vuint8m2_t vs2,
                                         vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredor_vs_u8m4_u8m1_m(vbool2_t vm, vuint8m4_t vs2,
                                         vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredor_vs_u8m8_u8m1_m(vbool1_t vm, vuint8m8_t vs2,
                                         vuint8m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredor_vs_u16mf4_u16m1_m(vbool64_t vm, vuint16mf4_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredor_vs_u16mf2_u16m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredor_vs_u16m1_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                            vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredor_vs_u16m2_u16m1_m(vbool8_t vm, vuint16m2_t vs2,
                                            vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredor_vs_u16m4_u16m1_m(vbool4_t vm, vuint16m4_t vs2,
                                            vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredor_vs_u16m8_u16m1_m(vbool2_t vm, vuint16m8_t vs2,
                                            vuint16m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredor_vs_u32mf2_u32m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredor_vs_u32m1_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                            vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredor_vs_u32m2_u32m1_m(vbool16_t vm, vuint32m2_t vs2,
                                            vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredor_vs_u32m4_u32m1_m(vbool8_t vm, vuint32m4_t vs2,
                                            vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredor_vs_u32m8_u32m1_m(vbool4_t vm, vuint32m8_t vs2,
                                            vuint32m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredor_vs_u64m1_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                            vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredor_vs_u64m2_u64m1_m(vbool32_t vm, vuint64m2_t vs2,
                                            vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredor_vs_u64m4_u64m1_m(vbool16_t vm, vuint64m4_t vs2,
                                            vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredor_vs_u64m8_u64m1_m(vbool8_t vm, vuint64m8_t vs2,
                                            vuint64m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8mf8_u8m1_m(vbool64_t vm, vuint8mf8_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8mf4_u8m1_m(vbool32_t vm, vuint8mf4_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8mf2_u8m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                           vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8m1_u8m1_m(vbool8_t vm, vuint8m1_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8m2_u8m1_m(vbool4_t vm, vuint8m2_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8m4_u8m1_m(vbool2_t vm, vuint8m4_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vredxor_vs_u8m8_u8m1_m(vbool1_t vm, vuint8m8_t vs2,
                                          vuint8m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16mf4_u16m1_m(vbool64_t vm, vuint16mf4_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16mf2_u16m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16m1_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16m2_u16m1_m(vbool8_t vm, vuint16m2_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16m4_u16m1_m(vbool4_t vm, vuint16m4_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vredxor_vs_u16m8_u16m1_m(vbool2_t vm, vuint16m8_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredxor_vs_u32mf2_u32m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                              vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredxor_vs_u32m1_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredxor_vs_u32m2_u32m1_m(vbool16_t vm, vuint32m2_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredxor_vs_u32m4_u32m1_m(vbool8_t vm, vuint32m4_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vredxor_vs_u32m8_u32m1_m(vbool4_t vm, vuint32m8_t vs2,
                                             vuint32m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredxor_vs_u64m1_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredxor_vs_u64m2_u64m1_m(vbool32_t vm, vuint64m2_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredxor_vs_u64m4_u64m1_m(vbool16_t vm, vuint64m4_t vs2,
                                             vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vredxor_vs_u64m8_u64m1_m(vbool8_t vm, vuint64m8_t vs2,
                                             vuint64m1_t vs1, size_t vl);
----

[[vector-widening-integer-reduction]]
==== Vector Widening Integer Reduction Intrinsics

[,c]
----
vint16m1_t __riscv_vwredsum_vs_i8mf8_i16m1(vint8mf8_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8mf4_i16m1(vint8mf4_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8mf2_i16m1(vint8mf2_t vs2, vint16m1_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8m1_i16m1(vint8m1_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8m2_i16m1(vint8m2_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8m4_i16m1(vint8m4_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8m8_i16m1(vint8m8_t vs2, vint16m1_t vs1,
                                          size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16mf4_i32m1(vint16mf4_t vs2, vint32m1_t vs1,
                                            size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16mf2_i32m1(vint16mf2_t vs2, vint32m1_t vs1,
                                            size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16m1_i32m1(vint16m1_t vs2, vint32m1_t vs1,
                                           size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16m2_i32m1(vint16m2_t vs2, vint32m1_t vs1,
                                           size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16m4_i32m1(vint16m4_t vs2, vint32m1_t vs1,
                                           size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16m8_i32m1(vint16m8_t vs2, vint32m1_t vs1,
                                           size_t vl);
vint64m1_t __riscv_vwredsum_vs_i32mf2_i64m1(vint32mf2_t vs2, vint64m1_t vs1,
                                            size_t vl);
vint64m1_t __riscv_vwredsum_vs_i32m1_i64m1(vint32m1_t vs2, vint64m1_t vs1,
                                           size_t vl);
vint64m1_t __riscv_vwredsum_vs_i32m2_i64m1(vint32m2_t vs2, vint64m1_t vs1,
                                           size_t vl);
vint64m1_t __riscv_vwredsum_vs_i32m4_i64m1(vint32m4_t vs2, vint64m1_t vs1,
                                           size_t vl);
vint64m1_t __riscv_vwredsum_vs_i32m8_i64m1(vint32m8_t vs2, vint64m1_t vs1,
                                           size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8mf8_u16m1(vuint8mf8_t vs2, vuint16m1_t vs1,
                                             size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8mf4_u16m1(vuint8mf4_t vs2, vuint16m1_t vs1,
                                             size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8mf2_u16m1(vuint8mf2_t vs2, vuint16m1_t vs1,
                                             size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8m1_u16m1(vuint8m1_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8m2_u16m1(vuint8m2_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8m4_u16m1(vuint8m4_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8m8_u16m1(vuint8m8_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16mf4_u32m1(vuint16mf4_t vs2, vuint32m1_t vs1,
                                              size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16mf2_u32m1(vuint16mf2_t vs2, vuint32m1_t vs1,
                                              size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16m1_u32m1(vuint16m1_t vs2, vuint32m1_t vs1,
                                             size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16m2_u32m1(vuint16m2_t vs2, vuint32m1_t vs1,
                                             size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16m4_u32m1(vuint16m4_t vs2, vuint32m1_t vs1,
                                             size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16m8_u32m1(vuint16m8_t vs2, vuint32m1_t vs1,
                                             size_t vl);
vuint64m1_t __riscv_vwredsumu_vs_u32mf2_u64m1(vuint32mf2_t vs2, vuint64m1_t vs1,
                                              size_t vl);
vuint64m1_t __riscv_vwredsumu_vs_u32m1_u64m1(vuint32m1_t vs2, vuint64m1_t vs1,
                                             size_t vl);
vuint64m1_t __riscv_vwredsumu_vs_u32m2_u64m1(vuint32m2_t vs2, vuint64m1_t vs1,
                                             size_t vl);
vuint64m1_t __riscv_vwredsumu_vs_u32m4_u64m1(vuint32m4_t vs2, vuint64m1_t vs1,
                                             size_t vl);
vuint64m1_t __riscv_vwredsumu_vs_u32m8_u64m1(vuint32m8_t vs2, vuint64m1_t vs1,
                                             size_t vl);
// masked functions
vint16m1_t __riscv_vwredsum_vs_i8mf8_i16m1_m(vbool64_t vm, vint8mf8_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8mf4_i16m1_m(vbool32_t vm, vint8mf4_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8mf2_i16m1_m(vbool16_t vm, vint8mf2_t vs2,
                                             vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8m1_i16m1_m(vbool8_t vm, vint8m1_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8m2_i16m1_m(vbool4_t vm, vint8m2_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8m4_i16m1_m(vbool2_t vm, vint8m4_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vwredsum_vs_i8m8_i16m1_m(vbool1_t vm, vint8m8_t vs2,
                                            vint16m1_t vs1, size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16mf4_i32m1_m(vbool64_t vm, vint16mf4_t vs2,
                                              vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16mf2_i32m1_m(vbool32_t vm, vint16mf2_t vs2,
                                              vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16m1_i32m1_m(vbool16_t vm, vint16m1_t vs2,
                                             vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16m2_i32m1_m(vbool8_t vm, vint16m2_t vs2,
                                             vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16m4_i32m1_m(vbool4_t vm, vint16m4_t vs2,
                                             vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vwredsum_vs_i16m8_i32m1_m(vbool2_t vm, vint16m8_t vs2,
                                             vint32m1_t vs1, size_t vl);
vint64m1_t __riscv_vwredsum_vs_i32mf2_i64m1_m(vbool64_t vm, vint32mf2_t vs2,
                                              vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vwredsum_vs_i32m1_i64m1_m(vbool32_t vm, vint32m1_t vs2,
                                             vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vwredsum_vs_i32m2_i64m1_m(vbool16_t vm, vint32m2_t vs2,
                                             vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vwredsum_vs_i32m4_i64m1_m(vbool8_t vm, vint32m4_t vs2,
                                             vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vwredsum_vs_i32m8_i64m1_m(vbool4_t vm, vint32m8_t vs2,
                                             vint64m1_t vs1, size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8mf8_u16m1_m(vbool64_t vm, vuint8mf8_t vs2,
                                               vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8mf4_u16m1_m(vbool32_t vm, vuint8mf4_t vs2,
                                               vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8mf2_u16m1_m(vbool16_t vm, vuint8mf2_t vs2,
                                               vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8m1_u16m1_m(vbool8_t vm, vuint8m1_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8m2_u16m1_m(vbool4_t vm, vuint8m2_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8m4_u16m1_m(vbool2_t vm, vuint8m4_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vwredsumu_vs_u8m8_u16m1_m(vbool1_t vm, vuint8m8_t vs2,
                                              vuint16m1_t vs1, size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16mf4_u32m1_m(vbool64_t vm, vuint16mf4_t vs2,
                                                vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16mf2_u32m1_m(vbool32_t vm, vuint16mf2_t vs2,
                                                vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16m1_u32m1_m(vbool16_t vm, vuint16m1_t vs2,
                                               vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16m2_u32m1_m(vbool8_t vm, vuint16m2_t vs2,
                                               vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16m4_u32m1_m(vbool4_t vm, vuint16m4_t vs2,
                                               vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vwredsumu_vs_u16m8_u32m1_m(vbool2_t vm, vuint16m8_t vs2,
                                               vuint32m1_t vs1, size_t vl);
vuint64m1_t __riscv_vwredsumu_vs_u32mf2_u64m1_m(vbool64_t vm, vuint32mf2_t vs2,
                                                vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vwredsumu_vs_u32m1_u64m1_m(vbool32_t vm, vuint32m1_t vs2,
                                               vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vwredsumu_vs_u32m2_u64m1_m(vbool16_t vm, vuint32m2_t vs2,
                                               vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vwredsumu_vs_u32m4_u64m1_m(vbool8_t vm, vuint32m4_t vs2,
                                               vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vwredsumu_vs_u32m8_u64m1_m(vbool4_t vm, vuint32m8_t vs2,
                                               vuint64m1_t vs1, size_t vl);
----

[[vector-single-width-floating-point-reduction]]
==== Vector Single-Width Floating-Point Reduction Intrinsics

[,c]
----
vfloat16m1_t __riscv_vfredosum_vs_f16mf4_f16m1(vfloat16mf4_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16mf2_f16m1(vfloat16mf2_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m1_f16m1(vfloat16m1_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m2_f16m1(vfloat16m2_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m4_f16m1(vfloat16m4_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m8_f16m1(vfloat16m8_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32mf2_f32m1(vfloat32mf2_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m1_f32m1(vfloat32m1_t vs2,
                                              vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m2_f32m1(vfloat32m2_t vs2,
                                              vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m4_f32m1(vfloat32m4_t vs2,
                                              vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m8_f32m1(vfloat32m8_t vs2,
                                              vfloat32m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m1_f64m1(vfloat64m1_t vs2,
                                              vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m2_f64m1(vfloat64m2_t vs2,
                                              vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m4_f64m1(vfloat64m4_t vs2,
                                              vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m8_f64m1(vfloat64m8_t vs2,
                                              vfloat64m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16mf4_f16m1(vfloat16mf4_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16mf2_f16m1(vfloat16mf2_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m1_f16m1(vfloat16m1_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m2_f16m1(vfloat16m2_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m4_f16m1(vfloat16m4_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m8_f16m1(vfloat16m8_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32mf2_f32m1(vfloat32mf2_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m1_f32m1(vfloat32m1_t vs2,
                                              vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m2_f32m1(vfloat32m2_t vs2,
                                              vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m4_f32m1(vfloat32m4_t vs2,
                                              vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m8_f32m1(vfloat32m8_t vs2,
                                              vfloat32m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m1_f64m1(vfloat64m1_t vs2,
                                              vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m2_f64m1(vfloat64m2_t vs2,
                                              vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m4_f64m1(vfloat64m4_t vs2,
                                              vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m8_f64m1(vfloat64m8_t vs2,
                                              vfloat64m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16mf4_f16m1(vfloat16mf4_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16mf2_f16m1(vfloat16mf2_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16m1_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                             size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16m2_f16m1(vfloat16m2_t vs2, vfloat16m1_t vs1,
                                             size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16m4_f16m1(vfloat16m4_t vs2, vfloat16m1_t vs1,
                                             size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16m8_f16m1(vfloat16m8_t vs2, vfloat16m1_t vs1,
                                             size_t vl);
vfloat32m1_t __riscv_vfredmax_vs_f32mf2_f32m1(vfloat32mf2_t vs2,
                                              vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmax_vs_f32m1_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                             size_t vl);
vfloat32m1_t __riscv_vfredmax_vs_f32m2_f32m1(vfloat32m2_t vs2, vfloat32m1_t vs1,
                                             size_t vl);
vfloat32m1_t __riscv_vfredmax_vs_f32m4_f32m1(vfloat32m4_t vs2, vfloat32m1_t vs1,
                                             size_t vl);
vfloat32m1_t __riscv_vfredmax_vs_f32m8_f32m1(vfloat32m8_t vs2, vfloat32m1_t vs1,
                                             size_t vl);
vfloat64m1_t __riscv_vfredmax_vs_f64m1_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                             size_t vl);
vfloat64m1_t __riscv_vfredmax_vs_f64m2_f64m1(vfloat64m2_t vs2, vfloat64m1_t vs1,
                                             size_t vl);
vfloat64m1_t __riscv_vfredmax_vs_f64m4_f64m1(vfloat64m4_t vs2, vfloat64m1_t vs1,
                                             size_t vl);
vfloat64m1_t __riscv_vfredmax_vs_f64m8_f64m1(vfloat64m8_t vs2, vfloat64m1_t vs1,
                                             size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16mf4_f16m1(vfloat16mf4_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16mf2_f16m1(vfloat16mf2_t vs2,
                                              vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16m1_f16m1(vfloat16m1_t vs2, vfloat16m1_t vs1,
                                             size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16m2_f16m1(vfloat16m2_t vs2, vfloat16m1_t vs1,
                                             size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16m4_f16m1(vfloat16m4_t vs2, vfloat16m1_t vs1,
                                             size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16m8_f16m1(vfloat16m8_t vs2, vfloat16m1_t vs1,
                                             size_t vl);
vfloat32m1_t __riscv_vfredmin_vs_f32mf2_f32m1(vfloat32mf2_t vs2,
                                              vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmin_vs_f32m1_f32m1(vfloat32m1_t vs2, vfloat32m1_t vs1,
                                             size_t vl);
vfloat32m1_t __riscv_vfredmin_vs_f32m2_f32m1(vfloat32m2_t vs2, vfloat32m1_t vs1,
                                             size_t vl);
vfloat32m1_t __riscv_vfredmin_vs_f32m4_f32m1(vfloat32m4_t vs2, vfloat32m1_t vs1,
                                             size_t vl);
vfloat32m1_t __riscv_vfredmin_vs_f32m8_f32m1(vfloat32m8_t vs2, vfloat32m1_t vs1,
                                             size_t vl);
vfloat64m1_t __riscv_vfredmin_vs_f64m1_f64m1(vfloat64m1_t vs2, vfloat64m1_t vs1,
                                             size_t vl);
vfloat64m1_t __riscv_vfredmin_vs_f64m2_f64m1(vfloat64m2_t vs2, vfloat64m1_t vs1,
                                             size_t vl);
vfloat64m1_t __riscv_vfredmin_vs_f64m4_f64m1(vfloat64m4_t vs2, vfloat64m1_t vs1,
                                             size_t vl);
vfloat64m1_t __riscv_vfredmin_vs_f64m8_f64m1(vfloat64m8_t vs2, vfloat64m1_t vs1,
                                             size_t vl);
// masked functions
vfloat16m1_t __riscv_vfredosum_vs_f16mf4_f16m1_m(vbool64_t vm,
                                                 vfloat16mf4_t vs2,
                                                 vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16mf2_f16m1_m(vbool32_t vm,
                                                 vfloat16mf2_t vs2,
                                                 vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m1_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m2_f16m1_m(vbool8_t vm, vfloat16m2_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m4_f16m1_m(vbool4_t vm, vfloat16m4_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m8_f16m1_m(vbool2_t vm, vfloat16m8_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32mf2_f32m1_m(vbool64_t vm,
                                                 vfloat32mf2_t vs2,
                                                 vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m1_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m2_f32m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m4_f32m1_m(vbool8_t vm, vfloat32m4_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m8_f32m1_m(vbool4_t vm, vfloat32m8_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m1_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                                vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m2_f64m1_m(vbool32_t vm, vfloat64m2_t vs2,
                                                vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m4_f64m1_m(vbool16_t vm, vfloat64m4_t vs2,
                                                vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m8_f64m1_m(vbool8_t vm, vfloat64m8_t vs2,
                                                vfloat64m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16mf4_f16m1_m(vbool64_t vm,
                                                 vfloat16mf4_t vs2,
                                                 vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16mf2_f16m1_m(vbool32_t vm,
                                                 vfloat16mf2_t vs2,
                                                 vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m1_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m2_f16m1_m(vbool8_t vm, vfloat16m2_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m4_f16m1_m(vbool4_t vm, vfloat16m4_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m8_f16m1_m(vbool2_t vm, vfloat16m8_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32mf2_f32m1_m(vbool64_t vm,
                                                 vfloat32mf2_t vs2,
                                                 vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m1_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m2_f32m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m4_f32m1_m(vbool8_t vm, vfloat32m4_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m8_f32m1_m(vbool4_t vm, vfloat32m8_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m1_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                                vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m2_f64m1_m(vbool32_t vm, vfloat64m2_t vs2,
                                                vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m4_f64m1_m(vbool16_t vm, vfloat64m4_t vs2,
                                                vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m8_f64m1_m(vbool8_t vm, vfloat64m8_t vs2,
                                                vfloat64m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16mf4_f16m1_m(vbool64_t vm, vfloat16mf4_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16mf2_f16m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16m1_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16m2_f16m1_m(vbool8_t vm, vfloat16m2_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16m4_f16m1_m(vbool4_t vm, vfloat16m4_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmax_vs_f16m8_f16m1_m(vbool2_t vm, vfloat16m8_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmax_vs_f32mf2_f32m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmax_vs_f32m1_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmax_vs_f32m2_f32m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmax_vs_f32m4_f32m1_m(vbool8_t vm, vfloat32m4_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmax_vs_f32m8_f32m1_m(vbool4_t vm, vfloat32m8_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredmax_vs_f64m1_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredmax_vs_f64m2_f64m1_m(vbool32_t vm, vfloat64m2_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredmax_vs_f64m4_f64m1_m(vbool16_t vm, vfloat64m4_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredmax_vs_f64m8_f64m1_m(vbool8_t vm, vfloat64m8_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16mf4_f16m1_m(vbool64_t vm, vfloat16mf4_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16mf2_f16m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                                vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16m1_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16m2_f16m1_m(vbool8_t vm, vfloat16m2_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16m4_f16m1_m(vbool4_t vm, vfloat16m4_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredmin_vs_f16m8_f16m1_m(vbool2_t vm, vfloat16m8_t vs2,
                                               vfloat16m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmin_vs_f32mf2_f32m1_m(vbool64_t vm, vfloat32mf2_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmin_vs_f32m1_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmin_vs_f32m2_f32m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmin_vs_f32m4_f32m1_m(vbool8_t vm, vfloat32m4_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfredmin_vs_f32m8_f32m1_m(vbool4_t vm, vfloat32m8_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredmin_vs_f64m1_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredmin_vs_f64m2_f64m1_m(vbool32_t vm, vfloat64m2_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredmin_vs_f64m4_f64m1_m(vbool16_t vm, vfloat64m4_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfredmin_vs_f64m8_f64m1_m(vbool8_t vm, vfloat64m8_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16mf4_f16m1_rm(vfloat16mf4_t vs2,
                                                  vfloat16m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16mf2_f16m1_rm(vfloat16mf2_t vs2,
                                                  vfloat16m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m1_f16m1_rm(vfloat16m1_t vs2,
                                                 vfloat16m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m2_f16m1_rm(vfloat16m2_t vs2,
                                                 vfloat16m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m4_f16m1_rm(vfloat16m4_t vs2,
                                                 vfloat16m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m8_f16m1_rm(vfloat16m8_t vs2,
                                                 vfloat16m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32mf2_f32m1_rm(vfloat32mf2_t vs2,
                                                  vfloat32m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m1_f32m1_rm(vfloat32m1_t vs2,
                                                 vfloat32m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m2_f32m1_rm(vfloat32m2_t vs2,
                                                 vfloat32m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m4_f32m1_rm(vfloat32m4_t vs2,
                                                 vfloat32m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m8_f32m1_rm(vfloat32m8_t vs2,
                                                 vfloat32m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m1_f64m1_rm(vfloat64m1_t vs2,
                                                 vfloat64m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m2_f64m1_rm(vfloat64m2_t vs2,
                                                 vfloat64m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m4_f64m1_rm(vfloat64m4_t vs2,
                                                 vfloat64m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m8_f64m1_rm(vfloat64m8_t vs2,
                                                 vfloat64m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16mf4_f16m1_rm(vfloat16mf4_t vs2,
                                                  vfloat16m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16mf2_f16m1_rm(vfloat16mf2_t vs2,
                                                  vfloat16m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m1_f16m1_rm(vfloat16m1_t vs2,
                                                 vfloat16m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m2_f16m1_rm(vfloat16m2_t vs2,
                                                 vfloat16m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m4_f16m1_rm(vfloat16m4_t vs2,
                                                 vfloat16m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m8_f16m1_rm(vfloat16m8_t vs2,
                                                 vfloat16m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32mf2_f32m1_rm(vfloat32mf2_t vs2,
                                                  vfloat32m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m1_f32m1_rm(vfloat32m1_t vs2,
                                                 vfloat32m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m2_f32m1_rm(vfloat32m2_t vs2,
                                                 vfloat32m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m4_f32m1_rm(vfloat32m4_t vs2,
                                                 vfloat32m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m8_f32m1_rm(vfloat32m8_t vs2,
                                                 vfloat32m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m1_f64m1_rm(vfloat64m1_t vs2,
                                                 vfloat64m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m2_f64m1_rm(vfloat64m2_t vs2,
                                                 vfloat64m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m4_f64m1_rm(vfloat64m4_t vs2,
                                                 vfloat64m1_t vs1,
                                                 unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m8_f64m1_rm(vfloat64m8_t vs2,
                                                 vfloat64m1_t vs1,
                                                 unsigned int frm, size_t vl);
// masked functions
vfloat16m1_t __riscv_vfredosum_vs_f16mf4_f16m1_rm_m(vbool64_t vm,
                                                    vfloat16mf4_t vs2,
                                                    vfloat16m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16mf2_f16m1_rm_m(vbool32_t vm,
                                                    vfloat16mf2_t vs2,
                                                    vfloat16m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m1_f16m1_rm_m(vbool16_t vm,
                                                   vfloat16m1_t vs2,
                                                   vfloat16m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m2_f16m1_rm_m(vbool8_t vm,
                                                   vfloat16m2_t vs2,
                                                   vfloat16m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m4_f16m1_rm_m(vbool4_t vm,
                                                   vfloat16m4_t vs2,
                                                   vfloat16m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_vs_f16m8_f16m1_rm_m(vbool2_t vm,
                                                   vfloat16m8_t vs2,
                                                   vfloat16m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32mf2_f32m1_rm_m(vbool64_t vm,
                                                    vfloat32mf2_t vs2,
                                                    vfloat32m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m1_f32m1_rm_m(vbool32_t vm,
                                                   vfloat32m1_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m2_f32m1_rm_m(vbool16_t vm,
                                                   vfloat32m2_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m4_f32m1_rm_m(vbool8_t vm,
                                                   vfloat32m4_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_vs_f32m8_f32m1_rm_m(vbool4_t vm,
                                                   vfloat32m8_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m1_f64m1_rm_m(vbool64_t vm,
                                                   vfloat64m1_t vs2,
                                                   vfloat64m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m2_f64m1_rm_m(vbool32_t vm,
                                                   vfloat64m2_t vs2,
                                                   vfloat64m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m4_f64m1_rm_m(vbool16_t vm,
                                                   vfloat64m4_t vs2,
                                                   vfloat64m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_vs_f64m8_f64m1_rm_m(vbool8_t vm,
                                                   vfloat64m8_t vs2,
                                                   vfloat64m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16mf4_f16m1_rm_m(vbool64_t vm,
                                                    vfloat16mf4_t vs2,
                                                    vfloat16m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16mf2_f16m1_rm_m(vbool32_t vm,
                                                    vfloat16mf2_t vs2,
                                                    vfloat16m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m1_f16m1_rm_m(vbool16_t vm,
                                                   vfloat16m1_t vs2,
                                                   vfloat16m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m2_f16m1_rm_m(vbool8_t vm,
                                                   vfloat16m2_t vs2,
                                                   vfloat16m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m4_f16m1_rm_m(vbool4_t vm,
                                                   vfloat16m4_t vs2,
                                                   vfloat16m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_vs_f16m8_f16m1_rm_m(vbool2_t vm,
                                                   vfloat16m8_t vs2,
                                                   vfloat16m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32mf2_f32m1_rm_m(vbool64_t vm,
                                                    vfloat32mf2_t vs2,
                                                    vfloat32m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m1_f32m1_rm_m(vbool32_t vm,
                                                   vfloat32m1_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m2_f32m1_rm_m(vbool16_t vm,
                                                   vfloat32m2_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m4_f32m1_rm_m(vbool8_t vm,
                                                   vfloat32m4_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_vs_f32m8_f32m1_rm_m(vbool4_t vm,
                                                   vfloat32m8_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m1_f64m1_rm_m(vbool64_t vm,
                                                   vfloat64m1_t vs2,
                                                   vfloat64m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m2_f64m1_rm_m(vbool32_t vm,
                                                   vfloat64m2_t vs2,
                                                   vfloat64m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m4_f64m1_rm_m(vbool16_t vm,
                                                   vfloat64m4_t vs2,
                                                   vfloat64m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_vs_f64m8_f64m1_rm_m(vbool8_t vm,
                                                   vfloat64m8_t vs2,
                                                   vfloat64m1_t vs1,
                                                   unsigned int frm, size_t vl);
----

[[vector-widening-floating-point-reduction]]
==== Vector Widening Floating-Point Reduction Intrinsics

[,c]
----
vfloat32m1_t __riscv_vfwredosum_vs_f16mf4_f32m1(vfloat16mf4_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16mf2_f32m1(vfloat16mf2_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m1_f32m1(vfloat16m1_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m2_f32m1(vfloat16m2_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m4_f32m1(vfloat16m4_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m8_f32m1(vfloat16m8_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32mf2_f64m1(vfloat32mf2_t vs2,
                                                vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m1_f64m1(vfloat32m1_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m2_f64m1(vfloat32m2_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m4_f64m1(vfloat32m4_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m8_f64m1(vfloat32m8_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16mf4_f32m1(vfloat16mf4_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16mf2_f32m1(vfloat16mf2_t vs2,
                                                vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m1_f32m1(vfloat16m1_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m2_f32m1(vfloat16m2_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m4_f32m1(vfloat16m4_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m8_f32m1(vfloat16m8_t vs2,
                                               vfloat32m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32mf2_f64m1(vfloat32mf2_t vs2,
                                                vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m1_f64m1(vfloat32m1_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m2_f64m1(vfloat32m2_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m4_f64m1(vfloat32m4_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m8_f64m1(vfloat32m8_t vs2,
                                               vfloat64m1_t vs1, size_t vl);
// masked functions
vfloat32m1_t __riscv_vfwredosum_vs_f16mf4_f32m1_m(vbool64_t vm,
                                                  vfloat16mf4_t vs2,
                                                  vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16mf2_f32m1_m(vbool32_t vm,
                                                  vfloat16mf2_t vs2,
                                                  vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m1_f32m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                                 vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m2_f32m1_m(vbool8_t vm, vfloat16m2_t vs2,
                                                 vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m4_f32m1_m(vbool4_t vm, vfloat16m4_t vs2,
                                                 vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m8_f32m1_m(vbool2_t vm, vfloat16m8_t vs2,
                                                 vfloat32m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32mf2_f64m1_m(vbool64_t vm,
                                                  vfloat32mf2_t vs2,
                                                  vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m1_f64m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                                 vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m2_f64m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                                 vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m4_f64m1_m(vbool8_t vm, vfloat32m4_t vs2,
                                                 vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m8_f64m1_m(vbool4_t vm, vfloat32m8_t vs2,
                                                 vfloat64m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16mf4_f32m1_m(vbool64_t vm,
                                                  vfloat16mf4_t vs2,
                                                  vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16mf2_f32m1_m(vbool32_t vm,
                                                  vfloat16mf2_t vs2,
                                                  vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m1_f32m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                                 vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m2_f32m1_m(vbool8_t vm, vfloat16m2_t vs2,
                                                 vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m4_f32m1_m(vbool4_t vm, vfloat16m4_t vs2,
                                                 vfloat32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m8_f32m1_m(vbool2_t vm, vfloat16m8_t vs2,
                                                 vfloat32m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32mf2_f64m1_m(vbool64_t vm,
                                                  vfloat32mf2_t vs2,
                                                  vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m1_f64m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                                 vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m2_f64m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                                 vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m4_f64m1_m(vbool8_t vm, vfloat32m4_t vs2,
                                                 vfloat64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m8_f64m1_m(vbool4_t vm, vfloat32m8_t vs2,
                                                 vfloat64m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16mf4_f32m1_rm(vfloat16mf4_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16mf2_f32m1_rm(vfloat16mf2_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m1_f32m1_rm(vfloat16m1_t vs2,
                                                  vfloat32m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m2_f32m1_rm(vfloat16m2_t vs2,
                                                  vfloat32m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m4_f32m1_rm(vfloat16m4_t vs2,
                                                  vfloat32m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m8_f32m1_rm(vfloat16m8_t vs2,
                                                  vfloat32m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32mf2_f64m1_rm(vfloat32mf2_t vs2,
                                                   vfloat64m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m1_f64m1_rm(vfloat32m1_t vs2,
                                                  vfloat64m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m2_f64m1_rm(vfloat32m2_t vs2,
                                                  vfloat64m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m4_f64m1_rm(vfloat32m4_t vs2,
                                                  vfloat64m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m8_f64m1_rm(vfloat32m8_t vs2,
                                                  vfloat64m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16mf4_f32m1_rm(vfloat16mf4_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16mf2_f32m1_rm(vfloat16mf2_t vs2,
                                                   vfloat32m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m1_f32m1_rm(vfloat16m1_t vs2,
                                                  vfloat32m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m2_f32m1_rm(vfloat16m2_t vs2,
                                                  vfloat32m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m4_f32m1_rm(vfloat16m4_t vs2,
                                                  vfloat32m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m8_f32m1_rm(vfloat16m8_t vs2,
                                                  vfloat32m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32mf2_f64m1_rm(vfloat32mf2_t vs2,
                                                   vfloat64m1_t vs1,
                                                   unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m1_f64m1_rm(vfloat32m1_t vs2,
                                                  vfloat64m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m2_f64m1_rm(vfloat32m2_t vs2,
                                                  vfloat64m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m4_f64m1_rm(vfloat32m4_t vs2,
                                                  vfloat64m1_t vs1,
                                                  unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m8_f64m1_rm(vfloat32m8_t vs2,
                                                  vfloat64m1_t vs1,
                                                  unsigned int frm, size_t vl);
// masked functions
vfloat32m1_t __riscv_vfwredosum_vs_f16mf4_f32m1_rm_m(vbool64_t vm,
                                                     vfloat16mf4_t vs2,
                                                     vfloat32m1_t vs1,
                                                     unsigned int frm,
                                                     size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16mf2_f32m1_rm_m(vbool32_t vm,
                                                     vfloat16mf2_t vs2,
                                                     vfloat32m1_t vs1,
                                                     unsigned int frm,
                                                     size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m1_f32m1_rm_m(vbool16_t vm,
                                                    vfloat16m1_t vs2,
                                                    vfloat32m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m2_f32m1_rm_m(vbool8_t vm,
                                                    vfloat16m2_t vs2,
                                                    vfloat32m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m4_f32m1_rm_m(vbool4_t vm,
                                                    vfloat16m4_t vs2,
                                                    vfloat32m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat32m1_t __riscv_vfwredosum_vs_f16m8_f32m1_rm_m(vbool2_t vm,
                                                    vfloat16m8_t vs2,
                                                    vfloat32m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32mf2_f64m1_rm_m(vbool64_t vm,
                                                     vfloat32mf2_t vs2,
                                                     vfloat64m1_t vs1,
                                                     unsigned int frm,
                                                     size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m1_f64m1_rm_m(vbool32_t vm,
                                                    vfloat32m1_t vs2,
                                                    vfloat64m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m2_f64m1_rm_m(vbool16_t vm,
                                                    vfloat32m2_t vs2,
                                                    vfloat64m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m4_f64m1_rm_m(vbool8_t vm,
                                                    vfloat32m4_t vs2,
                                                    vfloat64m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat64m1_t __riscv_vfwredosum_vs_f32m8_f64m1_rm_m(vbool4_t vm,
                                                    vfloat32m8_t vs2,
                                                    vfloat64m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16mf4_f32m1_rm_m(vbool64_t vm,
                                                     vfloat16mf4_t vs2,
                                                     vfloat32m1_t vs1,
                                                     unsigned int frm,
                                                     size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16mf2_f32m1_rm_m(vbool32_t vm,
                                                     vfloat16mf2_t vs2,
                                                     vfloat32m1_t vs1,
                                                     unsigned int frm,
                                                     size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m1_f32m1_rm_m(vbool16_t vm,
                                                    vfloat16m1_t vs2,
                                                    vfloat32m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m2_f32m1_rm_m(vbool8_t vm,
                                                    vfloat16m2_t vs2,
                                                    vfloat32m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m4_f32m1_rm_m(vbool4_t vm,
                                                    vfloat16m4_t vs2,
                                                    vfloat32m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat32m1_t __riscv_vfwredusum_vs_f16m8_f32m1_rm_m(vbool2_t vm,
                                                    vfloat16m8_t vs2,
                                                    vfloat32m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32mf2_f64m1_rm_m(vbool64_t vm,
                                                     vfloat32mf2_t vs2,
                                                     vfloat64m1_t vs1,
                                                     unsigned int frm,
                                                     size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m1_f64m1_rm_m(vbool32_t vm,
                                                    vfloat32m1_t vs2,
                                                    vfloat64m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m2_f64m1_rm_m(vbool16_t vm,
                                                    vfloat32m2_t vs2,
                                                    vfloat64m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m4_f64m1_rm_m(vbool8_t vm,
                                                    vfloat32m4_t vs2,
                                                    vfloat64m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
vfloat64m1_t __riscv_vfwredusum_vs_f32m8_f64m1_rm_m(vbool4_t vm,
                                                    vfloat32m8_t vs2,
                                                    vfloat64m1_t vs1,
                                                    unsigned int frm,
                                                    size_t vl);
----

=== Vector Mask Intrinsics

[[vector-mask-register-logical]]
==== Vector Mask-Register Logical

[,c]
----
vbool1_t __riscv_vmand_mm_b1(vbool1_t vs2, vbool1_t vs1, size_t vl);
vbool2_t __riscv_vmand_mm_b2(vbool2_t vs2, vbool2_t vs1, size_t vl);
vbool4_t __riscv_vmand_mm_b4(vbool4_t vs2, vbool4_t vs1, size_t vl);
vbool8_t __riscv_vmand_mm_b8(vbool8_t vs2, vbool8_t vs1, size_t vl);
vbool16_t __riscv_vmand_mm_b16(vbool16_t vs2, vbool16_t vs1, size_t vl);
vbool32_t __riscv_vmand_mm_b32(vbool32_t vs2, vbool32_t vs1, size_t vl);
vbool64_t __riscv_vmand_mm_b64(vbool64_t vs2, vbool64_t vs1, size_t vl);
vbool1_t __riscv_vmnand_mm_b1(vbool1_t vs2, vbool1_t vs1, size_t vl);
vbool2_t __riscv_vmnand_mm_b2(vbool2_t vs2, vbool2_t vs1, size_t vl);
vbool4_t __riscv_vmnand_mm_b4(vbool4_t vs2, vbool4_t vs1, size_t vl);
vbool8_t __riscv_vmnand_mm_b8(vbool8_t vs2, vbool8_t vs1, size_t vl);
vbool16_t __riscv_vmnand_mm_b16(vbool16_t vs2, vbool16_t vs1, size_t vl);
vbool32_t __riscv_vmnand_mm_b32(vbool32_t vs2, vbool32_t vs1, size_t vl);
vbool64_t __riscv_vmnand_mm_b64(vbool64_t vs2, vbool64_t vs1, size_t vl);
vbool1_t __riscv_vmandn_mm_b1(vbool1_t vs2, vbool1_t vs1, size_t vl);
vbool2_t __riscv_vmandn_mm_b2(vbool2_t vs2, vbool2_t vs1, size_t vl);
vbool4_t __riscv_vmandn_mm_b4(vbool4_t vs2, vbool4_t vs1, size_t vl);
vbool8_t __riscv_vmandn_mm_b8(vbool8_t vs2, vbool8_t vs1, size_t vl);
vbool16_t __riscv_vmandn_mm_b16(vbool16_t vs2, vbool16_t vs1, size_t vl);
vbool32_t __riscv_vmandn_mm_b32(vbool32_t vs2, vbool32_t vs1, size_t vl);
vbool64_t __riscv_vmandn_mm_b64(vbool64_t vs2, vbool64_t vs1, size_t vl);
vbool1_t __riscv_vmxor_mm_b1(vbool1_t vs2, vbool1_t vs1, size_t vl);
vbool2_t __riscv_vmxor_mm_b2(vbool2_t vs2, vbool2_t vs1, size_t vl);
vbool4_t __riscv_vmxor_mm_b4(vbool4_t vs2, vbool4_t vs1, size_t vl);
vbool8_t __riscv_vmxor_mm_b8(vbool8_t vs2, vbool8_t vs1, size_t vl);
vbool16_t __riscv_vmxor_mm_b16(vbool16_t vs2, vbool16_t vs1, size_t vl);
vbool32_t __riscv_vmxor_mm_b32(vbool32_t vs2, vbool32_t vs1, size_t vl);
vbool64_t __riscv_vmxor_mm_b64(vbool64_t vs2, vbool64_t vs1, size_t vl);
vbool1_t __riscv_vmor_mm_b1(vbool1_t vs2, vbool1_t vs1, size_t vl);
vbool2_t __riscv_vmor_mm_b2(vbool2_t vs2, vbool2_t vs1, size_t vl);
vbool4_t __riscv_vmor_mm_b4(vbool4_t vs2, vbool4_t vs1, size_t vl);
vbool8_t __riscv_vmor_mm_b8(vbool8_t vs2, vbool8_t vs1, size_t vl);
vbool16_t __riscv_vmor_mm_b16(vbool16_t vs2, vbool16_t vs1, size_t vl);
vbool32_t __riscv_vmor_mm_b32(vbool32_t vs2, vbool32_t vs1, size_t vl);
vbool64_t __riscv_vmor_mm_b64(vbool64_t vs2, vbool64_t vs1, size_t vl);
vbool1_t __riscv_vmnor_mm_b1(vbool1_t vs2, vbool1_t vs1, size_t vl);
vbool2_t __riscv_vmnor_mm_b2(vbool2_t vs2, vbool2_t vs1, size_t vl);
vbool4_t __riscv_vmnor_mm_b4(vbool4_t vs2, vbool4_t vs1, size_t vl);
vbool8_t __riscv_vmnor_mm_b8(vbool8_t vs2, vbool8_t vs1, size_t vl);
vbool16_t __riscv_vmnor_mm_b16(vbool16_t vs2, vbool16_t vs1, size_t vl);
vbool32_t __riscv_vmnor_mm_b32(vbool32_t vs2, vbool32_t vs1, size_t vl);
vbool64_t __riscv_vmnor_mm_b64(vbool64_t vs2, vbool64_t vs1, size_t vl);
vbool1_t __riscv_vmorn_mm_b1(vbool1_t vs2, vbool1_t vs1, size_t vl);
vbool2_t __riscv_vmorn_mm_b2(vbool2_t vs2, vbool2_t vs1, size_t vl);
vbool4_t __riscv_vmorn_mm_b4(vbool4_t vs2, vbool4_t vs1, size_t vl);
vbool8_t __riscv_vmorn_mm_b8(vbool8_t vs2, vbool8_t vs1, size_t vl);
vbool16_t __riscv_vmorn_mm_b16(vbool16_t vs2, vbool16_t vs1, size_t vl);
vbool32_t __riscv_vmorn_mm_b32(vbool32_t vs2, vbool32_t vs1, size_t vl);
vbool64_t __riscv_vmorn_mm_b64(vbool64_t vs2, vbool64_t vs1, size_t vl);
vbool1_t __riscv_vmxnor_mm_b1(vbool1_t vs2, vbool1_t vs1, size_t vl);
vbool2_t __riscv_vmxnor_mm_b2(vbool2_t vs2, vbool2_t vs1, size_t vl);
vbool4_t __riscv_vmxnor_mm_b4(vbool4_t vs2, vbool4_t vs1, size_t vl);
vbool8_t __riscv_vmxnor_mm_b8(vbool8_t vs2, vbool8_t vs1, size_t vl);
vbool16_t __riscv_vmxnor_mm_b16(vbool16_t vs2, vbool16_t vs1, size_t vl);
vbool32_t __riscv_vmxnor_mm_b32(vbool32_t vs2, vbool32_t vs1, size_t vl);
vbool64_t __riscv_vmxnor_mm_b64(vbool64_t vs2, vbool64_t vs1, size_t vl);
vbool1_t __riscv_vmmv_m_b1(vbool1_t vs, size_t vl);
vbool2_t __riscv_vmmv_m_b2(vbool2_t vs, size_t vl);
vbool4_t __riscv_vmmv_m_b4(vbool4_t vs, size_t vl);
vbool8_t __riscv_vmmv_m_b8(vbool8_t vs, size_t vl);
vbool16_t __riscv_vmmv_m_b16(vbool16_t vs, size_t vl);
vbool32_t __riscv_vmmv_m_b32(vbool32_t vs, size_t vl);
vbool64_t __riscv_vmmv_m_b64(vbool64_t vs, size_t vl);
vbool1_t __riscv_vmclr_m_b1(size_t vl);
vbool2_t __riscv_vmclr_m_b2(size_t vl);
vbool4_t __riscv_vmclr_m_b4(size_t vl);
vbool8_t __riscv_vmclr_m_b8(size_t vl);
vbool16_t __riscv_vmclr_m_b16(size_t vl);
vbool32_t __riscv_vmclr_m_b32(size_t vl);
vbool64_t __riscv_vmclr_m_b64(size_t vl);
vbool1_t __riscv_vmset_m_b1(size_t vl);
vbool2_t __riscv_vmset_m_b2(size_t vl);
vbool4_t __riscv_vmset_m_b4(size_t vl);
vbool8_t __riscv_vmset_m_b8(size_t vl);
vbool16_t __riscv_vmset_m_b16(size_t vl);
vbool32_t __riscv_vmset_m_b32(size_t vl);
vbool64_t __riscv_vmset_m_b64(size_t vl);
vbool1_t __riscv_vmnot_m_b1(vbool1_t vs, size_t vl);
vbool2_t __riscv_vmnot_m_b2(vbool2_t vs, size_t vl);
vbool4_t __riscv_vmnot_m_b4(vbool4_t vs, size_t vl);
vbool8_t __riscv_vmnot_m_b8(vbool8_t vs, size_t vl);
vbool16_t __riscv_vmnot_m_b16(vbool16_t vs, size_t vl);
vbool32_t __riscv_vmnot_m_b32(vbool32_t vs, size_t vl);
vbool64_t __riscv_vmnot_m_b64(vbool64_t vs, size_t vl);
----

[[vector-count-population-in-mask-vcpopm]]
==== Vector count population in mask `vcpop.m`

[,c]
----
unsigned long __riscv_vcpop_m_b1(vbool1_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b2(vbool2_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b4(vbool4_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b8(vbool8_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b16(vbool16_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b32(vbool32_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b64(vbool64_t vs2, size_t vl);
// masked functions
unsigned long __riscv_vcpop_m_b1_m(vbool1_t vm, vbool1_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b2_m(vbool2_t vm, vbool2_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b4_m(vbool4_t vm, vbool4_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b8_m(vbool8_t vm, vbool8_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b16_m(vbool16_t vm, vbool16_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b32_m(vbool32_t vm, vbool32_t vs2, size_t vl);
unsigned long __riscv_vcpop_m_b64_m(vbool64_t vm, vbool64_t vs2, size_t vl);
----

[[vfirst-find-first-set-mask-bit]]
==== `vfirst` find-first-set mask bit

[,c]
----
long __riscv_vfirst_m_b1(vbool1_t vs2, size_t vl);
long __riscv_vfirst_m_b2(vbool2_t vs2, size_t vl);
long __riscv_vfirst_m_b4(vbool4_t vs2, size_t vl);
long __riscv_vfirst_m_b8(vbool8_t vs2, size_t vl);
long __riscv_vfirst_m_b16(vbool16_t vs2, size_t vl);
long __riscv_vfirst_m_b32(vbool32_t vs2, size_t vl);
long __riscv_vfirst_m_b64(vbool64_t vs2, size_t vl);
// masked functions
long __riscv_vfirst_m_b1_m(vbool1_t vm, vbool1_t vs2, size_t vl);
long __riscv_vfirst_m_b2_m(vbool2_t vm, vbool2_t vs2, size_t vl);
long __riscv_vfirst_m_b4_m(vbool4_t vm, vbool4_t vs2, size_t vl);
long __riscv_vfirst_m_b8_m(vbool8_t vm, vbool8_t vs2, size_t vl);
long __riscv_vfirst_m_b16_m(vbool16_t vm, vbool16_t vs2, size_t vl);
long __riscv_vfirst_m_b32_m(vbool32_t vm, vbool32_t vs2, size_t vl);
long __riscv_vfirst_m_b64_m(vbool64_t vm, vbool64_t vs2, size_t vl);
----

[[vmsbfm-set-before-first-mask-bit]]
==== `vmsbf.m` set-before-first mask bit

[,c]
----
vbool1_t __riscv_vmsbf_m_b1(vbool1_t vs2, size_t vl);
vbool2_t __riscv_vmsbf_m_b2(vbool2_t vs2, size_t vl);
vbool4_t __riscv_vmsbf_m_b4(vbool4_t vs2, size_t vl);
vbool8_t __riscv_vmsbf_m_b8(vbool8_t vs2, size_t vl);
vbool16_t __riscv_vmsbf_m_b16(vbool16_t vs2, size_t vl);
vbool32_t __riscv_vmsbf_m_b32(vbool32_t vs2, size_t vl);
vbool64_t __riscv_vmsbf_m_b64(vbool64_t vs2, size_t vl);
// masked functions
vbool1_t __riscv_vmsbf_m_b1_m(vbool1_t vm, vbool1_t vs2, size_t vl);
vbool2_t __riscv_vmsbf_m_b2_m(vbool2_t vm, vbool2_t vs2, size_t vl);
vbool4_t __riscv_vmsbf_m_b4_m(vbool4_t vm, vbool4_t vs2, size_t vl);
vbool8_t __riscv_vmsbf_m_b8_m(vbool8_t vm, vbool8_t vs2, size_t vl);
vbool16_t __riscv_vmsbf_m_b16_m(vbool16_t vm, vbool16_t vs2, size_t vl);
vbool32_t __riscv_vmsbf_m_b32_m(vbool32_t vm, vbool32_t vs2, size_t vl);
vbool64_t __riscv_vmsbf_m_b64_m(vbool64_t vm, vbool64_t vs2, size_t vl);
----

[[vmsifm-set-including-first-mask-bit]]
==== `vmsif.m` set-including-first mask bit

[,c]
----
vbool1_t __riscv_vmsif_m_b1(vbool1_t vs2, size_t vl);
vbool2_t __riscv_vmsif_m_b2(vbool2_t vs2, size_t vl);
vbool4_t __riscv_vmsif_m_b4(vbool4_t vs2, size_t vl);
vbool8_t __riscv_vmsif_m_b8(vbool8_t vs2, size_t vl);
vbool16_t __riscv_vmsif_m_b16(vbool16_t vs2, size_t vl);
vbool32_t __riscv_vmsif_m_b32(vbool32_t vs2, size_t vl);
vbool64_t __riscv_vmsif_m_b64(vbool64_t vs2, size_t vl);
// masked functions
vbool1_t __riscv_vmsif_m_b1_m(vbool1_t vm, vbool1_t vs2, size_t vl);
vbool2_t __riscv_vmsif_m_b2_m(vbool2_t vm, vbool2_t vs2, size_t vl);
vbool4_t __riscv_vmsif_m_b4_m(vbool4_t vm, vbool4_t vs2, size_t vl);
vbool8_t __riscv_vmsif_m_b8_m(vbool8_t vm, vbool8_t vs2, size_t vl);
vbool16_t __riscv_vmsif_m_b16_m(vbool16_t vm, vbool16_t vs2, size_t vl);
vbool32_t __riscv_vmsif_m_b32_m(vbool32_t vm, vbool32_t vs2, size_t vl);
vbool64_t __riscv_vmsif_m_b64_m(vbool64_t vm, vbool64_t vs2, size_t vl);
----

[[vmsofm-set-only-first-mask-bit]]
==== `vmsof.m` set-only-first mask bit

[,c]
----
vbool1_t __riscv_vmsof_m_b1(vbool1_t vs2, size_t vl);
vbool2_t __riscv_vmsof_m_b2(vbool2_t vs2, size_t vl);
vbool4_t __riscv_vmsof_m_b4(vbool4_t vs2, size_t vl);
vbool8_t __riscv_vmsof_m_b8(vbool8_t vs2, size_t vl);
vbool16_t __riscv_vmsof_m_b16(vbool16_t vs2, size_t vl);
vbool32_t __riscv_vmsof_m_b32(vbool32_t vs2, size_t vl);
vbool64_t __riscv_vmsof_m_b64(vbool64_t vs2, size_t vl);
// masked functions
vbool1_t __riscv_vmsof_m_b1_m(vbool1_t vm, vbool1_t vs2, size_t vl);
vbool2_t __riscv_vmsof_m_b2_m(vbool2_t vm, vbool2_t vs2, size_t vl);
vbool4_t __riscv_vmsof_m_b4_m(vbool4_t vm, vbool4_t vs2, size_t vl);
vbool8_t __riscv_vmsof_m_b8_m(vbool8_t vm, vbool8_t vs2, size_t vl);
vbool16_t __riscv_vmsof_m_b16_m(vbool16_t vm, vbool16_t vs2, size_t vl);
vbool32_t __riscv_vmsof_m_b32_m(vbool32_t vm, vbool32_t vs2, size_t vl);
vbool64_t __riscv_vmsof_m_b64_m(vbool64_t vm, vbool64_t vs2, size_t vl);
----

[[vector-iota]]
==== Vector Iota Intrinsics

[,c]
----
vuint8mf8_t __riscv_viota_m_u8mf8(vbool64_t vs2, size_t vl);
vuint8mf4_t __riscv_viota_m_u8mf4(vbool32_t vs2, size_t vl);
vuint8mf2_t __riscv_viota_m_u8mf2(vbool16_t vs2, size_t vl);
vuint8m1_t __riscv_viota_m_u8m1(vbool8_t vs2, size_t vl);
vuint8m2_t __riscv_viota_m_u8m2(vbool4_t vs2, size_t vl);
vuint8m4_t __riscv_viota_m_u8m4(vbool2_t vs2, size_t vl);
vuint8m8_t __riscv_viota_m_u8m8(vbool1_t vs2, size_t vl);
vuint16mf4_t __riscv_viota_m_u16mf4(vbool64_t vs2, size_t vl);
vuint16mf2_t __riscv_viota_m_u16mf2(vbool32_t vs2, size_t vl);
vuint16m1_t __riscv_viota_m_u16m1(vbool16_t vs2, size_t vl);
vuint16m2_t __riscv_viota_m_u16m2(vbool8_t vs2, size_t vl);
vuint16m4_t __riscv_viota_m_u16m4(vbool4_t vs2, size_t vl);
vuint16m8_t __riscv_viota_m_u16m8(vbool2_t vs2, size_t vl);
vuint32mf2_t __riscv_viota_m_u32mf2(vbool64_t vs2, size_t vl);
vuint32m1_t __riscv_viota_m_u32m1(vbool32_t vs2, size_t vl);
vuint32m2_t __riscv_viota_m_u32m2(vbool16_t vs2, size_t vl);
vuint32m4_t __riscv_viota_m_u32m4(vbool8_t vs2, size_t vl);
vuint32m8_t __riscv_viota_m_u32m8(vbool4_t vs2, size_t vl);
vuint64m1_t __riscv_viota_m_u64m1(vbool64_t vs2, size_t vl);
vuint64m2_t __riscv_viota_m_u64m2(vbool32_t vs2, size_t vl);
vuint64m4_t __riscv_viota_m_u64m4(vbool16_t vs2, size_t vl);
vuint64m8_t __riscv_viota_m_u64m8(vbool8_t vs2, size_t vl);
// masked functions
vuint8mf8_t __riscv_viota_m_u8mf8_m(vbool64_t vm, vbool64_t vs2, size_t vl);
vuint8mf4_t __riscv_viota_m_u8mf4_m(vbool32_t vm, vbool32_t vs2, size_t vl);
vuint8mf2_t __riscv_viota_m_u8mf2_m(vbool16_t vm, vbool16_t vs2, size_t vl);
vuint8m1_t __riscv_viota_m_u8m1_m(vbool8_t vm, vbool8_t vs2, size_t vl);
vuint8m2_t __riscv_viota_m_u8m2_m(vbool4_t vm, vbool4_t vs2, size_t vl);
vuint8m4_t __riscv_viota_m_u8m4_m(vbool2_t vm, vbool2_t vs2, size_t vl);
vuint8m8_t __riscv_viota_m_u8m8_m(vbool1_t vm, vbool1_t vs2, size_t vl);
vuint16mf4_t __riscv_viota_m_u16mf4_m(vbool64_t vm, vbool64_t vs2, size_t vl);
vuint16mf2_t __riscv_viota_m_u16mf2_m(vbool32_t vm, vbool32_t vs2, size_t vl);
vuint16m1_t __riscv_viota_m_u16m1_m(vbool16_t vm, vbool16_t vs2, size_t vl);
vuint16m2_t __riscv_viota_m_u16m2_m(vbool8_t vm, vbool8_t vs2, size_t vl);
vuint16m4_t __riscv_viota_m_u16m4_m(vbool4_t vm, vbool4_t vs2, size_t vl);
vuint16m8_t __riscv_viota_m_u16m8_m(vbool2_t vm, vbool2_t vs2, size_t vl);
vuint32mf2_t __riscv_viota_m_u32mf2_m(vbool64_t vm, vbool64_t vs2, size_t vl);
vuint32m1_t __riscv_viota_m_u32m1_m(vbool32_t vm, vbool32_t vs2, size_t vl);
vuint32m2_t __riscv_viota_m_u32m2_m(vbool16_t vm, vbool16_t vs2, size_t vl);
vuint32m4_t __riscv_viota_m_u32m4_m(vbool8_t vm, vbool8_t vs2, size_t vl);
vuint32m8_t __riscv_viota_m_u32m8_m(vbool4_t vm, vbool4_t vs2, size_t vl);
vuint64m1_t __riscv_viota_m_u64m1_m(vbool64_t vm, vbool64_t vs2, size_t vl);
vuint64m2_t __riscv_viota_m_u64m2_m(vbool32_t vm, vbool32_t vs2, size_t vl);
vuint64m4_t __riscv_viota_m_u64m4_m(vbool16_t vm, vbool16_t vs2, size_t vl);
vuint64m8_t __riscv_viota_m_u64m8_m(vbool8_t vm, vbool8_t vs2, size_t vl);
----

[[vector-element-index]]
==== Vector Element Index Intrinsics

[,c]
----
vuint8mf8_t __riscv_vid_v_u8mf8(size_t vl);
vuint8mf4_t __riscv_vid_v_u8mf4(size_t vl);
vuint8mf2_t __riscv_vid_v_u8mf2(size_t vl);
vuint8m1_t __riscv_vid_v_u8m1(size_t vl);
vuint8m2_t __riscv_vid_v_u8m2(size_t vl);
vuint8m4_t __riscv_vid_v_u8m4(size_t vl);
vuint8m8_t __riscv_vid_v_u8m8(size_t vl);
vuint16mf4_t __riscv_vid_v_u16mf4(size_t vl);
vuint16mf2_t __riscv_vid_v_u16mf2(size_t vl);
vuint16m1_t __riscv_vid_v_u16m1(size_t vl);
vuint16m2_t __riscv_vid_v_u16m2(size_t vl);
vuint16m4_t __riscv_vid_v_u16m4(size_t vl);
vuint16m8_t __riscv_vid_v_u16m8(size_t vl);
vuint32mf2_t __riscv_vid_v_u32mf2(size_t vl);
vuint32m1_t __riscv_vid_v_u32m1(size_t vl);
vuint32m2_t __riscv_vid_v_u32m2(size_t vl);
vuint32m4_t __riscv_vid_v_u32m4(size_t vl);
vuint32m8_t __riscv_vid_v_u32m8(size_t vl);
vuint64m1_t __riscv_vid_v_u64m1(size_t vl);
vuint64m2_t __riscv_vid_v_u64m2(size_t vl);
vuint64m4_t __riscv_vid_v_u64m4(size_t vl);
vuint64m8_t __riscv_vid_v_u64m8(size_t vl);
// masked functions
vuint8mf8_t __riscv_vid_v_u8mf8_m(vbool64_t vm, size_t vl);
vuint8mf4_t __riscv_vid_v_u8mf4_m(vbool32_t vm, size_t vl);
vuint8mf2_t __riscv_vid_v_u8mf2_m(vbool16_t vm, size_t vl);
vuint8m1_t __riscv_vid_v_u8m1_m(vbool8_t vm, size_t vl);
vuint8m2_t __riscv_vid_v_u8m2_m(vbool4_t vm, size_t vl);
vuint8m4_t __riscv_vid_v_u8m4_m(vbool2_t vm, size_t vl);
vuint8m8_t __riscv_vid_v_u8m8_m(vbool1_t vm, size_t vl);
vuint16mf4_t __riscv_vid_v_u16mf4_m(vbool64_t vm, size_t vl);
vuint16mf2_t __riscv_vid_v_u16mf2_m(vbool32_t vm, size_t vl);
vuint16m1_t __riscv_vid_v_u16m1_m(vbool16_t vm, size_t vl);
vuint16m2_t __riscv_vid_v_u16m2_m(vbool8_t vm, size_t vl);
vuint16m4_t __riscv_vid_v_u16m4_m(vbool4_t vm, size_t vl);
vuint16m8_t __riscv_vid_v_u16m8_m(vbool2_t vm, size_t vl);
vuint32mf2_t __riscv_vid_v_u32mf2_m(vbool64_t vm, size_t vl);
vuint32m1_t __riscv_vid_v_u32m1_m(vbool32_t vm, size_t vl);
vuint32m2_t __riscv_vid_v_u32m2_m(vbool16_t vm, size_t vl);
vuint32m4_t __riscv_vid_v_u32m4_m(vbool8_t vm, size_t vl);
vuint32m8_t __riscv_vid_v_u32m8_m(vbool4_t vm, size_t vl);
vuint64m1_t __riscv_vid_v_u64m1_m(vbool64_t vm, size_t vl);
vuint64m2_t __riscv_vid_v_u64m2_m(vbool32_t vm, size_t vl);
vuint64m4_t __riscv_vid_v_u64m4_m(vbool16_t vm, size_t vl);
vuint64m8_t __riscv_vid_v_u64m8_m(vbool8_t vm, size_t vl);
----

=== Vector Permutation Intrinsics

[[integer-scalar-move]]
==== Integer and Floating-Point Scalar Move Intrinsics

[,c]
----
_Float16 __riscv_vfmv_f_s_f16mf4_f16(vfloat16mf4_t vs1);
vfloat16mf4_t __riscv_vfmv_s_f_f16mf4(_Float16 rs1, size_t vl);
_Float16 __riscv_vfmv_f_s_f16mf2_f16(vfloat16mf2_t vs1);
vfloat16mf2_t __riscv_vfmv_s_f_f16mf2(_Float16 rs1, size_t vl);
_Float16 __riscv_vfmv_f_s_f16m1_f16(vfloat16m1_t vs1);
vfloat16m1_t __riscv_vfmv_s_f_f16m1(_Float16 rs1, size_t vl);
_Float16 __riscv_vfmv_f_s_f16m2_f16(vfloat16m2_t vs1);
vfloat16m2_t __riscv_vfmv_s_f_f16m2(_Float16 rs1, size_t vl);
_Float16 __riscv_vfmv_f_s_f16m4_f16(vfloat16m4_t vs1);
vfloat16m4_t __riscv_vfmv_s_f_f16m4(_Float16 rs1, size_t vl);
_Float16 __riscv_vfmv_f_s_f16m8_f16(vfloat16m8_t vs1);
vfloat16m8_t __riscv_vfmv_s_f_f16m8(_Float16 rs1, size_t vl);
float __riscv_vfmv_f_s_f32mf2_f32(vfloat32mf2_t vs1);
vfloat32mf2_t __riscv_vfmv_s_f_f32mf2(float rs1, size_t vl);
float __riscv_vfmv_f_s_f32m1_f32(vfloat32m1_t vs1);
vfloat32m1_t __riscv_vfmv_s_f_f32m1(float rs1, size_t vl);
float __riscv_vfmv_f_s_f32m2_f32(vfloat32m2_t vs1);
vfloat32m2_t __riscv_vfmv_s_f_f32m2(float rs1, size_t vl);
float __riscv_vfmv_f_s_f32m4_f32(vfloat32m4_t vs1);
vfloat32m4_t __riscv_vfmv_s_f_f32m4(float rs1, size_t vl);
float __riscv_vfmv_f_s_f32m8_f32(vfloat32m8_t vs1);
vfloat32m8_t __riscv_vfmv_s_f_f32m8(float rs1, size_t vl);
double __riscv_vfmv_f_s_f64m1_f64(vfloat64m1_t vs1);
vfloat64m1_t __riscv_vfmv_s_f_f64m1(double rs1, size_t vl);
double __riscv_vfmv_f_s_f64m2_f64(vfloat64m2_t vs1);
vfloat64m2_t __riscv_vfmv_s_f_f64m2(double rs1, size_t vl);
double __riscv_vfmv_f_s_f64m4_f64(vfloat64m4_t vs1);
vfloat64m4_t __riscv_vfmv_s_f_f64m4(double rs1, size_t vl);
double __riscv_vfmv_f_s_f64m8_f64(vfloat64m8_t vs1);
vfloat64m8_t __riscv_vfmv_s_f_f64m8(double rs1, size_t vl);
int8_t __riscv_vmv_x_s_i8mf8_i8(vint8mf8_t vs1);
vint8mf8_t __riscv_vmv_s_x_i8mf8(int8_t rs1, size_t vl);
int8_t __riscv_vmv_x_s_i8mf4_i8(vint8mf4_t vs1);
vint8mf4_t __riscv_vmv_s_x_i8mf4(int8_t rs1, size_t vl);
int8_t __riscv_vmv_x_s_i8mf2_i8(vint8mf2_t vs1);
vint8mf2_t __riscv_vmv_s_x_i8mf2(int8_t rs1, size_t vl);
int8_t __riscv_vmv_x_s_i8m1_i8(vint8m1_t vs1);
vint8m1_t __riscv_vmv_s_x_i8m1(int8_t rs1, size_t vl);
int8_t __riscv_vmv_x_s_i8m2_i8(vint8m2_t vs1);
vint8m2_t __riscv_vmv_s_x_i8m2(int8_t rs1, size_t vl);
int8_t __riscv_vmv_x_s_i8m4_i8(vint8m4_t vs1);
vint8m4_t __riscv_vmv_s_x_i8m4(int8_t rs1, size_t vl);
int8_t __riscv_vmv_x_s_i8m8_i8(vint8m8_t vs1);
vint8m8_t __riscv_vmv_s_x_i8m8(int8_t rs1, size_t vl);
int16_t __riscv_vmv_x_s_i16mf4_i16(vint16mf4_t vs1);
vint16mf4_t __riscv_vmv_s_x_i16mf4(int16_t rs1, size_t vl);
int16_t __riscv_vmv_x_s_i16mf2_i16(vint16mf2_t vs1);
vint16mf2_t __riscv_vmv_s_x_i16mf2(int16_t rs1, size_t vl);
int16_t __riscv_vmv_x_s_i16m1_i16(vint16m1_t vs1);
vint16m1_t __riscv_vmv_s_x_i16m1(int16_t rs1, size_t vl);
int16_t __riscv_vmv_x_s_i16m2_i16(vint16m2_t vs1);
vint16m2_t __riscv_vmv_s_x_i16m2(int16_t rs1, size_t vl);
int16_t __riscv_vmv_x_s_i16m4_i16(vint16m4_t vs1);
vint16m4_t __riscv_vmv_s_x_i16m4(int16_t rs1, size_t vl);
int16_t __riscv_vmv_x_s_i16m8_i16(vint16m8_t vs1);
vint16m8_t __riscv_vmv_s_x_i16m8(int16_t rs1, size_t vl);
int32_t __riscv_vmv_x_s_i32mf2_i32(vint32mf2_t vs1);
vint32mf2_t __riscv_vmv_s_x_i32mf2(int32_t rs1, size_t vl);
int32_t __riscv_vmv_x_s_i32m1_i32(vint32m1_t vs1);
vint32m1_t __riscv_vmv_s_x_i32m1(int32_t rs1, size_t vl);
int32_t __riscv_vmv_x_s_i32m2_i32(vint32m2_t vs1);
vint32m2_t __riscv_vmv_s_x_i32m2(int32_t rs1, size_t vl);
int32_t __riscv_vmv_x_s_i32m4_i32(vint32m4_t vs1);
vint32m4_t __riscv_vmv_s_x_i32m4(int32_t rs1, size_t vl);
int32_t __riscv_vmv_x_s_i32m8_i32(vint32m8_t vs1);
vint32m8_t __riscv_vmv_s_x_i32m8(int32_t rs1, size_t vl);
int64_t __riscv_vmv_x_s_i64m1_i64(vint64m1_t vs1);
vint64m1_t __riscv_vmv_s_x_i64m1(int64_t rs1, size_t vl);
int64_t __riscv_vmv_x_s_i64m2_i64(vint64m2_t vs1);
vint64m2_t __riscv_vmv_s_x_i64m2(int64_t rs1, size_t vl);
int64_t __riscv_vmv_x_s_i64m4_i64(vint64m4_t vs1);
vint64m4_t __riscv_vmv_s_x_i64m4(int64_t rs1, size_t vl);
int64_t __riscv_vmv_x_s_i64m8_i64(vint64m8_t vs1);
vint64m8_t __riscv_vmv_s_x_i64m8(int64_t rs1, size_t vl);
uint8_t __riscv_vmv_x_s_u8mf8_u8(vuint8mf8_t vs1);
vuint8mf8_t __riscv_vmv_s_x_u8mf8(uint8_t rs1, size_t vl);
uint8_t __riscv_vmv_x_s_u8mf4_u8(vuint8mf4_t vs1);
vuint8mf4_t __riscv_vmv_s_x_u8mf4(uint8_t rs1, size_t vl);
uint8_t __riscv_vmv_x_s_u8mf2_u8(vuint8mf2_t vs1);
vuint8mf2_t __riscv_vmv_s_x_u8mf2(uint8_t rs1, size_t vl);
uint8_t __riscv_vmv_x_s_u8m1_u8(vuint8m1_t vs1);
vuint8m1_t __riscv_vmv_s_x_u8m1(uint8_t rs1, size_t vl);
uint8_t __riscv_vmv_x_s_u8m2_u8(vuint8m2_t vs1);
vuint8m2_t __riscv_vmv_s_x_u8m2(uint8_t rs1, size_t vl);
uint8_t __riscv_vmv_x_s_u8m4_u8(vuint8m4_t vs1);
vuint8m4_t __riscv_vmv_s_x_u8m4(uint8_t rs1, size_t vl);
uint8_t __riscv_vmv_x_s_u8m8_u8(vuint8m8_t vs1);
vuint8m8_t __riscv_vmv_s_x_u8m8(uint8_t rs1, size_t vl);
uint16_t __riscv_vmv_x_s_u16mf4_u16(vuint16mf4_t vs1);
vuint16mf4_t __riscv_vmv_s_x_u16mf4(uint16_t rs1, size_t vl);
uint16_t __riscv_vmv_x_s_u16mf2_u16(vuint16mf2_t vs1);
vuint16mf2_t __riscv_vmv_s_x_u16mf2(uint16_t rs1, size_t vl);
uint16_t __riscv_vmv_x_s_u16m1_u16(vuint16m1_t vs1);
vuint16m1_t __riscv_vmv_s_x_u16m1(uint16_t rs1, size_t vl);
uint16_t __riscv_vmv_x_s_u16m2_u16(vuint16m2_t vs1);
vuint16m2_t __riscv_vmv_s_x_u16m2(uint16_t rs1, size_t vl);
uint16_t __riscv_vmv_x_s_u16m4_u16(vuint16m4_t vs1);
vuint16m4_t __riscv_vmv_s_x_u16m4(uint16_t rs1, size_t vl);
uint16_t __riscv_vmv_x_s_u16m8_u16(vuint16m8_t vs1);
vuint16m8_t __riscv_vmv_s_x_u16m8(uint16_t rs1, size_t vl);
uint32_t __riscv_vmv_x_s_u32mf2_u32(vuint32mf2_t vs1);
vuint32mf2_t __riscv_vmv_s_x_u32mf2(uint32_t rs1, size_t vl);
uint32_t __riscv_vmv_x_s_u32m1_u32(vuint32m1_t vs1);
vuint32m1_t __riscv_vmv_s_x_u32m1(uint32_t rs1, size_t vl);
uint32_t __riscv_vmv_x_s_u32m2_u32(vuint32m2_t vs1);
vuint32m2_t __riscv_vmv_s_x_u32m2(uint32_t rs1, size_t vl);
uint32_t __riscv_vmv_x_s_u32m4_u32(vuint32m4_t vs1);
vuint32m4_t __riscv_vmv_s_x_u32m4(uint32_t rs1, size_t vl);
uint32_t __riscv_vmv_x_s_u32m8_u32(vuint32m8_t vs1);
vuint32m8_t __riscv_vmv_s_x_u32m8(uint32_t rs1, size_t vl);
uint64_t __riscv_vmv_x_s_u64m1_u64(vuint64m1_t vs1);
vuint64m1_t __riscv_vmv_s_x_u64m1(uint64_t rs1, size_t vl);
uint64_t __riscv_vmv_x_s_u64m2_u64(vuint64m2_t vs1);
vuint64m2_t __riscv_vmv_s_x_u64m2(uint64_t rs1, size_t vl);
uint64_t __riscv_vmv_x_s_u64m4_u64(vuint64m4_t vs1);
vuint64m4_t __riscv_vmv_s_x_u64m4(uint64_t rs1, size_t vl);
uint64_t __riscv_vmv_x_s_u64m8_u64(vuint64m8_t vs1);
vuint64m8_t __riscv_vmv_s_x_u64m8(uint64_t rs1, size_t vl);
----

[[vector-slideup]]
==== Vector Slideup Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vslideup_vx_f16mf4(vfloat16mf4_t vd, vfloat16mf4_t vs2,
                                         size_t rs1, size_t vl);
vfloat16mf2_t __riscv_vslideup_vx_f16mf2(vfloat16mf2_t vd, vfloat16mf2_t vs2,
                                         size_t rs1, size_t vl);
vfloat16m1_t __riscv_vslideup_vx_f16m1(vfloat16m1_t vd, vfloat16m1_t vs2,
                                       size_t rs1, size_t vl);
vfloat16m2_t __riscv_vslideup_vx_f16m2(vfloat16m2_t vd, vfloat16m2_t vs2,
                                       size_t rs1, size_t vl);
vfloat16m4_t __riscv_vslideup_vx_f16m4(vfloat16m4_t vd, vfloat16m4_t vs2,
                                       size_t rs1, size_t vl);
vfloat16m8_t __riscv_vslideup_vx_f16m8(vfloat16m8_t vd, vfloat16m8_t vs2,
                                       size_t rs1, size_t vl);
vfloat32mf2_t __riscv_vslideup_vx_f32mf2(vfloat32mf2_t vd, vfloat32mf2_t vs2,
                                         size_t rs1, size_t vl);
vfloat32m1_t __riscv_vslideup_vx_f32m1(vfloat32m1_t vd, vfloat32m1_t vs2,
                                       size_t rs1, size_t vl);
vfloat32m2_t __riscv_vslideup_vx_f32m2(vfloat32m2_t vd, vfloat32m2_t vs2,
                                       size_t rs1, size_t vl);
vfloat32m4_t __riscv_vslideup_vx_f32m4(vfloat32m4_t vd, vfloat32m4_t vs2,
                                       size_t rs1, size_t vl);
vfloat32m8_t __riscv_vslideup_vx_f32m8(vfloat32m8_t vd, vfloat32m8_t vs2,
                                       size_t rs1, size_t vl);
vfloat64m1_t __riscv_vslideup_vx_f64m1(vfloat64m1_t vd, vfloat64m1_t vs2,
                                       size_t rs1, size_t vl);
vfloat64m2_t __riscv_vslideup_vx_f64m2(vfloat64m2_t vd, vfloat64m2_t vs2,
                                       size_t rs1, size_t vl);
vfloat64m4_t __riscv_vslideup_vx_f64m4(vfloat64m4_t vd, vfloat64m4_t vs2,
                                       size_t rs1, size_t vl);
vfloat64m8_t __riscv_vslideup_vx_f64m8(vfloat64m8_t vd, vfloat64m8_t vs2,
                                       size_t rs1, size_t vl);
vint8mf8_t __riscv_vslideup_vx_i8mf8(vint8mf8_t vd, vint8mf8_t vs2, size_t rs1,
                                     size_t vl);
vint8mf4_t __riscv_vslideup_vx_i8mf4(vint8mf4_t vd, vint8mf4_t vs2, size_t rs1,
                                     size_t vl);
vint8mf2_t __riscv_vslideup_vx_i8mf2(vint8mf2_t vd, vint8mf2_t vs2, size_t rs1,
                                     size_t vl);
vint8m1_t __riscv_vslideup_vx_i8m1(vint8m1_t vd, vint8m1_t vs2, size_t rs1,
                                   size_t vl);
vint8m2_t __riscv_vslideup_vx_i8m2(vint8m2_t vd, vint8m2_t vs2, size_t rs1,
                                   size_t vl);
vint8m4_t __riscv_vslideup_vx_i8m4(vint8m4_t vd, vint8m4_t vs2, size_t rs1,
                                   size_t vl);
vint8m8_t __riscv_vslideup_vx_i8m8(vint8m8_t vd, vint8m8_t vs2, size_t rs1,
                                   size_t vl);
vint16mf4_t __riscv_vslideup_vx_i16mf4(vint16mf4_t vd, vint16mf4_t vs2,
                                       size_t rs1, size_t vl);
vint16mf2_t __riscv_vslideup_vx_i16mf2(vint16mf2_t vd, vint16mf2_t vs2,
                                       size_t rs1, size_t vl);
vint16m1_t __riscv_vslideup_vx_i16m1(vint16m1_t vd, vint16m1_t vs2, size_t rs1,
                                     size_t vl);
vint16m2_t __riscv_vslideup_vx_i16m2(vint16m2_t vd, vint16m2_t vs2, size_t rs1,
                                     size_t vl);
vint16m4_t __riscv_vslideup_vx_i16m4(vint16m4_t vd, vint16m4_t vs2, size_t rs1,
                                     size_t vl);
vint16m8_t __riscv_vslideup_vx_i16m8(vint16m8_t vd, vint16m8_t vs2, size_t rs1,
                                     size_t vl);
vint32mf2_t __riscv_vslideup_vx_i32mf2(vint32mf2_t vd, vint32mf2_t vs2,
                                       size_t rs1, size_t vl);
vint32m1_t __riscv_vslideup_vx_i32m1(vint32m1_t vd, vint32m1_t vs2, size_t rs1,
                                     size_t vl);
vint32m2_t __riscv_vslideup_vx_i32m2(vint32m2_t vd, vint32m2_t vs2, size_t rs1,
                                     size_t vl);
vint32m4_t __riscv_vslideup_vx_i32m4(vint32m4_t vd, vint32m4_t vs2, size_t rs1,
                                     size_t vl);
vint32m8_t __riscv_vslideup_vx_i32m8(vint32m8_t vd, vint32m8_t vs2, size_t rs1,
                                     size_t vl);
vint64m1_t __riscv_vslideup_vx_i64m1(vint64m1_t vd, vint64m1_t vs2, size_t rs1,
                                     size_t vl);
vint64m2_t __riscv_vslideup_vx_i64m2(vint64m2_t vd, vint64m2_t vs2, size_t rs1,
                                     size_t vl);
vint64m4_t __riscv_vslideup_vx_i64m4(vint64m4_t vd, vint64m4_t vs2, size_t rs1,
                                     size_t vl);
vint64m8_t __riscv_vslideup_vx_i64m8(vint64m8_t vd, vint64m8_t vs2, size_t rs1,
                                     size_t vl);
vuint8mf8_t __riscv_vslideup_vx_u8mf8(vuint8mf8_t vd, vuint8mf8_t vs2,
                                      size_t rs1, size_t vl);
vuint8mf4_t __riscv_vslideup_vx_u8mf4(vuint8mf4_t vd, vuint8mf4_t vs2,
                                      size_t rs1, size_t vl);
vuint8mf2_t __riscv_vslideup_vx_u8mf2(vuint8mf2_t vd, vuint8mf2_t vs2,
                                      size_t rs1, size_t vl);
vuint8m1_t __riscv_vslideup_vx_u8m1(vuint8m1_t vd, vuint8m1_t vs2, size_t rs1,
                                    size_t vl);
vuint8m2_t __riscv_vslideup_vx_u8m2(vuint8m2_t vd, vuint8m2_t vs2, size_t rs1,
                                    size_t vl);
vuint8m4_t __riscv_vslideup_vx_u8m4(vuint8m4_t vd, vuint8m4_t vs2, size_t rs1,
                                    size_t vl);
vuint8m8_t __riscv_vslideup_vx_u8m8(vuint8m8_t vd, vuint8m8_t vs2, size_t rs1,
                                    size_t vl);
vuint16mf4_t __riscv_vslideup_vx_u16mf4(vuint16mf4_t vd, vuint16mf4_t vs2,
                                        size_t rs1, size_t vl);
vuint16mf2_t __riscv_vslideup_vx_u16mf2(vuint16mf2_t vd, vuint16mf2_t vs2,
                                        size_t rs1, size_t vl);
vuint16m1_t __riscv_vslideup_vx_u16m1(vuint16m1_t vd, vuint16m1_t vs2,
                                      size_t rs1, size_t vl);
vuint16m2_t __riscv_vslideup_vx_u16m2(vuint16m2_t vd, vuint16m2_t vs2,
                                      size_t rs1, size_t vl);
vuint16m4_t __riscv_vslideup_vx_u16m4(vuint16m4_t vd, vuint16m4_t vs2,
                                      size_t rs1, size_t vl);
vuint16m8_t __riscv_vslideup_vx_u16m8(vuint16m8_t vd, vuint16m8_t vs2,
                                      size_t rs1, size_t vl);
vuint32mf2_t __riscv_vslideup_vx_u32mf2(vuint32mf2_t vd, vuint32mf2_t vs2,
                                        size_t rs1, size_t vl);
vuint32m1_t __riscv_vslideup_vx_u32m1(vuint32m1_t vd, vuint32m1_t vs2,
                                      size_t rs1, size_t vl);
vuint32m2_t __riscv_vslideup_vx_u32m2(vuint32m2_t vd, vuint32m2_t vs2,
                                      size_t rs1, size_t vl);
vuint32m4_t __riscv_vslideup_vx_u32m4(vuint32m4_t vd, vuint32m4_t vs2,
                                      size_t rs1, size_t vl);
vuint32m8_t __riscv_vslideup_vx_u32m8(vuint32m8_t vd, vuint32m8_t vs2,
                                      size_t rs1, size_t vl);
vuint64m1_t __riscv_vslideup_vx_u64m1(vuint64m1_t vd, vuint64m1_t vs2,
                                      size_t rs1, size_t vl);
vuint64m2_t __riscv_vslideup_vx_u64m2(vuint64m2_t vd, vuint64m2_t vs2,
                                      size_t rs1, size_t vl);
vuint64m4_t __riscv_vslideup_vx_u64m4(vuint64m4_t vd, vuint64m4_t vs2,
                                      size_t rs1, size_t vl);
vuint64m8_t __riscv_vslideup_vx_u64m8(vuint64m8_t vd, vuint64m8_t vs2,
                                      size_t rs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vslideup_vx_f16mf4_m(vbool64_t vm, vfloat16mf4_t vd,
                                           vfloat16mf4_t vs2, size_t rs1,
                                           size_t vl);
vfloat16mf2_t __riscv_vslideup_vx_f16mf2_m(vbool32_t vm, vfloat16mf2_t vd,
                                           vfloat16mf2_t vs2, size_t rs1,
                                           size_t vl);
vfloat16m1_t __riscv_vslideup_vx_f16m1_m(vbool16_t vm, vfloat16m1_t vd,
                                         vfloat16m1_t vs2, size_t rs1,
                                         size_t vl);
vfloat16m2_t __riscv_vslideup_vx_f16m2_m(vbool8_t vm, vfloat16m2_t vd,
                                         vfloat16m2_t vs2, size_t rs1,
                                         size_t vl);
vfloat16m4_t __riscv_vslideup_vx_f16m4_m(vbool4_t vm, vfloat16m4_t vd,
                                         vfloat16m4_t vs2, size_t rs1,
                                         size_t vl);
vfloat16m8_t __riscv_vslideup_vx_f16m8_m(vbool2_t vm, vfloat16m8_t vd,
                                         vfloat16m8_t vs2, size_t rs1,
                                         size_t vl);
vfloat32mf2_t __riscv_vslideup_vx_f32mf2_m(vbool64_t vm, vfloat32mf2_t vd,
                                           vfloat32mf2_t vs2, size_t rs1,
                                           size_t vl);
vfloat32m1_t __riscv_vslideup_vx_f32m1_m(vbool32_t vm, vfloat32m1_t vd,
                                         vfloat32m1_t vs2, size_t rs1,
                                         size_t vl);
vfloat32m2_t __riscv_vslideup_vx_f32m2_m(vbool16_t vm, vfloat32m2_t vd,
                                         vfloat32m2_t vs2, size_t rs1,
                                         size_t vl);
vfloat32m4_t __riscv_vslideup_vx_f32m4_m(vbool8_t vm, vfloat32m4_t vd,
                                         vfloat32m4_t vs2, size_t rs1,
                                         size_t vl);
vfloat32m8_t __riscv_vslideup_vx_f32m8_m(vbool4_t vm, vfloat32m8_t vd,
                                         vfloat32m8_t vs2, size_t rs1,
                                         size_t vl);
vfloat64m1_t __riscv_vslideup_vx_f64m1_m(vbool64_t vm, vfloat64m1_t vd,
                                         vfloat64m1_t vs2, size_t rs1,
                                         size_t vl);
vfloat64m2_t __riscv_vslideup_vx_f64m2_m(vbool32_t vm, vfloat64m2_t vd,
                                         vfloat64m2_t vs2, size_t rs1,
                                         size_t vl);
vfloat64m4_t __riscv_vslideup_vx_f64m4_m(vbool16_t vm, vfloat64m4_t vd,
                                         vfloat64m4_t vs2, size_t rs1,
                                         size_t vl);
vfloat64m8_t __riscv_vslideup_vx_f64m8_m(vbool8_t vm, vfloat64m8_t vd,
                                         vfloat64m8_t vs2, size_t rs1,
                                         size_t vl);
vint8mf8_t __riscv_vslideup_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vd,
                                       vint8mf8_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vslideup_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vd,
                                       vint8mf4_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vslideup_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vd,
                                       vint8mf2_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vslideup_vx_i8m1_m(vbool8_t vm, vint8m1_t vd, vint8m1_t vs2,
                                     size_t rs1, size_t vl);
vint8m2_t __riscv_vslideup_vx_i8m2_m(vbool4_t vm, vint8m2_t vd, vint8m2_t vs2,
                                     size_t rs1, size_t vl);
vint8m4_t __riscv_vslideup_vx_i8m4_m(vbool2_t vm, vint8m4_t vd, vint8m4_t vs2,
                                     size_t rs1, size_t vl);
vint8m8_t __riscv_vslideup_vx_i8m8_m(vbool1_t vm, vint8m8_t vd, vint8m8_t vs2,
                                     size_t rs1, size_t vl);
vint16mf4_t __riscv_vslideup_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vd,
                                         vint16mf4_t vs2, size_t rs1,
                                         size_t vl);
vint16mf2_t __riscv_vslideup_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vd,
                                         vint16mf2_t vs2, size_t rs1,
                                         size_t vl);
vint16m1_t __riscv_vslideup_vx_i16m1_m(vbool16_t vm, vint16m1_t vd,
                                       vint16m1_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vslideup_vx_i16m2_m(vbool8_t vm, vint16m2_t vd,
                                       vint16m2_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vslideup_vx_i16m4_m(vbool4_t vm, vint16m4_t vd,
                                       vint16m4_t vs2, size_t rs1, size_t vl);
vint16m8_t __riscv_vslideup_vx_i16m8_m(vbool2_t vm, vint16m8_t vd,
                                       vint16m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vslideup_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vd,
                                         vint32mf2_t vs2, size_t rs1,
                                         size_t vl);
vint32m1_t __riscv_vslideup_vx_i32m1_m(vbool32_t vm, vint32m1_t vd,
                                       vint32m1_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vslideup_vx_i32m2_m(vbool16_t vm, vint32m2_t vd,
                                       vint32m2_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vslideup_vx_i32m4_m(vbool8_t vm, vint32m4_t vd,
                                       vint32m4_t vs2, size_t rs1, size_t vl);
vint32m8_t __riscv_vslideup_vx_i32m8_m(vbool4_t vm, vint32m8_t vd,
                                       vint32m8_t vs2, size_t rs1, size_t vl);
vint64m1_t __riscv_vslideup_vx_i64m1_m(vbool64_t vm, vint64m1_t vd,
                                       vint64m1_t vs2, size_t rs1, size_t vl);
vint64m2_t __riscv_vslideup_vx_i64m2_m(vbool32_t vm, vint64m2_t vd,
                                       vint64m2_t vs2, size_t rs1, size_t vl);
vint64m4_t __riscv_vslideup_vx_i64m4_m(vbool16_t vm, vint64m4_t vd,
                                       vint64m4_t vs2, size_t rs1, size_t vl);
vint64m8_t __riscv_vslideup_vx_i64m8_m(vbool8_t vm, vint64m8_t vd,
                                       vint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vslideup_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vd,
                                        vuint8mf8_t vs2, size_t rs1, size_t vl);
vuint8mf4_t __riscv_vslideup_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vd,
                                        vuint8mf4_t vs2, size_t rs1, size_t vl);
vuint8mf2_t __riscv_vslideup_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vd,
                                        vuint8mf2_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vslideup_vx_u8m1_m(vbool8_t vm, vuint8m1_t vd,
                                      vuint8m1_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vslideup_vx_u8m2_m(vbool4_t vm, vuint8m2_t vd,
                                      vuint8m2_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vslideup_vx_u8m4_m(vbool2_t vm, vuint8m4_t vd,
                                      vuint8m4_t vs2, size_t rs1, size_t vl);
vuint8m8_t __riscv_vslideup_vx_u8m8_m(vbool1_t vm, vuint8m8_t vd,
                                      vuint8m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vslideup_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vd,
                                          vuint16mf4_t vs2, size_t rs1,
                                          size_t vl);
vuint16mf2_t __riscv_vslideup_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vd,
                                          vuint16mf2_t vs2, size_t rs1,
                                          size_t vl);
vuint16m1_t __riscv_vslideup_vx_u16m1_m(vbool16_t vm, vuint16m1_t vd,
                                        vuint16m1_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vslideup_vx_u16m2_m(vbool8_t vm, vuint16m2_t vd,
                                        vuint16m2_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vslideup_vx_u16m4_m(vbool4_t vm, vuint16m4_t vd,
                                        vuint16m4_t vs2, size_t rs1, size_t vl);
vuint16m8_t __riscv_vslideup_vx_u16m8_m(vbool2_t vm, vuint16m8_t vd,
                                        vuint16m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vslideup_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vd,
                                          vuint32mf2_t vs2, size_t rs1,
                                          size_t vl);
vuint32m1_t __riscv_vslideup_vx_u32m1_m(vbool32_t vm, vuint32m1_t vd,
                                        vuint32m1_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vslideup_vx_u32m2_m(vbool16_t vm, vuint32m2_t vd,
                                        vuint32m2_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vslideup_vx_u32m4_m(vbool8_t vm, vuint32m4_t vd,
                                        vuint32m4_t vs2, size_t rs1, size_t vl);
vuint32m8_t __riscv_vslideup_vx_u32m8_m(vbool4_t vm, vuint32m8_t vd,
                                        vuint32m8_t vs2, size_t rs1, size_t vl);
vuint64m1_t __riscv_vslideup_vx_u64m1_m(vbool64_t vm, vuint64m1_t vd,
                                        vuint64m1_t vs2, size_t rs1, size_t vl);
vuint64m2_t __riscv_vslideup_vx_u64m2_m(vbool32_t vm, vuint64m2_t vd,
                                        vuint64m2_t vs2, size_t rs1, size_t vl);
vuint64m4_t __riscv_vslideup_vx_u64m4_m(vbool16_t vm, vuint64m4_t vd,
                                        vuint64m4_t vs2, size_t rs1, size_t vl);
vuint64m8_t __riscv_vslideup_vx_u64m8_m(vbool8_t vm, vuint64m8_t vd,
                                        vuint64m8_t vs2, size_t rs1, size_t vl);
----

[[vector-slidedown]]
==== Vector Slidedown Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vslidedown_vx_f16mf4(vfloat16mf4_t vs2, size_t rs1,
                                           size_t vl);
vfloat16mf2_t __riscv_vslidedown_vx_f16mf2(vfloat16mf2_t vs2, size_t rs1,
                                           size_t vl);
vfloat16m1_t __riscv_vslidedown_vx_f16m1(vfloat16m1_t vs2, size_t rs1,
                                         size_t vl);
vfloat16m2_t __riscv_vslidedown_vx_f16m2(vfloat16m2_t vs2, size_t rs1,
                                         size_t vl);
vfloat16m4_t __riscv_vslidedown_vx_f16m4(vfloat16m4_t vs2, size_t rs1,
                                         size_t vl);
vfloat16m8_t __riscv_vslidedown_vx_f16m8(vfloat16m8_t vs2, size_t rs1,
                                         size_t vl);
vfloat32mf2_t __riscv_vslidedown_vx_f32mf2(vfloat32mf2_t vs2, size_t rs1,
                                           size_t vl);
vfloat32m1_t __riscv_vslidedown_vx_f32m1(vfloat32m1_t vs2, size_t rs1,
                                         size_t vl);
vfloat32m2_t __riscv_vslidedown_vx_f32m2(vfloat32m2_t vs2, size_t rs1,
                                         size_t vl);
vfloat32m4_t __riscv_vslidedown_vx_f32m4(vfloat32m4_t vs2, size_t rs1,
                                         size_t vl);
vfloat32m8_t __riscv_vslidedown_vx_f32m8(vfloat32m8_t vs2, size_t rs1,
                                         size_t vl);
vfloat64m1_t __riscv_vslidedown_vx_f64m1(vfloat64m1_t vs2, size_t rs1,
                                         size_t vl);
vfloat64m2_t __riscv_vslidedown_vx_f64m2(vfloat64m2_t vs2, size_t rs1,
                                         size_t vl);
vfloat64m4_t __riscv_vslidedown_vx_f64m4(vfloat64m4_t vs2, size_t rs1,
                                         size_t vl);
vfloat64m8_t __riscv_vslidedown_vx_f64m8(vfloat64m8_t vs2, size_t rs1,
                                         size_t vl);
vint8mf8_t __riscv_vslidedown_vx_i8mf8(vint8mf8_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vslidedown_vx_i8mf4(vint8mf4_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vslidedown_vx_i8mf2(vint8mf2_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vslidedown_vx_i8m1(vint8m1_t vs2, size_t rs1, size_t vl);
vint8m2_t __riscv_vslidedown_vx_i8m2(vint8m2_t vs2, size_t rs1, size_t vl);
vint8m4_t __riscv_vslidedown_vx_i8m4(vint8m4_t vs2, size_t rs1, size_t vl);
vint8m8_t __riscv_vslidedown_vx_i8m8(vint8m8_t vs2, size_t rs1, size_t vl);
vint16mf4_t __riscv_vslidedown_vx_i16mf4(vint16mf4_t vs2, size_t rs1,
                                         size_t vl);
vint16mf2_t __riscv_vslidedown_vx_i16mf2(vint16mf2_t vs2, size_t rs1,
                                         size_t vl);
vint16m1_t __riscv_vslidedown_vx_i16m1(vint16m1_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vslidedown_vx_i16m2(vint16m2_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vslidedown_vx_i16m4(vint16m4_t vs2, size_t rs1, size_t vl);
vint16m8_t __riscv_vslidedown_vx_i16m8(vint16m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vslidedown_vx_i32mf2(vint32mf2_t vs2, size_t rs1,
                                         size_t vl);
vint32m1_t __riscv_vslidedown_vx_i32m1(vint32m1_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vslidedown_vx_i32m2(vint32m2_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vslidedown_vx_i32m4(vint32m4_t vs2, size_t rs1, size_t vl);
vint32m8_t __riscv_vslidedown_vx_i32m8(vint32m8_t vs2, size_t rs1, size_t vl);
vint64m1_t __riscv_vslidedown_vx_i64m1(vint64m1_t vs2, size_t rs1, size_t vl);
vint64m2_t __riscv_vslidedown_vx_i64m2(vint64m2_t vs2, size_t rs1, size_t vl);
vint64m4_t __riscv_vslidedown_vx_i64m4(vint64m4_t vs2, size_t rs1, size_t vl);
vint64m8_t __riscv_vslidedown_vx_i64m8(vint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vslidedown_vx_u8mf8(vuint8mf8_t vs2, size_t rs1, size_t vl);
vuint8mf4_t __riscv_vslidedown_vx_u8mf4(vuint8mf4_t vs2, size_t rs1, size_t vl);
vuint8mf2_t __riscv_vslidedown_vx_u8mf2(vuint8mf2_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vslidedown_vx_u8m1(vuint8m1_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vslidedown_vx_u8m2(vuint8m2_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vslidedown_vx_u8m4(vuint8m4_t vs2, size_t rs1, size_t vl);
vuint8m8_t __riscv_vslidedown_vx_u8m8(vuint8m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vslidedown_vx_u16mf4(vuint16mf4_t vs2, size_t rs1,
                                          size_t vl);
vuint16mf2_t __riscv_vslidedown_vx_u16mf2(vuint16mf2_t vs2, size_t rs1,
                                          size_t vl);
vuint16m1_t __riscv_vslidedown_vx_u16m1(vuint16m1_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vslidedown_vx_u16m2(vuint16m2_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vslidedown_vx_u16m4(vuint16m4_t vs2, size_t rs1, size_t vl);
vuint16m8_t __riscv_vslidedown_vx_u16m8(vuint16m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vslidedown_vx_u32mf2(vuint32mf2_t vs2, size_t rs1,
                                          size_t vl);
vuint32m1_t __riscv_vslidedown_vx_u32m1(vuint32m1_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vslidedown_vx_u32m2(vuint32m2_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vslidedown_vx_u32m4(vuint32m4_t vs2, size_t rs1, size_t vl);
vuint32m8_t __riscv_vslidedown_vx_u32m8(vuint32m8_t vs2, size_t rs1, size_t vl);
vuint64m1_t __riscv_vslidedown_vx_u64m1(vuint64m1_t vs2, size_t rs1, size_t vl);
vuint64m2_t __riscv_vslidedown_vx_u64m2(vuint64m2_t vs2, size_t rs1, size_t vl);
vuint64m4_t __riscv_vslidedown_vx_u64m4(vuint64m4_t vs2, size_t rs1, size_t vl);
vuint64m8_t __riscv_vslidedown_vx_u64m8(vuint64m8_t vs2, size_t rs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vslidedown_vx_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                             size_t rs1, size_t vl);
vfloat16mf2_t __riscv_vslidedown_vx_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                             size_t rs1, size_t vl);
vfloat16m1_t __riscv_vslidedown_vx_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                           size_t rs1, size_t vl);
vfloat16m2_t __riscv_vslidedown_vx_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                           size_t rs1, size_t vl);
vfloat16m4_t __riscv_vslidedown_vx_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                           size_t rs1, size_t vl);
vfloat16m8_t __riscv_vslidedown_vx_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                           size_t rs1, size_t vl);
vfloat32mf2_t __riscv_vslidedown_vx_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                             size_t rs1, size_t vl);
vfloat32m1_t __riscv_vslidedown_vx_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                           size_t rs1, size_t vl);
vfloat32m2_t __riscv_vslidedown_vx_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                           size_t rs1, size_t vl);
vfloat32m4_t __riscv_vslidedown_vx_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                           size_t rs1, size_t vl);
vfloat32m8_t __riscv_vslidedown_vx_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                           size_t rs1, size_t vl);
vfloat64m1_t __riscv_vslidedown_vx_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                           size_t rs1, size_t vl);
vfloat64m2_t __riscv_vslidedown_vx_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                           size_t rs1, size_t vl);
vfloat64m4_t __riscv_vslidedown_vx_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                           size_t rs1, size_t vl);
vfloat64m8_t __riscv_vslidedown_vx_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                           size_t rs1, size_t vl);
vint8mf8_t __riscv_vslidedown_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                         size_t rs1, size_t vl);
vint8mf4_t __riscv_vslidedown_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                         size_t rs1, size_t vl);
vint8mf2_t __riscv_vslidedown_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                         size_t rs1, size_t vl);
vint8m1_t __riscv_vslidedown_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, size_t rs1,
                                       size_t vl);
vint8m2_t __riscv_vslidedown_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, size_t rs1,
                                       size_t vl);
vint8m4_t __riscv_vslidedown_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, size_t rs1,
                                       size_t vl);
vint8m8_t __riscv_vslidedown_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, size_t rs1,
                                       size_t vl);
vint16mf4_t __riscv_vslidedown_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                           size_t rs1, size_t vl);
vint16mf2_t __riscv_vslidedown_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                           size_t rs1, size_t vl);
vint16m1_t __riscv_vslidedown_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                         size_t rs1, size_t vl);
vint16m2_t __riscv_vslidedown_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2,
                                         size_t rs1, size_t vl);
vint16m4_t __riscv_vslidedown_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2,
                                         size_t rs1, size_t vl);
vint16m8_t __riscv_vslidedown_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2,
                                         size_t rs1, size_t vl);
vint32mf2_t __riscv_vslidedown_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                           size_t rs1, size_t vl);
vint32m1_t __riscv_vslidedown_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                         size_t rs1, size_t vl);
vint32m2_t __riscv_vslidedown_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                         size_t rs1, size_t vl);
vint32m4_t __riscv_vslidedown_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2,
                                         size_t rs1, size_t vl);
vint32m8_t __riscv_vslidedown_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2,
                                         size_t rs1, size_t vl);
vint64m1_t __riscv_vslidedown_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                         size_t rs1, size_t vl);
vint64m2_t __riscv_vslidedown_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                         size_t rs1, size_t vl);
vint64m4_t __riscv_vslidedown_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                         size_t rs1, size_t vl);
vint64m8_t __riscv_vslidedown_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2,
                                         size_t rs1, size_t vl);
vuint8mf8_t __riscv_vslidedown_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                          size_t rs1, size_t vl);
vuint8mf4_t __riscv_vslidedown_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                          size_t rs1, size_t vl);
vuint8mf2_t __riscv_vslidedown_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                          size_t rs1, size_t vl);
vuint8m1_t __riscv_vslidedown_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, size_t rs1,
                                        size_t vl);
vuint8m2_t __riscv_vslidedown_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, size_t rs1,
                                        size_t vl);
vuint8m4_t __riscv_vslidedown_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, size_t rs1,
                                        size_t vl);
vuint8m8_t __riscv_vslidedown_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, size_t rs1,
                                        size_t vl);
vuint16mf4_t __riscv_vslidedown_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                            size_t rs1, size_t vl);
vuint16mf2_t __riscv_vslidedown_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                            size_t rs1, size_t vl);
vuint16m1_t __riscv_vslidedown_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                          size_t rs1, size_t vl);
vuint16m2_t __riscv_vslidedown_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                          size_t rs1, size_t vl);
vuint16m4_t __riscv_vslidedown_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                          size_t rs1, size_t vl);
vuint16m8_t __riscv_vslidedown_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                          size_t rs1, size_t vl);
vuint32mf2_t __riscv_vslidedown_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                            size_t rs1, size_t vl);
vuint32m1_t __riscv_vslidedown_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                          size_t rs1, size_t vl);
vuint32m2_t __riscv_vslidedown_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                          size_t rs1, size_t vl);
vuint32m4_t __riscv_vslidedown_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                          size_t rs1, size_t vl);
vuint32m8_t __riscv_vslidedown_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                          size_t rs1, size_t vl);
vuint64m1_t __riscv_vslidedown_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                          size_t rs1, size_t vl);
vuint64m2_t __riscv_vslidedown_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                          size_t rs1, size_t vl);
vuint64m4_t __riscv_vslidedown_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                          size_t rs1, size_t vl);
vuint64m8_t __riscv_vslidedown_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                          size_t rs1, size_t vl);
----

[[vector-slide1up-and-slide1down]]
==== Vector Slide1up and Slide1down Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfslide1up_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                           size_t vl);
vfloat16mf2_t __riscv_vfslide1up_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                           size_t vl);
vfloat16m1_t __riscv_vfslide1up_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1,
                                         size_t vl);
vfloat16m2_t __riscv_vfslide1up_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1,
                                         size_t vl);
vfloat16m4_t __riscv_vfslide1up_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1,
                                         size_t vl);
vfloat16m8_t __riscv_vfslide1up_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1,
                                         size_t vl);
vfloat32mf2_t __riscv_vfslide1up_vf_f32mf2(vfloat32mf2_t vs2, float rs1,
                                           size_t vl);
vfloat32m1_t __riscv_vfslide1up_vf_f32m1(vfloat32m1_t vs2, float rs1,
                                         size_t vl);
vfloat32m2_t __riscv_vfslide1up_vf_f32m2(vfloat32m2_t vs2, float rs1,
                                         size_t vl);
vfloat32m4_t __riscv_vfslide1up_vf_f32m4(vfloat32m4_t vs2, float rs1,
                                         size_t vl);
vfloat32m8_t __riscv_vfslide1up_vf_f32m8(vfloat32m8_t vs2, float rs1,
                                         size_t vl);
vfloat64m1_t __riscv_vfslide1up_vf_f64m1(vfloat64m1_t vs2, double rs1,
                                         size_t vl);
vfloat64m2_t __riscv_vfslide1up_vf_f64m2(vfloat64m2_t vs2, double rs1,
                                         size_t vl);
vfloat64m4_t __riscv_vfslide1up_vf_f64m4(vfloat64m4_t vs2, double rs1,
                                         size_t vl);
vfloat64m8_t __riscv_vfslide1up_vf_f64m8(vfloat64m8_t vs2, double rs1,
                                         size_t vl);
vfloat16mf4_t __riscv_vfslide1down_vf_f16mf4(vfloat16mf4_t vs2, _Float16 rs1,
                                             size_t vl);
vfloat16mf2_t __riscv_vfslide1down_vf_f16mf2(vfloat16mf2_t vs2, _Float16 rs1,
                                             size_t vl);
vfloat16m1_t __riscv_vfslide1down_vf_f16m1(vfloat16m1_t vs2, _Float16 rs1,
                                           size_t vl);
vfloat16m2_t __riscv_vfslide1down_vf_f16m2(vfloat16m2_t vs2, _Float16 rs1,
                                           size_t vl);
vfloat16m4_t __riscv_vfslide1down_vf_f16m4(vfloat16m4_t vs2, _Float16 rs1,
                                           size_t vl);
vfloat16m8_t __riscv_vfslide1down_vf_f16m8(vfloat16m8_t vs2, _Float16 rs1,
                                           size_t vl);
vfloat32mf2_t __riscv_vfslide1down_vf_f32mf2(vfloat32mf2_t vs2, float rs1,
                                             size_t vl);
vfloat32m1_t __riscv_vfslide1down_vf_f32m1(vfloat32m1_t vs2, float rs1,
                                           size_t vl);
vfloat32m2_t __riscv_vfslide1down_vf_f32m2(vfloat32m2_t vs2, float rs1,
                                           size_t vl);
vfloat32m4_t __riscv_vfslide1down_vf_f32m4(vfloat32m4_t vs2, float rs1,
                                           size_t vl);
vfloat32m8_t __riscv_vfslide1down_vf_f32m8(vfloat32m8_t vs2, float rs1,
                                           size_t vl);
vfloat64m1_t __riscv_vfslide1down_vf_f64m1(vfloat64m1_t vs2, double rs1,
                                           size_t vl);
vfloat64m2_t __riscv_vfslide1down_vf_f64m2(vfloat64m2_t vs2, double rs1,
                                           size_t vl);
vfloat64m4_t __riscv_vfslide1down_vf_f64m4(vfloat64m4_t vs2, double rs1,
                                           size_t vl);
vfloat64m8_t __riscv_vfslide1down_vf_f64m8(vfloat64m8_t vs2, double rs1,
                                           size_t vl);
vint8mf8_t __riscv_vslide1up_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vslide1up_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vslide1up_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vslide1up_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vslide1up_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vslide1up_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vslide1up_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vslide1up_vx_i16mf4(vint16mf4_t vs2, int16_t rs1,
                                        size_t vl);
vint16mf2_t __riscv_vslide1up_vx_i16mf2(vint16mf2_t vs2, int16_t rs1,
                                        size_t vl);
vint16m1_t __riscv_vslide1up_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vslide1up_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vslide1up_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vslide1up_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vslide1up_vx_i32mf2(vint32mf2_t vs2, int32_t rs1,
                                        size_t vl);
vint32m1_t __riscv_vslide1up_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vslide1up_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vslide1up_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vslide1up_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vslide1up_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vslide1up_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vslide1up_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vslide1up_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vslide1down_vx_i8mf8(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vslide1down_vx_i8mf4(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vslide1down_vx_i8mf2(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vslide1down_vx_i8m1(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vslide1down_vx_i8m2(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vslide1down_vx_i8m4(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vslide1down_vx_i8m8(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vslide1down_vx_i16mf4(vint16mf4_t vs2, int16_t rs1,
                                          size_t vl);
vint16mf2_t __riscv_vslide1down_vx_i16mf2(vint16mf2_t vs2, int16_t rs1,
                                          size_t vl);
vint16m1_t __riscv_vslide1down_vx_i16m1(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vslide1down_vx_i16m2(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vslide1down_vx_i16m4(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vslide1down_vx_i16m8(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vslide1down_vx_i32mf2(vint32mf2_t vs2, int32_t rs1,
                                          size_t vl);
vint32m1_t __riscv_vslide1down_vx_i32m1(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vslide1down_vx_i32m2(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vslide1down_vx_i32m4(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vslide1down_vx_i32m8(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vslide1down_vx_i64m1(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vslide1down_vx_i64m2(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vslide1down_vx_i64m4(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vslide1down_vx_i64m8(vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vslide1up_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vslide1up_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vslide1up_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vslide1up_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vslide1up_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vslide1up_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vslide1up_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vslide1up_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1,
                                         size_t vl);
vuint16mf2_t __riscv_vslide1up_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1,
                                         size_t vl);
vuint16m1_t __riscv_vslide1up_vx_u16m1(vuint16m1_t vs2, uint16_t rs1,
                                       size_t vl);
vuint16m2_t __riscv_vslide1up_vx_u16m2(vuint16m2_t vs2, uint16_t rs1,
                                       size_t vl);
vuint16m4_t __riscv_vslide1up_vx_u16m4(vuint16m4_t vs2, uint16_t rs1,
                                       size_t vl);
vuint16m8_t __riscv_vslide1up_vx_u16m8(vuint16m8_t vs2, uint16_t rs1,
                                       size_t vl);
vuint32mf2_t __riscv_vslide1up_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1,
                                         size_t vl);
vuint32m1_t __riscv_vslide1up_vx_u32m1(vuint32m1_t vs2, uint32_t rs1,
                                       size_t vl);
vuint32m2_t __riscv_vslide1up_vx_u32m2(vuint32m2_t vs2, uint32_t rs1,
                                       size_t vl);
vuint32m4_t __riscv_vslide1up_vx_u32m4(vuint32m4_t vs2, uint32_t rs1,
                                       size_t vl);
vuint32m8_t __riscv_vslide1up_vx_u32m8(vuint32m8_t vs2, uint32_t rs1,
                                       size_t vl);
vuint64m1_t __riscv_vslide1up_vx_u64m1(vuint64m1_t vs2, uint64_t rs1,
                                       size_t vl);
vuint64m2_t __riscv_vslide1up_vx_u64m2(vuint64m2_t vs2, uint64_t rs1,
                                       size_t vl);
vuint64m4_t __riscv_vslide1up_vx_u64m4(vuint64m4_t vs2, uint64_t rs1,
                                       size_t vl);
vuint64m8_t __riscv_vslide1up_vx_u64m8(vuint64m8_t vs2, uint64_t rs1,
                                       size_t vl);
vuint8mf8_t __riscv_vslide1down_vx_u8mf8(vuint8mf8_t vs2, uint8_t rs1,
                                         size_t vl);
vuint8mf4_t __riscv_vslide1down_vx_u8mf4(vuint8mf4_t vs2, uint8_t rs1,
                                         size_t vl);
vuint8mf2_t __riscv_vslide1down_vx_u8mf2(vuint8mf2_t vs2, uint8_t rs1,
                                         size_t vl);
vuint8m1_t __riscv_vslide1down_vx_u8m1(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vslide1down_vx_u8m2(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vslide1down_vx_u8m4(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vslide1down_vx_u8m8(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vslide1down_vx_u16mf4(vuint16mf4_t vs2, uint16_t rs1,
                                           size_t vl);
vuint16mf2_t __riscv_vslide1down_vx_u16mf2(vuint16mf2_t vs2, uint16_t rs1,
                                           size_t vl);
vuint16m1_t __riscv_vslide1down_vx_u16m1(vuint16m1_t vs2, uint16_t rs1,
                                         size_t vl);
vuint16m2_t __riscv_vslide1down_vx_u16m2(vuint16m2_t vs2, uint16_t rs1,
                                         size_t vl);
vuint16m4_t __riscv_vslide1down_vx_u16m4(vuint16m4_t vs2, uint16_t rs1,
                                         size_t vl);
vuint16m8_t __riscv_vslide1down_vx_u16m8(vuint16m8_t vs2, uint16_t rs1,
                                         size_t vl);
vuint32mf2_t __riscv_vslide1down_vx_u32mf2(vuint32mf2_t vs2, uint32_t rs1,
                                           size_t vl);
vuint32m1_t __riscv_vslide1down_vx_u32m1(vuint32m1_t vs2, uint32_t rs1,
                                         size_t vl);
vuint32m2_t __riscv_vslide1down_vx_u32m2(vuint32m2_t vs2, uint32_t rs1,
                                         size_t vl);
vuint32m4_t __riscv_vslide1down_vx_u32m4(vuint32m4_t vs2, uint32_t rs1,
                                         size_t vl);
vuint32m8_t __riscv_vslide1down_vx_u32m8(vuint32m8_t vs2, uint32_t rs1,
                                         size_t vl);
vuint64m1_t __riscv_vslide1down_vx_u64m1(vuint64m1_t vs2, uint64_t rs1,
                                         size_t vl);
vuint64m2_t __riscv_vslide1down_vx_u64m2(vuint64m2_t vs2, uint64_t rs1,
                                         size_t vl);
vuint64m4_t __riscv_vslide1down_vx_u64m4(vuint64m4_t vs2, uint64_t rs1,
                                         size_t vl);
vuint64m8_t __riscv_vslide1down_vx_u64m8(vuint64m8_t vs2, uint64_t rs1,
                                         size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfslide1up_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                             _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfslide1up_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                             _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfslide1up_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                           _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfslide1up_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                           _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfslide1up_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                           _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfslide1up_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                           _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfslide1up_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                             float rs1, size_t vl);
vfloat32m1_t __riscv_vfslide1up_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                           float rs1, size_t vl);
vfloat32m2_t __riscv_vfslide1up_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                           float rs1, size_t vl);
vfloat32m4_t __riscv_vfslide1up_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                           float rs1, size_t vl);
vfloat32m8_t __riscv_vfslide1up_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                           float rs1, size_t vl);
vfloat64m1_t __riscv_vfslide1up_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                           double rs1, size_t vl);
vfloat64m2_t __riscv_vfslide1up_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                           double rs1, size_t vl);
vfloat64m4_t __riscv_vfslide1up_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                           double rs1, size_t vl);
vfloat64m8_t __riscv_vfslide1up_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                           double rs1, size_t vl);
vfloat16mf4_t __riscv_vfslide1down_vf_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                               _Float16 rs1, size_t vl);
vfloat16mf2_t __riscv_vfslide1down_vf_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                               _Float16 rs1, size_t vl);
vfloat16m1_t __riscv_vfslide1down_vf_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                             _Float16 rs1, size_t vl);
vfloat16m2_t __riscv_vfslide1down_vf_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                             _Float16 rs1, size_t vl);
vfloat16m4_t __riscv_vfslide1down_vf_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                             _Float16 rs1, size_t vl);
vfloat16m8_t __riscv_vfslide1down_vf_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                             _Float16 rs1, size_t vl);
vfloat32mf2_t __riscv_vfslide1down_vf_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                               float rs1, size_t vl);
vfloat32m1_t __riscv_vfslide1down_vf_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                             float rs1, size_t vl);
vfloat32m2_t __riscv_vfslide1down_vf_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                             float rs1, size_t vl);
vfloat32m4_t __riscv_vfslide1down_vf_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                             float rs1, size_t vl);
vfloat32m8_t __riscv_vfslide1down_vf_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                             float rs1, size_t vl);
vfloat64m1_t __riscv_vfslide1down_vf_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                             double rs1, size_t vl);
vfloat64m2_t __riscv_vfslide1down_vf_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                             double rs1, size_t vl);
vfloat64m4_t __riscv_vfslide1down_vf_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                             double rs1, size_t vl);
vfloat64m8_t __riscv_vfslide1down_vf_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                             double rs1, size_t vl);
vint8mf8_t __riscv_vslide1up_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                        int8_t rs1, size_t vl);
vint8mf4_t __riscv_vslide1up_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                        int8_t rs1, size_t vl);
vint8mf2_t __riscv_vslide1up_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                        int8_t rs1, size_t vl);
vint8m1_t __riscv_vslide1up_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                      size_t vl);
vint8m2_t __riscv_vslide1up_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                      size_t vl);
vint8m4_t __riscv_vslide1up_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                      size_t vl);
vint8m8_t __riscv_vslide1up_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                      size_t vl);
vint16mf4_t __riscv_vslide1up_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                          int16_t rs1, size_t vl);
vint16mf2_t __riscv_vslide1up_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                          int16_t rs1, size_t vl);
vint16m1_t __riscv_vslide1up_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                        int16_t rs1, size_t vl);
vint16m2_t __riscv_vslide1up_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2,
                                        int16_t rs1, size_t vl);
vint16m4_t __riscv_vslide1up_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2,
                                        int16_t rs1, size_t vl);
vint16m8_t __riscv_vslide1up_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2,
                                        int16_t rs1, size_t vl);
vint32mf2_t __riscv_vslide1up_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                          int32_t rs1, size_t vl);
vint32m1_t __riscv_vslide1up_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                        int32_t rs1, size_t vl);
vint32m2_t __riscv_vslide1up_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                        int32_t rs1, size_t vl);
vint32m4_t __riscv_vslide1up_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2,
                                        int32_t rs1, size_t vl);
vint32m8_t __riscv_vslide1up_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2,
                                        int32_t rs1, size_t vl);
vint64m1_t __riscv_vslide1up_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                        int64_t rs1, size_t vl);
vint64m2_t __riscv_vslide1up_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                        int64_t rs1, size_t vl);
vint64m4_t __riscv_vslide1up_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                        int64_t rs1, size_t vl);
vint64m8_t __riscv_vslide1up_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2,
                                        int64_t rs1, size_t vl);
vint8mf8_t __riscv_vslide1down_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                          int8_t rs1, size_t vl);
vint8mf4_t __riscv_vslide1down_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                          int8_t rs1, size_t vl);
vint8mf2_t __riscv_vslide1down_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                          int8_t rs1, size_t vl);
vint8m1_t __riscv_vslide1down_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, int8_t rs1,
                                        size_t vl);
vint8m2_t __riscv_vslide1down_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, int8_t rs1,
                                        size_t vl);
vint8m4_t __riscv_vslide1down_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, int8_t rs1,
                                        size_t vl);
vint8m8_t __riscv_vslide1down_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, int8_t rs1,
                                        size_t vl);
vint16mf4_t __riscv_vslide1down_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                            int16_t rs1, size_t vl);
vint16mf2_t __riscv_vslide1down_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                            int16_t rs1, size_t vl);
vint16m1_t __riscv_vslide1down_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                          int16_t rs1, size_t vl);
vint16m2_t __riscv_vslide1down_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2,
                                          int16_t rs1, size_t vl);
vint16m4_t __riscv_vslide1down_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2,
                                          int16_t rs1, size_t vl);
vint16m8_t __riscv_vslide1down_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2,
                                          int16_t rs1, size_t vl);
vint32mf2_t __riscv_vslide1down_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                            int32_t rs1, size_t vl);
vint32m1_t __riscv_vslide1down_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                          int32_t rs1, size_t vl);
vint32m2_t __riscv_vslide1down_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                          int32_t rs1, size_t vl);
vint32m4_t __riscv_vslide1down_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2,
                                          int32_t rs1, size_t vl);
vint32m8_t __riscv_vslide1down_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2,
                                          int32_t rs1, size_t vl);
vint64m1_t __riscv_vslide1down_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                          int64_t rs1, size_t vl);
vint64m2_t __riscv_vslide1down_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                          int64_t rs1, size_t vl);
vint64m4_t __riscv_vslide1down_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                          int64_t rs1, size_t vl);
vint64m8_t __riscv_vslide1down_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2,
                                          int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vslide1up_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                         uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vslide1up_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                         uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vslide1up_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                         uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vslide1up_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                                       size_t vl);
vuint8m2_t __riscv_vslide1up_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                                       size_t vl);
vuint8m4_t __riscv_vslide1up_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                                       size_t vl);
vuint8m8_t __riscv_vslide1up_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1,
                                       size_t vl);
vuint16mf4_t __riscv_vslide1up_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                           uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vslide1up_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                           uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vslide1up_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                         uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vslide1up_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                         uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vslide1up_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                         uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vslide1up_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                         uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vslide1up_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                           uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vslide1up_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                         uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vslide1up_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                         uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vslide1up_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                         uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vslide1up_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                         uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vslide1up_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                         uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vslide1up_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                         uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vslide1up_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                         uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vslide1up_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                         uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vslide1down_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                           uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vslide1down_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                           uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vslide1down_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                           uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vslide1down_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2,
                                         uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vslide1down_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2,
                                         uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vslide1down_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2,
                                         uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vslide1down_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2,
                                         uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vslide1down_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                             uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vslide1down_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                             uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vslide1down_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                           uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vslide1down_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                           uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vslide1down_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                           uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vslide1down_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                           uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vslide1down_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                             uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vslide1down_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                           uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vslide1down_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                           uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vslide1down_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                           uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vslide1down_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                           uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vslide1down_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                           uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vslide1down_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                           uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vslide1down_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                           uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vslide1down_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                           uint64_t rs1, size_t vl);
----

[[vector-register-gather]]
==== Vector Register Gather Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vrgather_vv_f16mf4(vfloat16mf4_t vs2, vuint16mf4_t vs1,
                                         size_t vl);
vfloat16mf4_t __riscv_vrgather_vx_f16mf4(vfloat16mf4_t vs2, size_t vs1,
                                         size_t vl);
vfloat16mf2_t __riscv_vrgather_vv_f16mf2(vfloat16mf2_t vs2, vuint16mf2_t vs1,
                                         size_t vl);
vfloat16mf2_t __riscv_vrgather_vx_f16mf2(vfloat16mf2_t vs2, size_t vs1,
                                         size_t vl);
vfloat16m1_t __riscv_vrgather_vv_f16m1(vfloat16m1_t vs2, vuint16m1_t vs1,
                                       size_t vl);
vfloat16m1_t __riscv_vrgather_vx_f16m1(vfloat16m1_t vs2, size_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgather_vv_f16m2(vfloat16m2_t vs2, vuint16m2_t vs1,
                                       size_t vl);
vfloat16m2_t __riscv_vrgather_vx_f16m2(vfloat16m2_t vs2, size_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgather_vv_f16m4(vfloat16m4_t vs2, vuint16m4_t vs1,
                                       size_t vl);
vfloat16m4_t __riscv_vrgather_vx_f16m4(vfloat16m4_t vs2, size_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgather_vv_f16m8(vfloat16m8_t vs2, vuint16m8_t vs1,
                                       size_t vl);
vfloat16m8_t __riscv_vrgather_vx_f16m8(vfloat16m8_t vs2, size_t vs1, size_t vl);
vfloat32mf2_t __riscv_vrgather_vv_f32mf2(vfloat32mf2_t vs2, vuint32mf2_t vs1,
                                         size_t vl);
vfloat32mf2_t __riscv_vrgather_vx_f32mf2(vfloat32mf2_t vs2, size_t vs1,
                                         size_t vl);
vfloat32m1_t __riscv_vrgather_vv_f32m1(vfloat32m1_t vs2, vuint32m1_t vs1,
                                       size_t vl);
vfloat32m1_t __riscv_vrgather_vx_f32m1(vfloat32m1_t vs2, size_t vs1, size_t vl);
vfloat32m2_t __riscv_vrgather_vv_f32m2(vfloat32m2_t vs2, vuint32m2_t vs1,
                                       size_t vl);
vfloat32m2_t __riscv_vrgather_vx_f32m2(vfloat32m2_t vs2, size_t vs1, size_t vl);
vfloat32m4_t __riscv_vrgather_vv_f32m4(vfloat32m4_t vs2, vuint32m4_t vs1,
                                       size_t vl);
vfloat32m4_t __riscv_vrgather_vx_f32m4(vfloat32m4_t vs2, size_t vs1, size_t vl);
vfloat32m8_t __riscv_vrgather_vv_f32m8(vfloat32m8_t vs2, vuint32m8_t vs1,
                                       size_t vl);
vfloat32m8_t __riscv_vrgather_vx_f32m8(vfloat32m8_t vs2, size_t vs1, size_t vl);
vfloat64m1_t __riscv_vrgather_vv_f64m1(vfloat64m1_t vs2, vuint64m1_t vs1,
                                       size_t vl);
vfloat64m1_t __riscv_vrgather_vx_f64m1(vfloat64m1_t vs2, size_t vs1, size_t vl);
vfloat64m2_t __riscv_vrgather_vv_f64m2(vfloat64m2_t vs2, vuint64m2_t vs1,
                                       size_t vl);
vfloat64m2_t __riscv_vrgather_vx_f64m2(vfloat64m2_t vs2, size_t vs1, size_t vl);
vfloat64m4_t __riscv_vrgather_vv_f64m4(vfloat64m4_t vs2, vuint64m4_t vs1,
                                       size_t vl);
vfloat64m4_t __riscv_vrgather_vx_f64m4(vfloat64m4_t vs2, size_t vs1, size_t vl);
vfloat64m8_t __riscv_vrgather_vv_f64m8(vfloat64m8_t vs2, vuint64m8_t vs1,
                                       size_t vl);
vfloat64m8_t __riscv_vrgather_vx_f64m8(vfloat64m8_t vs2, size_t vs1, size_t vl);
vfloat16mf4_t __riscv_vrgatherei16_vv_f16mf4(vfloat16mf4_t vs2,
                                             vuint16mf4_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgatherei16_vv_f16mf2(vfloat16mf2_t vs2,
                                             vuint16mf2_t vs1, size_t vl);
vfloat16m1_t __riscv_vrgatherei16_vv_f16m1(vfloat16m1_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vfloat16m2_t __riscv_vrgatherei16_vv_f16m2(vfloat16m2_t vs2, vuint16m2_t vs1,
                                           size_t vl);
vfloat16m4_t __riscv_vrgatherei16_vv_f16m4(vfloat16m4_t vs2, vuint16m4_t vs1,
                                           size_t vl);
vfloat16m8_t __riscv_vrgatherei16_vv_f16m8(vfloat16m8_t vs2, vuint16m8_t vs1,
                                           size_t vl);
vfloat32mf2_t __riscv_vrgatherei16_vv_f32mf2(vfloat32mf2_t vs2,
                                             vuint16mf4_t vs1, size_t vl);
vfloat32m1_t __riscv_vrgatherei16_vv_f32m1(vfloat32m1_t vs2, vuint16mf2_t vs1,
                                           size_t vl);
vfloat32m2_t __riscv_vrgatherei16_vv_f32m2(vfloat32m2_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vfloat32m4_t __riscv_vrgatherei16_vv_f32m4(vfloat32m4_t vs2, vuint16m2_t vs1,
                                           size_t vl);
vfloat32m8_t __riscv_vrgatherei16_vv_f32m8(vfloat32m8_t vs2, vuint16m4_t vs1,
                                           size_t vl);
vfloat64m1_t __riscv_vrgatherei16_vv_f64m1(vfloat64m1_t vs2, vuint16mf4_t vs1,
                                           size_t vl);
vfloat64m2_t __riscv_vrgatherei16_vv_f64m2(vfloat64m2_t vs2, vuint16mf2_t vs1,
                                           size_t vl);
vfloat64m4_t __riscv_vrgatherei16_vv_f64m4(vfloat64m4_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vfloat64m8_t __riscv_vrgatherei16_vv_f64m8(vfloat64m8_t vs2, vuint16m2_t vs1,
                                           size_t vl);
vint8mf8_t __riscv_vrgather_vv_i8mf8(vint8mf8_t vs2, vuint8mf8_t vs1,
                                     size_t vl);
vint8mf8_t __riscv_vrgather_vx_i8mf8(vint8mf8_t vs2, size_t vs1, size_t vl);
vint8mf4_t __riscv_vrgather_vv_i8mf4(vint8mf4_t vs2, vuint8mf4_t vs1,
                                     size_t vl);
vint8mf4_t __riscv_vrgather_vx_i8mf4(vint8mf4_t vs2, size_t vs1, size_t vl);
vint8mf2_t __riscv_vrgather_vv_i8mf2(vint8mf2_t vs2, vuint8mf2_t vs1,
                                     size_t vl);
vint8mf2_t __riscv_vrgather_vx_i8mf2(vint8mf2_t vs2, size_t vs1, size_t vl);
vint8m1_t __riscv_vrgather_vv_i8m1(vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vrgather_vx_i8m1(vint8m1_t vs2, size_t vs1, size_t vl);
vint8m2_t __riscv_vrgather_vv_i8m2(vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vrgather_vx_i8m2(vint8m2_t vs2, size_t vs1, size_t vl);
vint8m4_t __riscv_vrgather_vv_i8m4(vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vrgather_vx_i8m4(vint8m4_t vs2, size_t vs1, size_t vl);
vint8m8_t __riscv_vrgather_vv_i8m8(vint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vrgather_vx_i8m8(vint8m8_t vs2, size_t vs1, size_t vl);
vint16mf4_t __riscv_vrgather_vv_i16mf4(vint16mf4_t vs2, vuint16mf4_t vs1,
                                       size_t vl);
vint16mf4_t __riscv_vrgather_vx_i16mf4(vint16mf4_t vs2, size_t vs1, size_t vl);
vint16mf2_t __riscv_vrgather_vv_i16mf2(vint16mf2_t vs2, vuint16mf2_t vs1,
                                       size_t vl);
vint16mf2_t __riscv_vrgather_vx_i16mf2(vint16mf2_t vs2, size_t vs1, size_t vl);
vint16m1_t __riscv_vrgather_vv_i16m1(vint16m1_t vs2, vuint16m1_t vs1,
                                     size_t vl);
vint16m1_t __riscv_vrgather_vx_i16m1(vint16m1_t vs2, size_t vs1, size_t vl);
vint16m2_t __riscv_vrgather_vv_i16m2(vint16m2_t vs2, vuint16m2_t vs1,
                                     size_t vl);
vint16m2_t __riscv_vrgather_vx_i16m2(vint16m2_t vs2, size_t vs1, size_t vl);
vint16m4_t __riscv_vrgather_vv_i16m4(vint16m4_t vs2, vuint16m4_t vs1,
                                     size_t vl);
vint16m4_t __riscv_vrgather_vx_i16m4(vint16m4_t vs2, size_t vs1, size_t vl);
vint16m8_t __riscv_vrgather_vv_i16m8(vint16m8_t vs2, vuint16m8_t vs1,
                                     size_t vl);
vint16m8_t __riscv_vrgather_vx_i16m8(vint16m8_t vs2, size_t vs1, size_t vl);
vint32mf2_t __riscv_vrgather_vv_i32mf2(vint32mf2_t vs2, vuint32mf2_t vs1,
                                       size_t vl);
vint32mf2_t __riscv_vrgather_vx_i32mf2(vint32mf2_t vs2, size_t vs1, size_t vl);
vint32m1_t __riscv_vrgather_vv_i32m1(vint32m1_t vs2, vuint32m1_t vs1,
                                     size_t vl);
vint32m1_t __riscv_vrgather_vx_i32m1(vint32m1_t vs2, size_t vs1, size_t vl);
vint32m2_t __riscv_vrgather_vv_i32m2(vint32m2_t vs2, vuint32m2_t vs1,
                                     size_t vl);
vint32m2_t __riscv_vrgather_vx_i32m2(vint32m2_t vs2, size_t vs1, size_t vl);
vint32m4_t __riscv_vrgather_vv_i32m4(vint32m4_t vs2, vuint32m4_t vs1,
                                     size_t vl);
vint32m4_t __riscv_vrgather_vx_i32m4(vint32m4_t vs2, size_t vs1, size_t vl);
vint32m8_t __riscv_vrgather_vv_i32m8(vint32m8_t vs2, vuint32m8_t vs1,
                                     size_t vl);
vint32m8_t __riscv_vrgather_vx_i32m8(vint32m8_t vs2, size_t vs1, size_t vl);
vint64m1_t __riscv_vrgather_vv_i64m1(vint64m1_t vs2, vuint64m1_t vs1,
                                     size_t vl);
vint64m1_t __riscv_vrgather_vx_i64m1(vint64m1_t vs2, size_t vs1, size_t vl);
vint64m2_t __riscv_vrgather_vv_i64m2(vint64m2_t vs2, vuint64m2_t vs1,
                                     size_t vl);
vint64m2_t __riscv_vrgather_vx_i64m2(vint64m2_t vs2, size_t vs1, size_t vl);
vint64m4_t __riscv_vrgather_vv_i64m4(vint64m4_t vs2, vuint64m4_t vs1,
                                     size_t vl);
vint64m4_t __riscv_vrgather_vx_i64m4(vint64m4_t vs2, size_t vs1, size_t vl);
vint64m8_t __riscv_vrgather_vv_i64m8(vint64m8_t vs2, vuint64m8_t vs1,
                                     size_t vl);
vint64m8_t __riscv_vrgather_vx_i64m8(vint64m8_t vs2, size_t vs1, size_t vl);
vint8mf8_t __riscv_vrgatherei16_vv_i8mf8(vint8mf8_t vs2, vuint16mf4_t vs1,
                                         size_t vl);
vint8mf4_t __riscv_vrgatherei16_vv_i8mf4(vint8mf4_t vs2, vuint16mf2_t vs1,
                                         size_t vl);
vint8mf2_t __riscv_vrgatherei16_vv_i8mf2(vint8mf2_t vs2, vuint16m1_t vs1,
                                         size_t vl);
vint8m1_t __riscv_vrgatherei16_vv_i8m1(vint8m1_t vs2, vuint16m2_t vs1,
                                       size_t vl);
vint8m2_t __riscv_vrgatherei16_vv_i8m2(vint8m2_t vs2, vuint16m4_t vs1,
                                       size_t vl);
vint8m4_t __riscv_vrgatherei16_vv_i8m4(vint8m4_t vs2, vuint16m8_t vs1,
                                       size_t vl);
vint16mf4_t __riscv_vrgatherei16_vv_i16mf4(vint16mf4_t vs2, vuint16mf4_t vs1,
                                           size_t vl);
vint16mf2_t __riscv_vrgatherei16_vv_i16mf2(vint16mf2_t vs2, vuint16mf2_t vs1,
                                           size_t vl);
vint16m1_t __riscv_vrgatherei16_vv_i16m1(vint16m1_t vs2, vuint16m1_t vs1,
                                         size_t vl);
vint16m2_t __riscv_vrgatherei16_vv_i16m2(vint16m2_t vs2, vuint16m2_t vs1,
                                         size_t vl);
vint16m4_t __riscv_vrgatherei16_vv_i16m4(vint16m4_t vs2, vuint16m4_t vs1,
                                         size_t vl);
vint16m8_t __riscv_vrgatherei16_vv_i16m8(vint16m8_t vs2, vuint16m8_t vs1,
                                         size_t vl);
vint32mf2_t __riscv_vrgatherei16_vv_i32mf2(vint32mf2_t vs2, vuint16mf4_t vs1,
                                           size_t vl);
vint32m1_t __riscv_vrgatherei16_vv_i32m1(vint32m1_t vs2, vuint16mf2_t vs1,
                                         size_t vl);
vint32m2_t __riscv_vrgatherei16_vv_i32m2(vint32m2_t vs2, vuint16m1_t vs1,
                                         size_t vl);
vint32m4_t __riscv_vrgatherei16_vv_i32m4(vint32m4_t vs2, vuint16m2_t vs1,
                                         size_t vl);
vint32m8_t __riscv_vrgatherei16_vv_i32m8(vint32m8_t vs2, vuint16m4_t vs1,
                                         size_t vl);
vint64m1_t __riscv_vrgatherei16_vv_i64m1(vint64m1_t vs2, vuint16mf4_t vs1,
                                         size_t vl);
vint64m2_t __riscv_vrgatherei16_vv_i64m2(vint64m2_t vs2, vuint16mf2_t vs1,
                                         size_t vl);
vint64m4_t __riscv_vrgatherei16_vv_i64m4(vint64m4_t vs2, vuint16m1_t vs1,
                                         size_t vl);
vint64m8_t __riscv_vrgatherei16_vv_i64m8(vint64m8_t vs2, vuint16m2_t vs1,
                                         size_t vl);
vuint8mf8_t __riscv_vrgather_vv_u8mf8(vuint8mf8_t vs2, vuint8mf8_t vs1,
                                      size_t vl);
vuint8mf8_t __riscv_vrgather_vx_u8mf8(vuint8mf8_t vs2, size_t vs1, size_t vl);
vuint8mf4_t __riscv_vrgather_vv_u8mf4(vuint8mf4_t vs2, vuint8mf4_t vs1,
                                      size_t vl);
vuint8mf4_t __riscv_vrgather_vx_u8mf4(vuint8mf4_t vs2, size_t vs1, size_t vl);
vuint8mf2_t __riscv_vrgather_vv_u8mf2(vuint8mf2_t vs2, vuint8mf2_t vs1,
                                      size_t vl);
vuint8mf2_t __riscv_vrgather_vx_u8mf2(vuint8mf2_t vs2, size_t vs1, size_t vl);
vuint8m1_t __riscv_vrgather_vv_u8m1(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vrgather_vx_u8m1(vuint8m1_t vs2, size_t vs1, size_t vl);
vuint8m2_t __riscv_vrgather_vv_u8m2(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vrgather_vx_u8m2(vuint8m2_t vs2, size_t vs1, size_t vl);
vuint8m4_t __riscv_vrgather_vv_u8m4(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vrgather_vx_u8m4(vuint8m4_t vs2, size_t vs1, size_t vl);
vuint8m8_t __riscv_vrgather_vv_u8m8(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vrgather_vx_u8m8(vuint8m8_t vs2, size_t vs1, size_t vl);
vuint16mf4_t __riscv_vrgather_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                        size_t vl);
vuint16mf4_t __riscv_vrgather_vx_u16mf4(vuint16mf4_t vs2, size_t vs1,
                                        size_t vl);
vuint16mf2_t __riscv_vrgather_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                        size_t vl);
vuint16mf2_t __riscv_vrgather_vx_u16mf2(vuint16mf2_t vs2, size_t vs1,
                                        size_t vl);
vuint16m1_t __riscv_vrgather_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                      size_t vl);
vuint16m1_t __riscv_vrgather_vx_u16m1(vuint16m1_t vs2, size_t vs1, size_t vl);
vuint16m2_t __riscv_vrgather_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                      size_t vl);
vuint16m2_t __riscv_vrgather_vx_u16m2(vuint16m2_t vs2, size_t vs1, size_t vl);
vuint16m4_t __riscv_vrgather_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                      size_t vl);
vuint16m4_t __riscv_vrgather_vx_u16m4(vuint16m4_t vs2, size_t vs1, size_t vl);
vuint16m8_t __riscv_vrgather_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                      size_t vl);
vuint16m8_t __riscv_vrgather_vx_u16m8(vuint16m8_t vs2, size_t vs1, size_t vl);
vuint32mf2_t __riscv_vrgather_vv_u32mf2(vuint32mf2_t vs2, vuint32mf2_t vs1,
                                        size_t vl);
vuint32mf2_t __riscv_vrgather_vx_u32mf2(vuint32mf2_t vs2, size_t vs1,
                                        size_t vl);
vuint32m1_t __riscv_vrgather_vv_u32m1(vuint32m1_t vs2, vuint32m1_t vs1,
                                      size_t vl);
vuint32m1_t __riscv_vrgather_vx_u32m1(vuint32m1_t vs2, size_t vs1, size_t vl);
vuint32m2_t __riscv_vrgather_vv_u32m2(vuint32m2_t vs2, vuint32m2_t vs1,
                                      size_t vl);
vuint32m2_t __riscv_vrgather_vx_u32m2(vuint32m2_t vs2, size_t vs1, size_t vl);
vuint32m4_t __riscv_vrgather_vv_u32m4(vuint32m4_t vs2, vuint32m4_t vs1,
                                      size_t vl);
vuint32m4_t __riscv_vrgather_vx_u32m4(vuint32m4_t vs2, size_t vs1, size_t vl);
vuint32m8_t __riscv_vrgather_vv_u32m8(vuint32m8_t vs2, vuint32m8_t vs1,
                                      size_t vl);
vuint32m8_t __riscv_vrgather_vx_u32m8(vuint32m8_t vs2, size_t vs1, size_t vl);
vuint64m1_t __riscv_vrgather_vv_u64m1(vuint64m1_t vs2, vuint64m1_t vs1,
                                      size_t vl);
vuint64m1_t __riscv_vrgather_vx_u64m1(vuint64m1_t vs2, size_t vs1, size_t vl);
vuint64m2_t __riscv_vrgather_vv_u64m2(vuint64m2_t vs2, vuint64m2_t vs1,
                                      size_t vl);
vuint64m2_t __riscv_vrgather_vx_u64m2(vuint64m2_t vs2, size_t vs1, size_t vl);
vuint64m4_t __riscv_vrgather_vv_u64m4(vuint64m4_t vs2, vuint64m4_t vs1,
                                      size_t vl);
vuint64m4_t __riscv_vrgather_vx_u64m4(vuint64m4_t vs2, size_t vs1, size_t vl);
vuint64m8_t __riscv_vrgather_vv_u64m8(vuint64m8_t vs2, vuint64m8_t vs1,
                                      size_t vl);
vuint64m8_t __riscv_vrgather_vx_u64m8(vuint64m8_t vs2, size_t vs1, size_t vl);
vuint8mf8_t __riscv_vrgatherei16_vv_u8mf8(vuint8mf8_t vs2, vuint16mf4_t vs1,
                                          size_t vl);
vuint8mf4_t __riscv_vrgatherei16_vv_u8mf4(vuint8mf4_t vs2, vuint16mf2_t vs1,
                                          size_t vl);
vuint8mf2_t __riscv_vrgatherei16_vv_u8mf2(vuint8mf2_t vs2, vuint16m1_t vs1,
                                          size_t vl);
vuint8m1_t __riscv_vrgatherei16_vv_u8m1(vuint8m1_t vs2, vuint16m2_t vs1,
                                        size_t vl);
vuint8m2_t __riscv_vrgatherei16_vv_u8m2(vuint8m2_t vs2, vuint16m4_t vs1,
                                        size_t vl);
vuint8m4_t __riscv_vrgatherei16_vv_u8m4(vuint8m4_t vs2, vuint16m8_t vs1,
                                        size_t vl);
vuint16mf4_t __riscv_vrgatherei16_vv_u16mf4(vuint16mf4_t vs2, vuint16mf4_t vs1,
                                            size_t vl);
vuint16mf2_t __riscv_vrgatherei16_vv_u16mf2(vuint16mf2_t vs2, vuint16mf2_t vs1,
                                            size_t vl);
vuint16m1_t __riscv_vrgatherei16_vv_u16m1(vuint16m1_t vs2, vuint16m1_t vs1,
                                          size_t vl);
vuint16m2_t __riscv_vrgatherei16_vv_u16m2(vuint16m2_t vs2, vuint16m2_t vs1,
                                          size_t vl);
vuint16m4_t __riscv_vrgatherei16_vv_u16m4(vuint16m4_t vs2, vuint16m4_t vs1,
                                          size_t vl);
vuint16m8_t __riscv_vrgatherei16_vv_u16m8(vuint16m8_t vs2, vuint16m8_t vs1,
                                          size_t vl);
vuint32mf2_t __riscv_vrgatherei16_vv_u32mf2(vuint32mf2_t vs2, vuint16mf4_t vs1,
                                            size_t vl);
vuint32m1_t __riscv_vrgatherei16_vv_u32m1(vuint32m1_t vs2, vuint16mf2_t vs1,
                                          size_t vl);
vuint32m2_t __riscv_vrgatherei16_vv_u32m2(vuint32m2_t vs2, vuint16m1_t vs1,
                                          size_t vl);
vuint32m4_t __riscv_vrgatherei16_vv_u32m4(vuint32m4_t vs2, vuint16m2_t vs1,
                                          size_t vl);
vuint32m8_t __riscv_vrgatherei16_vv_u32m8(vuint32m8_t vs2, vuint16m4_t vs1,
                                          size_t vl);
vuint64m1_t __riscv_vrgatherei16_vv_u64m1(vuint64m1_t vs2, vuint16mf4_t vs1,
                                          size_t vl);
vuint64m2_t __riscv_vrgatherei16_vv_u64m2(vuint64m2_t vs2, vuint16mf2_t vs1,
                                          size_t vl);
vuint64m4_t __riscv_vrgatherei16_vv_u64m4(vuint64m4_t vs2, vuint16m1_t vs1,
                                          size_t vl);
vuint64m8_t __riscv_vrgatherei16_vv_u64m8(vuint64m8_t vs2, vuint16m2_t vs1,
                                          size_t vl);
// masked functions
vfloat16mf4_t __riscv_vrgather_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           vuint16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vrgather_vx_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           size_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           vuint16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather_vx_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           size_t vs1, size_t vl);
vfloat16m1_t __riscv_vrgather_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                         vuint16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vrgather_vx_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                         size_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgather_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                         vuint16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgather_vx_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                         size_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgather_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                         vuint16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgather_vx_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                         size_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgather_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                         vuint16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgather_vx_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                         size_t vs1, size_t vl);
vfloat32mf2_t __riscv_vrgather_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           vuint32mf2_t vs1, size_t vl);
vfloat32mf2_t __riscv_vrgather_vx_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                           size_t vs1, size_t vl);
vfloat32m1_t __riscv_vrgather_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                         vuint32m1_t vs1, size_t vl);
vfloat32m1_t __riscv_vrgather_vx_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                         size_t vs1, size_t vl);
vfloat32m2_t __riscv_vrgather_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                         vuint32m2_t vs1, size_t vl);
vfloat32m2_t __riscv_vrgather_vx_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                         size_t vs1, size_t vl);
vfloat32m4_t __riscv_vrgather_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                         vuint32m4_t vs1, size_t vl);
vfloat32m4_t __riscv_vrgather_vx_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                         size_t vs1, size_t vl);
vfloat32m8_t __riscv_vrgather_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                         vuint32m8_t vs1, size_t vl);
vfloat32m8_t __riscv_vrgather_vx_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                         size_t vs1, size_t vl);
vfloat64m1_t __riscv_vrgather_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                         vuint64m1_t vs1, size_t vl);
vfloat64m1_t __riscv_vrgather_vx_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                         size_t vs1, size_t vl);
vfloat64m2_t __riscv_vrgather_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                         vuint64m2_t vs1, size_t vl);
vfloat64m2_t __riscv_vrgather_vx_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                         size_t vs1, size_t vl);
vfloat64m4_t __riscv_vrgather_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                         vuint64m4_t vs1, size_t vl);
vfloat64m4_t __riscv_vrgather_vx_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                         size_t vs1, size_t vl);
vfloat64m8_t __riscv_vrgather_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                         vuint64m8_t vs1, size_t vl);
vfloat64m8_t __riscv_vrgather_vx_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                         size_t vs1, size_t vl);
vfloat16mf4_t __riscv_vrgatherei16_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                               vuint16mf4_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgatherei16_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                               vuint16mf2_t vs1, size_t vl);
vfloat16m1_t __riscv_vrgatherei16_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgatherei16_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                             vuint16m2_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgatherei16_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                             vuint16m4_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgatherei16_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                             vuint16m8_t vs1, size_t vl);
vfloat32mf2_t __riscv_vrgatherei16_vv_f32mf2_m(vbool64_t vm, vfloat32mf2_t vs2,
                                               vuint16mf4_t vs1, size_t vl);
vfloat32m1_t __riscv_vrgatherei16_vv_f32m1_m(vbool32_t vm, vfloat32m1_t vs2,
                                             vuint16mf2_t vs1, size_t vl);
vfloat32m2_t __riscv_vrgatherei16_vv_f32m2_m(vbool16_t vm, vfloat32m2_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vfloat32m4_t __riscv_vrgatherei16_vv_f32m4_m(vbool8_t vm, vfloat32m4_t vs2,
                                             vuint16m2_t vs1, size_t vl);
vfloat32m8_t __riscv_vrgatherei16_vv_f32m8_m(vbool4_t vm, vfloat32m8_t vs2,
                                             vuint16m4_t vs1, size_t vl);
vfloat64m1_t __riscv_vrgatherei16_vv_f64m1_m(vbool64_t vm, vfloat64m1_t vs2,
                                             vuint16mf4_t vs1, size_t vl);
vfloat64m2_t __riscv_vrgatherei16_vv_f64m2_m(vbool32_t vm, vfloat64m2_t vs2,
                                             vuint16mf2_t vs1, size_t vl);
vfloat64m4_t __riscv_vrgatherei16_vv_f64m4_m(vbool16_t vm, vfloat64m4_t vs2,
                                             vuint16m1_t vs1, size_t vl);
vfloat64m8_t __riscv_vrgatherei16_vv_f64m8_m(vbool8_t vm, vfloat64m8_t vs2,
                                             vuint16m2_t vs1, size_t vl);
vint8mf8_t __riscv_vrgather_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                       vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vrgather_vx_i8mf8_m(vbool64_t vm, vint8mf8_t vs2, size_t vs1,
                                       size_t vl);
vint8mf4_t __riscv_vrgather_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                       vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vrgather_vx_i8mf4_m(vbool32_t vm, vint8mf4_t vs2, size_t vs1,
                                       size_t vl);
vint8mf2_t __riscv_vrgather_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                       vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vrgather_vx_i8mf2_m(vbool16_t vm, vint8mf2_t vs2, size_t vs1,
                                       size_t vl);
vint8m1_t __riscv_vrgather_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2, vuint8m1_t vs1,
                                     size_t vl);
vint8m1_t __riscv_vrgather_vx_i8m1_m(vbool8_t vm, vint8m1_t vs2, size_t vs1,
                                     size_t vl);
vint8m2_t __riscv_vrgather_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2, vuint8m2_t vs1,
                                     size_t vl);
vint8m2_t __riscv_vrgather_vx_i8m2_m(vbool4_t vm, vint8m2_t vs2, size_t vs1,
                                     size_t vl);
vint8m4_t __riscv_vrgather_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2, vuint8m4_t vs1,
                                     size_t vl);
vint8m4_t __riscv_vrgather_vx_i8m4_m(vbool2_t vm, vint8m4_t vs2, size_t vs1,
                                     size_t vl);
vint8m8_t __riscv_vrgather_vv_i8m8_m(vbool1_t vm, vint8m8_t vs2, vuint8m8_t vs1,
                                     size_t vl);
vint8m8_t __riscv_vrgather_vx_i8m8_m(vbool1_t vm, vint8m8_t vs2, size_t vs1,
                                     size_t vl);
vint16mf4_t __riscv_vrgather_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                         vuint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vrgather_vx_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                         size_t vs1, size_t vl);
vint16mf2_t __riscv_vrgather_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                         vuint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vrgather_vx_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                         size_t vs1, size_t vl);
vint16m1_t __riscv_vrgather_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                       vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vrgather_vx_i16m1_m(vbool16_t vm, vint16m1_t vs2, size_t vs1,
                                       size_t vl);
vint16m2_t __riscv_vrgather_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2,
                                       vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vrgather_vx_i16m2_m(vbool8_t vm, vint16m2_t vs2, size_t vs1,
                                       size_t vl);
vint16m4_t __riscv_vrgather_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2,
                                       vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vrgather_vx_i16m4_m(vbool4_t vm, vint16m4_t vs2, size_t vs1,
                                       size_t vl);
vint16m8_t __riscv_vrgather_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2,
                                       vuint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vrgather_vx_i16m8_m(vbool2_t vm, vint16m8_t vs2, size_t vs1,
                                       size_t vl);
vint32mf2_t __riscv_vrgather_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                         vuint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vrgather_vx_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                         size_t vs1, size_t vl);
vint32m1_t __riscv_vrgather_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                       vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vrgather_vx_i32m1_m(vbool32_t vm, vint32m1_t vs2, size_t vs1,
                                       size_t vl);
vint32m2_t __riscv_vrgather_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                       vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vrgather_vx_i32m2_m(vbool16_t vm, vint32m2_t vs2, size_t vs1,
                                       size_t vl);
vint32m4_t __riscv_vrgather_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2,
                                       vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vrgather_vx_i32m4_m(vbool8_t vm, vint32m4_t vs2, size_t vs1,
                                       size_t vl);
vint32m8_t __riscv_vrgather_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2,
                                       vuint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vrgather_vx_i32m8_m(vbool4_t vm, vint32m8_t vs2, size_t vs1,
                                       size_t vl);
vint64m1_t __riscv_vrgather_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                       vuint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vrgather_vx_i64m1_m(vbool64_t vm, vint64m1_t vs2, size_t vs1,
                                       size_t vl);
vint64m2_t __riscv_vrgather_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                       vuint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vrgather_vx_i64m2_m(vbool32_t vm, vint64m2_t vs2, size_t vs1,
                                       size_t vl);
vint64m4_t __riscv_vrgather_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                       vuint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vrgather_vx_i64m4_m(vbool16_t vm, vint64m4_t vs2, size_t vs1,
                                       size_t vl);
vint64m8_t __riscv_vrgather_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2,
                                       vuint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vrgather_vx_i64m8_m(vbool8_t vm, vint64m8_t vs2, size_t vs1,
                                       size_t vl);
vint8mf8_t __riscv_vrgatherei16_vv_i8mf8_m(vbool64_t vm, vint8mf8_t vs2,
                                           vuint16mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vrgatherei16_vv_i8mf4_m(vbool32_t vm, vint8mf4_t vs2,
                                           vuint16mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vrgatherei16_vv_i8mf2_m(vbool16_t vm, vint8mf2_t vs2,
                                           vuint16m1_t vs1, size_t vl);
vint8m1_t __riscv_vrgatherei16_vv_i8m1_m(vbool8_t vm, vint8m1_t vs2,
                                         vuint16m2_t vs1, size_t vl);
vint8m2_t __riscv_vrgatherei16_vv_i8m2_m(vbool4_t vm, vint8m2_t vs2,
                                         vuint16m4_t vs1, size_t vl);
vint8m4_t __riscv_vrgatherei16_vv_i8m4_m(vbool2_t vm, vint8m4_t vs2,
                                         vuint16m8_t vs1, size_t vl);
vint16mf4_t __riscv_vrgatherei16_vv_i16mf4_m(vbool64_t vm, vint16mf4_t vs2,
                                             vuint16mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vrgatherei16_vv_i16mf2_m(vbool32_t vm, vint16mf2_t vs2,
                                             vuint16mf2_t vs1, size_t vl);
vint16m1_t __riscv_vrgatherei16_vv_i16m1_m(vbool16_t vm, vint16m1_t vs2,
                                           vuint16m1_t vs1, size_t vl);
vint16m2_t __riscv_vrgatherei16_vv_i16m2_m(vbool8_t vm, vint16m2_t vs2,
                                           vuint16m2_t vs1, size_t vl);
vint16m4_t __riscv_vrgatherei16_vv_i16m4_m(vbool4_t vm, vint16m4_t vs2,
                                           vuint16m4_t vs1, size_t vl);
vint16m8_t __riscv_vrgatherei16_vv_i16m8_m(vbool2_t vm, vint16m8_t vs2,
                                           vuint16m8_t vs1, size_t vl);
vint32mf2_t __riscv_vrgatherei16_vv_i32mf2_m(vbool64_t vm, vint32mf2_t vs2,
                                             vuint16mf4_t vs1, size_t vl);
vint32m1_t __riscv_vrgatherei16_vv_i32m1_m(vbool32_t vm, vint32m1_t vs2,
                                           vuint16mf2_t vs1, size_t vl);
vint32m2_t __riscv_vrgatherei16_vv_i32m2_m(vbool16_t vm, vint32m2_t vs2,
                                           vuint16m1_t vs1, size_t vl);
vint32m4_t __riscv_vrgatherei16_vv_i32m4_m(vbool8_t vm, vint32m4_t vs2,
                                           vuint16m2_t vs1, size_t vl);
vint32m8_t __riscv_vrgatherei16_vv_i32m8_m(vbool4_t vm, vint32m8_t vs2,
                                           vuint16m4_t vs1, size_t vl);
vint64m1_t __riscv_vrgatherei16_vv_i64m1_m(vbool64_t vm, vint64m1_t vs2,
                                           vuint16mf4_t vs1, size_t vl);
vint64m2_t __riscv_vrgatherei16_vv_i64m2_m(vbool32_t vm, vint64m2_t vs2,
                                           vuint16mf2_t vs1, size_t vl);
vint64m4_t __riscv_vrgatherei16_vv_i64m4_m(vbool16_t vm, vint64m4_t vs2,
                                           vuint16m1_t vs1, size_t vl);
vint64m8_t __riscv_vrgatherei16_vv_i64m8_m(vbool8_t vm, vint64m8_t vs2,
                                           vuint16m2_t vs1, size_t vl);
vuint8mf8_t __riscv_vrgather_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                        vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vrgather_vx_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                        size_t vs1, size_t vl);
vuint8mf4_t __riscv_vrgather_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                        vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vrgather_vx_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                        size_t vs1, size_t vl);
vuint8mf2_t __riscv_vrgather_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                        vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vrgather_vx_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                        size_t vs1, size_t vl);
vuint8m1_t __riscv_vrgather_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2,
                                      vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vrgather_vx_u8m1_m(vbool8_t vm, vuint8m1_t vs2, size_t vs1,
                                      size_t vl);
vuint8m2_t __riscv_vrgather_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2,
                                      vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vrgather_vx_u8m2_m(vbool4_t vm, vuint8m2_t vs2, size_t vs1,
                                      size_t vl);
vuint8m4_t __riscv_vrgather_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2,
                                      vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vrgather_vx_u8m4_m(vbool2_t vm, vuint8m4_t vs2, size_t vs1,
                                      size_t vl);
vuint8m8_t __riscv_vrgather_vv_u8m8_m(vbool1_t vm, vuint8m8_t vs2,
                                      vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vrgather_vx_u8m8_m(vbool1_t vm, vuint8m8_t vs2, size_t vs1,
                                      size_t vl);
vuint16mf4_t __riscv_vrgather_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                          vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vrgather_vx_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                          size_t vs1, size_t vl);
vuint16mf2_t __riscv_vrgather_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                          vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vrgather_vx_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                          size_t vs1, size_t vl);
vuint16m1_t __riscv_vrgather_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                        vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vrgather_vx_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                        size_t vs1, size_t vl);
vuint16m2_t __riscv_vrgather_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                        vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vrgather_vx_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                        size_t vs1, size_t vl);
vuint16m4_t __riscv_vrgather_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                        vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vrgather_vx_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                        size_t vs1, size_t vl);
vuint16m8_t __riscv_vrgather_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                        vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vrgather_vx_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                        size_t vs1, size_t vl);
vuint32mf2_t __riscv_vrgather_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                          vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vrgather_vx_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                          size_t vs1, size_t vl);
vuint32m1_t __riscv_vrgather_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                        vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vrgather_vx_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                        size_t vs1, size_t vl);
vuint32m2_t __riscv_vrgather_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                        vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vrgather_vx_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                        size_t vs1, size_t vl);
vuint32m4_t __riscv_vrgather_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                        vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vrgather_vx_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                        size_t vs1, size_t vl);
vuint32m8_t __riscv_vrgather_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                        vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vrgather_vx_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                        size_t vs1, size_t vl);
vuint64m1_t __riscv_vrgather_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                        vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vrgather_vx_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                        size_t vs1, size_t vl);
vuint64m2_t __riscv_vrgather_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                        vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vrgather_vx_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                        size_t vs1, size_t vl);
vuint64m4_t __riscv_vrgather_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                        vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vrgather_vx_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                        size_t vs1, size_t vl);
vuint64m8_t __riscv_vrgather_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                        vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vrgather_vx_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                        size_t vs1, size_t vl);
vuint8mf8_t __riscv_vrgatherei16_vv_u8mf8_m(vbool64_t vm, vuint8mf8_t vs2,
                                            vuint16mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vrgatherei16_vv_u8mf4_m(vbool32_t vm, vuint8mf4_t vs2,
                                            vuint16mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vrgatherei16_vv_u8mf2_m(vbool16_t vm, vuint8mf2_t vs2,
                                            vuint16m1_t vs1, size_t vl);
vuint8m1_t __riscv_vrgatherei16_vv_u8m1_m(vbool8_t vm, vuint8m1_t vs2,
                                          vuint16m2_t vs1, size_t vl);
vuint8m2_t __riscv_vrgatherei16_vv_u8m2_m(vbool4_t vm, vuint8m2_t vs2,
                                          vuint16m4_t vs1, size_t vl);
vuint8m4_t __riscv_vrgatherei16_vv_u8m4_m(vbool2_t vm, vuint8m4_t vs2,
                                          vuint16m8_t vs1, size_t vl);
vuint16mf4_t __riscv_vrgatherei16_vv_u16mf4_m(vbool64_t vm, vuint16mf4_t vs2,
                                              vuint16mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vrgatherei16_vv_u16mf2_m(vbool32_t vm, vuint16mf2_t vs2,
                                              vuint16mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vrgatherei16_vv_u16m1_m(vbool16_t vm, vuint16m1_t vs2,
                                            vuint16m1_t vs1, size_t vl);
vuint16m2_t __riscv_vrgatherei16_vv_u16m2_m(vbool8_t vm, vuint16m2_t vs2,
                                            vuint16m2_t vs1, size_t vl);
vuint16m4_t __riscv_vrgatherei16_vv_u16m4_m(vbool4_t vm, vuint16m4_t vs2,
                                            vuint16m4_t vs1, size_t vl);
vuint16m8_t __riscv_vrgatherei16_vv_u16m8_m(vbool2_t vm, vuint16m8_t vs2,
                                            vuint16m8_t vs1, size_t vl);
vuint32mf2_t __riscv_vrgatherei16_vv_u32mf2_m(vbool64_t vm, vuint32mf2_t vs2,
                                              vuint16mf4_t vs1, size_t vl);
vuint32m1_t __riscv_vrgatherei16_vv_u32m1_m(vbool32_t vm, vuint32m1_t vs2,
                                            vuint16mf2_t vs1, size_t vl);
vuint32m2_t __riscv_vrgatherei16_vv_u32m2_m(vbool16_t vm, vuint32m2_t vs2,
                                            vuint16m1_t vs1, size_t vl);
vuint32m4_t __riscv_vrgatherei16_vv_u32m4_m(vbool8_t vm, vuint32m4_t vs2,
                                            vuint16m2_t vs1, size_t vl);
vuint32m8_t __riscv_vrgatherei16_vv_u32m8_m(vbool4_t vm, vuint32m8_t vs2,
                                            vuint16m4_t vs1, size_t vl);
vuint64m1_t __riscv_vrgatherei16_vv_u64m1_m(vbool64_t vm, vuint64m1_t vs2,
                                            vuint16mf4_t vs1, size_t vl);
vuint64m2_t __riscv_vrgatherei16_vv_u64m2_m(vbool32_t vm, vuint64m2_t vs2,
                                            vuint16mf2_t vs1, size_t vl);
vuint64m4_t __riscv_vrgatherei16_vv_u64m4_m(vbool16_t vm, vuint64m4_t vs2,
                                            vuint16m1_t vs1, size_t vl);
vuint64m8_t __riscv_vrgatherei16_vv_u64m8_m(vbool8_t vm, vuint64m8_t vs2,
                                            vuint16m2_t vs1, size_t vl);
----

[[vector-compress]]
==== Vector Compress Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vcompress_vm_f16mf4(vfloat16mf4_t vs2, vbool64_t vs1,
                                          size_t vl);
vfloat16mf2_t __riscv_vcompress_vm_f16mf2(vfloat16mf2_t vs2, vbool32_t vs1,
                                          size_t vl);
vfloat16m1_t __riscv_vcompress_vm_f16m1(vfloat16m1_t vs2, vbool16_t vs1,
                                        size_t vl);
vfloat16m2_t __riscv_vcompress_vm_f16m2(vfloat16m2_t vs2, vbool8_t vs1,
                                        size_t vl);
vfloat16m4_t __riscv_vcompress_vm_f16m4(vfloat16m4_t vs2, vbool4_t vs1,
                                        size_t vl);
vfloat16m8_t __riscv_vcompress_vm_f16m8(vfloat16m8_t vs2, vbool2_t vs1,
                                        size_t vl);
vfloat32mf2_t __riscv_vcompress_vm_f32mf2(vfloat32mf2_t vs2, vbool64_t vs1,
                                          size_t vl);
vfloat32m1_t __riscv_vcompress_vm_f32m1(vfloat32m1_t vs2, vbool32_t vs1,
                                        size_t vl);
vfloat32m2_t __riscv_vcompress_vm_f32m2(vfloat32m2_t vs2, vbool16_t vs1,
                                        size_t vl);
vfloat32m4_t __riscv_vcompress_vm_f32m4(vfloat32m4_t vs2, vbool8_t vs1,
                                        size_t vl);
vfloat32m8_t __riscv_vcompress_vm_f32m8(vfloat32m8_t vs2, vbool4_t vs1,
                                        size_t vl);
vfloat64m1_t __riscv_vcompress_vm_f64m1(vfloat64m1_t vs2, vbool64_t vs1,
                                        size_t vl);
vfloat64m2_t __riscv_vcompress_vm_f64m2(vfloat64m2_t vs2, vbool32_t vs1,
                                        size_t vl);
vfloat64m4_t __riscv_vcompress_vm_f64m4(vfloat64m4_t vs2, vbool16_t vs1,
                                        size_t vl);
vfloat64m8_t __riscv_vcompress_vm_f64m8(vfloat64m8_t vs2, vbool8_t vs1,
                                        size_t vl);
vint8mf8_t __riscv_vcompress_vm_i8mf8(vint8mf8_t vs2, vbool64_t vs1, size_t vl);
vint8mf4_t __riscv_vcompress_vm_i8mf4(vint8mf4_t vs2, vbool32_t vs1, size_t vl);
vint8mf2_t __riscv_vcompress_vm_i8mf2(vint8mf2_t vs2, vbool16_t vs1, size_t vl);
vint8m1_t __riscv_vcompress_vm_i8m1(vint8m1_t vs2, vbool8_t vs1, size_t vl);
vint8m2_t __riscv_vcompress_vm_i8m2(vint8m2_t vs2, vbool4_t vs1, size_t vl);
vint8m4_t __riscv_vcompress_vm_i8m4(vint8m4_t vs2, vbool2_t vs1, size_t vl);
vint8m8_t __riscv_vcompress_vm_i8m8(vint8m8_t vs2, vbool1_t vs1, size_t vl);
vint16mf4_t __riscv_vcompress_vm_i16mf4(vint16mf4_t vs2, vbool64_t vs1,
                                        size_t vl);
vint16mf2_t __riscv_vcompress_vm_i16mf2(vint16mf2_t vs2, vbool32_t vs1,
                                        size_t vl);
vint16m1_t __riscv_vcompress_vm_i16m1(vint16m1_t vs2, vbool16_t vs1, size_t vl);
vint16m2_t __riscv_vcompress_vm_i16m2(vint16m2_t vs2, vbool8_t vs1, size_t vl);
vint16m4_t __riscv_vcompress_vm_i16m4(vint16m4_t vs2, vbool4_t vs1, size_t vl);
vint16m8_t __riscv_vcompress_vm_i16m8(vint16m8_t vs2, vbool2_t vs1, size_t vl);
vint32mf2_t __riscv_vcompress_vm_i32mf2(vint32mf2_t vs2, vbool64_t vs1,
                                        size_t vl);
vint32m1_t __riscv_vcompress_vm_i32m1(vint32m1_t vs2, vbool32_t vs1, size_t vl);
vint32m2_t __riscv_vcompress_vm_i32m2(vint32m2_t vs2, vbool16_t vs1, size_t vl);
vint32m4_t __riscv_vcompress_vm_i32m4(vint32m4_t vs2, vbool8_t vs1, size_t vl);
vint32m8_t __riscv_vcompress_vm_i32m8(vint32m8_t vs2, vbool4_t vs1, size_t vl);
vint64m1_t __riscv_vcompress_vm_i64m1(vint64m1_t vs2, vbool64_t vs1, size_t vl);
vint64m2_t __riscv_vcompress_vm_i64m2(vint64m2_t vs2, vbool32_t vs1, size_t vl);
vint64m4_t __riscv_vcompress_vm_i64m4(vint64m4_t vs2, vbool16_t vs1, size_t vl);
vint64m8_t __riscv_vcompress_vm_i64m8(vint64m8_t vs2, vbool8_t vs1, size_t vl);
vuint8mf8_t __riscv_vcompress_vm_u8mf8(vuint8mf8_t vs2, vbool64_t vs1,
                                       size_t vl);
vuint8mf4_t __riscv_vcompress_vm_u8mf4(vuint8mf4_t vs2, vbool32_t vs1,
                                       size_t vl);
vuint8mf2_t __riscv_vcompress_vm_u8mf2(vuint8mf2_t vs2, vbool16_t vs1,
                                       size_t vl);
vuint8m1_t __riscv_vcompress_vm_u8m1(vuint8m1_t vs2, vbool8_t vs1, size_t vl);
vuint8m2_t __riscv_vcompress_vm_u8m2(vuint8m2_t vs2, vbool4_t vs1, size_t vl);
vuint8m4_t __riscv_vcompress_vm_u8m4(vuint8m4_t vs2, vbool2_t vs1, size_t vl);
vuint8m8_t __riscv_vcompress_vm_u8m8(vuint8m8_t vs2, vbool1_t vs1, size_t vl);
vuint16mf4_t __riscv_vcompress_vm_u16mf4(vuint16mf4_t vs2, vbool64_t vs1,
                                         size_t vl);
vuint16mf2_t __riscv_vcompress_vm_u16mf2(vuint16mf2_t vs2, vbool32_t vs1,
                                         size_t vl);
vuint16m1_t __riscv_vcompress_vm_u16m1(vuint16m1_t vs2, vbool16_t vs1,
                                       size_t vl);
vuint16m2_t __riscv_vcompress_vm_u16m2(vuint16m2_t vs2, vbool8_t vs1,
                                       size_t vl);
vuint16m4_t __riscv_vcompress_vm_u16m4(vuint16m4_t vs2, vbool4_t vs1,
                                       size_t vl);
vuint16m8_t __riscv_vcompress_vm_u16m8(vuint16m8_t vs2, vbool2_t vs1,
                                       size_t vl);
vuint32mf2_t __riscv_vcompress_vm_u32mf2(vuint32mf2_t vs2, vbool64_t vs1,
                                         size_t vl);
vuint32m1_t __riscv_vcompress_vm_u32m1(vuint32m1_t vs2, vbool32_t vs1,
                                       size_t vl);
vuint32m2_t __riscv_vcompress_vm_u32m2(vuint32m2_t vs2, vbool16_t vs1,
                                       size_t vl);
vuint32m4_t __riscv_vcompress_vm_u32m4(vuint32m4_t vs2, vbool8_t vs1,
                                       size_t vl);
vuint32m8_t __riscv_vcompress_vm_u32m8(vuint32m8_t vs2, vbool4_t vs1,
                                       size_t vl);
vuint64m1_t __riscv_vcompress_vm_u64m1(vuint64m1_t vs2, vbool64_t vs1,
                                       size_t vl);
vuint64m2_t __riscv_vcompress_vm_u64m2(vuint64m2_t vs2, vbool32_t vs1,
                                       size_t vl);
vuint64m4_t __riscv_vcompress_vm_u64m4(vuint64m4_t vs2, vbool16_t vs1,
                                       size_t vl);
vuint64m8_t __riscv_vcompress_vm_u64m8(vuint64m8_t vs2, vbool8_t vs1,
                                       size_t vl);
----

=== Miscellaneous Vector Utility Intrinsics

[[set-vl-and-vtype]]
==== Get `vl` with specific vtype

[,c]
----
size_t __riscv_vsetvl_e8mf8(size_t avl);
size_t __riscv_vsetvl_e8mf4(size_t avl);
size_t __riscv_vsetvl_e8mf2(size_t avl);
size_t __riscv_vsetvl_e8m1(size_t avl);
size_t __riscv_vsetvl_e8m2(size_t avl);
size_t __riscv_vsetvl_e8m4(size_t avl);
size_t __riscv_vsetvl_e8m8(size_t avl);
size_t __riscv_vsetvl_e16mf4(size_t avl);
size_t __riscv_vsetvl_e16mf2(size_t avl);
size_t __riscv_vsetvl_e16m1(size_t avl);
size_t __riscv_vsetvl_e16m2(size_t avl);
size_t __riscv_vsetvl_e16m4(size_t avl);
size_t __riscv_vsetvl_e16m8(size_t avl);
size_t __riscv_vsetvl_e32mf2(size_t avl);
size_t __riscv_vsetvl_e32m1(size_t avl);
size_t __riscv_vsetvl_e32m2(size_t avl);
size_t __riscv_vsetvl_e32m4(size_t avl);
size_t __riscv_vsetvl_e32m8(size_t avl);
size_t __riscv_vsetvl_e64m1(size_t avl);
size_t __riscv_vsetvl_e64m2(size_t avl);
size_t __riscv_vsetvl_e64m4(size_t avl);
size_t __riscv_vsetvl_e64m8(size_t avl);
----

[[set-vl-to-vlmax-with-specific-vtype]]
==== Get `VLMAX` with specific vtype

[,c]
----
size_t __riscv_vsetvlmax_e8mf8();
size_t __riscv_vsetvlmax_e8mf4();
size_t __riscv_vsetvlmax_e8mf2();
size_t __riscv_vsetvlmax_e8m1();
size_t __riscv_vsetvlmax_e8m2();
size_t __riscv_vsetvlmax_e8m4();
size_t __riscv_vsetvlmax_e8m8();
size_t __riscv_vsetvlmax_e16mf4();
size_t __riscv_vsetvlmax_e16mf2();
size_t __riscv_vsetvlmax_e16m1();
size_t __riscv_vsetvlmax_e16m2();
size_t __riscv_vsetvlmax_e16m4();
size_t __riscv_vsetvlmax_e16m8();
size_t __riscv_vsetvlmax_e32mf2();
size_t __riscv_vsetvlmax_e32m1();
size_t __riscv_vsetvlmax_e32m2();
size_t __riscv_vsetvlmax_e32m4();
size_t __riscv_vsetvlmax_e32m8();
size_t __riscv_vsetvlmax_e64m1();
size_t __riscv_vsetvlmax_e64m2();
size_t __riscv_vsetvlmax_e64m4();
size_t __riscv_vsetvlmax_e64m8();
----

[[reinterpret-cast-conversion]]
==== Reinterpret Cast Conversion Intrinsics

[,c]
----
// Reinterpret between different type under the same SEW/LMUL
vuint8mf8_t __riscv_vreinterpret_v_i8mf8_u8mf8(vint8mf8_t src);
vuint8mf4_t __riscv_vreinterpret_v_i8mf4_u8mf4(vint8mf4_t src);
vuint8mf2_t __riscv_vreinterpret_v_i8mf2_u8mf2(vint8mf2_t src);
vuint8m1_t __riscv_vreinterpret_v_i8m1_u8m1(vint8m1_t src);
vuint8m2_t __riscv_vreinterpret_v_i8m2_u8m2(vint8m2_t src);
vuint8m4_t __riscv_vreinterpret_v_i8m4_u8m4(vint8m4_t src);
vuint8m8_t __riscv_vreinterpret_v_i8m8_u8m8(vint8m8_t src);
vint8mf8_t __riscv_vreinterpret_v_u8mf8_i8mf8(vuint8mf8_t src);
vint8mf4_t __riscv_vreinterpret_v_u8mf4_i8mf4(vuint8mf4_t src);
vint8mf2_t __riscv_vreinterpret_v_u8mf2_i8mf2(vuint8mf2_t src);
vint8m1_t __riscv_vreinterpret_v_u8m1_i8m1(vuint8m1_t src);
vint8m2_t __riscv_vreinterpret_v_u8m2_i8m2(vuint8m2_t src);
vint8m4_t __riscv_vreinterpret_v_u8m4_i8m4(vuint8m4_t src);
vint8m8_t __riscv_vreinterpret_v_u8m8_i8m8(vuint8m8_t src);
vfloat16mf4_t __riscv_vreinterpret_v_i16mf4_f16mf4(vint16mf4_t src);
vfloat16mf2_t __riscv_vreinterpret_v_i16mf2_f16mf2(vint16mf2_t src);
vfloat16m1_t __riscv_vreinterpret_v_i16m1_f16m1(vint16m1_t src);
vfloat16m2_t __riscv_vreinterpret_v_i16m2_f16m2(vint16m2_t src);
vfloat16m4_t __riscv_vreinterpret_v_i16m4_f16m4(vint16m4_t src);
vfloat16m8_t __riscv_vreinterpret_v_i16m8_f16m8(vint16m8_t src);
vfloat16mf4_t __riscv_vreinterpret_v_u16mf4_f16mf4(vuint16mf4_t src);
vfloat16mf2_t __riscv_vreinterpret_v_u16mf2_f16mf2(vuint16mf2_t src);
vfloat16m1_t __riscv_vreinterpret_v_u16m1_f16m1(vuint16m1_t src);
vfloat16m2_t __riscv_vreinterpret_v_u16m2_f16m2(vuint16m2_t src);
vfloat16m4_t __riscv_vreinterpret_v_u16m4_f16m4(vuint16m4_t src);
vfloat16m8_t __riscv_vreinterpret_v_u16m8_f16m8(vuint16m8_t src);
vuint16mf4_t __riscv_vreinterpret_v_i16mf4_u16mf4(vint16mf4_t src);
vuint16mf2_t __riscv_vreinterpret_v_i16mf2_u16mf2(vint16mf2_t src);
vuint16m1_t __riscv_vreinterpret_v_i16m1_u16m1(vint16m1_t src);
vuint16m2_t __riscv_vreinterpret_v_i16m2_u16m2(vint16m2_t src);
vuint16m4_t __riscv_vreinterpret_v_i16m4_u16m4(vint16m4_t src);
vuint16m8_t __riscv_vreinterpret_v_i16m8_u16m8(vint16m8_t src);
vint16mf4_t __riscv_vreinterpret_v_u16mf4_i16mf4(vuint16mf4_t src);
vint16mf2_t __riscv_vreinterpret_v_u16mf2_i16mf2(vuint16mf2_t src);
vint16m1_t __riscv_vreinterpret_v_u16m1_i16m1(vuint16m1_t src);
vint16m2_t __riscv_vreinterpret_v_u16m2_i16m2(vuint16m2_t src);
vint16m4_t __riscv_vreinterpret_v_u16m4_i16m4(vuint16m4_t src);
vint16m8_t __riscv_vreinterpret_v_u16m8_i16m8(vuint16m8_t src);
vint16mf4_t __riscv_vreinterpret_v_f16mf4_i16mf4(vfloat16mf4_t src);
vint16mf2_t __riscv_vreinterpret_v_f16mf2_i16mf2(vfloat16mf2_t src);
vint16m1_t __riscv_vreinterpret_v_f16m1_i16m1(vfloat16m1_t src);
vint16m2_t __riscv_vreinterpret_v_f16m2_i16m2(vfloat16m2_t src);
vint16m4_t __riscv_vreinterpret_v_f16m4_i16m4(vfloat16m4_t src);
vint16m8_t __riscv_vreinterpret_v_f16m8_i16m8(vfloat16m8_t src);
vuint16mf4_t __riscv_vreinterpret_v_f16mf4_u16mf4(vfloat16mf4_t src);
vuint16mf2_t __riscv_vreinterpret_v_f16mf2_u16mf2(vfloat16mf2_t src);
vuint16m1_t __riscv_vreinterpret_v_f16m1_u16m1(vfloat16m1_t src);
vuint16m2_t __riscv_vreinterpret_v_f16m2_u16m2(vfloat16m2_t src);
vuint16m4_t __riscv_vreinterpret_v_f16m4_u16m4(vfloat16m4_t src);
vuint16m8_t __riscv_vreinterpret_v_f16m8_u16m8(vfloat16m8_t src);
vfloat32mf2_t __riscv_vreinterpret_v_i32mf2_f32mf2(vint32mf2_t src);
vfloat32m1_t __riscv_vreinterpret_v_i32m1_f32m1(vint32m1_t src);
vfloat32m2_t __riscv_vreinterpret_v_i32m2_f32m2(vint32m2_t src);
vfloat32m4_t __riscv_vreinterpret_v_i32m4_f32m4(vint32m4_t src);
vfloat32m8_t __riscv_vreinterpret_v_i32m8_f32m8(vint32m8_t src);
vfloat32mf2_t __riscv_vreinterpret_v_u32mf2_f32mf2(vuint32mf2_t src);
vfloat32m1_t __riscv_vreinterpret_v_u32m1_f32m1(vuint32m1_t src);
vfloat32m2_t __riscv_vreinterpret_v_u32m2_f32m2(vuint32m2_t src);
vfloat32m4_t __riscv_vreinterpret_v_u32m4_f32m4(vuint32m4_t src);
vfloat32m8_t __riscv_vreinterpret_v_u32m8_f32m8(vuint32m8_t src);
vuint32mf2_t __riscv_vreinterpret_v_i32mf2_u32mf2(vint32mf2_t src);
vuint32m1_t __riscv_vreinterpret_v_i32m1_u32m1(vint32m1_t src);
vuint32m2_t __riscv_vreinterpret_v_i32m2_u32m2(vint32m2_t src);
vuint32m4_t __riscv_vreinterpret_v_i32m4_u32m4(vint32m4_t src);
vuint32m8_t __riscv_vreinterpret_v_i32m8_u32m8(vint32m8_t src);
vint32mf2_t __riscv_vreinterpret_v_u32mf2_i32mf2(vuint32mf2_t src);
vint32m1_t __riscv_vreinterpret_v_u32m1_i32m1(vuint32m1_t src);
vint32m2_t __riscv_vreinterpret_v_u32m2_i32m2(vuint32m2_t src);
vint32m4_t __riscv_vreinterpret_v_u32m4_i32m4(vuint32m4_t src);
vint32m8_t __riscv_vreinterpret_v_u32m8_i32m8(vuint32m8_t src);
vint32mf2_t __riscv_vreinterpret_v_f32mf2_i32mf2(vfloat32mf2_t src);
vint32m1_t __riscv_vreinterpret_v_f32m1_i32m1(vfloat32m1_t src);
vint32m2_t __riscv_vreinterpret_v_f32m2_i32m2(vfloat32m2_t src);
vint32m4_t __riscv_vreinterpret_v_f32m4_i32m4(vfloat32m4_t src);
vint32m8_t __riscv_vreinterpret_v_f32m8_i32m8(vfloat32m8_t src);
vuint32mf2_t __riscv_vreinterpret_v_f32mf2_u32mf2(vfloat32mf2_t src);
vuint32m1_t __riscv_vreinterpret_v_f32m1_u32m1(vfloat32m1_t src);
vuint32m2_t __riscv_vreinterpret_v_f32m2_u32m2(vfloat32m2_t src);
vuint32m4_t __riscv_vreinterpret_v_f32m4_u32m4(vfloat32m4_t src);
vuint32m8_t __riscv_vreinterpret_v_f32m8_u32m8(vfloat32m8_t src);
vfloat64m1_t __riscv_vreinterpret_v_i64m1_f64m1(vint64m1_t src);
vfloat64m2_t __riscv_vreinterpret_v_i64m2_f64m2(vint64m2_t src);
vfloat64m4_t __riscv_vreinterpret_v_i64m4_f64m4(vint64m4_t src);
vfloat64m8_t __riscv_vreinterpret_v_i64m8_f64m8(vint64m8_t src);
vfloat64m1_t __riscv_vreinterpret_v_u64m1_f64m1(vuint64m1_t src);
vfloat64m2_t __riscv_vreinterpret_v_u64m2_f64m2(vuint64m2_t src);
vfloat64m4_t __riscv_vreinterpret_v_u64m4_f64m4(vuint64m4_t src);
vfloat64m8_t __riscv_vreinterpret_v_u64m8_f64m8(vuint64m8_t src);
vuint64m1_t __riscv_vreinterpret_v_i64m1_u64m1(vint64m1_t src);
vuint64m2_t __riscv_vreinterpret_v_i64m2_u64m2(vint64m2_t src);
vuint64m4_t __riscv_vreinterpret_v_i64m4_u64m4(vint64m4_t src);
vuint64m8_t __riscv_vreinterpret_v_i64m8_u64m8(vint64m8_t src);
vint64m1_t __riscv_vreinterpret_v_u64m1_i64m1(vuint64m1_t src);
vint64m2_t __riscv_vreinterpret_v_u64m2_i64m2(vuint64m2_t src);
vint64m4_t __riscv_vreinterpret_v_u64m4_i64m4(vuint64m4_t src);
vint64m8_t __riscv_vreinterpret_v_u64m8_i64m8(vuint64m8_t src);
vint64m1_t __riscv_vreinterpret_v_f64m1_i64m1(vfloat64m1_t src);
vint64m2_t __riscv_vreinterpret_v_f64m2_i64m2(vfloat64m2_t src);
vint64m4_t __riscv_vreinterpret_v_f64m4_i64m4(vfloat64m4_t src);
vint64m8_t __riscv_vreinterpret_v_f64m8_i64m8(vfloat64m8_t src);
vuint64m1_t __riscv_vreinterpret_v_f64m1_u64m1(vfloat64m1_t src);
vuint64m2_t __riscv_vreinterpret_v_f64m2_u64m2(vfloat64m2_t src);
vuint64m4_t __riscv_vreinterpret_v_f64m4_u64m4(vfloat64m4_t src);
vuint64m8_t __riscv_vreinterpret_v_f64m8_u64m8(vfloat64m8_t src);
// Reinterpret between different SEW under the same LMUL
vint16mf4_t __riscv_vreinterpret_v_i8mf4_i16mf4(vint8mf4_t src);
vint16mf2_t __riscv_vreinterpret_v_i8mf2_i16mf2(vint8mf2_t src);
vint16m1_t __riscv_vreinterpret_v_i8m1_i16m1(vint8m1_t src);
vint16m2_t __riscv_vreinterpret_v_i8m2_i16m2(vint8m2_t src);
vint16m4_t __riscv_vreinterpret_v_i8m4_i16m4(vint8m4_t src);
vint16m8_t __riscv_vreinterpret_v_i8m8_i16m8(vint8m8_t src);
vuint16mf4_t __riscv_vreinterpret_v_u8mf4_u16mf4(vuint8mf4_t src);
vuint16mf2_t __riscv_vreinterpret_v_u8mf2_u16mf2(vuint8mf2_t src);
vuint16m1_t __riscv_vreinterpret_v_u8m1_u16m1(vuint8m1_t src);
vuint16m2_t __riscv_vreinterpret_v_u8m2_u16m2(vuint8m2_t src);
vuint16m4_t __riscv_vreinterpret_v_u8m4_u16m4(vuint8m4_t src);
vuint16m8_t __riscv_vreinterpret_v_u8m8_u16m8(vuint8m8_t src);
vint32mf2_t __riscv_vreinterpret_v_i8mf2_i32mf2(vint8mf2_t src);
vint32m1_t __riscv_vreinterpret_v_i8m1_i32m1(vint8m1_t src);
vint32m2_t __riscv_vreinterpret_v_i8m2_i32m2(vint8m2_t src);
vint32m4_t __riscv_vreinterpret_v_i8m4_i32m4(vint8m4_t src);
vint32m8_t __riscv_vreinterpret_v_i8m8_i32m8(vint8m8_t src);
vuint32mf2_t __riscv_vreinterpret_v_u8mf2_u32mf2(vuint8mf2_t src);
vuint32m1_t __riscv_vreinterpret_v_u8m1_u32m1(vuint8m1_t src);
vuint32m2_t __riscv_vreinterpret_v_u8m2_u32m2(vuint8m2_t src);
vuint32m4_t __riscv_vreinterpret_v_u8m4_u32m4(vuint8m4_t src);
vuint32m8_t __riscv_vreinterpret_v_u8m8_u32m8(vuint8m8_t src);
vint64m1_t __riscv_vreinterpret_v_i8m1_i64m1(vint8m1_t src);
vint64m2_t __riscv_vreinterpret_v_i8m2_i64m2(vint8m2_t src);
vint64m4_t __riscv_vreinterpret_v_i8m4_i64m4(vint8m4_t src);
vint64m8_t __riscv_vreinterpret_v_i8m8_i64m8(vint8m8_t src);
vuint64m1_t __riscv_vreinterpret_v_u8m1_u64m1(vuint8m1_t src);
vuint64m2_t __riscv_vreinterpret_v_u8m2_u64m2(vuint8m2_t src);
vuint64m4_t __riscv_vreinterpret_v_u8m4_u64m4(vuint8m4_t src);
vuint64m8_t __riscv_vreinterpret_v_u8m8_u64m8(vuint8m8_t src);
vint8mf4_t __riscv_vreinterpret_v_i16mf4_i8mf4(vint16mf4_t src);
vint8mf2_t __riscv_vreinterpret_v_i16mf2_i8mf2(vint16mf2_t src);
vint8m1_t __riscv_vreinterpret_v_i16m1_i8m1(vint16m1_t src);
vint8m2_t __riscv_vreinterpret_v_i16m2_i8m2(vint16m2_t src);
vint8m4_t __riscv_vreinterpret_v_i16m4_i8m4(vint16m4_t src);
vint8m8_t __riscv_vreinterpret_v_i16m8_i8m8(vint16m8_t src);
vuint8mf4_t __riscv_vreinterpret_v_u16mf4_u8mf4(vuint16mf4_t src);
vuint8mf2_t __riscv_vreinterpret_v_u16mf2_u8mf2(vuint16mf2_t src);
vuint8m1_t __riscv_vreinterpret_v_u16m1_u8m1(vuint16m1_t src);
vuint8m2_t __riscv_vreinterpret_v_u16m2_u8m2(vuint16m2_t src);
vuint8m4_t __riscv_vreinterpret_v_u16m4_u8m4(vuint16m4_t src);
vuint8m8_t __riscv_vreinterpret_v_u16m8_u8m8(vuint16m8_t src);
vint32mf2_t __riscv_vreinterpret_v_i16mf2_i32mf2(vint16mf2_t src);
vint32m1_t __riscv_vreinterpret_v_i16m1_i32m1(vint16m1_t src);
vint32m2_t __riscv_vreinterpret_v_i16m2_i32m2(vint16m2_t src);
vint32m4_t __riscv_vreinterpret_v_i16m4_i32m4(vint16m4_t src);
vint32m8_t __riscv_vreinterpret_v_i16m8_i32m8(vint16m8_t src);
vuint32mf2_t __riscv_vreinterpret_v_u16mf2_u32mf2(vuint16mf2_t src);
vuint32m1_t __riscv_vreinterpret_v_u16m1_u32m1(vuint16m1_t src);
vuint32m2_t __riscv_vreinterpret_v_u16m2_u32m2(vuint16m2_t src);
vuint32m4_t __riscv_vreinterpret_v_u16m4_u32m4(vuint16m4_t src);
vuint32m8_t __riscv_vreinterpret_v_u16m8_u32m8(vuint16m8_t src);
vint64m1_t __riscv_vreinterpret_v_i16m1_i64m1(vint16m1_t src);
vint64m2_t __riscv_vreinterpret_v_i16m2_i64m2(vint16m2_t src);
vint64m4_t __riscv_vreinterpret_v_i16m4_i64m4(vint16m4_t src);
vint64m8_t __riscv_vreinterpret_v_i16m8_i64m8(vint16m8_t src);
vuint64m1_t __riscv_vreinterpret_v_u16m1_u64m1(vuint16m1_t src);
vuint64m2_t __riscv_vreinterpret_v_u16m2_u64m2(vuint16m2_t src);
vuint64m4_t __riscv_vreinterpret_v_u16m4_u64m4(vuint16m4_t src);
vuint64m8_t __riscv_vreinterpret_v_u16m8_u64m8(vuint16m8_t src);
vint8mf2_t __riscv_vreinterpret_v_i32mf2_i8mf2(vint32mf2_t src);
vint8m1_t __riscv_vreinterpret_v_i32m1_i8m1(vint32m1_t src);
vint8m2_t __riscv_vreinterpret_v_i32m2_i8m2(vint32m2_t src);
vint8m4_t __riscv_vreinterpret_v_i32m4_i8m4(vint32m4_t src);
vint8m8_t __riscv_vreinterpret_v_i32m8_i8m8(vint32m8_t src);
vuint8mf2_t __riscv_vreinterpret_v_u32mf2_u8mf2(vuint32mf2_t src);
vuint8m1_t __riscv_vreinterpret_v_u32m1_u8m1(vuint32m1_t src);
vuint8m2_t __riscv_vreinterpret_v_u32m2_u8m2(vuint32m2_t src);
vuint8m4_t __riscv_vreinterpret_v_u32m4_u8m4(vuint32m4_t src);
vuint8m8_t __riscv_vreinterpret_v_u32m8_u8m8(vuint32m8_t src);
vint16mf2_t __riscv_vreinterpret_v_i32mf2_i16mf2(vint32mf2_t src);
vint16m1_t __riscv_vreinterpret_v_i32m1_i16m1(vint32m1_t src);
vint16m2_t __riscv_vreinterpret_v_i32m2_i16m2(vint32m2_t src);
vint16m4_t __riscv_vreinterpret_v_i32m4_i16m4(vint32m4_t src);
vint16m8_t __riscv_vreinterpret_v_i32m8_i16m8(vint32m8_t src);
vuint16mf2_t __riscv_vreinterpret_v_u32mf2_u16mf2(vuint32mf2_t src);
vuint16m1_t __riscv_vreinterpret_v_u32m1_u16m1(vuint32m1_t src);
vuint16m2_t __riscv_vreinterpret_v_u32m2_u16m2(vuint32m2_t src);
vuint16m4_t __riscv_vreinterpret_v_u32m4_u16m4(vuint32m4_t src);
vuint16m8_t __riscv_vreinterpret_v_u32m8_u16m8(vuint32m8_t src);
vint64m1_t __riscv_vreinterpret_v_i32m1_i64m1(vint32m1_t src);
vint64m2_t __riscv_vreinterpret_v_i32m2_i64m2(vint32m2_t src);
vint64m4_t __riscv_vreinterpret_v_i32m4_i64m4(vint32m4_t src);
vint64m8_t __riscv_vreinterpret_v_i32m8_i64m8(vint32m8_t src);
vuint64m1_t __riscv_vreinterpret_v_u32m1_u64m1(vuint32m1_t src);
vuint64m2_t __riscv_vreinterpret_v_u32m2_u64m2(vuint32m2_t src);
vuint64m4_t __riscv_vreinterpret_v_u32m4_u64m4(vuint32m4_t src);
vuint64m8_t __riscv_vreinterpret_v_u32m8_u64m8(vuint32m8_t src);
vint8m1_t __riscv_vreinterpret_v_i64m1_i8m1(vint64m1_t src);
vint8m2_t __riscv_vreinterpret_v_i64m2_i8m2(vint64m2_t src);
vint8m4_t __riscv_vreinterpret_v_i64m4_i8m4(vint64m4_t src);
vint8m8_t __riscv_vreinterpret_v_i64m8_i8m8(vint64m8_t src);
vuint8m1_t __riscv_vreinterpret_v_u64m1_u8m1(vuint64m1_t src);
vuint8m2_t __riscv_vreinterpret_v_u64m2_u8m2(vuint64m2_t src);
vuint8m4_t __riscv_vreinterpret_v_u64m4_u8m4(vuint64m4_t src);
vuint8m8_t __riscv_vreinterpret_v_u64m8_u8m8(vuint64m8_t src);
vint16m1_t __riscv_vreinterpret_v_i64m1_i16m1(vint64m1_t src);
vint16m2_t __riscv_vreinterpret_v_i64m2_i16m2(vint64m2_t src);
vint16m4_t __riscv_vreinterpret_v_i64m4_i16m4(vint64m4_t src);
vint16m8_t __riscv_vreinterpret_v_i64m8_i16m8(vint64m8_t src);
vuint16m1_t __riscv_vreinterpret_v_u64m1_u16m1(vuint64m1_t src);
vuint16m2_t __riscv_vreinterpret_v_u64m2_u16m2(vuint64m2_t src);
vuint16m4_t __riscv_vreinterpret_v_u64m4_u16m4(vuint64m4_t src);
vuint16m8_t __riscv_vreinterpret_v_u64m8_u16m8(vuint64m8_t src);
vint32m1_t __riscv_vreinterpret_v_i64m1_i32m1(vint64m1_t src);
vint32m2_t __riscv_vreinterpret_v_i64m2_i32m2(vint64m2_t src);
vint32m4_t __riscv_vreinterpret_v_i64m4_i32m4(vint64m4_t src);
vint32m8_t __riscv_vreinterpret_v_i64m8_i32m8(vint64m8_t src);
vuint32m1_t __riscv_vreinterpret_v_u64m1_u32m1(vuint64m1_t src);
vuint32m2_t __riscv_vreinterpret_v_u64m2_u32m2(vuint64m2_t src);
vuint32m4_t __riscv_vreinterpret_v_u64m4_u32m4(vuint64m4_t src);
vuint32m8_t __riscv_vreinterpret_v_u64m8_u32m8(vuint64m8_t src);
// Reinterpret between vector boolean types and LMUL=1 (m1) vector integer types
vbool64_t __riscv_vreinterpret_v_i8m1_b64(vint8m1_t src);
vint8m1_t __riscv_vreinterpret_v_b64_i8m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_v_i8m1_b32(vint8m1_t src);
vint8m1_t __riscv_vreinterpret_v_b32_i8m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_v_i8m1_b16(vint8m1_t src);
vint8m1_t __riscv_vreinterpret_v_b16_i8m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_v_i8m1_b8(vint8m1_t src);
vint8m1_t __riscv_vreinterpret_v_b8_i8m1(vbool8_t src);
vbool4_t __riscv_vreinterpret_v_i8m1_b4(vint8m1_t src);
vint8m1_t __riscv_vreinterpret_v_b4_i8m1(vbool4_t src);
vbool2_t __riscv_vreinterpret_v_i8m1_b2(vint8m1_t src);
vint8m1_t __riscv_vreinterpret_v_b2_i8m1(vbool2_t src);
vbool1_t __riscv_vreinterpret_v_i8m1_b1(vint8m1_t src);
vint8m1_t __riscv_vreinterpret_v_b1_i8m1(vbool1_t src);
vbool64_t __riscv_vreinterpret_v_u8m1_b64(vuint8m1_t src);
vuint8m1_t __riscv_vreinterpret_v_b64_u8m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_v_u8m1_b32(vuint8m1_t src);
vuint8m1_t __riscv_vreinterpret_v_b32_u8m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_v_u8m1_b16(vuint8m1_t src);
vuint8m1_t __riscv_vreinterpret_v_b16_u8m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_v_u8m1_b8(vuint8m1_t src);
vuint8m1_t __riscv_vreinterpret_v_b8_u8m1(vbool8_t src);
vbool4_t __riscv_vreinterpret_v_u8m1_b4(vuint8m1_t src);
vuint8m1_t __riscv_vreinterpret_v_b4_u8m1(vbool4_t src);
vbool2_t __riscv_vreinterpret_v_u8m1_b2(vuint8m1_t src);
vuint8m1_t __riscv_vreinterpret_v_b2_u8m1(vbool2_t src);
vbool1_t __riscv_vreinterpret_v_u8m1_b1(vuint8m1_t src);
vuint8m1_t __riscv_vreinterpret_v_b1_u8m1(vbool1_t src);
vbool64_t __riscv_vreinterpret_v_i16m1_b64(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b64_i16m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_v_i16m1_b32(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b32_i16m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_v_i16m1_b16(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b16_i16m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_v_i16m1_b8(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b8_i16m1(vbool8_t src);
vbool4_t __riscv_vreinterpret_v_i16m1_b4(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b4_i16m1(vbool4_t src);
vbool2_t __riscv_vreinterpret_v_i16m1_b2(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b2_i16m1(vbool2_t src);
vbool64_t __riscv_vreinterpret_v_u16m1_b64(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b64_u16m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_v_u16m1_b32(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b32_u16m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_v_u16m1_b16(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b16_u16m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_v_u16m1_b8(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b8_u16m1(vbool8_t src);
vbool4_t __riscv_vreinterpret_v_u16m1_b4(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b4_u16m1(vbool4_t src);
vbool2_t __riscv_vreinterpret_v_u16m1_b2(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b2_u16m1(vbool2_t src);
vbool64_t __riscv_vreinterpret_v_i32m1_b64(vint32m1_t src);
vint32m1_t __riscv_vreinterpret_v_b64_i32m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_v_i32m1_b32(vint32m1_t src);
vint32m1_t __riscv_vreinterpret_v_b32_i32m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_v_i32m1_b16(vint32m1_t src);
vint32m1_t __riscv_vreinterpret_v_b16_i32m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_v_i32m1_b8(vint32m1_t src);
vint32m1_t __riscv_vreinterpret_v_b8_i32m1(vbool8_t src);
vbool4_t __riscv_vreinterpret_v_i32m1_b4(vint32m1_t src);
vint32m1_t __riscv_vreinterpret_v_b4_i32m1(vbool4_t src);
vbool64_t __riscv_vreinterpret_v_u32m1_b64(vuint32m1_t src);
vuint32m1_t __riscv_vreinterpret_v_b64_u32m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_v_u32m1_b32(vuint32m1_t src);
vuint32m1_t __riscv_vreinterpret_v_b32_u32m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_v_u32m1_b16(vuint32m1_t src);
vuint32m1_t __riscv_vreinterpret_v_b16_u32m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_v_u32m1_b8(vuint32m1_t src);
vuint32m1_t __riscv_vreinterpret_v_b8_u32m1(vbool8_t src);
vbool4_t __riscv_vreinterpret_v_u32m1_b4(vuint32m1_t src);
vuint32m1_t __riscv_vreinterpret_v_b4_u32m1(vbool4_t src);
vbool64_t __riscv_vreinterpret_v_i64m1_b64(vint64m1_t src);
vint64m1_t __riscv_vreinterpret_v_b64_i64m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_v_i64m1_b32(vint64m1_t src);
vint64m1_t __riscv_vreinterpret_v_b32_i64m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_v_i64m1_b16(vint64m1_t src);
vint64m1_t __riscv_vreinterpret_v_b16_i64m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_v_i64m1_b8(vint64m1_t src);
vint64m1_t __riscv_vreinterpret_v_b8_i64m1(vbool8_t src);
vbool64_t __riscv_vreinterpret_v_u64m1_b64(vuint64m1_t src);
vuint64m1_t __riscv_vreinterpret_v_b64_u64m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_v_u64m1_b32(vuint64m1_t src);
vuint64m1_t __riscv_vreinterpret_v_b32_u64m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_v_u64m1_b16(vuint64m1_t src);
vuint64m1_t __riscv_vreinterpret_v_b16_u64m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_v_u64m1_b8(vuint64m1_t src);
vuint64m1_t __riscv_vreinterpret_v_b8_u64m1(vbool8_t src);
----

[[vector-lmul-extensionn]]
==== Vector LMUL Extension Intrinsics

[,c]
----
vfloat16mf2_t __riscv_vlmul_ext_v_f16mf4_f16mf2(vfloat16mf4_t value);
vfloat16m1_t __riscv_vlmul_ext_v_f16mf4_f16m1(vfloat16mf4_t value);
vfloat16m2_t __riscv_vlmul_ext_v_f16mf4_f16m2(vfloat16mf4_t value);
vfloat16m4_t __riscv_vlmul_ext_v_f16mf4_f16m4(vfloat16mf4_t value);
vfloat16m8_t __riscv_vlmul_ext_v_f16mf4_f16m8(vfloat16mf4_t value);
vfloat16m1_t __riscv_vlmul_ext_v_f16mf2_f16m1(vfloat16mf2_t value);
vfloat16m2_t __riscv_vlmul_ext_v_f16mf2_f16m2(vfloat16mf2_t value);
vfloat16m4_t __riscv_vlmul_ext_v_f16mf2_f16m4(vfloat16mf2_t value);
vfloat16m8_t __riscv_vlmul_ext_v_f16mf2_f16m8(vfloat16mf2_t value);
vfloat16m2_t __riscv_vlmul_ext_v_f16m1_f16m2(vfloat16m1_t value);
vfloat16m4_t __riscv_vlmul_ext_v_f16m1_f16m4(vfloat16m1_t value);
vfloat16m8_t __riscv_vlmul_ext_v_f16m1_f16m8(vfloat16m1_t value);
vfloat16m4_t __riscv_vlmul_ext_v_f16m2_f16m4(vfloat16m2_t value);
vfloat16m8_t __riscv_vlmul_ext_v_f16m2_f16m8(vfloat16m2_t value);
vfloat16m8_t __riscv_vlmul_ext_v_f16m4_f16m8(vfloat16m4_t value);
vfloat32m1_t __riscv_vlmul_ext_v_f32mf2_f32m1(vfloat32mf2_t value);
vfloat32m2_t __riscv_vlmul_ext_v_f32mf2_f32m2(vfloat32mf2_t value);
vfloat32m4_t __riscv_vlmul_ext_v_f32mf2_f32m4(vfloat32mf2_t value);
vfloat32m8_t __riscv_vlmul_ext_v_f32mf2_f32m8(vfloat32mf2_t value);
vfloat32m2_t __riscv_vlmul_ext_v_f32m1_f32m2(vfloat32m1_t value);
vfloat32m4_t __riscv_vlmul_ext_v_f32m1_f32m4(vfloat32m1_t value);
vfloat32m8_t __riscv_vlmul_ext_v_f32m1_f32m8(vfloat32m1_t value);
vfloat32m4_t __riscv_vlmul_ext_v_f32m2_f32m4(vfloat32m2_t value);
vfloat32m8_t __riscv_vlmul_ext_v_f32m2_f32m8(vfloat32m2_t value);
vfloat32m8_t __riscv_vlmul_ext_v_f32m4_f32m8(vfloat32m4_t value);
vfloat64m2_t __riscv_vlmul_ext_v_f64m1_f64m2(vfloat64m1_t value);
vfloat64m4_t __riscv_vlmul_ext_v_f64m1_f64m4(vfloat64m1_t value);
vfloat64m8_t __riscv_vlmul_ext_v_f64m1_f64m8(vfloat64m1_t value);
vfloat64m4_t __riscv_vlmul_ext_v_f64m2_f64m4(vfloat64m2_t value);
vfloat64m8_t __riscv_vlmul_ext_v_f64m2_f64m8(vfloat64m2_t value);
vfloat64m8_t __riscv_vlmul_ext_v_f64m4_f64m8(vfloat64m4_t value);
vint8mf4_t __riscv_vlmul_ext_v_i8mf8_i8mf4(vint8mf8_t value);
vint8mf2_t __riscv_vlmul_ext_v_i8mf8_i8mf2(vint8mf8_t value);
vint8m1_t __riscv_vlmul_ext_v_i8mf8_i8m1(vint8mf8_t value);
vint8m2_t __riscv_vlmul_ext_v_i8mf8_i8m2(vint8mf8_t value);
vint8m4_t __riscv_vlmul_ext_v_i8mf8_i8m4(vint8mf8_t value);
vint8m8_t __riscv_vlmul_ext_v_i8mf8_i8m8(vint8mf8_t value);
vint8mf2_t __riscv_vlmul_ext_v_i8mf4_i8mf2(vint8mf4_t value);
vint8m1_t __riscv_vlmul_ext_v_i8mf4_i8m1(vint8mf4_t value);
vint8m2_t __riscv_vlmul_ext_v_i8mf4_i8m2(vint8mf4_t value);
vint8m4_t __riscv_vlmul_ext_v_i8mf4_i8m4(vint8mf4_t value);
vint8m8_t __riscv_vlmul_ext_v_i8mf4_i8m8(vint8mf4_t value);
vint8m1_t __riscv_vlmul_ext_v_i8mf2_i8m1(vint8mf2_t value);
vint8m2_t __riscv_vlmul_ext_v_i8mf2_i8m2(vint8mf2_t value);
vint8m4_t __riscv_vlmul_ext_v_i8mf2_i8m4(vint8mf2_t value);
vint8m8_t __riscv_vlmul_ext_v_i8mf2_i8m8(vint8mf2_t value);
vint8m2_t __riscv_vlmul_ext_v_i8m1_i8m2(vint8m1_t value);
vint8m4_t __riscv_vlmul_ext_v_i8m1_i8m4(vint8m1_t value);
vint8m8_t __riscv_vlmul_ext_v_i8m1_i8m8(vint8m1_t value);
vint8m4_t __riscv_vlmul_ext_v_i8m2_i8m4(vint8m2_t value);
vint8m8_t __riscv_vlmul_ext_v_i8m2_i8m8(vint8m2_t value);
vint8m8_t __riscv_vlmul_ext_v_i8m4_i8m8(vint8m4_t value);
vint16mf2_t __riscv_vlmul_ext_v_i16mf4_i16mf2(vint16mf4_t value);
vint16m1_t __riscv_vlmul_ext_v_i16mf4_i16m1(vint16mf4_t value);
vint16m2_t __riscv_vlmul_ext_v_i16mf4_i16m2(vint16mf4_t value);
vint16m4_t __riscv_vlmul_ext_v_i16mf4_i16m4(vint16mf4_t value);
vint16m8_t __riscv_vlmul_ext_v_i16mf4_i16m8(vint16mf4_t value);
vint16m1_t __riscv_vlmul_ext_v_i16mf2_i16m1(vint16mf2_t value);
vint16m2_t __riscv_vlmul_ext_v_i16mf2_i16m2(vint16mf2_t value);
vint16m4_t __riscv_vlmul_ext_v_i16mf2_i16m4(vint16mf2_t value);
vint16m8_t __riscv_vlmul_ext_v_i16mf2_i16m8(vint16mf2_t value);
vint16m2_t __riscv_vlmul_ext_v_i16m1_i16m2(vint16m1_t value);
vint16m4_t __riscv_vlmul_ext_v_i16m1_i16m4(vint16m1_t value);
vint16m8_t __riscv_vlmul_ext_v_i16m1_i16m8(vint16m1_t value);
vint16m4_t __riscv_vlmul_ext_v_i16m2_i16m4(vint16m2_t value);
vint16m8_t __riscv_vlmul_ext_v_i16m2_i16m8(vint16m2_t value);
vint16m8_t __riscv_vlmul_ext_v_i16m4_i16m8(vint16m4_t value);
vint32m1_t __riscv_vlmul_ext_v_i32mf2_i32m1(vint32mf2_t value);
vint32m2_t __riscv_vlmul_ext_v_i32mf2_i32m2(vint32mf2_t value);
vint32m4_t __riscv_vlmul_ext_v_i32mf2_i32m4(vint32mf2_t value);
vint32m8_t __riscv_vlmul_ext_v_i32mf2_i32m8(vint32mf2_t value);
vint32m2_t __riscv_vlmul_ext_v_i32m1_i32m2(vint32m1_t value);
vint32m4_t __riscv_vlmul_ext_v_i32m1_i32m4(vint32m1_t value);
vint32m8_t __riscv_vlmul_ext_v_i32m1_i32m8(vint32m1_t value);
vint32m4_t __riscv_vlmul_ext_v_i32m2_i32m4(vint32m2_t value);
vint32m8_t __riscv_vlmul_ext_v_i32m2_i32m8(vint32m2_t value);
vint32m8_t __riscv_vlmul_ext_v_i32m4_i32m8(vint32m4_t value);
vint64m2_t __riscv_vlmul_ext_v_i64m1_i64m2(vint64m1_t value);
vint64m4_t __riscv_vlmul_ext_v_i64m1_i64m4(vint64m1_t value);
vint64m8_t __riscv_vlmul_ext_v_i64m1_i64m8(vint64m1_t value);
vint64m4_t __riscv_vlmul_ext_v_i64m2_i64m4(vint64m2_t value);
vint64m8_t __riscv_vlmul_ext_v_i64m2_i64m8(vint64m2_t value);
vint64m8_t __riscv_vlmul_ext_v_i64m4_i64m8(vint64m4_t value);
vuint8mf4_t __riscv_vlmul_ext_v_u8mf8_u8mf4(vuint8mf8_t value);
vuint8mf2_t __riscv_vlmul_ext_v_u8mf8_u8mf2(vuint8mf8_t value);
vuint8m1_t __riscv_vlmul_ext_v_u8mf8_u8m1(vuint8mf8_t value);
vuint8m2_t __riscv_vlmul_ext_v_u8mf8_u8m2(vuint8mf8_t value);
vuint8m4_t __riscv_vlmul_ext_v_u8mf8_u8m4(vuint8mf8_t value);
vuint8m8_t __riscv_vlmul_ext_v_u8mf8_u8m8(vuint8mf8_t value);
vuint8mf2_t __riscv_vlmul_ext_v_u8mf4_u8mf2(vuint8mf4_t value);
vuint8m1_t __riscv_vlmul_ext_v_u8mf4_u8m1(vuint8mf4_t value);
vuint8m2_t __riscv_vlmul_ext_v_u8mf4_u8m2(vuint8mf4_t value);
vuint8m4_t __riscv_vlmul_ext_v_u8mf4_u8m4(vuint8mf4_t value);
vuint8m8_t __riscv_vlmul_ext_v_u8mf4_u8m8(vuint8mf4_t value);
vuint8m1_t __riscv_vlmul_ext_v_u8mf2_u8m1(vuint8mf2_t value);
vuint8m2_t __riscv_vlmul_ext_v_u8mf2_u8m2(vuint8mf2_t value);
vuint8m4_t __riscv_vlmul_ext_v_u8mf2_u8m4(vuint8mf2_t value);
vuint8m8_t __riscv_vlmul_ext_v_u8mf2_u8m8(vuint8mf2_t value);
vuint8m2_t __riscv_vlmul_ext_v_u8m1_u8m2(vuint8m1_t value);
vuint8m4_t __riscv_vlmul_ext_v_u8m1_u8m4(vuint8m1_t value);
vuint8m8_t __riscv_vlmul_ext_v_u8m1_u8m8(vuint8m1_t value);
vuint8m4_t __riscv_vlmul_ext_v_u8m2_u8m4(vuint8m2_t value);
vuint8m8_t __riscv_vlmul_ext_v_u8m2_u8m8(vuint8m2_t value);
vuint8m8_t __riscv_vlmul_ext_v_u8m4_u8m8(vuint8m4_t value);
vuint16mf2_t __riscv_vlmul_ext_v_u16mf4_u16mf2(vuint16mf4_t value);
vuint16m1_t __riscv_vlmul_ext_v_u16mf4_u16m1(vuint16mf4_t value);
vuint16m2_t __riscv_vlmul_ext_v_u16mf4_u16m2(vuint16mf4_t value);
vuint16m4_t __riscv_vlmul_ext_v_u16mf4_u16m4(vuint16mf4_t value);
vuint16m8_t __riscv_vlmul_ext_v_u16mf4_u16m8(vuint16mf4_t value);
vuint16m1_t __riscv_vlmul_ext_v_u16mf2_u16m1(vuint16mf2_t value);
vuint16m2_t __riscv_vlmul_ext_v_u16mf2_u16m2(vuint16mf2_t value);
vuint16m4_t __riscv_vlmul_ext_v_u16mf2_u16m4(vuint16mf2_t value);
vuint16m8_t __riscv_vlmul_ext_v_u16mf2_u16m8(vuint16mf2_t value);
vuint16m2_t __riscv_vlmul_ext_v_u16m1_u16m2(vuint16m1_t value);
vuint16m4_t __riscv_vlmul_ext_v_u16m1_u16m4(vuint16m1_t value);
vuint16m8_t __riscv_vlmul_ext_v_u16m1_u16m8(vuint16m1_t value);
vuint16m4_t __riscv_vlmul_ext_v_u16m2_u16m4(vuint16m2_t value);
vuint16m8_t __riscv_vlmul_ext_v_u16m2_u16m8(vuint16m2_t value);
vuint16m8_t __riscv_vlmul_ext_v_u16m4_u16m8(vuint16m4_t value);
vuint32m1_t __riscv_vlmul_ext_v_u32mf2_u32m1(vuint32mf2_t value);
vuint32m2_t __riscv_vlmul_ext_v_u32mf2_u32m2(vuint32mf2_t value);
vuint32m4_t __riscv_vlmul_ext_v_u32mf2_u32m4(vuint32mf2_t value);
vuint32m8_t __riscv_vlmul_ext_v_u32mf2_u32m8(vuint32mf2_t value);
vuint32m2_t __riscv_vlmul_ext_v_u32m1_u32m2(vuint32m1_t value);
vuint32m4_t __riscv_vlmul_ext_v_u32m1_u32m4(vuint32m1_t value);
vuint32m8_t __riscv_vlmul_ext_v_u32m1_u32m8(vuint32m1_t value);
vuint32m4_t __riscv_vlmul_ext_v_u32m2_u32m4(vuint32m2_t value);
vuint32m8_t __riscv_vlmul_ext_v_u32m2_u32m8(vuint32m2_t value);
vuint32m8_t __riscv_vlmul_ext_v_u32m4_u32m8(vuint32m4_t value);
vuint64m2_t __riscv_vlmul_ext_v_u64m1_u64m2(vuint64m1_t value);
vuint64m4_t __riscv_vlmul_ext_v_u64m1_u64m4(vuint64m1_t value);
vuint64m8_t __riscv_vlmul_ext_v_u64m1_u64m8(vuint64m1_t value);
vuint64m4_t __riscv_vlmul_ext_v_u64m2_u64m4(vuint64m2_t value);
vuint64m8_t __riscv_vlmul_ext_v_u64m2_u64m8(vuint64m2_t value);
vuint64m8_t __riscv_vlmul_ext_v_u64m4_u64m8(vuint64m4_t value);
----

[[vector-lmul-truncation]]
==== Vector LMUL Truncation Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vlmul_trunc_v_f16mf2_f16mf4(vfloat16mf2_t value);
vfloat16mf4_t __riscv_vlmul_trunc_v_f16m1_f16mf4(vfloat16m1_t value);
vfloat16mf2_t __riscv_vlmul_trunc_v_f16m1_f16mf2(vfloat16m1_t value);
vfloat16mf4_t __riscv_vlmul_trunc_v_f16m2_f16mf4(vfloat16m2_t value);
vfloat16mf2_t __riscv_vlmul_trunc_v_f16m2_f16mf2(vfloat16m2_t value);
vfloat16m1_t __riscv_vlmul_trunc_v_f16m2_f16m1(vfloat16m2_t value);
vfloat16mf4_t __riscv_vlmul_trunc_v_f16m4_f16mf4(vfloat16m4_t value);
vfloat16mf2_t __riscv_vlmul_trunc_v_f16m4_f16mf2(vfloat16m4_t value);
vfloat16m1_t __riscv_vlmul_trunc_v_f16m4_f16m1(vfloat16m4_t value);
vfloat16m2_t __riscv_vlmul_trunc_v_f16m4_f16m2(vfloat16m4_t value);
vfloat16mf4_t __riscv_vlmul_trunc_v_f16m8_f16mf4(vfloat16m8_t value);
vfloat16mf2_t __riscv_vlmul_trunc_v_f16m8_f16mf2(vfloat16m8_t value);
vfloat16m1_t __riscv_vlmul_trunc_v_f16m8_f16m1(vfloat16m8_t value);
vfloat16m2_t __riscv_vlmul_trunc_v_f16m8_f16m2(vfloat16m8_t value);
vfloat16m4_t __riscv_vlmul_trunc_v_f16m8_f16m4(vfloat16m8_t value);
vfloat32mf2_t __riscv_vlmul_trunc_v_f32m1_f32mf2(vfloat32m1_t value);
vfloat32mf2_t __riscv_vlmul_trunc_v_f32m2_f32mf2(vfloat32m2_t value);
vfloat32m1_t __riscv_vlmul_trunc_v_f32m2_f32m1(vfloat32m2_t value);
vfloat32mf2_t __riscv_vlmul_trunc_v_f32m4_f32mf2(vfloat32m4_t value);
vfloat32m1_t __riscv_vlmul_trunc_v_f32m4_f32m1(vfloat32m4_t value);
vfloat32m2_t __riscv_vlmul_trunc_v_f32m4_f32m2(vfloat32m4_t value);
vfloat32mf2_t __riscv_vlmul_trunc_v_f32m8_f32mf2(vfloat32m8_t value);
vfloat32m1_t __riscv_vlmul_trunc_v_f32m8_f32m1(vfloat32m8_t value);
vfloat32m2_t __riscv_vlmul_trunc_v_f32m8_f32m2(vfloat32m8_t value);
vfloat32m4_t __riscv_vlmul_trunc_v_f32m8_f32m4(vfloat32m8_t value);
vfloat64m1_t __riscv_vlmul_trunc_v_f64m2_f64m1(vfloat64m2_t value);
vfloat64m1_t __riscv_vlmul_trunc_v_f64m4_f64m1(vfloat64m4_t value);
vfloat64m2_t __riscv_vlmul_trunc_v_f64m4_f64m2(vfloat64m4_t value);
vfloat64m1_t __riscv_vlmul_trunc_v_f64m8_f64m1(vfloat64m8_t value);
vfloat64m2_t __riscv_vlmul_trunc_v_f64m8_f64m2(vfloat64m8_t value);
vfloat64m4_t __riscv_vlmul_trunc_v_f64m8_f64m4(vfloat64m8_t value);
vint8mf8_t __riscv_vlmul_trunc_v_i8mf4_i8mf8(vint8mf4_t value);
vint8mf8_t __riscv_vlmul_trunc_v_i8mf2_i8mf8(vint8mf2_t value);
vint8mf4_t __riscv_vlmul_trunc_v_i8mf2_i8mf4(vint8mf2_t value);
vint8mf8_t __riscv_vlmul_trunc_v_i8m1_i8mf8(vint8m1_t value);
vint8mf4_t __riscv_vlmul_trunc_v_i8m1_i8mf4(vint8m1_t value);
vint8mf2_t __riscv_vlmul_trunc_v_i8m1_i8mf2(vint8m1_t value);
vint8mf8_t __riscv_vlmul_trunc_v_i8m2_i8mf8(vint8m2_t value);
vint8mf4_t __riscv_vlmul_trunc_v_i8m2_i8mf4(vint8m2_t value);
vint8mf2_t __riscv_vlmul_trunc_v_i8m2_i8mf2(vint8m2_t value);
vint8m1_t __riscv_vlmul_trunc_v_i8m2_i8m1(vint8m2_t value);
vint8mf8_t __riscv_vlmul_trunc_v_i8m4_i8mf8(vint8m4_t value);
vint8mf4_t __riscv_vlmul_trunc_v_i8m4_i8mf4(vint8m4_t value);
vint8mf2_t __riscv_vlmul_trunc_v_i8m4_i8mf2(vint8m4_t value);
vint8m1_t __riscv_vlmul_trunc_v_i8m4_i8m1(vint8m4_t value);
vint8m2_t __riscv_vlmul_trunc_v_i8m4_i8m2(vint8m4_t value);
vint8mf8_t __riscv_vlmul_trunc_v_i8m8_i8mf8(vint8m8_t value);
vint8mf4_t __riscv_vlmul_trunc_v_i8m8_i8mf4(vint8m8_t value);
vint8mf2_t __riscv_vlmul_trunc_v_i8m8_i8mf2(vint8m8_t value);
vint8m1_t __riscv_vlmul_trunc_v_i8m8_i8m1(vint8m8_t value);
vint8m2_t __riscv_vlmul_trunc_v_i8m8_i8m2(vint8m8_t value);
vint8m4_t __riscv_vlmul_trunc_v_i8m8_i8m4(vint8m8_t value);
vint16mf4_t __riscv_vlmul_trunc_v_i16mf2_i16mf4(vint16mf2_t value);
vint16mf4_t __riscv_vlmul_trunc_v_i16m1_i16mf4(vint16m1_t value);
vint16mf2_t __riscv_vlmul_trunc_v_i16m1_i16mf2(vint16m1_t value);
vint16mf4_t __riscv_vlmul_trunc_v_i16m2_i16mf4(vint16m2_t value);
vint16mf2_t __riscv_vlmul_trunc_v_i16m2_i16mf2(vint16m2_t value);
vint16m1_t __riscv_vlmul_trunc_v_i16m2_i16m1(vint16m2_t value);
vint16mf4_t __riscv_vlmul_trunc_v_i16m4_i16mf4(vint16m4_t value);
vint16mf2_t __riscv_vlmul_trunc_v_i16m4_i16mf2(vint16m4_t value);
vint16m1_t __riscv_vlmul_trunc_v_i16m4_i16m1(vint16m4_t value);
vint16m2_t __riscv_vlmul_trunc_v_i16m4_i16m2(vint16m4_t value);
vint16mf4_t __riscv_vlmul_trunc_v_i16m8_i16mf4(vint16m8_t value);
vint16mf2_t __riscv_vlmul_trunc_v_i16m8_i16mf2(vint16m8_t value);
vint16m1_t __riscv_vlmul_trunc_v_i16m8_i16m1(vint16m8_t value);
vint16m2_t __riscv_vlmul_trunc_v_i16m8_i16m2(vint16m8_t value);
vint16m4_t __riscv_vlmul_trunc_v_i16m8_i16m4(vint16m8_t value);
vint32mf2_t __riscv_vlmul_trunc_v_i32m1_i32mf2(vint32m1_t value);
vint32mf2_t __riscv_vlmul_trunc_v_i32m2_i32mf2(vint32m2_t value);
vint32m1_t __riscv_vlmul_trunc_v_i32m2_i32m1(vint32m2_t value);
vint32mf2_t __riscv_vlmul_trunc_v_i32m4_i32mf2(vint32m4_t value);
vint32m1_t __riscv_vlmul_trunc_v_i32m4_i32m1(vint32m4_t value);
vint32m2_t __riscv_vlmul_trunc_v_i32m4_i32m2(vint32m4_t value);
vint32mf2_t __riscv_vlmul_trunc_v_i32m8_i32mf2(vint32m8_t value);
vint32m1_t __riscv_vlmul_trunc_v_i32m8_i32m1(vint32m8_t value);
vint32m2_t __riscv_vlmul_trunc_v_i32m8_i32m2(vint32m8_t value);
vint32m4_t __riscv_vlmul_trunc_v_i32m8_i32m4(vint32m8_t value);
vint64m1_t __riscv_vlmul_trunc_v_i64m2_i64m1(vint64m2_t value);
vint64m1_t __riscv_vlmul_trunc_v_i64m4_i64m1(vint64m4_t value);
vint64m2_t __riscv_vlmul_trunc_v_i64m4_i64m2(vint64m4_t value);
vint64m1_t __riscv_vlmul_trunc_v_i64m8_i64m1(vint64m8_t value);
vint64m2_t __riscv_vlmul_trunc_v_i64m8_i64m2(vint64m8_t value);
vint64m4_t __riscv_vlmul_trunc_v_i64m8_i64m4(vint64m8_t value);
vuint8mf8_t __riscv_vlmul_trunc_v_u8mf4_u8mf8(vuint8mf4_t value);
vuint8mf8_t __riscv_vlmul_trunc_v_u8mf2_u8mf8(vuint8mf2_t value);
vuint8mf4_t __riscv_vlmul_trunc_v_u8mf2_u8mf4(vuint8mf2_t value);
vuint8mf8_t __riscv_vlmul_trunc_v_u8m1_u8mf8(vuint8m1_t value);
vuint8mf4_t __riscv_vlmul_trunc_v_u8m1_u8mf4(vuint8m1_t value);
vuint8mf2_t __riscv_vlmul_trunc_v_u8m1_u8mf2(vuint8m1_t value);
vuint8mf8_t __riscv_vlmul_trunc_v_u8m2_u8mf8(vuint8m2_t value);
vuint8mf4_t __riscv_vlmul_trunc_v_u8m2_u8mf4(vuint8m2_t value);
vuint8mf2_t __riscv_vlmul_trunc_v_u8m2_u8mf2(vuint8m2_t value);
vuint8m1_t __riscv_vlmul_trunc_v_u8m2_u8m1(vuint8m2_t value);
vuint8mf8_t __riscv_vlmul_trunc_v_u8m4_u8mf8(vuint8m4_t value);
vuint8mf4_t __riscv_vlmul_trunc_v_u8m4_u8mf4(vuint8m4_t value);
vuint8mf2_t __riscv_vlmul_trunc_v_u8m4_u8mf2(vuint8m4_t value);
vuint8m1_t __riscv_vlmul_trunc_v_u8m4_u8m1(vuint8m4_t value);
vuint8m2_t __riscv_vlmul_trunc_v_u8m4_u8m2(vuint8m4_t value);
vuint8mf8_t __riscv_vlmul_trunc_v_u8m8_u8mf8(vuint8m8_t value);
vuint8mf4_t __riscv_vlmul_trunc_v_u8m8_u8mf4(vuint8m8_t value);
vuint8mf2_t __riscv_vlmul_trunc_v_u8m8_u8mf2(vuint8m8_t value);
vuint8m1_t __riscv_vlmul_trunc_v_u8m8_u8m1(vuint8m8_t value);
vuint8m2_t __riscv_vlmul_trunc_v_u8m8_u8m2(vuint8m8_t value);
vuint8m4_t __riscv_vlmul_trunc_v_u8m8_u8m4(vuint8m8_t value);
vuint16mf4_t __riscv_vlmul_trunc_v_u16mf2_u16mf4(vuint16mf2_t value);
vuint16mf4_t __riscv_vlmul_trunc_v_u16m1_u16mf4(vuint16m1_t value);
vuint16mf2_t __riscv_vlmul_trunc_v_u16m1_u16mf2(vuint16m1_t value);
vuint16mf4_t __riscv_vlmul_trunc_v_u16m2_u16mf4(vuint16m2_t value);
vuint16mf2_t __riscv_vlmul_trunc_v_u16m2_u16mf2(vuint16m2_t value);
vuint16m1_t __riscv_vlmul_trunc_v_u16m2_u16m1(vuint16m2_t value);
vuint16mf4_t __riscv_vlmul_trunc_v_u16m4_u16mf4(vuint16m4_t value);
vuint16mf2_t __riscv_vlmul_trunc_v_u16m4_u16mf2(vuint16m4_t value);
vuint16m1_t __riscv_vlmul_trunc_v_u16m4_u16m1(vuint16m4_t value);
vuint16m2_t __riscv_vlmul_trunc_v_u16m4_u16m2(vuint16m4_t value);
vuint16mf4_t __riscv_vlmul_trunc_v_u16m8_u16mf4(vuint16m8_t value);
vuint16mf2_t __riscv_vlmul_trunc_v_u16m8_u16mf2(vuint16m8_t value);
vuint16m1_t __riscv_vlmul_trunc_v_u16m8_u16m1(vuint16m8_t value);
vuint16m2_t __riscv_vlmul_trunc_v_u16m8_u16m2(vuint16m8_t value);
vuint16m4_t __riscv_vlmul_trunc_v_u16m8_u16m4(vuint16m8_t value);
vuint32mf2_t __riscv_vlmul_trunc_v_u32m1_u32mf2(vuint32m1_t value);
vuint32mf2_t __riscv_vlmul_trunc_v_u32m2_u32mf2(vuint32m2_t value);
vuint32m1_t __riscv_vlmul_trunc_v_u32m2_u32m1(vuint32m2_t value);
vuint32mf2_t __riscv_vlmul_trunc_v_u32m4_u32mf2(vuint32m4_t value);
vuint32m1_t __riscv_vlmul_trunc_v_u32m4_u32m1(vuint32m4_t value);
vuint32m2_t __riscv_vlmul_trunc_v_u32m4_u32m2(vuint32m4_t value);
vuint32mf2_t __riscv_vlmul_trunc_v_u32m8_u32mf2(vuint32m8_t value);
vuint32m1_t __riscv_vlmul_trunc_v_u32m8_u32m1(vuint32m8_t value);
vuint32m2_t __riscv_vlmul_trunc_v_u32m8_u32m2(vuint32m8_t value);
vuint32m4_t __riscv_vlmul_trunc_v_u32m8_u32m4(vuint32m8_t value);
vuint64m1_t __riscv_vlmul_trunc_v_u64m2_u64m1(vuint64m2_t value);
vuint64m1_t __riscv_vlmul_trunc_v_u64m4_u64m1(vuint64m4_t value);
vuint64m2_t __riscv_vlmul_trunc_v_u64m4_u64m2(vuint64m4_t value);
vuint64m1_t __riscv_vlmul_trunc_v_u64m8_u64m1(vuint64m8_t value);
vuint64m2_t __riscv_vlmul_trunc_v_u64m8_u64m2(vuint64m8_t value);
vuint64m4_t __riscv_vlmul_trunc_v_u64m8_u64m4(vuint64m8_t value);
----

[[vector-initialization]]
==== Vector Initialization Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vundefined_f16mf4();
vfloat16mf2_t __riscv_vundefined_f16mf2();
vfloat16m1_t __riscv_vundefined_f16m1();
vfloat16m2_t __riscv_vundefined_f16m2();
vfloat16m4_t __riscv_vundefined_f16m4();
vfloat16m8_t __riscv_vundefined_f16m8();
vfloat32mf2_t __riscv_vundefined_f32mf2();
vfloat32m1_t __riscv_vundefined_f32m1();
vfloat32m2_t __riscv_vundefined_f32m2();
vfloat32m4_t __riscv_vundefined_f32m4();
vfloat32m8_t __riscv_vundefined_f32m8();
vfloat64m1_t __riscv_vundefined_f64m1();
vfloat64m2_t __riscv_vundefined_f64m2();
vfloat64m4_t __riscv_vundefined_f64m4();
vfloat64m8_t __riscv_vundefined_f64m8();
vint8mf8_t __riscv_vundefined_i8mf8();
vint8mf4_t __riscv_vundefined_i8mf4();
vint8mf2_t __riscv_vundefined_i8mf2();
vint8m1_t __riscv_vundefined_i8m1();
vint8m2_t __riscv_vundefined_i8m2();
vint8m4_t __riscv_vundefined_i8m4();
vint8m8_t __riscv_vundefined_i8m8();
vint16mf4_t __riscv_vundefined_i16mf4();
vint16mf2_t __riscv_vundefined_i16mf2();
vint16m1_t __riscv_vundefined_i16m1();
vint16m2_t __riscv_vundefined_i16m2();
vint16m4_t __riscv_vundefined_i16m4();
vint16m8_t __riscv_vundefined_i16m8();
vint32mf2_t __riscv_vundefined_i32mf2();
vint32m1_t __riscv_vundefined_i32m1();
vint32m2_t __riscv_vundefined_i32m2();
vint32m4_t __riscv_vundefined_i32m4();
vint32m8_t __riscv_vundefined_i32m8();
vint64m1_t __riscv_vundefined_i64m1();
vint64m2_t __riscv_vundefined_i64m2();
vint64m4_t __riscv_vundefined_i64m4();
vint64m8_t __riscv_vundefined_i64m8();
vuint8mf8_t __riscv_vundefined_u8mf8();
vuint8mf4_t __riscv_vundefined_u8mf4();
vuint8mf2_t __riscv_vundefined_u8mf2();
vuint8m1_t __riscv_vundefined_u8m1();
vuint8m2_t __riscv_vundefined_u8m2();
vuint8m4_t __riscv_vundefined_u8m4();
vuint8m8_t __riscv_vundefined_u8m8();
vuint16mf4_t __riscv_vundefined_u16mf4();
vuint16mf2_t __riscv_vundefined_u16mf2();
vuint16m1_t __riscv_vundefined_u16m1();
vuint16m2_t __riscv_vundefined_u16m2();
vuint16m4_t __riscv_vundefined_u16m4();
vuint16m8_t __riscv_vundefined_u16m8();
vuint32mf2_t __riscv_vundefined_u32mf2();
vuint32m1_t __riscv_vundefined_u32m1();
vuint32m2_t __riscv_vundefined_u32m2();
vuint32m4_t __riscv_vundefined_u32m4();
vuint32m8_t __riscv_vundefined_u32m8();
vuint64m1_t __riscv_vundefined_u64m1();
vuint64m2_t __riscv_vundefined_u64m2();
vuint64m4_t __riscv_vundefined_u64m4();
vuint64m8_t __riscv_vundefined_u64m8();
vfloat16mf4x2_t __riscv_vundefined_f16mf4x2();
vfloat16mf4x3_t __riscv_vundefined_f16mf4x3();
vfloat16mf4x4_t __riscv_vundefined_f16mf4x4();
vfloat16mf4x5_t __riscv_vundefined_f16mf4x5();
vfloat16mf4x6_t __riscv_vundefined_f16mf4x6();
vfloat16mf4x7_t __riscv_vundefined_f16mf4x7();
vfloat16mf4x8_t __riscv_vundefined_f16mf4x8();
vfloat16mf2x2_t __riscv_vundefined_f16mf2x2();
vfloat16mf2x3_t __riscv_vundefined_f16mf2x3();
vfloat16mf2x4_t __riscv_vundefined_f16mf2x4();
vfloat16mf2x5_t __riscv_vundefined_f16mf2x5();
vfloat16mf2x6_t __riscv_vundefined_f16mf2x6();
vfloat16mf2x7_t __riscv_vundefined_f16mf2x7();
vfloat16mf2x8_t __riscv_vundefined_f16mf2x8();
vfloat16m1x2_t __riscv_vundefined_f16m1x2();
vfloat16m1x3_t __riscv_vundefined_f16m1x3();
vfloat16m1x4_t __riscv_vundefined_f16m1x4();
vfloat16m1x5_t __riscv_vundefined_f16m1x5();
vfloat16m1x6_t __riscv_vundefined_f16m1x6();
vfloat16m1x7_t __riscv_vundefined_f16m1x7();
vfloat16m1x8_t __riscv_vundefined_f16m1x8();
vfloat16m2x2_t __riscv_vundefined_f16m2x2();
vfloat16m2x3_t __riscv_vundefined_f16m2x3();
vfloat16m2x4_t __riscv_vundefined_f16m2x4();
vfloat16m4x2_t __riscv_vundefined_f16m4x2();
vfloat32mf2x2_t __riscv_vundefined_f32mf2x2();
vfloat32mf2x3_t __riscv_vundefined_f32mf2x3();
vfloat32mf2x4_t __riscv_vundefined_f32mf2x4();
vfloat32mf2x5_t __riscv_vundefined_f32mf2x5();
vfloat32mf2x6_t __riscv_vundefined_f32mf2x6();
vfloat32mf2x7_t __riscv_vundefined_f32mf2x7();
vfloat32mf2x8_t __riscv_vundefined_f32mf2x8();
vfloat32m1x2_t __riscv_vundefined_f32m1x2();
vfloat32m1x3_t __riscv_vundefined_f32m1x3();
vfloat32m1x4_t __riscv_vundefined_f32m1x4();
vfloat32m1x5_t __riscv_vundefined_f32m1x5();
vfloat32m1x6_t __riscv_vundefined_f32m1x6();
vfloat32m1x7_t __riscv_vundefined_f32m1x7();
vfloat32m1x8_t __riscv_vundefined_f32m1x8();
vfloat32m2x2_t __riscv_vundefined_f32m2x2();
vfloat32m2x3_t __riscv_vundefined_f32m2x3();
vfloat32m2x4_t __riscv_vundefined_f32m2x4();
vfloat32m4x2_t __riscv_vundefined_f32m4x2();
vfloat64m1x2_t __riscv_vundefined_f64m1x2();
vfloat64m1x3_t __riscv_vundefined_f64m1x3();
vfloat64m1x4_t __riscv_vundefined_f64m1x4();
vfloat64m1x5_t __riscv_vundefined_f64m1x5();
vfloat64m1x6_t __riscv_vundefined_f64m1x6();
vfloat64m1x7_t __riscv_vundefined_f64m1x7();
vfloat64m1x8_t __riscv_vundefined_f64m1x8();
vfloat64m2x2_t __riscv_vundefined_f64m2x2();
vfloat64m2x3_t __riscv_vundefined_f64m2x3();
vfloat64m2x4_t __riscv_vundefined_f64m2x4();
vfloat64m4x2_t __riscv_vundefined_f64m4x2();
vint8mf8x2_t __riscv_vundefined_i8mf8x2();
vint8mf8x3_t __riscv_vundefined_i8mf8x3();
vint8mf8x4_t __riscv_vundefined_i8mf8x4();
vint8mf8x5_t __riscv_vundefined_i8mf8x5();
vint8mf8x6_t __riscv_vundefined_i8mf8x6();
vint8mf8x7_t __riscv_vundefined_i8mf8x7();
vint8mf8x8_t __riscv_vundefined_i8mf8x8();
vint8mf4x2_t __riscv_vundefined_i8mf4x2();
vint8mf4x3_t __riscv_vundefined_i8mf4x3();
vint8mf4x4_t __riscv_vundefined_i8mf4x4();
vint8mf4x5_t __riscv_vundefined_i8mf4x5();
vint8mf4x6_t __riscv_vundefined_i8mf4x6();
vint8mf4x7_t __riscv_vundefined_i8mf4x7();
vint8mf4x8_t __riscv_vundefined_i8mf4x8();
vint8mf2x2_t __riscv_vundefined_i8mf2x2();
vint8mf2x3_t __riscv_vundefined_i8mf2x3();
vint8mf2x4_t __riscv_vundefined_i8mf2x4();
vint8mf2x5_t __riscv_vundefined_i8mf2x5();
vint8mf2x6_t __riscv_vundefined_i8mf2x6();
vint8mf2x7_t __riscv_vundefined_i8mf2x7();
vint8mf2x8_t __riscv_vundefined_i8mf2x8();
vint8m1x2_t __riscv_vundefined_i8m1x2();
vint8m1x3_t __riscv_vundefined_i8m1x3();
vint8m1x4_t __riscv_vundefined_i8m1x4();
vint8m1x5_t __riscv_vundefined_i8m1x5();
vint8m1x6_t __riscv_vundefined_i8m1x6();
vint8m1x7_t __riscv_vundefined_i8m1x7();
vint8m1x8_t __riscv_vundefined_i8m1x8();
vint8m2x2_t __riscv_vundefined_i8m2x2();
vint8m2x3_t __riscv_vundefined_i8m2x3();
vint8m2x4_t __riscv_vundefined_i8m2x4();
vint8m4x2_t __riscv_vundefined_i8m4x2();
vint16mf4x2_t __riscv_vundefined_i16mf4x2();
vint16mf4x3_t __riscv_vundefined_i16mf4x3();
vint16mf4x4_t __riscv_vundefined_i16mf4x4();
vint16mf4x5_t __riscv_vundefined_i16mf4x5();
vint16mf4x6_t __riscv_vundefined_i16mf4x6();
vint16mf4x7_t __riscv_vundefined_i16mf4x7();
vint16mf4x8_t __riscv_vundefined_i16mf4x8();
vint16mf2x2_t __riscv_vundefined_i16mf2x2();
vint16mf2x3_t __riscv_vundefined_i16mf2x3();
vint16mf2x4_t __riscv_vundefined_i16mf2x4();
vint16mf2x5_t __riscv_vundefined_i16mf2x5();
vint16mf2x6_t __riscv_vundefined_i16mf2x6();
vint16mf2x7_t __riscv_vundefined_i16mf2x7();
vint16mf2x8_t __riscv_vundefined_i16mf2x8();
vint16m1x2_t __riscv_vundefined_i16m1x2();
vint16m1x3_t __riscv_vundefined_i16m1x3();
vint16m1x4_t __riscv_vundefined_i16m1x4();
vint16m1x5_t __riscv_vundefined_i16m1x5();
vint16m1x6_t __riscv_vundefined_i16m1x6();
vint16m1x7_t __riscv_vundefined_i16m1x7();
vint16m1x8_t __riscv_vundefined_i16m1x8();
vint16m2x2_t __riscv_vundefined_i16m2x2();
vint16m2x3_t __riscv_vundefined_i16m2x3();
vint16m2x4_t __riscv_vundefined_i16m2x4();
vint16m4x2_t __riscv_vundefined_i16m4x2();
vint32mf2x2_t __riscv_vundefined_i32mf2x2();
vint32mf2x3_t __riscv_vundefined_i32mf2x3();
vint32mf2x4_t __riscv_vundefined_i32mf2x4();
vint32mf2x5_t __riscv_vundefined_i32mf2x5();
vint32mf2x6_t __riscv_vundefined_i32mf2x6();
vint32mf2x7_t __riscv_vundefined_i32mf2x7();
vint32mf2x8_t __riscv_vundefined_i32mf2x8();
vint32m1x2_t __riscv_vundefined_i32m1x2();
vint32m1x3_t __riscv_vundefined_i32m1x3();
vint32m1x4_t __riscv_vundefined_i32m1x4();
vint32m1x5_t __riscv_vundefined_i32m1x5();
vint32m1x6_t __riscv_vundefined_i32m1x6();
vint32m1x7_t __riscv_vundefined_i32m1x7();
vint32m1x8_t __riscv_vundefined_i32m1x8();
vint32m2x2_t __riscv_vundefined_i32m2x2();
vint32m2x3_t __riscv_vundefined_i32m2x3();
vint32m2x4_t __riscv_vundefined_i32m2x4();
vint32m4x2_t __riscv_vundefined_i32m4x2();
vint64m1x2_t __riscv_vundefined_i64m1x2();
vint64m1x3_t __riscv_vundefined_i64m1x3();
vint64m1x4_t __riscv_vundefined_i64m1x4();
vint64m1x5_t __riscv_vundefined_i64m1x5();
vint64m1x6_t __riscv_vundefined_i64m1x6();
vint64m1x7_t __riscv_vundefined_i64m1x7();
vint64m1x8_t __riscv_vundefined_i64m1x8();
vint64m2x2_t __riscv_vundefined_i64m2x2();
vint64m2x3_t __riscv_vundefined_i64m2x3();
vint64m2x4_t __riscv_vundefined_i64m2x4();
vint64m4x2_t __riscv_vundefined_i64m4x2();
vuint8mf8x2_t __riscv_vundefined_u8mf8x2();
vuint8mf8x3_t __riscv_vundefined_u8mf8x3();
vuint8mf8x4_t __riscv_vundefined_u8mf8x4();
vuint8mf8x5_t __riscv_vundefined_u8mf8x5();
vuint8mf8x6_t __riscv_vundefined_u8mf8x6();
vuint8mf8x7_t __riscv_vundefined_u8mf8x7();
vuint8mf8x8_t __riscv_vundefined_u8mf8x8();
vuint8mf4x2_t __riscv_vundefined_u8mf4x2();
vuint8mf4x3_t __riscv_vundefined_u8mf4x3();
vuint8mf4x4_t __riscv_vundefined_u8mf4x4();
vuint8mf4x5_t __riscv_vundefined_u8mf4x5();
vuint8mf4x6_t __riscv_vundefined_u8mf4x6();
vuint8mf4x7_t __riscv_vundefined_u8mf4x7();
vuint8mf4x8_t __riscv_vundefined_u8mf4x8();
vuint8mf2x2_t __riscv_vundefined_u8mf2x2();
vuint8mf2x3_t __riscv_vundefined_u8mf2x3();
vuint8mf2x4_t __riscv_vundefined_u8mf2x4();
vuint8mf2x5_t __riscv_vundefined_u8mf2x5();
vuint8mf2x6_t __riscv_vundefined_u8mf2x6();
vuint8mf2x7_t __riscv_vundefined_u8mf2x7();
vuint8mf2x8_t __riscv_vundefined_u8mf2x8();
vuint8m1x2_t __riscv_vundefined_u8m1x2();
vuint8m1x3_t __riscv_vundefined_u8m1x3();
vuint8m1x4_t __riscv_vundefined_u8m1x4();
vuint8m1x5_t __riscv_vundefined_u8m1x5();
vuint8m1x6_t __riscv_vundefined_u8m1x6();
vuint8m1x7_t __riscv_vundefined_u8m1x7();
vuint8m1x8_t __riscv_vundefined_u8m1x8();
vuint8m2x2_t __riscv_vundefined_u8m2x2();
vuint8m2x3_t __riscv_vundefined_u8m2x3();
vuint8m2x4_t __riscv_vundefined_u8m2x4();
vuint8m4x2_t __riscv_vundefined_u8m4x2();
vuint16mf4x2_t __riscv_vundefined_u16mf4x2();
vuint16mf4x3_t __riscv_vundefined_u16mf4x3();
vuint16mf4x4_t __riscv_vundefined_u16mf4x4();
vuint16mf4x5_t __riscv_vundefined_u16mf4x5();
vuint16mf4x6_t __riscv_vundefined_u16mf4x6();
vuint16mf4x7_t __riscv_vundefined_u16mf4x7();
vuint16mf4x8_t __riscv_vundefined_u16mf4x8();
vuint16mf2x2_t __riscv_vundefined_u16mf2x2();
vuint16mf2x3_t __riscv_vundefined_u16mf2x3();
vuint16mf2x4_t __riscv_vundefined_u16mf2x4();
vuint16mf2x5_t __riscv_vundefined_u16mf2x5();
vuint16mf2x6_t __riscv_vundefined_u16mf2x6();
vuint16mf2x7_t __riscv_vundefined_u16mf2x7();
vuint16mf2x8_t __riscv_vundefined_u16mf2x8();
vuint16m1x2_t __riscv_vundefined_u16m1x2();
vuint16m1x3_t __riscv_vundefined_u16m1x3();
vuint16m1x4_t __riscv_vundefined_u16m1x4();
vuint16m1x5_t __riscv_vundefined_u16m1x5();
vuint16m1x6_t __riscv_vundefined_u16m1x6();
vuint16m1x7_t __riscv_vundefined_u16m1x7();
vuint16m1x8_t __riscv_vundefined_u16m1x8();
vuint16m2x2_t __riscv_vundefined_u16m2x2();
vuint16m2x3_t __riscv_vundefined_u16m2x3();
vuint16m2x4_t __riscv_vundefined_u16m2x4();
vuint16m4x2_t __riscv_vundefined_u16m4x2();
vuint32mf2x2_t __riscv_vundefined_u32mf2x2();
vuint32mf2x3_t __riscv_vundefined_u32mf2x3();
vuint32mf2x4_t __riscv_vundefined_u32mf2x4();
vuint32mf2x5_t __riscv_vundefined_u32mf2x5();
vuint32mf2x6_t __riscv_vundefined_u32mf2x6();
vuint32mf2x7_t __riscv_vundefined_u32mf2x7();
vuint32mf2x8_t __riscv_vundefined_u32mf2x8();
vuint32m1x2_t __riscv_vundefined_u32m1x2();
vuint32m1x3_t __riscv_vundefined_u32m1x3();
vuint32m1x4_t __riscv_vundefined_u32m1x4();
vuint32m1x5_t __riscv_vundefined_u32m1x5();
vuint32m1x6_t __riscv_vundefined_u32m1x6();
vuint32m1x7_t __riscv_vundefined_u32m1x7();
vuint32m1x8_t __riscv_vundefined_u32m1x8();
vuint32m2x2_t __riscv_vundefined_u32m2x2();
vuint32m2x3_t __riscv_vundefined_u32m2x3();
vuint32m2x4_t __riscv_vundefined_u32m2x4();
vuint32m4x2_t __riscv_vundefined_u32m4x2();
vuint64m1x2_t __riscv_vundefined_u64m1x2();
vuint64m1x3_t __riscv_vundefined_u64m1x3();
vuint64m1x4_t __riscv_vundefined_u64m1x4();
vuint64m1x5_t __riscv_vundefined_u64m1x5();
vuint64m1x6_t __riscv_vundefined_u64m1x6();
vuint64m1x7_t __riscv_vundefined_u64m1x7();
vuint64m1x8_t __riscv_vundefined_u64m1x8();
vuint64m2x2_t __riscv_vundefined_u64m2x2();
vuint64m2x3_t __riscv_vundefined_u64m2x3();
vuint64m2x4_t __riscv_vundefined_u64m2x4();
vuint64m4x2_t __riscv_vundefined_u64m4x2();
----

[[vector-insertion]]
==== Vector Insertion Intrinsics

[,c]
----
vfloat16m2_t __riscv_vset_v_f16m1_f16m2(vfloat16m2_t dest, size_t index,
                                        vfloat16m1_t value);
vfloat16m4_t __riscv_vset_v_f16m1_f16m4(vfloat16m4_t dest, size_t index,
                                        vfloat16m1_t value);
vfloat16m4_t __riscv_vset_v_f16m2_f16m4(vfloat16m4_t dest, size_t index,
                                        vfloat16m2_t value);
vfloat16m8_t __riscv_vset_v_f16m1_f16m8(vfloat16m8_t dest, size_t index,
                                        vfloat16m1_t value);
vfloat16m8_t __riscv_vset_v_f16m2_f16m8(vfloat16m8_t dest, size_t index,
                                        vfloat16m2_t value);
vfloat16m8_t __riscv_vset_v_f16m4_f16m8(vfloat16m8_t dest, size_t index,
                                        vfloat16m4_t value);
vfloat32m2_t __riscv_vset_v_f32m1_f32m2(vfloat32m2_t dest, size_t index,
                                        vfloat32m1_t value);
vfloat32m4_t __riscv_vset_v_f32m1_f32m4(vfloat32m4_t dest, size_t index,
                                        vfloat32m1_t value);
vfloat32m4_t __riscv_vset_v_f32m2_f32m4(vfloat32m4_t dest, size_t index,
                                        vfloat32m2_t value);
vfloat32m8_t __riscv_vset_v_f32m1_f32m8(vfloat32m8_t dest, size_t index,
                                        vfloat32m1_t value);
vfloat32m8_t __riscv_vset_v_f32m2_f32m8(vfloat32m8_t dest, size_t index,
                                        vfloat32m2_t value);
vfloat32m8_t __riscv_vset_v_f32m4_f32m8(vfloat32m8_t dest, size_t index,
                                        vfloat32m4_t value);
vfloat64m2_t __riscv_vset_v_f64m1_f64m2(vfloat64m2_t dest, size_t index,
                                        vfloat64m1_t value);
vfloat64m4_t __riscv_vset_v_f64m1_f64m4(vfloat64m4_t dest, size_t index,
                                        vfloat64m1_t value);
vfloat64m4_t __riscv_vset_v_f64m2_f64m4(vfloat64m4_t dest, size_t index,
                                        vfloat64m2_t value);
vfloat64m8_t __riscv_vset_v_f64m1_f64m8(vfloat64m8_t dest, size_t index,
                                        vfloat64m1_t value);
vfloat64m8_t __riscv_vset_v_f64m2_f64m8(vfloat64m8_t dest, size_t index,
                                        vfloat64m2_t value);
vfloat64m8_t __riscv_vset_v_f64m4_f64m8(vfloat64m8_t dest, size_t index,
                                        vfloat64m4_t value);
vint8m2_t __riscv_vset_v_i8m1_i8m2(vint8m2_t dest, size_t index,
                                   vint8m1_t value);
vint8m4_t __riscv_vset_v_i8m1_i8m4(vint8m4_t dest, size_t index,
                                   vint8m1_t value);
vint8m4_t __riscv_vset_v_i8m2_i8m4(vint8m4_t dest, size_t index,
                                   vint8m2_t value);
vint8m8_t __riscv_vset_v_i8m1_i8m8(vint8m8_t dest, size_t index,
                                   vint8m1_t value);
vint8m8_t __riscv_vset_v_i8m2_i8m8(vint8m8_t dest, size_t index,
                                   vint8m2_t value);
vint8m8_t __riscv_vset_v_i8m4_i8m8(vint8m8_t dest, size_t index,
                                   vint8m4_t value);
vint16m2_t __riscv_vset_v_i16m1_i16m2(vint16m2_t dest, size_t index,
                                      vint16m1_t value);
vint16m4_t __riscv_vset_v_i16m1_i16m4(vint16m4_t dest, size_t index,
                                      vint16m1_t value);
vint16m4_t __riscv_vset_v_i16m2_i16m4(vint16m4_t dest, size_t index,
                                      vint16m2_t value);
vint16m8_t __riscv_vset_v_i16m1_i16m8(vint16m8_t dest, size_t index,
                                      vint16m1_t value);
vint16m8_t __riscv_vset_v_i16m2_i16m8(vint16m8_t dest, size_t index,
                                      vint16m2_t value);
vint16m8_t __riscv_vset_v_i16m4_i16m8(vint16m8_t dest, size_t index,
                                      vint16m4_t value);
vint32m2_t __riscv_vset_v_i32m1_i32m2(vint32m2_t dest, size_t index,
                                      vint32m1_t value);
vint32m4_t __riscv_vset_v_i32m1_i32m4(vint32m4_t dest, size_t index,
                                      vint32m1_t value);
vint32m4_t __riscv_vset_v_i32m2_i32m4(vint32m4_t dest, size_t index,
                                      vint32m2_t value);
vint32m8_t __riscv_vset_v_i32m1_i32m8(vint32m8_t dest, size_t index,
                                      vint32m1_t value);
vint32m8_t __riscv_vset_v_i32m2_i32m8(vint32m8_t dest, size_t index,
                                      vint32m2_t value);
vint32m8_t __riscv_vset_v_i32m4_i32m8(vint32m8_t dest, size_t index,
                                      vint32m4_t value);
vint64m2_t __riscv_vset_v_i64m1_i64m2(vint64m2_t dest, size_t index,
                                      vint64m1_t value);
vint64m4_t __riscv_vset_v_i64m1_i64m4(vint64m4_t dest, size_t index,
                                      vint64m1_t value);
vint64m4_t __riscv_vset_v_i64m2_i64m4(vint64m4_t dest, size_t index,
                                      vint64m2_t value);
vint64m8_t __riscv_vset_v_i64m1_i64m8(vint64m8_t dest, size_t index,
                                      vint64m1_t value);
vint64m8_t __riscv_vset_v_i64m2_i64m8(vint64m8_t dest, size_t index,
                                      vint64m2_t value);
vint64m8_t __riscv_vset_v_i64m4_i64m8(vint64m8_t dest, size_t index,
                                      vint64m4_t value);
vuint8m2_t __riscv_vset_v_u8m1_u8m2(vuint8m2_t dest, size_t index,
                                    vuint8m1_t value);
vuint8m4_t __riscv_vset_v_u8m1_u8m4(vuint8m4_t dest, size_t index,
                                    vuint8m1_t value);
vuint8m4_t __riscv_vset_v_u8m2_u8m4(vuint8m4_t dest, size_t index,
                                    vuint8m2_t value);
vuint8m8_t __riscv_vset_v_u8m1_u8m8(vuint8m8_t dest, size_t index,
                                    vuint8m1_t value);
vuint8m8_t __riscv_vset_v_u8m2_u8m8(vuint8m8_t dest, size_t index,
                                    vuint8m2_t value);
vuint8m8_t __riscv_vset_v_u8m4_u8m8(vuint8m8_t dest, size_t index,
                                    vuint8m4_t value);
vuint16m2_t __riscv_vset_v_u16m1_u16m2(vuint16m2_t dest, size_t index,
                                       vuint16m1_t value);
vuint16m4_t __riscv_vset_v_u16m1_u16m4(vuint16m4_t dest, size_t index,
                                       vuint16m1_t value);
vuint16m4_t __riscv_vset_v_u16m2_u16m4(vuint16m4_t dest, size_t index,
                                       vuint16m2_t value);
vuint16m8_t __riscv_vset_v_u16m1_u16m8(vuint16m8_t dest, size_t index,
                                       vuint16m1_t value);
vuint16m8_t __riscv_vset_v_u16m2_u16m8(vuint16m8_t dest, size_t index,
                                       vuint16m2_t value);
vuint16m8_t __riscv_vset_v_u16m4_u16m8(vuint16m8_t dest, size_t index,
                                       vuint16m4_t value);
vuint32m2_t __riscv_vset_v_u32m1_u32m2(vuint32m2_t dest, size_t index,
                                       vuint32m1_t value);
vuint32m4_t __riscv_vset_v_u32m1_u32m4(vuint32m4_t dest, size_t index,
                                       vuint32m1_t value);
vuint32m4_t __riscv_vset_v_u32m2_u32m4(vuint32m4_t dest, size_t index,
                                       vuint32m2_t value);
vuint32m8_t __riscv_vset_v_u32m1_u32m8(vuint32m8_t dest, size_t index,
                                       vuint32m1_t value);
vuint32m8_t __riscv_vset_v_u32m2_u32m8(vuint32m8_t dest, size_t index,
                                       vuint32m2_t value);
vuint32m8_t __riscv_vset_v_u32m4_u32m8(vuint32m8_t dest, size_t index,
                                       vuint32m4_t value);
vuint64m2_t __riscv_vset_v_u64m1_u64m2(vuint64m2_t dest, size_t index,
                                       vuint64m1_t value);
vuint64m4_t __riscv_vset_v_u64m1_u64m4(vuint64m4_t dest, size_t index,
                                       vuint64m1_t value);
vuint64m4_t __riscv_vset_v_u64m2_u64m4(vuint64m4_t dest, size_t index,
                                       vuint64m2_t value);
vuint64m8_t __riscv_vset_v_u64m1_u64m8(vuint64m8_t dest, size_t index,
                                       vuint64m1_t value);
vuint64m8_t __riscv_vset_v_u64m2_u64m8(vuint64m8_t dest, size_t index,
                                       vuint64m2_t value);
vuint64m8_t __riscv_vset_v_u64m4_u64m8(vuint64m8_t dest, size_t index,
                                       vuint64m4_t value);
vfloat16mf4x2_t __riscv_vset_v_f16mf4_f16mf4x2(vfloat16mf4x2_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x3_t __riscv_vset_v_f16mf4_f16mf4x3(vfloat16mf4x3_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x4_t __riscv_vset_v_f16mf4_f16mf4x4(vfloat16mf4x4_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x5_t __riscv_vset_v_f16mf4_f16mf4x5(vfloat16mf4x5_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x6_t __riscv_vset_v_f16mf4_f16mf4x6(vfloat16mf4x6_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x7_t __riscv_vset_v_f16mf4_f16mf4x7(vfloat16mf4x7_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x8_t __riscv_vset_v_f16mf4_f16mf4x8(vfloat16mf4x8_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf2x2_t __riscv_vset_v_f16mf2_f16mf2x2(vfloat16mf2x2_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x3_t __riscv_vset_v_f16mf2_f16mf2x3(vfloat16mf2x3_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x4_t __riscv_vset_v_f16mf2_f16mf2x4(vfloat16mf2x4_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x5_t __riscv_vset_v_f16mf2_f16mf2x5(vfloat16mf2x5_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x6_t __riscv_vset_v_f16mf2_f16mf2x6(vfloat16mf2x6_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x7_t __riscv_vset_v_f16mf2_f16mf2x7(vfloat16mf2x7_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x8_t __riscv_vset_v_f16mf2_f16mf2x8(vfloat16mf2x8_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16m1x2_t __riscv_vset_v_f16m1_f16m1x2(vfloat16m1x2_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x3_t __riscv_vset_v_f16m1_f16m1x3(vfloat16m1x3_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x4_t __riscv_vset_v_f16m1_f16m1x4(vfloat16m1x4_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x5_t __riscv_vset_v_f16m1_f16m1x5(vfloat16m1x5_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x6_t __riscv_vset_v_f16m1_f16m1x6(vfloat16m1x6_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x7_t __riscv_vset_v_f16m1_f16m1x7(vfloat16m1x7_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x8_t __riscv_vset_v_f16m1_f16m1x8(vfloat16m1x8_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m2x2_t __riscv_vset_v_f16m2_f16m2x2(vfloat16m2x2_t dest, size_t index,
                                            vfloat16m2_t value);
vfloat16m2x3_t __riscv_vset_v_f16m2_f16m2x3(vfloat16m2x3_t dest, size_t index,
                                            vfloat16m2_t value);
vfloat16m2x4_t __riscv_vset_v_f16m2_f16m2x4(vfloat16m2x4_t dest, size_t index,
                                            vfloat16m2_t value);
vfloat16m4x2_t __riscv_vset_v_f16m4_f16m4x2(vfloat16m4x2_t dest, size_t index,
                                            vfloat16m4_t value);
vfloat32mf2x2_t __riscv_vset_v_f32mf2_f32mf2x2(vfloat32mf2x2_t dest,
                                               size_t index,
                                               vfloat32mf2_t value);
vfloat32mf2x3_t __riscv_vset_v_f32mf2_f32mf2x3(vfloat32mf2x3_t dest,
                                               size_t index,
                                               vfloat32mf2_t value);
vfloat32mf2x4_t __riscv_vset_v_f32mf2_f32mf2x4(vfloat32mf2x4_t dest,
                                               size_t index,
                                               vfloat32mf2_t value);
vfloat32mf2x5_t __riscv_vset_v_f32mf2_f32mf2x5(vfloat32mf2x5_t dest,
                                               size_t index,
                                               vfloat32mf2_t value);
vfloat32mf2x6_t __riscv_vset_v_f32mf2_f32mf2x6(vfloat32mf2x6_t dest,
                                               size_t index,
                                               vfloat32mf2_t value);
vfloat32mf2x7_t __riscv_vset_v_f32mf2_f32mf2x7(vfloat32mf2x7_t dest,
                                               size_t index,
                                               vfloat32mf2_t value);
vfloat32mf2x8_t __riscv_vset_v_f32mf2_f32mf2x8(vfloat32mf2x8_t dest,
                                               size_t index,
                                               vfloat32mf2_t value);
vfloat32m1x2_t __riscv_vset_v_f32m1_f32m1x2(vfloat32m1x2_t dest, size_t index,
                                            vfloat32m1_t value);
vfloat32m1x3_t __riscv_vset_v_f32m1_f32m1x3(vfloat32m1x3_t dest, size_t index,
                                            vfloat32m1_t value);
vfloat32m1x4_t __riscv_vset_v_f32m1_f32m1x4(vfloat32m1x4_t dest, size_t index,
                                            vfloat32m1_t value);
vfloat32m1x5_t __riscv_vset_v_f32m1_f32m1x5(vfloat32m1x5_t dest, size_t index,
                                            vfloat32m1_t value);
vfloat32m1x6_t __riscv_vset_v_f32m1_f32m1x6(vfloat32m1x6_t dest, size_t index,
                                            vfloat32m1_t value);
vfloat32m1x7_t __riscv_vset_v_f32m1_f32m1x7(vfloat32m1x7_t dest, size_t index,
                                            vfloat32m1_t value);
vfloat32m1x8_t __riscv_vset_v_f32m1_f32m1x8(vfloat32m1x8_t dest, size_t index,
                                            vfloat32m1_t value);
vfloat32m2x2_t __riscv_vset_v_f32m2_f32m2x2(vfloat32m2x2_t dest, size_t index,
                                            vfloat32m2_t value);
vfloat32m2x3_t __riscv_vset_v_f32m2_f32m2x3(vfloat32m2x3_t dest, size_t index,
                                            vfloat32m2_t value);
vfloat32m2x4_t __riscv_vset_v_f32m2_f32m2x4(vfloat32m2x4_t dest, size_t index,
                                            vfloat32m2_t value);
vfloat32m4x2_t __riscv_vset_v_f32m4_f32m4x2(vfloat32m4x2_t dest, size_t index,
                                            vfloat32m4_t value);
vfloat64m1x2_t __riscv_vset_v_f64m1_f64m1x2(vfloat64m1x2_t dest, size_t index,
                                            vfloat64m1_t value);
vfloat64m1x3_t __riscv_vset_v_f64m1_f64m1x3(vfloat64m1x3_t dest, size_t index,
                                            vfloat64m1_t value);
vfloat64m1x4_t __riscv_vset_v_f64m1_f64m1x4(vfloat64m1x4_t dest, size_t index,
                                            vfloat64m1_t value);
vfloat64m1x5_t __riscv_vset_v_f64m1_f64m1x5(vfloat64m1x5_t dest, size_t index,
                                            vfloat64m1_t value);
vfloat64m1x6_t __riscv_vset_v_f64m1_f64m1x6(vfloat64m1x6_t dest, size_t index,
                                            vfloat64m1_t value);
vfloat64m1x7_t __riscv_vset_v_f64m1_f64m1x7(vfloat64m1x7_t dest, size_t index,
                                            vfloat64m1_t value);
vfloat64m1x8_t __riscv_vset_v_f64m1_f64m1x8(vfloat64m1x8_t dest, size_t index,
                                            vfloat64m1_t value);
vfloat64m2x2_t __riscv_vset_v_f64m2_f64m2x2(vfloat64m2x2_t dest, size_t index,
                                            vfloat64m2_t value);
vfloat64m2x3_t __riscv_vset_v_f64m2_f64m2x3(vfloat64m2x3_t dest, size_t index,
                                            vfloat64m2_t value);
vfloat64m2x4_t __riscv_vset_v_f64m2_f64m2x4(vfloat64m2x4_t dest, size_t index,
                                            vfloat64m2_t value);
vfloat64m4x2_t __riscv_vset_v_f64m4_f64m4x2(vfloat64m4x2_t dest, size_t index,
                                            vfloat64m4_t value);
vint8mf8x2_t __riscv_vset_v_i8mf8_i8mf8x2(vint8mf8x2_t dest, size_t index,
                                          vint8mf8_t value);
vint8mf8x3_t __riscv_vset_v_i8mf8_i8mf8x3(vint8mf8x3_t dest, size_t index,
                                          vint8mf8_t value);
vint8mf8x4_t __riscv_vset_v_i8mf8_i8mf8x4(vint8mf8x4_t dest, size_t index,
                                          vint8mf8_t value);
vint8mf8x5_t __riscv_vset_v_i8mf8_i8mf8x5(vint8mf8x5_t dest, size_t index,
                                          vint8mf8_t value);
vint8mf8x6_t __riscv_vset_v_i8mf8_i8mf8x6(vint8mf8x6_t dest, size_t index,
                                          vint8mf8_t value);
vint8mf8x7_t __riscv_vset_v_i8mf8_i8mf8x7(vint8mf8x7_t dest, size_t index,
                                          vint8mf8_t value);
vint8mf8x8_t __riscv_vset_v_i8mf8_i8mf8x8(vint8mf8x8_t dest, size_t index,
                                          vint8mf8_t value);
vint8mf4x2_t __riscv_vset_v_i8mf4_i8mf4x2(vint8mf4x2_t dest, size_t index,
                                          vint8mf4_t value);
vint8mf4x3_t __riscv_vset_v_i8mf4_i8mf4x3(vint8mf4x3_t dest, size_t index,
                                          vint8mf4_t value);
vint8mf4x4_t __riscv_vset_v_i8mf4_i8mf4x4(vint8mf4x4_t dest, size_t index,
                                          vint8mf4_t value);
vint8mf4x5_t __riscv_vset_v_i8mf4_i8mf4x5(vint8mf4x5_t dest, size_t index,
                                          vint8mf4_t value);
vint8mf4x6_t __riscv_vset_v_i8mf4_i8mf4x6(vint8mf4x6_t dest, size_t index,
                                          vint8mf4_t value);
vint8mf4x7_t __riscv_vset_v_i8mf4_i8mf4x7(vint8mf4x7_t dest, size_t index,
                                          vint8mf4_t value);
vint8mf4x8_t __riscv_vset_v_i8mf4_i8mf4x8(vint8mf4x8_t dest, size_t index,
                                          vint8mf4_t value);
vint8mf2x2_t __riscv_vset_v_i8mf2_i8mf2x2(vint8mf2x2_t dest, size_t index,
                                          vint8mf2_t value);
vint8mf2x3_t __riscv_vset_v_i8mf2_i8mf2x3(vint8mf2x3_t dest, size_t index,
                                          vint8mf2_t value);
vint8mf2x4_t __riscv_vset_v_i8mf2_i8mf2x4(vint8mf2x4_t dest, size_t index,
                                          vint8mf2_t value);
vint8mf2x5_t __riscv_vset_v_i8mf2_i8mf2x5(vint8mf2x5_t dest, size_t index,
                                          vint8mf2_t value);
vint8mf2x6_t __riscv_vset_v_i8mf2_i8mf2x6(vint8mf2x6_t dest, size_t index,
                                          vint8mf2_t value);
vint8mf2x7_t __riscv_vset_v_i8mf2_i8mf2x7(vint8mf2x7_t dest, size_t index,
                                          vint8mf2_t value);
vint8mf2x8_t __riscv_vset_v_i8mf2_i8mf2x8(vint8mf2x8_t dest, size_t index,
                                          vint8mf2_t value);
vint8m1x2_t __riscv_vset_v_i8m1_i8m1x2(vint8m1x2_t dest, size_t index,
                                       vint8m1_t value);
vint8m1x3_t __riscv_vset_v_i8m1_i8m1x3(vint8m1x3_t dest, size_t index,
                                       vint8m1_t value);
vint8m1x4_t __riscv_vset_v_i8m1_i8m1x4(vint8m1x4_t dest, size_t index,
                                       vint8m1_t value);
vint8m1x5_t __riscv_vset_v_i8m1_i8m1x5(vint8m1x5_t dest, size_t index,
                                       vint8m1_t value);
vint8m1x6_t __riscv_vset_v_i8m1_i8m1x6(vint8m1x6_t dest, size_t index,
                                       vint8m1_t value);
vint8m1x7_t __riscv_vset_v_i8m1_i8m1x7(vint8m1x7_t dest, size_t index,
                                       vint8m1_t value);
vint8m1x8_t __riscv_vset_v_i8m1_i8m1x8(vint8m1x8_t dest, size_t index,
                                       vint8m1_t value);
vint8m2x2_t __riscv_vset_v_i8m2_i8m2x2(vint8m2x2_t dest, size_t index,
                                       vint8m2_t value);
vint8m2x3_t __riscv_vset_v_i8m2_i8m2x3(vint8m2x3_t dest, size_t index,
                                       vint8m2_t value);
vint8m2x4_t __riscv_vset_v_i8m2_i8m2x4(vint8m2x4_t dest, size_t index,
                                       vint8m2_t value);
vint8m4x2_t __riscv_vset_v_i8m4_i8m4x2(vint8m4x2_t dest, size_t index,
                                       vint8m4_t value);
vint16mf4x2_t __riscv_vset_v_i16mf4_i16mf4x2(vint16mf4x2_t dest, size_t index,
                                             vint16mf4_t value);
vint16mf4x3_t __riscv_vset_v_i16mf4_i16mf4x3(vint16mf4x3_t dest, size_t index,
                                             vint16mf4_t value);
vint16mf4x4_t __riscv_vset_v_i16mf4_i16mf4x4(vint16mf4x4_t dest, size_t index,
                                             vint16mf4_t value);
vint16mf4x5_t __riscv_vset_v_i16mf4_i16mf4x5(vint16mf4x5_t dest, size_t index,
                                             vint16mf4_t value);
vint16mf4x6_t __riscv_vset_v_i16mf4_i16mf4x6(vint16mf4x6_t dest, size_t index,
                                             vint16mf4_t value);
vint16mf4x7_t __riscv_vset_v_i16mf4_i16mf4x7(vint16mf4x7_t dest, size_t index,
                                             vint16mf4_t value);
vint16mf4x8_t __riscv_vset_v_i16mf4_i16mf4x8(vint16mf4x8_t dest, size_t index,
                                             vint16mf4_t value);
vint16mf2x2_t __riscv_vset_v_i16mf2_i16mf2x2(vint16mf2x2_t dest, size_t index,
                                             vint16mf2_t value);
vint16mf2x3_t __riscv_vset_v_i16mf2_i16mf2x3(vint16mf2x3_t dest, size_t index,
                                             vint16mf2_t value);
vint16mf2x4_t __riscv_vset_v_i16mf2_i16mf2x4(vint16mf2x4_t dest, size_t index,
                                             vint16mf2_t value);
vint16mf2x5_t __riscv_vset_v_i16mf2_i16mf2x5(vint16mf2x5_t dest, size_t index,
                                             vint16mf2_t value);
vint16mf2x6_t __riscv_vset_v_i16mf2_i16mf2x6(vint16mf2x6_t dest, size_t index,
                                             vint16mf2_t value);
vint16mf2x7_t __riscv_vset_v_i16mf2_i16mf2x7(vint16mf2x7_t dest, size_t index,
                                             vint16mf2_t value);
vint16mf2x8_t __riscv_vset_v_i16mf2_i16mf2x8(vint16mf2x8_t dest, size_t index,
                                             vint16mf2_t value);
vint16m1x2_t __riscv_vset_v_i16m1_i16m1x2(vint16m1x2_t dest, size_t index,
                                          vint16m1_t value);
vint16m1x3_t __riscv_vset_v_i16m1_i16m1x3(vint16m1x3_t dest, size_t index,
                                          vint16m1_t value);
vint16m1x4_t __riscv_vset_v_i16m1_i16m1x4(vint16m1x4_t dest, size_t index,
                                          vint16m1_t value);
vint16m1x5_t __riscv_vset_v_i16m1_i16m1x5(vint16m1x5_t dest, size_t index,
                                          vint16m1_t value);
vint16m1x6_t __riscv_vset_v_i16m1_i16m1x6(vint16m1x6_t dest, size_t index,
                                          vint16m1_t value);
vint16m1x7_t __riscv_vset_v_i16m1_i16m1x7(vint16m1x7_t dest, size_t index,
                                          vint16m1_t value);
vint16m1x8_t __riscv_vset_v_i16m1_i16m1x8(vint16m1x8_t dest, size_t index,
                                          vint16m1_t value);
vint16m2x2_t __riscv_vset_v_i16m2_i16m2x2(vint16m2x2_t dest, size_t index,
                                          vint16m2_t value);
vint16m2x3_t __riscv_vset_v_i16m2_i16m2x3(vint16m2x3_t dest, size_t index,
                                          vint16m2_t value);
vint16m2x4_t __riscv_vset_v_i16m2_i16m2x4(vint16m2x4_t dest, size_t index,
                                          vint16m2_t value);
vint16m4x2_t __riscv_vset_v_i16m4_i16m4x2(vint16m4x2_t dest, size_t index,
                                          vint16m4_t value);
vint32mf2x2_t __riscv_vset_v_i32mf2_i32mf2x2(vint32mf2x2_t dest, size_t index,
                                             vint32mf2_t value);
vint32mf2x3_t __riscv_vset_v_i32mf2_i32mf2x3(vint32mf2x3_t dest, size_t index,
                                             vint32mf2_t value);
vint32mf2x4_t __riscv_vset_v_i32mf2_i32mf2x4(vint32mf2x4_t dest, size_t index,
                                             vint32mf2_t value);
vint32mf2x5_t __riscv_vset_v_i32mf2_i32mf2x5(vint32mf2x5_t dest, size_t index,
                                             vint32mf2_t value);
vint32mf2x6_t __riscv_vset_v_i32mf2_i32mf2x6(vint32mf2x6_t dest, size_t index,
                                             vint32mf2_t value);
vint32mf2x7_t __riscv_vset_v_i32mf2_i32mf2x7(vint32mf2x7_t dest, size_t index,
                                             vint32mf2_t value);
vint32mf2x8_t __riscv_vset_v_i32mf2_i32mf2x8(vint32mf2x8_t dest, size_t index,
                                             vint32mf2_t value);
vint32m1x2_t __riscv_vset_v_i32m1_i32m1x2(vint32m1x2_t dest, size_t index,
                                          vint32m1_t value);
vint32m1x3_t __riscv_vset_v_i32m1_i32m1x3(vint32m1x3_t dest, size_t index,
                                          vint32m1_t value);
vint32m1x4_t __riscv_vset_v_i32m1_i32m1x4(vint32m1x4_t dest, size_t index,
                                          vint32m1_t value);
vint32m1x5_t __riscv_vset_v_i32m1_i32m1x5(vint32m1x5_t dest, size_t index,
                                          vint32m1_t value);
vint32m1x6_t __riscv_vset_v_i32m1_i32m1x6(vint32m1x6_t dest, size_t index,
                                          vint32m1_t value);
vint32m1x7_t __riscv_vset_v_i32m1_i32m1x7(vint32m1x7_t dest, size_t index,
                                          vint32m1_t value);
vint32m1x8_t __riscv_vset_v_i32m1_i32m1x8(vint32m1x8_t dest, size_t index,
                                          vint32m1_t value);
vint32m2x2_t __riscv_vset_v_i32m2_i32m2x2(vint32m2x2_t dest, size_t index,
                                          vint32m2_t value);
vint32m2x3_t __riscv_vset_v_i32m2_i32m2x3(vint32m2x3_t dest, size_t index,
                                          vint32m2_t value);
vint32m2x4_t __riscv_vset_v_i32m2_i32m2x4(vint32m2x4_t dest, size_t index,
                                          vint32m2_t value);
vint32m4x2_t __riscv_vset_v_i32m4_i32m4x2(vint32m4x2_t dest, size_t index,
                                          vint32m4_t value);
vint64m1x2_t __riscv_vset_v_i64m1_i64m1x2(vint64m1x2_t dest, size_t index,
                                          vint64m1_t value);
vint64m1x3_t __riscv_vset_v_i64m1_i64m1x3(vint64m1x3_t dest, size_t index,
                                          vint64m1_t value);
vint64m1x4_t __riscv_vset_v_i64m1_i64m1x4(vint64m1x4_t dest, size_t index,
                                          vint64m1_t value);
vint64m1x5_t __riscv_vset_v_i64m1_i64m1x5(vint64m1x5_t dest, size_t index,
                                          vint64m1_t value);
vint64m1x6_t __riscv_vset_v_i64m1_i64m1x6(vint64m1x6_t dest, size_t index,
                                          vint64m1_t value);
vint64m1x7_t __riscv_vset_v_i64m1_i64m1x7(vint64m1x7_t dest, size_t index,
                                          vint64m1_t value);
vint64m1x8_t __riscv_vset_v_i64m1_i64m1x8(vint64m1x8_t dest, size_t index,
                                          vint64m1_t value);
vint64m2x2_t __riscv_vset_v_i64m2_i64m2x2(vint64m2x2_t dest, size_t index,
                                          vint64m2_t value);
vint64m2x3_t __riscv_vset_v_i64m2_i64m2x3(vint64m2x3_t dest, size_t index,
                                          vint64m2_t value);
vint64m2x4_t __riscv_vset_v_i64m2_i64m2x4(vint64m2x4_t dest, size_t index,
                                          vint64m2_t value);
vint64m4x2_t __riscv_vset_v_i64m4_i64m4x2(vint64m4x2_t dest, size_t index,
                                          vint64m4_t value);
vuint8mf8x2_t __riscv_vset_v_u8mf8_u8mf8x2(vuint8mf8x2_t dest, size_t index,
                                           vuint8mf8_t value);
vuint8mf8x3_t __riscv_vset_v_u8mf8_u8mf8x3(vuint8mf8x3_t dest, size_t index,
                                           vuint8mf8_t value);
vuint8mf8x4_t __riscv_vset_v_u8mf8_u8mf8x4(vuint8mf8x4_t dest, size_t index,
                                           vuint8mf8_t value);
vuint8mf8x5_t __riscv_vset_v_u8mf8_u8mf8x5(vuint8mf8x5_t dest, size_t index,
                                           vuint8mf8_t value);
vuint8mf8x6_t __riscv_vset_v_u8mf8_u8mf8x6(vuint8mf8x6_t dest, size_t index,
                                           vuint8mf8_t value);
vuint8mf8x7_t __riscv_vset_v_u8mf8_u8mf8x7(vuint8mf8x7_t dest, size_t index,
                                           vuint8mf8_t value);
vuint8mf8x8_t __riscv_vset_v_u8mf8_u8mf8x8(vuint8mf8x8_t dest, size_t index,
                                           vuint8mf8_t value);
vuint8mf4x2_t __riscv_vset_v_u8mf4_u8mf4x2(vuint8mf4x2_t dest, size_t index,
                                           vuint8mf4_t value);
vuint8mf4x3_t __riscv_vset_v_u8mf4_u8mf4x3(vuint8mf4x3_t dest, size_t index,
                                           vuint8mf4_t value);
vuint8mf4x4_t __riscv_vset_v_u8mf4_u8mf4x4(vuint8mf4x4_t dest, size_t index,
                                           vuint8mf4_t value);
vuint8mf4x5_t __riscv_vset_v_u8mf4_u8mf4x5(vuint8mf4x5_t dest, size_t index,
                                           vuint8mf4_t value);
vuint8mf4x6_t __riscv_vset_v_u8mf4_u8mf4x6(vuint8mf4x6_t dest, size_t index,
                                           vuint8mf4_t value);
vuint8mf4x7_t __riscv_vset_v_u8mf4_u8mf4x7(vuint8mf4x7_t dest, size_t index,
                                           vuint8mf4_t value);
vuint8mf4x8_t __riscv_vset_v_u8mf4_u8mf4x8(vuint8mf4x8_t dest, size_t index,
                                           vuint8mf4_t value);
vuint8mf2x2_t __riscv_vset_v_u8mf2_u8mf2x2(vuint8mf2x2_t dest, size_t index,
                                           vuint8mf2_t value);
vuint8mf2x3_t __riscv_vset_v_u8mf2_u8mf2x3(vuint8mf2x3_t dest, size_t index,
                                           vuint8mf2_t value);
vuint8mf2x4_t __riscv_vset_v_u8mf2_u8mf2x4(vuint8mf2x4_t dest, size_t index,
                                           vuint8mf2_t value);
vuint8mf2x5_t __riscv_vset_v_u8mf2_u8mf2x5(vuint8mf2x5_t dest, size_t index,
                                           vuint8mf2_t value);
vuint8mf2x6_t __riscv_vset_v_u8mf2_u8mf2x6(vuint8mf2x6_t dest, size_t index,
                                           vuint8mf2_t value);
vuint8mf2x7_t __riscv_vset_v_u8mf2_u8mf2x7(vuint8mf2x7_t dest, size_t index,
                                           vuint8mf2_t value);
vuint8mf2x8_t __riscv_vset_v_u8mf2_u8mf2x8(vuint8mf2x8_t dest, size_t index,
                                           vuint8mf2_t value);
vuint8m1x2_t __riscv_vset_v_u8m1_u8m1x2(vuint8m1x2_t dest, size_t index,
                                        vuint8m1_t value);
vuint8m1x3_t __riscv_vset_v_u8m1_u8m1x3(vuint8m1x3_t dest, size_t index,
                                        vuint8m1_t value);
vuint8m1x4_t __riscv_vset_v_u8m1_u8m1x4(vuint8m1x4_t dest, size_t index,
                                        vuint8m1_t value);
vuint8m1x5_t __riscv_vset_v_u8m1_u8m1x5(vuint8m1x5_t dest, size_t index,
                                        vuint8m1_t value);
vuint8m1x6_t __riscv_vset_v_u8m1_u8m1x6(vuint8m1x6_t dest, size_t index,
                                        vuint8m1_t value);
vuint8m1x7_t __riscv_vset_v_u8m1_u8m1x7(vuint8m1x7_t dest, size_t index,
                                        vuint8m1_t value);
vuint8m1x8_t __riscv_vset_v_u8m1_u8m1x8(vuint8m1x8_t dest, size_t index,
                                        vuint8m1_t value);
vuint8m2x2_t __riscv_vset_v_u8m2_u8m2x2(vuint8m2x2_t dest, size_t index,
                                        vuint8m2_t value);
vuint8m2x3_t __riscv_vset_v_u8m2_u8m2x3(vuint8m2x3_t dest, size_t index,
                                        vuint8m2_t value);
vuint8m2x4_t __riscv_vset_v_u8m2_u8m2x4(vuint8m2x4_t dest, size_t index,
                                        vuint8m2_t value);
vuint8m4x2_t __riscv_vset_v_u8m4_u8m4x2(vuint8m4x2_t dest, size_t index,
                                        vuint8m4_t value);
vuint16mf4x2_t __riscv_vset_v_u16mf4_u16mf4x2(vuint16mf4x2_t dest, size_t index,
                                              vuint16mf4_t value);
vuint16mf4x3_t __riscv_vset_v_u16mf4_u16mf4x3(vuint16mf4x3_t dest, size_t index,
                                              vuint16mf4_t value);
vuint16mf4x4_t __riscv_vset_v_u16mf4_u16mf4x4(vuint16mf4x4_t dest, size_t index,
                                              vuint16mf4_t value);
vuint16mf4x5_t __riscv_vset_v_u16mf4_u16mf4x5(vuint16mf4x5_t dest, size_t index,
                                              vuint16mf4_t value);
vuint16mf4x6_t __riscv_vset_v_u16mf4_u16mf4x6(vuint16mf4x6_t dest, size_t index,
                                              vuint16mf4_t value);
vuint16mf4x7_t __riscv_vset_v_u16mf4_u16mf4x7(vuint16mf4x7_t dest, size_t index,
                                              vuint16mf4_t value);
vuint16mf4x8_t __riscv_vset_v_u16mf4_u16mf4x8(vuint16mf4x8_t dest, size_t index,
                                              vuint16mf4_t value);
vuint16mf2x2_t __riscv_vset_v_u16mf2_u16mf2x2(vuint16mf2x2_t dest, size_t index,
                                              vuint16mf2_t value);
vuint16mf2x3_t __riscv_vset_v_u16mf2_u16mf2x3(vuint16mf2x3_t dest, size_t index,
                                              vuint16mf2_t value);
vuint16mf2x4_t __riscv_vset_v_u16mf2_u16mf2x4(vuint16mf2x4_t dest, size_t index,
                                              vuint16mf2_t value);
vuint16mf2x5_t __riscv_vset_v_u16mf2_u16mf2x5(vuint16mf2x5_t dest, size_t index,
                                              vuint16mf2_t value);
vuint16mf2x6_t __riscv_vset_v_u16mf2_u16mf2x6(vuint16mf2x6_t dest, size_t index,
                                              vuint16mf2_t value);
vuint16mf2x7_t __riscv_vset_v_u16mf2_u16mf2x7(vuint16mf2x7_t dest, size_t index,
                                              vuint16mf2_t value);
vuint16mf2x8_t __riscv_vset_v_u16mf2_u16mf2x8(vuint16mf2x8_t dest, size_t index,
                                              vuint16mf2_t value);
vuint16m1x2_t __riscv_vset_v_u16m1_u16m1x2(vuint16m1x2_t dest, size_t index,
                                           vuint16m1_t value);
vuint16m1x3_t __riscv_vset_v_u16m1_u16m1x3(vuint16m1x3_t dest, size_t index,
                                           vuint16m1_t value);
vuint16m1x4_t __riscv_vset_v_u16m1_u16m1x4(vuint16m1x4_t dest, size_t index,
                                           vuint16m1_t value);
vuint16m1x5_t __riscv_vset_v_u16m1_u16m1x5(vuint16m1x5_t dest, size_t index,
                                           vuint16m1_t value);
vuint16m1x6_t __riscv_vset_v_u16m1_u16m1x6(vuint16m1x6_t dest, size_t index,
                                           vuint16m1_t value);
vuint16m1x7_t __riscv_vset_v_u16m1_u16m1x7(vuint16m1x7_t dest, size_t index,
                                           vuint16m1_t value);
vuint16m1x8_t __riscv_vset_v_u16m1_u16m1x8(vuint16m1x8_t dest, size_t index,
                                           vuint16m1_t value);
vuint16m2x2_t __riscv_vset_v_u16m2_u16m2x2(vuint16m2x2_t dest, size_t index,
                                           vuint16m2_t value);
vuint16m2x3_t __riscv_vset_v_u16m2_u16m2x3(vuint16m2x3_t dest, size_t index,
                                           vuint16m2_t value);
vuint16m2x4_t __riscv_vset_v_u16m2_u16m2x4(vuint16m2x4_t dest, size_t index,
                                           vuint16m2_t value);
vuint16m4x2_t __riscv_vset_v_u16m4_u16m4x2(vuint16m4x2_t dest, size_t index,
                                           vuint16m4_t value);
vuint32mf2x2_t __riscv_vset_v_u32mf2_u32mf2x2(vuint32mf2x2_t dest, size_t index,
                                              vuint32mf2_t value);
vuint32mf2x3_t __riscv_vset_v_u32mf2_u32mf2x3(vuint32mf2x3_t dest, size_t index,
                                              vuint32mf2_t value);
vuint32mf2x4_t __riscv_vset_v_u32mf2_u32mf2x4(vuint32mf2x4_t dest, size_t index,
                                              vuint32mf2_t value);
vuint32mf2x5_t __riscv_vset_v_u32mf2_u32mf2x5(vuint32mf2x5_t dest, size_t index,
                                              vuint32mf2_t value);
vuint32mf2x6_t __riscv_vset_v_u32mf2_u32mf2x6(vuint32mf2x6_t dest, size_t index,
                                              vuint32mf2_t value);
vuint32mf2x7_t __riscv_vset_v_u32mf2_u32mf2x7(vuint32mf2x7_t dest, size_t index,
                                              vuint32mf2_t value);
vuint32mf2x8_t __riscv_vset_v_u32mf2_u32mf2x8(vuint32mf2x8_t dest, size_t index,
                                              vuint32mf2_t value);
vuint32m1x2_t __riscv_vset_v_u32m1_u32m1x2(vuint32m1x2_t dest, size_t index,
                                           vuint32m1_t value);
vuint32m1x3_t __riscv_vset_v_u32m1_u32m1x3(vuint32m1x3_t dest, size_t index,
                                           vuint32m1_t value);
vuint32m1x4_t __riscv_vset_v_u32m1_u32m1x4(vuint32m1x4_t dest, size_t index,
                                           vuint32m1_t value);
vuint32m1x5_t __riscv_vset_v_u32m1_u32m1x5(vuint32m1x5_t dest, size_t index,
                                           vuint32m1_t value);
vuint32m1x6_t __riscv_vset_v_u32m1_u32m1x6(vuint32m1x6_t dest, size_t index,
                                           vuint32m1_t value);
vuint32m1x7_t __riscv_vset_v_u32m1_u32m1x7(vuint32m1x7_t dest, size_t index,
                                           vuint32m1_t value);
vuint32m1x8_t __riscv_vset_v_u32m1_u32m1x8(vuint32m1x8_t dest, size_t index,
                                           vuint32m1_t value);
vuint32m2x2_t __riscv_vset_v_u32m2_u32m2x2(vuint32m2x2_t dest, size_t index,
                                           vuint32m2_t value);
vuint32m2x3_t __riscv_vset_v_u32m2_u32m2x3(vuint32m2x3_t dest, size_t index,
                                           vuint32m2_t value);
vuint32m2x4_t __riscv_vset_v_u32m2_u32m2x4(vuint32m2x4_t dest, size_t index,
                                           vuint32m2_t value);
vuint32m4x2_t __riscv_vset_v_u32m4_u32m4x2(vuint32m4x2_t dest, size_t index,
                                           vuint32m4_t value);
vuint64m1x2_t __riscv_vset_v_u64m1_u64m1x2(vuint64m1x2_t dest, size_t index,
                                           vuint64m1_t value);
vuint64m1x3_t __riscv_vset_v_u64m1_u64m1x3(vuint64m1x3_t dest, size_t index,
                                           vuint64m1_t value);
vuint64m1x4_t __riscv_vset_v_u64m1_u64m1x4(vuint64m1x4_t dest, size_t index,
                                           vuint64m1_t value);
vuint64m1x5_t __riscv_vset_v_u64m1_u64m1x5(vuint64m1x5_t dest, size_t index,
                                           vuint64m1_t value);
vuint64m1x6_t __riscv_vset_v_u64m1_u64m1x6(vuint64m1x6_t dest, size_t index,
                                           vuint64m1_t value);
vuint64m1x7_t __riscv_vset_v_u64m1_u64m1x7(vuint64m1x7_t dest, size_t index,
                                           vuint64m1_t value);
vuint64m1x8_t __riscv_vset_v_u64m1_u64m1x8(vuint64m1x8_t dest, size_t index,
                                           vuint64m1_t value);
vuint64m2x2_t __riscv_vset_v_u64m2_u64m2x2(vuint64m2x2_t dest, size_t index,
                                           vuint64m2_t value);
vuint64m2x3_t __riscv_vset_v_u64m2_u64m2x3(vuint64m2x3_t dest, size_t index,
                                           vuint64m2_t value);
vuint64m2x4_t __riscv_vset_v_u64m2_u64m2x4(vuint64m2x4_t dest, size_t index,
                                           vuint64m2_t value);
vuint64m4x2_t __riscv_vset_v_u64m4_u64m4x2(vuint64m4x2_t dest, size_t index,
                                           vuint64m4_t value);
----

[[vector-extraction]]
==== Vector Extraction Intrinsics

[,c]
----
vfloat16m1_t __riscv_vget_v_f16m2_f16m1(vfloat16m2_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m4_f16m1(vfloat16m4_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m8_f16m1(vfloat16m8_t src, size_t index);
vfloat16m2_t __riscv_vget_v_f16m4_f16m2(vfloat16m4_t src, size_t index);
vfloat16m2_t __riscv_vget_v_f16m8_f16m2(vfloat16m8_t src, size_t index);
vfloat16m4_t __riscv_vget_v_f16m8_f16m4(vfloat16m8_t src, size_t index);
vfloat32m1_t __riscv_vget_v_f32m2_f32m1(vfloat32m2_t src, size_t index);
vfloat32m1_t __riscv_vget_v_f32m4_f32m1(vfloat32m4_t src, size_t index);
vfloat32m1_t __riscv_vget_v_f32m8_f32m1(vfloat32m8_t src, size_t index);
vfloat32m2_t __riscv_vget_v_f32m4_f32m2(vfloat32m4_t src, size_t index);
vfloat32m2_t __riscv_vget_v_f32m8_f32m2(vfloat32m8_t src, size_t index);
vfloat32m4_t __riscv_vget_v_f32m8_f32m4(vfloat32m8_t src, size_t index);
vfloat64m1_t __riscv_vget_v_f64m2_f64m1(vfloat64m2_t src, size_t index);
vfloat64m1_t __riscv_vget_v_f64m4_f64m1(vfloat64m4_t src, size_t index);
vfloat64m1_t __riscv_vget_v_f64m8_f64m1(vfloat64m8_t src, size_t index);
vfloat64m2_t __riscv_vget_v_f64m4_f64m2(vfloat64m4_t src, size_t index);
vfloat64m2_t __riscv_vget_v_f64m8_f64m2(vfloat64m8_t src, size_t index);
vfloat64m4_t __riscv_vget_v_f64m8_f64m4(vfloat64m8_t src, size_t index);
vint8m1_t __riscv_vget_v_i8m2_i8m1(vint8m2_t src, size_t index);
vint8m1_t __riscv_vget_v_i8m4_i8m1(vint8m4_t src, size_t index);
vint8m1_t __riscv_vget_v_i8m8_i8m1(vint8m8_t src, size_t index);
vint8m2_t __riscv_vget_v_i8m4_i8m2(vint8m4_t src, size_t index);
vint8m2_t __riscv_vget_v_i8m8_i8m2(vint8m8_t src, size_t index);
vint8m4_t __riscv_vget_v_i8m8_i8m4(vint8m8_t src, size_t index);
vint16m1_t __riscv_vget_v_i16m2_i16m1(vint16m2_t src, size_t index);
vint16m1_t __riscv_vget_v_i16m4_i16m1(vint16m4_t src, size_t index);
vint16m1_t __riscv_vget_v_i16m8_i16m1(vint16m8_t src, size_t index);
vint16m2_t __riscv_vget_v_i16m4_i16m2(vint16m4_t src, size_t index);
vint16m2_t __riscv_vget_v_i16m8_i16m2(vint16m8_t src, size_t index);
vint16m4_t __riscv_vget_v_i16m8_i16m4(vint16m8_t src, size_t index);
vint32m1_t __riscv_vget_v_i32m2_i32m1(vint32m2_t src, size_t index);
vint32m1_t __riscv_vget_v_i32m4_i32m1(vint32m4_t src, size_t index);
vint32m1_t __riscv_vget_v_i32m8_i32m1(vint32m8_t src, size_t index);
vint32m2_t __riscv_vget_v_i32m4_i32m2(vint32m4_t src, size_t index);
vint32m2_t __riscv_vget_v_i32m8_i32m2(vint32m8_t src, size_t index);
vint32m4_t __riscv_vget_v_i32m8_i32m4(vint32m8_t src, size_t index);
vint64m1_t __riscv_vget_v_i64m2_i64m1(vint64m2_t src, size_t index);
vint64m1_t __riscv_vget_v_i64m4_i64m1(vint64m4_t src, size_t index);
vint64m1_t __riscv_vget_v_i64m8_i64m1(vint64m8_t src, size_t index);
vint64m2_t __riscv_vget_v_i64m4_i64m2(vint64m4_t src, size_t index);
vint64m2_t __riscv_vget_v_i64m8_i64m2(vint64m8_t src, size_t index);
vint64m4_t __riscv_vget_v_i64m8_i64m4(vint64m8_t src, size_t index);
vuint8m1_t __riscv_vget_v_u8m2_u8m1(vuint8m2_t src, size_t index);
vuint8m1_t __riscv_vget_v_u8m4_u8m1(vuint8m4_t src, size_t index);
vuint8m1_t __riscv_vget_v_u8m8_u8m1(vuint8m8_t src, size_t index);
vuint8m2_t __riscv_vget_v_u8m4_u8m2(vuint8m4_t src, size_t index);
vuint8m2_t __riscv_vget_v_u8m8_u8m2(vuint8m8_t src, size_t index);
vuint8m4_t __riscv_vget_v_u8m8_u8m4(vuint8m8_t src, size_t index);
vuint16m1_t __riscv_vget_v_u16m2_u16m1(vuint16m2_t src, size_t index);
vuint16m1_t __riscv_vget_v_u16m4_u16m1(vuint16m4_t src, size_t index);
vuint16m1_t __riscv_vget_v_u16m8_u16m1(vuint16m8_t src, size_t index);
vuint16m2_t __riscv_vget_v_u16m4_u16m2(vuint16m4_t src, size_t index);
vuint16m2_t __riscv_vget_v_u16m8_u16m2(vuint16m8_t src, size_t index);
vuint16m4_t __riscv_vget_v_u16m8_u16m4(vuint16m8_t src, size_t index);
vuint32m1_t __riscv_vget_v_u32m2_u32m1(vuint32m2_t src, size_t index);
vuint32m1_t __riscv_vget_v_u32m4_u32m1(vuint32m4_t src, size_t index);
vuint32m1_t __riscv_vget_v_u32m8_u32m1(vuint32m8_t src, size_t index);
vuint32m2_t __riscv_vget_v_u32m4_u32m2(vuint32m4_t src, size_t index);
vuint32m2_t __riscv_vget_v_u32m8_u32m2(vuint32m8_t src, size_t index);
vuint32m4_t __riscv_vget_v_u32m8_u32m4(vuint32m8_t src, size_t index);
vuint64m1_t __riscv_vget_v_u64m2_u64m1(vuint64m2_t src, size_t index);
vuint64m1_t __riscv_vget_v_u64m4_u64m1(vuint64m4_t src, size_t index);
vuint64m1_t __riscv_vget_v_u64m8_u64m1(vuint64m8_t src, size_t index);
vuint64m2_t __riscv_vget_v_u64m4_u64m2(vuint64m4_t src, size_t index);
vuint64m2_t __riscv_vget_v_u64m8_u64m2(vuint64m8_t src, size_t index);
vuint64m4_t __riscv_vget_v_u64m8_u64m4(vuint64m8_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x2_f16mf4(vfloat16mf4x2_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x3_f16mf4(vfloat16mf4x3_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x4_f16mf4(vfloat16mf4x4_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x5_f16mf4(vfloat16mf4x5_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x6_f16mf4(vfloat16mf4x6_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x7_f16mf4(vfloat16mf4x7_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x8_f16mf4(vfloat16mf4x8_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x2_f16mf2(vfloat16mf2x2_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x3_f16mf2(vfloat16mf2x3_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x4_f16mf2(vfloat16mf2x4_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x5_f16mf2(vfloat16mf2x5_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x6_f16mf2(vfloat16mf2x6_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x7_f16mf2(vfloat16mf2x7_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x8_f16mf2(vfloat16mf2x8_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x2_f16m1(vfloat16m1x2_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x3_f16m1(vfloat16m1x3_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x4_f16m1(vfloat16m1x4_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x5_f16m1(vfloat16m1x5_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x6_f16m1(vfloat16m1x6_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x7_f16m1(vfloat16m1x7_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x8_f16m1(vfloat16m1x8_t src, size_t index);
vfloat16m2_t __riscv_vget_v_f16m2x2_f16m2(vfloat16m2x2_t src, size_t index);
vfloat16m2_t __riscv_vget_v_f16m2x3_f16m2(vfloat16m2x3_t src, size_t index);
vfloat16m2_t __riscv_vget_v_f16m2x4_f16m2(vfloat16m2x4_t src, size_t index);
vfloat16m4_t __riscv_vget_v_f16m4x2_f16m4(vfloat16m4x2_t src, size_t index);
vfloat32mf2_t __riscv_vget_v_f32mf2x2_f32mf2(vfloat32mf2x2_t src, size_t index);
vfloat32mf2_t __riscv_vget_v_f32mf2x3_f32mf2(vfloat32mf2x3_t src, size_t index);
vfloat32mf2_t __riscv_vget_v_f32mf2x4_f32mf2(vfloat32mf2x4_t src, size_t index);
vfloat32mf2_t __riscv_vget_v_f32mf2x5_f32mf2(vfloat32mf2x5_t src, size_t index);
vfloat32mf2_t __riscv_vget_v_f32mf2x6_f32mf2(vfloat32mf2x6_t src, size_t index);
vfloat32mf2_t __riscv_vget_v_f32mf2x7_f32mf2(vfloat32mf2x7_t src, size_t index);
vfloat32mf2_t __riscv_vget_v_f32mf2x8_f32mf2(vfloat32mf2x8_t src, size_t index);
vfloat32m1_t __riscv_vget_v_f32m1x2_f32m1(vfloat32m1x2_t src, size_t index);
vfloat32m1_t __riscv_vget_v_f32m1x3_f32m1(vfloat32m1x3_t src, size_t index);
vfloat32m1_t __riscv_vget_v_f32m1x4_f32m1(vfloat32m1x4_t src, size_t index);
vfloat32m1_t __riscv_vget_v_f32m1x5_f32m1(vfloat32m1x5_t src, size_t index);
vfloat32m1_t __riscv_vget_v_f32m1x6_f32m1(vfloat32m1x6_t src, size_t index);
vfloat32m1_t __riscv_vget_v_f32m1x7_f32m1(vfloat32m1x7_t src, size_t index);
vfloat32m1_t __riscv_vget_v_f32m1x8_f32m1(vfloat32m1x8_t src, size_t index);
vfloat32m2_t __riscv_vget_v_f32m2x2_f32m2(vfloat32m2x2_t src, size_t index);
vfloat32m2_t __riscv_vget_v_f32m2x3_f32m2(vfloat32m2x3_t src, size_t index);
vfloat32m2_t __riscv_vget_v_f32m2x4_f32m2(vfloat32m2x4_t src, size_t index);
vfloat32m4_t __riscv_vget_v_f32m4x2_f32m4(vfloat32m4x2_t src, size_t index);
vfloat64m1_t __riscv_vget_v_f64m1x2_f64m1(vfloat64m1x2_t src, size_t index);
vfloat64m1_t __riscv_vget_v_f64m1x3_f64m1(vfloat64m1x3_t src, size_t index);
vfloat64m1_t __riscv_vget_v_f64m1x4_f64m1(vfloat64m1x4_t src, size_t index);
vfloat64m1_t __riscv_vget_v_f64m1x5_f64m1(vfloat64m1x5_t src, size_t index);
vfloat64m1_t __riscv_vget_v_f64m1x6_f64m1(vfloat64m1x6_t src, size_t index);
vfloat64m1_t __riscv_vget_v_f64m1x7_f64m1(vfloat64m1x7_t src, size_t index);
vfloat64m1_t __riscv_vget_v_f64m1x8_f64m1(vfloat64m1x8_t src, size_t index);
vfloat64m2_t __riscv_vget_v_f64m2x2_f64m2(vfloat64m2x2_t src, size_t index);
vfloat64m2_t __riscv_vget_v_f64m2x3_f64m2(vfloat64m2x3_t src, size_t index);
vfloat64m2_t __riscv_vget_v_f64m2x4_f64m2(vfloat64m2x4_t src, size_t index);
vfloat64m4_t __riscv_vget_v_f64m4x2_f64m4(vfloat64m4x2_t src, size_t index);
vint8mf8_t __riscv_vget_v_i8mf8x2_i8mf8(vint8mf8x2_t src, size_t index);
vint8mf8_t __riscv_vget_v_i8mf8x3_i8mf8(vint8mf8x3_t src, size_t index);
vint8mf8_t __riscv_vget_v_i8mf8x4_i8mf8(vint8mf8x4_t src, size_t index);
vint8mf8_t __riscv_vget_v_i8mf8x5_i8mf8(vint8mf8x5_t src, size_t index);
vint8mf8_t __riscv_vget_v_i8mf8x6_i8mf8(vint8mf8x6_t src, size_t index);
vint8mf8_t __riscv_vget_v_i8mf8x7_i8mf8(vint8mf8x7_t src, size_t index);
vint8mf8_t __riscv_vget_v_i8mf8x8_i8mf8(vint8mf8x8_t src, size_t index);
vint8mf4_t __riscv_vget_v_i8mf4x2_i8mf4(vint8mf4x2_t src, size_t index);
vint8mf4_t __riscv_vget_v_i8mf4x3_i8mf4(vint8mf4x3_t src, size_t index);
vint8mf4_t __riscv_vget_v_i8mf4x4_i8mf4(vint8mf4x4_t src, size_t index);
vint8mf4_t __riscv_vget_v_i8mf4x5_i8mf4(vint8mf4x5_t src, size_t index);
vint8mf4_t __riscv_vget_v_i8mf4x6_i8mf4(vint8mf4x6_t src, size_t index);
vint8mf4_t __riscv_vget_v_i8mf4x7_i8mf4(vint8mf4x7_t src, size_t index);
vint8mf4_t __riscv_vget_v_i8mf4x8_i8mf4(vint8mf4x8_t src, size_t index);
vint8mf2_t __riscv_vget_v_i8mf2x2_i8mf2(vint8mf2x2_t src, size_t index);
vint8mf2_t __riscv_vget_v_i8mf2x3_i8mf2(vint8mf2x3_t src, size_t index);
vint8mf2_t __riscv_vget_v_i8mf2x4_i8mf2(vint8mf2x4_t src, size_t index);
vint8mf2_t __riscv_vget_v_i8mf2x5_i8mf2(vint8mf2x5_t src, size_t index);
vint8mf2_t __riscv_vget_v_i8mf2x6_i8mf2(vint8mf2x6_t src, size_t index);
vint8mf2_t __riscv_vget_v_i8mf2x7_i8mf2(vint8mf2x7_t src, size_t index);
vint8mf2_t __riscv_vget_v_i8mf2x8_i8mf2(vint8mf2x8_t src, size_t index);
vint8m1_t __riscv_vget_v_i8m1x2_i8m1(vint8m1x2_t src, size_t index);
vint8m1_t __riscv_vget_v_i8m1x3_i8m1(vint8m1x3_t src, size_t index);
vint8m1_t __riscv_vget_v_i8m1x4_i8m1(vint8m1x4_t src, size_t index);
vint8m1_t __riscv_vget_v_i8m1x5_i8m1(vint8m1x5_t src, size_t index);
vint8m1_t __riscv_vget_v_i8m1x6_i8m1(vint8m1x6_t src, size_t index);
vint8m1_t __riscv_vget_v_i8m1x7_i8m1(vint8m1x7_t src, size_t index);
vint8m1_t __riscv_vget_v_i8m1x8_i8m1(vint8m1x8_t src, size_t index);
vint8m2_t __riscv_vget_v_i8m2x2_i8m2(vint8m2x2_t src, size_t index);
vint8m2_t __riscv_vget_v_i8m2x3_i8m2(vint8m2x3_t src, size_t index);
vint8m2_t __riscv_vget_v_i8m2x4_i8m2(vint8m2x4_t src, size_t index);
vint8m4_t __riscv_vget_v_i8m4x2_i8m4(vint8m4x2_t src, size_t index);
vint16mf4_t __riscv_vget_v_i16mf4x2_i16mf4(vint16mf4x2_t src, size_t index);
vint16mf4_t __riscv_vget_v_i16mf4x3_i16mf4(vint16mf4x3_t src, size_t index);
vint16mf4_t __riscv_vget_v_i16mf4x4_i16mf4(vint16mf4x4_t src, size_t index);
vint16mf4_t __riscv_vget_v_i16mf4x5_i16mf4(vint16mf4x5_t src, size_t index);
vint16mf4_t __riscv_vget_v_i16mf4x6_i16mf4(vint16mf4x6_t src, size_t index);
vint16mf4_t __riscv_vget_v_i16mf4x7_i16mf4(vint16mf4x7_t src, size_t index);
vint16mf4_t __riscv_vget_v_i16mf4x8_i16mf4(vint16mf4x8_t src, size_t index);
vint16mf2_t __riscv_vget_v_i16mf2x2_i16mf2(vint16mf2x2_t src, size_t index);
vint16mf2_t __riscv_vget_v_i16mf2x3_i16mf2(vint16mf2x3_t src, size_t index);
vint16mf2_t __riscv_vget_v_i16mf2x4_i16mf2(vint16mf2x4_t src, size_t index);
vint16mf2_t __riscv_vget_v_i16mf2x5_i16mf2(vint16mf2x5_t src, size_t index);
vint16mf2_t __riscv_vget_v_i16mf2x6_i16mf2(vint16mf2x6_t src, size_t index);
vint16mf2_t __riscv_vget_v_i16mf2x7_i16mf2(vint16mf2x7_t src, size_t index);
vint16mf2_t __riscv_vget_v_i16mf2x8_i16mf2(vint16mf2x8_t src, size_t index);
vint16m1_t __riscv_vget_v_i16m1x2_i16m1(vint16m1x2_t src, size_t index);
vint16m1_t __riscv_vget_v_i16m1x3_i16m1(vint16m1x3_t src, size_t index);
vint16m1_t __riscv_vget_v_i16m1x4_i16m1(vint16m1x4_t src, size_t index);
vint16m1_t __riscv_vget_v_i16m1x5_i16m1(vint16m1x5_t src, size_t index);
vint16m1_t __riscv_vget_v_i16m1x6_i16m1(vint16m1x6_t src, size_t index);
vint16m1_t __riscv_vget_v_i16m1x7_i16m1(vint16m1x7_t src, size_t index);
vint16m1_t __riscv_vget_v_i16m1x8_i16m1(vint16m1x8_t src, size_t index);
vint16m2_t __riscv_vget_v_i16m2x2_i16m2(vint16m2x2_t src, size_t index);
vint16m2_t __riscv_vget_v_i16m2x3_i16m2(vint16m2x3_t src, size_t index);
vint16m2_t __riscv_vget_v_i16m2x4_i16m2(vint16m2x4_t src, size_t index);
vint16m4_t __riscv_vget_v_i16m4x2_i16m4(vint16m4x2_t src, size_t index);
vint32mf2_t __riscv_vget_v_i32mf2x2_i32mf2(vint32mf2x2_t src, size_t index);
vint32mf2_t __riscv_vget_v_i32mf2x3_i32mf2(vint32mf2x3_t src, size_t index);
vint32mf2_t __riscv_vget_v_i32mf2x4_i32mf2(vint32mf2x4_t src, size_t index);
vint32mf2_t __riscv_vget_v_i32mf2x5_i32mf2(vint32mf2x5_t src, size_t index);
vint32mf2_t __riscv_vget_v_i32mf2x6_i32mf2(vint32mf2x6_t src, size_t index);
vint32mf2_t __riscv_vget_v_i32mf2x7_i32mf2(vint32mf2x7_t src, size_t index);
vint32mf2_t __riscv_vget_v_i32mf2x8_i32mf2(vint32mf2x8_t src, size_t index);
vint32m1_t __riscv_vget_v_i32m1x2_i32m1(vint32m1x2_t src, size_t index);
vint32m1_t __riscv_vget_v_i32m1x3_i32m1(vint32m1x3_t src, size_t index);
vint32m1_t __riscv_vget_v_i32m1x4_i32m1(vint32m1x4_t src, size_t index);
vint32m1_t __riscv_vget_v_i32m1x5_i32m1(vint32m1x5_t src, size_t index);
vint32m1_t __riscv_vget_v_i32m1x6_i32m1(vint32m1x6_t src, size_t index);
vint32m1_t __riscv_vget_v_i32m1x7_i32m1(vint32m1x7_t src, size_t index);
vint32m1_t __riscv_vget_v_i32m1x8_i32m1(vint32m1x8_t src, size_t index);
vint32m2_t __riscv_vget_v_i32m2x2_i32m2(vint32m2x2_t src, size_t index);
vint32m2_t __riscv_vget_v_i32m2x3_i32m2(vint32m2x3_t src, size_t index);
vint32m2_t __riscv_vget_v_i32m2x4_i32m2(vint32m2x4_t src, size_t index);
vint32m4_t __riscv_vget_v_i32m4x2_i32m4(vint32m4x2_t src, size_t index);
vint64m1_t __riscv_vget_v_i64m1x2_i64m1(vint64m1x2_t src, size_t index);
vint64m1_t __riscv_vget_v_i64m1x3_i64m1(vint64m1x3_t src, size_t index);
vint64m1_t __riscv_vget_v_i64m1x4_i64m1(vint64m1x4_t src, size_t index);
vint64m1_t __riscv_vget_v_i64m1x5_i64m1(vint64m1x5_t src, size_t index);
vint64m1_t __riscv_vget_v_i64m1x6_i64m1(vint64m1x6_t src, size_t index);
vint64m1_t __riscv_vget_v_i64m1x7_i64m1(vint64m1x7_t src, size_t index);
vint64m1_t __riscv_vget_v_i64m1x8_i64m1(vint64m1x8_t src, size_t index);
vint64m2_t __riscv_vget_v_i64m2x2_i64m2(vint64m2x2_t src, size_t index);
vint64m2_t __riscv_vget_v_i64m2x3_i64m2(vint64m2x3_t src, size_t index);
vint64m2_t __riscv_vget_v_i64m2x4_i64m2(vint64m2x4_t src, size_t index);
vint64m4_t __riscv_vget_v_i64m4x2_i64m4(vint64m4x2_t src, size_t index);
vuint8mf8_t __riscv_vget_v_u8mf8x2_u8mf8(vuint8mf8x2_t src, size_t index);
vuint8mf8_t __riscv_vget_v_u8mf8x3_u8mf8(vuint8mf8x3_t src, size_t index);
vuint8mf8_t __riscv_vget_v_u8mf8x4_u8mf8(vuint8mf8x4_t src, size_t index);
vuint8mf8_t __riscv_vget_v_u8mf8x5_u8mf8(vuint8mf8x5_t src, size_t index);
vuint8mf8_t __riscv_vget_v_u8mf8x6_u8mf8(vuint8mf8x6_t src, size_t index);
vuint8mf8_t __riscv_vget_v_u8mf8x7_u8mf8(vuint8mf8x7_t src, size_t index);
vuint8mf8_t __riscv_vget_v_u8mf8x8_u8mf8(vuint8mf8x8_t src, size_t index);
vuint8mf4_t __riscv_vget_v_u8mf4x2_u8mf4(vuint8mf4x2_t src, size_t index);
vuint8mf4_t __riscv_vget_v_u8mf4x3_u8mf4(vuint8mf4x3_t src, size_t index);
vuint8mf4_t __riscv_vget_v_u8mf4x4_u8mf4(vuint8mf4x4_t src, size_t index);
vuint8mf4_t __riscv_vget_v_u8mf4x5_u8mf4(vuint8mf4x5_t src, size_t index);
vuint8mf4_t __riscv_vget_v_u8mf4x6_u8mf4(vuint8mf4x6_t src, size_t index);
vuint8mf4_t __riscv_vget_v_u8mf4x7_u8mf4(vuint8mf4x7_t src, size_t index);
vuint8mf4_t __riscv_vget_v_u8mf4x8_u8mf4(vuint8mf4x8_t src, size_t index);
vuint8mf2_t __riscv_vget_v_u8mf2x2_u8mf2(vuint8mf2x2_t src, size_t index);
vuint8mf2_t __riscv_vget_v_u8mf2x3_u8mf2(vuint8mf2x3_t src, size_t index);
vuint8mf2_t __riscv_vget_v_u8mf2x4_u8mf2(vuint8mf2x4_t src, size_t index);
vuint8mf2_t __riscv_vget_v_u8mf2x5_u8mf2(vuint8mf2x5_t src, size_t index);
vuint8mf2_t __riscv_vget_v_u8mf2x6_u8mf2(vuint8mf2x6_t src, size_t index);
vuint8mf2_t __riscv_vget_v_u8mf2x7_u8mf2(vuint8mf2x7_t src, size_t index);
vuint8mf2_t __riscv_vget_v_u8mf2x8_u8mf2(vuint8mf2x8_t src, size_t index);
vuint8m1_t __riscv_vget_v_u8m1x2_u8m1(vuint8m1x2_t src, size_t index);
vuint8m1_t __riscv_vget_v_u8m1x3_u8m1(vuint8m1x3_t src, size_t index);
vuint8m1_t __riscv_vget_v_u8m1x4_u8m1(vuint8m1x4_t src, size_t index);
vuint8m1_t __riscv_vget_v_u8m1x5_u8m1(vuint8m1x5_t src, size_t index);
vuint8m1_t __riscv_vget_v_u8m1x6_u8m1(vuint8m1x6_t src, size_t index);
vuint8m1_t __riscv_vget_v_u8m1x7_u8m1(vuint8m1x7_t src, size_t index);
vuint8m1_t __riscv_vget_v_u8m1x8_u8m1(vuint8m1x8_t src, size_t index);
vuint8m2_t __riscv_vget_v_u8m2x2_u8m2(vuint8m2x2_t src, size_t index);
vuint8m2_t __riscv_vget_v_u8m2x3_u8m2(vuint8m2x3_t src, size_t index);
vuint8m2_t __riscv_vget_v_u8m2x4_u8m2(vuint8m2x4_t src, size_t index);
vuint8m4_t __riscv_vget_v_u8m4x2_u8m4(vuint8m4x2_t src, size_t index);
vuint16mf4_t __riscv_vget_v_u16mf4x2_u16mf4(vuint16mf4x2_t src, size_t index);
vuint16mf4_t __riscv_vget_v_u16mf4x3_u16mf4(vuint16mf4x3_t src, size_t index);
vuint16mf4_t __riscv_vget_v_u16mf4x4_u16mf4(vuint16mf4x4_t src, size_t index);
vuint16mf4_t __riscv_vget_v_u16mf4x5_u16mf4(vuint16mf4x5_t src, size_t index);
vuint16mf4_t __riscv_vget_v_u16mf4x6_u16mf4(vuint16mf4x6_t src, size_t index);
vuint16mf4_t __riscv_vget_v_u16mf4x7_u16mf4(vuint16mf4x7_t src, size_t index);
vuint16mf4_t __riscv_vget_v_u16mf4x8_u16mf4(vuint16mf4x8_t src, size_t index);
vuint16mf2_t __riscv_vget_v_u16mf2x2_u16mf2(vuint16mf2x2_t src, size_t index);
vuint16mf2_t __riscv_vget_v_u16mf2x3_u16mf2(vuint16mf2x3_t src, size_t index);
vuint16mf2_t __riscv_vget_v_u16mf2x4_u16mf2(vuint16mf2x4_t src, size_t index);
vuint16mf2_t __riscv_vget_v_u16mf2x5_u16mf2(vuint16mf2x5_t src, size_t index);
vuint16mf2_t __riscv_vget_v_u16mf2x6_u16mf2(vuint16mf2x6_t src, size_t index);
vuint16mf2_t __riscv_vget_v_u16mf2x7_u16mf2(vuint16mf2x7_t src, size_t index);
vuint16mf2_t __riscv_vget_v_u16mf2x8_u16mf2(vuint16mf2x8_t src, size_t index);
vuint16m1_t __riscv_vget_v_u16m1x2_u16m1(vuint16m1x2_t src, size_t index);
vuint16m1_t __riscv_vget_v_u16m1x3_u16m1(vuint16m1x3_t src, size_t index);
vuint16m1_t __riscv_vget_v_u16m1x4_u16m1(vuint16m1x4_t src, size_t index);
vuint16m1_t __riscv_vget_v_u16m1x5_u16m1(vuint16m1x5_t src, size_t index);
vuint16m1_t __riscv_vget_v_u16m1x6_u16m1(vuint16m1x6_t src, size_t index);
vuint16m1_t __riscv_vget_v_u16m1x7_u16m1(vuint16m1x7_t src, size_t index);
vuint16m1_t __riscv_vget_v_u16m1x8_u16m1(vuint16m1x8_t src, size_t index);
vuint16m2_t __riscv_vget_v_u16m2x2_u16m2(vuint16m2x2_t src, size_t index);
vuint16m2_t __riscv_vget_v_u16m2x3_u16m2(vuint16m2x3_t src, size_t index);
vuint16m2_t __riscv_vget_v_u16m2x4_u16m2(vuint16m2x4_t src, size_t index);
vuint16m4_t __riscv_vget_v_u16m4x2_u16m4(vuint16m4x2_t src, size_t index);
vuint32mf2_t __riscv_vget_v_u32mf2x2_u32mf2(vuint32mf2x2_t src, size_t index);
vuint32mf2_t __riscv_vget_v_u32mf2x3_u32mf2(vuint32mf2x3_t src, size_t index);
vuint32mf2_t __riscv_vget_v_u32mf2x4_u32mf2(vuint32mf2x4_t src, size_t index);
vuint32mf2_t __riscv_vget_v_u32mf2x5_u32mf2(vuint32mf2x5_t src, size_t index);
vuint32mf2_t __riscv_vget_v_u32mf2x6_u32mf2(vuint32mf2x6_t src, size_t index);
vuint32mf2_t __riscv_vget_v_u32mf2x7_u32mf2(vuint32mf2x7_t src, size_t index);
vuint32mf2_t __riscv_vget_v_u32mf2x8_u32mf2(vuint32mf2x8_t src, size_t index);
vuint32m1_t __riscv_vget_v_u32m1x2_u32m1(vuint32m1x2_t src, size_t index);
vuint32m1_t __riscv_vget_v_u32m1x3_u32m1(vuint32m1x3_t src, size_t index);
vuint32m1_t __riscv_vget_v_u32m1x4_u32m1(vuint32m1x4_t src, size_t index);
vuint32m1_t __riscv_vget_v_u32m1x5_u32m1(vuint32m1x5_t src, size_t index);
vuint32m1_t __riscv_vget_v_u32m1x6_u32m1(vuint32m1x6_t src, size_t index);
vuint32m1_t __riscv_vget_v_u32m1x7_u32m1(vuint32m1x7_t src, size_t index);
vuint32m1_t __riscv_vget_v_u32m1x8_u32m1(vuint32m1x8_t src, size_t index);
vuint32m2_t __riscv_vget_v_u32m2x2_u32m2(vuint32m2x2_t src, size_t index);
vuint32m2_t __riscv_vget_v_u32m2x3_u32m2(vuint32m2x3_t src, size_t index);
vuint32m2_t __riscv_vget_v_u32m2x4_u32m2(vuint32m2x4_t src, size_t index);
vuint32m4_t __riscv_vget_v_u32m4x2_u32m4(vuint32m4x2_t src, size_t index);
vuint64m1_t __riscv_vget_v_u64m1x2_u64m1(vuint64m1x2_t src, size_t index);
vuint64m1_t __riscv_vget_v_u64m1x3_u64m1(vuint64m1x3_t src, size_t index);
vuint64m1_t __riscv_vget_v_u64m1x4_u64m1(vuint64m1x4_t src, size_t index);
vuint64m1_t __riscv_vget_v_u64m1x5_u64m1(vuint64m1x5_t src, size_t index);
vuint64m1_t __riscv_vget_v_u64m1x6_u64m1(vuint64m1x6_t src, size_t index);
vuint64m1_t __riscv_vget_v_u64m1x7_u64m1(vuint64m1x7_t src, size_t index);
vuint64m1_t __riscv_vget_v_u64m1x8_u64m1(vuint64m1x8_t src, size_t index);
vuint64m2_t __riscv_vget_v_u64m2x2_u64m2(vuint64m2x2_t src, size_t index);
vuint64m2_t __riscv_vget_v_u64m2x3_u64m2(vuint64m2x3_t src, size_t index);
vuint64m2_t __riscv_vget_v_u64m2x4_u64m2(vuint64m2x4_t src, size_t index);
vuint64m4_t __riscv_vget_v_u64m4x2_u64m4(vuint64m4x2_t src, size_t index);
----

[[vector-creation]]
==== Vector Creation Intrinsics

[,c]
----
vfloat16m2_t __riscv_vcreate_v_f16m1_f16m2(vfloat16m1_t v0, vfloat16m1_t v1);
vfloat16m4_t __riscv_vcreate_v_f16m1_f16m4(vfloat16m1_t v0, vfloat16m1_t v1,
                                           vfloat16m1_t v2, vfloat16m1_t v3);
vfloat16m8_t __riscv_vcreate_v_f16m1_f16m8(vfloat16m1_t v0, vfloat16m1_t v1,
                                           vfloat16m1_t v2, vfloat16m1_t v3,
                                           vfloat16m1_t v4, vfloat16m1_t v5,
                                           vfloat16m1_t v6, vfloat16m1_t v7);
vfloat16m4_t __riscv_vcreate_v_f16m2_f16m4(vfloat16m2_t v0, vfloat16m2_t v1);
vfloat16m8_t __riscv_vcreate_v_f16m2_f16m8(vfloat16m2_t v0, vfloat16m2_t v1,
                                           vfloat16m2_t v2, vfloat16m2_t v3);
vfloat16m8_t __riscv_vcreate_v_f16m4_f16m8(vfloat16m4_t v0, vfloat16m4_t v1);
vfloat32m2_t __riscv_vcreate_v_f32m1_f32m2(vfloat32m1_t v0, vfloat32m1_t v1);
vfloat32m4_t __riscv_vcreate_v_f32m1_f32m4(vfloat32m1_t v0, vfloat32m1_t v1,
                                           vfloat32m1_t v2, vfloat32m1_t v3);
vfloat32m8_t __riscv_vcreate_v_f32m1_f32m8(vfloat32m1_t v0, vfloat32m1_t v1,
                                           vfloat32m1_t v2, vfloat32m1_t v3,
                                           vfloat32m1_t v4, vfloat32m1_t v5,
                                           vfloat32m1_t v6, vfloat32m1_t v7);
vfloat32m4_t __riscv_vcreate_v_f32m2_f32m4(vfloat32m2_t v0, vfloat32m2_t v1);
vfloat32m8_t __riscv_vcreate_v_f32m2_f32m8(vfloat32m2_t v0, vfloat32m2_t v1,
                                           vfloat32m2_t v2, vfloat32m2_t v3);
vfloat32m8_t __riscv_vcreate_v_f32m4_f32m8(vfloat32m4_t v0, vfloat32m4_t v1);
vfloat64m2_t __riscv_vcreate_v_f64m1_f64m2(vfloat64m1_t v0, vfloat64m1_t v1);
vfloat64m4_t __riscv_vcreate_v_f64m1_f64m4(vfloat64m1_t v0, vfloat64m1_t v1,
                                           vfloat64m1_t v2, vfloat64m1_t v3);
vfloat64m8_t __riscv_vcreate_v_f64m1_f64m8(vfloat64m1_t v0, vfloat64m1_t v1,
                                           vfloat64m1_t v2, vfloat64m1_t v3,
                                           vfloat64m1_t v4, vfloat64m1_t v5,
                                           vfloat64m1_t v6, vfloat64m1_t v7);
vfloat64m4_t __riscv_vcreate_v_f64m2_f64m4(vfloat64m2_t v0, vfloat64m2_t v1);
vfloat64m8_t __riscv_vcreate_v_f64m2_f64m8(vfloat64m2_t v0, vfloat64m2_t v1,
                                           vfloat64m2_t v2, vfloat64m2_t v3);
vfloat64m8_t __riscv_vcreate_v_f64m4_f64m8(vfloat64m4_t v0, vfloat64m4_t v1);
vint8m2_t __riscv_vcreate_v_i8m1_i8m2(vint8m1_t v0, vint8m1_t v1);
vint8m4_t __riscv_vcreate_v_i8m1_i8m4(vint8m1_t v0, vint8m1_t v1, vint8m1_t v2,
                                      vint8m1_t v3);
vint8m8_t __riscv_vcreate_v_i8m1_i8m8(vint8m1_t v0, vint8m1_t v1, vint8m1_t v2,
                                      vint8m1_t v3, vint8m1_t v4, vint8m1_t v5,
                                      vint8m1_t v6, vint8m1_t v7);
vint8m4_t __riscv_vcreate_v_i8m2_i8m4(vint8m2_t v0, vint8m2_t v1);
vint8m8_t __riscv_vcreate_v_i8m2_i8m8(vint8m2_t v0, vint8m2_t v1, vint8m2_t v2,
                                      vint8m2_t v3);
vint8m8_t __riscv_vcreate_v_i8m4_i8m8(vint8m4_t v0, vint8m4_t v1);
vint16m2_t __riscv_vcreate_v_i16m1_i16m2(vint16m1_t v0, vint16m1_t v1);
vint16m4_t __riscv_vcreate_v_i16m1_i16m4(vint16m1_t v0, vint16m1_t v1,
                                         vint16m1_t v2, vint16m1_t v3);
vint16m8_t __riscv_vcreate_v_i16m1_i16m8(vint16m1_t v0, vint16m1_t v1,
                                         vint16m1_t v2, vint16m1_t v3,
                                         vint16m1_t v4, vint16m1_t v5,
                                         vint16m1_t v6, vint16m1_t v7);
vint16m4_t __riscv_vcreate_v_i16m2_i16m4(vint16m2_t v0, vint16m2_t v1);
vint16m8_t __riscv_vcreate_v_i16m2_i16m8(vint16m2_t v0, vint16m2_t v1,
                                         vint16m2_t v2, vint16m2_t v3);
vint16m8_t __riscv_vcreate_v_i16m4_i16m8(vint16m4_t v0, vint16m4_t v1);
vint32m2_t __riscv_vcreate_v_i32m1_i32m2(vint32m1_t v0, vint32m1_t v1);
vint32m4_t __riscv_vcreate_v_i32m1_i32m4(vint32m1_t v0, vint32m1_t v1,
                                         vint32m1_t v2, vint32m1_t v3);
vint32m8_t __riscv_vcreate_v_i32m1_i32m8(vint32m1_t v0, vint32m1_t v1,
                                         vint32m1_t v2, vint32m1_t v3,
                                         vint32m1_t v4, vint32m1_t v5,
                                         vint32m1_t v6, vint32m1_t v7);
vint32m4_t __riscv_vcreate_v_i32m2_i32m4(vint32m2_t v0, vint32m2_t v1);
vint32m8_t __riscv_vcreate_v_i32m2_i32m8(vint32m2_t v0, vint32m2_t v1,
                                         vint32m2_t v2, vint32m2_t v3);
vint32m8_t __riscv_vcreate_v_i32m4_i32m8(vint32m4_t v0, vint32m4_t v1);
vint64m2_t __riscv_vcreate_v_i64m1_i64m2(vint64m1_t v0, vint64m1_t v1);
vint64m4_t __riscv_vcreate_v_i64m1_i64m4(vint64m1_t v0, vint64m1_t v1,
                                         vint64m1_t v2, vint64m1_t v3);
vint64m8_t __riscv_vcreate_v_i64m1_i64m8(vint64m1_t v0, vint64m1_t v1,
                                         vint64m1_t v2, vint64m1_t v3,
                                         vint64m1_t v4, vint64m1_t v5,
                                         vint64m1_t v6, vint64m1_t v7);
vint64m4_t __riscv_vcreate_v_i64m2_i64m4(vint64m2_t v0, vint64m2_t v1);
vint64m8_t __riscv_vcreate_v_i64m2_i64m8(vint64m2_t v0, vint64m2_t v1,
                                         vint64m2_t v2, vint64m2_t v3);
vint64m8_t __riscv_vcreate_v_i64m4_i64m8(vint64m4_t v0, vint64m4_t v1);
vuint8m2_t __riscv_vcreate_v_u8m1_u8m2(vuint8m1_t v0, vuint8m1_t v1);
vuint8m4_t __riscv_vcreate_v_u8m1_u8m4(vuint8m1_t v0, vuint8m1_t v1,
                                       vuint8m1_t v2, vuint8m1_t v3);
vuint8m8_t __riscv_vcreate_v_u8m1_u8m8(vuint8m1_t v0, vuint8m1_t v1,
                                       vuint8m1_t v2, vuint8m1_t v3,
                                       vuint8m1_t v4, vuint8m1_t v5,
                                       vuint8m1_t v6, vuint8m1_t v7);
vuint8m4_t __riscv_vcreate_v_u8m2_u8m4(vuint8m2_t v0, vuint8m2_t v1);
vuint8m8_t __riscv_vcreate_v_u8m2_u8m8(vuint8m2_t v0, vuint8m2_t v1,
                                       vuint8m2_t v2, vuint8m2_t v3);
vuint8m8_t __riscv_vcreate_v_u8m4_u8m8(vuint8m4_t v0, vuint8m4_t v1);
vuint16m2_t __riscv_vcreate_v_u16m1_u16m2(vuint16m1_t v0, vuint16m1_t v1);
vuint16m4_t __riscv_vcreate_v_u16m1_u16m4(vuint16m1_t v0, vuint16m1_t v1,
                                          vuint16m1_t v2, vuint16m1_t v3);
vuint16m8_t __riscv_vcreate_v_u16m1_u16m8(vuint16m1_t v0, vuint16m1_t v1,
                                          vuint16m1_t v2, vuint16m1_t v3,
                                          vuint16m1_t v4, vuint16m1_t v5,
                                          vuint16m1_t v6, vuint16m1_t v7);
vuint16m4_t __riscv_vcreate_v_u16m2_u16m4(vuint16m2_t v0, vuint16m2_t v1);
vuint16m8_t __riscv_vcreate_v_u16m2_u16m8(vuint16m2_t v0, vuint16m2_t v1,
                                          vuint16m2_t v2, vuint16m2_t v3);
vuint16m8_t __riscv_vcreate_v_u16m4_u16m8(vuint16m4_t v0, vuint16m4_t v1);
vuint32m2_t __riscv_vcreate_v_u32m1_u32m2(vuint32m1_t v0, vuint32m1_t v1);
vuint32m4_t __riscv_vcreate_v_u32m1_u32m4(vuint32m1_t v0, vuint32m1_t v1,
                                          vuint32m1_t v2, vuint32m1_t v3);
vuint32m8_t __riscv_vcreate_v_u32m1_u32m8(vuint32m1_t v0, vuint32m1_t v1,
                                          vuint32m1_t v2, vuint32m1_t v3,
                                          vuint32m1_t v4, vuint32m1_t v5,
                                          vuint32m1_t v6, vuint32m1_t v7);
vuint32m4_t __riscv_vcreate_v_u32m2_u32m4(vuint32m2_t v0, vuint32m2_t v1);
vuint32m8_t __riscv_vcreate_v_u32m2_u32m8(vuint32m2_t v0, vuint32m2_t v1,
                                          vuint32m2_t v2, vuint32m2_t v3);
vuint32m8_t __riscv_vcreate_v_u32m4_u32m8(vuint32m4_t v0, vuint32m4_t v1);
vuint64m2_t __riscv_vcreate_v_u64m1_u64m2(vuint64m1_t v0, vuint64m1_t v1);
vuint64m4_t __riscv_vcreate_v_u64m1_u64m4(vuint64m1_t v0, vuint64m1_t v1,
                                          vuint64m1_t v2, vuint64m1_t v3);
vuint64m8_t __riscv_vcreate_v_u64m1_u64m8(vuint64m1_t v0, vuint64m1_t v1,
                                          vuint64m1_t v2, vuint64m1_t v3,
                                          vuint64m1_t v4, vuint64m1_t v5,
                                          vuint64m1_t v6, vuint64m1_t v7);
vuint64m4_t __riscv_vcreate_v_u64m2_u64m4(vuint64m2_t v0, vuint64m2_t v1);
vuint64m8_t __riscv_vcreate_v_u64m2_u64m8(vuint64m2_t v0, vuint64m2_t v1,
                                          vuint64m2_t v2, vuint64m2_t v3);
vuint64m8_t __riscv_vcreate_v_u64m4_u64m8(vuint64m4_t v0, vuint64m4_t v1);
vfloat16mf4x2_t __riscv_vcreate_v_f16mf4x2(vfloat16mf4_t v0, vfloat16mf4_t v1);
vfloat16mf4x3_t __riscv_vcreate_v_f16mf4x3(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2);
vfloat16mf4x4_t __riscv_vcreate_v_f16mf4x4(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2, vfloat16mf4_t v3);
vfloat16mf4x5_t __riscv_vcreate_v_f16mf4x5(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2, vfloat16mf4_t v3,
                                           vfloat16mf4_t v4);
vfloat16mf4x6_t __riscv_vcreate_v_f16mf4x6(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2, vfloat16mf4_t v3,
                                           vfloat16mf4_t v4, vfloat16mf4_t v5);
vfloat16mf4x7_t __riscv_vcreate_v_f16mf4x7(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2, vfloat16mf4_t v3,
                                           vfloat16mf4_t v4, vfloat16mf4_t v5,
                                           vfloat16mf4_t v6);
vfloat16mf4x8_t __riscv_vcreate_v_f16mf4x8(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2, vfloat16mf4_t v3,
                                           vfloat16mf4_t v4, vfloat16mf4_t v5,
                                           vfloat16mf4_t v6, vfloat16mf4_t v7);
vfloat16mf2x2_t __riscv_vcreate_v_f16mf2x2(vfloat16mf2_t v0, vfloat16mf2_t v1);
vfloat16mf2x3_t __riscv_vcreate_v_f16mf2x3(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2);
vfloat16mf2x4_t __riscv_vcreate_v_f16mf2x4(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2, vfloat16mf2_t v3);
vfloat16mf2x5_t __riscv_vcreate_v_f16mf2x5(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2, vfloat16mf2_t v3,
                                           vfloat16mf2_t v4);
vfloat16mf2x6_t __riscv_vcreate_v_f16mf2x6(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2, vfloat16mf2_t v3,
                                           vfloat16mf2_t v4, vfloat16mf2_t v5);
vfloat16mf2x7_t __riscv_vcreate_v_f16mf2x7(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2, vfloat16mf2_t v3,
                                           vfloat16mf2_t v4, vfloat16mf2_t v5,
                                           vfloat16mf2_t v6);
vfloat16mf2x8_t __riscv_vcreate_v_f16mf2x8(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2, vfloat16mf2_t v3,
                                           vfloat16mf2_t v4, vfloat16mf2_t v5,
                                           vfloat16mf2_t v6, vfloat16mf2_t v7);
vfloat16m1x2_t __riscv_vcreate_v_f16m1x2(vfloat16m1_t v0, vfloat16m1_t v1);
vfloat16m1x3_t __riscv_vcreate_v_f16m1x3(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2);
vfloat16m1x4_t __riscv_vcreate_v_f16m1x4(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2, vfloat16m1_t v3);
vfloat16m1x5_t __riscv_vcreate_v_f16m1x5(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2, vfloat16m1_t v3,
                                         vfloat16m1_t v4);
vfloat16m1x6_t __riscv_vcreate_v_f16m1x6(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2, vfloat16m1_t v3,
                                         vfloat16m1_t v4, vfloat16m1_t v5);
vfloat16m1x7_t __riscv_vcreate_v_f16m1x7(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2, vfloat16m1_t v3,
                                         vfloat16m1_t v4, vfloat16m1_t v5,
                                         vfloat16m1_t v6);
vfloat16m1x8_t __riscv_vcreate_v_f16m1x8(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2, vfloat16m1_t v3,
                                         vfloat16m1_t v4, vfloat16m1_t v5,
                                         vfloat16m1_t v6, vfloat16m1_t v7);
vfloat16m2x2_t __riscv_vcreate_v_f16m2x2(vfloat16m2_t v0, vfloat16m2_t v1);
vfloat16m2x3_t __riscv_vcreate_v_f16m2x3(vfloat16m2_t v0, vfloat16m2_t v1,
                                         vfloat16m2_t v2);
vfloat16m2x4_t __riscv_vcreate_v_f16m2x4(vfloat16m2_t v0, vfloat16m2_t v1,
                                         vfloat16m2_t v2, vfloat16m2_t v3);
vfloat16m4x2_t __riscv_vcreate_v_f16m4x2(vfloat16m4_t v0, vfloat16m4_t v1);
vfloat32mf2x2_t __riscv_vcreate_v_f32mf2x2(vfloat32mf2_t v0, vfloat32mf2_t v1);
vfloat32mf2x3_t __riscv_vcreate_v_f32mf2x3(vfloat32mf2_t v0, vfloat32mf2_t v1,
                                           vfloat32mf2_t v2);
vfloat32mf2x4_t __riscv_vcreate_v_f32mf2x4(vfloat32mf2_t v0, vfloat32mf2_t v1,
                                           vfloat32mf2_t v2, vfloat32mf2_t v3);
vfloat32mf2x5_t __riscv_vcreate_v_f32mf2x5(vfloat32mf2_t v0, vfloat32mf2_t v1,
                                           vfloat32mf2_t v2, vfloat32mf2_t v3,
                                           vfloat32mf2_t v4);
vfloat32mf2x6_t __riscv_vcreate_v_f32mf2x6(vfloat32mf2_t v0, vfloat32mf2_t v1,
                                           vfloat32mf2_t v2, vfloat32mf2_t v3,
                                           vfloat32mf2_t v4, vfloat32mf2_t v5);
vfloat32mf2x7_t __riscv_vcreate_v_f32mf2x7(vfloat32mf2_t v0, vfloat32mf2_t v1,
                                           vfloat32mf2_t v2, vfloat32mf2_t v3,
                                           vfloat32mf2_t v4, vfloat32mf2_t v5,
                                           vfloat32mf2_t v6);
vfloat32mf2x8_t __riscv_vcreate_v_f32mf2x8(vfloat32mf2_t v0, vfloat32mf2_t v1,
                                           vfloat32mf2_t v2, vfloat32mf2_t v3,
                                           vfloat32mf2_t v4, vfloat32mf2_t v5,
                                           vfloat32mf2_t v6, vfloat32mf2_t v7);
vfloat32m1x2_t __riscv_vcreate_v_f32m1x2(vfloat32m1_t v0, vfloat32m1_t v1);
vfloat32m1x3_t __riscv_vcreate_v_f32m1x3(vfloat32m1_t v0, vfloat32m1_t v1,
                                         vfloat32m1_t v2);
vfloat32m1x4_t __riscv_vcreate_v_f32m1x4(vfloat32m1_t v0, vfloat32m1_t v1,
                                         vfloat32m1_t v2, vfloat32m1_t v3);
vfloat32m1x5_t __riscv_vcreate_v_f32m1x5(vfloat32m1_t v0, vfloat32m1_t v1,
                                         vfloat32m1_t v2, vfloat32m1_t v3,
                                         vfloat32m1_t v4);
vfloat32m1x6_t __riscv_vcreate_v_f32m1x6(vfloat32m1_t v0, vfloat32m1_t v1,
                                         vfloat32m1_t v2, vfloat32m1_t v3,
                                         vfloat32m1_t v4, vfloat32m1_t v5);
vfloat32m1x7_t __riscv_vcreate_v_f32m1x7(vfloat32m1_t v0, vfloat32m1_t v1,
                                         vfloat32m1_t v2, vfloat32m1_t v3,
                                         vfloat32m1_t v4, vfloat32m1_t v5,
                                         vfloat32m1_t v6);
vfloat32m1x8_t __riscv_vcreate_v_f32m1x8(vfloat32m1_t v0, vfloat32m1_t v1,
                                         vfloat32m1_t v2, vfloat32m1_t v3,
                                         vfloat32m1_t v4, vfloat32m1_t v5,
                                         vfloat32m1_t v6, vfloat32m1_t v7);
vfloat32m2x2_t __riscv_vcreate_v_f32m2x2(vfloat32m2_t v0, vfloat32m2_t v1);
vfloat32m2x3_t __riscv_vcreate_v_f32m2x3(vfloat32m2_t v0, vfloat32m2_t v1,
                                         vfloat32m2_t v2);
vfloat32m2x4_t __riscv_vcreate_v_f32m2x4(vfloat32m2_t v0, vfloat32m2_t v1,
                                         vfloat32m2_t v2, vfloat32m2_t v3);
vfloat32m4x2_t __riscv_vcreate_v_f32m4x2(vfloat32m4_t v0, vfloat32m4_t v1);
vfloat64m1x2_t __riscv_vcreate_v_f64m1x2(vfloat64m1_t v0, vfloat64m1_t v1);
vfloat64m1x3_t __riscv_vcreate_v_f64m1x3(vfloat64m1_t v0, vfloat64m1_t v1,
                                         vfloat64m1_t v2);
vfloat64m1x4_t __riscv_vcreate_v_f64m1x4(vfloat64m1_t v0, vfloat64m1_t v1,
                                         vfloat64m1_t v2, vfloat64m1_t v3);
vfloat64m1x5_t __riscv_vcreate_v_f64m1x5(vfloat64m1_t v0, vfloat64m1_t v1,
                                         vfloat64m1_t v2, vfloat64m1_t v3,
                                         vfloat64m1_t v4);
vfloat64m1x6_t __riscv_vcreate_v_f64m1x6(vfloat64m1_t v0, vfloat64m1_t v1,
                                         vfloat64m1_t v2, vfloat64m1_t v3,
                                         vfloat64m1_t v4, vfloat64m1_t v5);
vfloat64m1x7_t __riscv_vcreate_v_f64m1x7(vfloat64m1_t v0, vfloat64m1_t v1,
                                         vfloat64m1_t v2, vfloat64m1_t v3,
                                         vfloat64m1_t v4, vfloat64m1_t v5,
                                         vfloat64m1_t v6);
vfloat64m1x8_t __riscv_vcreate_v_f64m1x8(vfloat64m1_t v0, vfloat64m1_t v1,
                                         vfloat64m1_t v2, vfloat64m1_t v3,
                                         vfloat64m1_t v4, vfloat64m1_t v5,
                                         vfloat64m1_t v6, vfloat64m1_t v7);
vfloat64m2x2_t __riscv_vcreate_v_f64m2x2(vfloat64m2_t v0, vfloat64m2_t v1);
vfloat64m2x3_t __riscv_vcreate_v_f64m2x3(vfloat64m2_t v0, vfloat64m2_t v1,
                                         vfloat64m2_t v2);
vfloat64m2x4_t __riscv_vcreate_v_f64m2x4(vfloat64m2_t v0, vfloat64m2_t v1,
                                         vfloat64m2_t v2, vfloat64m2_t v3);
vfloat64m4x2_t __riscv_vcreate_v_f64m4x2(vfloat64m4_t v0, vfloat64m4_t v1);
vint8mf8x2_t __riscv_vcreate_v_i8mf8x2(vint8mf8_t v0, vint8mf8_t v1);
vint8mf8x3_t __riscv_vcreate_v_i8mf8x3(vint8mf8_t v0, vint8mf8_t v1,
                                       vint8mf8_t v2);
vint8mf8x4_t __riscv_vcreate_v_i8mf8x4(vint8mf8_t v0, vint8mf8_t v1,
                                       vint8mf8_t v2, vint8mf8_t v3);
vint8mf8x5_t __riscv_vcreate_v_i8mf8x5(vint8mf8_t v0, vint8mf8_t v1,
                                       vint8mf8_t v2, vint8mf8_t v3,
                                       vint8mf8_t v4);
vint8mf8x6_t __riscv_vcreate_v_i8mf8x6(vint8mf8_t v0, vint8mf8_t v1,
                                       vint8mf8_t v2, vint8mf8_t v3,
                                       vint8mf8_t v4, vint8mf8_t v5);
vint8mf8x7_t __riscv_vcreate_v_i8mf8x7(vint8mf8_t v0, vint8mf8_t v1,
                                       vint8mf8_t v2, vint8mf8_t v3,
                                       vint8mf8_t v4, vint8mf8_t v5,
                                       vint8mf8_t v6);
vint8mf8x8_t __riscv_vcreate_v_i8mf8x8(vint8mf8_t v0, vint8mf8_t v1,
                                       vint8mf8_t v2, vint8mf8_t v3,
                                       vint8mf8_t v4, vint8mf8_t v5,
                                       vint8mf8_t v6, vint8mf8_t v7);
vint8mf4x2_t __riscv_vcreate_v_i8mf4x2(vint8mf4_t v0, vint8mf4_t v1);
vint8mf4x3_t __riscv_vcreate_v_i8mf4x3(vint8mf4_t v0, vint8mf4_t v1,
                                       vint8mf4_t v2);
vint8mf4x4_t __riscv_vcreate_v_i8mf4x4(vint8mf4_t v0, vint8mf4_t v1,
                                       vint8mf4_t v2, vint8mf4_t v3);
vint8mf4x5_t __riscv_vcreate_v_i8mf4x5(vint8mf4_t v0, vint8mf4_t v1,
                                       vint8mf4_t v2, vint8mf4_t v3,
                                       vint8mf4_t v4);
vint8mf4x6_t __riscv_vcreate_v_i8mf4x6(vint8mf4_t v0, vint8mf4_t v1,
                                       vint8mf4_t v2, vint8mf4_t v3,
                                       vint8mf4_t v4, vint8mf4_t v5);
vint8mf4x7_t __riscv_vcreate_v_i8mf4x7(vint8mf4_t v0, vint8mf4_t v1,
                                       vint8mf4_t v2, vint8mf4_t v3,
                                       vint8mf4_t v4, vint8mf4_t v5,
                                       vint8mf4_t v6);
vint8mf4x8_t __riscv_vcreate_v_i8mf4x8(vint8mf4_t v0, vint8mf4_t v1,
                                       vint8mf4_t v2, vint8mf4_t v3,
                                       vint8mf4_t v4, vint8mf4_t v5,
                                       vint8mf4_t v6, vint8mf4_t v7);
vint8mf2x2_t __riscv_vcreate_v_i8mf2x2(vint8mf2_t v0, vint8mf2_t v1);
vint8mf2x3_t __riscv_vcreate_v_i8mf2x3(vint8mf2_t v0, vint8mf2_t v1,
                                       vint8mf2_t v2);
vint8mf2x4_t __riscv_vcreate_v_i8mf2x4(vint8mf2_t v0, vint8mf2_t v1,
                                       vint8mf2_t v2, vint8mf2_t v3);
vint8mf2x5_t __riscv_vcreate_v_i8mf2x5(vint8mf2_t v0, vint8mf2_t v1,
                                       vint8mf2_t v2, vint8mf2_t v3,
                                       vint8mf2_t v4);
vint8mf2x6_t __riscv_vcreate_v_i8mf2x6(vint8mf2_t v0, vint8mf2_t v1,
                                       vint8mf2_t v2, vint8mf2_t v3,
                                       vint8mf2_t v4, vint8mf2_t v5);
vint8mf2x7_t __riscv_vcreate_v_i8mf2x7(vint8mf2_t v0, vint8mf2_t v1,
                                       vint8mf2_t v2, vint8mf2_t v3,
                                       vint8mf2_t v4, vint8mf2_t v5,
                                       vint8mf2_t v6);
vint8mf2x8_t __riscv_vcreate_v_i8mf2x8(vint8mf2_t v0, vint8mf2_t v1,
                                       vint8mf2_t v2, vint8mf2_t v3,
                                       vint8mf2_t v4, vint8mf2_t v5,
                                       vint8mf2_t v6, vint8mf2_t v7);
vint8m1x2_t __riscv_vcreate_v_i8m1x2(vint8m1_t v0, vint8m1_t v1);
vint8m1x3_t __riscv_vcreate_v_i8m1x3(vint8m1_t v0, vint8m1_t v1, vint8m1_t v2);
vint8m1x4_t __riscv_vcreate_v_i8m1x4(vint8m1_t v0, vint8m1_t v1, vint8m1_t v2,
                                     vint8m1_t v3);
vint8m1x5_t __riscv_vcreate_v_i8m1x5(vint8m1_t v0, vint8m1_t v1, vint8m1_t v2,
                                     vint8m1_t v3, vint8m1_t v4);
vint8m1x6_t __riscv_vcreate_v_i8m1x6(vint8m1_t v0, vint8m1_t v1, vint8m1_t v2,
                                     vint8m1_t v3, vint8m1_t v4, vint8m1_t v5);
vint8m1x7_t __riscv_vcreate_v_i8m1x7(vint8m1_t v0, vint8m1_t v1, vint8m1_t v2,
                                     vint8m1_t v3, vint8m1_t v4, vint8m1_t v5,
                                     vint8m1_t v6);
vint8m1x8_t __riscv_vcreate_v_i8m1x8(vint8m1_t v0, vint8m1_t v1, vint8m1_t v2,
                                     vint8m1_t v3, vint8m1_t v4, vint8m1_t v5,
                                     vint8m1_t v6, vint8m1_t v7);
vint8m2x2_t __riscv_vcreate_v_i8m2x2(vint8m2_t v0, vint8m2_t v1);
vint8m2x3_t __riscv_vcreate_v_i8m2x3(vint8m2_t v0, vint8m2_t v1, vint8m2_t v2);
vint8m2x4_t __riscv_vcreate_v_i8m2x4(vint8m2_t v0, vint8m2_t v1, vint8m2_t v2,
                                     vint8m2_t v3);
vint8m4x2_t __riscv_vcreate_v_i8m4x2(vint8m4_t v0, vint8m4_t v1);
vint16mf4x2_t __riscv_vcreate_v_i16mf4x2(vint16mf4_t v0, vint16mf4_t v1);
vint16mf4x3_t __riscv_vcreate_v_i16mf4x3(vint16mf4_t v0, vint16mf4_t v1,
                                         vint16mf4_t v2);
vint16mf4x4_t __riscv_vcreate_v_i16mf4x4(vint16mf4_t v0, vint16mf4_t v1,
                                         vint16mf4_t v2, vint16mf4_t v3);
vint16mf4x5_t __riscv_vcreate_v_i16mf4x5(vint16mf4_t v0, vint16mf4_t v1,
                                         vint16mf4_t v2, vint16mf4_t v3,
                                         vint16mf4_t v4);
vint16mf4x6_t __riscv_vcreate_v_i16mf4x6(vint16mf4_t v0, vint16mf4_t v1,
                                         vint16mf4_t v2, vint16mf4_t v3,
                                         vint16mf4_t v4, vint16mf4_t v5);
vint16mf4x7_t __riscv_vcreate_v_i16mf4x7(vint16mf4_t v0, vint16mf4_t v1,
                                         vint16mf4_t v2, vint16mf4_t v3,
                                         vint16mf4_t v4, vint16mf4_t v5,
                                         vint16mf4_t v6);
vint16mf4x8_t __riscv_vcreate_v_i16mf4x8(vint16mf4_t v0, vint16mf4_t v1,
                                         vint16mf4_t v2, vint16mf4_t v3,
                                         vint16mf4_t v4, vint16mf4_t v5,
                                         vint16mf4_t v6, vint16mf4_t v7);
vint16mf2x2_t __riscv_vcreate_v_i16mf2x2(vint16mf2_t v0, vint16mf2_t v1);
vint16mf2x3_t __riscv_vcreate_v_i16mf2x3(vint16mf2_t v0, vint16mf2_t v1,
                                         vint16mf2_t v2);
vint16mf2x4_t __riscv_vcreate_v_i16mf2x4(vint16mf2_t v0, vint16mf2_t v1,
                                         vint16mf2_t v2, vint16mf2_t v3);
vint16mf2x5_t __riscv_vcreate_v_i16mf2x5(vint16mf2_t v0, vint16mf2_t v1,
                                         vint16mf2_t v2, vint16mf2_t v3,
                                         vint16mf2_t v4);
vint16mf2x6_t __riscv_vcreate_v_i16mf2x6(vint16mf2_t v0, vint16mf2_t v1,
                                         vint16mf2_t v2, vint16mf2_t v3,
                                         vint16mf2_t v4, vint16mf2_t v5);
vint16mf2x7_t __riscv_vcreate_v_i16mf2x7(vint16mf2_t v0, vint16mf2_t v1,
                                         vint16mf2_t v2, vint16mf2_t v3,
                                         vint16mf2_t v4, vint16mf2_t v5,
                                         vint16mf2_t v6);
vint16mf2x8_t __riscv_vcreate_v_i16mf2x8(vint16mf2_t v0, vint16mf2_t v1,
                                         vint16mf2_t v2, vint16mf2_t v3,
                                         vint16mf2_t v4, vint16mf2_t v5,
                                         vint16mf2_t v6, vint16mf2_t v7);
vint16m1x2_t __riscv_vcreate_v_i16m1x2(vint16m1_t v0, vint16m1_t v1);
vint16m1x3_t __riscv_vcreate_v_i16m1x3(vint16m1_t v0, vint16m1_t v1,
                                       vint16m1_t v2);
vint16m1x4_t __riscv_vcreate_v_i16m1x4(vint16m1_t v0, vint16m1_t v1,
                                       vint16m1_t v2, vint16m1_t v3);
vint16m1x5_t __riscv_vcreate_v_i16m1x5(vint16m1_t v0, vint16m1_t v1,
                                       vint16m1_t v2, vint16m1_t v3,
                                       vint16m1_t v4);
vint16m1x6_t __riscv_vcreate_v_i16m1x6(vint16m1_t v0, vint16m1_t v1,
                                       vint16m1_t v2, vint16m1_t v3,
                                       vint16m1_t v4, vint16m1_t v5);
vint16m1x7_t __riscv_vcreate_v_i16m1x7(vint16m1_t v0, vint16m1_t v1,
                                       vint16m1_t v2, vint16m1_t v3,
                                       vint16m1_t v4, vint16m1_t v5,
                                       vint16m1_t v6);
vint16m1x8_t __riscv_vcreate_v_i16m1x8(vint16m1_t v0, vint16m1_t v1,
                                       vint16m1_t v2, vint16m1_t v3,
                                       vint16m1_t v4, vint16m1_t v5,
                                       vint16m1_t v6, vint16m1_t v7);
vint16m2x2_t __riscv_vcreate_v_i16m2x2(vint16m2_t v0, vint16m2_t v1);
vint16m2x3_t __riscv_vcreate_v_i16m2x3(vint16m2_t v0, vint16m2_t v1,
                                       vint16m2_t v2);
vint16m2x4_t __riscv_vcreate_v_i16m2x4(vint16m2_t v0, vint16m2_t v1,
                                       vint16m2_t v2, vint16m2_t v3);
vint16m4x2_t __riscv_vcreate_v_i16m4x2(vint16m4_t v0, vint16m4_t v1);
vint32mf2x2_t __riscv_vcreate_v_i32mf2x2(vint32mf2_t v0, vint32mf2_t v1);
vint32mf2x3_t __riscv_vcreate_v_i32mf2x3(vint32mf2_t v0, vint32mf2_t v1,
                                         vint32mf2_t v2);
vint32mf2x4_t __riscv_vcreate_v_i32mf2x4(vint32mf2_t v0, vint32mf2_t v1,
                                         vint32mf2_t v2, vint32mf2_t v3);
vint32mf2x5_t __riscv_vcreate_v_i32mf2x5(vint32mf2_t v0, vint32mf2_t v1,
                                         vint32mf2_t v2, vint32mf2_t v3,
                                         vint32mf2_t v4);
vint32mf2x6_t __riscv_vcreate_v_i32mf2x6(vint32mf2_t v0, vint32mf2_t v1,
                                         vint32mf2_t v2, vint32mf2_t v3,
                                         vint32mf2_t v4, vint32mf2_t v5);
vint32mf2x7_t __riscv_vcreate_v_i32mf2x7(vint32mf2_t v0, vint32mf2_t v1,
                                         vint32mf2_t v2, vint32mf2_t v3,
                                         vint32mf2_t v4, vint32mf2_t v5,
                                         vint32mf2_t v6);
vint32mf2x8_t __riscv_vcreate_v_i32mf2x8(vint32mf2_t v0, vint32mf2_t v1,
                                         vint32mf2_t v2, vint32mf2_t v3,
                                         vint32mf2_t v4, vint32mf2_t v5,
                                         vint32mf2_t v6, vint32mf2_t v7);
vint32m1x2_t __riscv_vcreate_v_i32m1x2(vint32m1_t v0, vint32m1_t v1);
vint32m1x3_t __riscv_vcreate_v_i32m1x3(vint32m1_t v0, vint32m1_t v1,
                                       vint32m1_t v2);
vint32m1x4_t __riscv_vcreate_v_i32m1x4(vint32m1_t v0, vint32m1_t v1,
                                       vint32m1_t v2, vint32m1_t v3);
vint32m1x5_t __riscv_vcreate_v_i32m1x5(vint32m1_t v0, vint32m1_t v1,
                                       vint32m1_t v2, vint32m1_t v3,
                                       vint32m1_t v4);
vint32m1x6_t __riscv_vcreate_v_i32m1x6(vint32m1_t v0, vint32m1_t v1,
                                       vint32m1_t v2, vint32m1_t v3,
                                       vint32m1_t v4, vint32m1_t v5);
vint32m1x7_t __riscv_vcreate_v_i32m1x7(vint32m1_t v0, vint32m1_t v1,
                                       vint32m1_t v2, vint32m1_t v3,
                                       vint32m1_t v4, vint32m1_t v5,
                                       vint32m1_t v6);
vint32m1x8_t __riscv_vcreate_v_i32m1x8(vint32m1_t v0, vint32m1_t v1,
                                       vint32m1_t v2, vint32m1_t v3,
                                       vint32m1_t v4, vint32m1_t v5,
                                       vint32m1_t v6, vint32m1_t v7);
vint32m2x2_t __riscv_vcreate_v_i32m2x2(vint32m2_t v0, vint32m2_t v1);
vint32m2x3_t __riscv_vcreate_v_i32m2x3(vint32m2_t v0, vint32m2_t v1,
                                       vint32m2_t v2);
vint32m2x4_t __riscv_vcreate_v_i32m2x4(vint32m2_t v0, vint32m2_t v1,
                                       vint32m2_t v2, vint32m2_t v3);
vint32m4x2_t __riscv_vcreate_v_i32m4x2(vint32m4_t v0, vint32m4_t v1);
vint64m1x2_t __riscv_vcreate_v_i64m1x2(vint64m1_t v0, vint64m1_t v1);
vint64m1x3_t __riscv_vcreate_v_i64m1x3(vint64m1_t v0, vint64m1_t v1,
                                       vint64m1_t v2);
vint64m1x4_t __riscv_vcreate_v_i64m1x4(vint64m1_t v0, vint64m1_t v1,
                                       vint64m1_t v2, vint64m1_t v3);
vint64m1x5_t __riscv_vcreate_v_i64m1x5(vint64m1_t v0, vint64m1_t v1,
                                       vint64m1_t v2, vint64m1_t v3,
                                       vint64m1_t v4);
vint64m1x6_t __riscv_vcreate_v_i64m1x6(vint64m1_t v0, vint64m1_t v1,
                                       vint64m1_t v2, vint64m1_t v3,
                                       vint64m1_t v4, vint64m1_t v5);
vint64m1x7_t __riscv_vcreate_v_i64m1x7(vint64m1_t v0, vint64m1_t v1,
                                       vint64m1_t v2, vint64m1_t v3,
                                       vint64m1_t v4, vint64m1_t v5,
                                       vint64m1_t v6);
vint64m1x8_t __riscv_vcreate_v_i64m1x8(vint64m1_t v0, vint64m1_t v1,
                                       vint64m1_t v2, vint64m1_t v3,
                                       vint64m1_t v4, vint64m1_t v5,
                                       vint64m1_t v6, vint64m1_t v7);
vint64m2x2_t __riscv_vcreate_v_i64m2x2(vint64m2_t v0, vint64m2_t v1);
vint64m2x3_t __riscv_vcreate_v_i64m2x3(vint64m2_t v0, vint64m2_t v1,
                                       vint64m2_t v2);
vint64m2x4_t __riscv_vcreate_v_i64m2x4(vint64m2_t v0, vint64m2_t v1,
                                       vint64m2_t v2, vint64m2_t v3);
vint64m4x2_t __riscv_vcreate_v_i64m4x2(vint64m4_t v0, vint64m4_t v1);
vuint8mf8x2_t __riscv_vcreate_v_u8mf8x2(vuint8mf8_t v0, vuint8mf8_t v1);
vuint8mf8x3_t __riscv_vcreate_v_u8mf8x3(vuint8mf8_t v0, vuint8mf8_t v1,
                                        vuint8mf8_t v2);
vuint8mf8x4_t __riscv_vcreate_v_u8mf8x4(vuint8mf8_t v0, vuint8mf8_t v1,
                                        vuint8mf8_t v2, vuint8mf8_t v3);
vuint8mf8x5_t __riscv_vcreate_v_u8mf8x5(vuint8mf8_t v0, vuint8mf8_t v1,
                                        vuint8mf8_t v2, vuint8mf8_t v3,
                                        vuint8mf8_t v4);
vuint8mf8x6_t __riscv_vcreate_v_u8mf8x6(vuint8mf8_t v0, vuint8mf8_t v1,
                                        vuint8mf8_t v2, vuint8mf8_t v3,
                                        vuint8mf8_t v4, vuint8mf8_t v5);
vuint8mf8x7_t __riscv_vcreate_v_u8mf8x7(vuint8mf8_t v0, vuint8mf8_t v1,
                                        vuint8mf8_t v2, vuint8mf8_t v3,
                                        vuint8mf8_t v4, vuint8mf8_t v5,
                                        vuint8mf8_t v6);
vuint8mf8x8_t __riscv_vcreate_v_u8mf8x8(vuint8mf8_t v0, vuint8mf8_t v1,
                                        vuint8mf8_t v2, vuint8mf8_t v3,
                                        vuint8mf8_t v4, vuint8mf8_t v5,
                                        vuint8mf8_t v6, vuint8mf8_t v7);
vuint8mf4x2_t __riscv_vcreate_v_u8mf4x2(vuint8mf4_t v0, vuint8mf4_t v1);
vuint8mf4x3_t __riscv_vcreate_v_u8mf4x3(vuint8mf4_t v0, vuint8mf4_t v1,
                                        vuint8mf4_t v2);
vuint8mf4x4_t __riscv_vcreate_v_u8mf4x4(vuint8mf4_t v0, vuint8mf4_t v1,
                                        vuint8mf4_t v2, vuint8mf4_t v3);
vuint8mf4x5_t __riscv_vcreate_v_u8mf4x5(vuint8mf4_t v0, vuint8mf4_t v1,
                                        vuint8mf4_t v2, vuint8mf4_t v3,
                                        vuint8mf4_t v4);
vuint8mf4x6_t __riscv_vcreate_v_u8mf4x6(vuint8mf4_t v0, vuint8mf4_t v1,
                                        vuint8mf4_t v2, vuint8mf4_t v3,
                                        vuint8mf4_t v4, vuint8mf4_t v5);
vuint8mf4x7_t __riscv_vcreate_v_u8mf4x7(vuint8mf4_t v0, vuint8mf4_t v1,
                                        vuint8mf4_t v2, vuint8mf4_t v3,
                                        vuint8mf4_t v4, vuint8mf4_t v5,
                                        vuint8mf4_t v6);
vuint8mf4x8_t __riscv_vcreate_v_u8mf4x8(vuint8mf4_t v0, vuint8mf4_t v1,
                                        vuint8mf4_t v2, vuint8mf4_t v3,
                                        vuint8mf4_t v4, vuint8mf4_t v5,
                                        vuint8mf4_t v6, vuint8mf4_t v7);
vuint8mf2x2_t __riscv_vcreate_v_u8mf2x2(vuint8mf2_t v0, vuint8mf2_t v1);
vuint8mf2x3_t __riscv_vcreate_v_u8mf2x3(vuint8mf2_t v0, vuint8mf2_t v1,
                                        vuint8mf2_t v2);
vuint8mf2x4_t __riscv_vcreate_v_u8mf2x4(vuint8mf2_t v0, vuint8mf2_t v1,
                                        vuint8mf2_t v2, vuint8mf2_t v3);
vuint8mf2x5_t __riscv_vcreate_v_u8mf2x5(vuint8mf2_t v0, vuint8mf2_t v1,
                                        vuint8mf2_t v2, vuint8mf2_t v3,
                                        vuint8mf2_t v4);
vuint8mf2x6_t __riscv_vcreate_v_u8mf2x6(vuint8mf2_t v0, vuint8mf2_t v1,
                                        vuint8mf2_t v2, vuint8mf2_t v3,
                                        vuint8mf2_t v4, vuint8mf2_t v5);
vuint8mf2x7_t __riscv_vcreate_v_u8mf2x7(vuint8mf2_t v0, vuint8mf2_t v1,
                                        vuint8mf2_t v2, vuint8mf2_t v3,
                                        vuint8mf2_t v4, vuint8mf2_t v5,
                                        vuint8mf2_t v6);
vuint8mf2x8_t __riscv_vcreate_v_u8mf2x8(vuint8mf2_t v0, vuint8mf2_t v1,
                                        vuint8mf2_t v2, vuint8mf2_t v3,
                                        vuint8mf2_t v4, vuint8mf2_t v5,
                                        vuint8mf2_t v6, vuint8mf2_t v7);
vuint8m1x2_t __riscv_vcreate_v_u8m1x2(vuint8m1_t v0, vuint8m1_t v1);
vuint8m1x3_t __riscv_vcreate_v_u8m1x3(vuint8m1_t v0, vuint8m1_t v1,
                                      vuint8m1_t v2);
vuint8m1x4_t __riscv_vcreate_v_u8m1x4(vuint8m1_t v0, vuint8m1_t v1,
                                      vuint8m1_t v2, vuint8m1_t v3);
vuint8m1x5_t __riscv_vcreate_v_u8m1x5(vuint8m1_t v0, vuint8m1_t v1,
                                      vuint8m1_t v2, vuint8m1_t v3,
                                      vuint8m1_t v4);
vuint8m1x6_t __riscv_vcreate_v_u8m1x6(vuint8m1_t v0, vuint8m1_t v1,
                                      vuint8m1_t v2, vuint8m1_t v3,
                                      vuint8m1_t v4, vuint8m1_t v5);
vuint8m1x7_t __riscv_vcreate_v_u8m1x7(vuint8m1_t v0, vuint8m1_t v1,
                                      vuint8m1_t v2, vuint8m1_t v3,
                                      vuint8m1_t v4, vuint8m1_t v5,
                                      vuint8m1_t v6);
vuint8m1x8_t __riscv_vcreate_v_u8m1x8(vuint8m1_t v0, vuint8m1_t v1,
                                      vuint8m1_t v2, vuint8m1_t v3,
                                      vuint8m1_t v4, vuint8m1_t v5,
                                      vuint8m1_t v6, vuint8m1_t v7);
vuint8m2x2_t __riscv_vcreate_v_u8m2x2(vuint8m2_t v0, vuint8m2_t v1);
vuint8m2x3_t __riscv_vcreate_v_u8m2x3(vuint8m2_t v0, vuint8m2_t v1,
                                      vuint8m2_t v2);
vuint8m2x4_t __riscv_vcreate_v_u8m2x4(vuint8m2_t v0, vuint8m2_t v1,
                                      vuint8m2_t v2, vuint8m2_t v3);
vuint8m4x2_t __riscv_vcreate_v_u8m4x2(vuint8m4_t v0, vuint8m4_t v1);
vuint16mf4x2_t __riscv_vcreate_v_u16mf4x2(vuint16mf4_t v0, vuint16mf4_t v1);
vuint16mf4x3_t __riscv_vcreate_v_u16mf4x3(vuint16mf4_t v0, vuint16mf4_t v1,
                                          vuint16mf4_t v2);
vuint16mf4x4_t __riscv_vcreate_v_u16mf4x4(vuint16mf4_t v0, vuint16mf4_t v1,
                                          vuint16mf4_t v2, vuint16mf4_t v3);
vuint16mf4x5_t __riscv_vcreate_v_u16mf4x5(vuint16mf4_t v0, vuint16mf4_t v1,
                                          vuint16mf4_t v2, vuint16mf4_t v3,
                                          vuint16mf4_t v4);
vuint16mf4x6_t __riscv_vcreate_v_u16mf4x6(vuint16mf4_t v0, vuint16mf4_t v1,
                                          vuint16mf4_t v2, vuint16mf4_t v3,
                                          vuint16mf4_t v4, vuint16mf4_t v5);
vuint16mf4x7_t __riscv_vcreate_v_u16mf4x7(vuint16mf4_t v0, vuint16mf4_t v1,
                                          vuint16mf4_t v2, vuint16mf4_t v3,
                                          vuint16mf4_t v4, vuint16mf4_t v5,
                                          vuint16mf4_t v6);
vuint16mf4x8_t __riscv_vcreate_v_u16mf4x8(vuint16mf4_t v0, vuint16mf4_t v1,
                                          vuint16mf4_t v2, vuint16mf4_t v3,
                                          vuint16mf4_t v4, vuint16mf4_t v5,
                                          vuint16mf4_t v6, vuint16mf4_t v7);
vuint16mf2x2_t __riscv_vcreate_v_u16mf2x2(vuint16mf2_t v0, vuint16mf2_t v1);
vuint16mf2x3_t __riscv_vcreate_v_u16mf2x3(vuint16mf2_t v0, vuint16mf2_t v1,
                                          vuint16mf2_t v2);
vuint16mf2x4_t __riscv_vcreate_v_u16mf2x4(vuint16mf2_t v0, vuint16mf2_t v1,
                                          vuint16mf2_t v2, vuint16mf2_t v3);
vuint16mf2x5_t __riscv_vcreate_v_u16mf2x5(vuint16mf2_t v0, vuint16mf2_t v1,
                                          vuint16mf2_t v2, vuint16mf2_t v3,
                                          vuint16mf2_t v4);
vuint16mf2x6_t __riscv_vcreate_v_u16mf2x6(vuint16mf2_t v0, vuint16mf2_t v1,
                                          vuint16mf2_t v2, vuint16mf2_t v3,
                                          vuint16mf2_t v4, vuint16mf2_t v5);
vuint16mf2x7_t __riscv_vcreate_v_u16mf2x7(vuint16mf2_t v0, vuint16mf2_t v1,
                                          vuint16mf2_t v2, vuint16mf2_t v3,
                                          vuint16mf2_t v4, vuint16mf2_t v5,
                                          vuint16mf2_t v6);
vuint16mf2x8_t __riscv_vcreate_v_u16mf2x8(vuint16mf2_t v0, vuint16mf2_t v1,
                                          vuint16mf2_t v2, vuint16mf2_t v3,
                                          vuint16mf2_t v4, vuint16mf2_t v5,
                                          vuint16mf2_t v6, vuint16mf2_t v7);
vuint16m1x2_t __riscv_vcreate_v_u16m1x2(vuint16m1_t v0, vuint16m1_t v1);
vuint16m1x3_t __riscv_vcreate_v_u16m1x3(vuint16m1_t v0, vuint16m1_t v1,
                                        vuint16m1_t v2);
vuint16m1x4_t __riscv_vcreate_v_u16m1x4(vuint16m1_t v0, vuint16m1_t v1,
                                        vuint16m1_t v2, vuint16m1_t v3);
vuint16m1x5_t __riscv_vcreate_v_u16m1x5(vuint16m1_t v0, vuint16m1_t v1,
                                        vuint16m1_t v2, vuint16m1_t v3,
                                        vuint16m1_t v4);
vuint16m1x6_t __riscv_vcreate_v_u16m1x6(vuint16m1_t v0, vuint16m1_t v1,
                                        vuint16m1_t v2, vuint16m1_t v3,
                                        vuint16m1_t v4, vuint16m1_t v5);
vuint16m1x7_t __riscv_vcreate_v_u16m1x7(vuint16m1_t v0, vuint16m1_t v1,
                                        vuint16m1_t v2, vuint16m1_t v3,
                                        vuint16m1_t v4, vuint16m1_t v5,
                                        vuint16m1_t v6);
vuint16m1x8_t __riscv_vcreate_v_u16m1x8(vuint16m1_t v0, vuint16m1_t v1,
                                        vuint16m1_t v2, vuint16m1_t v3,
                                        vuint16m1_t v4, vuint16m1_t v5,
                                        vuint16m1_t v6, vuint16m1_t v7);
vuint16m2x2_t __riscv_vcreate_v_u16m2x2(vuint16m2_t v0, vuint16m2_t v1);
vuint16m2x3_t __riscv_vcreate_v_u16m2x3(vuint16m2_t v0, vuint16m2_t v1,
                                        vuint16m2_t v2);
vuint16m2x4_t __riscv_vcreate_v_u16m2x4(vuint16m2_t v0, vuint16m2_t v1,
                                        vuint16m2_t v2, vuint16m2_t v3);
vuint16m4x2_t __riscv_vcreate_v_u16m4x2(vuint16m4_t v0, vuint16m4_t v1);
vuint32mf2x2_t __riscv_vcreate_v_u32mf2x2(vuint32mf2_t v0, vuint32mf2_t v1);
vuint32mf2x3_t __riscv_vcreate_v_u32mf2x3(vuint32mf2_t v0, vuint32mf2_t v1,
                                          vuint32mf2_t v2);
vuint32mf2x4_t __riscv_vcreate_v_u32mf2x4(vuint32mf2_t v0, vuint32mf2_t v1,
                                          vuint32mf2_t v2, vuint32mf2_t v3);
vuint32mf2x5_t __riscv_vcreate_v_u32mf2x5(vuint32mf2_t v0, vuint32mf2_t v1,
                                          vuint32mf2_t v2, vuint32mf2_t v3,
                                          vuint32mf2_t v4);
vuint32mf2x6_t __riscv_vcreate_v_u32mf2x6(vuint32mf2_t v0, vuint32mf2_t v1,
                                          vuint32mf2_t v2, vuint32mf2_t v3,
                                          vuint32mf2_t v4, vuint32mf2_t v5);
vuint32mf2x7_t __riscv_vcreate_v_u32mf2x7(vuint32mf2_t v0, vuint32mf2_t v1,
                                          vuint32mf2_t v2, vuint32mf2_t v3,
                                          vuint32mf2_t v4, vuint32mf2_t v5,
                                          vuint32mf2_t v6);
vuint32mf2x8_t __riscv_vcreate_v_u32mf2x8(vuint32mf2_t v0, vuint32mf2_t v1,
                                          vuint32mf2_t v2, vuint32mf2_t v3,
                                          vuint32mf2_t v4, vuint32mf2_t v5,
                                          vuint32mf2_t v6, vuint32mf2_t v7);
vuint32m1x2_t __riscv_vcreate_v_u32m1x2(vuint32m1_t v0, vuint32m1_t v1);
vuint32m1x3_t __riscv_vcreate_v_u32m1x3(vuint32m1_t v0, vuint32m1_t v1,
                                        vuint32m1_t v2);
vuint32m1x4_t __riscv_vcreate_v_u32m1x4(vuint32m1_t v0, vuint32m1_t v1,
                                        vuint32m1_t v2, vuint32m1_t v3);
vuint32m1x5_t __riscv_vcreate_v_u32m1x5(vuint32m1_t v0, vuint32m1_t v1,
                                        vuint32m1_t v2, vuint32m1_t v3,
                                        vuint32m1_t v4);
vuint32m1x6_t __riscv_vcreate_v_u32m1x6(vuint32m1_t v0, vuint32m1_t v1,
                                        vuint32m1_t v2, vuint32m1_t v3,
                                        vuint32m1_t v4, vuint32m1_t v5);
vuint32m1x7_t __riscv_vcreate_v_u32m1x7(vuint32m1_t v0, vuint32m1_t v1,
                                        vuint32m1_t v2, vuint32m1_t v3,
                                        vuint32m1_t v4, vuint32m1_t v5,
                                        vuint32m1_t v6);
vuint32m1x8_t __riscv_vcreate_v_u32m1x8(vuint32m1_t v0, vuint32m1_t v1,
                                        vuint32m1_t v2, vuint32m1_t v3,
                                        vuint32m1_t v4, vuint32m1_t v5,
                                        vuint32m1_t v6, vuint32m1_t v7);
vuint32m2x2_t __riscv_vcreate_v_u32m2x2(vuint32m2_t v0, vuint32m2_t v1);
vuint32m2x3_t __riscv_vcreate_v_u32m2x3(vuint32m2_t v0, vuint32m2_t v1,
                                        vuint32m2_t v2);
vuint32m2x4_t __riscv_vcreate_v_u32m2x4(vuint32m2_t v0, vuint32m2_t v1,
                                        vuint32m2_t v2, vuint32m2_t v3);
vuint32m4x2_t __riscv_vcreate_v_u32m4x2(vuint32m4_t v0, vuint32m4_t v1);
vuint64m1x2_t __riscv_vcreate_v_u64m1x2(vuint64m1_t v0, vuint64m1_t v1);
vuint64m1x3_t __riscv_vcreate_v_u64m1x3(vuint64m1_t v0, vuint64m1_t v1,
                                        vuint64m1_t v2);
vuint64m1x4_t __riscv_vcreate_v_u64m1x4(vuint64m1_t v0, vuint64m1_t v1,
                                        vuint64m1_t v2, vuint64m1_t v3);
vuint64m1x5_t __riscv_vcreate_v_u64m1x5(vuint64m1_t v0, vuint64m1_t v1,
                                        vuint64m1_t v2, vuint64m1_t v3,
                                        vuint64m1_t v4);
vuint64m1x6_t __riscv_vcreate_v_u64m1x6(vuint64m1_t v0, vuint64m1_t v1,
                                        vuint64m1_t v2, vuint64m1_t v3,
                                        vuint64m1_t v4, vuint64m1_t v5);
vuint64m1x7_t __riscv_vcreate_v_u64m1x7(vuint64m1_t v0, vuint64m1_t v1,
                                        vuint64m1_t v2, vuint64m1_t v3,
                                        vuint64m1_t v4, vuint64m1_t v5,
                                        vuint64m1_t v6);
vuint64m1x8_t __riscv_vcreate_v_u64m1x8(vuint64m1_t v0, vuint64m1_t v1,
                                        vuint64m1_t v2, vuint64m1_t v3,
                                        vuint64m1_t v4, vuint64m1_t v5,
                                        vuint64m1_t v6, vuint64m1_t v7);
vuint64m2x2_t __riscv_vcreate_v_u64m2x2(vuint64m2_t v0, vuint64m2_t v1);
vuint64m2x3_t __riscv_vcreate_v_u64m2x3(vuint64m2_t v0, vuint64m2_t v1,
                                        vuint64m2_t v2);
vuint64m2x4_t __riscv_vcreate_v_u64m2x4(vuint64m2_t v0, vuint64m2_t v1,
                                        vuint64m2_t v2, vuint64m2_t v3);
vuint64m4x2_t __riscv_vcreate_v_u64m4x2(vuint64m4_t v0, vuint64m4_t v1);
----
