
=== Vector Integer Arithmetic Intrinsics

[[overloaded-vector-single-width-integer-add-and-subtract]]
==== Vector Single-Width Integer Add and Subtract Intrinsics

[,c]
----
vint8mf8_t __riscv_vadd(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vadd(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vadd(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vadd(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vadd(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vadd(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vadd(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vadd(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vadd(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vadd(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vadd(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vadd(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vadd(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vadd(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vadd(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vadd(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vadd(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vadd(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vadd(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vadd(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vadd(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vadd(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vadd(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vadd(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vadd(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vadd(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vadd(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vadd(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vadd(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vadd(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vadd(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vadd(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vadd(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vadd(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vadd(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vadd(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vadd(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vadd(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vadd(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vadd(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vadd(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vadd(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vadd(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vadd(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vsub(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vsub(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vsub(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vsub(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vsub(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vsub(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vsub(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vsub(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vsub(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vsub(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vsub(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vsub(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vsub(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vsub(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vsub(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vsub(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vsub(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vsub(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vsub(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vsub(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vsub(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vsub(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vsub(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vsub(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vsub(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vsub(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vsub(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vsub(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vsub(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vsub(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vsub(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vsub(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vsub(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vsub(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vsub(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vsub(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vsub(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vsub(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vsub(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vsub(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vsub(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vsub(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vsub(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vsub(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vrsub(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vrsub(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vrsub(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vrsub(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vrsub(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vrsub(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vrsub(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vrsub(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vrsub(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vrsub(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vrsub(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vrsub(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vrsub(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vrsub(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vrsub(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vrsub(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vrsub(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vrsub(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vrsub(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vrsub(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vrsub(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vrsub(vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vadd(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vadd(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vadd(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vadd(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vadd(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vadd(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vadd(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vadd(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vadd(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vadd(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vadd(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vadd(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vadd(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vadd(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vadd(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vadd(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vadd(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vadd(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vadd(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vadd(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vadd(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vadd(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vadd(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vadd(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vadd(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vadd(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vadd(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vadd(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vadd(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vadd(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vadd(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vadd(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vadd(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vadd(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vadd(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vadd(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vadd(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vadd(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vadd(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vadd(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vadd(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vadd(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vadd(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vadd(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vsub(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vsub(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vsub(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vsub(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vsub(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vsub(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vsub(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vsub(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vsub(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vsub(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vsub(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vsub(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vsub(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vsub(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vsub(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vsub(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vsub(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vsub(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vsub(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vsub(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vsub(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vsub(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vsub(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vsub(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vsub(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vsub(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vsub(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vsub(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vsub(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vsub(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vsub(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vsub(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vsub(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vsub(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vsub(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vsub(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vsub(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vsub(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vsub(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vsub(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vsub(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vsub(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vsub(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vsub(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vrsub(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vrsub(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vrsub(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vrsub(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vrsub(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vrsub(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vrsub(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vrsub(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vrsub(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vrsub(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vrsub(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vrsub(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vrsub(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vrsub(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vrsub(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vrsub(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vrsub(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vrsub(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vrsub(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vrsub(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vrsub(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vrsub(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vadd(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vadd(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vadd(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vadd(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vadd(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vadd(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vadd(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vadd(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vadd(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vadd(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vadd(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vadd(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vadd(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vadd(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vadd(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vadd(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vadd(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vadd(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vadd(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vadd(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vadd(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vadd(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vadd(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vadd(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vadd(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vadd(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vadd(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vadd(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vadd(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vadd(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vadd(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vadd(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vadd(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vadd(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vadd(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vadd(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vadd(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vadd(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vadd(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vadd(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vadd(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vadd(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vadd(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vadd(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vsub(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vsub(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vsub(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vsub(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vsub(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vsub(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vsub(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vsub(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vsub(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vsub(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vsub(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vsub(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vsub(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vsub(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vsub(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vsub(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vsub(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vsub(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vsub(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vsub(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vsub(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vsub(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vsub(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vsub(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vsub(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vsub(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vsub(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vsub(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vsub(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vsub(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vsub(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vsub(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vsub(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vsub(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vsub(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vsub(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vsub(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vsub(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vsub(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vsub(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vsub(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vsub(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vsub(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vsub(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vrsub(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vrsub(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vrsub(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vrsub(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vrsub(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vrsub(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vrsub(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vrsub(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                          size_t vl);
vint16mf2_t __riscv_vrsub(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                          size_t vl);
vint16m1_t __riscv_vrsub(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vrsub(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vrsub(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vrsub(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vrsub(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                          size_t vl);
vint32m1_t __riscv_vrsub(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vrsub(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vrsub(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vrsub(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vrsub(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vrsub(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vrsub(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vrsub(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vadd(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vuint8mf8_t __riscv_vadd(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vadd(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vuint8mf4_t __riscv_vadd(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vadd(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vuint8mf2_t __riscv_vadd(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vadd(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vadd(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vadd(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vadd(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vadd(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vadd(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vadd(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vadd(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vadd(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                          size_t vl);
vuint16mf4_t __riscv_vadd(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                          size_t vl);
vuint16mf2_t __riscv_vadd(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                          size_t vl);
vuint16mf2_t __riscv_vadd(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m1_t __riscv_vadd(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vuint16m1_t __riscv_vadd(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                         size_t vl);
vuint16m2_t __riscv_vadd(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                         size_t vl);
vuint16m2_t __riscv_vadd(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vadd(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                         size_t vl);
vuint16m4_t __riscv_vadd(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vadd(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                         size_t vl);
vuint16m8_t __riscv_vadd(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vadd(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                          size_t vl);
vuint32mf2_t __riscv_vadd(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m1_t __riscv_vadd(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vuint32m1_t __riscv_vadd(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m2_t __riscv_vadd(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vuint32m2_t __riscv_vadd(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m4_t __riscv_vadd(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                         size_t vl);
vuint32m4_t __riscv_vadd(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vadd(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                         size_t vl);
vuint32m8_t __riscv_vadd(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vadd(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vuint64m1_t __riscv_vadd(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m2_t __riscv_vadd(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vuint64m2_t __riscv_vadd(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m4_t __riscv_vadd(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vuint64m4_t __riscv_vadd(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m8_t __riscv_vadd(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                         size_t vl);
vuint64m8_t __riscv_vadd(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vsub(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vuint8mf8_t __riscv_vsub(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vsub(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vuint8mf4_t __riscv_vsub(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vsub(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vuint8mf2_t __riscv_vsub(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vsub(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vsub(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vsub(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vsub(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vsub(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vsub(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vsub(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vsub(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vsub(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                          size_t vl);
vuint16mf4_t __riscv_vsub(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                          size_t vl);
vuint16mf2_t __riscv_vsub(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                          size_t vl);
vuint16mf2_t __riscv_vsub(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m1_t __riscv_vsub(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vuint16m1_t __riscv_vsub(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                         size_t vl);
vuint16m2_t __riscv_vsub(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                         size_t vl);
vuint16m2_t __riscv_vsub(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vsub(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                         size_t vl);
vuint16m4_t __riscv_vsub(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vsub(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                         size_t vl);
vuint16m8_t __riscv_vsub(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vsub(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                          size_t vl);
vuint32mf2_t __riscv_vsub(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m1_t __riscv_vsub(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vuint32m1_t __riscv_vsub(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m2_t __riscv_vsub(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vuint32m2_t __riscv_vsub(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m4_t __riscv_vsub(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                         size_t vl);
vuint32m4_t __riscv_vsub(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vsub(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                         size_t vl);
vuint32m8_t __riscv_vsub(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vsub(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vuint64m1_t __riscv_vsub(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m2_t __riscv_vsub(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vuint64m2_t __riscv_vsub(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m4_t __riscv_vsub(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vuint64m4_t __riscv_vsub(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m8_t __riscv_vsub(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                         size_t vl);
vuint64m8_t __riscv_vsub(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vrsub(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                          size_t vl);
vuint8mf4_t __riscv_vrsub(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                          size_t vl);
vuint8mf2_t __riscv_vrsub(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                          size_t vl);
vuint8m1_t __riscv_vrsub(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vrsub(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vrsub(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vrsub(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vrsub(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                           size_t vl);
vuint16mf2_t __riscv_vrsub(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                           size_t vl);
vuint16m1_t __riscv_vrsub(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m2_t __riscv_vrsub(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m4_t __riscv_vrsub(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m8_t __riscv_vrsub(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                          size_t vl);
vuint32mf2_t __riscv_vrsub(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                           size_t vl);
vuint32m1_t __riscv_vrsub(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m2_t __riscv_vrsub(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m4_t __riscv_vrsub(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m8_t __riscv_vrsub(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                          size_t vl);
vuint64m1_t __riscv_vrsub(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m2_t __riscv_vrsub(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m4_t __riscv_vrsub(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m8_t __riscv_vrsub(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                          size_t vl);
----

[[overloaded-vector-widening-integer-add-subtract]]
==== Vector Widening Integer Add/Subtract Intrinsics

[,c]
----
vint16mf4_t __riscv_vwadd_vv(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwadd_vx(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vwadd_wv(vint16mf4_t vs2, vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwadd_wx(vint16mf4_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwadd_vv(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwadd_vx(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwadd_wv(vint16mf2_t vs2, vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwadd_wx(vint16mf2_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwadd_vv(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwadd_vx(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwadd_wv(vint16m1_t vs2, vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwadd_wx(vint16m1_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwadd_vv(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwadd_vx(vint8m1_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwadd_wv(vint16m2_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwadd_wx(vint16m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwadd_vv(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwadd_vx(vint8m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwadd_wv(vint16m4_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwadd_wx(vint16m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwadd_vv(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwadd_vx(vint8m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwadd_wv(vint16m8_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwadd_wx(vint16m8_t vs2, int8_t rs1, size_t vl);
vint32mf2_t __riscv_vwadd_vv(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwadd_vx(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vwadd_wv(vint32mf2_t vs2, vint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwadd_wx(vint32mf2_t vs2, int16_t rs1, size_t vl);
vint32m1_t __riscv_vwadd_vv(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwadd_vx(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint32m1_t __riscv_vwadd_wv(vint32m1_t vs2, vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwadd_wx(vint32m1_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwadd_vv(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwadd_vx(vint16m1_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwadd_wv(vint32m2_t vs2, vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwadd_wx(vint32m2_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwadd_vv(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwadd_vx(vint16m2_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwadd_wv(vint32m4_t vs2, vint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwadd_wx(vint32m4_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwadd_vv(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwadd_vx(vint16m4_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwadd_wv(vint32m8_t vs2, vint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwadd_wx(vint32m8_t vs2, int16_t rs1, size_t vl);
vint64m1_t __riscv_vwadd_vv(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwadd_vx(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vwadd_wv(vint64m1_t vs2, vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwadd_wx(vint64m1_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwadd_vv(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwadd_vx(vint32m1_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwadd_wv(vint64m2_t vs2, vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwadd_wx(vint64m2_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwadd_vv(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwadd_vx(vint32m2_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwadd_wv(vint64m4_t vs2, vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwadd_wx(vint64m4_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwadd_vv(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwadd_vx(vint32m4_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwadd_wv(vint64m8_t vs2, vint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwadd_wx(vint64m8_t vs2, int32_t rs1, size_t vl);
vint16mf4_t __riscv_vwsub_vv(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwsub_vx(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vwsub_wv(vint16mf4_t vs2, vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwsub_wx(vint16mf4_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwsub_vv(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwsub_vx(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwsub_wv(vint16mf2_t vs2, vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwsub_wx(vint16mf2_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwsub_vv(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwsub_vx(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwsub_wv(vint16m1_t vs2, vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwsub_wx(vint16m1_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwsub_vv(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwsub_vx(vint8m1_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwsub_wv(vint16m2_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwsub_wx(vint16m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwsub_vv(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwsub_vx(vint8m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwsub_wv(vint16m4_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwsub_wx(vint16m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwsub_vv(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwsub_vx(vint8m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwsub_wv(vint16m8_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwsub_wx(vint16m8_t vs2, int8_t rs1, size_t vl);
vint32mf2_t __riscv_vwsub_vv(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwsub_vx(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vwsub_wv(vint32mf2_t vs2, vint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwsub_wx(vint32mf2_t vs2, int16_t rs1, size_t vl);
vint32m1_t __riscv_vwsub_vv(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwsub_vx(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint32m1_t __riscv_vwsub_wv(vint32m1_t vs2, vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwsub_wx(vint32m1_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwsub_vv(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwsub_vx(vint16m1_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwsub_wv(vint32m2_t vs2, vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwsub_wx(vint32m2_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwsub_vv(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwsub_vx(vint16m2_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwsub_wv(vint32m4_t vs2, vint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwsub_wx(vint32m4_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwsub_vv(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwsub_vx(vint16m4_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwsub_wv(vint32m8_t vs2, vint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwsub_wx(vint32m8_t vs2, int16_t rs1, size_t vl);
vint64m1_t __riscv_vwsub_vv(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwsub_vx(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vwsub_wv(vint64m1_t vs2, vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwsub_wx(vint64m1_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwsub_vv(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwsub_vx(vint32m1_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwsub_wv(vint64m2_t vs2, vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwsub_wx(vint64m2_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwsub_vv(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwsub_vx(vint32m2_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwsub_wv(vint64m4_t vs2, vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwsub_wx(vint64m4_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwsub_vv(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwsub_vx(vint32m4_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwsub_wv(vint64m8_t vs2, vint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwsub_wx(vint64m8_t vs2, int32_t rs1, size_t vl);
vuint16mf4_t __riscv_vwaddu_vv(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint16mf4_t __riscv_vwaddu_vx(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vwaddu_wv(vuint16mf4_t vs2, vuint8mf8_t vs1, size_t vl);
vuint16mf4_t __riscv_vwaddu_wx(vuint16mf4_t vs2, uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwaddu_vv(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vwaddu_vx(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwaddu_wv(vuint16mf2_t vs2, vuint8mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vwaddu_wx(vuint16mf2_t vs2, uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwaddu_vv(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vwaddu_vx(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwaddu_wv(vuint16m1_t vs2, vuint8mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vwaddu_wx(vuint16m1_t vs2, uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwaddu_vv(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwaddu_vx(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwaddu_wv(vuint16m2_t vs2, vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwaddu_wx(vuint16m2_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwaddu_vv(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwaddu_vx(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwaddu_wv(vuint16m4_t vs2, vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwaddu_wx(vuint16m4_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwaddu_vv(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwaddu_vx(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwaddu_wv(vuint16m8_t vs2, vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwaddu_wx(vuint16m8_t vs2, uint8_t rs1, size_t vl);
vuint32mf2_t __riscv_vwaddu_vv(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint32mf2_t __riscv_vwaddu_vx(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vwaddu_wv(vuint32mf2_t vs2, vuint16mf4_t vs1, size_t vl);
vuint32mf2_t __riscv_vwaddu_wx(vuint32mf2_t vs2, uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwaddu_vv(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vwaddu_vx(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwaddu_wv(vuint32m1_t vs2, vuint16mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vwaddu_wx(vuint32m1_t vs2, uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwaddu_vv(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint32m2_t __riscv_vwaddu_vx(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwaddu_wv(vuint32m2_t vs2, vuint16m1_t vs1, size_t vl);
vuint32m2_t __riscv_vwaddu_wx(vuint32m2_t vs2, uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwaddu_vv(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint32m4_t __riscv_vwaddu_vx(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwaddu_wv(vuint32m4_t vs2, vuint16m2_t vs1, size_t vl);
vuint32m4_t __riscv_vwaddu_wx(vuint32m4_t vs2, uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwaddu_vv(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint32m8_t __riscv_vwaddu_vx(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwaddu_wv(vuint32m8_t vs2, vuint16m4_t vs1, size_t vl);
vuint32m8_t __riscv_vwaddu_wx(vuint32m8_t vs2, uint16_t rs1, size_t vl);
vuint64m1_t __riscv_vwaddu_vv(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint64m1_t __riscv_vwaddu_vx(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vwaddu_wv(vuint64m1_t vs2, vuint32mf2_t vs1, size_t vl);
vuint64m1_t __riscv_vwaddu_wx(vuint64m1_t vs2, uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwaddu_vv(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint64m2_t __riscv_vwaddu_vx(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwaddu_wv(vuint64m2_t vs2, vuint32m1_t vs1, size_t vl);
vuint64m2_t __riscv_vwaddu_wx(vuint64m2_t vs2, uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwaddu_vv(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint64m4_t __riscv_vwaddu_vx(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwaddu_wv(vuint64m4_t vs2, vuint32m2_t vs1, size_t vl);
vuint64m4_t __riscv_vwaddu_wx(vuint64m4_t vs2, uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwaddu_vv(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint64m8_t __riscv_vwaddu_vx(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwaddu_wv(vuint64m8_t vs2, vuint32m4_t vs1, size_t vl);
vuint64m8_t __riscv_vwaddu_wx(vuint64m8_t vs2, uint32_t rs1, size_t vl);
vuint16mf4_t __riscv_vwsubu_vv(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint16mf4_t __riscv_vwsubu_vx(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vwsubu_wv(vuint16mf4_t vs2, vuint8mf8_t vs1, size_t vl);
vuint16mf4_t __riscv_vwsubu_wx(vuint16mf4_t vs2, uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwsubu_vv(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vwsubu_vx(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwsubu_wv(vuint16mf2_t vs2, vuint8mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vwsubu_wx(vuint16mf2_t vs2, uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwsubu_vv(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vwsubu_vx(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwsubu_wv(vuint16m1_t vs2, vuint8mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vwsubu_wx(vuint16m1_t vs2, uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwsubu_vv(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwsubu_vx(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwsubu_wv(vuint16m2_t vs2, vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwsubu_wx(vuint16m2_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwsubu_vv(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwsubu_vx(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwsubu_wv(vuint16m4_t vs2, vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwsubu_wx(vuint16m4_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwsubu_vv(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwsubu_vx(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwsubu_wv(vuint16m8_t vs2, vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwsubu_wx(vuint16m8_t vs2, uint8_t rs1, size_t vl);
vuint32mf2_t __riscv_vwsubu_vv(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint32mf2_t __riscv_vwsubu_vx(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vwsubu_wv(vuint32mf2_t vs2, vuint16mf4_t vs1, size_t vl);
vuint32mf2_t __riscv_vwsubu_wx(vuint32mf2_t vs2, uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwsubu_vv(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vwsubu_vx(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwsubu_wv(vuint32m1_t vs2, vuint16mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vwsubu_wx(vuint32m1_t vs2, uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwsubu_vv(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint32m2_t __riscv_vwsubu_vx(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwsubu_wv(vuint32m2_t vs2, vuint16m1_t vs1, size_t vl);
vuint32m2_t __riscv_vwsubu_wx(vuint32m2_t vs2, uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwsubu_vv(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint32m4_t __riscv_vwsubu_vx(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwsubu_wv(vuint32m4_t vs2, vuint16m2_t vs1, size_t vl);
vuint32m4_t __riscv_vwsubu_wx(vuint32m4_t vs2, uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwsubu_vv(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint32m8_t __riscv_vwsubu_vx(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwsubu_wv(vuint32m8_t vs2, vuint16m4_t vs1, size_t vl);
vuint32m8_t __riscv_vwsubu_wx(vuint32m8_t vs2, uint16_t rs1, size_t vl);
vuint64m1_t __riscv_vwsubu_vv(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint64m1_t __riscv_vwsubu_vx(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vwsubu_wv(vuint64m1_t vs2, vuint32mf2_t vs1, size_t vl);
vuint64m1_t __riscv_vwsubu_wx(vuint64m1_t vs2, uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwsubu_vv(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint64m2_t __riscv_vwsubu_vx(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwsubu_wv(vuint64m2_t vs2, vuint32m1_t vs1, size_t vl);
vuint64m2_t __riscv_vwsubu_wx(vuint64m2_t vs2, uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwsubu_vv(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint64m4_t __riscv_vwsubu_vx(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwsubu_wv(vuint64m4_t vs2, vuint32m2_t vs1, size_t vl);
vuint64m4_t __riscv_vwsubu_wx(vuint64m4_t vs2, uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwsubu_vv(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint64m8_t __riscv_vwsubu_vx(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwsubu_wv(vuint64m8_t vs2, vuint32m4_t vs1, size_t vl);
vuint64m8_t __riscv_vwsubu_wx(vuint64m8_t vs2, uint32_t rs1, size_t vl);
// masked functions
vint16mf4_t __riscv_vwadd_vv(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                             size_t vl);
vint16mf4_t __riscv_vwadd_vx(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                             size_t vl);
vint16mf4_t __riscv_vwadd_wv(vbool64_t vm, vint16mf4_t vs2, vint8mf8_t vs1,
                             size_t vl);
vint16mf4_t __riscv_vwadd_wx(vbool64_t vm, vint16mf4_t vs2, int8_t rs1,
                             size_t vl);
vint16mf2_t __riscv_vwadd_vv(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                             size_t vl);
vint16mf2_t __riscv_vwadd_vx(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                             size_t vl);
vint16mf2_t __riscv_vwadd_wv(vbool32_t vm, vint16mf2_t vs2, vint8mf4_t vs1,
                             size_t vl);
vint16mf2_t __riscv_vwadd_wx(vbool32_t vm, vint16mf2_t vs2, int8_t rs1,
                             size_t vl);
vint16m1_t __riscv_vwadd_vv(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                            size_t vl);
vint16m1_t __riscv_vwadd_vx(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                            size_t vl);
vint16m1_t __riscv_vwadd_wv(vbool16_t vm, vint16m1_t vs2, vint8mf2_t vs1,
                            size_t vl);
vint16m1_t __riscv_vwadd_wx(vbool16_t vm, vint16m1_t vs2, int8_t rs1,
                            size_t vl);
vint16m2_t __riscv_vwadd_vv(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                            size_t vl);
vint16m2_t __riscv_vwadd_vx(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwadd_wv(vbool8_t vm, vint16m2_t vs2, vint8m1_t vs1,
                            size_t vl);
vint16m2_t __riscv_vwadd_wx(vbool8_t vm, vint16m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwadd_vv(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                            size_t vl);
vint16m4_t __riscv_vwadd_vx(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwadd_wv(vbool4_t vm, vint16m4_t vs2, vint8m2_t vs1,
                            size_t vl);
vint16m4_t __riscv_vwadd_wx(vbool4_t vm, vint16m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwadd_vv(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                            size_t vl);
vint16m8_t __riscv_vwadd_vx(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwadd_wv(vbool2_t vm, vint16m8_t vs2, vint8m4_t vs1,
                            size_t vl);
vint16m8_t __riscv_vwadd_wx(vbool2_t vm, vint16m8_t vs2, int8_t rs1, size_t vl);
vint32mf2_t __riscv_vwadd_vv(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                             size_t vl);
vint32mf2_t __riscv_vwadd_vx(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                             size_t vl);
vint32mf2_t __riscv_vwadd_wv(vbool64_t vm, vint32mf2_t vs2, vint16mf4_t vs1,
                             size_t vl);
vint32mf2_t __riscv_vwadd_wx(vbool64_t vm, vint32mf2_t vs2, int16_t rs1,
                             size_t vl);
vint32m1_t __riscv_vwadd_vv(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                            size_t vl);
vint32m1_t __riscv_vwadd_vx(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                            size_t vl);
vint32m1_t __riscv_vwadd_wv(vbool32_t vm, vint32m1_t vs2, vint16mf2_t vs1,
                            size_t vl);
vint32m1_t __riscv_vwadd_wx(vbool32_t vm, vint32m1_t vs2, int16_t rs1,
                            size_t vl);
vint32m2_t __riscv_vwadd_vv(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                            size_t vl);
vint32m2_t __riscv_vwadd_vx(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                            size_t vl);
vint32m2_t __riscv_vwadd_wv(vbool16_t vm, vint32m2_t vs2, vint16m1_t vs1,
                            size_t vl);
vint32m2_t __riscv_vwadd_wx(vbool16_t vm, vint32m2_t vs2, int16_t rs1,
                            size_t vl);
vint32m4_t __riscv_vwadd_vv(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                            size_t vl);
vint32m4_t __riscv_vwadd_vx(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                            size_t vl);
vint32m4_t __riscv_vwadd_wv(vbool8_t vm, vint32m4_t vs2, vint16m2_t vs1,
                            size_t vl);
vint32m4_t __riscv_vwadd_wx(vbool8_t vm, vint32m4_t vs2, int16_t rs1,
                            size_t vl);
vint32m8_t __riscv_vwadd_vv(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                            size_t vl);
vint32m8_t __riscv_vwadd_vx(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                            size_t vl);
vint32m8_t __riscv_vwadd_wv(vbool4_t vm, vint32m8_t vs2, vint16m4_t vs1,
                            size_t vl);
vint32m8_t __riscv_vwadd_wx(vbool4_t vm, vint32m8_t vs2, int16_t rs1,
                            size_t vl);
vint64m1_t __riscv_vwadd_vv(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                            size_t vl);
vint64m1_t __riscv_vwadd_vx(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                            size_t vl);
vint64m1_t __riscv_vwadd_wv(vbool64_t vm, vint64m1_t vs2, vint32mf2_t vs1,
                            size_t vl);
vint64m1_t __riscv_vwadd_wx(vbool64_t vm, vint64m1_t vs2, int32_t rs1,
                            size_t vl);
vint64m2_t __riscv_vwadd_vv(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                            size_t vl);
vint64m2_t __riscv_vwadd_vx(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                            size_t vl);
vint64m2_t __riscv_vwadd_wv(vbool32_t vm, vint64m2_t vs2, vint32m1_t vs1,
                            size_t vl);
vint64m2_t __riscv_vwadd_wx(vbool32_t vm, vint64m2_t vs2, int32_t rs1,
                            size_t vl);
vint64m4_t __riscv_vwadd_vv(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                            size_t vl);
vint64m4_t __riscv_vwadd_vx(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                            size_t vl);
vint64m4_t __riscv_vwadd_wv(vbool16_t vm, vint64m4_t vs2, vint32m2_t vs1,
                            size_t vl);
vint64m4_t __riscv_vwadd_wx(vbool16_t vm, vint64m4_t vs2, int32_t rs1,
                            size_t vl);
vint64m8_t __riscv_vwadd_vv(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                            size_t vl);
vint64m8_t __riscv_vwadd_vx(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                            size_t vl);
vint64m8_t __riscv_vwadd_wv(vbool8_t vm, vint64m8_t vs2, vint32m4_t vs1,
                            size_t vl);
vint64m8_t __riscv_vwadd_wx(vbool8_t vm, vint64m8_t vs2, int32_t rs1,
                            size_t vl);
vint16mf4_t __riscv_vwsub_vv(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                             size_t vl);
vint16mf4_t __riscv_vwsub_vx(vbool64_t vm, vint8mf8_t vs2, int8_t rs1,
                             size_t vl);
vint16mf4_t __riscv_vwsub_wv(vbool64_t vm, vint16mf4_t vs2, vint8mf8_t vs1,
                             size_t vl);
vint16mf4_t __riscv_vwsub_wx(vbool64_t vm, vint16mf4_t vs2, int8_t rs1,
                             size_t vl);
vint16mf2_t __riscv_vwsub_vv(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                             size_t vl);
vint16mf2_t __riscv_vwsub_vx(vbool32_t vm, vint8mf4_t vs2, int8_t rs1,
                             size_t vl);
vint16mf2_t __riscv_vwsub_wv(vbool32_t vm, vint16mf2_t vs2, vint8mf4_t vs1,
                             size_t vl);
vint16mf2_t __riscv_vwsub_wx(vbool32_t vm, vint16mf2_t vs2, int8_t rs1,
                             size_t vl);
vint16m1_t __riscv_vwsub_vv(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                            size_t vl);
vint16m1_t __riscv_vwsub_vx(vbool16_t vm, vint8mf2_t vs2, int8_t rs1,
                            size_t vl);
vint16m1_t __riscv_vwsub_wv(vbool16_t vm, vint16m1_t vs2, vint8mf2_t vs1,
                            size_t vl);
vint16m1_t __riscv_vwsub_wx(vbool16_t vm, vint16m1_t vs2, int8_t rs1,
                            size_t vl);
vint16m2_t __riscv_vwsub_vv(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1,
                            size_t vl);
vint16m2_t __riscv_vwsub_vx(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwsub_wv(vbool8_t vm, vint16m2_t vs2, vint8m1_t vs1,
                            size_t vl);
vint16m2_t __riscv_vwsub_wx(vbool8_t vm, vint16m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwsub_vv(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1,
                            size_t vl);
vint16m4_t __riscv_vwsub_vx(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwsub_wv(vbool4_t vm, vint16m4_t vs2, vint8m2_t vs1,
                            size_t vl);
vint16m4_t __riscv_vwsub_wx(vbool4_t vm, vint16m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwsub_vv(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1,
                            size_t vl);
vint16m8_t __riscv_vwsub_vx(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwsub_wv(vbool2_t vm, vint16m8_t vs2, vint8m4_t vs1,
                            size_t vl);
vint16m8_t __riscv_vwsub_wx(vbool2_t vm, vint16m8_t vs2, int8_t rs1, size_t vl);
vint32mf2_t __riscv_vwsub_vv(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                             size_t vl);
vint32mf2_t __riscv_vwsub_vx(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                             size_t vl);
vint32mf2_t __riscv_vwsub_wv(vbool64_t vm, vint32mf2_t vs2, vint16mf4_t vs1,
                             size_t vl);
vint32mf2_t __riscv_vwsub_wx(vbool64_t vm, vint32mf2_t vs2, int16_t rs1,
                             size_t vl);
vint32m1_t __riscv_vwsub_vv(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                            size_t vl);
vint32m1_t __riscv_vwsub_vx(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                            size_t vl);
vint32m1_t __riscv_vwsub_wv(vbool32_t vm, vint32m1_t vs2, vint16mf2_t vs1,
                            size_t vl);
vint32m1_t __riscv_vwsub_wx(vbool32_t vm, vint32m1_t vs2, int16_t rs1,
                            size_t vl);
vint32m2_t __riscv_vwsub_vv(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                            size_t vl);
vint32m2_t __riscv_vwsub_vx(vbool16_t vm, vint16m1_t vs2, int16_t rs1,
                            size_t vl);
vint32m2_t __riscv_vwsub_wv(vbool16_t vm, vint32m2_t vs2, vint16m1_t vs1,
                            size_t vl);
vint32m2_t __riscv_vwsub_wx(vbool16_t vm, vint32m2_t vs2, int16_t rs1,
                            size_t vl);
vint32m4_t __riscv_vwsub_vv(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                            size_t vl);
vint32m4_t __riscv_vwsub_vx(vbool8_t vm, vint16m2_t vs2, int16_t rs1,
                            size_t vl);
vint32m4_t __riscv_vwsub_wv(vbool8_t vm, vint32m4_t vs2, vint16m2_t vs1,
                            size_t vl);
vint32m4_t __riscv_vwsub_wx(vbool8_t vm, vint32m4_t vs2, int16_t rs1,
                            size_t vl);
vint32m8_t __riscv_vwsub_vv(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                            size_t vl);
vint32m8_t __riscv_vwsub_vx(vbool4_t vm, vint16m4_t vs2, int16_t rs1,
                            size_t vl);
vint32m8_t __riscv_vwsub_wv(vbool4_t vm, vint32m8_t vs2, vint16m4_t vs1,
                            size_t vl);
vint32m8_t __riscv_vwsub_wx(vbool4_t vm, vint32m8_t vs2, int16_t rs1,
                            size_t vl);
vint64m1_t __riscv_vwsub_vv(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                            size_t vl);
vint64m1_t __riscv_vwsub_vx(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                            size_t vl);
vint64m1_t __riscv_vwsub_wv(vbool64_t vm, vint64m1_t vs2, vint32mf2_t vs1,
                            size_t vl);
vint64m1_t __riscv_vwsub_wx(vbool64_t vm, vint64m1_t vs2, int32_t rs1,
                            size_t vl);
vint64m2_t __riscv_vwsub_vv(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                            size_t vl);
vint64m2_t __riscv_vwsub_vx(vbool32_t vm, vint32m1_t vs2, int32_t rs1,
                            size_t vl);
vint64m2_t __riscv_vwsub_wv(vbool32_t vm, vint64m2_t vs2, vint32m1_t vs1,
                            size_t vl);
vint64m2_t __riscv_vwsub_wx(vbool32_t vm, vint64m2_t vs2, int32_t rs1,
                            size_t vl);
vint64m4_t __riscv_vwsub_vv(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                            size_t vl);
vint64m4_t __riscv_vwsub_vx(vbool16_t vm, vint32m2_t vs2, int32_t rs1,
                            size_t vl);
vint64m4_t __riscv_vwsub_wv(vbool16_t vm, vint64m4_t vs2, vint32m2_t vs1,
                            size_t vl);
vint64m4_t __riscv_vwsub_wx(vbool16_t vm, vint64m4_t vs2, int32_t rs1,
                            size_t vl);
vint64m8_t __riscv_vwsub_vv(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                            size_t vl);
vint64m8_t __riscv_vwsub_vx(vbool8_t vm, vint32m4_t vs2, int32_t rs1,
                            size_t vl);
vint64m8_t __riscv_vwsub_wv(vbool8_t vm, vint64m8_t vs2, vint32m4_t vs1,
                            size_t vl);
vint64m8_t __riscv_vwsub_wx(vbool8_t vm, vint64m8_t vs2, int32_t rs1,
                            size_t vl);
vuint16mf4_t __riscv_vwaddu_vv(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                               size_t vl);
vuint16mf4_t __riscv_vwaddu_vx(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                               size_t vl);
vuint16mf4_t __riscv_vwaddu_wv(vbool64_t vm, vuint16mf4_t vs2, vuint8mf8_t vs1,
                               size_t vl);
vuint16mf4_t __riscv_vwaddu_wx(vbool64_t vm, vuint16mf4_t vs2, uint8_t rs1,
                               size_t vl);
vuint16mf2_t __riscv_vwaddu_vv(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                               size_t vl);
vuint16mf2_t __riscv_vwaddu_vx(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                               size_t vl);
vuint16mf2_t __riscv_vwaddu_wv(vbool32_t vm, vuint16mf2_t vs2, vuint8mf4_t vs1,
                               size_t vl);
vuint16mf2_t __riscv_vwaddu_wx(vbool32_t vm, vuint16mf2_t vs2, uint8_t rs1,
                               size_t vl);
vuint16m1_t __riscv_vwaddu_vv(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                              size_t vl);
vuint16m1_t __riscv_vwaddu_vx(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m1_t __riscv_vwaddu_wv(vbool16_t vm, vuint16m1_t vs2, vuint8mf2_t vs1,
                              size_t vl);
vuint16m1_t __riscv_vwaddu_wx(vbool16_t vm, vuint16m1_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m2_t __riscv_vwaddu_vv(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                              size_t vl);
vuint16m2_t __riscv_vwaddu_vx(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m2_t __riscv_vwaddu_wv(vbool8_t vm, vuint16m2_t vs2, vuint8m1_t vs1,
                              size_t vl);
vuint16m2_t __riscv_vwaddu_wx(vbool8_t vm, vuint16m2_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m4_t __riscv_vwaddu_vv(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                              size_t vl);
vuint16m4_t __riscv_vwaddu_vx(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m4_t __riscv_vwaddu_wv(vbool4_t vm, vuint16m4_t vs2, vuint8m2_t vs1,
                              size_t vl);
vuint16m4_t __riscv_vwaddu_wx(vbool4_t vm, vuint16m4_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m8_t __riscv_vwaddu_vv(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                              size_t vl);
vuint16m8_t __riscv_vwaddu_vx(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m8_t __riscv_vwaddu_wv(vbool2_t vm, vuint16m8_t vs2, vuint8m4_t vs1,
                              size_t vl);
vuint16m8_t __riscv_vwaddu_wx(vbool2_t vm, vuint16m8_t vs2, uint8_t rs1,
                              size_t vl);
vuint32mf2_t __riscv_vwaddu_vv(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                               size_t vl);
vuint32mf2_t __riscv_vwaddu_vx(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                               size_t vl);
vuint32mf2_t __riscv_vwaddu_wv(vbool64_t vm, vuint32mf2_t vs2, vuint16mf4_t vs1,
                               size_t vl);
vuint32mf2_t __riscv_vwaddu_wx(vbool64_t vm, vuint32mf2_t vs2, uint16_t rs1,
                               size_t vl);
vuint32m1_t __riscv_vwaddu_vv(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                              size_t vl);
vuint32m1_t __riscv_vwaddu_vx(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m1_t __riscv_vwaddu_wv(vbool32_t vm, vuint32m1_t vs2, vuint16mf2_t vs1,
                              size_t vl);
vuint32m1_t __riscv_vwaddu_wx(vbool32_t vm, vuint32m1_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m2_t __riscv_vwaddu_vv(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                              size_t vl);
vuint32m2_t __riscv_vwaddu_vx(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m2_t __riscv_vwaddu_wv(vbool16_t vm, vuint32m2_t vs2, vuint16m1_t vs1,
                              size_t vl);
vuint32m2_t __riscv_vwaddu_wx(vbool16_t vm, vuint32m2_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m4_t __riscv_vwaddu_vv(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                              size_t vl);
vuint32m4_t __riscv_vwaddu_vx(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m4_t __riscv_vwaddu_wv(vbool8_t vm, vuint32m4_t vs2, vuint16m2_t vs1,
                              size_t vl);
vuint32m4_t __riscv_vwaddu_wx(vbool8_t vm, vuint32m4_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m8_t __riscv_vwaddu_vv(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                              size_t vl);
vuint32m8_t __riscv_vwaddu_vx(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m8_t __riscv_vwaddu_wv(vbool4_t vm, vuint32m8_t vs2, vuint16m4_t vs1,
                              size_t vl);
vuint32m8_t __riscv_vwaddu_wx(vbool4_t vm, vuint32m8_t vs2, uint16_t rs1,
                              size_t vl);
vuint64m1_t __riscv_vwaddu_vv(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                              size_t vl);
vuint64m1_t __riscv_vwaddu_vx(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m1_t __riscv_vwaddu_wv(vbool64_t vm, vuint64m1_t vs2, vuint32mf2_t vs1,
                              size_t vl);
vuint64m1_t __riscv_vwaddu_wx(vbool64_t vm, vuint64m1_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m2_t __riscv_vwaddu_vv(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                              size_t vl);
vuint64m2_t __riscv_vwaddu_vx(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m2_t __riscv_vwaddu_wv(vbool32_t vm, vuint64m2_t vs2, vuint32m1_t vs1,
                              size_t vl);
vuint64m2_t __riscv_vwaddu_wx(vbool32_t vm, vuint64m2_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m4_t __riscv_vwaddu_vv(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                              size_t vl);
vuint64m4_t __riscv_vwaddu_vx(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m4_t __riscv_vwaddu_wv(vbool16_t vm, vuint64m4_t vs2, vuint32m2_t vs1,
                              size_t vl);
vuint64m4_t __riscv_vwaddu_wx(vbool16_t vm, vuint64m4_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m8_t __riscv_vwaddu_vv(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                              size_t vl);
vuint64m8_t __riscv_vwaddu_vx(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m8_t __riscv_vwaddu_wv(vbool8_t vm, vuint64m8_t vs2, vuint32m4_t vs1,
                              size_t vl);
vuint64m8_t __riscv_vwaddu_wx(vbool8_t vm, vuint64m8_t vs2, uint32_t rs1,
                              size_t vl);
vuint16mf4_t __riscv_vwsubu_vv(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                               size_t vl);
vuint16mf4_t __riscv_vwsubu_vx(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                               size_t vl);
vuint16mf4_t __riscv_vwsubu_wv(vbool64_t vm, vuint16mf4_t vs2, vuint8mf8_t vs1,
                               size_t vl);
vuint16mf4_t __riscv_vwsubu_wx(vbool64_t vm, vuint16mf4_t vs2, uint8_t rs1,
                               size_t vl);
vuint16mf2_t __riscv_vwsubu_vv(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                               size_t vl);
vuint16mf2_t __riscv_vwsubu_vx(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                               size_t vl);
vuint16mf2_t __riscv_vwsubu_wv(vbool32_t vm, vuint16mf2_t vs2, vuint8mf4_t vs1,
                               size_t vl);
vuint16mf2_t __riscv_vwsubu_wx(vbool32_t vm, vuint16mf2_t vs2, uint8_t rs1,
                               size_t vl);
vuint16m1_t __riscv_vwsubu_vv(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                              size_t vl);
vuint16m1_t __riscv_vwsubu_vx(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m1_t __riscv_vwsubu_wv(vbool16_t vm, vuint16m1_t vs2, vuint8mf2_t vs1,
                              size_t vl);
vuint16m1_t __riscv_vwsubu_wx(vbool16_t vm, vuint16m1_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m2_t __riscv_vwsubu_vv(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                              size_t vl);
vuint16m2_t __riscv_vwsubu_vx(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m2_t __riscv_vwsubu_wv(vbool8_t vm, vuint16m2_t vs2, vuint8m1_t vs1,
                              size_t vl);
vuint16m2_t __riscv_vwsubu_wx(vbool8_t vm, vuint16m2_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m4_t __riscv_vwsubu_vv(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                              size_t vl);
vuint16m4_t __riscv_vwsubu_vx(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m4_t __riscv_vwsubu_wv(vbool4_t vm, vuint16m4_t vs2, vuint8m2_t vs1,
                              size_t vl);
vuint16m4_t __riscv_vwsubu_wx(vbool4_t vm, vuint16m4_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m8_t __riscv_vwsubu_vv(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                              size_t vl);
vuint16m8_t __riscv_vwsubu_vx(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1,
                              size_t vl);
vuint16m8_t __riscv_vwsubu_wv(vbool2_t vm, vuint16m8_t vs2, vuint8m4_t vs1,
                              size_t vl);
vuint16m8_t __riscv_vwsubu_wx(vbool2_t vm, vuint16m8_t vs2, uint8_t rs1,
                              size_t vl);
vuint32mf2_t __riscv_vwsubu_vv(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                               size_t vl);
vuint32mf2_t __riscv_vwsubu_vx(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                               size_t vl);
vuint32mf2_t __riscv_vwsubu_wv(vbool64_t vm, vuint32mf2_t vs2, vuint16mf4_t vs1,
                               size_t vl);
vuint32mf2_t __riscv_vwsubu_wx(vbool64_t vm, vuint32mf2_t vs2, uint16_t rs1,
                               size_t vl);
vuint32m1_t __riscv_vwsubu_vv(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                              size_t vl);
vuint32m1_t __riscv_vwsubu_vx(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m1_t __riscv_vwsubu_wv(vbool32_t vm, vuint32m1_t vs2, vuint16mf2_t vs1,
                              size_t vl);
vuint32m1_t __riscv_vwsubu_wx(vbool32_t vm, vuint32m1_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m2_t __riscv_vwsubu_vv(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                              size_t vl);
vuint32m2_t __riscv_vwsubu_vx(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m2_t __riscv_vwsubu_wv(vbool16_t vm, vuint32m2_t vs2, vuint16m1_t vs1,
                              size_t vl);
vuint32m2_t __riscv_vwsubu_wx(vbool16_t vm, vuint32m2_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m4_t __riscv_vwsubu_vv(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                              size_t vl);
vuint32m4_t __riscv_vwsubu_vx(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m4_t __riscv_vwsubu_wv(vbool8_t vm, vuint32m4_t vs2, vuint16m2_t vs1,
                              size_t vl);
vuint32m4_t __riscv_vwsubu_wx(vbool8_t vm, vuint32m4_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m8_t __riscv_vwsubu_vv(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                              size_t vl);
vuint32m8_t __riscv_vwsubu_vx(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                              size_t vl);
vuint32m8_t __riscv_vwsubu_wv(vbool4_t vm, vuint32m8_t vs2, vuint16m4_t vs1,
                              size_t vl);
vuint32m8_t __riscv_vwsubu_wx(vbool4_t vm, vuint32m8_t vs2, uint16_t rs1,
                              size_t vl);
vuint64m1_t __riscv_vwsubu_vv(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                              size_t vl);
vuint64m1_t __riscv_vwsubu_vx(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m1_t __riscv_vwsubu_wv(vbool64_t vm, vuint64m1_t vs2, vuint32mf2_t vs1,
                              size_t vl);
vuint64m1_t __riscv_vwsubu_wx(vbool64_t vm, vuint64m1_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m2_t __riscv_vwsubu_vv(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                              size_t vl);
vuint64m2_t __riscv_vwsubu_vx(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m2_t __riscv_vwsubu_wv(vbool32_t vm, vuint64m2_t vs2, vuint32m1_t vs1,
                              size_t vl);
vuint64m2_t __riscv_vwsubu_wx(vbool32_t vm, vuint64m2_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m4_t __riscv_vwsubu_vv(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                              size_t vl);
vuint64m4_t __riscv_vwsubu_vx(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m4_t __riscv_vwsubu_wv(vbool16_t vm, vuint64m4_t vs2, vuint32m2_t vs1,
                              size_t vl);
vuint64m4_t __riscv_vwsubu_wx(vbool16_t vm, vuint64m4_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m8_t __riscv_vwsubu_vv(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                              size_t vl);
vuint64m8_t __riscv_vwsubu_vx(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                              size_t vl);
vuint64m8_t __riscv_vwsubu_wv(vbool8_t vm, vuint64m8_t vs2, vuint32m4_t vs1,
                              size_t vl);
vuint64m8_t __riscv_vwsubu_wx(vbool8_t vm, vuint64m8_t vs2, uint32_t rs1,
                              size_t vl);
----

[[overloaded-vector-integer-widening]]
==== Vector Integer Widening Intrinsics

[,c]
----
vint16mf4_t __riscv_vwcvt_x(vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwcvt_x(vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwcvt_x(vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwcvt_x(vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwcvt_x(vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwcvt_x(vint8m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwcvtu_x(vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vwcvtu_x(vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vwcvtu_x(vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vwcvtu_x(vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vwcvtu_x(vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vwcvtu_x(vuint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwcvt_x(vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwcvt_x(vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwcvt_x(vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwcvt_x(vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwcvt_x(vint16m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwcvtu_x(vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vwcvtu_x(vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vwcvtu_x(vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vwcvtu_x(vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vwcvtu_x(vuint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwcvt_x(vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwcvt_x(vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwcvt_x(vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwcvt_x(vint32m4_t vs2, size_t vl);
vuint64m1_t __riscv_vwcvtu_x(vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vwcvtu_x(vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vwcvtu_x(vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vwcvtu_x(vuint32m4_t vs2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwcvt_x(vbool64_t vm, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwcvt_x(vbool32_t vm, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwcvt_x(vbool16_t vm, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwcvt_x(vbool8_t vm, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwcvt_x(vbool4_t vm, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwcvt_x(vbool2_t vm, vint8m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwcvtu_x(vbool64_t vm, vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vwcvtu_x(vbool32_t vm, vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vwcvtu_x(vbool16_t vm, vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vwcvtu_x(vbool8_t vm, vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vwcvtu_x(vbool4_t vm, vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vwcvtu_x(vbool2_t vm, vuint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwcvt_x(vbool64_t vm, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwcvt_x(vbool32_t vm, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwcvt_x(vbool16_t vm, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwcvt_x(vbool8_t vm, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwcvt_x(vbool4_t vm, vint16m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwcvtu_x(vbool64_t vm, vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vwcvtu_x(vbool32_t vm, vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vwcvtu_x(vbool16_t vm, vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vwcvtu_x(vbool8_t vm, vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vwcvtu_x(vbool4_t vm, vuint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwcvt_x(vbool64_t vm, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwcvt_x(vbool32_t vm, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwcvt_x(vbool16_t vm, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwcvt_x(vbool8_t vm, vint32m4_t vs2, size_t vl);
vuint64m1_t __riscv_vwcvtu_x(vbool64_t vm, vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vwcvtu_x(vbool32_t vm, vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vwcvtu_x(vbool16_t vm, vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vwcvtu_x(vbool8_t vm, vuint32m4_t vs2, size_t vl);
----

[[overloaded-vector-integer-extension]]
==== Vector Integer Extension Intrinsics

[,c]
----
vint16mf4_t __riscv_vsext_vf2(vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vsext_vf2(vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vsext_vf2(vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vsext_vf2(vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vsext_vf2(vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vsext_vf2(vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vsext_vf4(vint8mf8_t vs2, size_t vl);
vint32m1_t __riscv_vsext_vf4(vint8mf4_t vs2, size_t vl);
vint32m2_t __riscv_vsext_vf4(vint8mf2_t vs2, size_t vl);
vint32m4_t __riscv_vsext_vf4(vint8m1_t vs2, size_t vl);
vint32m8_t __riscv_vsext_vf4(vint8m2_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf8(vint8mf8_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf8(vint8mf4_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf8(vint8mf2_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf8(vint8m1_t vs2, size_t vl);
vint32mf2_t __riscv_vsext_vf2(vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vsext_vf2(vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vsext_vf2(vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vsext_vf2(vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vsext_vf2(vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf4(vint16mf4_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf4(vint16mf2_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf4(vint16m1_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf4(vint16m2_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf2(vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf2(vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf2(vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf2(vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vzext_vf2(vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vzext_vf2(vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vzext_vf2(vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vzext_vf2(vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vzext_vf2(vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vzext_vf2(vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vzext_vf4(vuint8mf8_t vs2, size_t vl);
vuint32m1_t __riscv_vzext_vf4(vuint8mf4_t vs2, size_t vl);
vuint32m2_t __riscv_vzext_vf4(vuint8mf2_t vs2, size_t vl);
vuint32m4_t __riscv_vzext_vf4(vuint8m1_t vs2, size_t vl);
vuint32m8_t __riscv_vzext_vf4(vuint8m2_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf8(vuint8mf8_t vs2, size_t vl);
vuint64m2_t __riscv_vzext_vf8(vuint8mf4_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf8(vuint8mf2_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf8(vuint8m1_t vs2, size_t vl);
vuint32mf2_t __riscv_vzext_vf2(vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vzext_vf2(vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vzext_vf2(vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vzext_vf2(vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vzext_vf2(vuint16m4_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf4(vuint16mf4_t vs2, size_t vl);
vuint64m2_t __riscv_vzext_vf4(vuint16mf2_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf4(vuint16m1_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf4(vuint16m2_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf2(vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vzext_vf2(vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf2(vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf2(vuint32m4_t vs2, size_t vl);
// masked functions
vint16mf4_t __riscv_vsext_vf2(vbool64_t vm, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vsext_vf2(vbool32_t vm, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vsext_vf2(vbool16_t vm, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vsext_vf2(vbool8_t vm, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vsext_vf2(vbool4_t vm, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vsext_vf2(vbool2_t vm, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vsext_vf4(vbool64_t vm, vint8mf8_t vs2, size_t vl);
vint32m1_t __riscv_vsext_vf4(vbool32_t vm, vint8mf4_t vs2, size_t vl);
vint32m2_t __riscv_vsext_vf4(vbool16_t vm, vint8mf2_t vs2, size_t vl);
vint32m4_t __riscv_vsext_vf4(vbool8_t vm, vint8m1_t vs2, size_t vl);
vint32m8_t __riscv_vsext_vf4(vbool4_t vm, vint8m2_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf8(vbool64_t vm, vint8mf8_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf8(vbool32_t vm, vint8mf4_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf8(vbool16_t vm, vint8mf2_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf8(vbool8_t vm, vint8m1_t vs2, size_t vl);
vint32mf2_t __riscv_vsext_vf2(vbool64_t vm, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vsext_vf2(vbool32_t vm, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vsext_vf2(vbool16_t vm, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vsext_vf2(vbool8_t vm, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vsext_vf2(vbool4_t vm, vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf4(vbool64_t vm, vint16mf4_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf4(vbool32_t vm, vint16mf2_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf4(vbool16_t vm, vint16m1_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf4(vbool8_t vm, vint16m2_t vs2, size_t vl);
vint64m1_t __riscv_vsext_vf2(vbool64_t vm, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vsext_vf2(vbool32_t vm, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vsext_vf2(vbool16_t vm, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vsext_vf2(vbool8_t vm, vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vzext_vf2(vbool64_t vm, vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vzext_vf2(vbool32_t vm, vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vzext_vf2(vbool16_t vm, vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vzext_vf2(vbool8_t vm, vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vzext_vf2(vbool4_t vm, vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vzext_vf2(vbool2_t vm, vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vzext_vf4(vbool64_t vm, vuint8mf8_t vs2, size_t vl);
vuint32m1_t __riscv_vzext_vf4(vbool32_t vm, vuint8mf4_t vs2, size_t vl);
vuint32m2_t __riscv_vzext_vf4(vbool16_t vm, vuint8mf2_t vs2, size_t vl);
vuint32m4_t __riscv_vzext_vf4(vbool8_t vm, vuint8m1_t vs2, size_t vl);
vuint32m8_t __riscv_vzext_vf4(vbool4_t vm, vuint8m2_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf8(vbool64_t vm, vuint8mf8_t vs2, size_t vl);
vuint64m2_t __riscv_vzext_vf8(vbool32_t vm, vuint8mf4_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf8(vbool16_t vm, vuint8mf2_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf8(vbool8_t vm, vuint8m1_t vs2, size_t vl);
vuint32mf2_t __riscv_vzext_vf2(vbool64_t vm, vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vzext_vf2(vbool32_t vm, vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vzext_vf2(vbool16_t vm, vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vzext_vf2(vbool8_t vm, vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vzext_vf2(vbool4_t vm, vuint16m4_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf4(vbool64_t vm, vuint16mf4_t vs2, size_t vl);
vuint64m2_t __riscv_vzext_vf4(vbool32_t vm, vuint16mf2_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf4(vbool16_t vm, vuint16m1_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf4(vbool8_t vm, vuint16m2_t vs2, size_t vl);
vuint64m1_t __riscv_vzext_vf2(vbool64_t vm, vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vzext_vf2(vbool32_t vm, vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vzext_vf2(vbool16_t vm, vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vzext_vf2(vbool8_t vm, vuint32m4_t vs2, size_t vl);
----

[[overloaded-vector-integer-neg]]
==== Vector Integer Neg Intrinsics

[,c]
----
vint8mf8_t __riscv_vneg(vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vneg(vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vneg(vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vneg(vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vneg(vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vneg(vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vneg(vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vneg(vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vneg(vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vneg(vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vneg(vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vneg(vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vneg(vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vneg(vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vneg(vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vneg(vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vneg(vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vneg(vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vneg(vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vneg(vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vneg(vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vneg(vint64m8_t vs2, size_t vl);
// masked functions
vint8mf8_t __riscv_vneg(vbool64_t vm, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vneg(vbool32_t vm, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vneg(vbool16_t vm, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vneg(vbool8_t vm, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vneg(vbool4_t vm, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vneg(vbool2_t vm, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vneg(vbool1_t vm, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vneg(vbool64_t vm, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vneg(vbool32_t vm, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vneg(vbool16_t vm, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vneg(vbool8_t vm, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vneg(vbool4_t vm, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vneg(vbool2_t vm, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vneg(vbool64_t vm, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vneg(vbool32_t vm, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vneg(vbool16_t vm, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vneg(vbool8_t vm, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vneg(vbool4_t vm, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vneg(vbool64_t vm, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vneg(vbool32_t vm, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vneg(vbool16_t vm, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vneg(vbool8_t vm, vint64m8_t vs2, size_t vl);
----

[[overloaded-vector-integer-add-with-carry-subtract-with-borrow]]
==== Vector Integer Add-with-Carry / Subtract-with-Borrow Intrinsics

[,c]
----
vint8mf8_t __riscv_vadc(vint8mf8_t vs2, vint8mf8_t vs1, vbool64_t v0,
                        size_t vl);
vint8mf8_t __riscv_vadc(vint8mf8_t vs2, int8_t rs1, vbool64_t v0, size_t vl);
vint8mf4_t __riscv_vadc(vint8mf4_t vs2, vint8mf4_t vs1, vbool32_t v0,
                        size_t vl);
vint8mf4_t __riscv_vadc(vint8mf4_t vs2, int8_t rs1, vbool32_t v0, size_t vl);
vint8mf2_t __riscv_vadc(vint8mf2_t vs2, vint8mf2_t vs1, vbool16_t v0,
                        size_t vl);
vint8mf2_t __riscv_vadc(vint8mf2_t vs2, int8_t rs1, vbool16_t v0, size_t vl);
vint8m1_t __riscv_vadc(vint8m1_t vs2, vint8m1_t vs1, vbool8_t v0, size_t vl);
vint8m1_t __riscv_vadc(vint8m1_t vs2, int8_t rs1, vbool8_t v0, size_t vl);
vint8m2_t __riscv_vadc(vint8m2_t vs2, vint8m2_t vs1, vbool4_t v0, size_t vl);
vint8m2_t __riscv_vadc(vint8m2_t vs2, int8_t rs1, vbool4_t v0, size_t vl);
vint8m4_t __riscv_vadc(vint8m4_t vs2, vint8m4_t vs1, vbool2_t v0, size_t vl);
vint8m4_t __riscv_vadc(vint8m4_t vs2, int8_t rs1, vbool2_t v0, size_t vl);
vint8m8_t __riscv_vadc(vint8m8_t vs2, vint8m8_t vs1, vbool1_t v0, size_t vl);
vint8m8_t __riscv_vadc(vint8m8_t vs2, int8_t rs1, vbool1_t v0, size_t vl);
vint16mf4_t __riscv_vadc(vint16mf4_t vs2, vint16mf4_t vs1, vbool64_t v0,
                         size_t vl);
vint16mf4_t __riscv_vadc(vint16mf4_t vs2, int16_t rs1, vbool64_t v0, size_t vl);
vint16mf2_t __riscv_vadc(vint16mf2_t vs2, vint16mf2_t vs1, vbool32_t v0,
                         size_t vl);
vint16mf2_t __riscv_vadc(vint16mf2_t vs2, int16_t rs1, vbool32_t v0, size_t vl);
vint16m1_t __riscv_vadc(vint16m1_t vs2, vint16m1_t vs1, vbool16_t v0,
                        size_t vl);
vint16m1_t __riscv_vadc(vint16m1_t vs2, int16_t rs1, vbool16_t v0, size_t vl);
vint16m2_t __riscv_vadc(vint16m2_t vs2, vint16m2_t vs1, vbool8_t v0, size_t vl);
vint16m2_t __riscv_vadc(vint16m2_t vs2, int16_t rs1, vbool8_t v0, size_t vl);
vint16m4_t __riscv_vadc(vint16m4_t vs2, vint16m4_t vs1, vbool4_t v0, size_t vl);
vint16m4_t __riscv_vadc(vint16m4_t vs2, int16_t rs1, vbool4_t v0, size_t vl);
vint16m8_t __riscv_vadc(vint16m8_t vs2, vint16m8_t vs1, vbool2_t v0, size_t vl);
vint16m8_t __riscv_vadc(vint16m8_t vs2, int16_t rs1, vbool2_t v0, size_t vl);
vint32mf2_t __riscv_vadc(vint32mf2_t vs2, vint32mf2_t vs1, vbool64_t v0,
                         size_t vl);
vint32mf2_t __riscv_vadc(vint32mf2_t vs2, int32_t rs1, vbool64_t v0, size_t vl);
vint32m1_t __riscv_vadc(vint32m1_t vs2, vint32m1_t vs1, vbool32_t v0,
                        size_t vl);
vint32m1_t __riscv_vadc(vint32m1_t vs2, int32_t rs1, vbool32_t v0, size_t vl);
vint32m2_t __riscv_vadc(vint32m2_t vs2, vint32m2_t vs1, vbool16_t v0,
                        size_t vl);
vint32m2_t __riscv_vadc(vint32m2_t vs2, int32_t rs1, vbool16_t v0, size_t vl);
vint32m4_t __riscv_vadc(vint32m4_t vs2, vint32m4_t vs1, vbool8_t v0, size_t vl);
vint32m4_t __riscv_vadc(vint32m4_t vs2, int32_t rs1, vbool8_t v0, size_t vl);
vint32m8_t __riscv_vadc(vint32m8_t vs2, vint32m8_t vs1, vbool4_t v0, size_t vl);
vint32m8_t __riscv_vadc(vint32m8_t vs2, int32_t rs1, vbool4_t v0, size_t vl);
vint64m1_t __riscv_vadc(vint64m1_t vs2, vint64m1_t vs1, vbool64_t v0,
                        size_t vl);
vint64m1_t __riscv_vadc(vint64m1_t vs2, int64_t rs1, vbool64_t v0, size_t vl);
vint64m2_t __riscv_vadc(vint64m2_t vs2, vint64m2_t vs1, vbool32_t v0,
                        size_t vl);
vint64m2_t __riscv_vadc(vint64m2_t vs2, int64_t rs1, vbool32_t v0, size_t vl);
vint64m4_t __riscv_vadc(vint64m4_t vs2, vint64m4_t vs1, vbool16_t v0,
                        size_t vl);
vint64m4_t __riscv_vadc(vint64m4_t vs2, int64_t rs1, vbool16_t v0, size_t vl);
vint64m8_t __riscv_vadc(vint64m8_t vs2, vint64m8_t vs1, vbool8_t v0, size_t vl);
vint64m8_t __riscv_vadc(vint64m8_t vs2, int64_t rs1, vbool8_t v0, size_t vl);
vint8mf8_t __riscv_vsbc(vint8mf8_t vs2, vint8mf8_t vs1, vbool64_t v0,
                        size_t vl);
vint8mf8_t __riscv_vsbc(vint8mf8_t vs2, int8_t rs1, vbool64_t v0, size_t vl);
vint8mf4_t __riscv_vsbc(vint8mf4_t vs2, vint8mf4_t vs1, vbool32_t v0,
                        size_t vl);
vint8mf4_t __riscv_vsbc(vint8mf4_t vs2, int8_t rs1, vbool32_t v0, size_t vl);
vint8mf2_t __riscv_vsbc(vint8mf2_t vs2, vint8mf2_t vs1, vbool16_t v0,
                        size_t vl);
vint8mf2_t __riscv_vsbc(vint8mf2_t vs2, int8_t rs1, vbool16_t v0, size_t vl);
vint8m1_t __riscv_vsbc(vint8m1_t vs2, vint8m1_t vs1, vbool8_t v0, size_t vl);
vint8m1_t __riscv_vsbc(vint8m1_t vs2, int8_t rs1, vbool8_t v0, size_t vl);
vint8m2_t __riscv_vsbc(vint8m2_t vs2, vint8m2_t vs1, vbool4_t v0, size_t vl);
vint8m2_t __riscv_vsbc(vint8m2_t vs2, int8_t rs1, vbool4_t v0, size_t vl);
vint8m4_t __riscv_vsbc(vint8m4_t vs2, vint8m4_t vs1, vbool2_t v0, size_t vl);
vint8m4_t __riscv_vsbc(vint8m4_t vs2, int8_t rs1, vbool2_t v0, size_t vl);
vint8m8_t __riscv_vsbc(vint8m8_t vs2, vint8m8_t vs1, vbool1_t v0, size_t vl);
vint8m8_t __riscv_vsbc(vint8m8_t vs2, int8_t rs1, vbool1_t v0, size_t vl);
vint16mf4_t __riscv_vsbc(vint16mf4_t vs2, vint16mf4_t vs1, vbool64_t v0,
                         size_t vl);
vint16mf4_t __riscv_vsbc(vint16mf4_t vs2, int16_t rs1, vbool64_t v0, size_t vl);
vint16mf2_t __riscv_vsbc(vint16mf2_t vs2, vint16mf2_t vs1, vbool32_t v0,
                         size_t vl);
vint16mf2_t __riscv_vsbc(vint16mf2_t vs2, int16_t rs1, vbool32_t v0, size_t vl);
vint16m1_t __riscv_vsbc(vint16m1_t vs2, vint16m1_t vs1, vbool16_t v0,
                        size_t vl);
vint16m1_t __riscv_vsbc(vint16m1_t vs2, int16_t rs1, vbool16_t v0, size_t vl);
vint16m2_t __riscv_vsbc(vint16m2_t vs2, vint16m2_t vs1, vbool8_t v0, size_t vl);
vint16m2_t __riscv_vsbc(vint16m2_t vs2, int16_t rs1, vbool8_t v0, size_t vl);
vint16m4_t __riscv_vsbc(vint16m4_t vs2, vint16m4_t vs1, vbool4_t v0, size_t vl);
vint16m4_t __riscv_vsbc(vint16m4_t vs2, int16_t rs1, vbool4_t v0, size_t vl);
vint16m8_t __riscv_vsbc(vint16m8_t vs2, vint16m8_t vs1, vbool2_t v0, size_t vl);
vint16m8_t __riscv_vsbc(vint16m8_t vs2, int16_t rs1, vbool2_t v0, size_t vl);
vint32mf2_t __riscv_vsbc(vint32mf2_t vs2, vint32mf2_t vs1, vbool64_t v0,
                         size_t vl);
vint32mf2_t __riscv_vsbc(vint32mf2_t vs2, int32_t rs1, vbool64_t v0, size_t vl);
vint32m1_t __riscv_vsbc(vint32m1_t vs2, vint32m1_t vs1, vbool32_t v0,
                        size_t vl);
vint32m1_t __riscv_vsbc(vint32m1_t vs2, int32_t rs1, vbool32_t v0, size_t vl);
vint32m2_t __riscv_vsbc(vint32m2_t vs2, vint32m2_t vs1, vbool16_t v0,
                        size_t vl);
vint32m2_t __riscv_vsbc(vint32m2_t vs2, int32_t rs1, vbool16_t v0, size_t vl);
vint32m4_t __riscv_vsbc(vint32m4_t vs2, vint32m4_t vs1, vbool8_t v0, size_t vl);
vint32m4_t __riscv_vsbc(vint32m4_t vs2, int32_t rs1, vbool8_t v0, size_t vl);
vint32m8_t __riscv_vsbc(vint32m8_t vs2, vint32m8_t vs1, vbool4_t v0, size_t vl);
vint32m8_t __riscv_vsbc(vint32m8_t vs2, int32_t rs1, vbool4_t v0, size_t vl);
vint64m1_t __riscv_vsbc(vint64m1_t vs2, vint64m1_t vs1, vbool64_t v0,
                        size_t vl);
vint64m1_t __riscv_vsbc(vint64m1_t vs2, int64_t rs1, vbool64_t v0, size_t vl);
vint64m2_t __riscv_vsbc(vint64m2_t vs2, vint64m2_t vs1, vbool32_t v0,
                        size_t vl);
vint64m2_t __riscv_vsbc(vint64m2_t vs2, int64_t rs1, vbool32_t v0, size_t vl);
vint64m4_t __riscv_vsbc(vint64m4_t vs2, vint64m4_t vs1, vbool16_t v0,
                        size_t vl);
vint64m4_t __riscv_vsbc(vint64m4_t vs2, int64_t rs1, vbool16_t v0, size_t vl);
vint64m8_t __riscv_vsbc(vint64m8_t vs2, vint64m8_t vs1, vbool8_t v0, size_t vl);
vint64m8_t __riscv_vsbc(vint64m8_t vs2, int64_t rs1, vbool8_t v0, size_t vl);
vuint8mf8_t __riscv_vadc(vuint8mf8_t vs2, vuint8mf8_t vs1, vbool64_t v0,
                         size_t vl);
vuint8mf8_t __riscv_vadc(vuint8mf8_t vs2, uint8_t rs1, vbool64_t v0, size_t vl);
vuint8mf4_t __riscv_vadc(vuint8mf4_t vs2, vuint8mf4_t vs1, vbool32_t v0,
                         size_t vl);
vuint8mf4_t __riscv_vadc(vuint8mf4_t vs2, uint8_t rs1, vbool32_t v0, size_t vl);
vuint8mf2_t __riscv_vadc(vuint8mf2_t vs2, vuint8mf2_t vs1, vbool16_t v0,
                         size_t vl);
vuint8mf2_t __riscv_vadc(vuint8mf2_t vs2, uint8_t rs1, vbool16_t v0, size_t vl);
vuint8m1_t __riscv_vadc(vuint8m1_t vs2, vuint8m1_t vs1, vbool8_t v0, size_t vl);
vuint8m1_t __riscv_vadc(vuint8m1_t vs2, uint8_t rs1, vbool8_t v0, size_t vl);
vuint8m2_t __riscv_vadc(vuint8m2_t vs2, vuint8m2_t vs1, vbool4_t v0, size_t vl);
vuint8m2_t __riscv_vadc(vuint8m2_t vs2, uint8_t rs1, vbool4_t v0, size_t vl);
vuint8m4_t __riscv_vadc(vuint8m4_t vs2, vuint8m4_t vs1, vbool2_t v0, size_t vl);
vuint8m4_t __riscv_vadc(vuint8m4_t vs2, uint8_t rs1, vbool2_t v0, size_t vl);
vuint8m8_t __riscv_vadc(vuint8m8_t vs2, vuint8m8_t vs1, vbool1_t v0, size_t vl);
vuint8m8_t __riscv_vadc(vuint8m8_t vs2, uint8_t rs1, vbool1_t v0, size_t vl);
vuint16mf4_t __riscv_vadc(vuint16mf4_t vs2, vuint16mf4_t vs1, vbool64_t v0,
                          size_t vl);
vuint16mf4_t __riscv_vadc(vuint16mf4_t vs2, uint16_t rs1, vbool64_t v0,
                          size_t vl);
vuint16mf2_t __riscv_vadc(vuint16mf2_t vs2, vuint16mf2_t vs1, vbool32_t v0,
                          size_t vl);
vuint16mf2_t __riscv_vadc(vuint16mf2_t vs2, uint16_t rs1, vbool32_t v0,
                          size_t vl);
vuint16m1_t __riscv_vadc(vuint16m1_t vs2, vuint16m1_t vs1, vbool16_t v0,
                         size_t vl);
vuint16m1_t __riscv_vadc(vuint16m1_t vs2, uint16_t rs1, vbool16_t v0,
                         size_t vl);
vuint16m2_t __riscv_vadc(vuint16m2_t vs2, vuint16m2_t vs1, vbool8_t v0,
                         size_t vl);
vuint16m2_t __riscv_vadc(vuint16m2_t vs2, uint16_t rs1, vbool8_t v0, size_t vl);
vuint16m4_t __riscv_vadc(vuint16m4_t vs2, vuint16m4_t vs1, vbool4_t v0,
                         size_t vl);
vuint16m4_t __riscv_vadc(vuint16m4_t vs2, uint16_t rs1, vbool4_t v0, size_t vl);
vuint16m8_t __riscv_vadc(vuint16m8_t vs2, vuint16m8_t vs1, vbool2_t v0,
                         size_t vl);
vuint16m8_t __riscv_vadc(vuint16m8_t vs2, uint16_t rs1, vbool2_t v0, size_t vl);
vuint32mf2_t __riscv_vadc(vuint32mf2_t vs2, vuint32mf2_t vs1, vbool64_t v0,
                          size_t vl);
vuint32mf2_t __riscv_vadc(vuint32mf2_t vs2, uint32_t rs1, vbool64_t v0,
                          size_t vl);
vuint32m1_t __riscv_vadc(vuint32m1_t vs2, vuint32m1_t vs1, vbool32_t v0,
                         size_t vl);
vuint32m1_t __riscv_vadc(vuint32m1_t vs2, uint32_t rs1, vbool32_t v0,
                         size_t vl);
vuint32m2_t __riscv_vadc(vuint32m2_t vs2, vuint32m2_t vs1, vbool16_t v0,
                         size_t vl);
vuint32m2_t __riscv_vadc(vuint32m2_t vs2, uint32_t rs1, vbool16_t v0,
                         size_t vl);
vuint32m4_t __riscv_vadc(vuint32m4_t vs2, vuint32m4_t vs1, vbool8_t v0,
                         size_t vl);
vuint32m4_t __riscv_vadc(vuint32m4_t vs2, uint32_t rs1, vbool8_t v0, size_t vl);
vuint32m8_t __riscv_vadc(vuint32m8_t vs2, vuint32m8_t vs1, vbool4_t v0,
                         size_t vl);
vuint32m8_t __riscv_vadc(vuint32m8_t vs2, uint32_t rs1, vbool4_t v0, size_t vl);
vuint64m1_t __riscv_vadc(vuint64m1_t vs2, vuint64m1_t vs1, vbool64_t v0,
                         size_t vl);
vuint64m1_t __riscv_vadc(vuint64m1_t vs2, uint64_t rs1, vbool64_t v0,
                         size_t vl);
vuint64m2_t __riscv_vadc(vuint64m2_t vs2, vuint64m2_t vs1, vbool32_t v0,
                         size_t vl);
vuint64m2_t __riscv_vadc(vuint64m2_t vs2, uint64_t rs1, vbool32_t v0,
                         size_t vl);
vuint64m4_t __riscv_vadc(vuint64m4_t vs2, vuint64m4_t vs1, vbool16_t v0,
                         size_t vl);
vuint64m4_t __riscv_vadc(vuint64m4_t vs2, uint64_t rs1, vbool16_t v0,
                         size_t vl);
vuint64m8_t __riscv_vadc(vuint64m8_t vs2, vuint64m8_t vs1, vbool8_t v0,
                         size_t vl);
vuint64m8_t __riscv_vadc(vuint64m8_t vs2, uint64_t rs1, vbool8_t v0, size_t vl);
vuint8mf8_t __riscv_vsbc(vuint8mf8_t vs2, vuint8mf8_t vs1, vbool64_t v0,
                         size_t vl);
vuint8mf8_t __riscv_vsbc(vuint8mf8_t vs2, uint8_t rs1, vbool64_t v0, size_t vl);
vuint8mf4_t __riscv_vsbc(vuint8mf4_t vs2, vuint8mf4_t vs1, vbool32_t v0,
                         size_t vl);
vuint8mf4_t __riscv_vsbc(vuint8mf4_t vs2, uint8_t rs1, vbool32_t v0, size_t vl);
vuint8mf2_t __riscv_vsbc(vuint8mf2_t vs2, vuint8mf2_t vs1, vbool16_t v0,
                         size_t vl);
vuint8mf2_t __riscv_vsbc(vuint8mf2_t vs2, uint8_t rs1, vbool16_t v0, size_t vl);
vuint8m1_t __riscv_vsbc(vuint8m1_t vs2, vuint8m1_t vs1, vbool8_t v0, size_t vl);
vuint8m1_t __riscv_vsbc(vuint8m1_t vs2, uint8_t rs1, vbool8_t v0, size_t vl);
vuint8m2_t __riscv_vsbc(vuint8m2_t vs2, vuint8m2_t vs1, vbool4_t v0, size_t vl);
vuint8m2_t __riscv_vsbc(vuint8m2_t vs2, uint8_t rs1, vbool4_t v0, size_t vl);
vuint8m4_t __riscv_vsbc(vuint8m4_t vs2, vuint8m4_t vs1, vbool2_t v0, size_t vl);
vuint8m4_t __riscv_vsbc(vuint8m4_t vs2, uint8_t rs1, vbool2_t v0, size_t vl);
vuint8m8_t __riscv_vsbc(vuint8m8_t vs2, vuint8m8_t vs1, vbool1_t v0, size_t vl);
vuint8m8_t __riscv_vsbc(vuint8m8_t vs2, uint8_t rs1, vbool1_t v0, size_t vl);
vuint16mf4_t __riscv_vsbc(vuint16mf4_t vs2, vuint16mf4_t vs1, vbool64_t v0,
                          size_t vl);
vuint16mf4_t __riscv_vsbc(vuint16mf4_t vs2, uint16_t rs1, vbool64_t v0,
                          size_t vl);
vuint16mf2_t __riscv_vsbc(vuint16mf2_t vs2, vuint16mf2_t vs1, vbool32_t v0,
                          size_t vl);
vuint16mf2_t __riscv_vsbc(vuint16mf2_t vs2, uint16_t rs1, vbool32_t v0,
                          size_t vl);
vuint16m1_t __riscv_vsbc(vuint16m1_t vs2, vuint16m1_t vs1, vbool16_t v0,
                         size_t vl);
vuint16m1_t __riscv_vsbc(vuint16m1_t vs2, uint16_t rs1, vbool16_t v0,
                         size_t vl);
vuint16m2_t __riscv_vsbc(vuint16m2_t vs2, vuint16m2_t vs1, vbool8_t v0,
                         size_t vl);
vuint16m2_t __riscv_vsbc(vuint16m2_t vs2, uint16_t rs1, vbool8_t v0, size_t vl);
vuint16m4_t __riscv_vsbc(vuint16m4_t vs2, vuint16m4_t vs1, vbool4_t v0,
                         size_t vl);
vuint16m4_t __riscv_vsbc(vuint16m4_t vs2, uint16_t rs1, vbool4_t v0, size_t vl);
vuint16m8_t __riscv_vsbc(vuint16m8_t vs2, vuint16m8_t vs1, vbool2_t v0,
                         size_t vl);
vuint16m8_t __riscv_vsbc(vuint16m8_t vs2, uint16_t rs1, vbool2_t v0, size_t vl);
vuint32mf2_t __riscv_vsbc(vuint32mf2_t vs2, vuint32mf2_t vs1, vbool64_t v0,
                          size_t vl);
vuint32mf2_t __riscv_vsbc(vuint32mf2_t vs2, uint32_t rs1, vbool64_t v0,
                          size_t vl);
vuint32m1_t __riscv_vsbc(vuint32m1_t vs2, vuint32m1_t vs1, vbool32_t v0,
                         size_t vl);
vuint32m1_t __riscv_vsbc(vuint32m1_t vs2, uint32_t rs1, vbool32_t v0,
                         size_t vl);
vuint32m2_t __riscv_vsbc(vuint32m2_t vs2, vuint32m2_t vs1, vbool16_t v0,
                         size_t vl);
vuint32m2_t __riscv_vsbc(vuint32m2_t vs2, uint32_t rs1, vbool16_t v0,
                         size_t vl);
vuint32m4_t __riscv_vsbc(vuint32m4_t vs2, vuint32m4_t vs1, vbool8_t v0,
                         size_t vl);
vuint32m4_t __riscv_vsbc(vuint32m4_t vs2, uint32_t rs1, vbool8_t v0, size_t vl);
vuint32m8_t __riscv_vsbc(vuint32m8_t vs2, vuint32m8_t vs1, vbool4_t v0,
                         size_t vl);
vuint32m8_t __riscv_vsbc(vuint32m8_t vs2, uint32_t rs1, vbool4_t v0, size_t vl);
vuint64m1_t __riscv_vsbc(vuint64m1_t vs2, vuint64m1_t vs1, vbool64_t v0,
                         size_t vl);
vuint64m1_t __riscv_vsbc(vuint64m1_t vs2, uint64_t rs1, vbool64_t v0,
                         size_t vl);
vuint64m2_t __riscv_vsbc(vuint64m2_t vs2, vuint64m2_t vs1, vbool32_t v0,
                         size_t vl);
vuint64m2_t __riscv_vsbc(vuint64m2_t vs2, uint64_t rs1, vbool32_t v0,
                         size_t vl);
vuint64m4_t __riscv_vsbc(vuint64m4_t vs2, vuint64m4_t vs1, vbool16_t v0,
                         size_t vl);
vuint64m4_t __riscv_vsbc(vuint64m4_t vs2, uint64_t rs1, vbool16_t v0,
                         size_t vl);
vuint64m8_t __riscv_vsbc(vuint64m8_t vs2, vuint64m8_t vs1, vbool8_t v0,
                         size_t vl);
vuint64m8_t __riscv_vsbc(vuint64m8_t vs2, uint64_t rs1, vbool8_t v0, size_t vl);
vbool64_t __riscv_vmadc(vint8mf8_t vs2, vint8mf8_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmadc(vint8mf8_t vs2, int8_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmadc(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmadc(vint8mf4_t vs2, vint8mf4_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmadc(vint8mf4_t vs2, int8_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmadc(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmadc(vint8mf2_t vs2, vint8mf2_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmadc(vint8mf2_t vs2, int8_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmadc(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmadc(vint8m1_t vs2, vint8m1_t vs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vint8m1_t vs2, int8_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmadc(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmadc(vint8m2_t vs2, vint8m2_t vs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc(vint8m2_t vs2, int8_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmadc(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmadc(vint8m4_t vs2, vint8m4_t vs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmadc(vint8m4_t vs2, int8_t rs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmadc(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmadc(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmadc(vint8m8_t vs2, vint8m8_t vs1, vbool1_t v0, size_t vl);
vbool1_t __riscv_vmadc(vint8m8_t vs2, int8_t rs1, vbool1_t v0, size_t vl);
vbool1_t __riscv_vmadc(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmadc(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmadc(vint16mf4_t vs2, vint16mf4_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmadc(vint16mf4_t vs2, int16_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmadc(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmadc(vint16mf2_t vs2, vint16mf2_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmadc(vint16mf2_t vs2, int16_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmadc(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmadc(vint16m1_t vs2, vint16m1_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmadc(vint16m1_t vs2, int16_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmadc(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmadc(vint16m2_t vs2, vint16m2_t vs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vint16m2_t vs2, int16_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmadc(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmadc(vint16m4_t vs2, vint16m4_t vs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc(vint16m4_t vs2, int16_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmadc(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmadc(vint16m8_t vs2, vint16m8_t vs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmadc(vint16m8_t vs2, int16_t rs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmadc(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmadc(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmadc(vint32mf2_t vs2, vint32mf2_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmadc(vint32mf2_t vs2, int32_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmadc(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmadc(vint32m1_t vs2, vint32m1_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmadc(vint32m1_t vs2, int32_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmadc(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmadc(vint32m2_t vs2, vint32m2_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmadc(vint32m2_t vs2, int32_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmadc(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmadc(vint32m4_t vs2, vint32m4_t vs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vint32m4_t vs2, int32_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmadc(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmadc(vint32m8_t vs2, vint32m8_t vs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc(vint32m8_t vs2, int32_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmadc(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmadc(vint64m1_t vs2, vint64m1_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmadc(vint64m1_t vs2, int64_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmadc(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmadc(vint64m2_t vs2, vint64m2_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmadc(vint64m2_t vs2, int64_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmadc(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmadc(vint64m4_t vs2, vint64m4_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmadc(vint64m4_t vs2, int64_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmadc(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmadc(vint64m8_t vs2, vint64m8_t vs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vint64m8_t vs2, int64_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmadc(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsbc(vint8mf8_t vs2, vint8mf8_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmsbc(vint8mf8_t vs2, int8_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsbc(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsbc(vint8mf4_t vs2, vint8mf4_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmsbc(vint8mf4_t vs2, int8_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsbc(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsbc(vint8mf2_t vs2, vint8mf2_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmsbc(vint8mf2_t vs2, int8_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsbc(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsbc(vint8m1_t vs2, vint8m1_t vs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vint8m1_t vs2, int8_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsbc(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsbc(vint8m2_t vs2, vint8m2_t vs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc(vint8m2_t vs2, int8_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsbc(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsbc(vint8m4_t vs2, vint8m4_t vs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmsbc(vint8m4_t vs2, int8_t rs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmsbc(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsbc(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsbc(vint8m8_t vs2, vint8m8_t vs1, vbool1_t v0, size_t vl);
vbool1_t __riscv_vmsbc(vint8m8_t vs2, int8_t rs1, vbool1_t v0, size_t vl);
vbool1_t __riscv_vmsbc(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsbc(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsbc(vint16mf4_t vs2, vint16mf4_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmsbc(vint16mf4_t vs2, int16_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsbc(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsbc(vint16mf2_t vs2, vint16mf2_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmsbc(vint16mf2_t vs2, int16_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsbc(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsbc(vint16m1_t vs2, vint16m1_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmsbc(vint16m1_t vs2, int16_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsbc(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsbc(vint16m2_t vs2, vint16m2_t vs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vint16m2_t vs2, int16_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsbc(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsbc(vint16m4_t vs2, vint16m4_t vs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc(vint16m4_t vs2, int16_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsbc(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsbc(vint16m8_t vs2, vint16m8_t vs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmsbc(vint16m8_t vs2, int16_t rs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmsbc(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsbc(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsbc(vint32mf2_t vs2, vint32mf2_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmsbc(vint32mf2_t vs2, int32_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsbc(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsbc(vint32m1_t vs2, vint32m1_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmsbc(vint32m1_t vs2, int32_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsbc(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsbc(vint32m2_t vs2, vint32m2_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmsbc(vint32m2_t vs2, int32_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsbc(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsbc(vint32m4_t vs2, vint32m4_t vs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vint32m4_t vs2, int32_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsbc(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsbc(vint32m8_t vs2, vint32m8_t vs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc(vint32m8_t vs2, int32_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsbc(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsbc(vint64m1_t vs2, vint64m1_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmsbc(vint64m1_t vs2, int64_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsbc(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsbc(vint64m2_t vs2, vint64m2_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmsbc(vint64m2_t vs2, int64_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsbc(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsbc(vint64m4_t vs2, vint64m4_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmsbc(vint64m4_t vs2, int64_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsbc(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsbc(vint64m8_t vs2, vint64m8_t vs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vint64m8_t vs2, int64_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsbc(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmadc(vuint8mf8_t vs2, vuint8mf8_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmadc(vuint8mf8_t vs2, uint8_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmadc(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmadc(vuint8mf4_t vs2, vuint8mf4_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmadc(vuint8mf4_t vs2, uint8_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmadc(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmadc(vuint8mf2_t vs2, vuint8mf2_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmadc(vuint8mf2_t vs2, uint8_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmadc(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmadc(vuint8m1_t vs2, vuint8m1_t vs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vuint8m1_t vs2, uint8_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmadc(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmadc(vuint8m2_t vs2, vuint8m2_t vs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc(vuint8m2_t vs2, uint8_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmadc(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmadc(vuint8m4_t vs2, vuint8m4_t vs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmadc(vuint8m4_t vs2, uint8_t rs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmadc(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmadc(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmadc(vuint8m8_t vs2, vuint8m8_t vs1, vbool1_t v0, size_t vl);
vbool1_t __riscv_vmadc(vuint8m8_t vs2, uint8_t rs1, vbool1_t v0, size_t vl);
vbool1_t __riscv_vmadc(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmadc(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmadc(vuint16mf4_t vs2, vuint16mf4_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmadc(vuint16mf4_t vs2, uint16_t rs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmadc(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmadc(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vbool32_t __riscv_vmadc(vuint16mf2_t vs2, vuint16mf2_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmadc(vuint16mf2_t vs2, uint16_t rs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmadc(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmadc(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vbool16_t __riscv_vmadc(vuint16m1_t vs2, vuint16m1_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmadc(vuint16m1_t vs2, uint16_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmadc(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmadc(vuint16m2_t vs2, vuint16m2_t vs1, vbool8_t v0,
                       size_t vl);
vbool8_t __riscv_vmadc(vuint16m2_t vs2, uint16_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmadc(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmadc(vuint16m4_t vs2, vuint16m4_t vs1, vbool4_t v0,
                       size_t vl);
vbool4_t __riscv_vmadc(vuint16m4_t vs2, uint16_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmadc(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmadc(vuint16m8_t vs2, vuint16m8_t vs1, vbool2_t v0,
                       size_t vl);
vbool2_t __riscv_vmadc(vuint16m8_t vs2, uint16_t rs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmadc(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmadc(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmadc(vuint32mf2_t vs2, vuint32mf2_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmadc(vuint32mf2_t vs2, uint32_t rs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmadc(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmadc(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vbool32_t __riscv_vmadc(vuint32m1_t vs2, vuint32m1_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmadc(vuint32m1_t vs2, uint32_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmadc(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmadc(vuint32m2_t vs2, vuint32m2_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmadc(vuint32m2_t vs2, uint32_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmadc(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmadc(vuint32m4_t vs2, vuint32m4_t vs1, vbool8_t v0,
                       size_t vl);
vbool8_t __riscv_vmadc(vuint32m4_t vs2, uint32_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmadc(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmadc(vuint32m8_t vs2, vuint32m8_t vs1, vbool4_t v0,
                       size_t vl);
vbool4_t __riscv_vmadc(vuint32m8_t vs2, uint32_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmadc(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmadc(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmadc(vuint64m1_t vs2, vuint64m1_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmadc(vuint64m1_t vs2, uint64_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmadc(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmadc(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmadc(vuint64m2_t vs2, vuint64m2_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmadc(vuint64m2_t vs2, uint64_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmadc(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmadc(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmadc(vuint64m4_t vs2, vuint64m4_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmadc(vuint64m4_t vs2, uint64_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmadc(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmadc(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmadc(vuint64m8_t vs2, vuint64m8_t vs1, vbool8_t v0,
                       size_t vl);
vbool8_t __riscv_vmadc(vuint64m8_t vs2, uint64_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmadc(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmadc(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsbc(vuint8mf8_t vs2, vuint8mf8_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmsbc(vuint8mf8_t vs2, uint8_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsbc(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsbc(vuint8mf4_t vs2, vuint8mf4_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmsbc(vuint8mf4_t vs2, uint8_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsbc(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsbc(vuint8mf2_t vs2, vuint8mf2_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmsbc(vuint8mf2_t vs2, uint8_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsbc(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsbc(vuint8m1_t vs2, vuint8m1_t vs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vuint8m1_t vs2, uint8_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsbc(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsbc(vuint8m2_t vs2, vuint8m2_t vs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc(vuint8m2_t vs2, uint8_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsbc(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsbc(vuint8m4_t vs2, vuint8m4_t vs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmsbc(vuint8m4_t vs2, uint8_t rs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmsbc(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsbc(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsbc(vuint8m8_t vs2, vuint8m8_t vs1, vbool1_t v0, size_t vl);
vbool1_t __riscv_vmsbc(vuint8m8_t vs2, uint8_t rs1, vbool1_t v0, size_t vl);
vbool1_t __riscv_vmsbc(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsbc(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsbc(vuint16mf4_t vs2, vuint16mf4_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmsbc(vuint16mf4_t vs2, uint16_t rs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmsbc(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsbc(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsbc(vuint16mf2_t vs2, vuint16mf2_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmsbc(vuint16mf2_t vs2, uint16_t rs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmsbc(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsbc(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsbc(vuint16m1_t vs2, vuint16m1_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmsbc(vuint16m1_t vs2, uint16_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsbc(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsbc(vuint16m2_t vs2, vuint16m2_t vs1, vbool8_t v0,
                       size_t vl);
vbool8_t __riscv_vmsbc(vuint16m2_t vs2, uint16_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsbc(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsbc(vuint16m4_t vs2, vuint16m4_t vs1, vbool4_t v0,
                       size_t vl);
vbool4_t __riscv_vmsbc(vuint16m4_t vs2, uint16_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsbc(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsbc(vuint16m8_t vs2, vuint16m8_t vs1, vbool2_t v0,
                       size_t vl);
vbool2_t __riscv_vmsbc(vuint16m8_t vs2, uint16_t rs1, vbool2_t v0, size_t vl);
vbool2_t __riscv_vmsbc(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsbc(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsbc(vuint32mf2_t vs2, vuint32mf2_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmsbc(vuint32mf2_t vs2, uint32_t rs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmsbc(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsbc(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsbc(vuint32m1_t vs2, vuint32m1_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmsbc(vuint32m1_t vs2, uint32_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsbc(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsbc(vuint32m2_t vs2, vuint32m2_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmsbc(vuint32m2_t vs2, uint32_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsbc(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsbc(vuint32m4_t vs2, vuint32m4_t vs1, vbool8_t v0,
                       size_t vl);
vbool8_t __riscv_vmsbc(vuint32m4_t vs2, uint32_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsbc(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsbc(vuint32m8_t vs2, vuint32m8_t vs1, vbool4_t v0,
                       size_t vl);
vbool4_t __riscv_vmsbc(vuint32m8_t vs2, uint32_t rs1, vbool4_t v0, size_t vl);
vbool4_t __riscv_vmsbc(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsbc(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsbc(vuint64m1_t vs2, vuint64m1_t vs1, vbool64_t v0,
                        size_t vl);
vbool64_t __riscv_vmsbc(vuint64m1_t vs2, uint64_t rs1, vbool64_t v0, size_t vl);
vbool64_t __riscv_vmsbc(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsbc(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsbc(vuint64m2_t vs2, vuint64m2_t vs1, vbool32_t v0,
                        size_t vl);
vbool32_t __riscv_vmsbc(vuint64m2_t vs2, uint64_t rs1, vbool32_t v0, size_t vl);
vbool32_t __riscv_vmsbc(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsbc(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsbc(vuint64m4_t vs2, vuint64m4_t vs1, vbool16_t v0,
                        size_t vl);
vbool16_t __riscv_vmsbc(vuint64m4_t vs2, uint64_t rs1, vbool16_t v0, size_t vl);
vbool16_t __riscv_vmsbc(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsbc(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsbc(vuint64m8_t vs2, vuint64m8_t vs1, vbool8_t v0,
                       size_t vl);
vbool8_t __riscv_vmsbc(vuint64m8_t vs2, uint64_t rs1, vbool8_t v0, size_t vl);
vbool8_t __riscv_vmsbc(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsbc(vuint64m8_t vs2, uint64_t rs1, size_t vl);
----

[[overloaded-vector-bitwise-binary-logical]]
==== Vector Bitwise Binary Logical Intrinsics

[,c]
----
vint8mf8_t __riscv_vand(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vand(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vand(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vand(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vand(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vand(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vand(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vand(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vand(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vand(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vand(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vand(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vand(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vand(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vand(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vand(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vand(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vand(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vand(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vand(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vand(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vand(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vand(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vand(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vand(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vand(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vand(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vand(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vand(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vand(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vand(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vand(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vand(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vand(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vand(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vand(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vand(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vand(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vand(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vand(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vand(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vand(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vand(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vand(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vor(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vor(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vor(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vor(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vor(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vor(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vor(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vor(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vor(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vor(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vor(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vor(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vor(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vor(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vor(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vor(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vor(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vor(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vor(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vor(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vor(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vor(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vor(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vor(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vor(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vor(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vor(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vor(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vor(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vor(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vor(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vor(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vor(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vor(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vor(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vor(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vor(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vor(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vor(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vor(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vor(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vor(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vor(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vor(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vxor(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vxor(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vxor(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vxor(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vxor(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vxor(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vxor(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vxor(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vxor(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vxor(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vxor(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vxor(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vxor(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vxor(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vxor(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vxor(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vxor(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vxor(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vxor(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vxor(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vxor(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vxor(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vxor(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vxor(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vxor(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vxor(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vxor(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vxor(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vxor(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vxor(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vxor(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vxor(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vxor(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vxor(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vxor(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vxor(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vxor(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vxor(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vxor(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vxor(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vxor(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vxor(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vxor(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vxor(vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vand(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vand(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vand(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vand(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vand(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vand(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vand(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vand(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vand(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vand(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vand(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vand(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vand(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vand(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vand(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vand(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vand(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vand(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vand(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vand(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vand(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vand(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vand(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vand(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vand(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vand(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vand(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vand(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vand(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vand(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vand(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vand(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vand(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vand(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vand(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vand(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vand(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vand(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vand(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vand(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vand(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vand(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vand(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vand(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vor(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vor(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vor(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vor(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vor(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vor(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vor(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vor(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vor(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vor(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vor(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vor(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vor(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vor(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vor(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vor(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vor(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vor(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vor(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vor(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vor(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vor(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vor(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vor(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vor(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vor(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vor(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vor(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vor(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vor(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vor(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vor(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vor(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vor(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vor(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vor(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vor(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vor(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vor(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vor(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vor(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vor(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vor(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vor(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vxor(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vxor(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vxor(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vxor(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vxor(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vxor(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vxor(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vxor(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vxor(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vxor(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vxor(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vxor(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vxor(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vxor(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vxor(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vxor(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vxor(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vxor(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vxor(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vxor(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vxor(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vxor(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vxor(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vxor(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vxor(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vxor(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vxor(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vxor(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vxor(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vxor(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vxor(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vxor(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vxor(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vxor(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vxor(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vxor(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vxor(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vxor(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vxor(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vxor(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vxor(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vxor(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vxor(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vxor(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vand(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vand(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vand(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vand(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vand(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vand(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vand(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vand(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vand(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vand(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vand(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vand(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vand(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vand(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vand(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vand(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vand(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vand(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vand(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vand(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vand(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vand(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vand(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vand(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vand(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vand(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vand(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vand(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vand(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vand(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vand(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vand(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vand(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vand(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vand(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vand(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vand(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vand(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vand(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vand(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vand(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vand(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vand(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vand(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vor(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vor(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vor(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vor(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vor(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vor(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vor(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vor(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vor(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vor(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vor(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vor(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vor(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vor(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vor(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                        size_t vl);
vint16mf4_t __riscv_vor(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vor(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                        size_t vl);
vint16mf2_t __riscv_vor(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vor(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vor(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vor(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vor(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vor(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vor(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vor(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vor(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vor(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                        size_t vl);
vint32mf2_t __riscv_vor(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vor(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vor(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vor(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vor(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vor(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vor(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vor(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vor(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vor(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vor(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vor(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vor(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vor(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vor(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vor(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vor(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vxor(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vxor(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vxor(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vxor(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vxor(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vxor(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vxor(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vxor(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vxor(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vxor(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vxor(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vxor(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vxor(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vxor(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vxor(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vxor(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vxor(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vxor(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vxor(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vxor(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vxor(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vxor(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vxor(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vxor(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vxor(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vxor(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vxor(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vxor(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vxor(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vxor(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vxor(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vxor(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vxor(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vxor(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vxor(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vxor(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vxor(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vxor(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vxor(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vxor(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vxor(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vxor(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vxor(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vxor(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vand(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vuint8mf8_t __riscv_vand(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vand(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vuint8mf4_t __riscv_vand(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vand(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vuint8mf2_t __riscv_vand(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vand(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vand(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vand(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vand(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vand(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vand(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vand(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vand(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vand(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                          size_t vl);
vuint16mf4_t __riscv_vand(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                          size_t vl);
vuint16mf2_t __riscv_vand(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                          size_t vl);
vuint16mf2_t __riscv_vand(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m1_t __riscv_vand(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vuint16m1_t __riscv_vand(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                         size_t vl);
vuint16m2_t __riscv_vand(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                         size_t vl);
vuint16m2_t __riscv_vand(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vand(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                         size_t vl);
vuint16m4_t __riscv_vand(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vand(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                         size_t vl);
vuint16m8_t __riscv_vand(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vand(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                          size_t vl);
vuint32mf2_t __riscv_vand(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m1_t __riscv_vand(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vuint32m1_t __riscv_vand(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m2_t __riscv_vand(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vuint32m2_t __riscv_vand(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m4_t __riscv_vand(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                         size_t vl);
vuint32m4_t __riscv_vand(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vand(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                         size_t vl);
vuint32m8_t __riscv_vand(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vand(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vuint64m1_t __riscv_vand(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m2_t __riscv_vand(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vuint64m2_t __riscv_vand(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m4_t __riscv_vand(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vuint64m4_t __riscv_vand(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m8_t __riscv_vand(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                         size_t vl);
vuint64m8_t __riscv_vand(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vor(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                        size_t vl);
vuint8mf8_t __riscv_vor(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vor(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                        size_t vl);
vuint8mf4_t __riscv_vor(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vor(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                        size_t vl);
vuint8mf2_t __riscv_vor(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vor(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vor(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vor(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vor(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vor(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vor(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vor(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vor(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vor(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                         size_t vl);
vuint16mf4_t __riscv_vor(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                         size_t vl);
vuint16mf2_t __riscv_vor(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                         size_t vl);
vuint16mf2_t __riscv_vor(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                         size_t vl);
vuint16m1_t __riscv_vor(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                        size_t vl);
vuint16m1_t __riscv_vor(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vor(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                        size_t vl);
vuint16m2_t __riscv_vor(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vor(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                        size_t vl);
vuint16m4_t __riscv_vor(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vor(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                        size_t vl);
vuint16m8_t __riscv_vor(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vor(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                         size_t vl);
vuint32mf2_t __riscv_vor(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m1_t __riscv_vor(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                        size_t vl);
vuint32m1_t __riscv_vor(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vor(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                        size_t vl);
vuint32m2_t __riscv_vor(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vor(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                        size_t vl);
vuint32m4_t __riscv_vor(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vor(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                        size_t vl);
vuint32m8_t __riscv_vor(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vor(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                        size_t vl);
vuint64m1_t __riscv_vor(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vor(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                        size_t vl);
vuint64m2_t __riscv_vor(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vor(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                        size_t vl);
vuint64m4_t __riscv_vor(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vor(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                        size_t vl);
vuint64m8_t __riscv_vor(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vxor(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vuint8mf8_t __riscv_vxor(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vxor(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vuint8mf4_t __riscv_vxor(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vxor(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vuint8mf2_t __riscv_vxor(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vxor(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vxor(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vxor(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vxor(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vxor(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vxor(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vxor(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vxor(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vxor(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                          size_t vl);
vuint16mf4_t __riscv_vxor(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                          size_t vl);
vuint16mf2_t __riscv_vxor(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                          size_t vl);
vuint16mf2_t __riscv_vxor(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m1_t __riscv_vxor(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vuint16m1_t __riscv_vxor(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                         size_t vl);
vuint16m2_t __riscv_vxor(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                         size_t vl);
vuint16m2_t __riscv_vxor(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vxor(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                         size_t vl);
vuint16m4_t __riscv_vxor(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vxor(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                         size_t vl);
vuint16m8_t __riscv_vxor(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vxor(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                          size_t vl);
vuint32mf2_t __riscv_vxor(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m1_t __riscv_vxor(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vuint32m1_t __riscv_vxor(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m2_t __riscv_vxor(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vuint32m2_t __riscv_vxor(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m4_t __riscv_vxor(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                         size_t vl);
vuint32m4_t __riscv_vxor(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vxor(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                         size_t vl);
vuint32m8_t __riscv_vxor(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vxor(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vuint64m1_t __riscv_vxor(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m2_t __riscv_vxor(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vuint64m2_t __riscv_vxor(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m4_t __riscv_vxor(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vuint64m4_t __riscv_vxor(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m8_t __riscv_vxor(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                         size_t vl);
vuint64m8_t __riscv_vxor(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
----

[[overloaded-vector-bitwise-unary-logical]]
==== Vector Bitwise Unary Logical Intrinsics

[,c]
----
vint8mf8_t __riscv_vnot(vint8mf8_t vs, size_t vl);
vint8mf4_t __riscv_vnot(vint8mf4_t vs, size_t vl);
vint8mf2_t __riscv_vnot(vint8mf2_t vs, size_t vl);
vint8m1_t __riscv_vnot(vint8m1_t vs, size_t vl);
vint8m2_t __riscv_vnot(vint8m2_t vs, size_t vl);
vint8m4_t __riscv_vnot(vint8m4_t vs, size_t vl);
vint8m8_t __riscv_vnot(vint8m8_t vs, size_t vl);
vint16mf4_t __riscv_vnot(vint16mf4_t vs, size_t vl);
vint16mf2_t __riscv_vnot(vint16mf2_t vs, size_t vl);
vint16m1_t __riscv_vnot(vint16m1_t vs, size_t vl);
vint16m2_t __riscv_vnot(vint16m2_t vs, size_t vl);
vint16m4_t __riscv_vnot(vint16m4_t vs, size_t vl);
vint16m8_t __riscv_vnot(vint16m8_t vs, size_t vl);
vint32mf2_t __riscv_vnot(vint32mf2_t vs, size_t vl);
vint32m1_t __riscv_vnot(vint32m1_t vs, size_t vl);
vint32m2_t __riscv_vnot(vint32m2_t vs, size_t vl);
vint32m4_t __riscv_vnot(vint32m4_t vs, size_t vl);
vint32m8_t __riscv_vnot(vint32m8_t vs, size_t vl);
vint64m1_t __riscv_vnot(vint64m1_t vs, size_t vl);
vint64m2_t __riscv_vnot(vint64m2_t vs, size_t vl);
vint64m4_t __riscv_vnot(vint64m4_t vs, size_t vl);
vint64m8_t __riscv_vnot(vint64m8_t vs, size_t vl);
vuint8mf8_t __riscv_vnot(vuint8mf8_t vs, size_t vl);
vuint8mf4_t __riscv_vnot(vuint8mf4_t vs, size_t vl);
vuint8mf2_t __riscv_vnot(vuint8mf2_t vs, size_t vl);
vuint8m1_t __riscv_vnot(vuint8m1_t vs, size_t vl);
vuint8m2_t __riscv_vnot(vuint8m2_t vs, size_t vl);
vuint8m4_t __riscv_vnot(vuint8m4_t vs, size_t vl);
vuint8m8_t __riscv_vnot(vuint8m8_t vs, size_t vl);
vuint16mf4_t __riscv_vnot(vuint16mf4_t vs, size_t vl);
vuint16mf2_t __riscv_vnot(vuint16mf2_t vs, size_t vl);
vuint16m1_t __riscv_vnot(vuint16m1_t vs, size_t vl);
vuint16m2_t __riscv_vnot(vuint16m2_t vs, size_t vl);
vuint16m4_t __riscv_vnot(vuint16m4_t vs, size_t vl);
vuint16m8_t __riscv_vnot(vuint16m8_t vs, size_t vl);
vuint32mf2_t __riscv_vnot(vuint32mf2_t vs, size_t vl);
vuint32m1_t __riscv_vnot(vuint32m1_t vs, size_t vl);
vuint32m2_t __riscv_vnot(vuint32m2_t vs, size_t vl);
vuint32m4_t __riscv_vnot(vuint32m4_t vs, size_t vl);
vuint32m8_t __riscv_vnot(vuint32m8_t vs, size_t vl);
vuint64m1_t __riscv_vnot(vuint64m1_t vs, size_t vl);
vuint64m2_t __riscv_vnot(vuint64m2_t vs, size_t vl);
vuint64m4_t __riscv_vnot(vuint64m4_t vs, size_t vl);
vuint64m8_t __riscv_vnot(vuint64m8_t vs, size_t vl);
// masked functions
vint8mf8_t __riscv_vnot(vbool64_t vm, vint8mf8_t vs, size_t vl);
vint8mf4_t __riscv_vnot(vbool32_t vm, vint8mf4_t vs, size_t vl);
vint8mf2_t __riscv_vnot(vbool16_t vm, vint8mf2_t vs, size_t vl);
vint8m1_t __riscv_vnot(vbool8_t vm, vint8m1_t vs, size_t vl);
vint8m2_t __riscv_vnot(vbool4_t vm, vint8m2_t vs, size_t vl);
vint8m4_t __riscv_vnot(vbool2_t vm, vint8m4_t vs, size_t vl);
vint8m8_t __riscv_vnot(vbool1_t vm, vint8m8_t vs, size_t vl);
vint16mf4_t __riscv_vnot(vbool64_t vm, vint16mf4_t vs, size_t vl);
vint16mf2_t __riscv_vnot(vbool32_t vm, vint16mf2_t vs, size_t vl);
vint16m1_t __riscv_vnot(vbool16_t vm, vint16m1_t vs, size_t vl);
vint16m2_t __riscv_vnot(vbool8_t vm, vint16m2_t vs, size_t vl);
vint16m4_t __riscv_vnot(vbool4_t vm, vint16m4_t vs, size_t vl);
vint16m8_t __riscv_vnot(vbool2_t vm, vint16m8_t vs, size_t vl);
vint32mf2_t __riscv_vnot(vbool64_t vm, vint32mf2_t vs, size_t vl);
vint32m1_t __riscv_vnot(vbool32_t vm, vint32m1_t vs, size_t vl);
vint32m2_t __riscv_vnot(vbool16_t vm, vint32m2_t vs, size_t vl);
vint32m4_t __riscv_vnot(vbool8_t vm, vint32m4_t vs, size_t vl);
vint32m8_t __riscv_vnot(vbool4_t vm, vint32m8_t vs, size_t vl);
vint64m1_t __riscv_vnot(vbool64_t vm, vint64m1_t vs, size_t vl);
vint64m2_t __riscv_vnot(vbool32_t vm, vint64m2_t vs, size_t vl);
vint64m4_t __riscv_vnot(vbool16_t vm, vint64m4_t vs, size_t vl);
vint64m8_t __riscv_vnot(vbool8_t vm, vint64m8_t vs, size_t vl);
vuint8mf8_t __riscv_vnot(vbool64_t vm, vuint8mf8_t vs, size_t vl);
vuint8mf4_t __riscv_vnot(vbool32_t vm, vuint8mf4_t vs, size_t vl);
vuint8mf2_t __riscv_vnot(vbool16_t vm, vuint8mf2_t vs, size_t vl);
vuint8m1_t __riscv_vnot(vbool8_t vm, vuint8m1_t vs, size_t vl);
vuint8m2_t __riscv_vnot(vbool4_t vm, vuint8m2_t vs, size_t vl);
vuint8m4_t __riscv_vnot(vbool2_t vm, vuint8m4_t vs, size_t vl);
vuint8m8_t __riscv_vnot(vbool1_t vm, vuint8m8_t vs, size_t vl);
vuint16mf4_t __riscv_vnot(vbool64_t vm, vuint16mf4_t vs, size_t vl);
vuint16mf2_t __riscv_vnot(vbool32_t vm, vuint16mf2_t vs, size_t vl);
vuint16m1_t __riscv_vnot(vbool16_t vm, vuint16m1_t vs, size_t vl);
vuint16m2_t __riscv_vnot(vbool8_t vm, vuint16m2_t vs, size_t vl);
vuint16m4_t __riscv_vnot(vbool4_t vm, vuint16m4_t vs, size_t vl);
vuint16m8_t __riscv_vnot(vbool2_t vm, vuint16m8_t vs, size_t vl);
vuint32mf2_t __riscv_vnot(vbool64_t vm, vuint32mf2_t vs, size_t vl);
vuint32m1_t __riscv_vnot(vbool32_t vm, vuint32m1_t vs, size_t vl);
vuint32m2_t __riscv_vnot(vbool16_t vm, vuint32m2_t vs, size_t vl);
vuint32m4_t __riscv_vnot(vbool8_t vm, vuint32m4_t vs, size_t vl);
vuint32m8_t __riscv_vnot(vbool4_t vm, vuint32m8_t vs, size_t vl);
vuint64m1_t __riscv_vnot(vbool64_t vm, vuint64m1_t vs, size_t vl);
vuint64m2_t __riscv_vnot(vbool32_t vm, vuint64m2_t vs, size_t vl);
vuint64m4_t __riscv_vnot(vbool16_t vm, vuint64m4_t vs, size_t vl);
vuint64m8_t __riscv_vnot(vbool8_t vm, vuint64m8_t vs, size_t vl);
----

[[overloaded-vector-single-width-bit-shift]]
==== Vector Single-Width Bit Shift Intrinsics

[,c]
----
vint8mf8_t __riscv_vsll(vint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vsll(vint8mf8_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vsll(vint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vsll(vint8mf4_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vsll(vint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vsll(vint8mf2_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vsll(vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vsll(vint8m1_t vs2, size_t rs1, size_t vl);
vint8m2_t __riscv_vsll(vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vsll(vint8m2_t vs2, size_t rs1, size_t vl);
vint8m4_t __riscv_vsll(vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vsll(vint8m4_t vs2, size_t rs1, size_t vl);
vint8m8_t __riscv_vsll(vint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vsll(vint8m8_t vs2, size_t rs1, size_t vl);
vint16mf4_t __riscv_vsll(vint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vsll(vint16mf4_t vs2, size_t rs1, size_t vl);
vint16mf2_t __riscv_vsll(vint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vsll(vint16mf2_t vs2, size_t rs1, size_t vl);
vint16m1_t __riscv_vsll(vint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vsll(vint16m1_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vsll(vint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vsll(vint16m2_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vsll(vint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vsll(vint16m4_t vs2, size_t rs1, size_t vl);
vint16m8_t __riscv_vsll(vint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vsll(vint16m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vsll(vint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vsll(vint32mf2_t vs2, size_t rs1, size_t vl);
vint32m1_t __riscv_vsll(vint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vsll(vint32m1_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vsll(vint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vsll(vint32m2_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vsll(vint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vsll(vint32m4_t vs2, size_t rs1, size_t vl);
vint32m8_t __riscv_vsll(vint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vsll(vint32m8_t vs2, size_t rs1, size_t vl);
vint64m1_t __riscv_vsll(vint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vsll(vint64m1_t vs2, size_t rs1, size_t vl);
vint64m2_t __riscv_vsll(vint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vsll(vint64m2_t vs2, size_t rs1, size_t vl);
vint64m4_t __riscv_vsll(vint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vsll(vint64m4_t vs2, size_t rs1, size_t vl);
vint64m8_t __riscv_vsll(vint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vsll(vint64m8_t vs2, size_t rs1, size_t vl);
vint8mf8_t __riscv_vsra(vint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vsra(vint8mf8_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vsra(vint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vsra(vint8mf4_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vsra(vint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vsra(vint8mf2_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vsra(vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vsra(vint8m1_t vs2, size_t rs1, size_t vl);
vint8m2_t __riscv_vsra(vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vsra(vint8m2_t vs2, size_t rs1, size_t vl);
vint8m4_t __riscv_vsra(vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vsra(vint8m4_t vs2, size_t rs1, size_t vl);
vint8m8_t __riscv_vsra(vint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vsra(vint8m8_t vs2, size_t rs1, size_t vl);
vint16mf4_t __riscv_vsra(vint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vsra(vint16mf4_t vs2, size_t rs1, size_t vl);
vint16mf2_t __riscv_vsra(vint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vsra(vint16mf2_t vs2, size_t rs1, size_t vl);
vint16m1_t __riscv_vsra(vint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vsra(vint16m1_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vsra(vint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vsra(vint16m2_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vsra(vint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vsra(vint16m4_t vs2, size_t rs1, size_t vl);
vint16m8_t __riscv_vsra(vint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vsra(vint16m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vsra(vint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vsra(vint32mf2_t vs2, size_t rs1, size_t vl);
vint32m1_t __riscv_vsra(vint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vsra(vint32m1_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vsra(vint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vsra(vint32m2_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vsra(vint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vsra(vint32m4_t vs2, size_t rs1, size_t vl);
vint32m8_t __riscv_vsra(vint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vsra(vint32m8_t vs2, size_t rs1, size_t vl);
vint64m1_t __riscv_vsra(vint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vsra(vint64m1_t vs2, size_t rs1, size_t vl);
vint64m2_t __riscv_vsra(vint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vsra(vint64m2_t vs2, size_t rs1, size_t vl);
vint64m4_t __riscv_vsra(vint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vsra(vint64m4_t vs2, size_t rs1, size_t vl);
vint64m8_t __riscv_vsra(vint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vsra(vint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vsll(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vsll(vuint8mf8_t vs2, size_t rs1, size_t vl);
vuint8mf4_t __riscv_vsll(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vsll(vuint8mf4_t vs2, size_t rs1, size_t vl);
vuint8mf2_t __riscv_vsll(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vsll(vuint8mf2_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vsll(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vsll(vuint8m1_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vsll(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vsll(vuint8m2_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vsll(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vsll(vuint8m4_t vs2, size_t rs1, size_t vl);
vuint8m8_t __riscv_vsll(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vsll(vuint8m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vsll(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vsll(vuint16mf4_t vs2, size_t rs1, size_t vl);
vuint16mf2_t __riscv_vsll(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vsll(vuint16mf2_t vs2, size_t rs1, size_t vl);
vuint16m1_t __riscv_vsll(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vsll(vuint16m1_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vsll(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vsll(vuint16m2_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vsll(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vsll(vuint16m4_t vs2, size_t rs1, size_t vl);
vuint16m8_t __riscv_vsll(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vsll(vuint16m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vsll(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vsll(vuint32mf2_t vs2, size_t rs1, size_t vl);
vuint32m1_t __riscv_vsll(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vsll(vuint32m1_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vsll(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vsll(vuint32m2_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vsll(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vsll(vuint32m4_t vs2, size_t rs1, size_t vl);
vuint32m8_t __riscv_vsll(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vsll(vuint32m8_t vs2, size_t rs1, size_t vl);
vuint64m1_t __riscv_vsll(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vsll(vuint64m1_t vs2, size_t rs1, size_t vl);
vuint64m2_t __riscv_vsll(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vsll(vuint64m2_t vs2, size_t rs1, size_t vl);
vuint64m4_t __riscv_vsll(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vsll(vuint64m4_t vs2, size_t rs1, size_t vl);
vuint64m8_t __riscv_vsll(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vsll(vuint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vsrl(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vsrl(vuint8mf8_t vs2, size_t rs1, size_t vl);
vuint8mf4_t __riscv_vsrl(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vsrl(vuint8mf4_t vs2, size_t rs1, size_t vl);
vuint8mf2_t __riscv_vsrl(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vsrl(vuint8mf2_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vsrl(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vsrl(vuint8m1_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vsrl(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vsrl(vuint8m2_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vsrl(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vsrl(vuint8m4_t vs2, size_t rs1, size_t vl);
vuint8m8_t __riscv_vsrl(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vsrl(vuint8m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vsrl(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vsrl(vuint16mf4_t vs2, size_t rs1, size_t vl);
vuint16mf2_t __riscv_vsrl(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vsrl(vuint16mf2_t vs2, size_t rs1, size_t vl);
vuint16m1_t __riscv_vsrl(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vsrl(vuint16m1_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vsrl(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vsrl(vuint16m2_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vsrl(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vsrl(vuint16m4_t vs2, size_t rs1, size_t vl);
vuint16m8_t __riscv_vsrl(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vsrl(vuint16m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vsrl(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vsrl(vuint32mf2_t vs2, size_t rs1, size_t vl);
vuint32m1_t __riscv_vsrl(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vsrl(vuint32m1_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vsrl(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vsrl(vuint32m2_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vsrl(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vsrl(vuint32m4_t vs2, size_t rs1, size_t vl);
vuint32m8_t __riscv_vsrl(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vsrl(vuint32m8_t vs2, size_t rs1, size_t vl);
vuint64m1_t __riscv_vsrl(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vsrl(vuint64m1_t vs2, size_t rs1, size_t vl);
vuint64m2_t __riscv_vsrl(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vsrl(vuint64m2_t vs2, size_t rs1, size_t vl);
vuint64m4_t __riscv_vsrl(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vsrl(vuint64m4_t vs2, size_t rs1, size_t vl);
vuint64m8_t __riscv_vsrl(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vsrl(vuint64m8_t vs2, size_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vsll(vbool64_t vm, vint8mf8_t vs2, vuint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vsll(vbool64_t vm, vint8mf8_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vsll(vbool32_t vm, vint8mf4_t vs2, vuint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vsll(vbool32_t vm, vint8mf4_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vsll(vbool16_t vm, vint8mf2_t vs2, vuint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vsll(vbool16_t vm, vint8mf2_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vsll(vbool8_t vm, vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vsll(vbool8_t vm, vint8m1_t vs2, size_t rs1, size_t vl);
vint8m2_t __riscv_vsll(vbool4_t vm, vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vsll(vbool4_t vm, vint8m2_t vs2, size_t rs1, size_t vl);
vint8m4_t __riscv_vsll(vbool2_t vm, vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vsll(vbool2_t vm, vint8m4_t vs2, size_t rs1, size_t vl);
vint8m8_t __riscv_vsll(vbool1_t vm, vint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vsll(vbool1_t vm, vint8m8_t vs2, size_t rs1, size_t vl);
vint16mf4_t __riscv_vsll(vbool64_t vm, vint16mf4_t vs2, vuint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vsll(vbool64_t vm, vint16mf4_t vs2, size_t rs1, size_t vl);
vint16mf2_t __riscv_vsll(vbool32_t vm, vint16mf2_t vs2, vuint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vsll(vbool32_t vm, vint16mf2_t vs2, size_t rs1, size_t vl);
vint16m1_t __riscv_vsll(vbool16_t vm, vint16m1_t vs2, vuint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vsll(vbool16_t vm, vint16m1_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vsll(vbool8_t vm, vint16m2_t vs2, vuint16m2_t vs1,
                        size_t vl);
vint16m2_t __riscv_vsll(vbool8_t vm, vint16m2_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vsll(vbool4_t vm, vint16m4_t vs2, vuint16m4_t vs1,
                        size_t vl);
vint16m4_t __riscv_vsll(vbool4_t vm, vint16m4_t vs2, size_t rs1, size_t vl);
vint16m8_t __riscv_vsll(vbool2_t vm, vint16m8_t vs2, vuint16m8_t vs1,
                        size_t vl);
vint16m8_t __riscv_vsll(vbool2_t vm, vint16m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vsll(vbool64_t vm, vint32mf2_t vs2, vuint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vsll(vbool64_t vm, vint32mf2_t vs2, size_t rs1, size_t vl);
vint32m1_t __riscv_vsll(vbool32_t vm, vint32m1_t vs2, vuint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vsll(vbool32_t vm, vint32m1_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vsll(vbool16_t vm, vint32m2_t vs2, vuint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vsll(vbool16_t vm, vint32m2_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vsll(vbool8_t vm, vint32m4_t vs2, vuint32m4_t vs1,
                        size_t vl);
vint32m4_t __riscv_vsll(vbool8_t vm, vint32m4_t vs2, size_t rs1, size_t vl);
vint32m8_t __riscv_vsll(vbool4_t vm, vint32m8_t vs2, vuint32m8_t vs1,
                        size_t vl);
vint32m8_t __riscv_vsll(vbool4_t vm, vint32m8_t vs2, size_t rs1, size_t vl);
vint64m1_t __riscv_vsll(vbool64_t vm, vint64m1_t vs2, vuint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vsll(vbool64_t vm, vint64m1_t vs2, size_t rs1, size_t vl);
vint64m2_t __riscv_vsll(vbool32_t vm, vint64m2_t vs2, vuint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vsll(vbool32_t vm, vint64m2_t vs2, size_t rs1, size_t vl);
vint64m4_t __riscv_vsll(vbool16_t vm, vint64m4_t vs2, vuint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vsll(vbool16_t vm, vint64m4_t vs2, size_t rs1, size_t vl);
vint64m8_t __riscv_vsll(vbool8_t vm, vint64m8_t vs2, vuint64m8_t vs1,
                        size_t vl);
vint64m8_t __riscv_vsll(vbool8_t vm, vint64m8_t vs2, size_t rs1, size_t vl);
vint8mf8_t __riscv_vsra(vbool64_t vm, vint8mf8_t vs2, vuint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vsra(vbool64_t vm, vint8mf8_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vsra(vbool32_t vm, vint8mf4_t vs2, vuint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vsra(vbool32_t vm, vint8mf4_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vsra(vbool16_t vm, vint8mf2_t vs2, vuint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vsra(vbool16_t vm, vint8mf2_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vsra(vbool8_t vm, vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vsra(vbool8_t vm, vint8m1_t vs2, size_t rs1, size_t vl);
vint8m2_t __riscv_vsra(vbool4_t vm, vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vsra(vbool4_t vm, vint8m2_t vs2, size_t rs1, size_t vl);
vint8m4_t __riscv_vsra(vbool2_t vm, vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vsra(vbool2_t vm, vint8m4_t vs2, size_t rs1, size_t vl);
vint8m8_t __riscv_vsra(vbool1_t vm, vint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vsra(vbool1_t vm, vint8m8_t vs2, size_t rs1, size_t vl);
vint16mf4_t __riscv_vsra(vbool64_t vm, vint16mf4_t vs2, vuint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vsra(vbool64_t vm, vint16mf4_t vs2, size_t rs1, size_t vl);
vint16mf2_t __riscv_vsra(vbool32_t vm, vint16mf2_t vs2, vuint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vsra(vbool32_t vm, vint16mf2_t vs2, size_t rs1, size_t vl);
vint16m1_t __riscv_vsra(vbool16_t vm, vint16m1_t vs2, vuint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vsra(vbool16_t vm, vint16m1_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vsra(vbool8_t vm, vint16m2_t vs2, vuint16m2_t vs1,
                        size_t vl);
vint16m2_t __riscv_vsra(vbool8_t vm, vint16m2_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vsra(vbool4_t vm, vint16m4_t vs2, vuint16m4_t vs1,
                        size_t vl);
vint16m4_t __riscv_vsra(vbool4_t vm, vint16m4_t vs2, size_t rs1, size_t vl);
vint16m8_t __riscv_vsra(vbool2_t vm, vint16m8_t vs2, vuint16m8_t vs1,
                        size_t vl);
vint16m8_t __riscv_vsra(vbool2_t vm, vint16m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vsra(vbool64_t vm, vint32mf2_t vs2, vuint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vsra(vbool64_t vm, vint32mf2_t vs2, size_t rs1, size_t vl);
vint32m1_t __riscv_vsra(vbool32_t vm, vint32m1_t vs2, vuint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vsra(vbool32_t vm, vint32m1_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vsra(vbool16_t vm, vint32m2_t vs2, vuint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vsra(vbool16_t vm, vint32m2_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vsra(vbool8_t vm, vint32m4_t vs2, vuint32m4_t vs1,
                        size_t vl);
vint32m4_t __riscv_vsra(vbool8_t vm, vint32m4_t vs2, size_t rs1, size_t vl);
vint32m8_t __riscv_vsra(vbool4_t vm, vint32m8_t vs2, vuint32m8_t vs1,
                        size_t vl);
vint32m8_t __riscv_vsra(vbool4_t vm, vint32m8_t vs2, size_t rs1, size_t vl);
vint64m1_t __riscv_vsra(vbool64_t vm, vint64m1_t vs2, vuint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vsra(vbool64_t vm, vint64m1_t vs2, size_t rs1, size_t vl);
vint64m2_t __riscv_vsra(vbool32_t vm, vint64m2_t vs2, vuint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vsra(vbool32_t vm, vint64m2_t vs2, size_t rs1, size_t vl);
vint64m4_t __riscv_vsra(vbool16_t vm, vint64m4_t vs2, vuint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vsra(vbool16_t vm, vint64m4_t vs2, size_t rs1, size_t vl);
vint64m8_t __riscv_vsra(vbool8_t vm, vint64m8_t vs2, vuint64m8_t vs1,
                        size_t vl);
vint64m8_t __riscv_vsra(vbool8_t vm, vint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vsll(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vuint8mf8_t __riscv_vsll(vbool64_t vm, vuint8mf8_t vs2, size_t rs1, size_t vl);
vuint8mf4_t __riscv_vsll(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vuint8mf4_t __riscv_vsll(vbool32_t vm, vuint8mf4_t vs2, size_t rs1, size_t vl);
vuint8mf2_t __riscv_vsll(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vuint8mf2_t __riscv_vsll(vbool16_t vm, vuint8mf2_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vsll(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vsll(vbool8_t vm, vuint8m1_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vsll(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vsll(vbool4_t vm, vuint8m2_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vsll(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vsll(vbool2_t vm, vuint8m4_t vs2, size_t rs1, size_t vl);
vuint8m8_t __riscv_vsll(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vsll(vbool1_t vm, vuint8m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vsll(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                          size_t vl);
vuint16mf4_t __riscv_vsll(vbool64_t vm, vuint16mf4_t vs2, size_t rs1,
                          size_t vl);
vuint16mf2_t __riscv_vsll(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                          size_t vl);
vuint16mf2_t __riscv_vsll(vbool32_t vm, vuint16mf2_t vs2, size_t rs1,
                          size_t vl);
vuint16m1_t __riscv_vsll(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vuint16m1_t __riscv_vsll(vbool16_t vm, vuint16m1_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vsll(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                         size_t vl);
vuint16m2_t __riscv_vsll(vbool8_t vm, vuint16m2_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vsll(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                         size_t vl);
vuint16m4_t __riscv_vsll(vbool4_t vm, vuint16m4_t vs2, size_t rs1, size_t vl);
vuint16m8_t __riscv_vsll(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                         size_t vl);
vuint16m8_t __riscv_vsll(vbool2_t vm, vuint16m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vsll(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                          size_t vl);
vuint32mf2_t __riscv_vsll(vbool64_t vm, vuint32mf2_t vs2, size_t rs1,
                          size_t vl);
vuint32m1_t __riscv_vsll(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vuint32m1_t __riscv_vsll(vbool32_t vm, vuint32m1_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vsll(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vuint32m2_t __riscv_vsll(vbool16_t vm, vuint32m2_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vsll(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                         size_t vl);
vuint32m4_t __riscv_vsll(vbool8_t vm, vuint32m4_t vs2, size_t rs1, size_t vl);
vuint32m8_t __riscv_vsll(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                         size_t vl);
vuint32m8_t __riscv_vsll(vbool4_t vm, vuint32m8_t vs2, size_t rs1, size_t vl);
vuint64m1_t __riscv_vsll(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vuint64m1_t __riscv_vsll(vbool64_t vm, vuint64m1_t vs2, size_t rs1, size_t vl);
vuint64m2_t __riscv_vsll(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vuint64m2_t __riscv_vsll(vbool32_t vm, vuint64m2_t vs2, size_t rs1, size_t vl);
vuint64m4_t __riscv_vsll(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vuint64m4_t __riscv_vsll(vbool16_t vm, vuint64m4_t vs2, size_t rs1, size_t vl);
vuint64m8_t __riscv_vsll(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                         size_t vl);
vuint64m8_t __riscv_vsll(vbool8_t vm, vuint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vsrl(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vuint8mf8_t __riscv_vsrl(vbool64_t vm, vuint8mf8_t vs2, size_t rs1, size_t vl);
vuint8mf4_t __riscv_vsrl(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vuint8mf4_t __riscv_vsrl(vbool32_t vm, vuint8mf4_t vs2, size_t rs1, size_t vl);
vuint8mf2_t __riscv_vsrl(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vuint8mf2_t __riscv_vsrl(vbool16_t vm, vuint8mf2_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vsrl(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vsrl(vbool8_t vm, vuint8m1_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vsrl(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vsrl(vbool4_t vm, vuint8m2_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vsrl(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vsrl(vbool2_t vm, vuint8m4_t vs2, size_t rs1, size_t vl);
vuint8m8_t __riscv_vsrl(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vsrl(vbool1_t vm, vuint8m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vsrl(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                          size_t vl);
vuint16mf4_t __riscv_vsrl(vbool64_t vm, vuint16mf4_t vs2, size_t rs1,
                          size_t vl);
vuint16mf2_t __riscv_vsrl(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                          size_t vl);
vuint16mf2_t __riscv_vsrl(vbool32_t vm, vuint16mf2_t vs2, size_t rs1,
                          size_t vl);
vuint16m1_t __riscv_vsrl(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vuint16m1_t __riscv_vsrl(vbool16_t vm, vuint16m1_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vsrl(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                         size_t vl);
vuint16m2_t __riscv_vsrl(vbool8_t vm, vuint16m2_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vsrl(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                         size_t vl);
vuint16m4_t __riscv_vsrl(vbool4_t vm, vuint16m4_t vs2, size_t rs1, size_t vl);
vuint16m8_t __riscv_vsrl(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                         size_t vl);
vuint16m8_t __riscv_vsrl(vbool2_t vm, vuint16m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vsrl(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                          size_t vl);
vuint32mf2_t __riscv_vsrl(vbool64_t vm, vuint32mf2_t vs2, size_t rs1,
                          size_t vl);
vuint32m1_t __riscv_vsrl(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vuint32m1_t __riscv_vsrl(vbool32_t vm, vuint32m1_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vsrl(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vuint32m2_t __riscv_vsrl(vbool16_t vm, vuint32m2_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vsrl(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                         size_t vl);
vuint32m4_t __riscv_vsrl(vbool8_t vm, vuint32m4_t vs2, size_t rs1, size_t vl);
vuint32m8_t __riscv_vsrl(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                         size_t vl);
vuint32m8_t __riscv_vsrl(vbool4_t vm, vuint32m8_t vs2, size_t rs1, size_t vl);
vuint64m1_t __riscv_vsrl(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vuint64m1_t __riscv_vsrl(vbool64_t vm, vuint64m1_t vs2, size_t rs1, size_t vl);
vuint64m2_t __riscv_vsrl(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vuint64m2_t __riscv_vsrl(vbool32_t vm, vuint64m2_t vs2, size_t rs1, size_t vl);
vuint64m4_t __riscv_vsrl(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vuint64m4_t __riscv_vsrl(vbool16_t vm, vuint64m4_t vs2, size_t rs1, size_t vl);
vuint64m8_t __riscv_vsrl(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                         size_t vl);
vuint64m8_t __riscv_vsrl(vbool8_t vm, vuint64m8_t vs2, size_t rs1, size_t vl);
----

[[overloaded-vector-narrowing-integer-right-shift]]
==== Vector Narrowing Integer Right Shift Intrinsics

[,c]
----
vint8mf8_t __riscv_vnsra(vint16mf4_t vs2, vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vnsra(vint16mf4_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vnsra(vint16mf2_t vs2, vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vnsra(vint16mf2_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vnsra(vint16m1_t vs2, vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vnsra(vint16m1_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vnsra(vint16m2_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vnsra(vint16m2_t vs2, size_t rs1, size_t vl);
vint8m2_t __riscv_vnsra(vint16m4_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vnsra(vint16m4_t vs2, size_t rs1, size_t vl);
vint8m4_t __riscv_vnsra(vint16m8_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vnsra(vint16m8_t vs2, size_t rs1, size_t vl);
vint16mf4_t __riscv_vnsra(vint32mf2_t vs2, vuint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vnsra(vint32mf2_t vs2, size_t rs1, size_t vl);
vint16mf2_t __riscv_vnsra(vint32m1_t vs2, vuint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vnsra(vint32m1_t vs2, size_t rs1, size_t vl);
vint16m1_t __riscv_vnsra(vint32m2_t vs2, vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vnsra(vint32m2_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vnsra(vint32m4_t vs2, vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vnsra(vint32m4_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vnsra(vint32m8_t vs2, vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vnsra(vint32m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vnsra(vint64m1_t vs2, vuint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vnsra(vint64m1_t vs2, size_t rs1, size_t vl);
vint32m1_t __riscv_vnsra(vint64m2_t vs2, vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vnsra(vint64m2_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vnsra(vint64m4_t vs2, vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vnsra(vint64m4_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vnsra(vint64m8_t vs2, vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vnsra(vint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vnsrl(vuint16mf4_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vnsrl(vuint16mf4_t vs2, size_t rs1, size_t vl);
vuint8mf4_t __riscv_vnsrl(vuint16mf2_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vnsrl(vuint16mf2_t vs2, size_t rs1, size_t vl);
vuint8mf2_t __riscv_vnsrl(vuint16m1_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vnsrl(vuint16m1_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vnsrl(vuint16m2_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vnsrl(vuint16m2_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vnsrl(vuint16m4_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vnsrl(vuint16m4_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vnsrl(vuint16m8_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vnsrl(vuint16m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vnsrl(vuint32mf2_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vnsrl(vuint32mf2_t vs2, size_t rs1, size_t vl);
vuint16mf2_t __riscv_vnsrl(vuint32m1_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vnsrl(vuint32m1_t vs2, size_t rs1, size_t vl);
vuint16m1_t __riscv_vnsrl(vuint32m2_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vnsrl(vuint32m2_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vnsrl(vuint32m4_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vnsrl(vuint32m4_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vnsrl(vuint32m8_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vnsrl(vuint32m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vnsrl(vuint64m1_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vnsrl(vuint64m1_t vs2, size_t rs1, size_t vl);
vuint32m1_t __riscv_vnsrl(vuint64m2_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vnsrl(vuint64m2_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vnsrl(vuint64m4_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vnsrl(vuint64m4_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vnsrl(vuint64m8_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vnsrl(vuint64m8_t vs2, size_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vnsra(vbool64_t vm, vint16mf4_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vint8mf8_t __riscv_vnsra(vbool64_t vm, vint16mf4_t vs2, size_t rs1, size_t vl);
vint8mf4_t __riscv_vnsra(vbool32_t vm, vint16mf2_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vint8mf4_t __riscv_vnsra(vbool32_t vm, vint16mf2_t vs2, size_t rs1, size_t vl);
vint8mf2_t __riscv_vnsra(vbool16_t vm, vint16m1_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vint8mf2_t __riscv_vnsra(vbool16_t vm, vint16m1_t vs2, size_t rs1, size_t vl);
vint8m1_t __riscv_vnsra(vbool8_t vm, vint16m2_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vnsra(vbool8_t vm, vint16m2_t vs2, size_t rs1, size_t vl);
vint8m2_t __riscv_vnsra(vbool4_t vm, vint16m4_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vnsra(vbool4_t vm, vint16m4_t vs2, size_t rs1, size_t vl);
vint8m4_t __riscv_vnsra(vbool2_t vm, vint16m8_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vnsra(vbool2_t vm, vint16m8_t vs2, size_t rs1, size_t vl);
vint16mf4_t __riscv_vnsra(vbool64_t vm, vint32mf2_t vs2, vuint16mf4_t vs1,
                          size_t vl);
vint16mf4_t __riscv_vnsra(vbool64_t vm, vint32mf2_t vs2, size_t rs1, size_t vl);
vint16mf2_t __riscv_vnsra(vbool32_t vm, vint32m1_t vs2, vuint16mf2_t vs1,
                          size_t vl);
vint16mf2_t __riscv_vnsra(vbool32_t vm, vint32m1_t vs2, size_t rs1, size_t vl);
vint16m1_t __riscv_vnsra(vbool16_t vm, vint32m2_t vs2, vuint16m1_t vs1,
                         size_t vl);
vint16m1_t __riscv_vnsra(vbool16_t vm, vint32m2_t vs2, size_t rs1, size_t vl);
vint16m2_t __riscv_vnsra(vbool8_t vm, vint32m4_t vs2, vuint16m2_t vs1,
                         size_t vl);
vint16m2_t __riscv_vnsra(vbool8_t vm, vint32m4_t vs2, size_t rs1, size_t vl);
vint16m4_t __riscv_vnsra(vbool4_t vm, vint32m8_t vs2, vuint16m4_t vs1,
                         size_t vl);
vint16m4_t __riscv_vnsra(vbool4_t vm, vint32m8_t vs2, size_t rs1, size_t vl);
vint32mf2_t __riscv_vnsra(vbool64_t vm, vint64m1_t vs2, vuint32mf2_t vs1,
                          size_t vl);
vint32mf2_t __riscv_vnsra(vbool64_t vm, vint64m1_t vs2, size_t rs1, size_t vl);
vint32m1_t __riscv_vnsra(vbool32_t vm, vint64m2_t vs2, vuint32m1_t vs1,
                         size_t vl);
vint32m1_t __riscv_vnsra(vbool32_t vm, vint64m2_t vs2, size_t rs1, size_t vl);
vint32m2_t __riscv_vnsra(vbool16_t vm, vint64m4_t vs2, vuint32m2_t vs1,
                         size_t vl);
vint32m2_t __riscv_vnsra(vbool16_t vm, vint64m4_t vs2, size_t rs1, size_t vl);
vint32m4_t __riscv_vnsra(vbool8_t vm, vint64m8_t vs2, vuint32m4_t vs1,
                         size_t vl);
vint32m4_t __riscv_vnsra(vbool8_t vm, vint64m8_t vs2, size_t rs1, size_t vl);
vuint8mf8_t __riscv_vnsrl(vbool64_t vm, vuint16mf4_t vs2, vuint8mf8_t vs1,
                          size_t vl);
vuint8mf8_t __riscv_vnsrl(vbool64_t vm, vuint16mf4_t vs2, size_t rs1,
                          size_t vl);
vuint8mf4_t __riscv_vnsrl(vbool32_t vm, vuint16mf2_t vs2, vuint8mf4_t vs1,
                          size_t vl);
vuint8mf4_t __riscv_vnsrl(vbool32_t vm, vuint16mf2_t vs2, size_t rs1,
                          size_t vl);
vuint8mf2_t __riscv_vnsrl(vbool16_t vm, vuint16m1_t vs2, vuint8mf2_t vs1,
                          size_t vl);
vuint8mf2_t __riscv_vnsrl(vbool16_t vm, vuint16m1_t vs2, size_t rs1, size_t vl);
vuint8m1_t __riscv_vnsrl(vbool8_t vm, vuint16m2_t vs2, vuint8m1_t vs1,
                         size_t vl);
vuint8m1_t __riscv_vnsrl(vbool8_t vm, vuint16m2_t vs2, size_t rs1, size_t vl);
vuint8m2_t __riscv_vnsrl(vbool4_t vm, vuint16m4_t vs2, vuint8m2_t vs1,
                         size_t vl);
vuint8m2_t __riscv_vnsrl(vbool4_t vm, vuint16m4_t vs2, size_t rs1, size_t vl);
vuint8m4_t __riscv_vnsrl(vbool2_t vm, vuint16m8_t vs2, vuint8m4_t vs1,
                         size_t vl);
vuint8m4_t __riscv_vnsrl(vbool2_t vm, vuint16m8_t vs2, size_t rs1, size_t vl);
vuint16mf4_t __riscv_vnsrl(vbool64_t vm, vuint32mf2_t vs2, vuint16mf4_t vs1,
                           size_t vl);
vuint16mf4_t __riscv_vnsrl(vbool64_t vm, vuint32mf2_t vs2, size_t rs1,
                           size_t vl);
vuint16mf2_t __riscv_vnsrl(vbool32_t vm, vuint32m1_t vs2, vuint16mf2_t vs1,
                           size_t vl);
vuint16mf2_t __riscv_vnsrl(vbool32_t vm, vuint32m1_t vs2, size_t rs1,
                           size_t vl);
vuint16m1_t __riscv_vnsrl(vbool16_t vm, vuint32m2_t vs2, vuint16m1_t vs1,
                          size_t vl);
vuint16m1_t __riscv_vnsrl(vbool16_t vm, vuint32m2_t vs2, size_t rs1, size_t vl);
vuint16m2_t __riscv_vnsrl(vbool8_t vm, vuint32m4_t vs2, vuint16m2_t vs1,
                          size_t vl);
vuint16m2_t __riscv_vnsrl(vbool8_t vm, vuint32m4_t vs2, size_t rs1, size_t vl);
vuint16m4_t __riscv_vnsrl(vbool4_t vm, vuint32m8_t vs2, vuint16m4_t vs1,
                          size_t vl);
vuint16m4_t __riscv_vnsrl(vbool4_t vm, vuint32m8_t vs2, size_t rs1, size_t vl);
vuint32mf2_t __riscv_vnsrl(vbool64_t vm, vuint64m1_t vs2, vuint32mf2_t vs1,
                           size_t vl);
vuint32mf2_t __riscv_vnsrl(vbool64_t vm, vuint64m1_t vs2, size_t rs1,
                           size_t vl);
vuint32m1_t __riscv_vnsrl(vbool32_t vm, vuint64m2_t vs2, vuint32m1_t vs1,
                          size_t vl);
vuint32m1_t __riscv_vnsrl(vbool32_t vm, vuint64m2_t vs2, size_t rs1, size_t vl);
vuint32m2_t __riscv_vnsrl(vbool16_t vm, vuint64m4_t vs2, vuint32m2_t vs1,
                          size_t vl);
vuint32m2_t __riscv_vnsrl(vbool16_t vm, vuint64m4_t vs2, size_t rs1, size_t vl);
vuint32m4_t __riscv_vnsrl(vbool8_t vm, vuint64m8_t vs2, vuint32m4_t vs1,
                          size_t vl);
vuint32m4_t __riscv_vnsrl(vbool8_t vm, vuint64m8_t vs2, size_t rs1, size_t vl);
----

[[overloaded-vector-integer-narrowing]]
==== Vector Integer Narrowing Intrinsics

[,c]
----
vint8mf8_t __riscv_vncvt_x(vint16mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vncvt_x(vint16mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vncvt_x(vint16m1_t vs2, size_t vl);
vint8m1_t __riscv_vncvt_x(vint16m2_t vs2, size_t vl);
vint8m2_t __riscv_vncvt_x(vint16m4_t vs2, size_t vl);
vint8m4_t __riscv_vncvt_x(vint16m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vncvt_x(vuint16mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vncvt_x(vuint16mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vncvt_x(vuint16m1_t vs2, size_t vl);
vuint8m1_t __riscv_vncvt_x(vuint16m2_t vs2, size_t vl);
vuint8m2_t __riscv_vncvt_x(vuint16m4_t vs2, size_t vl);
vuint8m4_t __riscv_vncvt_x(vuint16m8_t vs2, size_t vl);
vint16mf4_t __riscv_vncvt_x(vint32mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vncvt_x(vint32m1_t vs2, size_t vl);
vint16m1_t __riscv_vncvt_x(vint32m2_t vs2, size_t vl);
vint16m2_t __riscv_vncvt_x(vint32m4_t vs2, size_t vl);
vint16m4_t __riscv_vncvt_x(vint32m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vncvt_x(vuint32mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vncvt_x(vuint32m1_t vs2, size_t vl);
vuint16m1_t __riscv_vncvt_x(vuint32m2_t vs2, size_t vl);
vuint16m2_t __riscv_vncvt_x(vuint32m4_t vs2, size_t vl);
vuint16m4_t __riscv_vncvt_x(vuint32m8_t vs2, size_t vl);
vint32mf2_t __riscv_vncvt_x(vint64m1_t vs2, size_t vl);
vint32m1_t __riscv_vncvt_x(vint64m2_t vs2, size_t vl);
vint32m2_t __riscv_vncvt_x(vint64m4_t vs2, size_t vl);
vint32m4_t __riscv_vncvt_x(vint64m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vncvt_x(vuint64m1_t vs2, size_t vl);
vuint32m1_t __riscv_vncvt_x(vuint64m2_t vs2, size_t vl);
vuint32m2_t __riscv_vncvt_x(vuint64m4_t vs2, size_t vl);
vuint32m4_t __riscv_vncvt_x(vuint64m8_t vs2, size_t vl);
// masked functions
vint8mf8_t __riscv_vncvt_x(vbool64_t vm, vint16mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vncvt_x(vbool32_t vm, vint16mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vncvt_x(vbool16_t vm, vint16m1_t vs2, size_t vl);
vint8m1_t __riscv_vncvt_x(vbool8_t vm, vint16m2_t vs2, size_t vl);
vint8m2_t __riscv_vncvt_x(vbool4_t vm, vint16m4_t vs2, size_t vl);
vint8m4_t __riscv_vncvt_x(vbool2_t vm, vint16m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vncvt_x(vbool64_t vm, vuint16mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vncvt_x(vbool32_t vm, vuint16mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vncvt_x(vbool16_t vm, vuint16m1_t vs2, size_t vl);
vuint8m1_t __riscv_vncvt_x(vbool8_t vm, vuint16m2_t vs2, size_t vl);
vuint8m2_t __riscv_vncvt_x(vbool4_t vm, vuint16m4_t vs2, size_t vl);
vuint8m4_t __riscv_vncvt_x(vbool2_t vm, vuint16m8_t vs2, size_t vl);
vint16mf4_t __riscv_vncvt_x(vbool64_t vm, vint32mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vncvt_x(vbool32_t vm, vint32m1_t vs2, size_t vl);
vint16m1_t __riscv_vncvt_x(vbool16_t vm, vint32m2_t vs2, size_t vl);
vint16m2_t __riscv_vncvt_x(vbool8_t vm, vint32m4_t vs2, size_t vl);
vint16m4_t __riscv_vncvt_x(vbool4_t vm, vint32m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vncvt_x(vbool64_t vm, vuint32mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vncvt_x(vbool32_t vm, vuint32m1_t vs2, size_t vl);
vuint16m1_t __riscv_vncvt_x(vbool16_t vm, vuint32m2_t vs2, size_t vl);
vuint16m2_t __riscv_vncvt_x(vbool8_t vm, vuint32m4_t vs2, size_t vl);
vuint16m4_t __riscv_vncvt_x(vbool4_t vm, vuint32m8_t vs2, size_t vl);
vint32mf2_t __riscv_vncvt_x(vbool64_t vm, vint64m1_t vs2, size_t vl);
vint32m1_t __riscv_vncvt_x(vbool32_t vm, vint64m2_t vs2, size_t vl);
vint32m2_t __riscv_vncvt_x(vbool16_t vm, vint64m4_t vs2, size_t vl);
vint32m4_t __riscv_vncvt_x(vbool8_t vm, vint64m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vncvt_x(vbool64_t vm, vuint64m1_t vs2, size_t vl);
vuint32m1_t __riscv_vncvt_x(vbool32_t vm, vuint64m2_t vs2, size_t vl);
vuint32m2_t __riscv_vncvt_x(vbool16_t vm, vuint64m4_t vs2, size_t vl);
vuint32m4_t __riscv_vncvt_x(vbool8_t vm, vuint64m8_t vs2, size_t vl);
----

[[overloaded-vector-integer-comparison]]
==== Vector Integer Compare Intrinsics

[,c]
----
vbool64_t __riscv_vmseq(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmseq(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmseq(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmseq(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmseq(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmseq(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmseq(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmseq(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmseq(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmseq(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmseq(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmseq(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmseq(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmseq(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmseq(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmseq(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmseq(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmseq(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmseq(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmseq(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmseq(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmseq(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsne(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsne(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsne(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsne(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsne(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsne(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsne(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsne(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsne(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsne(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsne(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsne(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsne(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsne(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsne(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsne(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsne(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsne(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsne(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsne(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsne(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmslt(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmslt(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmslt(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmslt(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmslt(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmslt(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmslt(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmslt(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmslt(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmslt(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmslt(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmslt(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmslt(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmslt(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmslt(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmslt(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmslt(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmslt(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmslt(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmslt(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmslt(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmslt(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmslt(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmslt(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmslt(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmslt(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmslt(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmslt(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmslt(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmslt(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmslt(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmslt(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmslt(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmslt(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmslt(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmslt(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmslt(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmslt(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmslt(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmslt(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmslt(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmslt(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmslt(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmslt(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsle(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsle(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsle(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsle(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsle(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsle(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsle(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsle(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsle(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsle(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsle(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsle(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsle(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsle(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsle(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsle(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsle(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsle(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsle(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsle(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsle(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsle(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsle(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsle(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsle(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsle(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsle(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsle(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsle(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsle(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsle(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsle(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsle(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsle(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsle(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsle(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsle(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsle(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsle(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsle(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsle(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsle(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsle(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsle(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsgt(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsgt(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsgt(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsgt(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsgt(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsgt(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsgt(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgt(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsgt(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgt(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsgt(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgt(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsgt(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgt(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsgt(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsgt(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsgt(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsgt(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsgt(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsgt(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsgt(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsgt(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsgt(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsgt(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsgt(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsgt(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsgt(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsgt(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsgt(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsgt(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsgt(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsgt(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsgt(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsgt(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsgt(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsgt(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsgt(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsgt(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsgt(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsgt(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsgt(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsgt(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsgt(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsgt(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsge(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsge(vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsge(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsge(vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsge(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsge(vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsge(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsge(vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsge(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsge(vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsge(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsge(vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsge(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsge(vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsge(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsge(vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsge(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsge(vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsge(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsge(vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsge(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsge(vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsge(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsge(vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsge(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsge(vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsge(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsge(vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsge(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsge(vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsge(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsge(vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsge(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsge(vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsge(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsge(vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsge(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsge(vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsge(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsge(vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsge(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsge(vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsge(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsge(vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmseq(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmseq(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmseq(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmseq(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmseq(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmseq(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmseq(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmseq(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmseq(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmseq(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmseq(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmseq(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmseq(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmseq(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmseq(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmseq(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmseq(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmseq(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmseq(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmseq(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmseq(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsne(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsne(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsne(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsne(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsne(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsne(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsne(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsne(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsne(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsne(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsne(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsne(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsne(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsne(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsne(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsne(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsne(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsne(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsne(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsne(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsne(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsltu(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsltu(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsltu(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsltu(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsltu(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsltu(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsltu(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsltu(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsltu(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsltu(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsltu(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsltu(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsltu(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsltu(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsltu(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsltu(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsltu(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsltu(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsltu(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsltu(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsltu(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsltu(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsltu(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsltu(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsltu(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsltu(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsltu(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsltu(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsltu(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsltu(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsltu(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsltu(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsltu(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsltu(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsltu(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsltu(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsltu(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsltu(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsltu(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsltu(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsltu(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsltu(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsltu(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsltu(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsleu(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsleu(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsleu(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsleu(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsleu(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsleu(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsleu(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsleu(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsleu(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsleu(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsleu(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsleu(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsleu(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsleu(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsleu(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsleu(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsleu(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsleu(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsleu(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsleu(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsleu(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsleu(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsleu(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsleu(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsleu(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsleu(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsleu(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsleu(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsleu(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsleu(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsleu(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsleu(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsleu(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsleu(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsleu(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsleu(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsleu(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsleu(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsleu(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsleu(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsleu(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsleu(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsleu(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsleu(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsgtu(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsgtu(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsgtu(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgtu(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgtu(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsgtu(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgtu(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsgtu(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgtu(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsgtu(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsgtu(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsgtu(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsgtu(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsgtu(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsgtu(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsgtu(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsgtu(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsgtu(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsgtu(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsgtu(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsgtu(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsgtu(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsgtu(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsgtu(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsgtu(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vbool64_t __riscv_vmsgeu(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vbool32_t __riscv_vmsgeu(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vbool16_t __riscv_vmsgeu(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgeu(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgeu(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsgeu(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgeu(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsgeu(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgeu(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vbool64_t __riscv_vmsgeu(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vbool32_t __riscv_vmsgeu(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vbool16_t __riscv_vmsgeu(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsgeu(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsgeu(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsgeu(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsgeu(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vbool64_t __riscv_vmsgeu(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vbool32_t __riscv_vmsgeu(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vbool16_t __riscv_vmsgeu(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsgeu(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsgeu(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vbool64_t __riscv_vmsgeu(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vbool32_t __riscv_vmsgeu(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vbool16_t __riscv_vmsgeu(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsgeu(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vbool64_t __riscv_vmseq(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmseq(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmseq(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmseq(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmseq(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                        size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmseq(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmseq(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                        size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsne(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsne(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsne(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsne(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsne(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsne(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmslt(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vbool64_t __riscv_vmslt(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmslt(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vbool32_t __riscv_vmslt(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmslt(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmslt(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmslt(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmslt(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmslt(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmslt(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmslt(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmslt(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmslt(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmslt(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmslt(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                        size_t vl);
vbool64_t __riscv_vmslt(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmslt(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmslt(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmslt(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vbool16_t __riscv_vmslt(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmslt(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmslt(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmslt(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmslt(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmslt(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmslt(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmslt(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                        size_t vl);
vbool64_t __riscv_vmslt(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmslt(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vbool32_t __riscv_vmslt(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmslt(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmslt(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmslt(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmslt(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmslt(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmslt(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmslt(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vbool64_t __riscv_vmslt(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmslt(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmslt(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmslt(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vbool16_t __riscv_vmslt(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmslt(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmslt(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsle(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsle(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsle(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsle(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsle(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsle(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsle(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsle(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsle(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsle(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsle(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsle(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsle(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsle(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsle(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsle(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsle(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsle(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsle(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsle(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsle(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsle(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsle(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsle(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsle(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsle(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsle(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsle(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsle(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsle(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsle(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsle(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsle(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsle(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsle(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsle(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsle(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsle(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsle(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsle(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsle(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsle(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsle(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsle(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsgt(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsgt(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsgt(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsgt(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsgt(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsgt(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsgt(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgt(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsgt(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgt(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsgt(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgt(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsgt(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgt(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsgt(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsgt(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsgt(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsgt(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsgt(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsgt(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsgt(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsgt(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsgt(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsgt(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsgt(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsgt(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsgt(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsgt(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsgt(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsgt(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsgt(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsgt(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsgt(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsgt(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsgt(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsgt(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsgt(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsgt(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsgt(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsgt(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsgt(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsgt(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsgt(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsgt(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmsge(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsge(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vbool32_t __riscv_vmsge(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsge(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vbool16_t __riscv_vmsge(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsge(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vbool8_t __riscv_vmsge(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsge(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vbool4_t __riscv_vmsge(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsge(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vbool2_t __riscv_vmsge(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsge(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vbool1_t __riscv_vmsge(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsge(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vbool64_t __riscv_vmsge(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsge(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vbool32_t __riscv_vmsge(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsge(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vbool16_t __riscv_vmsge(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsge(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vbool8_t __riscv_vmsge(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vbool8_t __riscv_vmsge(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vbool4_t __riscv_vmsge(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vbool4_t __riscv_vmsge(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vbool2_t __riscv_vmsge(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vbool2_t __riscv_vmsge(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vbool64_t __riscv_vmsge(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsge(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vbool32_t __riscv_vmsge(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsge(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vbool16_t __riscv_vmsge(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsge(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vbool8_t __riscv_vmsge(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vbool8_t __riscv_vmsge(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vbool4_t __riscv_vmsge(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vbool4_t __riscv_vmsge(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vbool64_t __riscv_vmsge(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsge(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vbool32_t __riscv_vmsge(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsge(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vbool16_t __riscv_vmsge(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsge(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vbool8_t __riscv_vmsge(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vbool8_t __riscv_vmsge(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                        size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                        size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmseq(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmseq(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmseq(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmseq(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                        size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                        size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                        size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                        size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                       size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                       size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmseq(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                       size_t vl);
vbool2_t __riscv_vmseq(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                        size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                        size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                        size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                       size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                       size_t vl);
vbool4_t __riscv_vmseq(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                        size_t vl);
vbool64_t __riscv_vmseq(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmseq(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                        size_t vl);
vbool16_t __riscv_vmseq(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                       size_t vl);
vbool8_t __riscv_vmseq(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsne(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsne(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsne(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsne(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                        size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                        size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                       size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                       size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsne(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                       size_t vl);
vbool2_t __riscv_vmsne(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                        size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                       size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                       size_t vl);
vbool4_t __riscv_vmsne(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                        size_t vl);
vbool64_t __riscv_vmsne(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1, size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                        size_t vl);
vbool32_t __riscv_vmsne(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1, size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                        size_t vl);
vbool16_t __riscv_vmsne(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1, size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                       size_t vl);
vbool8_t __riscv_vmsne(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsltu(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsltu(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsltu(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsltu(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsltu(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsltu(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsltu(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsltu(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsltu(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsltu(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsltu(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsltu(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsltu(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsltu(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsltu(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsltu(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsltu(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsltu(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsltu(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsltu(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsltu(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsltu(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsltu(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                        size_t vl);
vbool4_t __riscv_vmsltu(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsltu(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                        size_t vl);
vbool2_t __riscv_vmsltu(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsltu(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsltu(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsltu(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsltu(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsltu(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsltu(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsltu(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsltu(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsltu(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                        size_t vl);
vbool4_t __riscv_vmsltu(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsltu(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsltu(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsltu(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsltu(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsltu(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsltu(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsltu(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsltu(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsleu(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsleu(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsleu(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsleu(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsleu(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsleu(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsleu(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsleu(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsleu(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsleu(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsleu(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsleu(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsleu(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsleu(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsleu(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsleu(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsleu(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsleu(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsleu(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsleu(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsleu(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsleu(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsleu(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                        size_t vl);
vbool4_t __riscv_vmsleu(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsleu(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                        size_t vl);
vbool2_t __riscv_vmsleu(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsleu(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsleu(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsleu(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsleu(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsleu(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsleu(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsleu(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsleu(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsleu(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                        size_t vl);
vbool4_t __riscv_vmsleu(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsleu(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsleu(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsleu(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsleu(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsleu(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsleu(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsleu(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsleu(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsgtu(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsgtu(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsgtu(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsgtu(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsgtu(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsgtu(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgtu(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgtu(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsgtu(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgtu(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsgtu(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgtu(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsgtu(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsgtu(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsgtu(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsgtu(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsgtu(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsgtu(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsgtu(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                        size_t vl);
vbool4_t __riscv_vmsgtu(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsgtu(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                        size_t vl);
vbool2_t __riscv_vmsgtu(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsgtu(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsgtu(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsgtu(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsgtu(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsgtu(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsgtu(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsgtu(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsgtu(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                        size_t vl);
vbool4_t __riscv_vmsgtu(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsgtu(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsgtu(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsgtu(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsgtu(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsgtu(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsgtu(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsgtu(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsgtu(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsgeu(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vbool32_t __riscv_vmsgeu(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsgeu(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vbool16_t __riscv_vmsgeu(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsgeu(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vbool8_t __riscv_vmsgeu(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vbool8_t __riscv_vmsgeu(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vbool4_t __riscv_vmsgeu(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vbool2_t __riscv_vmsgeu(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vbool2_t __riscv_vmsgeu(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vbool1_t __riscv_vmsgeu(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vbool1_t __riscv_vmsgeu(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsgeu(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsgeu(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsgeu(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsgeu(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsgeu(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsgeu(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsgeu(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                        size_t vl);
vbool4_t __riscv_vmsgeu(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vbool2_t __riscv_vmsgeu(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                        size_t vl);
vbool2_t __riscv_vmsgeu(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsgeu(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsgeu(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsgeu(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsgeu(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsgeu(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsgeu(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsgeu(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vbool4_t __riscv_vmsgeu(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                        size_t vl);
vbool4_t __riscv_vmsgeu(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vbool64_t __riscv_vmsgeu(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vbool64_t __riscv_vmsgeu(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                         size_t vl);
vbool32_t __riscv_vmsgeu(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vbool32_t __riscv_vmsgeu(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                         size_t vl);
vbool16_t __riscv_vmsgeu(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vbool16_t __riscv_vmsgeu(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                         size_t vl);
vbool8_t __riscv_vmsgeu(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                        size_t vl);
vbool8_t __riscv_vmsgeu(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
----

[[overloaded-vector-integer-minmax]]
==== Vector Integer Min/Max Intrinsics

[,c]
----
vint8mf8_t __riscv_vmin(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmin(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmin(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmin(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmin(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmin(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmin(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmin(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmin(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmin(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmin(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmin(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmin(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmin(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmin(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmin(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmin(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmin(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmin(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmin(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmin(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmin(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmin(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmin(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmin(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmin(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmin(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmin(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmin(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmin(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmin(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmin(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmin(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmin(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmin(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmin(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmin(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmin(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmin(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmin(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmin(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmin(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmin(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmin(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vmax(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmax(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmax(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmax(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmax(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmax(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmax(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmax(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmax(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmax(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmax(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmax(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmax(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmax(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmax(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmax(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmax(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmax(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmax(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmax(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmax(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmax(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmax(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmax(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmax(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmax(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmax(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmax(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmax(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmax(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmax(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmax(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmax(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmax(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmax(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmax(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmax(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmax(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmax(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmax(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmax(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmax(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmax(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmax(vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vminu(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vminu(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vminu(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vminu(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vminu(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vminu(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vminu(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vminu(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vminu(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vminu(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vminu(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vminu(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vminu(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vminu(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vminu(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vminu(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vminu(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vminu(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vminu(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vminu(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vminu(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vminu(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vminu(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vminu(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vminu(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vminu(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vminu(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vminu(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vminu(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vminu(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vminu(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vminu(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vminu(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vminu(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vminu(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vminu(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vminu(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vminu(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vminu(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vminu(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vminu(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vminu(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vminu(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vminu(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vmaxu(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vmaxu(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vmaxu(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vmaxu(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vmaxu(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vmaxu(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vmaxu(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vmaxu(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vmaxu(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vmaxu(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vmaxu(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vmaxu(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vmaxu(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vmaxu(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vmaxu(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vmaxu(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vmaxu(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vmaxu(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vmaxu(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vmaxu(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vmaxu(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vmaxu(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vmaxu(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vmaxu(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vmaxu(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vmaxu(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vmaxu(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vmaxu(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vmaxu(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vmaxu(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vmaxu(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vmaxu(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vmaxu(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vmaxu(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vmaxu(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vmaxu(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vmaxu(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vmaxu(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vmaxu(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vmaxu(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vmaxu(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vmaxu(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vmaxu(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vmaxu(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vmin(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vmin(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmin(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vmin(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmin(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vmin(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmin(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmin(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmin(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmin(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmin(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmin(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmin(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmin(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmin(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vmin(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmin(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vmin(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmin(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vmin(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmin(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmin(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmin(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmin(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmin(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmin(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmin(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vmin(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmin(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vmin(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmin(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vmin(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmin(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmin(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmin(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmin(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmin(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vmin(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmin(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vmin(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmin(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vmin(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmin(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmin(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vmax(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vmax(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmax(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vmax(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmax(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vmax(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmax(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmax(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmax(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmax(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmax(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmax(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmax(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmax(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmax(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vmax(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmax(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vmax(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmax(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vmax(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmax(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmax(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmax(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmax(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmax(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmax(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmax(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vmax(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmax(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vmax(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmax(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vmax(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmax(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmax(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmax(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmax(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmax(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vmax(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmax(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vmax(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmax(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vmax(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmax(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmax(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vminu(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                          size_t vl);
vuint8mf8_t __riscv_vminu(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                          size_t vl);
vuint8mf4_t __riscv_vminu(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                          size_t vl);
vuint8mf4_t __riscv_vminu(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                          size_t vl);
vuint8mf2_t __riscv_vminu(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                          size_t vl);
vuint8mf2_t __riscv_vminu(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                          size_t vl);
vuint8m1_t __riscv_vminu(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                         size_t vl);
vuint8m1_t __riscv_vminu(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vminu(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                         size_t vl);
vuint8m2_t __riscv_vminu(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vminu(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                         size_t vl);
vuint8m4_t __riscv_vminu(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vminu(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                         size_t vl);
vuint8m8_t __riscv_vminu(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vminu(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                           size_t vl);
vuint16mf4_t __riscv_vminu(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                           size_t vl);
vuint16mf2_t __riscv_vminu(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                           size_t vl);
vuint16mf2_t __riscv_vminu(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                           size_t vl);
vuint16m1_t __riscv_vminu(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                          size_t vl);
vuint16m1_t __riscv_vminu(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m2_t __riscv_vminu(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                          size_t vl);
vuint16m2_t __riscv_vminu(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m4_t __riscv_vminu(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                          size_t vl);
vuint16m4_t __riscv_vminu(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m8_t __riscv_vminu(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                          size_t vl);
vuint16m8_t __riscv_vminu(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                          size_t vl);
vuint32mf2_t __riscv_vminu(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                           size_t vl);
vuint32mf2_t __riscv_vminu(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                           size_t vl);
vuint32m1_t __riscv_vminu(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                          size_t vl);
vuint32m1_t __riscv_vminu(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m2_t __riscv_vminu(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                          size_t vl);
vuint32m2_t __riscv_vminu(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m4_t __riscv_vminu(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                          size_t vl);
vuint32m4_t __riscv_vminu(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m8_t __riscv_vminu(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                          size_t vl);
vuint32m8_t __riscv_vminu(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                          size_t vl);
vuint64m1_t __riscv_vminu(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                          size_t vl);
vuint64m1_t __riscv_vminu(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m2_t __riscv_vminu(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                          size_t vl);
vuint64m2_t __riscv_vminu(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m4_t __riscv_vminu(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                          size_t vl);
vuint64m4_t __riscv_vminu(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m8_t __riscv_vminu(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                          size_t vl);
vuint64m8_t __riscv_vminu(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                          size_t vl);
vuint8mf8_t __riscv_vmaxu(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                          size_t vl);
vuint8mf8_t __riscv_vmaxu(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                          size_t vl);
vuint8mf4_t __riscv_vmaxu(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                          size_t vl);
vuint8mf4_t __riscv_vmaxu(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                          size_t vl);
vuint8mf2_t __riscv_vmaxu(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                          size_t vl);
vuint8mf2_t __riscv_vmaxu(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                          size_t vl);
vuint8m1_t __riscv_vmaxu(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                         size_t vl);
vuint8m1_t __riscv_vmaxu(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vmaxu(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                         size_t vl);
vuint8m2_t __riscv_vmaxu(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vmaxu(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                         size_t vl);
vuint8m4_t __riscv_vmaxu(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vmaxu(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                         size_t vl);
vuint8m8_t __riscv_vmaxu(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vmaxu(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                           size_t vl);
vuint16mf4_t __riscv_vmaxu(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                           size_t vl);
vuint16mf2_t __riscv_vmaxu(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                           size_t vl);
vuint16mf2_t __riscv_vmaxu(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                           size_t vl);
vuint16m1_t __riscv_vmaxu(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                          size_t vl);
vuint16m1_t __riscv_vmaxu(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m2_t __riscv_vmaxu(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                          size_t vl);
vuint16m2_t __riscv_vmaxu(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m4_t __riscv_vmaxu(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                          size_t vl);
vuint16m4_t __riscv_vmaxu(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m8_t __riscv_vmaxu(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                          size_t vl);
vuint16m8_t __riscv_vmaxu(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                          size_t vl);
vuint32mf2_t __riscv_vmaxu(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                           size_t vl);
vuint32mf2_t __riscv_vmaxu(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                           size_t vl);
vuint32m1_t __riscv_vmaxu(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                          size_t vl);
vuint32m1_t __riscv_vmaxu(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m2_t __riscv_vmaxu(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                          size_t vl);
vuint32m2_t __riscv_vmaxu(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m4_t __riscv_vmaxu(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                          size_t vl);
vuint32m4_t __riscv_vmaxu(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m8_t __riscv_vmaxu(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                          size_t vl);
vuint32m8_t __riscv_vmaxu(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                          size_t vl);
vuint64m1_t __riscv_vmaxu(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                          size_t vl);
vuint64m1_t __riscv_vmaxu(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m2_t __riscv_vmaxu(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                          size_t vl);
vuint64m2_t __riscv_vmaxu(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m4_t __riscv_vmaxu(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                          size_t vl);
vuint64m4_t __riscv_vmaxu(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m8_t __riscv_vmaxu(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                          size_t vl);
vuint64m8_t __riscv_vmaxu(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                          size_t vl);
----

[[overloaded-vector-single-width-integer-multiply]]
==== Vector Single-Width Integer Multiply Intrinsics

[,c]
----
vint8mf8_t __riscv_vmul(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmul(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmul(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmul(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmul(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmul(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmul(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmul(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmul(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmul(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmul(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmul(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmul(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmul(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmul(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmul(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmul(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmul(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmul(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmul(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmul(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmul(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmul(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmul(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmul(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmul(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmul(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmul(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmul(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmul(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmul(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmul(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmul(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmul(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmul(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmul(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmul(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmul(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmul(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmul(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmul(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmul(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmul(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmul(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vmulh(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmulh(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmulh(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmulh(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmulh(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmulh(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmulh(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmulh(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmulh(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmulh(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmulh(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmulh(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmulh(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmulh(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmulh(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmulh(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmulh(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmulh(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmulh(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmulh(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmulh(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmulh(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmulh(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmulh(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmulh(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmulh(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmulh(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmulh(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmulh(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmulh(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmulh(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmulh(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmulh(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmulh(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmulh(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmulh(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmulh(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmulh(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmulh(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmulh(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmulh(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmulh(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmulh(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmulh(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vmulhsu(vint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vmulhsu(vint8mf8_t vs2, uint8_t rs1, size_t vl);
vint8mf4_t __riscv_vmulhsu(vint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vmulhsu(vint8mf4_t vs2, uint8_t rs1, size_t vl);
vint8mf2_t __riscv_vmulhsu(vint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vmulhsu(vint8mf2_t vs2, uint8_t rs1, size_t vl);
vint8m1_t __riscv_vmulhsu(vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmulhsu(vint8m1_t vs2, uint8_t rs1, size_t vl);
vint8m2_t __riscv_vmulhsu(vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmulhsu(vint8m2_t vs2, uint8_t rs1, size_t vl);
vint8m4_t __riscv_vmulhsu(vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmulhsu(vint8m4_t vs2, uint8_t rs1, size_t vl);
vint8m8_t __riscv_vmulhsu(vint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmulhsu(vint8m8_t vs2, uint8_t rs1, size_t vl);
vint16mf4_t __riscv_vmulhsu(vint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vmulhsu(vint16mf4_t vs2, uint16_t rs1, size_t vl);
vint16mf2_t __riscv_vmulhsu(vint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vmulhsu(vint16mf2_t vs2, uint16_t rs1, size_t vl);
vint16m1_t __riscv_vmulhsu(vint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vmulhsu(vint16m1_t vs2, uint16_t rs1, size_t vl);
vint16m2_t __riscv_vmulhsu(vint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmulhsu(vint16m2_t vs2, uint16_t rs1, size_t vl);
vint16m4_t __riscv_vmulhsu(vint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmulhsu(vint16m4_t vs2, uint16_t rs1, size_t vl);
vint16m8_t __riscv_vmulhsu(vint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmulhsu(vint16m8_t vs2, uint16_t rs1, size_t vl);
vint32mf2_t __riscv_vmulhsu(vint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vmulhsu(vint32mf2_t vs2, uint32_t rs1, size_t vl);
vint32m1_t __riscv_vmulhsu(vint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vmulhsu(vint32m1_t vs2, uint32_t rs1, size_t vl);
vint32m2_t __riscv_vmulhsu(vint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vmulhsu(vint32m2_t vs2, uint32_t rs1, size_t vl);
vint32m4_t __riscv_vmulhsu(vint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmulhsu(vint32m4_t vs2, uint32_t rs1, size_t vl);
vint32m8_t __riscv_vmulhsu(vint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmulhsu(vint32m8_t vs2, uint32_t rs1, size_t vl);
vint64m1_t __riscv_vmulhsu(vint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vmulhsu(vint64m1_t vs2, uint64_t rs1, size_t vl);
vint64m2_t __riscv_vmulhsu(vint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vmulhsu(vint64m2_t vs2, uint64_t rs1, size_t vl);
vint64m4_t __riscv_vmulhsu(vint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vmulhsu(vint64m4_t vs2, uint64_t rs1, size_t vl);
vint64m8_t __riscv_vmulhsu(vint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmulhsu(vint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vmul(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vmul(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vmul(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vmul(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vmul(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vmul(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vmul(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vmul(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vmul(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vmul(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vmul(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vmul(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vmul(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vmul(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vmul(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vmul(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vmul(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vmul(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vmul(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vmul(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vmul(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vmul(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vmul(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vmul(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vmul(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vmul(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vmul(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vmul(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vmul(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vmul(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vmul(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vmul(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vmul(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vmul(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vmul(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vmul(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vmul(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vmul(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vmul(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vmul(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vmul(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vmul(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vmul(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vmul(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vmulhu(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vmulhu(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vmulhu(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vmulhu(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vmulhu(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vmulhu(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vmulhu(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vmulhu(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vmulhu(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vmulhu(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vmulhu(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vmulhu(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vmulhu(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vmulhu(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vmulhu(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vmulhu(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vmulhu(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vmulhu(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vmulhu(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vmulhu(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vmulhu(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vmulhu(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vmulhu(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vmulhu(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vmulhu(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vmulhu(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vmulhu(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vmulhu(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vmulhu(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vmulhu(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vmulhu(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vmulhu(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vmulhu(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vmulhu(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vmulhu(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vmulhu(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vmulhu(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vmulhu(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vmulhu(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vmulhu(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vmulhu(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vmulhu(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vmulhu(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vmulhu(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vmul(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vmul(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmul(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vmul(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmul(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vmul(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmul(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmul(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmul(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmul(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmul(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmul(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmul(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmul(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmul(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vmul(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vmul(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vmul(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vmul(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vmul(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmul(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vmul(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmul(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vmul(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmul(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vmul(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmul(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vmul(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vmul(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vmul(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmul(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vmul(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmul(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vmul(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmul(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vmul(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmul(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vmul(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmul(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vmul(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmul(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vmul(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmul(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vmul(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vmulh(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                         size_t vl);
vint8mf8_t __riscv_vmulh(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vmulh(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                         size_t vl);
vint8mf4_t __riscv_vmulh(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vmulh(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                         size_t vl);
vint8mf2_t __riscv_vmulh(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vmulh(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vmulh(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vmulh(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vmulh(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vmulh(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vmulh(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vmulh(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vmulh(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vmulh(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                          size_t vl);
vint16mf4_t __riscv_vmulh(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                          size_t vl);
vint16mf2_t __riscv_vmulh(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                          size_t vl);
vint16mf2_t __riscv_vmulh(vbool32_t vm, vint16mf2_t vs2, int16_t rs1,
                          size_t vl);
vint16m1_t __riscv_vmulh(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                         size_t vl);
vint16m1_t __riscv_vmulh(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vmulh(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                         size_t vl);
vint16m2_t __riscv_vmulh(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vmulh(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                         size_t vl);
vint16m4_t __riscv_vmulh(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vmulh(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1,
                         size_t vl);
vint16m8_t __riscv_vmulh(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vmulh(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                          size_t vl);
vint32mf2_t __riscv_vmulh(vbool64_t vm, vint32mf2_t vs2, int32_t rs1,
                          size_t vl);
vint32m1_t __riscv_vmulh(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                         size_t vl);
vint32m1_t __riscv_vmulh(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vmulh(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                         size_t vl);
vint32m2_t __riscv_vmulh(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vmulh(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                         size_t vl);
vint32m4_t __riscv_vmulh(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vmulh(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1,
                         size_t vl);
vint32m8_t __riscv_vmulh(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vmulh(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                         size_t vl);
vint64m1_t __riscv_vmulh(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vmulh(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                         size_t vl);
vint64m2_t __riscv_vmulh(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vmulh(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                         size_t vl);
vint64m4_t __riscv_vmulh(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vmulh(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1,
                         size_t vl);
vint64m8_t __riscv_vmulh(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vmulhsu(vbool64_t vm, vint8mf8_t vs2, vuint8mf8_t vs1,
                           size_t vl);
vint8mf8_t __riscv_vmulhsu(vbool64_t vm, vint8mf8_t vs2, uint8_t rs1,
                           size_t vl);
vint8mf4_t __riscv_vmulhsu(vbool32_t vm, vint8mf4_t vs2, vuint8mf4_t vs1,
                           size_t vl);
vint8mf4_t __riscv_vmulhsu(vbool32_t vm, vint8mf4_t vs2, uint8_t rs1,
                           size_t vl);
vint8mf2_t __riscv_vmulhsu(vbool16_t vm, vint8mf2_t vs2, vuint8mf2_t vs1,
                           size_t vl);
vint8mf2_t __riscv_vmulhsu(vbool16_t vm, vint8mf2_t vs2, uint8_t rs1,
                           size_t vl);
vint8m1_t __riscv_vmulhsu(vbool8_t vm, vint8m1_t vs2, vuint8m1_t vs1,
                          size_t vl);
vint8m1_t __riscv_vmulhsu(vbool8_t vm, vint8m1_t vs2, uint8_t rs1, size_t vl);
vint8m2_t __riscv_vmulhsu(vbool4_t vm, vint8m2_t vs2, vuint8m2_t vs1,
                          size_t vl);
vint8m2_t __riscv_vmulhsu(vbool4_t vm, vint8m2_t vs2, uint8_t rs1, size_t vl);
vint8m4_t __riscv_vmulhsu(vbool2_t vm, vint8m4_t vs2, vuint8m4_t vs1,
                          size_t vl);
vint8m4_t __riscv_vmulhsu(vbool2_t vm, vint8m4_t vs2, uint8_t rs1, size_t vl);
vint8m8_t __riscv_vmulhsu(vbool1_t vm, vint8m8_t vs2, vuint8m8_t vs1,
                          size_t vl);
vint8m8_t __riscv_vmulhsu(vbool1_t vm, vint8m8_t vs2, uint8_t rs1, size_t vl);
vint16mf4_t __riscv_vmulhsu(vbool64_t vm, vint16mf4_t vs2, vuint16mf4_t vs1,
                            size_t vl);
vint16mf4_t __riscv_vmulhsu(vbool64_t vm, vint16mf4_t vs2, uint16_t rs1,
                            size_t vl);
vint16mf2_t __riscv_vmulhsu(vbool32_t vm, vint16mf2_t vs2, vuint16mf2_t vs1,
                            size_t vl);
vint16mf2_t __riscv_vmulhsu(vbool32_t vm, vint16mf2_t vs2, uint16_t rs1,
                            size_t vl);
vint16m1_t __riscv_vmulhsu(vbool16_t vm, vint16m1_t vs2, vuint16m1_t vs1,
                           size_t vl);
vint16m1_t __riscv_vmulhsu(vbool16_t vm, vint16m1_t vs2, uint16_t rs1,
                           size_t vl);
vint16m2_t __riscv_vmulhsu(vbool8_t vm, vint16m2_t vs2, vuint16m2_t vs1,
                           size_t vl);
vint16m2_t __riscv_vmulhsu(vbool8_t vm, vint16m2_t vs2, uint16_t rs1,
                           size_t vl);
vint16m4_t __riscv_vmulhsu(vbool4_t vm, vint16m4_t vs2, vuint16m4_t vs1,
                           size_t vl);
vint16m4_t __riscv_vmulhsu(vbool4_t vm, vint16m4_t vs2, uint16_t rs1,
                           size_t vl);
vint16m8_t __riscv_vmulhsu(vbool2_t vm, vint16m8_t vs2, vuint16m8_t vs1,
                           size_t vl);
vint16m8_t __riscv_vmulhsu(vbool2_t vm, vint16m8_t vs2, uint16_t rs1,
                           size_t vl);
vint32mf2_t __riscv_vmulhsu(vbool64_t vm, vint32mf2_t vs2, vuint32mf2_t vs1,
                            size_t vl);
vint32mf2_t __riscv_vmulhsu(vbool64_t vm, vint32mf2_t vs2, uint32_t rs1,
                            size_t vl);
vint32m1_t __riscv_vmulhsu(vbool32_t vm, vint32m1_t vs2, vuint32m1_t vs1,
                           size_t vl);
vint32m1_t __riscv_vmulhsu(vbool32_t vm, vint32m1_t vs2, uint32_t rs1,
                           size_t vl);
vint32m2_t __riscv_vmulhsu(vbool16_t vm, vint32m2_t vs2, vuint32m2_t vs1,
                           size_t vl);
vint32m2_t __riscv_vmulhsu(vbool16_t vm, vint32m2_t vs2, uint32_t rs1,
                           size_t vl);
vint32m4_t __riscv_vmulhsu(vbool8_t vm, vint32m4_t vs2, vuint32m4_t vs1,
                           size_t vl);
vint32m4_t __riscv_vmulhsu(vbool8_t vm, vint32m4_t vs2, uint32_t rs1,
                           size_t vl);
vint32m8_t __riscv_vmulhsu(vbool4_t vm, vint32m8_t vs2, vuint32m8_t vs1,
                           size_t vl);
vint32m8_t __riscv_vmulhsu(vbool4_t vm, vint32m8_t vs2, uint32_t rs1,
                           size_t vl);
vint64m1_t __riscv_vmulhsu(vbool64_t vm, vint64m1_t vs2, vuint64m1_t vs1,
                           size_t vl);
vint64m1_t __riscv_vmulhsu(vbool64_t vm, vint64m1_t vs2, uint64_t rs1,
                           size_t vl);
vint64m2_t __riscv_vmulhsu(vbool32_t vm, vint64m2_t vs2, vuint64m2_t vs1,
                           size_t vl);
vint64m2_t __riscv_vmulhsu(vbool32_t vm, vint64m2_t vs2, uint64_t rs1,
                           size_t vl);
vint64m4_t __riscv_vmulhsu(vbool16_t vm, vint64m4_t vs2, vuint64m4_t vs1,
                           size_t vl);
vint64m4_t __riscv_vmulhsu(vbool16_t vm, vint64m4_t vs2, uint64_t rs1,
                           size_t vl);
vint64m8_t __riscv_vmulhsu(vbool8_t vm, vint64m8_t vs2, vuint64m8_t vs1,
                           size_t vl);
vint64m8_t __riscv_vmulhsu(vbool8_t vm, vint64m8_t vs2, uint64_t rs1,
                           size_t vl);
vuint8mf8_t __riscv_vmul(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                         size_t vl);
vuint8mf8_t __riscv_vmul(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vmul(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                         size_t vl);
vuint8mf4_t __riscv_vmul(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vmul(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                         size_t vl);
vuint8mf2_t __riscv_vmul(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vmul(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vmul(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vmul(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vmul(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vmul(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vmul(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vmul(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vmul(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vmul(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                          size_t vl);
vuint16mf4_t __riscv_vmul(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                          size_t vl);
vuint16mf2_t __riscv_vmul(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                          size_t vl);
vuint16mf2_t __riscv_vmul(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m1_t __riscv_vmul(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                         size_t vl);
vuint16m1_t __riscv_vmul(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                         size_t vl);
vuint16m2_t __riscv_vmul(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                         size_t vl);
vuint16m2_t __riscv_vmul(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vmul(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                         size_t vl);
vuint16m4_t __riscv_vmul(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vmul(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                         size_t vl);
vuint16m8_t __riscv_vmul(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vmul(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                          size_t vl);
vuint32mf2_t __riscv_vmul(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m1_t __riscv_vmul(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                         size_t vl);
vuint32m1_t __riscv_vmul(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m2_t __riscv_vmul(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                         size_t vl);
vuint32m2_t __riscv_vmul(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                         size_t vl);
vuint32m4_t __riscv_vmul(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                         size_t vl);
vuint32m4_t __riscv_vmul(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vmul(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                         size_t vl);
vuint32m8_t __riscv_vmul(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vmul(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                         size_t vl);
vuint64m1_t __riscv_vmul(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m2_t __riscv_vmul(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                         size_t vl);
vuint64m2_t __riscv_vmul(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m4_t __riscv_vmul(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                         size_t vl);
vuint64m4_t __riscv_vmul(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                         size_t vl);
vuint64m8_t __riscv_vmul(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                         size_t vl);
vuint64m8_t __riscv_vmul(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vmulhu(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                           size_t vl);
vuint8mf8_t __riscv_vmulhu(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                           size_t vl);
vuint8mf4_t __riscv_vmulhu(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                           size_t vl);
vuint8mf4_t __riscv_vmulhu(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                           size_t vl);
vuint8mf2_t __riscv_vmulhu(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                           size_t vl);
vuint8mf2_t __riscv_vmulhu(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                           size_t vl);
vuint8m1_t __riscv_vmulhu(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                          size_t vl);
vuint8m1_t __riscv_vmulhu(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vmulhu(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                          size_t vl);
vuint8m2_t __riscv_vmulhu(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vmulhu(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                          size_t vl);
vuint8m4_t __riscv_vmulhu(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vmulhu(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                          size_t vl);
vuint8m8_t __riscv_vmulhu(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vmulhu(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                            size_t vl);
vuint16mf4_t __riscv_vmulhu(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                            size_t vl);
vuint16mf2_t __riscv_vmulhu(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                            size_t vl);
vuint16mf2_t __riscv_vmulhu(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                            size_t vl);
vuint16m1_t __riscv_vmulhu(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                           size_t vl);
vuint16m1_t __riscv_vmulhu(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                           size_t vl);
vuint16m2_t __riscv_vmulhu(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                           size_t vl);
vuint16m2_t __riscv_vmulhu(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                           size_t vl);
vuint16m4_t __riscv_vmulhu(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                           size_t vl);
vuint16m4_t __riscv_vmulhu(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                           size_t vl);
vuint16m8_t __riscv_vmulhu(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                           size_t vl);
vuint16m8_t __riscv_vmulhu(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                           size_t vl);
vuint32mf2_t __riscv_vmulhu(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                            size_t vl);
vuint32mf2_t __riscv_vmulhu(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                            size_t vl);
vuint32m1_t __riscv_vmulhu(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                           size_t vl);
vuint32m1_t __riscv_vmulhu(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                           size_t vl);
vuint32m2_t __riscv_vmulhu(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                           size_t vl);
vuint32m2_t __riscv_vmulhu(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                           size_t vl);
vuint32m4_t __riscv_vmulhu(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                           size_t vl);
vuint32m4_t __riscv_vmulhu(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                           size_t vl);
vuint32m8_t __riscv_vmulhu(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                           size_t vl);
vuint32m8_t __riscv_vmulhu(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                           size_t vl);
vuint64m1_t __riscv_vmulhu(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                           size_t vl);
vuint64m1_t __riscv_vmulhu(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                           size_t vl);
vuint64m2_t __riscv_vmulhu(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                           size_t vl);
vuint64m2_t __riscv_vmulhu(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                           size_t vl);
vuint64m4_t __riscv_vmulhu(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                           size_t vl);
vuint64m4_t __riscv_vmulhu(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                           size_t vl);
vuint64m8_t __riscv_vmulhu(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                           size_t vl);
vuint64m8_t __riscv_vmulhu(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                           size_t vl);
----

[[overloaded-vector-integer-divide]]
==== Vector Integer Divide Intrinsics

[,c]
----
vint8mf8_t __riscv_vdiv(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vdiv(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vdiv(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vdiv(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vdiv(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vdiv(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vdiv(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vdiv(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vdiv(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vdiv(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vdiv(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vdiv(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vdiv(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vdiv(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vdiv(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vdiv(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vdiv(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vdiv(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vdiv(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vdiv(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vdiv(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vdiv(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vdiv(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vdiv(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vdiv(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vdiv(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vdiv(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vdiv(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vdiv(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vdiv(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vdiv(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vdiv(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vdiv(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vdiv(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vdiv(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vdiv(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vdiv(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vdiv(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vdiv(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vdiv(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vdiv(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vdiv(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vdiv(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vdiv(vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vrem(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint8mf8_t __riscv_vrem(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vrem(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint8mf4_t __riscv_vrem(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vrem(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint8mf2_t __riscv_vrem(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vrem(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vrem(vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vrem(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vrem(vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vrem(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vrem(vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vrem(vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vrem(vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vrem(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint16mf4_t __riscv_vrem(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vrem(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint16mf2_t __riscv_vrem(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vrem(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint16m1_t __riscv_vrem(vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vrem(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vrem(vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vrem(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vrem(vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vrem(vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vrem(vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vrem(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint32mf2_t __riscv_vrem(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vrem(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint32m1_t __riscv_vrem(vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vrem(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint32m2_t __riscv_vrem(vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vrem(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vrem(vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vrem(vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vrem(vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vrem(vint64m1_t vs2, vint64m1_t vs1, size_t vl);
vint64m1_t __riscv_vrem(vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vrem(vint64m2_t vs2, vint64m2_t vs1, size_t vl);
vint64m2_t __riscv_vrem(vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vrem(vint64m4_t vs2, vint64m4_t vs1, size_t vl);
vint64m4_t __riscv_vrem(vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vrem(vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vrem(vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vdivu(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vdivu(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vdivu(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vdivu(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vdivu(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vdivu(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vdivu(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vdivu(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vdivu(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vdivu(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vdivu(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vdivu(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vdivu(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vdivu(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vdivu(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vdivu(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vdivu(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vdivu(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vdivu(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vdivu(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vdivu(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vdivu(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vdivu(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vdivu(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vdivu(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vdivu(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vdivu(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vdivu(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vdivu(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vdivu(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vdivu(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vdivu(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vdivu(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vdivu(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vdivu(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vdivu(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vdivu(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vdivu(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vdivu(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vdivu(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vdivu(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vdivu(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vdivu(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vdivu(vuint64m8_t vs2, uint64_t rs1, size_t vl);
vuint8mf8_t __riscv_vremu(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint8mf8_t __riscv_vremu(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint8mf4_t __riscv_vremu(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint8mf4_t __riscv_vremu(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint8mf2_t __riscv_vremu(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint8mf2_t __riscv_vremu(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint8m1_t __riscv_vremu(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint8m1_t __riscv_vremu(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vremu(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint8m2_t __riscv_vremu(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vremu(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint8m4_t __riscv_vremu(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vremu(vuint8m8_t vs2, vuint8m8_t vs1, size_t vl);
vuint8m8_t __riscv_vremu(vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vremu(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint16mf4_t __riscv_vremu(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint16mf2_t __riscv_vremu(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint16mf2_t __riscv_vremu(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint16m1_t __riscv_vremu(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint16m1_t __riscv_vremu(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint16m2_t __riscv_vremu(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint16m2_t __riscv_vremu(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint16m4_t __riscv_vremu(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint16m4_t __riscv_vremu(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint16m8_t __riscv_vremu(vuint16m8_t vs2, vuint16m8_t vs1, size_t vl);
vuint16m8_t __riscv_vremu(vuint16m8_t vs2, uint16_t rs1, size_t vl);
vuint32mf2_t __riscv_vremu(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint32mf2_t __riscv_vremu(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint32m1_t __riscv_vremu(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint32m1_t __riscv_vremu(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint32m2_t __riscv_vremu(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint32m2_t __riscv_vremu(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint32m4_t __riscv_vremu(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint32m4_t __riscv_vremu(vuint32m4_t vs2, uint32_t rs1, size_t vl);
vuint32m8_t __riscv_vremu(vuint32m8_t vs2, vuint32m8_t vs1, size_t vl);
vuint32m8_t __riscv_vremu(vuint32m8_t vs2, uint32_t rs1, size_t vl);
vuint64m1_t __riscv_vremu(vuint64m1_t vs2, vuint64m1_t vs1, size_t vl);
vuint64m1_t __riscv_vremu(vuint64m1_t vs2, uint64_t rs1, size_t vl);
vuint64m2_t __riscv_vremu(vuint64m2_t vs2, vuint64m2_t vs1, size_t vl);
vuint64m2_t __riscv_vremu(vuint64m2_t vs2, uint64_t rs1, size_t vl);
vuint64m4_t __riscv_vremu(vuint64m4_t vs2, vuint64m4_t vs1, size_t vl);
vuint64m4_t __riscv_vremu(vuint64m4_t vs2, uint64_t rs1, size_t vl);
vuint64m8_t __riscv_vremu(vuint64m8_t vs2, vuint64m8_t vs1, size_t vl);
vuint64m8_t __riscv_vremu(vuint64m8_t vs2, uint64_t rs1, size_t vl);
// masked functions
vint8mf8_t __riscv_vdiv(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vdiv(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vdiv(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vdiv(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vdiv(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vdiv(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vdiv(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vdiv(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vdiv(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vdiv(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vdiv(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vdiv(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vdiv(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vdiv(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vdiv(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vdiv(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vdiv(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vdiv(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vdiv(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vdiv(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vdiv(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vdiv(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vdiv(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vdiv(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vdiv(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vdiv(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vdiv(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vdiv(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vdiv(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vdiv(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vdiv(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vdiv(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vdiv(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vdiv(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vdiv(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vdiv(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vdiv(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vdiv(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vdiv(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vdiv(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vdiv(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vdiv(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vdiv(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vdiv(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vint8mf8_t __riscv_vrem(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                        size_t vl);
vint8mf8_t __riscv_vrem(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint8mf4_t __riscv_vrem(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                        size_t vl);
vint8mf4_t __riscv_vrem(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint8mf2_t __riscv_vrem(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                        size_t vl);
vint8mf2_t __riscv_vrem(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint8m1_t __riscv_vrem(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint8m1_t __riscv_vrem(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint8m2_t __riscv_vrem(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint8m2_t __riscv_vrem(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint8m4_t __riscv_vrem(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint8m4_t __riscv_vrem(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint8m8_t __riscv_vrem(vbool1_t vm, vint8m8_t vs2, vint8m8_t vs1, size_t vl);
vint8m8_t __riscv_vrem(vbool1_t vm, vint8m8_t vs2, int8_t rs1, size_t vl);
vint16mf4_t __riscv_vrem(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                         size_t vl);
vint16mf4_t __riscv_vrem(vbool64_t vm, vint16mf4_t vs2, int16_t rs1, size_t vl);
vint16mf2_t __riscv_vrem(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                         size_t vl);
vint16mf2_t __riscv_vrem(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint16m1_t __riscv_vrem(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                        size_t vl);
vint16m1_t __riscv_vrem(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint16m2_t __riscv_vrem(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint16m2_t __riscv_vrem(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint16m4_t __riscv_vrem(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint16m4_t __riscv_vrem(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint16m8_t __riscv_vrem(vbool2_t vm, vint16m8_t vs2, vint16m8_t vs1, size_t vl);
vint16m8_t __riscv_vrem(vbool2_t vm, vint16m8_t vs2, int16_t rs1, size_t vl);
vint32mf2_t __riscv_vrem(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                         size_t vl);
vint32mf2_t __riscv_vrem(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint32m1_t __riscv_vrem(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                        size_t vl);
vint32m1_t __riscv_vrem(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint32m2_t __riscv_vrem(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                        size_t vl);
vint32m2_t __riscv_vrem(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint32m4_t __riscv_vrem(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint32m4_t __riscv_vrem(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint32m8_t __riscv_vrem(vbool4_t vm, vint32m8_t vs2, vint32m8_t vs1, size_t vl);
vint32m8_t __riscv_vrem(vbool4_t vm, vint32m8_t vs2, int32_t rs1, size_t vl);
vint64m1_t __riscv_vrem(vbool64_t vm, vint64m1_t vs2, vint64m1_t vs1,
                        size_t vl);
vint64m1_t __riscv_vrem(vbool64_t vm, vint64m1_t vs2, int64_t rs1, size_t vl);
vint64m2_t __riscv_vrem(vbool32_t vm, vint64m2_t vs2, vint64m2_t vs1,
                        size_t vl);
vint64m2_t __riscv_vrem(vbool32_t vm, vint64m2_t vs2, int64_t rs1, size_t vl);
vint64m4_t __riscv_vrem(vbool16_t vm, vint64m4_t vs2, vint64m4_t vs1,
                        size_t vl);
vint64m4_t __riscv_vrem(vbool16_t vm, vint64m4_t vs2, int64_t rs1, size_t vl);
vint64m8_t __riscv_vrem(vbool8_t vm, vint64m8_t vs2, vint64m8_t vs1, size_t vl);
vint64m8_t __riscv_vrem(vbool8_t vm, vint64m8_t vs2, int64_t rs1, size_t vl);
vuint8mf8_t __riscv_vdivu(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                          size_t vl);
vuint8mf8_t __riscv_vdivu(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                          size_t vl);
vuint8mf4_t __riscv_vdivu(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                          size_t vl);
vuint8mf4_t __riscv_vdivu(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                          size_t vl);
vuint8mf2_t __riscv_vdivu(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                          size_t vl);
vuint8mf2_t __riscv_vdivu(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                          size_t vl);
vuint8m1_t __riscv_vdivu(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                         size_t vl);
vuint8m1_t __riscv_vdivu(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vdivu(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                         size_t vl);
vuint8m2_t __riscv_vdivu(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vdivu(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                         size_t vl);
vuint8m4_t __riscv_vdivu(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vdivu(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                         size_t vl);
vuint8m8_t __riscv_vdivu(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vdivu(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                           size_t vl);
vuint16mf4_t __riscv_vdivu(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                           size_t vl);
vuint16mf2_t __riscv_vdivu(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                           size_t vl);
vuint16mf2_t __riscv_vdivu(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                           size_t vl);
vuint16m1_t __riscv_vdivu(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                          size_t vl);
vuint16m1_t __riscv_vdivu(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m2_t __riscv_vdivu(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                          size_t vl);
vuint16m2_t __riscv_vdivu(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m4_t __riscv_vdivu(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                          size_t vl);
vuint16m4_t __riscv_vdivu(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m8_t __riscv_vdivu(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                          size_t vl);
vuint16m8_t __riscv_vdivu(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                          size_t vl);
vuint32mf2_t __riscv_vdivu(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                           size_t vl);
vuint32mf2_t __riscv_vdivu(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                           size_t vl);
vuint32m1_t __riscv_vdivu(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                          size_t vl);
vuint32m1_t __riscv_vdivu(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m2_t __riscv_vdivu(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                          size_t vl);
vuint32m2_t __riscv_vdivu(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m4_t __riscv_vdivu(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                          size_t vl);
vuint32m4_t __riscv_vdivu(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m8_t __riscv_vdivu(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                          size_t vl);
vuint32m8_t __riscv_vdivu(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                          size_t vl);
vuint64m1_t __riscv_vdivu(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                          size_t vl);
vuint64m1_t __riscv_vdivu(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m2_t __riscv_vdivu(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                          size_t vl);
vuint64m2_t __riscv_vdivu(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m4_t __riscv_vdivu(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                          size_t vl);
vuint64m4_t __riscv_vdivu(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m8_t __riscv_vdivu(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                          size_t vl);
vuint64m8_t __riscv_vdivu(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                          size_t vl);
vuint8mf8_t __riscv_vremu(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                          size_t vl);
vuint8mf8_t __riscv_vremu(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                          size_t vl);
vuint8mf4_t __riscv_vremu(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                          size_t vl);
vuint8mf4_t __riscv_vremu(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                          size_t vl);
vuint8mf2_t __riscv_vremu(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                          size_t vl);
vuint8mf2_t __riscv_vremu(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                          size_t vl);
vuint8m1_t __riscv_vremu(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                         size_t vl);
vuint8m1_t __riscv_vremu(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint8m2_t __riscv_vremu(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                         size_t vl);
vuint8m2_t __riscv_vremu(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint8m4_t __riscv_vremu(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                         size_t vl);
vuint8m4_t __riscv_vremu(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint8m8_t __riscv_vremu(vbool1_t vm, vuint8m8_t vs2, vuint8m8_t vs1,
                         size_t vl);
vuint8m8_t __riscv_vremu(vbool1_t vm, vuint8m8_t vs2, uint8_t rs1, size_t vl);
vuint16mf4_t __riscv_vremu(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                           size_t vl);
vuint16mf4_t __riscv_vremu(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                           size_t vl);
vuint16mf2_t __riscv_vremu(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                           size_t vl);
vuint16mf2_t __riscv_vremu(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                           size_t vl);
vuint16m1_t __riscv_vremu(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                          size_t vl);
vuint16m1_t __riscv_vremu(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m2_t __riscv_vremu(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                          size_t vl);
vuint16m2_t __riscv_vremu(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m4_t __riscv_vremu(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                          size_t vl);
vuint16m4_t __riscv_vremu(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                          size_t vl);
vuint16m8_t __riscv_vremu(vbool2_t vm, vuint16m8_t vs2, vuint16m8_t vs1,
                          size_t vl);
vuint16m8_t __riscv_vremu(vbool2_t vm, vuint16m8_t vs2, uint16_t rs1,
                          size_t vl);
vuint32mf2_t __riscv_vremu(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                           size_t vl);
vuint32mf2_t __riscv_vremu(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                           size_t vl);
vuint32m1_t __riscv_vremu(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                          size_t vl);
vuint32m1_t __riscv_vremu(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m2_t __riscv_vremu(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                          size_t vl);
vuint32m2_t __riscv_vremu(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m4_t __riscv_vremu(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                          size_t vl);
vuint32m4_t __riscv_vremu(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                          size_t vl);
vuint32m8_t __riscv_vremu(vbool4_t vm, vuint32m8_t vs2, vuint32m8_t vs1,
                          size_t vl);
vuint32m8_t __riscv_vremu(vbool4_t vm, vuint32m8_t vs2, uint32_t rs1,
                          size_t vl);
vuint64m1_t __riscv_vremu(vbool64_t vm, vuint64m1_t vs2, vuint64m1_t vs1,
                          size_t vl);
vuint64m1_t __riscv_vremu(vbool64_t vm, vuint64m1_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m2_t __riscv_vremu(vbool32_t vm, vuint64m2_t vs2, vuint64m2_t vs1,
                          size_t vl);
vuint64m2_t __riscv_vremu(vbool32_t vm, vuint64m2_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m4_t __riscv_vremu(vbool16_t vm, vuint64m4_t vs2, vuint64m4_t vs1,
                          size_t vl);
vuint64m4_t __riscv_vremu(vbool16_t vm, vuint64m4_t vs2, uint64_t rs1,
                          size_t vl);
vuint64m8_t __riscv_vremu(vbool8_t vm, vuint64m8_t vs2, vuint64m8_t vs1,
                          size_t vl);
vuint64m8_t __riscv_vremu(vbool8_t vm, vuint64m8_t vs2, uint64_t rs1,
                          size_t vl);
----

[[overloaded-vector-widening-integer-multiply]]
==== Vector Widening Integer Multiply Intrinsics

[,c]
----
vint16mf4_t __riscv_vwmul(vint8mf8_t vs2, vint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwmul(vint8mf8_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwmul(vint8mf4_t vs2, vint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwmul(vint8mf4_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwmul(vint8mf2_t vs2, vint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwmul(vint8mf2_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwmul(vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwmul(vint8m1_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwmul(vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwmul(vint8m2_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwmul(vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwmul(vint8m4_t vs2, int8_t rs1, size_t vl);
vint32mf2_t __riscv_vwmul(vint16mf4_t vs2, vint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwmul(vint16mf4_t vs2, int16_t rs1, size_t vl);
vint32m1_t __riscv_vwmul(vint16mf2_t vs2, vint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwmul(vint16mf2_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwmul(vint16m1_t vs2, vint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwmul(vint16m1_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwmul(vint16m2_t vs2, vint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwmul(vint16m2_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwmul(vint16m4_t vs2, vint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwmul(vint16m4_t vs2, int16_t rs1, size_t vl);
vint64m1_t __riscv_vwmul(vint32mf2_t vs2, vint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwmul(vint32mf2_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwmul(vint32m1_t vs2, vint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwmul(vint32m1_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwmul(vint32m2_t vs2, vint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwmul(vint32m2_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwmul(vint32m4_t vs2, vint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwmul(vint32m4_t vs2, int32_t rs1, size_t vl);
vint16mf4_t __riscv_vwmulsu(vint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vint16mf4_t __riscv_vwmulsu(vint8mf8_t vs2, uint8_t rs1, size_t vl);
vint16mf2_t __riscv_vwmulsu(vint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vwmulsu(vint8mf4_t vs2, uint8_t rs1, size_t vl);
vint16m1_t __riscv_vwmulsu(vint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vint16m1_t __riscv_vwmulsu(vint8mf2_t vs2, uint8_t rs1, size_t vl);
vint16m2_t __riscv_vwmulsu(vint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwmulsu(vint8m1_t vs2, uint8_t rs1, size_t vl);
vint16m4_t __riscv_vwmulsu(vint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwmulsu(vint8m2_t vs2, uint8_t rs1, size_t vl);
vint16m8_t __riscv_vwmulsu(vint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwmulsu(vint8m4_t vs2, uint8_t rs1, size_t vl);
vint32mf2_t __riscv_vwmulsu(vint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vint32mf2_t __riscv_vwmulsu(vint16mf4_t vs2, uint16_t rs1, size_t vl);
vint32m1_t __riscv_vwmulsu(vint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vint32m1_t __riscv_vwmulsu(vint16mf2_t vs2, uint16_t rs1, size_t vl);
vint32m2_t __riscv_vwmulsu(vint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vint32m2_t __riscv_vwmulsu(vint16m1_t vs2, uint16_t rs1, size_t vl);
vint32m4_t __riscv_vwmulsu(vint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vint32m4_t __riscv_vwmulsu(vint16m2_t vs2, uint16_t rs1, size_t vl);
vint32m8_t __riscv_vwmulsu(vint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vint32m8_t __riscv_vwmulsu(vint16m4_t vs2, uint16_t rs1, size_t vl);
vint64m1_t __riscv_vwmulsu(vint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vint64m1_t __riscv_vwmulsu(vint32mf2_t vs2, uint32_t rs1, size_t vl);
vint64m2_t __riscv_vwmulsu(vint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vint64m2_t __riscv_vwmulsu(vint32m1_t vs2, uint32_t rs1, size_t vl);
vint64m4_t __riscv_vwmulsu(vint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vint64m4_t __riscv_vwmulsu(vint32m2_t vs2, uint32_t rs1, size_t vl);
vint64m8_t __riscv_vwmulsu(vint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vint64m8_t __riscv_vwmulsu(vint32m4_t vs2, uint32_t rs1, size_t vl);
vuint16mf4_t __riscv_vwmulu(vuint8mf8_t vs2, vuint8mf8_t vs1, size_t vl);
vuint16mf4_t __riscv_vwmulu(vuint8mf8_t vs2, uint8_t rs1, size_t vl);
vuint16mf2_t __riscv_vwmulu(vuint8mf4_t vs2, vuint8mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vwmulu(vuint8mf4_t vs2, uint8_t rs1, size_t vl);
vuint16m1_t __riscv_vwmulu(vuint8mf2_t vs2, vuint8mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vwmulu(vuint8mf2_t vs2, uint8_t rs1, size_t vl);
vuint16m2_t __riscv_vwmulu(vuint8m1_t vs2, vuint8m1_t vs1, size_t vl);
vuint16m2_t __riscv_vwmulu(vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwmulu(vuint8m2_t vs2, vuint8m2_t vs1, size_t vl);
vuint16m4_t __riscv_vwmulu(vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwmulu(vuint8m4_t vs2, vuint8m4_t vs1, size_t vl);
vuint16m8_t __riscv_vwmulu(vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint32mf2_t __riscv_vwmulu(vuint16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vuint32mf2_t __riscv_vwmulu(vuint16mf4_t vs2, uint16_t rs1, size_t vl);
vuint32m1_t __riscv_vwmulu(vuint16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vwmulu(vuint16mf2_t vs2, uint16_t rs1, size_t vl);
vuint32m2_t __riscv_vwmulu(vuint16m1_t vs2, vuint16m1_t vs1, size_t vl);
vuint32m2_t __riscv_vwmulu(vuint16m1_t vs2, uint16_t rs1, size_t vl);
vuint32m4_t __riscv_vwmulu(vuint16m2_t vs2, vuint16m2_t vs1, size_t vl);
vuint32m4_t __riscv_vwmulu(vuint16m2_t vs2, uint16_t rs1, size_t vl);
vuint32m8_t __riscv_vwmulu(vuint16m4_t vs2, vuint16m4_t vs1, size_t vl);
vuint32m8_t __riscv_vwmulu(vuint16m4_t vs2, uint16_t rs1, size_t vl);
vuint64m1_t __riscv_vwmulu(vuint32mf2_t vs2, vuint32mf2_t vs1, size_t vl);
vuint64m1_t __riscv_vwmulu(vuint32mf2_t vs2, uint32_t rs1, size_t vl);
vuint64m2_t __riscv_vwmulu(vuint32m1_t vs2, vuint32m1_t vs1, size_t vl);
vuint64m2_t __riscv_vwmulu(vuint32m1_t vs2, uint32_t rs1, size_t vl);
vuint64m4_t __riscv_vwmulu(vuint32m2_t vs2, vuint32m2_t vs1, size_t vl);
vuint64m4_t __riscv_vwmulu(vuint32m2_t vs2, uint32_t rs1, size_t vl);
vuint64m8_t __riscv_vwmulu(vuint32m4_t vs2, vuint32m4_t vs1, size_t vl);
vuint64m8_t __riscv_vwmulu(vuint32m4_t vs2, uint32_t rs1, size_t vl);
// masked functions
vint16mf4_t __riscv_vwmul(vbool64_t vm, vint8mf8_t vs2, vint8mf8_t vs1,
                          size_t vl);
vint16mf4_t __riscv_vwmul(vbool64_t vm, vint8mf8_t vs2, int8_t rs1, size_t vl);
vint16mf2_t __riscv_vwmul(vbool32_t vm, vint8mf4_t vs2, vint8mf4_t vs1,
                          size_t vl);
vint16mf2_t __riscv_vwmul(vbool32_t vm, vint8mf4_t vs2, int8_t rs1, size_t vl);
vint16m1_t __riscv_vwmul(vbool16_t vm, vint8mf2_t vs2, vint8mf2_t vs1,
                         size_t vl);
vint16m1_t __riscv_vwmul(vbool16_t vm, vint8mf2_t vs2, int8_t rs1, size_t vl);
vint16m2_t __riscv_vwmul(vbool8_t vm, vint8m1_t vs2, vint8m1_t vs1, size_t vl);
vint16m2_t __riscv_vwmul(vbool8_t vm, vint8m1_t vs2, int8_t rs1, size_t vl);
vint16m4_t __riscv_vwmul(vbool4_t vm, vint8m2_t vs2, vint8m2_t vs1, size_t vl);
vint16m4_t __riscv_vwmul(vbool4_t vm, vint8m2_t vs2, int8_t rs1, size_t vl);
vint16m8_t __riscv_vwmul(vbool2_t vm, vint8m4_t vs2, vint8m4_t vs1, size_t vl);
vint16m8_t __riscv_vwmul(vbool2_t vm, vint8m4_t vs2, int8_t rs1, size_t vl);
vint32mf2_t __riscv_vwmul(vbool64_t vm, vint16mf4_t vs2, vint16mf4_t vs1,
                          size_t vl);
vint32mf2_t __riscv_vwmul(vbool64_t vm, vint16mf4_t vs2, int16_t rs1,
                          size_t vl);
vint32m1_t __riscv_vwmul(vbool32_t vm, vint16mf2_t vs2, vint16mf2_t vs1,
                         size_t vl);
vint32m1_t __riscv_vwmul(vbool32_t vm, vint16mf2_t vs2, int16_t rs1, size_t vl);
vint32m2_t __riscv_vwmul(vbool16_t vm, vint16m1_t vs2, vint16m1_t vs1,
                         size_t vl);
vint32m2_t __riscv_vwmul(vbool16_t vm, vint16m1_t vs2, int16_t rs1, size_t vl);
vint32m4_t __riscv_vwmul(vbool8_t vm, vint16m2_t vs2, vint16m2_t vs1,
                         size_t vl);
vint32m4_t __riscv_vwmul(vbool8_t vm, vint16m2_t vs2, int16_t rs1, size_t vl);
vint32m8_t __riscv_vwmul(vbool4_t vm, vint16m4_t vs2, vint16m4_t vs1,
                         size_t vl);
vint32m8_t __riscv_vwmul(vbool4_t vm, vint16m4_t vs2, int16_t rs1, size_t vl);
vint64m1_t __riscv_vwmul(vbool64_t vm, vint32mf2_t vs2, vint32mf2_t vs1,
                         size_t vl);
vint64m1_t __riscv_vwmul(vbool64_t vm, vint32mf2_t vs2, int32_t rs1, size_t vl);
vint64m2_t __riscv_vwmul(vbool32_t vm, vint32m1_t vs2, vint32m1_t vs1,
                         size_t vl);
vint64m2_t __riscv_vwmul(vbool32_t vm, vint32m1_t vs2, int32_t rs1, size_t vl);
vint64m4_t __riscv_vwmul(vbool16_t vm, vint32m2_t vs2, vint32m2_t vs1,
                         size_t vl);
vint64m4_t __riscv_vwmul(vbool16_t vm, vint32m2_t vs2, int32_t rs1, size_t vl);
vint64m8_t __riscv_vwmul(vbool8_t vm, vint32m4_t vs2, vint32m4_t vs1,
                         size_t vl);
vint64m8_t __riscv_vwmul(vbool8_t vm, vint32m4_t vs2, int32_t rs1, size_t vl);
vint16mf4_t __riscv_vwmulsu(vbool64_t vm, vint8mf8_t vs2, vuint8mf8_t vs1,
                            size_t vl);
vint16mf4_t __riscv_vwmulsu(vbool64_t vm, vint8mf8_t vs2, uint8_t rs1,
                            size_t vl);
vint16mf2_t __riscv_vwmulsu(vbool32_t vm, vint8mf4_t vs2, vuint8mf4_t vs1,
                            size_t vl);
vint16mf2_t __riscv_vwmulsu(vbool32_t vm, vint8mf4_t vs2, uint8_t rs1,
                            size_t vl);
vint16m1_t __riscv_vwmulsu(vbool16_t vm, vint8mf2_t vs2, vuint8mf2_t vs1,
                           size_t vl);
vint16m1_t __riscv_vwmulsu(vbool16_t vm, vint8mf2_t vs2, uint8_t rs1,
                           size_t vl);
vint16m2_t __riscv_vwmulsu(vbool8_t vm, vint8m1_t vs2, vuint8m1_t vs1,
                           size_t vl);
vint16m2_t __riscv_vwmulsu(vbool8_t vm, vint8m1_t vs2, uint8_t rs1, size_t vl);
vint16m4_t __riscv_vwmulsu(vbool4_t vm, vint8m2_t vs2, vuint8m2_t vs1,
                           size_t vl);
vint16m4_t __riscv_vwmulsu(vbool4_t vm, vint8m2_t vs2, uint8_t rs1, size_t vl);
vint16m8_t __riscv_vwmulsu(vbool2_t vm, vint8m4_t vs2, vuint8m4_t vs1,
                           size_t vl);
vint16m8_t __riscv_vwmulsu(vbool2_t vm, vint8m4_t vs2, uint8_t rs1, size_t vl);
vint32mf2_t __riscv_vwmulsu(vbool64_t vm, vint16mf4_t vs2, vuint16mf4_t vs1,
                            size_t vl);
vint32mf2_t __riscv_vwmulsu(vbool64_t vm, vint16mf4_t vs2, uint16_t rs1,
                            size_t vl);
vint32m1_t __riscv_vwmulsu(vbool32_t vm, vint16mf2_t vs2, vuint16mf2_t vs1,
                           size_t vl);
vint32m1_t __riscv_vwmulsu(vbool32_t vm, vint16mf2_t vs2, uint16_t rs1,
                           size_t vl);
vint32m2_t __riscv_vwmulsu(vbool16_t vm, vint16m1_t vs2, vuint16m1_t vs1,
                           size_t vl);
vint32m2_t __riscv_vwmulsu(vbool16_t vm, vint16m1_t vs2, uint16_t rs1,
                           size_t vl);
vint32m4_t __riscv_vwmulsu(vbool8_t vm, vint16m2_t vs2, vuint16m2_t vs1,
                           size_t vl);
vint32m4_t __riscv_vwmulsu(vbool8_t vm, vint16m2_t vs2, uint16_t rs1,
                           size_t vl);
vint32m8_t __riscv_vwmulsu(vbool4_t vm, vint16m4_t vs2, vuint16m4_t vs1,
                           size_t vl);
vint32m8_t __riscv_vwmulsu(vbool4_t vm, vint16m4_t vs2, uint16_t rs1,
                           size_t vl);
vint64m1_t __riscv_vwmulsu(vbool64_t vm, vint32mf2_t vs2, vuint32mf2_t vs1,
                           size_t vl);
vint64m1_t __riscv_vwmulsu(vbool64_t vm, vint32mf2_t vs2, uint32_t rs1,
                           size_t vl);
vint64m2_t __riscv_vwmulsu(vbool32_t vm, vint32m1_t vs2, vuint32m1_t vs1,
                           size_t vl);
vint64m2_t __riscv_vwmulsu(vbool32_t vm, vint32m1_t vs2, uint32_t rs1,
                           size_t vl);
vint64m4_t __riscv_vwmulsu(vbool16_t vm, vint32m2_t vs2, vuint32m2_t vs1,
                           size_t vl);
vint64m4_t __riscv_vwmulsu(vbool16_t vm, vint32m2_t vs2, uint32_t rs1,
                           size_t vl);
vint64m8_t __riscv_vwmulsu(vbool8_t vm, vint32m4_t vs2, vuint32m4_t vs1,
                           size_t vl);
vint64m8_t __riscv_vwmulsu(vbool8_t vm, vint32m4_t vs2, uint32_t rs1,
                           size_t vl);
vuint16mf4_t __riscv_vwmulu(vbool64_t vm, vuint8mf8_t vs2, vuint8mf8_t vs1,
                            size_t vl);
vuint16mf4_t __riscv_vwmulu(vbool64_t vm, vuint8mf8_t vs2, uint8_t rs1,
                            size_t vl);
vuint16mf2_t __riscv_vwmulu(vbool32_t vm, vuint8mf4_t vs2, vuint8mf4_t vs1,
                            size_t vl);
vuint16mf2_t __riscv_vwmulu(vbool32_t vm, vuint8mf4_t vs2, uint8_t rs1,
                            size_t vl);
vuint16m1_t __riscv_vwmulu(vbool16_t vm, vuint8mf2_t vs2, vuint8mf2_t vs1,
                           size_t vl);
vuint16m1_t __riscv_vwmulu(vbool16_t vm, vuint8mf2_t vs2, uint8_t rs1,
                           size_t vl);
vuint16m2_t __riscv_vwmulu(vbool8_t vm, vuint8m1_t vs2, vuint8m1_t vs1,
                           size_t vl);
vuint16m2_t __riscv_vwmulu(vbool8_t vm, vuint8m1_t vs2, uint8_t rs1, size_t vl);
vuint16m4_t __riscv_vwmulu(vbool4_t vm, vuint8m2_t vs2, vuint8m2_t vs1,
                           size_t vl);
vuint16m4_t __riscv_vwmulu(vbool4_t vm, vuint8m2_t vs2, uint8_t rs1, size_t vl);
vuint16m8_t __riscv_vwmulu(vbool2_t vm, vuint8m4_t vs2, vuint8m4_t vs1,
                           size_t vl);
vuint16m8_t __riscv_vwmulu(vbool2_t vm, vuint8m4_t vs2, uint8_t rs1, size_t vl);
vuint32mf2_t __riscv_vwmulu(vbool64_t vm, vuint16mf4_t vs2, vuint16mf4_t vs1,
                            size_t vl);
vuint32mf2_t __riscv_vwmulu(vbool64_t vm, vuint16mf4_t vs2, uint16_t rs1,
                            size_t vl);
vuint32m1_t __riscv_vwmulu(vbool32_t vm, vuint16mf2_t vs2, vuint16mf2_t vs1,
                           size_t vl);
vuint32m1_t __riscv_vwmulu(vbool32_t vm, vuint16mf2_t vs2, uint16_t rs1,
                           size_t vl);
vuint32m2_t __riscv_vwmulu(vbool16_t vm, vuint16m1_t vs2, vuint16m1_t vs1,
                           size_t vl);
vuint32m2_t __riscv_vwmulu(vbool16_t vm, vuint16m1_t vs2, uint16_t rs1,
                           size_t vl);
vuint32m4_t __riscv_vwmulu(vbool8_t vm, vuint16m2_t vs2, vuint16m2_t vs1,
                           size_t vl);
vuint32m4_t __riscv_vwmulu(vbool8_t vm, vuint16m2_t vs2, uint16_t rs1,
                           size_t vl);
vuint32m8_t __riscv_vwmulu(vbool4_t vm, vuint16m4_t vs2, vuint16m4_t vs1,
                           size_t vl);
vuint32m8_t __riscv_vwmulu(vbool4_t vm, vuint16m4_t vs2, uint16_t rs1,
                           size_t vl);
vuint64m1_t __riscv_vwmulu(vbool64_t vm, vuint32mf2_t vs2, vuint32mf2_t vs1,
                           size_t vl);
vuint64m1_t __riscv_vwmulu(vbool64_t vm, vuint32mf2_t vs2, uint32_t rs1,
                           size_t vl);
vuint64m2_t __riscv_vwmulu(vbool32_t vm, vuint32m1_t vs2, vuint32m1_t vs1,
                           size_t vl);
vuint64m2_t __riscv_vwmulu(vbool32_t vm, vuint32m1_t vs2, uint32_t rs1,
                           size_t vl);
vuint64m4_t __riscv_vwmulu(vbool16_t vm, vuint32m2_t vs2, vuint32m2_t vs1,
                           size_t vl);
vuint64m4_t __riscv_vwmulu(vbool16_t vm, vuint32m2_t vs2, uint32_t rs1,
                           size_t vl);
vuint64m8_t __riscv_vwmulu(vbool8_t vm, vuint32m4_t vs2, vuint32m4_t vs1,
                           size_t vl);
vuint64m8_t __riscv_vwmulu(vbool8_t vm, vuint32m4_t vs2, uint32_t rs1,
                           size_t vl);
----

[[overloaded-vector-single-width-integer-multiply-add]]
==== Vector Single-Width Integer Multiply-Add Intrinsics

[,c]
----
vint8mf8_t __riscv_vmacc(vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2,
                         size_t vl);
vint8mf8_t __riscv_vmacc(vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc(vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2,
                         size_t vl);
vint8mf4_t __riscv_vmacc(vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc(vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2,
                         size_t vl);
vint8mf2_t __riscv_vmacc(vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmacc(vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmacc(vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmacc(vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmacc(vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmacc(vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmacc(vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmacc(vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmacc(vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc(vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2,
                          size_t vl);
vint16mf4_t __riscv_vmacc(vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2,
                          size_t vl);
vint16mf2_t __riscv_vmacc(vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2,
                          size_t vl);
vint16mf2_t __riscv_vmacc(vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2,
                          size_t vl);
vint16m1_t __riscv_vmacc(vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2,
                         size_t vl);
vint16m1_t __riscv_vmacc(vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmacc(vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2,
                         size_t vl);
vint16m2_t __riscv_vmacc(vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmacc(vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2,
                         size_t vl);
vint16m4_t __riscv_vmacc(vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmacc(vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2,
                         size_t vl);
vint16m8_t __riscv_vmacc(vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc(vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2,
                          size_t vl);
vint32mf2_t __riscv_vmacc(vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2,
                          size_t vl);
vint32m1_t __riscv_vmacc(vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2,
                         size_t vl);
vint32m1_t __riscv_vmacc(vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmacc(vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2,
                         size_t vl);
vint32m2_t __riscv_vmacc(vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmacc(vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2,
                         size_t vl);
vint32m4_t __riscv_vmacc(vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmacc(vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2,
                         size_t vl);
vint32m8_t __riscv_vmacc(vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmacc(vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2,
                         size_t vl);
vint64m1_t __riscv_vmacc(vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmacc(vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2,
                         size_t vl);
vint64m2_t __riscv_vmacc(vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmacc(vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2,
                         size_t vl);
vint64m4_t __riscv_vmacc(vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmacc(vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2,
                         size_t vl);
vint64m8_t __riscv_vmacc(vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac(vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2,
                          size_t vl);
vint8mf8_t __riscv_vnmsac(vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac(vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2,
                          size_t vl);
vint8mf4_t __riscv_vnmsac(vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac(vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2,
                          size_t vl);
vint8mf2_t __riscv_vnmsac(vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac(vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac(vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac(vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac(vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac(vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac(vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac(vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac(vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac(vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2,
                           size_t vl);
vint16mf4_t __riscv_vnmsac(vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2,
                           size_t vl);
vint16mf2_t __riscv_vnmsac(vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2,
                           size_t vl);
vint16mf2_t __riscv_vnmsac(vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2,
                           size_t vl);
vint16m1_t __riscv_vnmsac(vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2,
                          size_t vl);
vint16m1_t __riscv_vnmsac(vint16m1_t vd, int16_t rs1, vint16m1_t vs2,
                          size_t vl);
vint16m2_t __riscv_vnmsac(vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2,
                          size_t vl);
vint16m2_t __riscv_vnmsac(vint16m2_t vd, int16_t rs1, vint16m2_t vs2,
                          size_t vl);
vint16m4_t __riscv_vnmsac(vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2,
                          size_t vl);
vint16m4_t __riscv_vnmsac(vint16m4_t vd, int16_t rs1, vint16m4_t vs2,
                          size_t vl);
vint16m8_t __riscv_vnmsac(vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2,
                          size_t vl);
vint16m8_t __riscv_vnmsac(vint16m8_t vd, int16_t rs1, vint16m8_t vs2,
                          size_t vl);
vint32mf2_t __riscv_vnmsac(vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2,
                           size_t vl);
vint32mf2_t __riscv_vnmsac(vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2,
                           size_t vl);
vint32m1_t __riscv_vnmsac(vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2,
                          size_t vl);
vint32m1_t __riscv_vnmsac(vint32m1_t vd, int32_t rs1, vint32m1_t vs2,
                          size_t vl);
vint32m2_t __riscv_vnmsac(vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2,
                          size_t vl);
vint32m2_t __riscv_vnmsac(vint32m2_t vd, int32_t rs1, vint32m2_t vs2,
                          size_t vl);
vint32m4_t __riscv_vnmsac(vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2,
                          size_t vl);
vint32m4_t __riscv_vnmsac(vint32m4_t vd, int32_t rs1, vint32m4_t vs2,
                          size_t vl);
vint32m8_t __riscv_vnmsac(vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2,
                          size_t vl);
vint32m8_t __riscv_vnmsac(vint32m8_t vd, int32_t rs1, vint32m8_t vs2,
                          size_t vl);
vint64m1_t __riscv_vnmsac(vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2,
                          size_t vl);
vint64m1_t __riscv_vnmsac(vint64m1_t vd, int64_t rs1, vint64m1_t vs2,
                          size_t vl);
vint64m2_t __riscv_vnmsac(vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2,
                          size_t vl);
vint64m2_t __riscv_vnmsac(vint64m2_t vd, int64_t rs1, vint64m2_t vs2,
                          size_t vl);
vint64m4_t __riscv_vnmsac(vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2,
                          size_t vl);
vint64m4_t __riscv_vnmsac(vint64m4_t vd, int64_t rs1, vint64m4_t vs2,
                          size_t vl);
vint64m8_t __riscv_vnmsac(vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2,
                          size_t vl);
vint64m8_t __riscv_vnmsac(vint64m8_t vd, int64_t rs1, vint64m8_t vs2,
                          size_t vl);
vint8mf8_t __riscv_vmadd(vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2,
                         size_t vl);
vint8mf8_t __riscv_vmadd(vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd(vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2,
                         size_t vl);
vint8mf4_t __riscv_vmadd(vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd(vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2,
                         size_t vl);
vint8mf2_t __riscv_vmadd(vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmadd(vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmadd(vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmadd(vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmadd(vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmadd(vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmadd(vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmadd(vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmadd(vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd(vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2,
                          size_t vl);
vint16mf4_t __riscv_vmadd(vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2,
                          size_t vl);
vint16mf2_t __riscv_vmadd(vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2,
                          size_t vl);
vint16mf2_t __riscv_vmadd(vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2,
                          size_t vl);
vint16m1_t __riscv_vmadd(vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2,
                         size_t vl);
vint16m1_t __riscv_vmadd(vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmadd(vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2,
                         size_t vl);
vint16m2_t __riscv_vmadd(vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmadd(vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2,
                         size_t vl);
vint16m4_t __riscv_vmadd(vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmadd(vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2,
                         size_t vl);
vint16m8_t __riscv_vmadd(vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd(vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2,
                          size_t vl);
vint32mf2_t __riscv_vmadd(vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2,
                          size_t vl);
vint32m1_t __riscv_vmadd(vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2,
                         size_t vl);
vint32m1_t __riscv_vmadd(vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmadd(vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2,
                         size_t vl);
vint32m2_t __riscv_vmadd(vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmadd(vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2,
                         size_t vl);
vint32m4_t __riscv_vmadd(vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmadd(vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2,
                         size_t vl);
vint32m8_t __riscv_vmadd(vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmadd(vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2,
                         size_t vl);
vint64m1_t __riscv_vmadd(vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmadd(vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2,
                         size_t vl);
vint64m2_t __riscv_vmadd(vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmadd(vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2,
                         size_t vl);
vint64m4_t __riscv_vmadd(vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmadd(vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2,
                         size_t vl);
vint64m8_t __riscv_vmadd(vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub(vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2,
                          size_t vl);
vint8mf8_t __riscv_vnmsub(vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub(vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2,
                          size_t vl);
vint8mf4_t __riscv_vnmsub(vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub(vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2,
                          size_t vl);
vint8mf2_t __riscv_vnmsub(vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub(vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub(vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub(vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub(vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub(vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub(vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub(vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub(vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub(vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2,
                           size_t vl);
vint16mf4_t __riscv_vnmsub(vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2,
                           size_t vl);
vint16mf2_t __riscv_vnmsub(vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2,
                           size_t vl);
vint16mf2_t __riscv_vnmsub(vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2,
                           size_t vl);
vint16m1_t __riscv_vnmsub(vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2,
                          size_t vl);
vint16m1_t __riscv_vnmsub(vint16m1_t vd, int16_t rs1, vint16m1_t vs2,
                          size_t vl);
vint16m2_t __riscv_vnmsub(vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2,
                          size_t vl);
vint16m2_t __riscv_vnmsub(vint16m2_t vd, int16_t rs1, vint16m2_t vs2,
                          size_t vl);
vint16m4_t __riscv_vnmsub(vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2,
                          size_t vl);
vint16m4_t __riscv_vnmsub(vint16m4_t vd, int16_t rs1, vint16m4_t vs2,
                          size_t vl);
vint16m8_t __riscv_vnmsub(vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2,
                          size_t vl);
vint16m8_t __riscv_vnmsub(vint16m8_t vd, int16_t rs1, vint16m8_t vs2,
                          size_t vl);
vint32mf2_t __riscv_vnmsub(vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2,
                           size_t vl);
vint32mf2_t __riscv_vnmsub(vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2,
                           size_t vl);
vint32m1_t __riscv_vnmsub(vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2,
                          size_t vl);
vint32m1_t __riscv_vnmsub(vint32m1_t vd, int32_t rs1, vint32m1_t vs2,
                          size_t vl);
vint32m2_t __riscv_vnmsub(vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2,
                          size_t vl);
vint32m2_t __riscv_vnmsub(vint32m2_t vd, int32_t rs1, vint32m2_t vs2,
                          size_t vl);
vint32m4_t __riscv_vnmsub(vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2,
                          size_t vl);
vint32m4_t __riscv_vnmsub(vint32m4_t vd, int32_t rs1, vint32m4_t vs2,
                          size_t vl);
vint32m8_t __riscv_vnmsub(vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2,
                          size_t vl);
vint32m8_t __riscv_vnmsub(vint32m8_t vd, int32_t rs1, vint32m8_t vs2,
                          size_t vl);
vint64m1_t __riscv_vnmsub(vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2,
                          size_t vl);
vint64m1_t __riscv_vnmsub(vint64m1_t vd, int64_t rs1, vint64m1_t vs2,
                          size_t vl);
vint64m2_t __riscv_vnmsub(vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2,
                          size_t vl);
vint64m2_t __riscv_vnmsub(vint64m2_t vd, int64_t rs1, vint64m2_t vs2,
                          size_t vl);
vint64m4_t __riscv_vnmsub(vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2,
                          size_t vl);
vint64m4_t __riscv_vnmsub(vint64m4_t vd, int64_t rs1, vint64m4_t vs2,
                          size_t vl);
vint64m8_t __riscv_vnmsub(vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2,
                          size_t vl);
vint64m8_t __riscv_vnmsub(vint64m8_t vd, int64_t rs1, vint64m8_t vs2,
                          size_t vl);
vuint8mf8_t __riscv_vmacc(vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2,
                          size_t vl);
vuint8mf8_t __riscv_vmacc(vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2,
                          size_t vl);
vuint8mf4_t __riscv_vmacc(vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2,
                          size_t vl);
vuint8mf4_t __riscv_vmacc(vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2,
                          size_t vl);
vuint8mf2_t __riscv_vmacc(vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2,
                          size_t vl);
vuint8mf2_t __riscv_vmacc(vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2,
                          size_t vl);
vuint8m1_t __riscv_vmacc(vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2,
                         size_t vl);
vuint8m1_t __riscv_vmacc(vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc(vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2,
                         size_t vl);
vuint8m2_t __riscv_vmacc(vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc(vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2,
                         size_t vl);
vuint8m4_t __riscv_vmacc(vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc(vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2,
                         size_t vl);
vuint8m8_t __riscv_vmacc(vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc(vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2,
                           size_t vl);
vuint16mf4_t __riscv_vmacc(vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2,
                           size_t vl);
vuint16mf2_t __riscv_vmacc(vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2,
                           size_t vl);
vuint16mf2_t __riscv_vmacc(vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2,
                           size_t vl);
vuint16m1_t __riscv_vmacc(vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2,
                          size_t vl);
vuint16m1_t __riscv_vmacc(vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2,
                          size_t vl);
vuint16m2_t __riscv_vmacc(vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2,
                          size_t vl);
vuint16m2_t __riscv_vmacc(vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2,
                          size_t vl);
vuint16m4_t __riscv_vmacc(vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2,
                          size_t vl);
vuint16m4_t __riscv_vmacc(vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2,
                          size_t vl);
vuint16m8_t __riscv_vmacc(vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2,
                          size_t vl);
vuint16m8_t __riscv_vmacc(vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2,
                          size_t vl);
vuint32mf2_t __riscv_vmacc(vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2,
                           size_t vl);
vuint32mf2_t __riscv_vmacc(vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2,
                           size_t vl);
vuint32m1_t __riscv_vmacc(vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2,
                          size_t vl);
vuint32m1_t __riscv_vmacc(vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2,
                          size_t vl);
vuint32m2_t __riscv_vmacc(vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2,
                          size_t vl);
vuint32m2_t __riscv_vmacc(vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2,
                          size_t vl);
vuint32m4_t __riscv_vmacc(vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2,
                          size_t vl);
vuint32m4_t __riscv_vmacc(vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2,
                          size_t vl);
vuint32m8_t __riscv_vmacc(vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2,
                          size_t vl);
vuint32m8_t __riscv_vmacc(vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2,
                          size_t vl);
vuint64m1_t __riscv_vmacc(vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2,
                          size_t vl);
vuint64m1_t __riscv_vmacc(vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2,
                          size_t vl);
vuint64m2_t __riscv_vmacc(vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2,
                          size_t vl);
vuint64m2_t __riscv_vmacc(vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2,
                          size_t vl);
vuint64m4_t __riscv_vmacc(vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2,
                          size_t vl);
vuint64m4_t __riscv_vmacc(vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2,
                          size_t vl);
vuint64m8_t __riscv_vmacc(vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2,
                          size_t vl);
vuint64m8_t __riscv_vmacc(vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2,
                          size_t vl);
vuint8mf8_t __riscv_vnmsac(vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2,
                           size_t vl);
vuint8mf8_t __riscv_vnmsac(vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2,
                           size_t vl);
vuint8mf4_t __riscv_vnmsac(vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2,
                           size_t vl);
vuint8mf4_t __riscv_vnmsac(vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2,
                           size_t vl);
vuint8mf2_t __riscv_vnmsac(vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2,
                           size_t vl);
vuint8mf2_t __riscv_vnmsac(vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2,
                           size_t vl);
vuint8m1_t __riscv_vnmsac(vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2,
                          size_t vl);
vuint8m1_t __riscv_vnmsac(vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2,
                          size_t vl);
vuint8m2_t __riscv_vnmsac(vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2,
                          size_t vl);
vuint8m2_t __riscv_vnmsac(vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2,
                          size_t vl);
vuint8m4_t __riscv_vnmsac(vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2,
                          size_t vl);
vuint8m4_t __riscv_vnmsac(vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2,
                          size_t vl);
vuint8m8_t __riscv_vnmsac(vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2,
                          size_t vl);
vuint8m8_t __riscv_vnmsac(vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2,
                          size_t vl);
vuint16mf4_t __riscv_vnmsac(vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2,
                            size_t vl);
vuint16mf4_t __riscv_vnmsac(vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2,
                            size_t vl);
vuint16mf2_t __riscv_vnmsac(vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2,
                            size_t vl);
vuint16mf2_t __riscv_vnmsac(vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2,
                            size_t vl);
vuint16m1_t __riscv_vnmsac(vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2,
                           size_t vl);
vuint16m1_t __riscv_vnmsac(vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2,
                           size_t vl);
vuint16m2_t __riscv_vnmsac(vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2,
                           size_t vl);
vuint16m2_t __riscv_vnmsac(vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2,
                           size_t vl);
vuint16m4_t __riscv_vnmsac(vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2,
                           size_t vl);
vuint16m4_t __riscv_vnmsac(vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2,
                           size_t vl);
vuint16m8_t __riscv_vnmsac(vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2,
                           size_t vl);
vuint16m8_t __riscv_vnmsac(vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2,
                           size_t vl);
vuint32mf2_t __riscv_vnmsac(vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2,
                            size_t vl);
vuint32mf2_t __riscv_vnmsac(vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2,
                            size_t vl);
vuint32m1_t __riscv_vnmsac(vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2,
                           size_t vl);
vuint32m1_t __riscv_vnmsac(vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2,
                           size_t vl);
vuint32m2_t __riscv_vnmsac(vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2,
                           size_t vl);
vuint32m2_t __riscv_vnmsac(vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2,
                           size_t vl);
vuint32m4_t __riscv_vnmsac(vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2,
                           size_t vl);
vuint32m4_t __riscv_vnmsac(vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2,
                           size_t vl);
vuint32m8_t __riscv_vnmsac(vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2,
                           size_t vl);
vuint32m8_t __riscv_vnmsac(vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2,
                           size_t vl);
vuint64m1_t __riscv_vnmsac(vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2,
                           size_t vl);
vuint64m1_t __riscv_vnmsac(vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2,
                           size_t vl);
vuint64m2_t __riscv_vnmsac(vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2,
                           size_t vl);
vuint64m2_t __riscv_vnmsac(vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2,
                           size_t vl);
vuint64m4_t __riscv_vnmsac(vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2,
                           size_t vl);
vuint64m4_t __riscv_vnmsac(vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2,
                           size_t vl);
vuint64m8_t __riscv_vnmsac(vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2,
                           size_t vl);
vuint64m8_t __riscv_vnmsac(vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2,
                           size_t vl);
vuint8mf8_t __riscv_vmadd(vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2,
                          size_t vl);
vuint8mf8_t __riscv_vmadd(vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2,
                          size_t vl);
vuint8mf4_t __riscv_vmadd(vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2,
                          size_t vl);
vuint8mf4_t __riscv_vmadd(vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2,
                          size_t vl);
vuint8mf2_t __riscv_vmadd(vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2,
                          size_t vl);
vuint8mf2_t __riscv_vmadd(vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2,
                          size_t vl);
vuint8m1_t __riscv_vmadd(vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2,
                         size_t vl);
vuint8m1_t __riscv_vmadd(vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd(vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2,
                         size_t vl);
vuint8m2_t __riscv_vmadd(vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd(vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2,
                         size_t vl);
vuint8m4_t __riscv_vmadd(vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd(vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2,
                         size_t vl);
vuint8m8_t __riscv_vmadd(vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd(vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2,
                           size_t vl);
vuint16mf4_t __riscv_vmadd(vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2,
                           size_t vl);
vuint16mf2_t __riscv_vmadd(vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2,
                           size_t vl);
vuint16mf2_t __riscv_vmadd(vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2,
                           size_t vl);
vuint16m1_t __riscv_vmadd(vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2,
                          size_t vl);
vuint16m1_t __riscv_vmadd(vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2,
                          size_t vl);
vuint16m2_t __riscv_vmadd(vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2,
                          size_t vl);
vuint16m2_t __riscv_vmadd(vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2,
                          size_t vl);
vuint16m4_t __riscv_vmadd(vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2,
                          size_t vl);
vuint16m4_t __riscv_vmadd(vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2,
                          size_t vl);
vuint16m8_t __riscv_vmadd(vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2,
                          size_t vl);
vuint16m8_t __riscv_vmadd(vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2,
                          size_t vl);
vuint32mf2_t __riscv_vmadd(vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2,
                           size_t vl);
vuint32mf2_t __riscv_vmadd(vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2,
                           size_t vl);
vuint32m1_t __riscv_vmadd(vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2,
                          size_t vl);
vuint32m1_t __riscv_vmadd(vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2,
                          size_t vl);
vuint32m2_t __riscv_vmadd(vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2,
                          size_t vl);
vuint32m2_t __riscv_vmadd(vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2,
                          size_t vl);
vuint32m4_t __riscv_vmadd(vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2,
                          size_t vl);
vuint32m4_t __riscv_vmadd(vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2,
                          size_t vl);
vuint32m8_t __riscv_vmadd(vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2,
                          size_t vl);
vuint32m8_t __riscv_vmadd(vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2,
                          size_t vl);
vuint64m1_t __riscv_vmadd(vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2,
                          size_t vl);
vuint64m1_t __riscv_vmadd(vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2,
                          size_t vl);
vuint64m2_t __riscv_vmadd(vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2,
                          size_t vl);
vuint64m2_t __riscv_vmadd(vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2,
                          size_t vl);
vuint64m4_t __riscv_vmadd(vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2,
                          size_t vl);
vuint64m4_t __riscv_vmadd(vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2,
                          size_t vl);
vuint64m8_t __riscv_vmadd(vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2,
                          size_t vl);
vuint64m8_t __riscv_vmadd(vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2,
                          size_t vl);
vuint8mf8_t __riscv_vnmsub(vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2,
                           size_t vl);
vuint8mf8_t __riscv_vnmsub(vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2,
                           size_t vl);
vuint8mf4_t __riscv_vnmsub(vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2,
                           size_t vl);
vuint8mf4_t __riscv_vnmsub(vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2,
                           size_t vl);
vuint8mf2_t __riscv_vnmsub(vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2,
                           size_t vl);
vuint8mf2_t __riscv_vnmsub(vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2,
                           size_t vl);
vuint8m1_t __riscv_vnmsub(vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2,
                          size_t vl);
vuint8m1_t __riscv_vnmsub(vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2,
                          size_t vl);
vuint8m2_t __riscv_vnmsub(vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2,
                          size_t vl);
vuint8m2_t __riscv_vnmsub(vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2,
                          size_t vl);
vuint8m4_t __riscv_vnmsub(vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2,
                          size_t vl);
vuint8m4_t __riscv_vnmsub(vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2,
                          size_t vl);
vuint8m8_t __riscv_vnmsub(vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2,
                          size_t vl);
vuint8m8_t __riscv_vnmsub(vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2,
                          size_t vl);
vuint16mf4_t __riscv_vnmsub(vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2,
                            size_t vl);
vuint16mf4_t __riscv_vnmsub(vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2,
                            size_t vl);
vuint16mf2_t __riscv_vnmsub(vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2,
                            size_t vl);
vuint16mf2_t __riscv_vnmsub(vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2,
                            size_t vl);
vuint16m1_t __riscv_vnmsub(vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2,
                           size_t vl);
vuint16m1_t __riscv_vnmsub(vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2,
                           size_t vl);
vuint16m2_t __riscv_vnmsub(vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2,
                           size_t vl);
vuint16m2_t __riscv_vnmsub(vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2,
                           size_t vl);
vuint16m4_t __riscv_vnmsub(vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2,
                           size_t vl);
vuint16m4_t __riscv_vnmsub(vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2,
                           size_t vl);
vuint16m8_t __riscv_vnmsub(vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2,
                           size_t vl);
vuint16m8_t __riscv_vnmsub(vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2,
                           size_t vl);
vuint32mf2_t __riscv_vnmsub(vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2,
                            size_t vl);
vuint32mf2_t __riscv_vnmsub(vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2,
                            size_t vl);
vuint32m1_t __riscv_vnmsub(vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2,
                           size_t vl);
vuint32m1_t __riscv_vnmsub(vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2,
                           size_t vl);
vuint32m2_t __riscv_vnmsub(vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2,
                           size_t vl);
vuint32m2_t __riscv_vnmsub(vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2,
                           size_t vl);
vuint32m4_t __riscv_vnmsub(vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2,
                           size_t vl);
vuint32m4_t __riscv_vnmsub(vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2,
                           size_t vl);
vuint32m8_t __riscv_vnmsub(vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2,
                           size_t vl);
vuint32m8_t __riscv_vnmsub(vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2,
                           size_t vl);
vuint64m1_t __riscv_vnmsub(vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2,
                           size_t vl);
vuint64m1_t __riscv_vnmsub(vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2,
                           size_t vl);
vuint64m2_t __riscv_vnmsub(vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2,
                           size_t vl);
vuint64m2_t __riscv_vnmsub(vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2,
                           size_t vl);
vuint64m4_t __riscv_vnmsub(vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2,
                           size_t vl);
vuint64m4_t __riscv_vnmsub(vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2,
                           size_t vl);
vuint64m8_t __riscv_vnmsub(vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2,
                           size_t vl);
vuint64m8_t __riscv_vnmsub(vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2,
                           size_t vl);
// masked functions
vint8mf8_t __riscv_vmacc(vbool64_t vm, vint8mf8_t vd, vint8mf8_t vs1,
                         vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmacc(vbool64_t vm, vint8mf8_t vd, int8_t rs1,
                         vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc(vbool32_t vm, vint8mf4_t vd, vint8mf4_t vs1,
                         vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc(vbool32_t vm, vint8mf4_t vd, int8_t rs1,
                         vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc(vbool16_t vm, vint8mf2_t vd, vint8mf2_t vs1,
                         vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc(vbool16_t vm, vint8mf2_t vd, int8_t rs1,
                         vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmacc(vbool8_t vm, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2,
                        size_t vl);
vint8m1_t __riscv_vmacc(vbool8_t vm, vint8m1_t vd, int8_t rs1, vint8m1_t vs2,
                        size_t vl);
vint8m2_t __riscv_vmacc(vbool4_t vm, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2,
                        size_t vl);
vint8m2_t __riscv_vmacc(vbool4_t vm, vint8m2_t vd, int8_t rs1, vint8m2_t vs2,
                        size_t vl);
vint8m4_t __riscv_vmacc(vbool2_t vm, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2,
                        size_t vl);
vint8m4_t __riscv_vmacc(vbool2_t vm, vint8m4_t vd, int8_t rs1, vint8m4_t vs2,
                        size_t vl);
vint8m8_t __riscv_vmacc(vbool1_t vm, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2,
                        size_t vl);
vint8m8_t __riscv_vmacc(vbool1_t vm, vint8m8_t vd, int8_t rs1, vint8m8_t vs2,
                        size_t vl);
vint16mf4_t __riscv_vmacc(vbool64_t vm, vint16mf4_t vd, vint16mf4_t vs1,
                          vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc(vbool64_t vm, vint16mf4_t vd, int16_t rs1,
                          vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc(vbool32_t vm, vint16mf2_t vd, vint16mf2_t vs1,
                          vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc(vbool32_t vm, vint16mf2_t vd, int16_t rs1,
                          vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmacc(vbool16_t vm, vint16m1_t vd, vint16m1_t vs1,
                         vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmacc(vbool16_t vm, vint16m1_t vd, int16_t rs1,
                         vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmacc(vbool8_t vm, vint16m2_t vd, vint16m2_t vs1,
                         vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmacc(vbool8_t vm, vint16m2_t vd, int16_t rs1,
                         vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmacc(vbool4_t vm, vint16m4_t vd, vint16m4_t vs1,
                         vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmacc(vbool4_t vm, vint16m4_t vd, int16_t rs1,
                         vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmacc(vbool2_t vm, vint16m8_t vd, vint16m8_t vs1,
                         vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmacc(vbool2_t vm, vint16m8_t vd, int16_t rs1,
                         vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc(vbool64_t vm, vint32mf2_t vd, vint32mf2_t vs1,
                          vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc(vbool64_t vm, vint32mf2_t vd, int32_t rs1,
                          vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmacc(vbool32_t vm, vint32m1_t vd, vint32m1_t vs1,
                         vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmacc(vbool32_t vm, vint32m1_t vd, int32_t rs1,
                         vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmacc(vbool16_t vm, vint32m2_t vd, vint32m2_t vs1,
                         vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmacc(vbool16_t vm, vint32m2_t vd, int32_t rs1,
                         vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmacc(vbool8_t vm, vint32m4_t vd, vint32m4_t vs1,
                         vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmacc(vbool8_t vm, vint32m4_t vd, int32_t rs1,
                         vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmacc(vbool4_t vm, vint32m8_t vd, vint32m8_t vs1,
                         vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmacc(vbool4_t vm, vint32m8_t vd, int32_t rs1,
                         vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmacc(vbool64_t vm, vint64m1_t vd, vint64m1_t vs1,
                         vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmacc(vbool64_t vm, vint64m1_t vd, int64_t rs1,
                         vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmacc(vbool32_t vm, vint64m2_t vd, vint64m2_t vs1,
                         vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmacc(vbool32_t vm, vint64m2_t vd, int64_t rs1,
                         vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmacc(vbool16_t vm, vint64m4_t vd, vint64m4_t vs1,
                         vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmacc(vbool16_t vm, vint64m4_t vd, int64_t rs1,
                         vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmacc(vbool8_t vm, vint64m8_t vd, vint64m8_t vs1,
                         vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmacc(vbool8_t vm, vint64m8_t vd, int64_t rs1,
                         vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac(vbool64_t vm, vint8mf8_t vd, vint8mf8_t vs1,
                          vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac(vbool64_t vm, vint8mf8_t vd, int8_t rs1,
                          vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac(vbool32_t vm, vint8mf4_t vd, vint8mf4_t vs1,
                          vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac(vbool32_t vm, vint8mf4_t vd, int8_t rs1,
                          vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac(vbool16_t vm, vint8mf2_t vd, vint8mf2_t vs1,
                          vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac(vbool16_t vm, vint8mf2_t vd, int8_t rs1,
                          vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac(vbool8_t vm, vint8m1_t vd, vint8m1_t vs1,
                         vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac(vbool8_t vm, vint8m1_t vd, int8_t rs1, vint8m1_t vs2,
                         size_t vl);
vint8m2_t __riscv_vnmsac(vbool4_t vm, vint8m2_t vd, vint8m2_t vs1,
                         vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac(vbool4_t vm, vint8m2_t vd, int8_t rs1, vint8m2_t vs2,
                         size_t vl);
vint8m4_t __riscv_vnmsac(vbool2_t vm, vint8m4_t vd, vint8m4_t vs1,
                         vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac(vbool2_t vm, vint8m4_t vd, int8_t rs1, vint8m4_t vs2,
                         size_t vl);
vint8m8_t __riscv_vnmsac(vbool1_t vm, vint8m8_t vd, vint8m8_t vs1,
                         vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac(vbool1_t vm, vint8m8_t vd, int8_t rs1, vint8m8_t vs2,
                         size_t vl);
vint16mf4_t __riscv_vnmsac(vbool64_t vm, vint16mf4_t vd, vint16mf4_t vs1,
                           vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac(vbool64_t vm, vint16mf4_t vd, int16_t rs1,
                           vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac(vbool32_t vm, vint16mf2_t vd, vint16mf2_t vs1,
                           vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac(vbool32_t vm, vint16mf2_t vd, int16_t rs1,
                           vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac(vbool16_t vm, vint16m1_t vd, vint16m1_t vs1,
                          vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac(vbool16_t vm, vint16m1_t vd, int16_t rs1,
                          vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac(vbool8_t vm, vint16m2_t vd, vint16m2_t vs1,
                          vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac(vbool8_t vm, vint16m2_t vd, int16_t rs1,
                          vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac(vbool4_t vm, vint16m4_t vd, vint16m4_t vs1,
                          vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac(vbool4_t vm, vint16m4_t vd, int16_t rs1,
                          vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac(vbool2_t vm, vint16m8_t vd, vint16m8_t vs1,
                          vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac(vbool2_t vm, vint16m8_t vd, int16_t rs1,
                          vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac(vbool64_t vm, vint32mf2_t vd, vint32mf2_t vs1,
                           vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac(vbool64_t vm, vint32mf2_t vd, int32_t rs1,
                           vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac(vbool32_t vm, vint32m1_t vd, vint32m1_t vs1,
                          vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac(vbool32_t vm, vint32m1_t vd, int32_t rs1,
                          vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac(vbool16_t vm, vint32m2_t vd, vint32m2_t vs1,
                          vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac(vbool16_t vm, vint32m2_t vd, int32_t rs1,
                          vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac(vbool8_t vm, vint32m4_t vd, vint32m4_t vs1,
                          vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac(vbool8_t vm, vint32m4_t vd, int32_t rs1,
                          vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac(vbool4_t vm, vint32m8_t vd, vint32m8_t vs1,
                          vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac(vbool4_t vm, vint32m8_t vd, int32_t rs1,
                          vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac(vbool64_t vm, vint64m1_t vd, vint64m1_t vs1,
                          vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac(vbool64_t vm, vint64m1_t vd, int64_t rs1,
                          vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac(vbool32_t vm, vint64m2_t vd, vint64m2_t vs1,
                          vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac(vbool32_t vm, vint64m2_t vd, int64_t rs1,
                          vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac(vbool16_t vm, vint64m4_t vd, vint64m4_t vs1,
                          vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac(vbool16_t vm, vint64m4_t vd, int64_t rs1,
                          vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac(vbool8_t vm, vint64m8_t vd, vint64m8_t vs1,
                          vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac(vbool8_t vm, vint64m8_t vd, int64_t rs1,
                          vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd(vbool64_t vm, vint8mf8_t vd, vint8mf8_t vs1,
                         vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd(vbool64_t vm, vint8mf8_t vd, int8_t rs1,
                         vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd(vbool32_t vm, vint8mf4_t vd, vint8mf4_t vs1,
                         vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd(vbool32_t vm, vint8mf4_t vd, int8_t rs1,
                         vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd(vbool16_t vm, vint8mf2_t vd, vint8mf2_t vs1,
                         vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd(vbool16_t vm, vint8mf2_t vd, int8_t rs1,
                         vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmadd(vbool8_t vm, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2,
                        size_t vl);
vint8m1_t __riscv_vmadd(vbool8_t vm, vint8m1_t vd, int8_t rs1, vint8m1_t vs2,
                        size_t vl);
vint8m2_t __riscv_vmadd(vbool4_t vm, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2,
                        size_t vl);
vint8m2_t __riscv_vmadd(vbool4_t vm, vint8m2_t vd, int8_t rs1, vint8m2_t vs2,
                        size_t vl);
vint8m4_t __riscv_vmadd(vbool2_t vm, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2,
                        size_t vl);
vint8m4_t __riscv_vmadd(vbool2_t vm, vint8m4_t vd, int8_t rs1, vint8m4_t vs2,
                        size_t vl);
vint8m8_t __riscv_vmadd(vbool1_t vm, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2,
                        size_t vl);
vint8m8_t __riscv_vmadd(vbool1_t vm, vint8m8_t vd, int8_t rs1, vint8m8_t vs2,
                        size_t vl);
vint16mf4_t __riscv_vmadd(vbool64_t vm, vint16mf4_t vd, vint16mf4_t vs1,
                          vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd(vbool64_t vm, vint16mf4_t vd, int16_t rs1,
                          vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd(vbool32_t vm, vint16mf2_t vd, vint16mf2_t vs1,
                          vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd(vbool32_t vm, vint16mf2_t vd, int16_t rs1,
                          vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmadd(vbool16_t vm, vint16m1_t vd, vint16m1_t vs1,
                         vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmadd(vbool16_t vm, vint16m1_t vd, int16_t rs1,
                         vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmadd(vbool8_t vm, vint16m2_t vd, vint16m2_t vs1,
                         vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmadd(vbool8_t vm, vint16m2_t vd, int16_t rs1,
                         vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmadd(vbool4_t vm, vint16m4_t vd, vint16m4_t vs1,
                         vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmadd(vbool4_t vm, vint16m4_t vd, int16_t rs1,
                         vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmadd(vbool2_t vm, vint16m8_t vd, vint16m8_t vs1,
                         vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmadd(vbool2_t vm, vint16m8_t vd, int16_t rs1,
                         vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd(vbool64_t vm, vint32mf2_t vd, vint32mf2_t vs1,
                          vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd(vbool64_t vm, vint32mf2_t vd, int32_t rs1,
                          vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmadd(vbool32_t vm, vint32m1_t vd, vint32m1_t vs1,
                         vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmadd(vbool32_t vm, vint32m1_t vd, int32_t rs1,
                         vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmadd(vbool16_t vm, vint32m2_t vd, vint32m2_t vs1,
                         vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmadd(vbool16_t vm, vint32m2_t vd, int32_t rs1,
                         vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmadd(vbool8_t vm, vint32m4_t vd, vint32m4_t vs1,
                         vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmadd(vbool8_t vm, vint32m4_t vd, int32_t rs1,
                         vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmadd(vbool4_t vm, vint32m8_t vd, vint32m8_t vs1,
                         vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmadd(vbool4_t vm, vint32m8_t vd, int32_t rs1,
                         vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmadd(vbool64_t vm, vint64m1_t vd, vint64m1_t vs1,
                         vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmadd(vbool64_t vm, vint64m1_t vd, int64_t rs1,
                         vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmadd(vbool32_t vm, vint64m2_t vd, vint64m2_t vs1,
                         vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmadd(vbool32_t vm, vint64m2_t vd, int64_t rs1,
                         vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmadd(vbool16_t vm, vint64m4_t vd, vint64m4_t vs1,
                         vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmadd(vbool16_t vm, vint64m4_t vd, int64_t rs1,
                         vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmadd(vbool8_t vm, vint64m8_t vd, vint64m8_t vs1,
                         vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmadd(vbool8_t vm, vint64m8_t vd, int64_t rs1,
                         vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub(vbool64_t vm, vint8mf8_t vd, vint8mf8_t vs1,
                          vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub(vbool64_t vm, vint8mf8_t vd, int8_t rs1,
                          vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub(vbool32_t vm, vint8mf4_t vd, vint8mf4_t vs1,
                          vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub(vbool32_t vm, vint8mf4_t vd, int8_t rs1,
                          vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub(vbool16_t vm, vint8mf2_t vd, vint8mf2_t vs1,
                          vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub(vbool16_t vm, vint8mf2_t vd, int8_t rs1,
                          vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub(vbool8_t vm, vint8m1_t vd, vint8m1_t vs1,
                         vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub(vbool8_t vm, vint8m1_t vd, int8_t rs1, vint8m1_t vs2,
                         size_t vl);
vint8m2_t __riscv_vnmsub(vbool4_t vm, vint8m2_t vd, vint8m2_t vs1,
                         vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub(vbool4_t vm, vint8m2_t vd, int8_t rs1, vint8m2_t vs2,
                         size_t vl);
vint8m4_t __riscv_vnmsub(vbool2_t vm, vint8m4_t vd, vint8m4_t vs1,
                         vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub(vbool2_t vm, vint8m4_t vd, int8_t rs1, vint8m4_t vs2,
                         size_t vl);
vint8m8_t __riscv_vnmsub(vbool1_t vm, vint8m8_t vd, vint8m8_t vs1,
                         vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub(vbool1_t vm, vint8m8_t vd, int8_t rs1, vint8m8_t vs2,
                         size_t vl);
vint16mf4_t __riscv_vnmsub(vbool64_t vm, vint16mf4_t vd, vint16mf4_t vs1,
                           vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub(vbool64_t vm, vint16mf4_t vd, int16_t rs1,
                           vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub(vbool32_t vm, vint16mf2_t vd, vint16mf2_t vs1,
                           vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub(vbool32_t vm, vint16mf2_t vd, int16_t rs1,
                           vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub(vbool16_t vm, vint16m1_t vd, vint16m1_t vs1,
                          vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub(vbool16_t vm, vint16m1_t vd, int16_t rs1,
                          vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub(vbool8_t vm, vint16m2_t vd, vint16m2_t vs1,
                          vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub(vbool8_t vm, vint16m2_t vd, int16_t rs1,
                          vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub(vbool4_t vm, vint16m4_t vd, vint16m4_t vs1,
                          vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub(vbool4_t vm, vint16m4_t vd, int16_t rs1,
                          vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub(vbool2_t vm, vint16m8_t vd, vint16m8_t vs1,
                          vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub(vbool2_t vm, vint16m8_t vd, int16_t rs1,
                          vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub(vbool64_t vm, vint32mf2_t vd, vint32mf2_t vs1,
                           vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub(vbool64_t vm, vint32mf2_t vd, int32_t rs1,
                           vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub(vbool32_t vm, vint32m1_t vd, vint32m1_t vs1,
                          vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub(vbool32_t vm, vint32m1_t vd, int32_t rs1,
                          vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub(vbool16_t vm, vint32m2_t vd, vint32m2_t vs1,
                          vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub(vbool16_t vm, vint32m2_t vd, int32_t rs1,
                          vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub(vbool8_t vm, vint32m4_t vd, vint32m4_t vs1,
                          vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub(vbool8_t vm, vint32m4_t vd, int32_t rs1,
                          vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub(vbool4_t vm, vint32m8_t vd, vint32m8_t vs1,
                          vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub(vbool4_t vm, vint32m8_t vd, int32_t rs1,
                          vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub(vbool64_t vm, vint64m1_t vd, vint64m1_t vs1,
                          vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub(vbool64_t vm, vint64m1_t vd, int64_t rs1,
                          vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub(vbool32_t vm, vint64m2_t vd, vint64m2_t vs1,
                          vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub(vbool32_t vm, vint64m2_t vd, int64_t rs1,
                          vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub(vbool16_t vm, vint64m4_t vd, vint64m4_t vs1,
                          vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub(vbool16_t vm, vint64m4_t vd, int64_t rs1,
                          vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub(vbool8_t vm, vint64m8_t vd, vint64m8_t vs1,
                          vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub(vbool8_t vm, vint64m8_t vd, int64_t rs1,
                          vint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc(vbool64_t vm, vuint8mf8_t vd, vuint8mf8_t vs1,
                          vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc(vbool64_t vm, vuint8mf8_t vd, uint8_t rs1,
                          vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc(vbool32_t vm, vuint8mf4_t vd, vuint8mf4_t vs1,
                          vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc(vbool32_t vm, vuint8mf4_t vd, uint8_t rs1,
                          vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc(vbool16_t vm, vuint8mf2_t vd, vuint8mf2_t vs1,
                          vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc(vbool16_t vm, vuint8mf2_t vd, uint8_t rs1,
                          vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc(vbool8_t vm, vuint8m1_t vd, vuint8m1_t vs1,
                         vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc(vbool8_t vm, vuint8m1_t vd, uint8_t rs1,
                         vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc(vbool4_t vm, vuint8m2_t vd, vuint8m2_t vs1,
                         vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc(vbool4_t vm, vuint8m2_t vd, uint8_t rs1,
                         vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc(vbool2_t vm, vuint8m4_t vd, vuint8m4_t vs1,
                         vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc(vbool2_t vm, vuint8m4_t vd, uint8_t rs1,
                         vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc(vbool1_t vm, vuint8m8_t vd, vuint8m8_t vs1,
                         vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc(vbool1_t vm, vuint8m8_t vd, uint8_t rs1,
                         vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc(vbool64_t vm, vuint16mf4_t vd, vuint16mf4_t vs1,
                           vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc(vbool64_t vm, vuint16mf4_t vd, uint16_t rs1,
                           vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc(vbool32_t vm, vuint16mf2_t vd, vuint16mf2_t vs1,
                           vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc(vbool32_t vm, vuint16mf2_t vd, uint16_t rs1,
                           vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc(vbool16_t vm, vuint16m1_t vd, vuint16m1_t vs1,
                          vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc(vbool16_t vm, vuint16m1_t vd, uint16_t rs1,
                          vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc(vbool8_t vm, vuint16m2_t vd, vuint16m2_t vs1,
                          vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc(vbool8_t vm, vuint16m2_t vd, uint16_t rs1,
                          vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc(vbool4_t vm, vuint16m4_t vd, vuint16m4_t vs1,
                          vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc(vbool4_t vm, vuint16m4_t vd, uint16_t rs1,
                          vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc(vbool2_t vm, vuint16m8_t vd, vuint16m8_t vs1,
                          vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc(vbool2_t vm, vuint16m8_t vd, uint16_t rs1,
                          vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc(vbool64_t vm, vuint32mf2_t vd, vuint32mf2_t vs1,
                           vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc(vbool64_t vm, vuint32mf2_t vd, uint32_t rs1,
                           vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc(vbool32_t vm, vuint32m1_t vd, vuint32m1_t vs1,
                          vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc(vbool32_t vm, vuint32m1_t vd, uint32_t rs1,
                          vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc(vbool16_t vm, vuint32m2_t vd, vuint32m2_t vs1,
                          vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc(vbool16_t vm, vuint32m2_t vd, uint32_t rs1,
                          vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc(vbool8_t vm, vuint32m4_t vd, vuint32m4_t vs1,
                          vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc(vbool8_t vm, vuint32m4_t vd, uint32_t rs1,
                          vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc(vbool4_t vm, vuint32m8_t vd, vuint32m8_t vs1,
                          vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc(vbool4_t vm, vuint32m8_t vd, uint32_t rs1,
                          vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc(vbool64_t vm, vuint64m1_t vd, vuint64m1_t vs1,
                          vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc(vbool64_t vm, vuint64m1_t vd, uint64_t rs1,
                          vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc(vbool32_t vm, vuint64m2_t vd, vuint64m2_t vs1,
                          vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc(vbool32_t vm, vuint64m2_t vd, uint64_t rs1,
                          vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc(vbool16_t vm, vuint64m4_t vd, vuint64m4_t vs1,
                          vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc(vbool16_t vm, vuint64m4_t vd, uint64_t rs1,
                          vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc(vbool8_t vm, vuint64m8_t vd, vuint64m8_t vs1,
                          vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc(vbool8_t vm, vuint64m8_t vd, uint64_t rs1,
                          vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac(vbool64_t vm, vuint8mf8_t vd, vuint8mf8_t vs1,
                           vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac(vbool64_t vm, vuint8mf8_t vd, uint8_t rs1,
                           vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac(vbool32_t vm, vuint8mf4_t vd, vuint8mf4_t vs1,
                           vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac(vbool32_t vm, vuint8mf4_t vd, uint8_t rs1,
                           vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac(vbool16_t vm, vuint8mf2_t vd, vuint8mf2_t vs1,
                           vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac(vbool16_t vm, vuint8mf2_t vd, uint8_t rs1,
                           vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac(vbool8_t vm, vuint8m1_t vd, vuint8m1_t vs1,
                          vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac(vbool8_t vm, vuint8m1_t vd, uint8_t rs1,
                          vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac(vbool4_t vm, vuint8m2_t vd, vuint8m2_t vs1,
                          vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac(vbool4_t vm, vuint8m2_t vd, uint8_t rs1,
                          vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac(vbool2_t vm, vuint8m4_t vd, vuint8m4_t vs1,
                          vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac(vbool2_t vm, vuint8m4_t vd, uint8_t rs1,
                          vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac(vbool1_t vm, vuint8m8_t vd, vuint8m8_t vs1,
                          vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac(vbool1_t vm, vuint8m8_t vd, uint8_t rs1,
                          vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac(vbool64_t vm, vuint16mf4_t vd, vuint16mf4_t vs1,
                            vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac(vbool64_t vm, vuint16mf4_t vd, uint16_t rs1,
                            vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac(vbool32_t vm, vuint16mf2_t vd, vuint16mf2_t vs1,
                            vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac(vbool32_t vm, vuint16mf2_t vd, uint16_t rs1,
                            vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac(vbool16_t vm, vuint16m1_t vd, vuint16m1_t vs1,
                           vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac(vbool16_t vm, vuint16m1_t vd, uint16_t rs1,
                           vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac(vbool8_t vm, vuint16m2_t vd, vuint16m2_t vs1,
                           vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac(vbool8_t vm, vuint16m2_t vd, uint16_t rs1,
                           vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac(vbool4_t vm, vuint16m4_t vd, vuint16m4_t vs1,
                           vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac(vbool4_t vm, vuint16m4_t vd, uint16_t rs1,
                           vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac(vbool2_t vm, vuint16m8_t vd, vuint16m8_t vs1,
                           vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac(vbool2_t vm, vuint16m8_t vd, uint16_t rs1,
                           vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac(vbool64_t vm, vuint32mf2_t vd, vuint32mf2_t vs1,
                            vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac(vbool64_t vm, vuint32mf2_t vd, uint32_t rs1,
                            vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac(vbool32_t vm, vuint32m1_t vd, vuint32m1_t vs1,
                           vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac(vbool32_t vm, vuint32m1_t vd, uint32_t rs1,
                           vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac(vbool16_t vm, vuint32m2_t vd, vuint32m2_t vs1,
                           vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac(vbool16_t vm, vuint32m2_t vd, uint32_t rs1,
                           vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac(vbool8_t vm, vuint32m4_t vd, vuint32m4_t vs1,
                           vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac(vbool8_t vm, vuint32m4_t vd, uint32_t rs1,
                           vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac(vbool4_t vm, vuint32m8_t vd, vuint32m8_t vs1,
                           vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac(vbool4_t vm, vuint32m8_t vd, uint32_t rs1,
                           vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac(vbool64_t vm, vuint64m1_t vd, vuint64m1_t vs1,
                           vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac(vbool64_t vm, vuint64m1_t vd, uint64_t rs1,
                           vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac(vbool32_t vm, vuint64m2_t vd, vuint64m2_t vs1,
                           vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac(vbool32_t vm, vuint64m2_t vd, uint64_t rs1,
                           vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac(vbool16_t vm, vuint64m4_t vd, vuint64m4_t vs1,
                           vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac(vbool16_t vm, vuint64m4_t vd, uint64_t rs1,
                           vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac(vbool8_t vm, vuint64m8_t vd, vuint64m8_t vs1,
                           vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac(vbool8_t vm, vuint64m8_t vd, uint64_t rs1,
                           vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd(vbool64_t vm, vuint8mf8_t vd, vuint8mf8_t vs1,
                          vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd(vbool64_t vm, vuint8mf8_t vd, uint8_t rs1,
                          vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd(vbool32_t vm, vuint8mf4_t vd, vuint8mf4_t vs1,
                          vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd(vbool32_t vm, vuint8mf4_t vd, uint8_t rs1,
                          vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd(vbool16_t vm, vuint8mf2_t vd, vuint8mf2_t vs1,
                          vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd(vbool16_t vm, vuint8mf2_t vd, uint8_t rs1,
                          vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd(vbool8_t vm, vuint8m1_t vd, vuint8m1_t vs1,
                         vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd(vbool8_t vm, vuint8m1_t vd, uint8_t rs1,
                         vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd(vbool4_t vm, vuint8m2_t vd, vuint8m2_t vs1,
                         vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd(vbool4_t vm, vuint8m2_t vd, uint8_t rs1,
                         vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd(vbool2_t vm, vuint8m4_t vd, vuint8m4_t vs1,
                         vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd(vbool2_t vm, vuint8m4_t vd, uint8_t rs1,
                         vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd(vbool1_t vm, vuint8m8_t vd, vuint8m8_t vs1,
                         vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd(vbool1_t vm, vuint8m8_t vd, uint8_t rs1,
                         vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd(vbool64_t vm, vuint16mf4_t vd, vuint16mf4_t vs1,
                           vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd(vbool64_t vm, vuint16mf4_t vd, uint16_t rs1,
                           vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd(vbool32_t vm, vuint16mf2_t vd, vuint16mf2_t vs1,
                           vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd(vbool32_t vm, vuint16mf2_t vd, uint16_t rs1,
                           vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd(vbool16_t vm, vuint16m1_t vd, vuint16m1_t vs1,
                          vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd(vbool16_t vm, vuint16m1_t vd, uint16_t rs1,
                          vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd(vbool8_t vm, vuint16m2_t vd, vuint16m2_t vs1,
                          vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd(vbool8_t vm, vuint16m2_t vd, uint16_t rs1,
                          vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd(vbool4_t vm, vuint16m4_t vd, vuint16m4_t vs1,
                          vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd(vbool4_t vm, vuint16m4_t vd, uint16_t rs1,
                          vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd(vbool2_t vm, vuint16m8_t vd, vuint16m8_t vs1,
                          vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd(vbool2_t vm, vuint16m8_t vd, uint16_t rs1,
                          vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd(vbool64_t vm, vuint32mf2_t vd, vuint32mf2_t vs1,
                           vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd(vbool64_t vm, vuint32mf2_t vd, uint32_t rs1,
                           vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd(vbool32_t vm, vuint32m1_t vd, vuint32m1_t vs1,
                          vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd(vbool32_t vm, vuint32m1_t vd, uint32_t rs1,
                          vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd(vbool16_t vm, vuint32m2_t vd, vuint32m2_t vs1,
                          vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd(vbool16_t vm, vuint32m2_t vd, uint32_t rs1,
                          vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd(vbool8_t vm, vuint32m4_t vd, vuint32m4_t vs1,
                          vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd(vbool8_t vm, vuint32m4_t vd, uint32_t rs1,
                          vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd(vbool4_t vm, vuint32m8_t vd, vuint32m8_t vs1,
                          vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd(vbool4_t vm, vuint32m8_t vd, uint32_t rs1,
                          vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd(vbool64_t vm, vuint64m1_t vd, vuint64m1_t vs1,
                          vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd(vbool64_t vm, vuint64m1_t vd, uint64_t rs1,
                          vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd(vbool32_t vm, vuint64m2_t vd, vuint64m2_t vs1,
                          vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd(vbool32_t vm, vuint64m2_t vd, uint64_t rs1,
                          vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd(vbool16_t vm, vuint64m4_t vd, vuint64m4_t vs1,
                          vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd(vbool16_t vm, vuint64m4_t vd, uint64_t rs1,
                          vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd(vbool8_t vm, vuint64m8_t vd, vuint64m8_t vs1,
                          vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd(vbool8_t vm, vuint64m8_t vd, uint64_t rs1,
                          vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub(vbool64_t vm, vuint8mf8_t vd, vuint8mf8_t vs1,
                           vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub(vbool64_t vm, vuint8mf8_t vd, uint8_t rs1,
                           vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub(vbool32_t vm, vuint8mf4_t vd, vuint8mf4_t vs1,
                           vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub(vbool32_t vm, vuint8mf4_t vd, uint8_t rs1,
                           vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub(vbool16_t vm, vuint8mf2_t vd, vuint8mf2_t vs1,
                           vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub(vbool16_t vm, vuint8mf2_t vd, uint8_t rs1,
                           vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub(vbool8_t vm, vuint8m1_t vd, vuint8m1_t vs1,
                          vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub(vbool8_t vm, vuint8m1_t vd, uint8_t rs1,
                          vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub(vbool4_t vm, vuint8m2_t vd, vuint8m2_t vs1,
                          vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub(vbool4_t vm, vuint8m2_t vd, uint8_t rs1,
                          vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub(vbool2_t vm, vuint8m4_t vd, vuint8m4_t vs1,
                          vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub(vbool2_t vm, vuint8m4_t vd, uint8_t rs1,
                          vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub(vbool1_t vm, vuint8m8_t vd, vuint8m8_t vs1,
                          vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub(vbool1_t vm, vuint8m8_t vd, uint8_t rs1,
                          vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub(vbool64_t vm, vuint16mf4_t vd, vuint16mf4_t vs1,
                            vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub(vbool64_t vm, vuint16mf4_t vd, uint16_t rs1,
                            vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub(vbool32_t vm, vuint16mf2_t vd, vuint16mf2_t vs1,
                            vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub(vbool32_t vm, vuint16mf2_t vd, uint16_t rs1,
                            vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub(vbool16_t vm, vuint16m1_t vd, vuint16m1_t vs1,
                           vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub(vbool16_t vm, vuint16m1_t vd, uint16_t rs1,
                           vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub(vbool8_t vm, vuint16m2_t vd, vuint16m2_t vs1,
                           vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub(vbool8_t vm, vuint16m2_t vd, uint16_t rs1,
                           vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub(vbool4_t vm, vuint16m4_t vd, vuint16m4_t vs1,
                           vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub(vbool4_t vm, vuint16m4_t vd, uint16_t rs1,
                           vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub(vbool2_t vm, vuint16m8_t vd, vuint16m8_t vs1,
                           vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub(vbool2_t vm, vuint16m8_t vd, uint16_t rs1,
                           vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub(vbool64_t vm, vuint32mf2_t vd, vuint32mf2_t vs1,
                            vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub(vbool64_t vm, vuint32mf2_t vd, uint32_t rs1,
                            vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub(vbool32_t vm, vuint32m1_t vd, vuint32m1_t vs1,
                           vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub(vbool32_t vm, vuint32m1_t vd, uint32_t rs1,
                           vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub(vbool16_t vm, vuint32m2_t vd, vuint32m2_t vs1,
                           vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub(vbool16_t vm, vuint32m2_t vd, uint32_t rs1,
                           vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub(vbool8_t vm, vuint32m4_t vd, vuint32m4_t vs1,
                           vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub(vbool8_t vm, vuint32m4_t vd, uint32_t rs1,
                           vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub(vbool4_t vm, vuint32m8_t vd, vuint32m8_t vs1,
                           vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub(vbool4_t vm, vuint32m8_t vd, uint32_t rs1,
                           vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub(vbool64_t vm, vuint64m1_t vd, vuint64m1_t vs1,
                           vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub(vbool64_t vm, vuint64m1_t vd, uint64_t rs1,
                           vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub(vbool32_t vm, vuint64m2_t vd, vuint64m2_t vs1,
                           vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub(vbool32_t vm, vuint64m2_t vd, uint64_t rs1,
                           vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub(vbool16_t vm, vuint64m4_t vd, vuint64m4_t vs1,
                           vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub(vbool16_t vm, vuint64m4_t vd, uint64_t rs1,
                           vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub(vbool8_t vm, vuint64m8_t vd, vuint64m8_t vs1,
                           vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub(vbool8_t vm, vuint64m8_t vd, uint64_t rs1,
                           vuint64m8_t vs2, size_t vl);
----

[[overloaded-vector-widening-integer-multiply-add]]
==== Vector Widening Integer Multiply-Add Intrinsics

[,c]
----
vint16mf4_t __riscv_vwmacc(vint16mf4_t vd, vint8mf8_t vs1, vint8mf8_t vs2,
                           size_t vl);
vint16mf4_t __riscv_vwmacc(vint16mf4_t vd, int8_t rs1, vint8mf8_t vs2,
                           size_t vl);
vint16mf2_t __riscv_vwmacc(vint16mf2_t vd, vint8mf4_t vs1, vint8mf4_t vs2,
                           size_t vl);
vint16mf2_t __riscv_vwmacc(vint16mf2_t vd, int8_t rs1, vint8mf4_t vs2,
                           size_t vl);
vint16m1_t __riscv_vwmacc(vint16m1_t vd, vint8mf2_t vs1, vint8mf2_t vs2,
                          size_t vl);
vint16m1_t __riscv_vwmacc(vint16m1_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc(vint16m2_t vd, vint8m1_t vs1, vint8m1_t vs2,
                          size_t vl);
vint16m2_t __riscv_vwmacc(vint16m2_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc(vint16m4_t vd, vint8m2_t vs1, vint8m2_t vs2,
                          size_t vl);
vint16m4_t __riscv_vwmacc(vint16m4_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc(vint16m8_t vd, vint8m4_t vs1, vint8m4_t vs2,
                          size_t vl);
vint16m8_t __riscv_vwmacc(vint16m8_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc(vint32mf2_t vd, vint16mf4_t vs1, vint16mf4_t vs2,
                           size_t vl);
vint32mf2_t __riscv_vwmacc(vint32mf2_t vd, int16_t rs1, vint16mf4_t vs2,
                           size_t vl);
vint32m1_t __riscv_vwmacc(vint32m1_t vd, vint16mf2_t vs1, vint16mf2_t vs2,
                          size_t vl);
vint32m1_t __riscv_vwmacc(vint32m1_t vd, int16_t rs1, vint16mf2_t vs2,
                          size_t vl);
vint32m2_t __riscv_vwmacc(vint32m2_t vd, vint16m1_t vs1, vint16m1_t vs2,
                          size_t vl);
vint32m2_t __riscv_vwmacc(vint32m2_t vd, int16_t rs1, vint16m1_t vs2,
                          size_t vl);
vint32m4_t __riscv_vwmacc(vint32m4_t vd, vint16m2_t vs1, vint16m2_t vs2,
                          size_t vl);
vint32m4_t __riscv_vwmacc(vint32m4_t vd, int16_t rs1, vint16m2_t vs2,
                          size_t vl);
vint32m8_t __riscv_vwmacc(vint32m8_t vd, vint16m4_t vs1, vint16m4_t vs2,
                          size_t vl);
vint32m8_t __riscv_vwmacc(vint32m8_t vd, int16_t rs1, vint16m4_t vs2,
                          size_t vl);
vint64m1_t __riscv_vwmacc(vint64m1_t vd, vint32mf2_t vs1, vint32mf2_t vs2,
                          size_t vl);
vint64m1_t __riscv_vwmacc(vint64m1_t vd, int32_t rs1, vint32mf2_t vs2,
                          size_t vl);
vint64m2_t __riscv_vwmacc(vint64m2_t vd, vint32m1_t vs1, vint32m1_t vs2,
                          size_t vl);
vint64m2_t __riscv_vwmacc(vint64m2_t vd, int32_t rs1, vint32m1_t vs2,
                          size_t vl);
vint64m4_t __riscv_vwmacc(vint64m4_t vd, vint32m2_t vs1, vint32m2_t vs2,
                          size_t vl);
vint64m4_t __riscv_vwmacc(vint64m4_t vd, int32_t rs1, vint32m2_t vs2,
                          size_t vl);
vint64m8_t __riscv_vwmacc(vint64m8_t vd, vint32m4_t vs1, vint32m4_t vs2,
                          size_t vl);
vint64m8_t __riscv_vwmacc(vint64m8_t vd, int32_t rs1, vint32m4_t vs2,
                          size_t vl);
vint16mf4_t __riscv_vwmaccsu(vint16mf4_t vd, vint8mf8_t vs1, vuint8mf8_t vs2,
                             size_t vl);
vint16mf4_t __riscv_vwmaccsu(vint16mf4_t vd, int8_t rs1, vuint8mf8_t vs2,
                             size_t vl);
vint16mf2_t __riscv_vwmaccsu(vint16mf2_t vd, vint8mf4_t vs1, vuint8mf4_t vs2,
                             size_t vl);
vint16mf2_t __riscv_vwmaccsu(vint16mf2_t vd, int8_t rs1, vuint8mf4_t vs2,
                             size_t vl);
vint16m1_t __riscv_vwmaccsu(vint16m1_t vd, vint8mf2_t vs1, vuint8mf2_t vs2,
                            size_t vl);
vint16m1_t __riscv_vwmaccsu(vint16m1_t vd, int8_t rs1, vuint8mf2_t vs2,
                            size_t vl);
vint16m2_t __riscv_vwmaccsu(vint16m2_t vd, vint8m1_t vs1, vuint8m1_t vs2,
                            size_t vl);
vint16m2_t __riscv_vwmaccsu(vint16m2_t vd, int8_t rs1, vuint8m1_t vs2,
                            size_t vl);
vint16m4_t __riscv_vwmaccsu(vint16m4_t vd, vint8m2_t vs1, vuint8m2_t vs2,
                            size_t vl);
vint16m4_t __riscv_vwmaccsu(vint16m4_t vd, int8_t rs1, vuint8m2_t vs2,
                            size_t vl);
vint16m8_t __riscv_vwmaccsu(vint16m8_t vd, vint8m4_t vs1, vuint8m4_t vs2,
                            size_t vl);
vint16m8_t __riscv_vwmaccsu(vint16m8_t vd, int8_t rs1, vuint8m4_t vs2,
                            size_t vl);
vint32mf2_t __riscv_vwmaccsu(vint32mf2_t vd, vint16mf4_t vs1, vuint16mf4_t vs2,
                             size_t vl);
vint32mf2_t __riscv_vwmaccsu(vint32mf2_t vd, int16_t rs1, vuint16mf4_t vs2,
                             size_t vl);
vint32m1_t __riscv_vwmaccsu(vint32m1_t vd, vint16mf2_t vs1, vuint16mf2_t vs2,
                            size_t vl);
vint32m1_t __riscv_vwmaccsu(vint32m1_t vd, int16_t rs1, vuint16mf2_t vs2,
                            size_t vl);
vint32m2_t __riscv_vwmaccsu(vint32m2_t vd, vint16m1_t vs1, vuint16m1_t vs2,
                            size_t vl);
vint32m2_t __riscv_vwmaccsu(vint32m2_t vd, int16_t rs1, vuint16m1_t vs2,
                            size_t vl);
vint32m4_t __riscv_vwmaccsu(vint32m4_t vd, vint16m2_t vs1, vuint16m2_t vs2,
                            size_t vl);
vint32m4_t __riscv_vwmaccsu(vint32m4_t vd, int16_t rs1, vuint16m2_t vs2,
                            size_t vl);
vint32m8_t __riscv_vwmaccsu(vint32m8_t vd, vint16m4_t vs1, vuint16m4_t vs2,
                            size_t vl);
vint32m8_t __riscv_vwmaccsu(vint32m8_t vd, int16_t rs1, vuint16m4_t vs2,
                            size_t vl);
vint64m1_t __riscv_vwmaccsu(vint64m1_t vd, vint32mf2_t vs1, vuint32mf2_t vs2,
                            size_t vl);
vint64m1_t __riscv_vwmaccsu(vint64m1_t vd, int32_t rs1, vuint32mf2_t vs2,
                            size_t vl);
vint64m2_t __riscv_vwmaccsu(vint64m2_t vd, vint32m1_t vs1, vuint32m1_t vs2,
                            size_t vl);
vint64m2_t __riscv_vwmaccsu(vint64m2_t vd, int32_t rs1, vuint32m1_t vs2,
                            size_t vl);
vint64m4_t __riscv_vwmaccsu(vint64m4_t vd, vint32m2_t vs1, vuint32m2_t vs2,
                            size_t vl);
vint64m4_t __riscv_vwmaccsu(vint64m4_t vd, int32_t rs1, vuint32m2_t vs2,
                            size_t vl);
vint64m8_t __riscv_vwmaccsu(vint64m8_t vd, vint32m4_t vs1, vuint32m4_t vs2,
                            size_t vl);
vint64m8_t __riscv_vwmaccsu(vint64m8_t vd, int32_t rs1, vuint32m4_t vs2,
                            size_t vl);
vint16mf4_t __riscv_vwmaccus(vint16mf4_t vd, uint8_t rs1, vint8mf8_t vs2,
                             size_t vl);
vint16mf2_t __riscv_vwmaccus(vint16mf2_t vd, uint8_t rs1, vint8mf4_t vs2,
                             size_t vl);
vint16m1_t __riscv_vwmaccus(vint16m1_t vd, uint8_t rs1, vint8mf2_t vs2,
                            size_t vl);
vint16m2_t __riscv_vwmaccus(vint16m2_t vd, uint8_t rs1, vint8m1_t vs2,
                            size_t vl);
vint16m4_t __riscv_vwmaccus(vint16m4_t vd, uint8_t rs1, vint8m2_t vs2,
                            size_t vl);
vint16m8_t __riscv_vwmaccus(vint16m8_t vd, uint8_t rs1, vint8m4_t vs2,
                            size_t vl);
vint32mf2_t __riscv_vwmaccus(vint32mf2_t vd, uint16_t rs1, vint16mf4_t vs2,
                             size_t vl);
vint32m1_t __riscv_vwmaccus(vint32m1_t vd, uint16_t rs1, vint16mf2_t vs2,
                            size_t vl);
vint32m2_t __riscv_vwmaccus(vint32m2_t vd, uint16_t rs1, vint16m1_t vs2,
                            size_t vl);
vint32m4_t __riscv_vwmaccus(vint32m4_t vd, uint16_t rs1, vint16m2_t vs2,
                            size_t vl);
vint32m8_t __riscv_vwmaccus(vint32m8_t vd, uint16_t rs1, vint16m4_t vs2,
                            size_t vl);
vint64m1_t __riscv_vwmaccus(vint64m1_t vd, uint32_t rs1, vint32mf2_t vs2,
                            size_t vl);
vint64m2_t __riscv_vwmaccus(vint64m2_t vd, uint32_t rs1, vint32m1_t vs2,
                            size_t vl);
vint64m4_t __riscv_vwmaccus(vint64m4_t vd, uint32_t rs1, vint32m2_t vs2,
                            size_t vl);
vint64m8_t __riscv_vwmaccus(vint64m8_t vd, uint32_t rs1, vint32m4_t vs2,
                            size_t vl);
vuint16mf4_t __riscv_vwmaccu(vuint16mf4_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2,
                             size_t vl);
vuint16mf4_t __riscv_vwmaccu(vuint16mf4_t vd, uint8_t rs1, vuint8mf8_t vs2,
                             size_t vl);
vuint16mf2_t __riscv_vwmaccu(vuint16mf2_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2,
                             size_t vl);
vuint16mf2_t __riscv_vwmaccu(vuint16mf2_t vd, uint8_t rs1, vuint8mf4_t vs2,
                             size_t vl);
vuint16m1_t __riscv_vwmaccu(vuint16m1_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2,
                            size_t vl);
vuint16m1_t __riscv_vwmaccu(vuint16m1_t vd, uint8_t rs1, vuint8mf2_t vs2,
                            size_t vl);
vuint16m2_t __riscv_vwmaccu(vuint16m2_t vd, vuint8m1_t vs1, vuint8m1_t vs2,
                            size_t vl);
vuint16m2_t __riscv_vwmaccu(vuint16m2_t vd, uint8_t rs1, vuint8m1_t vs2,
                            size_t vl);
vuint16m4_t __riscv_vwmaccu(vuint16m4_t vd, vuint8m2_t vs1, vuint8m2_t vs2,
                            size_t vl);
vuint16m4_t __riscv_vwmaccu(vuint16m4_t vd, uint8_t rs1, vuint8m2_t vs2,
                            size_t vl);
vuint16m8_t __riscv_vwmaccu(vuint16m8_t vd, vuint8m4_t vs1, vuint8m4_t vs2,
                            size_t vl);
vuint16m8_t __riscv_vwmaccu(vuint16m8_t vd, uint8_t rs1, vuint8m4_t vs2,
                            size_t vl);
vuint32mf2_t __riscv_vwmaccu(vuint32mf2_t vd, vuint16mf4_t vs1,
                             vuint16mf4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu(vuint32mf2_t vd, uint16_t rs1, vuint16mf4_t vs2,
                             size_t vl);
vuint32m1_t __riscv_vwmaccu(vuint32m1_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2,
                            size_t vl);
vuint32m1_t __riscv_vwmaccu(vuint32m1_t vd, uint16_t rs1, vuint16mf2_t vs2,
                            size_t vl);
vuint32m2_t __riscv_vwmaccu(vuint32m2_t vd, vuint16m1_t vs1, vuint16m1_t vs2,
                            size_t vl);
vuint32m2_t __riscv_vwmaccu(vuint32m2_t vd, uint16_t rs1, vuint16m1_t vs2,
                            size_t vl);
vuint32m4_t __riscv_vwmaccu(vuint32m4_t vd, vuint16m2_t vs1, vuint16m2_t vs2,
                            size_t vl);
vuint32m4_t __riscv_vwmaccu(vuint32m4_t vd, uint16_t rs1, vuint16m2_t vs2,
                            size_t vl);
vuint32m8_t __riscv_vwmaccu(vuint32m8_t vd, vuint16m4_t vs1, vuint16m4_t vs2,
                            size_t vl);
vuint32m8_t __riscv_vwmaccu(vuint32m8_t vd, uint16_t rs1, vuint16m4_t vs2,
                            size_t vl);
vuint64m1_t __riscv_vwmaccu(vuint64m1_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2,
                            size_t vl);
vuint64m1_t __riscv_vwmaccu(vuint64m1_t vd, uint32_t rs1, vuint32mf2_t vs2,
                            size_t vl);
vuint64m2_t __riscv_vwmaccu(vuint64m2_t vd, vuint32m1_t vs1, vuint32m1_t vs2,
                            size_t vl);
vuint64m2_t __riscv_vwmaccu(vuint64m2_t vd, uint32_t rs1, vuint32m1_t vs2,
                            size_t vl);
vuint64m4_t __riscv_vwmaccu(vuint64m4_t vd, vuint32m2_t vs1, vuint32m2_t vs2,
                            size_t vl);
vuint64m4_t __riscv_vwmaccu(vuint64m4_t vd, uint32_t rs1, vuint32m2_t vs2,
                            size_t vl);
vuint64m8_t __riscv_vwmaccu(vuint64m8_t vd, vuint32m4_t vs1, vuint32m4_t vs2,
                            size_t vl);
vuint64m8_t __riscv_vwmaccu(vuint64m8_t vd, uint32_t rs1, vuint32m4_t vs2,
                            size_t vl);
// masked functions
vint16mf4_t __riscv_vwmacc(vbool64_t vm, vint16mf4_t vd, vint8mf8_t vs1,
                           vint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmacc(vbool64_t vm, vint16mf4_t vd, int8_t rs1,
                           vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc(vbool32_t vm, vint16mf2_t vd, vint8mf4_t vs1,
                           vint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc(vbool32_t vm, vint16mf2_t vd, int8_t rs1,
                           vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc(vbool16_t vm, vint16m1_t vd, vint8mf2_t vs1,
                          vint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc(vbool16_t vm, vint16m1_t vd, int8_t rs1,
                          vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc(vbool8_t vm, vint16m2_t vd, vint8m1_t vs1,
                          vint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc(vbool8_t vm, vint16m2_t vd, int8_t rs1, vint8m1_t vs2,
                          size_t vl);
vint16m4_t __riscv_vwmacc(vbool4_t vm, vint16m4_t vd, vint8m2_t vs1,
                          vint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc(vbool4_t vm, vint16m4_t vd, int8_t rs1, vint8m2_t vs2,
                          size_t vl);
vint16m8_t __riscv_vwmacc(vbool2_t vm, vint16m8_t vd, vint8m4_t vs1,
                          vint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc(vbool2_t vm, vint16m8_t vd, int8_t rs1, vint8m4_t vs2,
                          size_t vl);
vint32mf2_t __riscv_vwmacc(vbool64_t vm, vint32mf2_t vd, vint16mf4_t vs1,
                           vint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc(vbool64_t vm, vint32mf2_t vd, int16_t rs1,
                           vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc(vbool32_t vm, vint32m1_t vd, vint16mf2_t vs1,
                          vint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc(vbool32_t vm, vint32m1_t vd, int16_t rs1,
                          vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc(vbool16_t vm, vint32m2_t vd, vint16m1_t vs1,
                          vint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc(vbool16_t vm, vint32m2_t vd, int16_t rs1,
                          vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc(vbool8_t vm, vint32m4_t vd, vint16m2_t vs1,
                          vint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc(vbool8_t vm, vint32m4_t vd, int16_t rs1,
                          vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc(vbool4_t vm, vint32m8_t vd, vint16m4_t vs1,
                          vint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc(vbool4_t vm, vint32m8_t vd, int16_t rs1,
                          vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc(vbool64_t vm, vint64m1_t vd, vint32mf2_t vs1,
                          vint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc(vbool64_t vm, vint64m1_t vd, int32_t rs1,
                          vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc(vbool32_t vm, vint64m2_t vd, vint32m1_t vs1,
                          vint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc(vbool32_t vm, vint64m2_t vd, int32_t rs1,
                          vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc(vbool16_t vm, vint64m4_t vd, vint32m2_t vs1,
                          vint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc(vbool16_t vm, vint64m4_t vd, int32_t rs1,
                          vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc(vbool8_t vm, vint64m8_t vd, vint32m4_t vs1,
                          vint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc(vbool8_t vm, vint64m8_t vd, int32_t rs1,
                          vint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu(vbool64_t vm, vint16mf4_t vd, vint8mf8_t vs1,
                             vuint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu(vbool64_t vm, vint16mf4_t vd, int8_t rs1,
                             vuint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu(vbool32_t vm, vint16mf2_t vd, vint8mf4_t vs1,
                             vuint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu(vbool32_t vm, vint16mf2_t vd, int8_t rs1,
                             vuint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu(vbool16_t vm, vint16m1_t vd, vint8mf2_t vs1,
                            vuint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu(vbool16_t vm, vint16m1_t vd, int8_t rs1,
                            vuint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu(vbool8_t vm, vint16m2_t vd, vint8m1_t vs1,
                            vuint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu(vbool8_t vm, vint16m2_t vd, int8_t rs1,
                            vuint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu(vbool4_t vm, vint16m4_t vd, vint8m2_t vs1,
                            vuint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu(vbool4_t vm, vint16m4_t vd, int8_t rs1,
                            vuint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu(vbool2_t vm, vint16m8_t vd, vint8m4_t vs1,
                            vuint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu(vbool2_t vm, vint16m8_t vd, int8_t rs1,
                            vuint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu(vbool64_t vm, vint32mf2_t vd, vint16mf4_t vs1,
                             vuint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu(vbool64_t vm, vint32mf2_t vd, int16_t rs1,
                             vuint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu(vbool32_t vm, vint32m1_t vd, vint16mf2_t vs1,
                            vuint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu(vbool32_t vm, vint32m1_t vd, int16_t rs1,
                            vuint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu(vbool16_t vm, vint32m2_t vd, vint16m1_t vs1,
                            vuint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu(vbool16_t vm, vint32m2_t vd, int16_t rs1,
                            vuint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu(vbool8_t vm, vint32m4_t vd, vint16m2_t vs1,
                            vuint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu(vbool8_t vm, vint32m4_t vd, int16_t rs1,
                            vuint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu(vbool4_t vm, vint32m8_t vd, vint16m4_t vs1,
                            vuint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu(vbool4_t vm, vint32m8_t vd, int16_t rs1,
                            vuint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu(vbool64_t vm, vint64m1_t vd, vint32mf2_t vs1,
                            vuint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu(vbool64_t vm, vint64m1_t vd, int32_t rs1,
                            vuint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu(vbool32_t vm, vint64m2_t vd, vint32m1_t vs1,
                            vuint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu(vbool32_t vm, vint64m2_t vd, int32_t rs1,
                            vuint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu(vbool16_t vm, vint64m4_t vd, vint32m2_t vs1,
                            vuint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu(vbool16_t vm, vint64m4_t vd, int32_t rs1,
                            vuint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu(vbool8_t vm, vint64m8_t vd, vint32m4_t vs1,
                            vuint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu(vbool8_t vm, vint64m8_t vd, int32_t rs1,
                            vuint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccus(vbool64_t vm, vint16mf4_t vd, uint8_t rs1,
                             vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccus(vbool32_t vm, vint16mf2_t vd, uint8_t rs1,
                             vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccus(vbool16_t vm, vint16m1_t vd, uint8_t rs1,
                            vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccus(vbool8_t vm, vint16m2_t vd, uint8_t rs1,
                            vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccus(vbool4_t vm, vint16m4_t vd, uint8_t rs1,
                            vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccus(vbool2_t vm, vint16m8_t vd, uint8_t rs1,
                            vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccus(vbool64_t vm, vint32mf2_t vd, uint16_t rs1,
                             vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccus(vbool32_t vm, vint32m1_t vd, uint16_t rs1,
                            vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccus(vbool16_t vm, vint32m2_t vd, uint16_t rs1,
                            vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccus(vbool8_t vm, vint32m4_t vd, uint16_t rs1,
                            vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccus(vbool4_t vm, vint32m8_t vd, uint16_t rs1,
                            vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccus(vbool64_t vm, vint64m1_t vd, uint32_t rs1,
                            vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccus(vbool32_t vm, vint64m2_t vd, uint32_t rs1,
                            vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccus(vbool16_t vm, vint64m4_t vd, uint32_t rs1,
                            vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccus(vbool8_t vm, vint64m8_t vd, uint32_t rs1,
                            vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu(vbool64_t vm, vuint16mf4_t vd, vuint8mf8_t vs1,
                             vuint8mf8_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu(vbool64_t vm, vuint16mf4_t vd, uint8_t rs1,
                             vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu(vbool32_t vm, vuint16mf2_t vd, vuint8mf4_t vs1,
                             vuint8mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu(vbool32_t vm, vuint16mf2_t vd, uint8_t rs1,
                             vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu(vbool16_t vm, vuint16m1_t vd, vuint8mf2_t vs1,
                            vuint8mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu(vbool16_t vm, vuint16m1_t vd, uint8_t rs1,
                            vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu(vbool8_t vm, vuint16m2_t vd, vuint8m1_t vs1,
                            vuint8m1_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu(vbool8_t vm, vuint16m2_t vd, uint8_t rs1,
                            vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu(vbool4_t vm, vuint16m4_t vd, vuint8m2_t vs1,
                            vuint8m2_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu(vbool4_t vm, vuint16m4_t vd, uint8_t rs1,
                            vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu(vbool2_t vm, vuint16m8_t vd, vuint8m4_t vs1,
                            vuint8m4_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu(vbool2_t vm, vuint16m8_t vd, uint8_t rs1,
                            vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu(vbool64_t vm, vuint32mf2_t vd, vuint16mf4_t vs1,
                             vuint16mf4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu(vbool64_t vm, vuint32mf2_t vd, uint16_t rs1,
                             vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu(vbool32_t vm, vuint32m1_t vd, vuint16mf2_t vs1,
                            vuint16mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu(vbool32_t vm, vuint32m1_t vd, uint16_t rs1,
                            vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu(vbool16_t vm, vuint32m2_t vd, vuint16m1_t vs1,
                            vuint16m1_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu(vbool16_t vm, vuint32m2_t vd, uint16_t rs1,
                            vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu(vbool8_t vm, vuint32m4_t vd, vuint16m2_t vs1,
                            vuint16m2_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu(vbool8_t vm, vuint32m4_t vd, uint16_t rs1,
                            vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu(vbool4_t vm, vuint32m8_t vd, vuint16m4_t vs1,
                            vuint16m4_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu(vbool4_t vm, vuint32m8_t vd, uint16_t rs1,
                            vuint16m4_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu(vbool64_t vm, vuint64m1_t vd, vuint32mf2_t vs1,
                            vuint32mf2_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu(vbool64_t vm, vuint64m1_t vd, uint32_t rs1,
                            vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu(vbool32_t vm, vuint64m2_t vd, vuint32m1_t vs1,
                            vuint32m1_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu(vbool32_t vm, vuint64m2_t vd, uint32_t rs1,
                            vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu(vbool16_t vm, vuint64m4_t vd, vuint32m2_t vs1,
                            vuint32m2_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu(vbool16_t vm, vuint64m4_t vd, uint32_t rs1,
                            vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu(vbool8_t vm, vuint64m8_t vd, vuint32m4_t vs1,
                            vuint32m4_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu(vbool8_t vm, vuint64m8_t vd, uint32_t rs1,
                            vuint32m4_t vs2, size_t vl);
----

[[overloaded-vector-integer-merge]]
==== Vector Integer Merge Intrinsics

[,c]
----
vint8mf8_t __riscv_vmerge(vint8mf8_t vs2, vint8mf8_t vs1, vbool64_t v0,
                          size_t vl);
vint8mf8_t __riscv_vmerge(vint8mf8_t vs2, int8_t rs1, vbool64_t v0, size_t vl);
vint8mf4_t __riscv_vmerge(vint8mf4_t vs2, vint8mf4_t vs1, vbool32_t v0,
                          size_t vl);
vint8mf4_t __riscv_vmerge(vint8mf4_t vs2, int8_t rs1, vbool32_t v0, size_t vl);
vint8mf2_t __riscv_vmerge(vint8mf2_t vs2, vint8mf2_t vs1, vbool16_t v0,
                          size_t vl);
vint8mf2_t __riscv_vmerge(vint8mf2_t vs2, int8_t rs1, vbool16_t v0, size_t vl);
vint8m1_t __riscv_vmerge(vint8m1_t vs2, vint8m1_t vs1, vbool8_t v0, size_t vl);
vint8m1_t __riscv_vmerge(vint8m1_t vs2, int8_t rs1, vbool8_t v0, size_t vl);
vint8m2_t __riscv_vmerge(vint8m2_t vs2, vint8m2_t vs1, vbool4_t v0, size_t vl);
vint8m2_t __riscv_vmerge(vint8m2_t vs2, int8_t rs1, vbool4_t v0, size_t vl);
vint8m4_t __riscv_vmerge(vint8m4_t vs2, vint8m4_t vs1, vbool2_t v0, size_t vl);
vint8m4_t __riscv_vmerge(vint8m4_t vs2, int8_t rs1, vbool2_t v0, size_t vl);
vint8m8_t __riscv_vmerge(vint8m8_t vs2, vint8m8_t vs1, vbool1_t v0, size_t vl);
vint8m8_t __riscv_vmerge(vint8m8_t vs2, int8_t rs1, vbool1_t v0, size_t vl);
vint16mf4_t __riscv_vmerge(vint16mf4_t vs2, vint16mf4_t vs1, vbool64_t v0,
                           size_t vl);
vint16mf4_t __riscv_vmerge(vint16mf4_t vs2, int16_t rs1, vbool64_t v0,
                           size_t vl);
vint16mf2_t __riscv_vmerge(vint16mf2_t vs2, vint16mf2_t vs1, vbool32_t v0,
                           size_t vl);
vint16mf2_t __riscv_vmerge(vint16mf2_t vs2, int16_t rs1, vbool32_t v0,
                           size_t vl);
vint16m1_t __riscv_vmerge(vint16m1_t vs2, vint16m1_t vs1, vbool16_t v0,
                          size_t vl);
vint16m1_t __riscv_vmerge(vint16m1_t vs2, int16_t rs1, vbool16_t v0, size_t vl);
vint16m2_t __riscv_vmerge(vint16m2_t vs2, vint16m2_t vs1, vbool8_t v0,
                          size_t vl);
vint16m2_t __riscv_vmerge(vint16m2_t vs2, int16_t rs1, vbool8_t v0, size_t vl);
vint16m4_t __riscv_vmerge(vint16m4_t vs2, vint16m4_t vs1, vbool4_t v0,
                          size_t vl);
vint16m4_t __riscv_vmerge(vint16m4_t vs2, int16_t rs1, vbool4_t v0, size_t vl);
vint16m8_t __riscv_vmerge(vint16m8_t vs2, vint16m8_t vs1, vbool2_t v0,
                          size_t vl);
vint16m8_t __riscv_vmerge(vint16m8_t vs2, int16_t rs1, vbool2_t v0, size_t vl);
vint32mf2_t __riscv_vmerge(vint32mf2_t vs2, vint32mf2_t vs1, vbool64_t v0,
                           size_t vl);
vint32mf2_t __riscv_vmerge(vint32mf2_t vs2, int32_t rs1, vbool64_t v0,
                           size_t vl);
vint32m1_t __riscv_vmerge(vint32m1_t vs2, vint32m1_t vs1, vbool32_t v0,
                          size_t vl);
vint32m1_t __riscv_vmerge(vint32m1_t vs2, int32_t rs1, vbool32_t v0, size_t vl);
vint32m2_t __riscv_vmerge(vint32m2_t vs2, vint32m2_t vs1, vbool16_t v0,
                          size_t vl);
vint32m2_t __riscv_vmerge(vint32m2_t vs2, int32_t rs1, vbool16_t v0, size_t vl);
vint32m4_t __riscv_vmerge(vint32m4_t vs2, vint32m4_t vs1, vbool8_t v0,
                          size_t vl);
vint32m4_t __riscv_vmerge(vint32m4_t vs2, int32_t rs1, vbool8_t v0, size_t vl);
vint32m8_t __riscv_vmerge(vint32m8_t vs2, vint32m8_t vs1, vbool4_t v0,
                          size_t vl);
vint32m8_t __riscv_vmerge(vint32m8_t vs2, int32_t rs1, vbool4_t v0, size_t vl);
vint64m1_t __riscv_vmerge(vint64m1_t vs2, vint64m1_t vs1, vbool64_t v0,
                          size_t vl);
vint64m1_t __riscv_vmerge(vint64m1_t vs2, int64_t rs1, vbool64_t v0, size_t vl);
vint64m2_t __riscv_vmerge(vint64m2_t vs2, vint64m2_t vs1, vbool32_t v0,
                          size_t vl);
vint64m2_t __riscv_vmerge(vint64m2_t vs2, int64_t rs1, vbool32_t v0, size_t vl);
vint64m4_t __riscv_vmerge(vint64m4_t vs2, vint64m4_t vs1, vbool16_t v0,
                          size_t vl);
vint64m4_t __riscv_vmerge(vint64m4_t vs2, int64_t rs1, vbool16_t v0, size_t vl);
vint64m8_t __riscv_vmerge(vint64m8_t vs2, vint64m8_t vs1, vbool8_t v0,
                          size_t vl);
vint64m8_t __riscv_vmerge(vint64m8_t vs2, int64_t rs1, vbool8_t v0, size_t vl);
vuint8mf8_t __riscv_vmerge(vuint8mf8_t vs2, vuint8mf8_t vs1, vbool64_t v0,
                           size_t vl);
vuint8mf8_t __riscv_vmerge(vuint8mf8_t vs2, uint8_t rs1, vbool64_t v0,
                           size_t vl);
vuint8mf4_t __riscv_vmerge(vuint8mf4_t vs2, vuint8mf4_t vs1, vbool32_t v0,
                           size_t vl);
vuint8mf4_t __riscv_vmerge(vuint8mf4_t vs2, uint8_t rs1, vbool32_t v0,
                           size_t vl);
vuint8mf2_t __riscv_vmerge(vuint8mf2_t vs2, vuint8mf2_t vs1, vbool16_t v0,
                           size_t vl);
vuint8mf2_t __riscv_vmerge(vuint8mf2_t vs2, uint8_t rs1, vbool16_t v0,
                           size_t vl);
vuint8m1_t __riscv_vmerge(vuint8m1_t vs2, vuint8m1_t vs1, vbool8_t v0,
                          size_t vl);
vuint8m1_t __riscv_vmerge(vuint8m1_t vs2, uint8_t rs1, vbool8_t v0, size_t vl);
vuint8m2_t __riscv_vmerge(vuint8m2_t vs2, vuint8m2_t vs1, vbool4_t v0,
                          size_t vl);
vuint8m2_t __riscv_vmerge(vuint8m2_t vs2, uint8_t rs1, vbool4_t v0, size_t vl);
vuint8m4_t __riscv_vmerge(vuint8m4_t vs2, vuint8m4_t vs1, vbool2_t v0,
                          size_t vl);
vuint8m4_t __riscv_vmerge(vuint8m4_t vs2, uint8_t rs1, vbool2_t v0, size_t vl);
vuint8m8_t __riscv_vmerge(vuint8m8_t vs2, vuint8m8_t vs1, vbool1_t v0,
                          size_t vl);
vuint8m8_t __riscv_vmerge(vuint8m8_t vs2, uint8_t rs1, vbool1_t v0, size_t vl);
vuint16mf4_t __riscv_vmerge(vuint16mf4_t vs2, vuint16mf4_t vs1, vbool64_t v0,
                            size_t vl);
vuint16mf4_t __riscv_vmerge(vuint16mf4_t vs2, uint16_t rs1, vbool64_t v0,
                            size_t vl);
vuint16mf2_t __riscv_vmerge(vuint16mf2_t vs2, vuint16mf2_t vs1, vbool32_t v0,
                            size_t vl);
vuint16mf2_t __riscv_vmerge(vuint16mf2_t vs2, uint16_t rs1, vbool32_t v0,
                            size_t vl);
vuint16m1_t __riscv_vmerge(vuint16m1_t vs2, vuint16m1_t vs1, vbool16_t v0,
                           size_t vl);
vuint16m1_t __riscv_vmerge(vuint16m1_t vs2, uint16_t rs1, vbool16_t v0,
                           size_t vl);
vuint16m2_t __riscv_vmerge(vuint16m2_t vs2, vuint16m2_t vs1, vbool8_t v0,
                           size_t vl);
vuint16m2_t __riscv_vmerge(vuint16m2_t vs2, uint16_t rs1, vbool8_t v0,
                           size_t vl);
vuint16m4_t __riscv_vmerge(vuint16m4_t vs2, vuint16m4_t vs1, vbool4_t v0,
                           size_t vl);
vuint16m4_t __riscv_vmerge(vuint16m4_t vs2, uint16_t rs1, vbool4_t v0,
                           size_t vl);
vuint16m8_t __riscv_vmerge(vuint16m8_t vs2, vuint16m8_t vs1, vbool2_t v0,
                           size_t vl);
vuint16m8_t __riscv_vmerge(vuint16m8_t vs2, uint16_t rs1, vbool2_t v0,
                           size_t vl);
vuint32mf2_t __riscv_vmerge(vuint32mf2_t vs2, vuint32mf2_t vs1, vbool64_t v0,
                            size_t vl);
vuint32mf2_t __riscv_vmerge(vuint32mf2_t vs2, uint32_t rs1, vbool64_t v0,
                            size_t vl);
vuint32m1_t __riscv_vmerge(vuint32m1_t vs2, vuint32m1_t vs1, vbool32_t v0,
                           size_t vl);
vuint32m1_t __riscv_vmerge(vuint32m1_t vs2, uint32_t rs1, vbool32_t v0,
                           size_t vl);
vuint32m2_t __riscv_vmerge(vuint32m2_t vs2, vuint32m2_t vs1, vbool16_t v0,
                           size_t vl);
vuint32m2_t __riscv_vmerge(vuint32m2_t vs2, uint32_t rs1, vbool16_t v0,
                           size_t vl);
vuint32m4_t __riscv_vmerge(vuint32m4_t vs2, vuint32m4_t vs1, vbool8_t v0,
                           size_t vl);
vuint32m4_t __riscv_vmerge(vuint32m4_t vs2, uint32_t rs1, vbool8_t v0,
                           size_t vl);
vuint32m8_t __riscv_vmerge(vuint32m8_t vs2, vuint32m8_t vs1, vbool4_t v0,
                           size_t vl);
vuint32m8_t __riscv_vmerge(vuint32m8_t vs2, uint32_t rs1, vbool4_t v0,
                           size_t vl);
vuint64m1_t __riscv_vmerge(vuint64m1_t vs2, vuint64m1_t vs1, vbool64_t v0,
                           size_t vl);
vuint64m1_t __riscv_vmerge(vuint64m1_t vs2, uint64_t rs1, vbool64_t v0,
                           size_t vl);
vuint64m2_t __riscv_vmerge(vuint64m2_t vs2, vuint64m2_t vs1, vbool32_t v0,
                           size_t vl);
vuint64m2_t __riscv_vmerge(vuint64m2_t vs2, uint64_t rs1, vbool32_t v0,
                           size_t vl);
vuint64m4_t __riscv_vmerge(vuint64m4_t vs2, vuint64m4_t vs1, vbool16_t v0,
                           size_t vl);
vuint64m4_t __riscv_vmerge(vuint64m4_t vs2, uint64_t rs1, vbool16_t v0,
                           size_t vl);
vuint64m8_t __riscv_vmerge(vuint64m8_t vs2, vuint64m8_t vs1, vbool8_t v0,
                           size_t vl);
vuint64m8_t __riscv_vmerge(vuint64m8_t vs2, uint64_t rs1, vbool8_t v0,
                           size_t vl);
----

[[overloaded-vector-integer-move]]
==== Vector Integer Move Intrinsics

[,c]
----
vint8mf8_t __riscv_vmv_v(vint8mf8_t vs1, size_t vl);
vint8mf4_t __riscv_vmv_v(vint8mf4_t vs1, size_t vl);
vint8mf2_t __riscv_vmv_v(vint8mf2_t vs1, size_t vl);
vint8m1_t __riscv_vmv_v(vint8m1_t vs1, size_t vl);
vint8m2_t __riscv_vmv_v(vint8m2_t vs1, size_t vl);
vint8m4_t __riscv_vmv_v(vint8m4_t vs1, size_t vl);
vint8m8_t __riscv_vmv_v(vint8m8_t vs1, size_t vl);
vint16mf4_t __riscv_vmv_v(vint16mf4_t vs1, size_t vl);
vint16mf2_t __riscv_vmv_v(vint16mf2_t vs1, size_t vl);
vint16m1_t __riscv_vmv_v(vint16m1_t vs1, size_t vl);
vint16m2_t __riscv_vmv_v(vint16m2_t vs1, size_t vl);
vint16m4_t __riscv_vmv_v(vint16m4_t vs1, size_t vl);
vint16m8_t __riscv_vmv_v(vint16m8_t vs1, size_t vl);
vint32mf2_t __riscv_vmv_v(vint32mf2_t vs1, size_t vl);
vint32m1_t __riscv_vmv_v(vint32m1_t vs1, size_t vl);
vint32m2_t __riscv_vmv_v(vint32m2_t vs1, size_t vl);
vint32m4_t __riscv_vmv_v(vint32m4_t vs1, size_t vl);
vint32m8_t __riscv_vmv_v(vint32m8_t vs1, size_t vl);
vint64m1_t __riscv_vmv_v(vint64m1_t vs1, size_t vl);
vint64m2_t __riscv_vmv_v(vint64m2_t vs1, size_t vl);
vint64m4_t __riscv_vmv_v(vint64m4_t vs1, size_t vl);
vint64m8_t __riscv_vmv_v(vint64m8_t vs1, size_t vl);
vuint8mf8_t __riscv_vmv_v(vuint8mf8_t vs1, size_t vl);
vuint8mf4_t __riscv_vmv_v(vuint8mf4_t vs1, size_t vl);
vuint8mf2_t __riscv_vmv_v(vuint8mf2_t vs1, size_t vl);
vuint8m1_t __riscv_vmv_v(vuint8m1_t vs1, size_t vl);
vuint8m2_t __riscv_vmv_v(vuint8m2_t vs1, size_t vl);
vuint8m4_t __riscv_vmv_v(vuint8m4_t vs1, size_t vl);
vuint8m8_t __riscv_vmv_v(vuint8m8_t vs1, size_t vl);
vuint16mf4_t __riscv_vmv_v(vuint16mf4_t vs1, size_t vl);
vuint16mf2_t __riscv_vmv_v(vuint16mf2_t vs1, size_t vl);
vuint16m1_t __riscv_vmv_v(vuint16m1_t vs1, size_t vl);
vuint16m2_t __riscv_vmv_v(vuint16m2_t vs1, size_t vl);
vuint16m4_t __riscv_vmv_v(vuint16m4_t vs1, size_t vl);
vuint16m8_t __riscv_vmv_v(vuint16m8_t vs1, size_t vl);
vuint32mf2_t __riscv_vmv_v(vuint32mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vmv_v(vuint32m1_t vs1, size_t vl);
vuint32m2_t __riscv_vmv_v(vuint32m2_t vs1, size_t vl);
vuint32m4_t __riscv_vmv_v(vuint32m4_t vs1, size_t vl);
vuint32m8_t __riscv_vmv_v(vuint32m8_t vs1, size_t vl);
vuint64m1_t __riscv_vmv_v(vuint64m1_t vs1, size_t vl);
vuint64m2_t __riscv_vmv_v(vuint64m2_t vs1, size_t vl);
vuint64m4_t __riscv_vmv_v(vuint64m4_t vs1, size_t vl);
vuint64m8_t __riscv_vmv_v(vuint64m8_t vs1, size_t vl);
----
