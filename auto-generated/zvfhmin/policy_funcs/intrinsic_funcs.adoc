
=== Float16 Vector Loads and Stores Intrinsics

[[policy-variant-vector-unit-stride-load]]
==== Vector Unit-Stride Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vle16_v_f16mf4_tu(vfloat16mf4_t vd, const _Float16 *rs1,
                                        size_t vl);
vfloat16mf2_t __riscv_vle16_v_f16mf2_tu(vfloat16mf2_t vd, const _Float16 *rs1,
                                        size_t vl);
vfloat16m1_t __riscv_vle16_v_f16m1_tu(vfloat16m1_t vd, const _Float16 *rs1,
                                      size_t vl);
vfloat16m2_t __riscv_vle16_v_f16m2_tu(vfloat16m2_t vd, const _Float16 *rs1,
                                      size_t vl);
vfloat16m4_t __riscv_vle16_v_f16m4_tu(vfloat16m4_t vd, const _Float16 *rs1,
                                      size_t vl);
vfloat16m8_t __riscv_vle16_v_f16m8_tu(vfloat16m8_t vd, const _Float16 *rs1,
                                      size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16_v_f16mf4_tum(vbool64_t vm, vfloat16mf4_t vd,
                                         const _Float16 *rs1, size_t vl);
vfloat16mf2_t __riscv_vle16_v_f16mf2_tum(vbool32_t vm, vfloat16mf2_t vd,
                                         const _Float16 *rs1, size_t vl);
vfloat16m1_t __riscv_vle16_v_f16m1_tum(vbool16_t vm, vfloat16m1_t vd,
                                       const _Float16 *rs1, size_t vl);
vfloat16m2_t __riscv_vle16_v_f16m2_tum(vbool8_t vm, vfloat16m2_t vd,
                                       const _Float16 *rs1, size_t vl);
vfloat16m4_t __riscv_vle16_v_f16m4_tum(vbool4_t vm, vfloat16m4_t vd,
                                       const _Float16 *rs1, size_t vl);
vfloat16m8_t __riscv_vle16_v_f16m8_tum(vbool2_t vm, vfloat16m8_t vd,
                                       const _Float16 *rs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16_v_f16mf4_tumu(vbool64_t vm, vfloat16mf4_t vd,
                                          const _Float16 *rs1, size_t vl);
vfloat16mf2_t __riscv_vle16_v_f16mf2_tumu(vbool32_t vm, vfloat16mf2_t vd,
                                          const _Float16 *rs1, size_t vl);
vfloat16m1_t __riscv_vle16_v_f16m1_tumu(vbool16_t vm, vfloat16m1_t vd,
                                        const _Float16 *rs1, size_t vl);
vfloat16m2_t __riscv_vle16_v_f16m2_tumu(vbool8_t vm, vfloat16m2_t vd,
                                        const _Float16 *rs1, size_t vl);
vfloat16m4_t __riscv_vle16_v_f16m4_tumu(vbool4_t vm, vfloat16m4_t vd,
                                        const _Float16 *rs1, size_t vl);
vfloat16m8_t __riscv_vle16_v_f16m8_tumu(vbool2_t vm, vfloat16m8_t vd,
                                        const _Float16 *rs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16_v_f16mf4_mu(vbool64_t vm, vfloat16mf4_t vd,
                                        const _Float16 *rs1, size_t vl);
vfloat16mf2_t __riscv_vle16_v_f16mf2_mu(vbool32_t vm, vfloat16mf2_t vd,
                                        const _Float16 *rs1, size_t vl);
vfloat16m1_t __riscv_vle16_v_f16m1_mu(vbool16_t vm, vfloat16m1_t vd,
                                      const _Float16 *rs1, size_t vl);
vfloat16m2_t __riscv_vle16_v_f16m2_mu(vbool8_t vm, vfloat16m2_t vd,
                                      const _Float16 *rs1, size_t vl);
vfloat16m4_t __riscv_vle16_v_f16m4_mu(vbool4_t vm, vfloat16m4_t vd,
                                      const _Float16 *rs1, size_t vl);
vfloat16m8_t __riscv_vle16_v_f16m8_mu(vbool2_t vm, vfloat16m8_t vd,
                                      const _Float16 *rs1, size_t vl);
----

[[policy-variant-vector-unit-stride-store]]
==== Vector Unit-Stride Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-strided-load]]
==== Vector Strided Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vlse16_v_f16mf4_tu(vfloat16mf4_t vd, const _Float16 *rs1,
                                         ptrdiff_t rs2, size_t vl);
vfloat16mf2_t __riscv_vlse16_v_f16mf2_tu(vfloat16mf2_t vd, const _Float16 *rs1,
                                         ptrdiff_t rs2, size_t vl);
vfloat16m1_t __riscv_vlse16_v_f16m1_tu(vfloat16m1_t vd, const _Float16 *rs1,
                                       ptrdiff_t rs2, size_t vl);
vfloat16m2_t __riscv_vlse16_v_f16m2_tu(vfloat16m2_t vd, const _Float16 *rs1,
                                       ptrdiff_t rs2, size_t vl);
vfloat16m4_t __riscv_vlse16_v_f16m4_tu(vfloat16m4_t vd, const _Float16 *rs1,
                                       ptrdiff_t rs2, size_t vl);
vfloat16m8_t __riscv_vlse16_v_f16m8_tu(vfloat16m8_t vd, const _Float16 *rs1,
                                       ptrdiff_t rs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vlse16_v_f16mf4_tum(vbool64_t vm, vfloat16mf4_t vd,
                                          const _Float16 *rs1, ptrdiff_t rs2,
                                          size_t vl);
vfloat16mf2_t __riscv_vlse16_v_f16mf2_tum(vbool32_t vm, vfloat16mf2_t vd,
                                          const _Float16 *rs1, ptrdiff_t rs2,
                                          size_t vl);
vfloat16m1_t __riscv_vlse16_v_f16m1_tum(vbool16_t vm, vfloat16m1_t vd,
                                        const _Float16 *rs1, ptrdiff_t rs2,
                                        size_t vl);
vfloat16m2_t __riscv_vlse16_v_f16m2_tum(vbool8_t vm, vfloat16m2_t vd,
                                        const _Float16 *rs1, ptrdiff_t rs2,
                                        size_t vl);
vfloat16m4_t __riscv_vlse16_v_f16m4_tum(vbool4_t vm, vfloat16m4_t vd,
                                        const _Float16 *rs1, ptrdiff_t rs2,
                                        size_t vl);
vfloat16m8_t __riscv_vlse16_v_f16m8_tum(vbool2_t vm, vfloat16m8_t vd,
                                        const _Float16 *rs1, ptrdiff_t rs2,
                                        size_t vl);
// masked functions
vfloat16mf4_t __riscv_vlse16_v_f16mf4_tumu(vbool64_t vm, vfloat16mf4_t vd,
                                           const _Float16 *rs1, ptrdiff_t rs2,
                                           size_t vl);
vfloat16mf2_t __riscv_vlse16_v_f16mf2_tumu(vbool32_t vm, vfloat16mf2_t vd,
                                           const _Float16 *rs1, ptrdiff_t rs2,
                                           size_t vl);
vfloat16m1_t __riscv_vlse16_v_f16m1_tumu(vbool16_t vm, vfloat16m1_t vd,
                                         const _Float16 *rs1, ptrdiff_t rs2,
                                         size_t vl);
vfloat16m2_t __riscv_vlse16_v_f16m2_tumu(vbool8_t vm, vfloat16m2_t vd,
                                         const _Float16 *rs1, ptrdiff_t rs2,
                                         size_t vl);
vfloat16m4_t __riscv_vlse16_v_f16m4_tumu(vbool4_t vm, vfloat16m4_t vd,
                                         const _Float16 *rs1, ptrdiff_t rs2,
                                         size_t vl);
vfloat16m8_t __riscv_vlse16_v_f16m8_tumu(vbool2_t vm, vfloat16m8_t vd,
                                         const _Float16 *rs1, ptrdiff_t rs2,
                                         size_t vl);
// masked functions
vfloat16mf4_t __riscv_vlse16_v_f16mf4_mu(vbool64_t vm, vfloat16mf4_t vd,
                                         const _Float16 *rs1, ptrdiff_t rs2,
                                         size_t vl);
vfloat16mf2_t __riscv_vlse16_v_f16mf2_mu(vbool32_t vm, vfloat16mf2_t vd,
                                         const _Float16 *rs1, ptrdiff_t rs2,
                                         size_t vl);
vfloat16m1_t __riscv_vlse16_v_f16m1_mu(vbool16_t vm, vfloat16m1_t vd,
                                       const _Float16 *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat16m2_t __riscv_vlse16_v_f16m2_mu(vbool8_t vm, vfloat16m2_t vd,
                                       const _Float16 *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat16m4_t __riscv_vlse16_v_f16m4_mu(vbool4_t vm, vfloat16m4_t vd,
                                       const _Float16 *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat16m8_t __riscv_vlse16_v_f16m8_mu(vbool2_t vm, vfloat16m8_t vd,
                                       const _Float16 *rs1, ptrdiff_t rs2,
                                       size_t vl);
----

[[policy-variant-vector-strided-store]]
==== Vector Strided Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-indexed-load]]
==== Vector Indexed Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vloxei16_v_f16mf4_tu(vfloat16mf4_t vd,
                                           const _Float16 *rs1,
                                           vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei16_v_f16mf2_tu(vfloat16mf2_t vd,
                                           const _Float16 *rs1,
                                           vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei16_v_f16m1_tu(vfloat16m1_t vd, const _Float16 *rs1,
                                         vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vloxei16_v_f16m2_tu(vfloat16m2_t vd, const _Float16 *rs1,
                                         vuint16m2_t rs2, size_t vl);
vfloat16m4_t __riscv_vloxei16_v_f16m4_tu(vfloat16m4_t vd, const _Float16 *rs1,
                                         vuint16m4_t rs2, size_t vl);
vfloat16m8_t __riscv_vloxei16_v_f16m8_tu(vfloat16m8_t vd, const _Float16 *rs1,
                                         vuint16m8_t rs2, size_t vl);
vfloat16mf4_t __riscv_vluxei16_v_f16mf4_tu(vfloat16mf4_t vd,
                                           const _Float16 *rs1,
                                           vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei16_v_f16mf2_tu(vfloat16mf2_t vd,
                                           const _Float16 *rs1,
                                           vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei16_v_f16m1_tu(vfloat16m1_t vd, const _Float16 *rs1,
                                         vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vluxei16_v_f16m2_tu(vfloat16m2_t vd, const _Float16 *rs1,
                                         vuint16m2_t rs2, size_t vl);
vfloat16m4_t __riscv_vluxei16_v_f16m4_tu(vfloat16m4_t vd, const _Float16 *rs1,
                                         vuint16m4_t rs2, size_t vl);
vfloat16m8_t __riscv_vluxei16_v_f16m8_tu(vfloat16m8_t vd, const _Float16 *rs1,
                                         vuint16m8_t rs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vloxei16_v_f16mf4_tum(vbool64_t vm, vfloat16mf4_t vd,
                                            const _Float16 *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei16_v_f16mf2_tum(vbool32_t vm, vfloat16mf2_t vd,
                                            const _Float16 *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei16_v_f16m1_tum(vbool16_t vm, vfloat16m1_t vd,
                                          const _Float16 *rs1, vuint16m1_t rs2,
                                          size_t vl);
vfloat16m2_t __riscv_vloxei16_v_f16m2_tum(vbool8_t vm, vfloat16m2_t vd,
                                          const _Float16 *rs1, vuint16m2_t rs2,
                                          size_t vl);
vfloat16m4_t __riscv_vloxei16_v_f16m4_tum(vbool4_t vm, vfloat16m4_t vd,
                                          const _Float16 *rs1, vuint16m4_t rs2,
                                          size_t vl);
vfloat16m8_t __riscv_vloxei16_v_f16m8_tum(vbool2_t vm, vfloat16m8_t vd,
                                          const _Float16 *rs1, vuint16m8_t rs2,
                                          size_t vl);
vfloat16mf4_t __riscv_vluxei16_v_f16mf4_tum(vbool64_t vm, vfloat16mf4_t vd,
                                            const _Float16 *rs1,
                                            vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei16_v_f16mf2_tum(vbool32_t vm, vfloat16mf2_t vd,
                                            const _Float16 *rs1,
                                            vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei16_v_f16m1_tum(vbool16_t vm, vfloat16m1_t vd,
                                          const _Float16 *rs1, vuint16m1_t rs2,
                                          size_t vl);
vfloat16m2_t __riscv_vluxei16_v_f16m2_tum(vbool8_t vm, vfloat16m2_t vd,
                                          const _Float16 *rs1, vuint16m2_t rs2,
                                          size_t vl);
vfloat16m4_t __riscv_vluxei16_v_f16m4_tum(vbool4_t vm, vfloat16m4_t vd,
                                          const _Float16 *rs1, vuint16m4_t rs2,
                                          size_t vl);
vfloat16m8_t __riscv_vluxei16_v_f16m8_tum(vbool2_t vm, vfloat16m8_t vd,
                                          const _Float16 *rs1, vuint16m8_t rs2,
                                          size_t vl);
// masked functions
vfloat16mf4_t __riscv_vloxei16_v_f16mf4_tumu(vbool64_t vm, vfloat16mf4_t vd,
                                             const _Float16 *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei16_v_f16mf2_tumu(vbool32_t vm, vfloat16mf2_t vd,
                                             const _Float16 *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei16_v_f16m1_tumu(vbool16_t vm, vfloat16m1_t vd,
                                           const _Float16 *rs1, vuint16m1_t rs2,
                                           size_t vl);
vfloat16m2_t __riscv_vloxei16_v_f16m2_tumu(vbool8_t vm, vfloat16m2_t vd,
                                           const _Float16 *rs1, vuint16m2_t rs2,
                                           size_t vl);
vfloat16m4_t __riscv_vloxei16_v_f16m4_tumu(vbool4_t vm, vfloat16m4_t vd,
                                           const _Float16 *rs1, vuint16m4_t rs2,
                                           size_t vl);
vfloat16m8_t __riscv_vloxei16_v_f16m8_tumu(vbool2_t vm, vfloat16m8_t vd,
                                           const _Float16 *rs1, vuint16m8_t rs2,
                                           size_t vl);
vfloat16mf4_t __riscv_vluxei16_v_f16mf4_tumu(vbool64_t vm, vfloat16mf4_t vd,
                                             const _Float16 *rs1,
                                             vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei16_v_f16mf2_tumu(vbool32_t vm, vfloat16mf2_t vd,
                                             const _Float16 *rs1,
                                             vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei16_v_f16m1_tumu(vbool16_t vm, vfloat16m1_t vd,
                                           const _Float16 *rs1, vuint16m1_t rs2,
                                           size_t vl);
vfloat16m2_t __riscv_vluxei16_v_f16m2_tumu(vbool8_t vm, vfloat16m2_t vd,
                                           const _Float16 *rs1, vuint16m2_t rs2,
                                           size_t vl);
vfloat16m4_t __riscv_vluxei16_v_f16m4_tumu(vbool4_t vm, vfloat16m4_t vd,
                                           const _Float16 *rs1, vuint16m4_t rs2,
                                           size_t vl);
vfloat16m8_t __riscv_vluxei16_v_f16m8_tumu(vbool2_t vm, vfloat16m8_t vd,
                                           const _Float16 *rs1, vuint16m8_t rs2,
                                           size_t vl);
// masked functions
vfloat16mf4_t __riscv_vloxei16_v_f16mf4_mu(vbool64_t vm, vfloat16mf4_t vd,
                                           const _Float16 *rs1,
                                           vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei16_v_f16mf2_mu(vbool32_t vm, vfloat16mf2_t vd,
                                           const _Float16 *rs1,
                                           vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei16_v_f16m1_mu(vbool16_t vm, vfloat16m1_t vd,
                                         const _Float16 *rs1, vuint16m1_t rs2,
                                         size_t vl);
vfloat16m2_t __riscv_vloxei16_v_f16m2_mu(vbool8_t vm, vfloat16m2_t vd,
                                         const _Float16 *rs1, vuint16m2_t rs2,
                                         size_t vl);
vfloat16m4_t __riscv_vloxei16_v_f16m4_mu(vbool4_t vm, vfloat16m4_t vd,
                                         const _Float16 *rs1, vuint16m4_t rs2,
                                         size_t vl);
vfloat16m8_t __riscv_vloxei16_v_f16m8_mu(vbool2_t vm, vfloat16m8_t vd,
                                         const _Float16 *rs1, vuint16m8_t rs2,
                                         size_t vl);
vfloat16mf4_t __riscv_vluxei16_v_f16mf4_mu(vbool64_t vm, vfloat16mf4_t vd,
                                           const _Float16 *rs1,
                                           vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei16_v_f16mf2_mu(vbool32_t vm, vfloat16mf2_t vd,
                                           const _Float16 *rs1,
                                           vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei16_v_f16m1_mu(vbool16_t vm, vfloat16m1_t vd,
                                         const _Float16 *rs1, vuint16m1_t rs2,
                                         size_t vl);
vfloat16m2_t __riscv_vluxei16_v_f16m2_mu(vbool8_t vm, vfloat16m2_t vd,
                                         const _Float16 *rs1, vuint16m2_t rs2,
                                         size_t vl);
vfloat16m4_t __riscv_vluxei16_v_f16m4_mu(vbool4_t vm, vfloat16m4_t vd,
                                         const _Float16 *rs1, vuint16m4_t rs2,
                                         size_t vl);
vfloat16m8_t __riscv_vluxei16_v_f16m8_mu(vbool2_t vm, vfloat16m8_t vd,
                                         const _Float16 *rs1, vuint16m8_t rs2,
                                         size_t vl);
----

[[policy-variant-vector-indexed-store]]
==== Vector Indexed Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-unit-stride-fault-only-first-loads]]
==== Unit-stride Fault-Only-First Loads Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vle16ff_v_f16mf4_tu(vfloat16mf4_t vd, const _Float16 *rs1,
                                          size_t *new_vl, size_t vl);
vfloat16mf2_t __riscv_vle16ff_v_f16mf2_tu(vfloat16mf2_t vd, const _Float16 *rs1,
                                          size_t *new_vl, size_t vl);
vfloat16m1_t __riscv_vle16ff_v_f16m1_tu(vfloat16m1_t vd, const _Float16 *rs1,
                                        size_t *new_vl, size_t vl);
vfloat16m2_t __riscv_vle16ff_v_f16m2_tu(vfloat16m2_t vd, const _Float16 *rs1,
                                        size_t *new_vl, size_t vl);
vfloat16m4_t __riscv_vle16ff_v_f16m4_tu(vfloat16m4_t vd, const _Float16 *rs1,
                                        size_t *new_vl, size_t vl);
vfloat16m8_t __riscv_vle16ff_v_f16m8_tu(vfloat16m8_t vd, const _Float16 *rs1,
                                        size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16ff_v_f16mf4_tum(vbool64_t vm, vfloat16mf4_t vd,
                                           const _Float16 *rs1, size_t *new_vl,
                                           size_t vl);
vfloat16mf2_t __riscv_vle16ff_v_f16mf2_tum(vbool32_t vm, vfloat16mf2_t vd,
                                           const _Float16 *rs1, size_t *new_vl,
                                           size_t vl);
vfloat16m1_t __riscv_vle16ff_v_f16m1_tum(vbool16_t vm, vfloat16m1_t vd,
                                         const _Float16 *rs1, size_t *new_vl,
                                         size_t vl);
vfloat16m2_t __riscv_vle16ff_v_f16m2_tum(vbool8_t vm, vfloat16m2_t vd,
                                         const _Float16 *rs1, size_t *new_vl,
                                         size_t vl);
vfloat16m4_t __riscv_vle16ff_v_f16m4_tum(vbool4_t vm, vfloat16m4_t vd,
                                         const _Float16 *rs1, size_t *new_vl,
                                         size_t vl);
vfloat16m8_t __riscv_vle16ff_v_f16m8_tum(vbool2_t vm, vfloat16m8_t vd,
                                         const _Float16 *rs1, size_t *new_vl,
                                         size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16ff_v_f16mf4_tumu(vbool64_t vm, vfloat16mf4_t vd,
                                            const _Float16 *rs1, size_t *new_vl,
                                            size_t vl);
vfloat16mf2_t __riscv_vle16ff_v_f16mf2_tumu(vbool32_t vm, vfloat16mf2_t vd,
                                            const _Float16 *rs1, size_t *new_vl,
                                            size_t vl);
vfloat16m1_t __riscv_vle16ff_v_f16m1_tumu(vbool16_t vm, vfloat16m1_t vd,
                                          const _Float16 *rs1, size_t *new_vl,
                                          size_t vl);
vfloat16m2_t __riscv_vle16ff_v_f16m2_tumu(vbool8_t vm, vfloat16m2_t vd,
                                          const _Float16 *rs1, size_t *new_vl,
                                          size_t vl);
vfloat16m4_t __riscv_vle16ff_v_f16m4_tumu(vbool4_t vm, vfloat16m4_t vd,
                                          const _Float16 *rs1, size_t *new_vl,
                                          size_t vl);
vfloat16m8_t __riscv_vle16ff_v_f16m8_tumu(vbool2_t vm, vfloat16m8_t vd,
                                          const _Float16 *rs1, size_t *new_vl,
                                          size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16ff_v_f16mf4_mu(vbool64_t vm, vfloat16mf4_t vd,
                                          const _Float16 *rs1, size_t *new_vl,
                                          size_t vl);
vfloat16mf2_t __riscv_vle16ff_v_f16mf2_mu(vbool32_t vm, vfloat16mf2_t vd,
                                          const _Float16 *rs1, size_t *new_vl,
                                          size_t vl);
vfloat16m1_t __riscv_vle16ff_v_f16m1_mu(vbool16_t vm, vfloat16m1_t vd,
                                        const _Float16 *rs1, size_t *new_vl,
                                        size_t vl);
vfloat16m2_t __riscv_vle16ff_v_f16m2_mu(vbool8_t vm, vfloat16m2_t vd,
                                        const _Float16 *rs1, size_t *new_vl,
                                        size_t vl);
vfloat16m4_t __riscv_vle16ff_v_f16m4_mu(vbool4_t vm, vfloat16m4_t vd,
                                        const _Float16 *rs1, size_t *new_vl,
                                        size_t vl);
vfloat16m8_t __riscv_vle16ff_v_f16m8_mu(vbool2_t vm, vfloat16m8_t vd,
                                        const _Float16 *rs1, size_t *new_vl,
                                        size_t vl);
----

=== Float16 Vector Loads and Stores Segment Intrinsics

[[policy-variant-vector-unit-stride-segment-load]]
==== Vector Unit-Stride Segment Load Intrinsics

[,c]
----
vfloat16mf4x2_t __riscv_vlseg2e16_v_f16mf4x2_tu(vfloat16mf4x2_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_v_f16mf4x3_tu(vfloat16mf4x3_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_v_f16mf4x4_tu(vfloat16mf4x4_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_v_f16mf4x5_tu(vfloat16mf4x5_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_v_f16mf4x6_tu(vfloat16mf4x6_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_v_f16mf4x7_tu(vfloat16mf4x7_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_v_f16mf4x8_tu(vfloat16mf4x8_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_v_f16mf2x2_tu(vfloat16mf2x2_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_v_f16mf2x3_tu(vfloat16mf2x3_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_v_f16mf2x4_tu(vfloat16mf2x4_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_v_f16mf2x5_tu(vfloat16mf2x5_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_v_f16mf2x6_tu(vfloat16mf2x6_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_v_f16mf2x7_tu(vfloat16mf2x7_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_v_f16mf2x8_tu(vfloat16mf2x8_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_v_f16m1x2_tu(vfloat16m1x2_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_v_f16m1x3_tu(vfloat16m1x3_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_v_f16m1x4_tu(vfloat16m1x4_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_v_f16m1x5_tu(vfloat16m1x5_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_v_f16m1x6_tu(vfloat16m1x6_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_v_f16m1x7_tu(vfloat16m1x7_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_v_f16m1x8_tu(vfloat16m1x8_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_v_f16m2x2_tu(vfloat16m2x2_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_v_f16m2x3_tu(vfloat16m2x3_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_v_f16m2x4_tu(vfloat16m2x4_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_v_f16m4x2_tu(vfloat16m4x2_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_v_f16mf4x2_tu(vfloat16mf4x2_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_v_f16mf4x3_tu(vfloat16mf4x3_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_v_f16mf4x4_tu(vfloat16mf4x4_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_v_f16mf4x5_tu(vfloat16mf4x5_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_v_f16mf4x6_tu(vfloat16mf4x6_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_v_f16mf4x7_tu(vfloat16mf4x7_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_v_f16mf4x8_tu(vfloat16mf4x8_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_v_f16mf2x2_tu(vfloat16mf2x2_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_v_f16mf2x3_tu(vfloat16mf2x3_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_v_f16mf2x4_tu(vfloat16mf2x4_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_v_f16mf2x5_tu(vfloat16mf2x5_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_v_f16mf2x6_tu(vfloat16mf2x6_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_v_f16mf2x7_tu(vfloat16mf2x7_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_v_f16mf2x8_tu(vfloat16mf2x8_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_v_f16m1x2_tu(vfloat16m1x2_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_v_f16m1x3_tu(vfloat16m1x3_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_v_f16m1x4_tu(vfloat16m1x4_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_v_f16m1x5_tu(vfloat16m1x5_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_v_f16m1x6_tu(vfloat16m1x6_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_v_f16m1x7_tu(vfloat16m1x7_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_v_f16m1x8_tu(vfloat16m1x8_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_v_f16m2x2_tu(vfloat16m2x2_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_v_f16m2x3_tu(vfloat16m2x3_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_v_f16m2x4_tu(vfloat16m2x4_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_v_f16m4x2_tu(vfloat16m4x2_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_v_f16mf4x2_tum(vbool64_t vm,
                                                 vfloat16mf4x2_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_v_f16mf4x3_tum(vbool64_t vm,
                                                 vfloat16mf4x3_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_v_f16mf4x4_tum(vbool64_t vm,
                                                 vfloat16mf4x4_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_v_f16mf4x5_tum(vbool64_t vm,
                                                 vfloat16mf4x5_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_v_f16mf4x6_tum(vbool64_t vm,
                                                 vfloat16mf4x6_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_v_f16mf4x7_tum(vbool64_t vm,
                                                 vfloat16mf4x7_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_v_f16mf4x8_tum(vbool64_t vm,
                                                 vfloat16mf4x8_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_v_f16mf2x2_tum(vbool32_t vm,
                                                 vfloat16mf2x2_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_v_f16mf2x3_tum(vbool32_t vm,
                                                 vfloat16mf2x3_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_v_f16mf2x4_tum(vbool32_t vm,
                                                 vfloat16mf2x4_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_v_f16mf2x5_tum(vbool32_t vm,
                                                 vfloat16mf2x5_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_v_f16mf2x6_tum(vbool32_t vm,
                                                 vfloat16mf2x6_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_v_f16mf2x7_tum(vbool32_t vm,
                                                 vfloat16mf2x7_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_v_f16mf2x8_tum(vbool32_t vm,
                                                 vfloat16mf2x8_t vd,
                                                 const _Float16 *rs1,
                                                 size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_v_f16m1x2_tum(vbool16_t vm, vfloat16m1x2_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_v_f16m1x3_tum(vbool16_t vm, vfloat16m1x3_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_v_f16m1x4_tum(vbool16_t vm, vfloat16m1x4_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_v_f16m1x5_tum(vbool16_t vm, vfloat16m1x5_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_v_f16m1x6_tum(vbool16_t vm, vfloat16m1x6_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_v_f16m1x7_tum(vbool16_t vm, vfloat16m1x7_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_v_f16m1x8_tum(vbool16_t vm, vfloat16m1x8_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_v_f16m2x2_tum(vbool8_t vm, vfloat16m2x2_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_v_f16m2x3_tum(vbool8_t vm, vfloat16m2x3_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_v_f16m2x4_tum(vbool8_t vm, vfloat16m2x4_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_v_f16m4x2_tum(vbool4_t vm, vfloat16m4x2_t vd,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_v_f16mf4x2_tum(vbool64_t vm,
                                                   vfloat16mf4x2_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_v_f16mf4x3_tum(vbool64_t vm,
                                                   vfloat16mf4x3_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_v_f16mf4x4_tum(vbool64_t vm,
                                                   vfloat16mf4x4_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_v_f16mf4x5_tum(vbool64_t vm,
                                                   vfloat16mf4x5_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_v_f16mf4x6_tum(vbool64_t vm,
                                                   vfloat16mf4x6_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_v_f16mf4x7_tum(vbool64_t vm,
                                                   vfloat16mf4x7_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_v_f16mf4x8_tum(vbool64_t vm,
                                                   vfloat16mf4x8_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_v_f16mf2x2_tum(vbool32_t vm,
                                                   vfloat16mf2x2_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_v_f16mf2x3_tum(vbool32_t vm,
                                                   vfloat16mf2x3_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_v_f16mf2x4_tum(vbool32_t vm,
                                                   vfloat16mf2x4_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_v_f16mf2x5_tum(vbool32_t vm,
                                                   vfloat16mf2x5_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_v_f16mf2x6_tum(vbool32_t vm,
                                                   vfloat16mf2x6_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_v_f16mf2x7_tum(vbool32_t vm,
                                                   vfloat16mf2x7_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_v_f16mf2x8_tum(vbool32_t vm,
                                                   vfloat16mf2x8_t vd,
                                                   const _Float16 *rs1,
                                                   size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_v_f16m1x2_tum(vbool16_t vm,
                                                 vfloat16m1x2_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_v_f16m1x3_tum(vbool16_t vm,
                                                 vfloat16m1x3_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_v_f16m1x4_tum(vbool16_t vm,
                                                 vfloat16m1x4_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_v_f16m1x5_tum(vbool16_t vm,
                                                 vfloat16m1x5_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_v_f16m1x6_tum(vbool16_t vm,
                                                 vfloat16m1x6_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_v_f16m1x7_tum(vbool16_t vm,
                                                 vfloat16m1x7_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_v_f16m1x8_tum(vbool16_t vm,
                                                 vfloat16m1x8_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_v_f16m2x2_tum(vbool8_t vm, vfloat16m2x2_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_v_f16m2x3_tum(vbool8_t vm, vfloat16m2x3_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_v_f16m2x4_tum(vbool8_t vm, vfloat16m2x4_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_v_f16m4x2_tum(vbool4_t vm, vfloat16m4x2_t vd,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_v_f16mf4x2_tumu(vbool64_t vm,
                                                  vfloat16mf4x2_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_v_f16mf4x3_tumu(vbool64_t vm,
                                                  vfloat16mf4x3_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_v_f16mf4x4_tumu(vbool64_t vm,
                                                  vfloat16mf4x4_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_v_f16mf4x5_tumu(vbool64_t vm,
                                                  vfloat16mf4x5_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_v_f16mf4x6_tumu(vbool64_t vm,
                                                  vfloat16mf4x6_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_v_f16mf4x7_tumu(vbool64_t vm,
                                                  vfloat16mf4x7_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_v_f16mf4x8_tumu(vbool64_t vm,
                                                  vfloat16mf4x8_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_v_f16mf2x2_tumu(vbool32_t vm,
                                                  vfloat16mf2x2_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_v_f16mf2x3_tumu(vbool32_t vm,
                                                  vfloat16mf2x3_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_v_f16mf2x4_tumu(vbool32_t vm,
                                                  vfloat16mf2x4_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_v_f16mf2x5_tumu(vbool32_t vm,
                                                  vfloat16mf2x5_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_v_f16mf2x6_tumu(vbool32_t vm,
                                                  vfloat16mf2x6_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_v_f16mf2x7_tumu(vbool32_t vm,
                                                  vfloat16mf2x7_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_v_f16mf2x8_tumu(vbool32_t vm,
                                                  vfloat16mf2x8_t vd,
                                                  const _Float16 *rs1,
                                                  size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_v_f16m1x2_tumu(vbool16_t vm, vfloat16m1x2_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_v_f16m1x3_tumu(vbool16_t vm, vfloat16m1x3_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_v_f16m1x4_tumu(vbool16_t vm, vfloat16m1x4_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_v_f16m1x5_tumu(vbool16_t vm, vfloat16m1x5_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_v_f16m1x6_tumu(vbool16_t vm, vfloat16m1x6_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_v_f16m1x7_tumu(vbool16_t vm, vfloat16m1x7_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_v_f16m1x8_tumu(vbool16_t vm, vfloat16m1x8_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_v_f16m2x2_tumu(vbool8_t vm, vfloat16m2x2_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_v_f16m2x3_tumu(vbool8_t vm, vfloat16m2x3_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_v_f16m2x4_tumu(vbool8_t vm, vfloat16m2x4_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_v_f16m4x2_tumu(vbool4_t vm, vfloat16m4x2_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_v_f16mf4x2_tumu(vbool64_t vm,
                                                    vfloat16mf4x2_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_v_f16mf4x3_tumu(vbool64_t vm,
                                                    vfloat16mf4x3_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_v_f16mf4x4_tumu(vbool64_t vm,
                                                    vfloat16mf4x4_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_v_f16mf4x5_tumu(vbool64_t vm,
                                                    vfloat16mf4x5_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_v_f16mf4x6_tumu(vbool64_t vm,
                                                    vfloat16mf4x6_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_v_f16mf4x7_tumu(vbool64_t vm,
                                                    vfloat16mf4x7_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_v_f16mf4x8_tumu(vbool64_t vm,
                                                    vfloat16mf4x8_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_v_f16mf2x2_tumu(vbool32_t vm,
                                                    vfloat16mf2x2_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_v_f16mf2x3_tumu(vbool32_t vm,
                                                    vfloat16mf2x3_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_v_f16mf2x4_tumu(vbool32_t vm,
                                                    vfloat16mf2x4_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_v_f16mf2x5_tumu(vbool32_t vm,
                                                    vfloat16mf2x5_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_v_f16mf2x6_tumu(vbool32_t vm,
                                                    vfloat16mf2x6_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_v_f16mf2x7_tumu(vbool32_t vm,
                                                    vfloat16mf2x7_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_v_f16mf2x8_tumu(vbool32_t vm,
                                                    vfloat16mf2x8_t vd,
                                                    const _Float16 *rs1,
                                                    size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_v_f16m1x2_tumu(vbool16_t vm,
                                                  vfloat16m1x2_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_v_f16m1x3_tumu(vbool16_t vm,
                                                  vfloat16m1x3_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_v_f16m1x4_tumu(vbool16_t vm,
                                                  vfloat16m1x4_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_v_f16m1x5_tumu(vbool16_t vm,
                                                  vfloat16m1x5_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_v_f16m1x6_tumu(vbool16_t vm,
                                                  vfloat16m1x6_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_v_f16m1x7_tumu(vbool16_t vm,
                                                  vfloat16m1x7_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_v_f16m1x8_tumu(vbool16_t vm,
                                                  vfloat16m1x8_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_v_f16m2x2_tumu(vbool8_t vm,
                                                  vfloat16m2x2_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_v_f16m2x3_tumu(vbool8_t vm,
                                                  vfloat16m2x3_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_v_f16m2x4_tumu(vbool8_t vm,
                                                  vfloat16m2x4_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_v_f16m4x2_tumu(vbool4_t vm,
                                                  vfloat16m4x2_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_v_f16mf4x2_mu(vbool64_t vm,
                                                vfloat16mf4x2_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_v_f16mf4x3_mu(vbool64_t vm,
                                                vfloat16mf4x3_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_v_f16mf4x4_mu(vbool64_t vm,
                                                vfloat16mf4x4_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_v_f16mf4x5_mu(vbool64_t vm,
                                                vfloat16mf4x5_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_v_f16mf4x6_mu(vbool64_t vm,
                                                vfloat16mf4x6_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_v_f16mf4x7_mu(vbool64_t vm,
                                                vfloat16mf4x7_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_v_f16mf4x8_mu(vbool64_t vm,
                                                vfloat16mf4x8_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_v_f16mf2x2_mu(vbool32_t vm,
                                                vfloat16mf2x2_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_v_f16mf2x3_mu(vbool32_t vm,
                                                vfloat16mf2x3_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_v_f16mf2x4_mu(vbool32_t vm,
                                                vfloat16mf2x4_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_v_f16mf2x5_mu(vbool32_t vm,
                                                vfloat16mf2x5_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_v_f16mf2x6_mu(vbool32_t vm,
                                                vfloat16mf2x6_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_v_f16mf2x7_mu(vbool32_t vm,
                                                vfloat16mf2x7_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_v_f16mf2x8_mu(vbool32_t vm,
                                                vfloat16mf2x8_t vd,
                                                const _Float16 *rs1, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_v_f16m1x2_mu(vbool16_t vm, vfloat16m1x2_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_v_f16m1x3_mu(vbool16_t vm, vfloat16m1x3_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_v_f16m1x4_mu(vbool16_t vm, vfloat16m1x4_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_v_f16m1x5_mu(vbool16_t vm, vfloat16m1x5_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_v_f16m1x6_mu(vbool16_t vm, vfloat16m1x6_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_v_f16m1x7_mu(vbool16_t vm, vfloat16m1x7_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_v_f16m1x8_mu(vbool16_t vm, vfloat16m1x8_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_v_f16m2x2_mu(vbool8_t vm, vfloat16m2x2_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_v_f16m2x3_mu(vbool8_t vm, vfloat16m2x3_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_v_f16m2x4_mu(vbool8_t vm, vfloat16m2x4_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_v_f16m4x2_mu(vbool4_t vm, vfloat16m4x2_t vd,
                                              const _Float16 *rs1, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_v_f16mf4x2_mu(vbool64_t vm,
                                                  vfloat16mf4x2_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_v_f16mf4x3_mu(vbool64_t vm,
                                                  vfloat16mf4x3_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_v_f16mf4x4_mu(vbool64_t vm,
                                                  vfloat16mf4x4_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_v_f16mf4x5_mu(vbool64_t vm,
                                                  vfloat16mf4x5_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_v_f16mf4x6_mu(vbool64_t vm,
                                                  vfloat16mf4x6_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_v_f16mf4x7_mu(vbool64_t vm,
                                                  vfloat16mf4x7_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_v_f16mf4x8_mu(vbool64_t vm,
                                                  vfloat16mf4x8_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_v_f16mf2x2_mu(vbool32_t vm,
                                                  vfloat16mf2x2_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_v_f16mf2x3_mu(vbool32_t vm,
                                                  vfloat16mf2x3_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_v_f16mf2x4_mu(vbool32_t vm,
                                                  vfloat16mf2x4_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_v_f16mf2x5_mu(vbool32_t vm,
                                                  vfloat16mf2x5_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_v_f16mf2x6_mu(vbool32_t vm,
                                                  vfloat16mf2x6_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_v_f16mf2x7_mu(vbool32_t vm,
                                                  vfloat16mf2x7_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_v_f16mf2x8_mu(vbool32_t vm,
                                                  vfloat16mf2x8_t vd,
                                                  const _Float16 *rs1,
                                                  size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_v_f16m1x2_mu(vbool16_t vm, vfloat16m1x2_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_v_f16m1x3_mu(vbool16_t vm, vfloat16m1x3_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_v_f16m1x4_mu(vbool16_t vm, vfloat16m1x4_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_v_f16m1x5_mu(vbool16_t vm, vfloat16m1x5_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_v_f16m1x6_mu(vbool16_t vm, vfloat16m1x6_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_v_f16m1x7_mu(vbool16_t vm, vfloat16m1x7_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_v_f16m1x8_mu(vbool16_t vm, vfloat16m1x8_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_v_f16m2x2_mu(vbool8_t vm, vfloat16m2x2_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_v_f16m2x3_mu(vbool8_t vm, vfloat16m2x3_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_v_f16m2x4_mu(vbool8_t vm, vfloat16m2x4_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_v_f16m4x2_mu(vbool4_t vm, vfloat16m4x2_t vd,
                                                const _Float16 *rs1,
                                                size_t *new_vl, size_t vl);
----

[[policy-variant-vecrtor-unit-stride-segment-store]]
==== Vector Unit-Stride Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-strided-segment-load]]
==== Vector Strided Segment Load Intrinsics

[,c]
----
vfloat16mf4x2_t __riscv_vlsseg2e16_v_f16mf4x2_tu(vfloat16mf4x2_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_v_f16mf4x3_tu(vfloat16mf4x3_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_v_f16mf4x4_tu(vfloat16mf4x4_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_v_f16mf4x5_tu(vfloat16mf4x5_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_v_f16mf4x6_tu(vfloat16mf4x6_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_v_f16mf4x7_tu(vfloat16mf4x7_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_v_f16mf4x8_tu(vfloat16mf4x8_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_v_f16mf2x2_tu(vfloat16mf2x2_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_v_f16mf2x3_tu(vfloat16mf2x3_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_v_f16mf2x4_tu(vfloat16mf2x4_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_v_f16mf2x5_tu(vfloat16mf2x5_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_v_f16mf2x6_tu(vfloat16mf2x6_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_v_f16mf2x7_tu(vfloat16mf2x7_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_v_f16mf2x8_tu(vfloat16mf2x8_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_v_f16m1x2_tu(vfloat16m1x2_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_v_f16m1x3_tu(vfloat16m1x3_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_v_f16m1x4_tu(vfloat16m1x4_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_v_f16m1x5_tu(vfloat16m1x5_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_v_f16m1x6_tu(vfloat16m1x6_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_v_f16m1x7_tu(vfloat16m1x7_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_v_f16m1x8_tu(vfloat16m1x8_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_v_f16m2x2_tu(vfloat16m2x2_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_v_f16m2x3_tu(vfloat16m2x3_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_v_f16m2x4_tu(vfloat16m2x4_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_v_f16m4x2_tu(vfloat16m4x2_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_v_f16mf4x2_tum(vbool64_t vm,
                                                  vfloat16mf4x2_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_v_f16mf4x3_tum(vbool64_t vm,
                                                  vfloat16mf4x3_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_v_f16mf4x4_tum(vbool64_t vm,
                                                  vfloat16mf4x4_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_v_f16mf4x5_tum(vbool64_t vm,
                                                  vfloat16mf4x5_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_v_f16mf4x6_tum(vbool64_t vm,
                                                  vfloat16mf4x6_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_v_f16mf4x7_tum(vbool64_t vm,
                                                  vfloat16mf4x7_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_v_f16mf4x8_tum(vbool64_t vm,
                                                  vfloat16mf4x8_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_v_f16mf2x2_tum(vbool32_t vm,
                                                  vfloat16mf2x2_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_v_f16mf2x3_tum(vbool32_t vm,
                                                  vfloat16mf2x3_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_v_f16mf2x4_tum(vbool32_t vm,
                                                  vfloat16mf2x4_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_v_f16mf2x5_tum(vbool32_t vm,
                                                  vfloat16mf2x5_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_v_f16mf2x6_tum(vbool32_t vm,
                                                  vfloat16mf2x6_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_v_f16mf2x7_tum(vbool32_t vm,
                                                  vfloat16mf2x7_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_v_f16mf2x8_tum(vbool32_t vm,
                                                  vfloat16mf2x8_t vd,
                                                  const _Float16 *rs1,
                                                  ptrdiff_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_v_f16m1x2_tum(vbool16_t vm, vfloat16m1x2_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_v_f16m1x3_tum(vbool16_t vm, vfloat16m1x3_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_v_f16m1x4_tum(vbool16_t vm, vfloat16m1x4_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_v_f16m1x5_tum(vbool16_t vm, vfloat16m1x5_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_v_f16m1x6_tum(vbool16_t vm, vfloat16m1x6_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_v_f16m1x7_tum(vbool16_t vm, vfloat16m1x7_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_v_f16m1x8_tum(vbool16_t vm, vfloat16m1x8_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_v_f16m2x2_tum(vbool8_t vm, vfloat16m2x2_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_v_f16m2x3_tum(vbool8_t vm, vfloat16m2x3_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_v_f16m2x4_tum(vbool8_t vm, vfloat16m2x4_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_v_f16m4x2_tum(vbool4_t vm, vfloat16m4x2_t vd,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_v_f16mf4x2_tumu(vbool64_t vm,
                                                   vfloat16mf4x2_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_v_f16mf4x3_tumu(vbool64_t vm,
                                                   vfloat16mf4x3_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_v_f16mf4x4_tumu(vbool64_t vm,
                                                   vfloat16mf4x4_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_v_f16mf4x5_tumu(vbool64_t vm,
                                                   vfloat16mf4x5_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_v_f16mf4x6_tumu(vbool64_t vm,
                                                   vfloat16mf4x6_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_v_f16mf4x7_tumu(vbool64_t vm,
                                                   vfloat16mf4x7_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_v_f16mf4x8_tumu(vbool64_t vm,
                                                   vfloat16mf4x8_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_v_f16mf2x2_tumu(vbool32_t vm,
                                                   vfloat16mf2x2_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_v_f16mf2x3_tumu(vbool32_t vm,
                                                   vfloat16mf2x3_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_v_f16mf2x4_tumu(vbool32_t vm,
                                                   vfloat16mf2x4_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_v_f16mf2x5_tumu(vbool32_t vm,
                                                   vfloat16mf2x5_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_v_f16mf2x6_tumu(vbool32_t vm,
                                                   vfloat16mf2x6_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_v_f16mf2x7_tumu(vbool32_t vm,
                                                   vfloat16mf2x7_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_v_f16mf2x8_tumu(vbool32_t vm,
                                                   vfloat16mf2x8_t vd,
                                                   const _Float16 *rs1,
                                                   ptrdiff_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_v_f16m1x2_tumu(vbool16_t vm,
                                                 vfloat16m1x2_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_v_f16m1x3_tumu(vbool16_t vm,
                                                 vfloat16m1x3_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_v_f16m1x4_tumu(vbool16_t vm,
                                                 vfloat16m1x4_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_v_f16m1x5_tumu(vbool16_t vm,
                                                 vfloat16m1x5_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_v_f16m1x6_tumu(vbool16_t vm,
                                                 vfloat16m1x6_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_v_f16m1x7_tumu(vbool16_t vm,
                                                 vfloat16m1x7_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_v_f16m1x8_tumu(vbool16_t vm,
                                                 vfloat16m1x8_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_v_f16m2x2_tumu(vbool8_t vm, vfloat16m2x2_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_v_f16m2x3_tumu(vbool8_t vm, vfloat16m2x3_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_v_f16m2x4_tumu(vbool8_t vm, vfloat16m2x4_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_v_f16m4x2_tumu(vbool4_t vm, vfloat16m4x2_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_v_f16mf4x2_mu(vbool64_t vm,
                                                 vfloat16mf4x2_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_v_f16mf4x3_mu(vbool64_t vm,
                                                 vfloat16mf4x3_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_v_f16mf4x4_mu(vbool64_t vm,
                                                 vfloat16mf4x4_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_v_f16mf4x5_mu(vbool64_t vm,
                                                 vfloat16mf4x5_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_v_f16mf4x6_mu(vbool64_t vm,
                                                 vfloat16mf4x6_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_v_f16mf4x7_mu(vbool64_t vm,
                                                 vfloat16mf4x7_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_v_f16mf4x8_mu(vbool64_t vm,
                                                 vfloat16mf4x8_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_v_f16mf2x2_mu(vbool32_t vm,
                                                 vfloat16mf2x2_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_v_f16mf2x3_mu(vbool32_t vm,
                                                 vfloat16mf2x3_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_v_f16mf2x4_mu(vbool32_t vm,
                                                 vfloat16mf2x4_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_v_f16mf2x5_mu(vbool32_t vm,
                                                 vfloat16mf2x5_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_v_f16mf2x6_mu(vbool32_t vm,
                                                 vfloat16mf2x6_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_v_f16mf2x7_mu(vbool32_t vm,
                                                 vfloat16mf2x7_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_v_f16mf2x8_mu(vbool32_t vm,
                                                 vfloat16mf2x8_t vd,
                                                 const _Float16 *rs1,
                                                 ptrdiff_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_v_f16m1x2_mu(vbool16_t vm, vfloat16m1x2_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_v_f16m1x3_mu(vbool16_t vm, vfloat16m1x3_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_v_f16m1x4_mu(vbool16_t vm, vfloat16m1x4_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_v_f16m1x5_mu(vbool16_t vm, vfloat16m1x5_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_v_f16m1x6_mu(vbool16_t vm, vfloat16m1x6_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_v_f16m1x7_mu(vbool16_t vm, vfloat16m1x7_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_v_f16m1x8_mu(vbool16_t vm, vfloat16m1x8_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_v_f16m2x2_mu(vbool8_t vm, vfloat16m2x2_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_v_f16m2x3_mu(vbool8_t vm, vfloat16m2x3_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_v_f16m2x4_mu(vbool8_t vm, vfloat16m2x4_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_v_f16m4x2_mu(vbool4_t vm, vfloat16m4x2_t vd,
                                               const _Float16 *rs1,
                                               ptrdiff_t rs2, size_t vl);
----

[[policy-variant-vector-strided-segment-store]]
==== Vector Strided Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-indexed-segment-load]]
==== Vector Indexed Segment Load Intrinsics

[,c]
----
vfloat16mf4x2_t __riscv_vloxseg2ei16_v_f16mf4x2_tu(vfloat16mf4x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_v_f16mf4x3_tu(vfloat16mf4x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_v_f16mf4x4_tu(vfloat16mf4x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_v_f16mf4x5_tu(vfloat16mf4x5_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_v_f16mf4x6_tu(vfloat16mf4x6_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_v_f16mf4x7_tu(vfloat16mf4x7_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_v_f16mf4x8_tu(vfloat16mf4x8_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_v_f16mf2x2_tu(vfloat16mf2x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_v_f16mf2x3_tu(vfloat16mf2x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_v_f16mf2x4_tu(vfloat16mf2x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_v_f16mf2x5_tu(vfloat16mf2x5_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_v_f16mf2x6_tu(vfloat16mf2x6_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_v_f16mf2x7_tu(vfloat16mf2x7_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_v_f16mf2x8_tu(vfloat16mf2x8_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_v_f16m1x2_tu(vfloat16m1x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_v_f16m1x3_tu(vfloat16m1x3_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_v_f16m1x4_tu(vfloat16m1x4_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_v_f16m1x5_tu(vfloat16m1x5_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_v_f16m1x6_tu(vfloat16m1x6_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_v_f16m1x7_tu(vfloat16m1x7_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_v_f16m1x8_tu(vfloat16m1x8_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_v_f16m2x2_tu(vfloat16m2x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_v_f16m2x3_tu(vfloat16m2x3_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_v_f16m2x4_tu(vfloat16m2x4_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_v_f16m4x2_tu(vfloat16m4x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_v_f16mf4x2_tu(vfloat16mf4x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_v_f16mf4x3_tu(vfloat16mf4x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_v_f16mf4x4_tu(vfloat16mf4x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_v_f16mf4x5_tu(vfloat16mf4x5_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_v_f16mf4x6_tu(vfloat16mf4x6_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_v_f16mf4x7_tu(vfloat16mf4x7_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_v_f16mf4x8_tu(vfloat16mf4x8_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_v_f16mf2x2_tu(vfloat16mf2x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_v_f16mf2x3_tu(vfloat16mf2x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_v_f16mf2x4_tu(vfloat16mf2x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_v_f16mf2x5_tu(vfloat16mf2x5_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_v_f16mf2x6_tu(vfloat16mf2x6_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_v_f16mf2x7_tu(vfloat16mf2x7_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_v_f16mf2x8_tu(vfloat16mf2x8_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_v_f16m1x2_tu(vfloat16m1x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_v_f16m1x3_tu(vfloat16m1x3_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_v_f16m1x4_tu(vfloat16m1x4_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_v_f16m1x5_tu(vfloat16m1x5_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_v_f16m1x6_tu(vfloat16m1x6_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_v_f16m1x7_tu(vfloat16m1x7_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_v_f16m1x8_tu(vfloat16m1x8_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_v_f16m2x2_tu(vfloat16m2x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_v_f16m2x3_tu(vfloat16m2x3_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_v_f16m2x4_tu(vfloat16m2x4_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_v_f16m4x2_tu(vfloat16m4x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m4_t rs2, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei16_v_f16mf4x2_tum(vbool64_t vm,
                                                    vfloat16mf4x2_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_v_f16mf4x3_tum(vbool64_t vm,
                                                    vfloat16mf4x3_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_v_f16mf4x4_tum(vbool64_t vm,
                                                    vfloat16mf4x4_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_v_f16mf4x5_tum(vbool64_t vm,
                                                    vfloat16mf4x5_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_v_f16mf4x6_tum(vbool64_t vm,
                                                    vfloat16mf4x6_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_v_f16mf4x7_tum(vbool64_t vm,
                                                    vfloat16mf4x7_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_v_f16mf4x8_tum(vbool64_t vm,
                                                    vfloat16mf4x8_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_v_f16mf2x2_tum(vbool32_t vm,
                                                    vfloat16mf2x2_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_v_f16mf2x3_tum(vbool32_t vm,
                                                    vfloat16mf2x3_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_v_f16mf2x4_tum(vbool32_t vm,
                                                    vfloat16mf2x4_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_v_f16mf2x5_tum(vbool32_t vm,
                                                    vfloat16mf2x5_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_v_f16mf2x6_tum(vbool32_t vm,
                                                    vfloat16mf2x6_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_v_f16mf2x7_tum(vbool32_t vm,
                                                    vfloat16mf2x7_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_v_f16mf2x8_tum(vbool32_t vm,
                                                    vfloat16mf2x8_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_v_f16m1x2_tum(vbool16_t vm,
                                                  vfloat16m1x2_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_v_f16m1x3_tum(vbool16_t vm,
                                                  vfloat16m1x3_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_v_f16m1x4_tum(vbool16_t vm,
                                                  vfloat16m1x4_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_v_f16m1x5_tum(vbool16_t vm,
                                                  vfloat16m1x5_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_v_f16m1x6_tum(vbool16_t vm,
                                                  vfloat16m1x6_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_v_f16m1x7_tum(vbool16_t vm,
                                                  vfloat16m1x7_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_v_f16m1x8_tum(vbool16_t vm,
                                                  vfloat16m1x8_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_v_f16m2x2_tum(vbool8_t vm,
                                                  vfloat16m2x2_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_v_f16m2x3_tum(vbool8_t vm,
                                                  vfloat16m2x3_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_v_f16m2x4_tum(vbool8_t vm,
                                                  vfloat16m2x4_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_v_f16m4x2_tum(vbool4_t vm,
                                                  vfloat16m4x2_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_v_f16mf4x2_tum(vbool64_t vm,
                                                    vfloat16mf4x2_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_v_f16mf4x3_tum(vbool64_t vm,
                                                    vfloat16mf4x3_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_v_f16mf4x4_tum(vbool64_t vm,
                                                    vfloat16mf4x4_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_v_f16mf4x5_tum(vbool64_t vm,
                                                    vfloat16mf4x5_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_v_f16mf4x6_tum(vbool64_t vm,
                                                    vfloat16mf4x6_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_v_f16mf4x7_tum(vbool64_t vm,
                                                    vfloat16mf4x7_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_v_f16mf4x8_tum(vbool64_t vm,
                                                    vfloat16mf4x8_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf4_t rs2,
                                                    size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_v_f16mf2x2_tum(vbool32_t vm,
                                                    vfloat16mf2x2_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_v_f16mf2x3_tum(vbool32_t vm,
                                                    vfloat16mf2x3_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_v_f16mf2x4_tum(vbool32_t vm,
                                                    vfloat16mf2x4_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_v_f16mf2x5_tum(vbool32_t vm,
                                                    vfloat16mf2x5_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_v_f16mf2x6_tum(vbool32_t vm,
                                                    vfloat16mf2x6_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_v_f16mf2x7_tum(vbool32_t vm,
                                                    vfloat16mf2x7_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_v_f16mf2x8_tum(vbool32_t vm,
                                                    vfloat16mf2x8_t vd,
                                                    const _Float16 *rs1,
                                                    vuint16mf2_t rs2,
                                                    size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_v_f16m1x2_tum(vbool16_t vm,
                                                  vfloat16m1x2_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_v_f16m1x3_tum(vbool16_t vm,
                                                  vfloat16m1x3_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_v_f16m1x4_tum(vbool16_t vm,
                                                  vfloat16m1x4_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_v_f16m1x5_tum(vbool16_t vm,
                                                  vfloat16m1x5_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_v_f16m1x6_tum(vbool16_t vm,
                                                  vfloat16m1x6_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_v_f16m1x7_tum(vbool16_t vm,
                                                  vfloat16m1x7_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_v_f16m1x8_tum(vbool16_t vm,
                                                  vfloat16m1x8_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_v_f16m2x2_tum(vbool8_t vm,
                                                  vfloat16m2x2_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_v_f16m2x3_tum(vbool8_t vm,
                                                  vfloat16m2x3_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_v_f16m2x4_tum(vbool8_t vm,
                                                  vfloat16m2x4_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_v_f16m4x2_tum(vbool4_t vm,
                                                  vfloat16m4x2_t vd,
                                                  const _Float16 *rs1,
                                                  vuint16m4_t rs2, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei16_v_f16mf4x2_tumu(vbool64_t vm,
                                                     vfloat16mf4x2_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_v_f16mf4x3_tumu(vbool64_t vm,
                                                     vfloat16mf4x3_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_v_f16mf4x4_tumu(vbool64_t vm,
                                                     vfloat16mf4x4_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_v_f16mf4x5_tumu(vbool64_t vm,
                                                     vfloat16mf4x5_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_v_f16mf4x6_tumu(vbool64_t vm,
                                                     vfloat16mf4x6_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_v_f16mf4x7_tumu(vbool64_t vm,
                                                     vfloat16mf4x7_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_v_f16mf4x8_tumu(vbool64_t vm,
                                                     vfloat16mf4x8_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_v_f16mf2x2_tumu(vbool32_t vm,
                                                     vfloat16mf2x2_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_v_f16mf2x3_tumu(vbool32_t vm,
                                                     vfloat16mf2x3_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_v_f16mf2x4_tumu(vbool32_t vm,
                                                     vfloat16mf2x4_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_v_f16mf2x5_tumu(vbool32_t vm,
                                                     vfloat16mf2x5_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_v_f16mf2x6_tumu(vbool32_t vm,
                                                     vfloat16mf2x6_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_v_f16mf2x7_tumu(vbool32_t vm,
                                                     vfloat16mf2x7_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_v_f16mf2x8_tumu(vbool32_t vm,
                                                     vfloat16mf2x8_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_v_f16m1x2_tumu(vbool16_t vm,
                                                   vfloat16m1x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_v_f16m1x3_tumu(vbool16_t vm,
                                                   vfloat16m1x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_v_f16m1x4_tumu(vbool16_t vm,
                                                   vfloat16m1x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_v_f16m1x5_tumu(vbool16_t vm,
                                                   vfloat16m1x5_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_v_f16m1x6_tumu(vbool16_t vm,
                                                   vfloat16m1x6_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_v_f16m1x7_tumu(vbool16_t vm,
                                                   vfloat16m1x7_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_v_f16m1x8_tumu(vbool16_t vm,
                                                   vfloat16m1x8_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_v_f16m2x2_tumu(vbool8_t vm,
                                                   vfloat16m2x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_v_f16m2x3_tumu(vbool8_t vm,
                                                   vfloat16m2x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_v_f16m2x4_tumu(vbool8_t vm,
                                                   vfloat16m2x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_v_f16m4x2_tumu(vbool4_t vm,
                                                   vfloat16m4x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_v_f16mf4x2_tumu(vbool64_t vm,
                                                     vfloat16mf4x2_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_v_f16mf4x3_tumu(vbool64_t vm,
                                                     vfloat16mf4x3_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_v_f16mf4x4_tumu(vbool64_t vm,
                                                     vfloat16mf4x4_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_v_f16mf4x5_tumu(vbool64_t vm,
                                                     vfloat16mf4x5_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_v_f16mf4x6_tumu(vbool64_t vm,
                                                     vfloat16mf4x6_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_v_f16mf4x7_tumu(vbool64_t vm,
                                                     vfloat16mf4x7_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_v_f16mf4x8_tumu(vbool64_t vm,
                                                     vfloat16mf4x8_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf4_t rs2,
                                                     size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_v_f16mf2x2_tumu(vbool32_t vm,
                                                     vfloat16mf2x2_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_v_f16mf2x3_tumu(vbool32_t vm,
                                                     vfloat16mf2x3_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_v_f16mf2x4_tumu(vbool32_t vm,
                                                     vfloat16mf2x4_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_v_f16mf2x5_tumu(vbool32_t vm,
                                                     vfloat16mf2x5_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_v_f16mf2x6_tumu(vbool32_t vm,
                                                     vfloat16mf2x6_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_v_f16mf2x7_tumu(vbool32_t vm,
                                                     vfloat16mf2x7_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_v_f16mf2x8_tumu(vbool32_t vm,
                                                     vfloat16mf2x8_t vd,
                                                     const _Float16 *rs1,
                                                     vuint16mf2_t rs2,
                                                     size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_v_f16m1x2_tumu(vbool16_t vm,
                                                   vfloat16m1x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_v_f16m1x3_tumu(vbool16_t vm,
                                                   vfloat16m1x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_v_f16m1x4_tumu(vbool16_t vm,
                                                   vfloat16m1x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_v_f16m1x5_tumu(vbool16_t vm,
                                                   vfloat16m1x5_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_v_f16m1x6_tumu(vbool16_t vm,
                                                   vfloat16m1x6_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_v_f16m1x7_tumu(vbool16_t vm,
                                                   vfloat16m1x7_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_v_f16m1x8_tumu(vbool16_t vm,
                                                   vfloat16m1x8_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_v_f16m2x2_tumu(vbool8_t vm,
                                                   vfloat16m2x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_v_f16m2x3_tumu(vbool8_t vm,
                                                   vfloat16m2x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_v_f16m2x4_tumu(vbool8_t vm,
                                                   vfloat16m2x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_v_f16m4x2_tumu(vbool4_t vm,
                                                   vfloat16m4x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16m4_t rs2, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei16_v_f16mf4x2_mu(vbool64_t vm,
                                                   vfloat16mf4x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_v_f16mf4x3_mu(vbool64_t vm,
                                                   vfloat16mf4x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_v_f16mf4x4_mu(vbool64_t vm,
                                                   vfloat16mf4x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_v_f16mf4x5_mu(vbool64_t vm,
                                                   vfloat16mf4x5_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_v_f16mf4x6_mu(vbool64_t vm,
                                                   vfloat16mf4x6_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_v_f16mf4x7_mu(vbool64_t vm,
                                                   vfloat16mf4x7_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_v_f16mf4x8_mu(vbool64_t vm,
                                                   vfloat16mf4x8_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_v_f16mf2x2_mu(vbool32_t vm,
                                                   vfloat16mf2x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_v_f16mf2x3_mu(vbool32_t vm,
                                                   vfloat16mf2x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_v_f16mf2x4_mu(vbool32_t vm,
                                                   vfloat16mf2x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_v_f16mf2x5_mu(vbool32_t vm,
                                                   vfloat16mf2x5_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_v_f16mf2x6_mu(vbool32_t vm,
                                                   vfloat16mf2x6_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_v_f16mf2x7_mu(vbool32_t vm,
                                                   vfloat16mf2x7_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_v_f16mf2x8_mu(vbool32_t vm,
                                                   vfloat16mf2x8_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_v_f16m1x2_mu(vbool16_t vm,
                                                 vfloat16m1x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_v_f16m1x3_mu(vbool16_t vm,
                                                 vfloat16m1x3_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_v_f16m1x4_mu(vbool16_t vm,
                                                 vfloat16m1x4_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_v_f16m1x5_mu(vbool16_t vm,
                                                 vfloat16m1x5_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_v_f16m1x6_mu(vbool16_t vm,
                                                 vfloat16m1x6_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_v_f16m1x7_mu(vbool16_t vm,
                                                 vfloat16m1x7_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_v_f16m1x8_mu(vbool16_t vm,
                                                 vfloat16m1x8_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_v_f16m2x2_mu(vbool8_t vm, vfloat16m2x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_v_f16m2x3_mu(vbool8_t vm, vfloat16m2x3_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_v_f16m2x4_mu(vbool8_t vm, vfloat16m2x4_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_v_f16m4x2_mu(vbool4_t vm, vfloat16m4x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_v_f16mf4x2_mu(vbool64_t vm,
                                                   vfloat16mf4x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_v_f16mf4x3_mu(vbool64_t vm,
                                                   vfloat16mf4x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_v_f16mf4x4_mu(vbool64_t vm,
                                                   vfloat16mf4x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_v_f16mf4x5_mu(vbool64_t vm,
                                                   vfloat16mf4x5_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_v_f16mf4x6_mu(vbool64_t vm,
                                                   vfloat16mf4x6_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_v_f16mf4x7_mu(vbool64_t vm,
                                                   vfloat16mf4x7_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_v_f16mf4x8_mu(vbool64_t vm,
                                                   vfloat16mf4x8_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_v_f16mf2x2_mu(vbool32_t vm,
                                                   vfloat16mf2x2_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_v_f16mf2x3_mu(vbool32_t vm,
                                                   vfloat16mf2x3_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_v_f16mf2x4_mu(vbool32_t vm,
                                                   vfloat16mf2x4_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_v_f16mf2x5_mu(vbool32_t vm,
                                                   vfloat16mf2x5_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_v_f16mf2x6_mu(vbool32_t vm,
                                                   vfloat16mf2x6_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_v_f16mf2x7_mu(vbool32_t vm,
                                                   vfloat16mf2x7_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_v_f16mf2x8_mu(vbool32_t vm,
                                                   vfloat16mf2x8_t vd,
                                                   const _Float16 *rs1,
                                                   vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_v_f16m1x2_mu(vbool16_t vm,
                                                 vfloat16m1x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_v_f16m1x3_mu(vbool16_t vm,
                                                 vfloat16m1x3_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_v_f16m1x4_mu(vbool16_t vm,
                                                 vfloat16m1x4_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_v_f16m1x5_mu(vbool16_t vm,
                                                 vfloat16m1x5_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_v_f16m1x6_mu(vbool16_t vm,
                                                 vfloat16m1x6_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_v_f16m1x7_mu(vbool16_t vm,
                                                 vfloat16m1x7_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_v_f16m1x8_mu(vbool16_t vm,
                                                 vfloat16m1x8_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_v_f16m2x2_mu(vbool8_t vm, vfloat16m2x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_v_f16m2x3_mu(vbool8_t vm, vfloat16m2x3_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_v_f16m2x4_mu(vbool8_t vm, vfloat16m2x4_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_v_f16m4x2_mu(vbool4_t vm, vfloat16m4x2_t vd,
                                                 const _Float16 *rs1,
                                                 vuint16m4_t rs2, size_t vl);
----

[[policy-variant-vector-indexed-segment-store]]
==== Vector Indexed Segment Store Intrinsics
Intrinsics here don't have a policy variant.

=== Float16 Miscellaneous Vector Utility Intrinsics

[[policy-variant-reinterpret-cast-conversion]]
==== Reinterpret Cast Conversion Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-lmul-extensionn]]
==== Vector LMUL Extension Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-lmul-truncation]]
==== Vector LMUL Truncation Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-initialization]]
==== Vector Initialization Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-insertion]]
==== Vector Insertion Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-extraction]]
==== Vector Extraction Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-vector-creation]]
==== Vector Creation Intrinsics
Intrinsics here don't have a policy variant.

=== Vector Permutation Intrinsics

[[policy-variant-vector-register-gather]]
==== Vector Register Gather Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vrgather_vv_f16mf4_tu(vfloat16mf4_t vd, vfloat16mf4_t vs2,
                                            vuint16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vrgather_vx_f16mf4_tu(vfloat16mf4_t vd, vfloat16mf4_t vs2,
                                            size_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather_vv_f16mf2_tu(vfloat16mf2_t vd, vfloat16mf2_t vs2,
                                            vuint16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather_vx_f16mf2_tu(vfloat16mf2_t vd, vfloat16mf2_t vs2,
                                            size_t vs1, size_t vl);
vfloat16m1_t __riscv_vrgather_vv_f16m1_tu(vfloat16m1_t vd, vfloat16m1_t vs2,
                                          vuint16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vrgather_vx_f16m1_tu(vfloat16m1_t vd, vfloat16m1_t vs2,
                                          size_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgather_vv_f16m2_tu(vfloat16m2_t vd, vfloat16m2_t vs2,
                                          vuint16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgather_vx_f16m2_tu(vfloat16m2_t vd, vfloat16m2_t vs2,
                                          size_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgather_vv_f16m4_tu(vfloat16m4_t vd, vfloat16m4_t vs2,
                                          vuint16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgather_vx_f16m4_tu(vfloat16m4_t vd, vfloat16m4_t vs2,
                                          size_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgather_vv_f16m8_tu(vfloat16m8_t vd, vfloat16m8_t vs2,
                                          vuint16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgather_vx_f16m8_tu(vfloat16m8_t vd, vfloat16m8_t vs2,
                                          size_t vs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vrgather_vv_f16mf4_tum(vbool64_t vm, vfloat16mf4_t vd,
                                             vfloat16mf4_t vs2,
                                             vuint16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vrgather_vx_f16mf4_tum(vbool64_t vm, vfloat16mf4_t vd,
                                             vfloat16mf4_t vs2, size_t vs1,
                                             size_t vl);
vfloat16mf2_t __riscv_vrgather_vv_f16mf2_tum(vbool32_t vm, vfloat16mf2_t vd,
                                             vfloat16mf2_t vs2,
                                             vuint16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather_vx_f16mf2_tum(vbool32_t vm, vfloat16mf2_t vd,
                                             vfloat16mf2_t vs2, size_t vs1,
                                             size_t vl);
vfloat16m1_t __riscv_vrgather_vv_f16m1_tum(vbool16_t vm, vfloat16m1_t vd,
                                           vfloat16m1_t vs2, vuint16m1_t vs1,
                                           size_t vl);
vfloat16m1_t __riscv_vrgather_vx_f16m1_tum(vbool16_t vm, vfloat16m1_t vd,
                                           vfloat16m1_t vs2, size_t vs1,
                                           size_t vl);
vfloat16m2_t __riscv_vrgather_vv_f16m2_tum(vbool8_t vm, vfloat16m2_t vd,
                                           vfloat16m2_t vs2, vuint16m2_t vs1,
                                           size_t vl);
vfloat16m2_t __riscv_vrgather_vx_f16m2_tum(vbool8_t vm, vfloat16m2_t vd,
                                           vfloat16m2_t vs2, size_t vs1,
                                           size_t vl);
vfloat16m4_t __riscv_vrgather_vv_f16m4_tum(vbool4_t vm, vfloat16m4_t vd,
                                           vfloat16m4_t vs2, vuint16m4_t vs1,
                                           size_t vl);
vfloat16m4_t __riscv_vrgather_vx_f16m4_tum(vbool4_t vm, vfloat16m4_t vd,
                                           vfloat16m4_t vs2, size_t vs1,
                                           size_t vl);
vfloat16m8_t __riscv_vrgather_vv_f16m8_tum(vbool2_t vm, vfloat16m8_t vd,
                                           vfloat16m8_t vs2, vuint16m8_t vs1,
                                           size_t vl);
vfloat16m8_t __riscv_vrgather_vx_f16m8_tum(vbool2_t vm, vfloat16m8_t vd,
                                           vfloat16m8_t vs2, size_t vs1,
                                           size_t vl);
// masked functions
vfloat16mf4_t __riscv_vrgather_vv_f16mf4_tumu(vbool64_t vm, vfloat16mf4_t vd,
                                              vfloat16mf4_t vs2,
                                              vuint16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vrgather_vx_f16mf4_tumu(vbool64_t vm, vfloat16mf4_t vd,
                                              vfloat16mf4_t vs2, size_t vs1,
                                              size_t vl);
vfloat16mf2_t __riscv_vrgather_vv_f16mf2_tumu(vbool32_t vm, vfloat16mf2_t vd,
                                              vfloat16mf2_t vs2,
                                              vuint16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather_vx_f16mf2_tumu(vbool32_t vm, vfloat16mf2_t vd,
                                              vfloat16mf2_t vs2, size_t vs1,
                                              size_t vl);
vfloat16m1_t __riscv_vrgather_vv_f16m1_tumu(vbool16_t vm, vfloat16m1_t vd,
                                            vfloat16m1_t vs2, vuint16m1_t vs1,
                                            size_t vl);
vfloat16m1_t __riscv_vrgather_vx_f16m1_tumu(vbool16_t vm, vfloat16m1_t vd,
                                            vfloat16m1_t vs2, size_t vs1,
                                            size_t vl);
vfloat16m2_t __riscv_vrgather_vv_f16m2_tumu(vbool8_t vm, vfloat16m2_t vd,
                                            vfloat16m2_t vs2, vuint16m2_t vs1,
                                            size_t vl);
vfloat16m2_t __riscv_vrgather_vx_f16m2_tumu(vbool8_t vm, vfloat16m2_t vd,
                                            vfloat16m2_t vs2, size_t vs1,
                                            size_t vl);
vfloat16m4_t __riscv_vrgather_vv_f16m4_tumu(vbool4_t vm, vfloat16m4_t vd,
                                            vfloat16m4_t vs2, vuint16m4_t vs1,
                                            size_t vl);
vfloat16m4_t __riscv_vrgather_vx_f16m4_tumu(vbool4_t vm, vfloat16m4_t vd,
                                            vfloat16m4_t vs2, size_t vs1,
                                            size_t vl);
vfloat16m8_t __riscv_vrgather_vv_f16m8_tumu(vbool2_t vm, vfloat16m8_t vd,
                                            vfloat16m8_t vs2, vuint16m8_t vs1,
                                            size_t vl);
vfloat16m8_t __riscv_vrgather_vx_f16m8_tumu(vbool2_t vm, vfloat16m8_t vd,
                                            vfloat16m8_t vs2, size_t vs1,
                                            size_t vl);
// masked functions
vfloat16mf4_t __riscv_vrgather_vv_f16mf4_mu(vbool64_t vm, vfloat16mf4_t vd,
                                            vfloat16mf4_t vs2, vuint16mf4_t vs1,
                                            size_t vl);
vfloat16mf4_t __riscv_vrgather_vx_f16mf4_mu(vbool64_t vm, vfloat16mf4_t vd,
                                            vfloat16mf4_t vs2, size_t vs1,
                                            size_t vl);
vfloat16mf2_t __riscv_vrgather_vv_f16mf2_mu(vbool32_t vm, vfloat16mf2_t vd,
                                            vfloat16mf2_t vs2, vuint16mf2_t vs1,
                                            size_t vl);
vfloat16mf2_t __riscv_vrgather_vx_f16mf2_mu(vbool32_t vm, vfloat16mf2_t vd,
                                            vfloat16mf2_t vs2, size_t vs1,
                                            size_t vl);
vfloat16m1_t __riscv_vrgather_vv_f16m1_mu(vbool16_t vm, vfloat16m1_t vd,
                                          vfloat16m1_t vs2, vuint16m1_t vs1,
                                          size_t vl);
vfloat16m1_t __riscv_vrgather_vx_f16m1_mu(vbool16_t vm, vfloat16m1_t vd,
                                          vfloat16m1_t vs2, size_t vs1,
                                          size_t vl);
vfloat16m2_t __riscv_vrgather_vv_f16m2_mu(vbool8_t vm, vfloat16m2_t vd,
                                          vfloat16m2_t vs2, vuint16m2_t vs1,
                                          size_t vl);
vfloat16m2_t __riscv_vrgather_vx_f16m2_mu(vbool8_t vm, vfloat16m2_t vd,
                                          vfloat16m2_t vs2, size_t vs1,
                                          size_t vl);
vfloat16m4_t __riscv_vrgather_vv_f16m4_mu(vbool4_t vm, vfloat16m4_t vd,
                                          vfloat16m4_t vs2, vuint16m4_t vs1,
                                          size_t vl);
vfloat16m4_t __riscv_vrgather_vx_f16m4_mu(vbool4_t vm, vfloat16m4_t vd,
                                          vfloat16m4_t vs2, size_t vs1,
                                          size_t vl);
vfloat16m8_t __riscv_vrgather_vv_f16m8_mu(vbool2_t vm, vfloat16m8_t vd,
                                          vfloat16m8_t vs2, vuint16m8_t vs1,
                                          size_t vl);
vfloat16m8_t __riscv_vrgather_vx_f16m8_mu(vbool2_t vm, vfloat16m8_t vd,
                                          vfloat16m8_t vs2, size_t vs1,
                                          size_t vl);
----

[[policy-variant-vector-compress]]
==== Vector Compress Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vcompress_vm_f16mf4_tu(vfloat16mf4_t vd,
                                             vfloat16mf4_t vs2, vbool64_t vs1,
                                             size_t vl);
vfloat16mf2_t __riscv_vcompress_vm_f16mf2_tu(vfloat16mf2_t vd,
                                             vfloat16mf2_t vs2, vbool32_t vs1,
                                             size_t vl);
vfloat16m1_t __riscv_vcompress_vm_f16m1_tu(vfloat16m1_t vd, vfloat16m1_t vs2,
                                           vbool16_t vs1, size_t vl);
vfloat16m2_t __riscv_vcompress_vm_f16m2_tu(vfloat16m2_t vd, vfloat16m2_t vs2,
                                           vbool8_t vs1, size_t vl);
vfloat16m4_t __riscv_vcompress_vm_f16m4_tu(vfloat16m4_t vd, vfloat16m4_t vs2,
                                           vbool4_t vs1, size_t vl);
vfloat16m8_t __riscv_vcompress_vm_f16m8_tu(vfloat16m8_t vd, vfloat16m8_t vs2,
                                           vbool2_t vs1, size_t vl);
----

=== Vector Float16 Intrinsics

[[policy-variant-widening-floating-pointinteger-type-convert]]
==== Widening Floating-Point/Integer Type-Convert Intrinsics

[,c]
----
vfloat32mf2_t __riscv_vfwcvt_f_f_v_f32mf2_tu(vfloat32mf2_t vd,
                                             vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_f_v_f32m1_tu(vfloat32m1_t vd, vfloat16mf2_t vs2,
                                           size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_f_v_f32m2_tu(vfloat32m2_t vd, vfloat16m1_t vs2,
                                           size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_f_v_f32m4_tu(vfloat32m4_t vd, vfloat16m2_t vs2,
                                           size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_f_v_f32m8_tu(vfloat32m8_t vd, vfloat16m4_t vs2,
                                           size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwcvt_f_f_v_f32mf2_tum(vbool64_t vm, vfloat32mf2_t vd,
                                              vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_f_v_f32m1_tum(vbool32_t vm, vfloat32m1_t vd,
                                            vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_f_v_f32m2_tum(vbool16_t vm, vfloat32m2_t vd,
                                            vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_f_v_f32m4_tum(vbool8_t vm, vfloat32m4_t vd,
                                            vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_f_v_f32m8_tum(vbool4_t vm, vfloat32m8_t vd,
                                            vfloat16m4_t vs2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwcvt_f_f_v_f32mf2_tumu(vbool64_t vm, vfloat32mf2_t vd,
                                               vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_f_v_f32m1_tumu(vbool32_t vm, vfloat32m1_t vd,
                                             vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_f_v_f32m2_tumu(vbool16_t vm, vfloat32m2_t vd,
                                             vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_f_v_f32m4_tumu(vbool8_t vm, vfloat32m4_t vd,
                                             vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_f_v_f32m8_tumu(vbool4_t vm, vfloat32m8_t vd,
                                             vfloat16m4_t vs2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwcvt_f_f_v_f32mf2_mu(vbool64_t vm, vfloat32mf2_t vd,
                                             vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_f_v_f32m1_mu(vbool32_t vm, vfloat32m1_t vd,
                                           vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_f_v_f32m2_mu(vbool16_t vm, vfloat32m2_t vd,
                                           vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_f_v_f32m4_mu(vbool8_t vm, vfloat32m4_t vd,
                                           vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_f_v_f32m8_mu(vbool4_t vm, vfloat32m8_t vd,
                                           vfloat16m4_t vs2, size_t vl);
// masked functions
// masked functions
// masked functions
----

[[policy-variant-narrowing-floating-pointinteger-type-convert]]
==== Narrowing Floating-Point/Integer Type-Convert Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_tu(vfloat16mf4_t vd,
                                             vfloat32mf2_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_f_w_f16mf4_tu(vfloat16mf4_t vd,
                                                 vfloat32mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_tu(vfloat16mf2_t vd, vfloat32m1_t vs2,
                                             size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_f_w_f16mf2_tu(vfloat16mf2_t vd,
                                                 vfloat32m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_tu(vfloat16m1_t vd, vfloat32m2_t vs2,
                                           size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_f_w_f16m1_tu(vfloat16m1_t vd,
                                               vfloat32m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_tu(vfloat16m2_t vd, vfloat32m4_t vs2,
                                           size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_f_w_f16m2_tu(vfloat16m2_t vd,
                                               vfloat32m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_tu(vfloat16m4_t vd, vfloat32m8_t vs2,
                                           size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_f_w_f16m4_tu(vfloat16m4_t vd,
                                               vfloat32m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_tum(vbool64_t vm, vfloat16mf4_t vd,
                                              vfloat32mf2_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_f_w_f16mf4_tum(vbool64_t vm,
                                                  vfloat16mf4_t vd,
                                                  vfloat32mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_tum(vbool32_t vm, vfloat16mf2_t vd,
                                              vfloat32m1_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_f_w_f16mf2_tum(vbool32_t vm,
                                                  vfloat16mf2_t vd,
                                                  vfloat32m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_tum(vbool16_t vm, vfloat16m1_t vd,
                                            vfloat32m2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_f_w_f16m1_tum(vbool16_t vm, vfloat16m1_t vd,
                                                vfloat32m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_tum(vbool8_t vm, vfloat16m2_t vd,
                                            vfloat32m4_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_f_w_f16m2_tum(vbool8_t vm, vfloat16m2_t vd,
                                                vfloat32m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_tum(vbool4_t vm, vfloat16m4_t vd,
                                            vfloat32m8_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_f_w_f16m4_tum(vbool4_t vm, vfloat16m4_t vd,
                                                vfloat32m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_tumu(vbool64_t vm, vfloat16mf4_t vd,
                                               vfloat32mf2_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_f_w_f16mf4_tumu(vbool64_t vm,
                                                   vfloat16mf4_t vd,
                                                   vfloat32mf2_t vs2,
                                                   size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_tumu(vbool32_t vm, vfloat16mf2_t vd,
                                               vfloat32m1_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_f_w_f16mf2_tumu(vbool32_t vm,
                                                   vfloat16mf2_t vd,
                                                   vfloat32m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_tumu(vbool16_t vm, vfloat16m1_t vd,
                                             vfloat32m2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_f_w_f16m1_tumu(vbool16_t vm, vfloat16m1_t vd,
                                                 vfloat32m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_tumu(vbool8_t vm, vfloat16m2_t vd,
                                             vfloat32m4_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_f_w_f16m2_tumu(vbool8_t vm, vfloat16m2_t vd,
                                                 vfloat32m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_tumu(vbool4_t vm, vfloat16m4_t vd,
                                             vfloat32m8_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_f_w_f16m4_tumu(vbool4_t vm, vfloat16m4_t vd,
                                                 vfloat32m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_mu(vbool64_t vm, vfloat16mf4_t vd,
                                             vfloat32mf2_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_f_w_f16mf4_mu(vbool64_t vm, vfloat16mf4_t vd,
                                                 vfloat32mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_mu(vbool32_t vm, vfloat16mf2_t vd,
                                             vfloat32m1_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_f_w_f16mf2_mu(vbool32_t vm, vfloat16mf2_t vd,
                                                 vfloat32m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_mu(vbool16_t vm, vfloat16m1_t vd,
                                           vfloat32m2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_f_w_f16m1_mu(vbool16_t vm, vfloat16m1_t vd,
                                               vfloat32m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_mu(vbool8_t vm, vfloat16m2_t vd,
                                           vfloat32m4_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_f_w_f16m2_mu(vbool8_t vm, vfloat16m2_t vd,
                                               vfloat32m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_mu(vbool4_t vm, vfloat16m4_t vd,
                                           vfloat32m8_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_f_w_f16m4_mu(vbool4_t vm, vfloat16m4_t vd,
                                               vfloat32m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_rm_tu(vfloat16mf4_t vd,
                                                vfloat32mf2_t vs2,
                                                unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_rm_tu(vfloat16mf2_t vd,
                                                vfloat32m1_t vs2,
                                                unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_rm_tu(vfloat16m1_t vd, vfloat32m2_t vs2,
                                              unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_rm_tu(vfloat16m2_t vd, vfloat32m4_t vs2,
                                              unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_rm_tu(vfloat16m4_t vd, vfloat32m8_t vs2,
                                              unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_rm_tum(vbool64_t vm, vfloat16mf4_t vd,
                                                 vfloat32mf2_t vs2,
                                                 unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_rm_tum(vbool32_t vm, vfloat16mf2_t vd,
                                                 vfloat32m1_t vs2,
                                                 unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_rm_tum(vbool16_t vm, vfloat16m1_t vd,
                                               vfloat32m2_t vs2,
                                               unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_rm_tum(vbool8_t vm, vfloat16m2_t vd,
                                               vfloat32m4_t vs2,
                                               unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_rm_tum(vbool4_t vm, vfloat16m4_t vd,
                                               vfloat32m8_t vs2,
                                               unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_rm_tumu(vbool64_t vm,
                                                  vfloat16mf4_t vd,
                                                  vfloat32mf2_t vs2,
                                                  unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_rm_tumu(vbool32_t vm,
                                                  vfloat16mf2_t vd,
                                                  vfloat32m1_t vs2,
                                                  unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_rm_tumu(vbool16_t vm, vfloat16m1_t vd,
                                                vfloat32m2_t vs2,
                                                unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_rm_tumu(vbool8_t vm, vfloat16m2_t vd,
                                                vfloat32m4_t vs2,
                                                unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_rm_tumu(vbool4_t vm, vfloat16m4_t vd,
                                                vfloat32m8_t vs2,
                                                unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_rm_mu(vbool64_t vm, vfloat16mf4_t vd,
                                                vfloat32mf2_t vs2,
                                                unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_rm_mu(vbool32_t vm, vfloat16mf2_t vd,
                                                vfloat32m1_t vs2,
                                                unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_rm_mu(vbool16_t vm, vfloat16m1_t vd,
                                              vfloat32m2_t vs2,
                                              unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_rm_mu(vbool8_t vm, vfloat16m2_t vd,
                                              vfloat32m4_t vs2,
                                              unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_rm_mu(vbool4_t vm, vfloat16m4_t vd,
                                              vfloat32m8_t vs2,
                                              unsigned int frm, size_t vl);
----
