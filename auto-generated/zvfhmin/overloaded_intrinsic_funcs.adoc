
=== Float16 Vector Loads and Stores Intrinsics

[[overloaded-vector-unit-stride-load]]
==== Vector Unit-Stride Load Intrinsics

[,c]
----
// masked functions
vfloat16mf4_t __riscv_vle16(vbool64_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf2_t __riscv_vle16(vbool32_t vm, const _Float16 *rs1, size_t vl);
vfloat16m1_t __riscv_vle16(vbool16_t vm, const _Float16 *rs1, size_t vl);
vfloat16m2_t __riscv_vle16(vbool8_t vm, const _Float16 *rs1, size_t vl);
vfloat16m4_t __riscv_vle16(vbool4_t vm, const _Float16 *rs1, size_t vl);
vfloat16m8_t __riscv_vle16(vbool2_t vm, const _Float16 *rs1, size_t vl);
----

[[overloaded-vector-unit-stride-store]]
==== Vector Unit-Stride Store Intrinsics

[,c]
----
void __riscv_vse16(_Float16 *rs1, vfloat16mf4_t vs3, size_t vl);
void __riscv_vse16(_Float16 *rs1, vfloat16mf2_t vs3, size_t vl);
void __riscv_vse16(_Float16 *rs1, vfloat16m1_t vs3, size_t vl);
void __riscv_vse16(_Float16 *rs1, vfloat16m2_t vs3, size_t vl);
void __riscv_vse16(_Float16 *rs1, vfloat16m4_t vs3, size_t vl);
void __riscv_vse16(_Float16 *rs1, vfloat16m8_t vs3, size_t vl);
// masked functions
void __riscv_vse16(vbool64_t vm, _Float16 *rs1, vfloat16mf4_t vs3, size_t vl);
void __riscv_vse16(vbool32_t vm, _Float16 *rs1, vfloat16mf2_t vs3, size_t vl);
void __riscv_vse16(vbool16_t vm, _Float16 *rs1, vfloat16m1_t vs3, size_t vl);
void __riscv_vse16(vbool8_t vm, _Float16 *rs1, vfloat16m2_t vs3, size_t vl);
void __riscv_vse16(vbool4_t vm, _Float16 *rs1, vfloat16m4_t vs3, size_t vl);
void __riscv_vse16(vbool2_t vm, _Float16 *rs1, vfloat16m8_t vs3, size_t vl);
----

[[overloaded-vector-strided-load]]
==== Vector Strided Load Intrinsics

[,c]
----
// masked functions
vfloat16mf4_t __riscv_vlse16(vbool64_t vm, const _Float16 *rs1, ptrdiff_t rs2,
                             size_t vl);
vfloat16mf2_t __riscv_vlse16(vbool32_t vm, const _Float16 *rs1, ptrdiff_t rs2,
                             size_t vl);
vfloat16m1_t __riscv_vlse16(vbool16_t vm, const _Float16 *rs1, ptrdiff_t rs2,
                            size_t vl);
vfloat16m2_t __riscv_vlse16(vbool8_t vm, const _Float16 *rs1, ptrdiff_t rs2,
                            size_t vl);
vfloat16m4_t __riscv_vlse16(vbool4_t vm, const _Float16 *rs1, ptrdiff_t rs2,
                            size_t vl);
vfloat16m8_t __riscv_vlse16(vbool2_t vm, const _Float16 *rs1, ptrdiff_t rs2,
                            size_t vl);
----

[[overloaded-vector-strided-store]]
==== Vector Strided Store Intrinsics

[,c]
----
void __riscv_vsse16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4_t vs3, size_t vl);
void __riscv_vsse16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2_t vs3, size_t vl);
void __riscv_vsse16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1_t vs3, size_t vl);
void __riscv_vsse16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m2_t vs3, size_t vl);
void __riscv_vsse16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m4_t vs3, size_t vl);
void __riscv_vsse16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m8_t vs3, size_t vl);
// masked functions
void __riscv_vsse16(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                    vfloat16mf4_t vs3, size_t vl);
void __riscv_vsse16(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                    vfloat16mf2_t vs3, size_t vl);
void __riscv_vsse16(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                    vfloat16m1_t vs3, size_t vl);
void __riscv_vsse16(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2, vfloat16m2_t vs3,
                    size_t vl);
void __riscv_vsse16(vbool4_t vm, _Float16 *rs1, ptrdiff_t rs2, vfloat16m4_t vs3,
                    size_t vl);
void __riscv_vsse16(vbool2_t vm, _Float16 *rs1, ptrdiff_t rs2, vfloat16m8_t vs3,
                    size_t vl);
----

[[overloaded-vector-indexed-load]]
==== Vector Indexed Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vloxei16(const _Float16 *rs1, vuint16mf4_t rs2,
                               size_t vl);
vfloat16mf2_t __riscv_vloxei16(const _Float16 *rs1, vuint16mf2_t rs2,
                               size_t vl);
vfloat16m1_t __riscv_vloxei16(const _Float16 *rs1, vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vloxei16(const _Float16 *rs1, vuint16m2_t rs2, size_t vl);
vfloat16m4_t __riscv_vloxei16(const _Float16 *rs1, vuint16m4_t rs2, size_t vl);
vfloat16m8_t __riscv_vloxei16(const _Float16 *rs1, vuint16m8_t rs2, size_t vl);
vfloat16mf4_t __riscv_vluxei16(const _Float16 *rs1, vuint16mf4_t rs2,
                               size_t vl);
vfloat16mf2_t __riscv_vluxei16(const _Float16 *rs1, vuint16mf2_t rs2,
                               size_t vl);
vfloat16m1_t __riscv_vluxei16(const _Float16 *rs1, vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vluxei16(const _Float16 *rs1, vuint16m2_t rs2, size_t vl);
vfloat16m4_t __riscv_vluxei16(const _Float16 *rs1, vuint16m4_t rs2, size_t vl);
vfloat16m8_t __riscv_vluxei16(const _Float16 *rs1, vuint16m8_t rs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vloxei16(vbool64_t vm, const _Float16 *rs1,
                               vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei16(vbool32_t vm, const _Float16 *rs1,
                               vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei16(vbool16_t vm, const _Float16 *rs1,
                              vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vloxei16(vbool8_t vm, const _Float16 *rs1, vuint16m2_t rs2,
                              size_t vl);
vfloat16m4_t __riscv_vloxei16(vbool4_t vm, const _Float16 *rs1, vuint16m4_t rs2,
                              size_t vl);
vfloat16m8_t __riscv_vloxei16(vbool2_t vm, const _Float16 *rs1, vuint16m8_t rs2,
                              size_t vl);
vfloat16mf4_t __riscv_vluxei16(vbool64_t vm, const _Float16 *rs1,
                               vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei16(vbool32_t vm, const _Float16 *rs1,
                               vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei16(vbool16_t vm, const _Float16 *rs1,
                              vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vluxei16(vbool8_t vm, const _Float16 *rs1, vuint16m2_t rs2,
                              size_t vl);
vfloat16m4_t __riscv_vluxei16(vbool4_t vm, const _Float16 *rs1, vuint16m4_t rs2,
                              size_t vl);
vfloat16m8_t __riscv_vluxei16(vbool2_t vm, const _Float16 *rs1, vuint16m8_t rs2,
                              size_t vl);
----

[[overloaded-vector-indexed-store]]
==== Vector Indexed Store Intrinsics

[,c]
----
void __riscv_vsoxei16(_Float16 *rs1, vuint16mf4_t rs2, vfloat16mf4_t vs3,
                      size_t vl);
void __riscv_vsoxei16(_Float16 *rs1, vuint16mf2_t rs2, vfloat16mf2_t vs3,
                      size_t vl);
void __riscv_vsoxei16(_Float16 *rs1, vuint16m1_t rs2, vfloat16m1_t vs3,
                      size_t vl);
void __riscv_vsoxei16(_Float16 *rs1, vuint16m2_t rs2, vfloat16m2_t vs3,
                      size_t vl);
void __riscv_vsoxei16(_Float16 *rs1, vuint16m4_t rs2, vfloat16m4_t vs3,
                      size_t vl);
void __riscv_vsoxei16(_Float16 *rs1, vuint16m8_t rs2, vfloat16m8_t vs3,
                      size_t vl);
void __riscv_vsuxei16(_Float16 *rs1, vuint16mf4_t rs2, vfloat16mf4_t vs3,
                      size_t vl);
void __riscv_vsuxei16(_Float16 *rs1, vuint16mf2_t rs2, vfloat16mf2_t vs3,
                      size_t vl);
void __riscv_vsuxei16(_Float16 *rs1, vuint16m1_t rs2, vfloat16m1_t vs3,
                      size_t vl);
void __riscv_vsuxei16(_Float16 *rs1, vuint16m2_t rs2, vfloat16m2_t vs3,
                      size_t vl);
void __riscv_vsuxei16(_Float16 *rs1, vuint16m4_t rs2, vfloat16m4_t vs3,
                      size_t vl);
void __riscv_vsuxei16(_Float16 *rs1, vuint16m8_t rs2, vfloat16m8_t vs3,
                      size_t vl);
// masked functions
void __riscv_vsoxei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t rs2,
                      vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t rs2,
                      vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t rs2,
                      vfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei16(vbool8_t vm, _Float16 *rs1, vuint16m2_t rs2,
                      vfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei16(vbool4_t vm, _Float16 *rs1, vuint16m4_t rs2,
                      vfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei16(vbool2_t vm, _Float16 *rs1, vuint16m8_t rs2,
                      vfloat16m8_t vs3, size_t vl);
void __riscv_vsuxei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t rs2,
                      vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t rs2,
                      vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t rs2,
                      vfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei16(vbool8_t vm, _Float16 *rs1, vuint16m2_t rs2,
                      vfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei16(vbool4_t vm, _Float16 *rs1, vuint16m4_t rs2,
                      vfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei16(vbool2_t vm, _Float16 *rs1, vuint16m8_t rs2,
                      vfloat16m8_t vs3, size_t vl);
----

[[overloaded-unit-stride-fault-only-first-loads]]
==== Unit-stride Fault-Only-First Loads Intrinsics

[,c]
----
// masked functions
vfloat16mf4_t __riscv_vle16ff(vbool64_t vm, const _Float16 *rs1, size_t *new_vl,
                              size_t vl);
vfloat16mf2_t __riscv_vle16ff(vbool32_t vm, const _Float16 *rs1, size_t *new_vl,
                              size_t vl);
vfloat16m1_t __riscv_vle16ff(vbool16_t vm, const _Float16 *rs1, size_t *new_vl,
                             size_t vl);
vfloat16m2_t __riscv_vle16ff(vbool8_t vm, const _Float16 *rs1, size_t *new_vl,
                             size_t vl);
vfloat16m4_t __riscv_vle16ff(vbool4_t vm, const _Float16 *rs1, size_t *new_vl,
                             size_t vl);
vfloat16m8_t __riscv_vle16ff(vbool2_t vm, const _Float16 *rs1, size_t *new_vl,
                             size_t vl);
----

=== Float16 Vector Loads and Stores Segment Intrinsics

[[overloaded-vector-unit-stride-segment-load]]
==== Vector Unit-Stride Segment Load Intrinsics

[,c]
----
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16(vbool64_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16(vbool64_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16(vbool64_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16(vbool64_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16(vbool64_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16(vbool64_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16(vbool64_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16(vbool32_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16(vbool32_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16(vbool32_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16(vbool32_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16(vbool32_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16(vbool32_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16(vbool32_t vm, const _Float16 *rs1, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16(vbool16_t vm, const _Float16 *rs1, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16(vbool16_t vm, const _Float16 *rs1, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16(vbool16_t vm, const _Float16 *rs1, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16(vbool16_t vm, const _Float16 *rs1, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16(vbool16_t vm, const _Float16 *rs1, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16(vbool16_t vm, const _Float16 *rs1, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16(vbool16_t vm, const _Float16 *rs1, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16(vbool8_t vm, const _Float16 *rs1, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16(vbool8_t vm, const _Float16 *rs1, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16(vbool8_t vm, const _Float16 *rs1, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16(vbool4_t vm, const _Float16 *rs1, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff(vbool64_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff(vbool64_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff(vbool64_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff(vbool64_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff(vbool64_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff(vbool64_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff(vbool64_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff(vbool32_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff(vbool32_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff(vbool32_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff(vbool32_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff(vbool32_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff(vbool32_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff(vbool32_t vm, const _Float16 *rs1,
                                    size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff(vbool16_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff(vbool16_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff(vbool16_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff(vbool16_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff(vbool16_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff(vbool16_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff(vbool16_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff(vbool8_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff(vbool8_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff(vbool8_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff(vbool4_t vm, const _Float16 *rs1,
                                   size_t *new_vl, size_t vl);
----

[[overloaded-vecrtor-unit-stride-segment-store]]
==== Vector Unit-Stride Segment Store Intrinsics

[,c]
----
void __riscv_vsseg2e16(_Float16 *rs1, vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsseg3e16(_Float16 *rs1, vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsseg4e16(_Float16 *rs1, vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsseg5e16(_Float16 *rs1, vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsseg6e16(_Float16 *rs1, vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsseg7e16(_Float16 *rs1, vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsseg8e16(_Float16 *rs1, vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsseg2e16(_Float16 *rs1, vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e16(_Float16 *rs1, vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e16(_Float16 *rs1, vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e16(_Float16 *rs1, vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e16(_Float16 *rs1, vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e16(_Float16 *rs1, vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e16(_Float16 *rs1, vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e16(_Float16 *rs1, vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsseg3e16(_Float16 *rs1, vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsseg4e16(_Float16 *rs1, vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsseg5e16(_Float16 *rs1, vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsseg6e16(_Float16 *rs1, vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsseg7e16(_Float16 *rs1, vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsseg8e16(_Float16 *rs1, vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsseg2e16(_Float16 *rs1, vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsseg3e16(_Float16 *rs1, vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsseg4e16(_Float16 *rs1, vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsseg2e16(_Float16 *rs1, vfloat16m4x2_t vs3, size_t vl);
// masked functions
void __riscv_vsseg2e16(vbool64_t vm, _Float16 *rs1, vfloat16mf4x2_t vs3,
                       size_t vl);
void __riscv_vsseg3e16(vbool64_t vm, _Float16 *rs1, vfloat16mf4x3_t vs3,
                       size_t vl);
void __riscv_vsseg4e16(vbool64_t vm, _Float16 *rs1, vfloat16mf4x4_t vs3,
                       size_t vl);
void __riscv_vsseg5e16(vbool64_t vm, _Float16 *rs1, vfloat16mf4x5_t vs3,
                       size_t vl);
void __riscv_vsseg6e16(vbool64_t vm, _Float16 *rs1, vfloat16mf4x6_t vs3,
                       size_t vl);
void __riscv_vsseg7e16(vbool64_t vm, _Float16 *rs1, vfloat16mf4x7_t vs3,
                       size_t vl);
void __riscv_vsseg8e16(vbool64_t vm, _Float16 *rs1, vfloat16mf4x8_t vs3,
                       size_t vl);
void __riscv_vsseg2e16(vbool32_t vm, _Float16 *rs1, vfloat16mf2x2_t vs3,
                       size_t vl);
void __riscv_vsseg3e16(vbool32_t vm, _Float16 *rs1, vfloat16mf2x3_t vs3,
                       size_t vl);
void __riscv_vsseg4e16(vbool32_t vm, _Float16 *rs1, vfloat16mf2x4_t vs3,
                       size_t vl);
void __riscv_vsseg5e16(vbool32_t vm, _Float16 *rs1, vfloat16mf2x5_t vs3,
                       size_t vl);
void __riscv_vsseg6e16(vbool32_t vm, _Float16 *rs1, vfloat16mf2x6_t vs3,
                       size_t vl);
void __riscv_vsseg7e16(vbool32_t vm, _Float16 *rs1, vfloat16mf2x7_t vs3,
                       size_t vl);
void __riscv_vsseg8e16(vbool32_t vm, _Float16 *rs1, vfloat16mf2x8_t vs3,
                       size_t vl);
void __riscv_vsseg2e16(vbool16_t vm, _Float16 *rs1, vfloat16m1x2_t vs3,
                       size_t vl);
void __riscv_vsseg3e16(vbool16_t vm, _Float16 *rs1, vfloat16m1x3_t vs3,
                       size_t vl);
void __riscv_vsseg4e16(vbool16_t vm, _Float16 *rs1, vfloat16m1x4_t vs3,
                       size_t vl);
void __riscv_vsseg5e16(vbool16_t vm, _Float16 *rs1, vfloat16m1x5_t vs3,
                       size_t vl);
void __riscv_vsseg6e16(vbool16_t vm, _Float16 *rs1, vfloat16m1x6_t vs3,
                       size_t vl);
void __riscv_vsseg7e16(vbool16_t vm, _Float16 *rs1, vfloat16m1x7_t vs3,
                       size_t vl);
void __riscv_vsseg8e16(vbool16_t vm, _Float16 *rs1, vfloat16m1x8_t vs3,
                       size_t vl);
void __riscv_vsseg2e16(vbool8_t vm, _Float16 *rs1, vfloat16m2x2_t vs3,
                       size_t vl);
void __riscv_vsseg3e16(vbool8_t vm, _Float16 *rs1, vfloat16m2x3_t vs3,
                       size_t vl);
void __riscv_vsseg4e16(vbool8_t vm, _Float16 *rs1, vfloat16m2x4_t vs3,
                       size_t vl);
void __riscv_vsseg2e16(vbool4_t vm, _Float16 *rs1, vfloat16m4x2_t vs3,
                       size_t vl);
----

[[overloaded-vector-strided-segment-load]]
==== Vector Strided Segment Load Intrinsics

[,c]
----
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16(vbool64_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16(vbool64_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16(vbool64_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16(vbool64_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16(vbool64_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16(vbool64_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16(vbool64_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16(vbool32_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16(vbool32_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16(vbool32_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16(vbool32_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16(vbool32_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16(vbool32_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16(vbool32_t vm, const _Float16 *rs1,
                                   ptrdiff_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16(vbool16_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16(vbool16_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16(vbool16_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16(vbool16_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16(vbool16_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16(vbool16_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16(vbool16_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16(vbool8_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16(vbool8_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16(vbool8_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16(vbool4_t vm, const _Float16 *rs1,
                                  ptrdiff_t rs2, size_t vl);
----

[[overloaded-vector-strided-segment-store]]
==== Vector Strided Segment Store Intrinsics

[,c]
----
void __riscv_vssseg2e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4x2_t vs3,
                        size_t vl);
void __riscv_vssseg3e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4x3_t vs3,
                        size_t vl);
void __riscv_vssseg4e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4x4_t vs3,
                        size_t vl);
void __riscv_vssseg5e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4x5_t vs3,
                        size_t vl);
void __riscv_vssseg6e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4x6_t vs3,
                        size_t vl);
void __riscv_vssseg7e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4x7_t vs3,
                        size_t vl);
void __riscv_vssseg8e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4x8_t vs3,
                        size_t vl);
void __riscv_vssseg2e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2x2_t vs3,
                        size_t vl);
void __riscv_vssseg3e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2x3_t vs3,
                        size_t vl);
void __riscv_vssseg4e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2x4_t vs3,
                        size_t vl);
void __riscv_vssseg5e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2x5_t vs3,
                        size_t vl);
void __riscv_vssseg6e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2x6_t vs3,
                        size_t vl);
void __riscv_vssseg7e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2x7_t vs3,
                        size_t vl);
void __riscv_vssseg8e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2x8_t vs3,
                        size_t vl);
void __riscv_vssseg2e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1x2_t vs3,
                        size_t vl);
void __riscv_vssseg3e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1x3_t vs3,
                        size_t vl);
void __riscv_vssseg4e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1x4_t vs3,
                        size_t vl);
void __riscv_vssseg5e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1x5_t vs3,
                        size_t vl);
void __riscv_vssseg6e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1x6_t vs3,
                        size_t vl);
void __riscv_vssseg7e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1x7_t vs3,
                        size_t vl);
void __riscv_vssseg8e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1x8_t vs3,
                        size_t vl);
void __riscv_vssseg2e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m2x2_t vs3,
                        size_t vl);
void __riscv_vssseg3e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m2x3_t vs3,
                        size_t vl);
void __riscv_vssseg4e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m2x4_t vs3,
                        size_t vl);
void __riscv_vssseg2e16(_Float16 *rs1, ptrdiff_t rs2, vfloat16m4x2_t vs3,
                        size_t vl);
// masked functions
void __riscv_vssseg2e16(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e16(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e16(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e16(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e16(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e16(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e16(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e16(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e16(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e16(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e16(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e16(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e16(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e16(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e16(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m1x2_t vs3, size_t vl);
void __riscv_vssseg3e16(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m1x3_t vs3, size_t vl);
void __riscv_vssseg4e16(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m1x4_t vs3, size_t vl);
void __riscv_vssseg5e16(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m1x5_t vs3, size_t vl);
void __riscv_vssseg6e16(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m1x6_t vs3, size_t vl);
void __riscv_vssseg7e16(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m1x7_t vs3, size_t vl);
void __riscv_vssseg8e16(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m1x8_t vs3, size_t vl);
void __riscv_vssseg2e16(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m2x2_t vs3, size_t vl);
void __riscv_vssseg3e16(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m2x3_t vs3, size_t vl);
void __riscv_vssseg4e16(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m2x4_t vs3, size_t vl);
void __riscv_vssseg2e16(vbool4_t vm, _Float16 *rs1, ptrdiff_t rs2,
                        vfloat16m4x2_t vs3, size_t vl);
----

[[overloaded-vector-indexed-segment-load]]
==== Vector Indexed Segment Load Intrinsics

[,c]
----
vfloat16mf4x2_t __riscv_vloxseg2ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16(const _Float16 *rs1, vuint16m2_t rs2,
                                    size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16(const _Float16 *rs1, vuint16m2_t rs2,
                                    size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16(const _Float16 *rs1, vuint16m2_t rs2,
                                    size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16(const _Float16 *rs1, vuint16m4_t rs2,
                                    size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16(const _Float16 *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16(const _Float16 *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16(const _Float16 *rs1, vuint16m1_t rs2,
                                    size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16(const _Float16 *rs1, vuint16m2_t rs2,
                                    size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16(const _Float16 *rs1, vuint16m2_t rs2,
                                    size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16(const _Float16 *rs1, vuint16m2_t rs2,
                                    size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16(const _Float16 *rs1, vuint16m4_t rs2,
                                    size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16(vbool8_t vm, const _Float16 *rs1,
                                    vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16(vbool8_t vm, const _Float16 *rs1,
                                    vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16(vbool8_t vm, const _Float16 *rs1,
                                    vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16(vbool4_t vm, const _Float16 *rs1,
                                    vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16(vbool64_t vm, const _Float16 *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16(vbool32_t vm, const _Float16 *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16(vbool16_t vm, const _Float16 *rs1,
                                    vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16(vbool8_t vm, const _Float16 *rs1,
                                    vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16(vbool8_t vm, const _Float16 *rs1,
                                    vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16(vbool8_t vm, const _Float16 *rs1,
                                    vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16(vbool4_t vm, const _Float16 *rs1,
                                    vuint16m4_t rs2, size_t vl);
----

[[overloaded-vector-indexed-segment-store]]
==== Vector Indexed Segment Store Intrinsics

[,c]
----
void __riscv_vsoxseg2ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x2_t vs3,
                          size_t vl);
void __riscv_vsoxseg3ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x3_t vs3,
                          size_t vl);
void __riscv_vsoxseg4ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x4_t vs3,
                          size_t vl);
void __riscv_vsoxseg5ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x5_t vs3,
                          size_t vl);
void __riscv_vsoxseg6ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x6_t vs3,
                          size_t vl);
void __riscv_vsoxseg7ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x7_t vs3,
                          size_t vl);
void __riscv_vsoxseg8ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x8_t vs3,
                          size_t vl);
void __riscv_vsoxseg2ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x2_t vs3,
                          size_t vl);
void __riscv_vsoxseg3ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x3_t vs3,
                          size_t vl);
void __riscv_vsoxseg4ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x4_t vs3,
                          size_t vl);
void __riscv_vsoxseg5ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x5_t vs3,
                          size_t vl);
void __riscv_vsoxseg6ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x6_t vs3,
                          size_t vl);
void __riscv_vsoxseg7ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x7_t vs3,
                          size_t vl);
void __riscv_vsoxseg8ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x8_t vs3,
                          size_t vl);
void __riscv_vsoxseg2ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x2_t vs3,
                          size_t vl);
void __riscv_vsoxseg3ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x3_t vs3,
                          size_t vl);
void __riscv_vsoxseg4ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x4_t vs3,
                          size_t vl);
void __riscv_vsoxseg5ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x5_t vs3,
                          size_t vl);
void __riscv_vsoxseg6ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x6_t vs3,
                          size_t vl);
void __riscv_vsoxseg7ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x7_t vs3,
                          size_t vl);
void __riscv_vsoxseg8ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x8_t vs3,
                          size_t vl);
void __riscv_vsoxseg2ei16(_Float16 *rs1, vuint16m2_t vs2, vfloat16m2x2_t vs3,
                          size_t vl);
void __riscv_vsoxseg3ei16(_Float16 *rs1, vuint16m2_t vs2, vfloat16m2x3_t vs3,
                          size_t vl);
void __riscv_vsoxseg4ei16(_Float16 *rs1, vuint16m2_t vs2, vfloat16m2x4_t vs3,
                          size_t vl);
void __riscv_vsoxseg2ei16(_Float16 *rs1, vuint16m4_t vs2, vfloat16m4x2_t vs3,
                          size_t vl);
void __riscv_vsuxseg2ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x2_t vs3,
                          size_t vl);
void __riscv_vsuxseg3ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x3_t vs3,
                          size_t vl);
void __riscv_vsuxseg4ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x4_t vs3,
                          size_t vl);
void __riscv_vsuxseg5ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x5_t vs3,
                          size_t vl);
void __riscv_vsuxseg6ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x6_t vs3,
                          size_t vl);
void __riscv_vsuxseg7ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x7_t vs3,
                          size_t vl);
void __riscv_vsuxseg8ei16(_Float16 *rs1, vuint16mf4_t vs2, vfloat16mf4x8_t vs3,
                          size_t vl);
void __riscv_vsuxseg2ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x2_t vs3,
                          size_t vl);
void __riscv_vsuxseg3ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x3_t vs3,
                          size_t vl);
void __riscv_vsuxseg4ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x4_t vs3,
                          size_t vl);
void __riscv_vsuxseg5ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x5_t vs3,
                          size_t vl);
void __riscv_vsuxseg6ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x6_t vs3,
                          size_t vl);
void __riscv_vsuxseg7ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x7_t vs3,
                          size_t vl);
void __riscv_vsuxseg8ei16(_Float16 *rs1, vuint16mf2_t vs2, vfloat16mf2x8_t vs3,
                          size_t vl);
void __riscv_vsuxseg2ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x2_t vs3,
                          size_t vl);
void __riscv_vsuxseg3ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x3_t vs3,
                          size_t vl);
void __riscv_vsuxseg4ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x4_t vs3,
                          size_t vl);
void __riscv_vsuxseg5ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x5_t vs3,
                          size_t vl);
void __riscv_vsuxseg6ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x6_t vs3,
                          size_t vl);
void __riscv_vsuxseg7ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x7_t vs3,
                          size_t vl);
void __riscv_vsuxseg8ei16(_Float16 *rs1, vuint16m1_t vs2, vfloat16m1x8_t vs3,
                          size_t vl);
void __riscv_vsuxseg2ei16(_Float16 *rs1, vuint16m2_t vs2, vfloat16m2x2_t vs3,
                          size_t vl);
void __riscv_vsuxseg3ei16(_Float16 *rs1, vuint16m2_t vs2, vfloat16m2x3_t vs3,
                          size_t vl);
void __riscv_vsuxseg4ei16(_Float16 *rs1, vuint16m2_t vs2, vfloat16m2x4_t vs3,
                          size_t vl);
void __riscv_vsuxseg2ei16(_Float16 *rs1, vuint16m4_t vs2, vfloat16m4x2_t vs3,
                          size_t vl);
// masked functions
void __riscv_vsoxseg2ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16(vbool8_t vm, _Float16 *rs1, vuint16m2_t vs2,
                          vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16(vbool8_t vm, _Float16 *rs1, vuint16m2_t vs2,
                          vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16(vbool8_t vm, _Float16 *rs1, vuint16m2_t vs2,
                          vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16(vbool4_t vm, _Float16 *rs1, vuint16m4_t vs2,
                          vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16(vbool64_t vm, _Float16 *rs1, vuint16mf4_t vs2,
                          vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16(vbool32_t vm, _Float16 *rs1, vuint16mf2_t vs2,
                          vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16(vbool16_t vm, _Float16 *rs1, vuint16m1_t vs2,
                          vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16(vbool8_t vm, _Float16 *rs1, vuint16m2_t vs2,
                          vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16(vbool8_t vm, _Float16 *rs1, vuint16m2_t vs2,
                          vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16(vbool8_t vm, _Float16 *rs1, vuint16m2_t vs2,
                          vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16(vbool4_t vm, _Float16 *rs1, vuint16m4_t vs2,
                          vfloat16m4x2_t vs3, size_t vl);
----

=== Float16 Miscellaneous Vector Utility Intrinsics

[[overloaded-reinterpret-cast-conversion]]
==== Reinterpret Cast Conversion Intrinsics

[,c]
----
// Reinterpret between different type under the same SEW/LMUL
vfloat16mf4_t __riscv_vreinterpret_f16mf4(vint16mf4_t src);
vfloat16mf2_t __riscv_vreinterpret_f16mf2(vint16mf2_t src);
vfloat16m1_t __riscv_vreinterpret_f16m1(vint16m1_t src);
vfloat16m2_t __riscv_vreinterpret_f16m2(vint16m2_t src);
vfloat16m4_t __riscv_vreinterpret_f16m4(vint16m4_t src);
vfloat16m8_t __riscv_vreinterpret_f16m8(vint16m8_t src);
vfloat16mf4_t __riscv_vreinterpret_f16mf4(vuint16mf4_t src);
vfloat16mf2_t __riscv_vreinterpret_f16mf2(vuint16mf2_t src);
vfloat16m1_t __riscv_vreinterpret_f16m1(vuint16m1_t src);
vfloat16m2_t __riscv_vreinterpret_f16m2(vuint16m2_t src);
vfloat16m4_t __riscv_vreinterpret_f16m4(vuint16m4_t src);
vfloat16m8_t __riscv_vreinterpret_f16m8(vuint16m8_t src);
vuint16mf4_t __riscv_vreinterpret_u16mf4(vint16mf4_t src);
vuint16mf2_t __riscv_vreinterpret_u16mf2(vint16mf2_t src);
vuint16m1_t __riscv_vreinterpret_u16m1(vint16m1_t src);
vuint16m2_t __riscv_vreinterpret_u16m2(vint16m2_t src);
vuint16m4_t __riscv_vreinterpret_u16m4(vint16m4_t src);
vuint16m8_t __riscv_vreinterpret_u16m8(vint16m8_t src);
vint16mf4_t __riscv_vreinterpret_i16mf4(vuint16mf4_t src);
vint16mf2_t __riscv_vreinterpret_i16mf2(vuint16mf2_t src);
vint16m1_t __riscv_vreinterpret_i16m1(vuint16m1_t src);
vint16m2_t __riscv_vreinterpret_i16m2(vuint16m2_t src);
vint16m4_t __riscv_vreinterpret_i16m4(vuint16m4_t src);
vint16m8_t __riscv_vreinterpret_i16m8(vuint16m8_t src);
vint16mf4_t __riscv_vreinterpret_i16mf4(vfloat16mf4_t src);
vint16mf2_t __riscv_vreinterpret_i16mf2(vfloat16mf2_t src);
vint16m1_t __riscv_vreinterpret_i16m1(vfloat16m1_t src);
vint16m2_t __riscv_vreinterpret_i16m2(vfloat16m2_t src);
vint16m4_t __riscv_vreinterpret_i16m4(vfloat16m4_t src);
vint16m8_t __riscv_vreinterpret_i16m8(vfloat16m8_t src);
vuint16mf4_t __riscv_vreinterpret_u16mf4(vfloat16mf4_t src);
vuint16mf2_t __riscv_vreinterpret_u16mf2(vfloat16mf2_t src);
vuint16m1_t __riscv_vreinterpret_u16m1(vfloat16m1_t src);
vuint16m2_t __riscv_vreinterpret_u16m2(vfloat16m2_t src);
vuint16m4_t __riscv_vreinterpret_u16m4(vfloat16m4_t src);
vuint16m8_t __riscv_vreinterpret_u16m8(vfloat16m8_t src);
// Reinterpret between different SEW under the same LMUL
// Reinterpret between vector boolean types and LMUL=1 (m1) vector integer types
vbool64_t __riscv_vreinterpret_b64(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_i16m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_b32(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_i16m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_b16(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_i16m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_b8(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_i16m1(vbool8_t src);
vbool4_t __riscv_vreinterpret_b4(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_i16m1(vbool4_t src);
vbool2_t __riscv_vreinterpret_b2(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_i16m1(vbool2_t src);
vbool64_t __riscv_vreinterpret_b64(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_u16m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_b32(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_u16m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_b16(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_u16m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_b8(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_u16m1(vbool8_t src);
vbool4_t __riscv_vreinterpret_b4(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_u16m1(vbool4_t src);
vbool2_t __riscv_vreinterpret_b2(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_u16m1(vbool2_t src);
----

[[overloaded-vector-lmul-extensionn]]
==== Vector LMUL Extension Intrinsics

[,c]
----
vfloat16mf2_t __riscv_vlmul_ext_f16mf2(vfloat16mf4_t value);
vfloat16m1_t __riscv_vlmul_ext_f16m1(vfloat16mf4_t value);
vfloat16m2_t __riscv_vlmul_ext_f16m2(vfloat16mf4_t value);
vfloat16m4_t __riscv_vlmul_ext_f16m4(vfloat16mf4_t value);
vfloat16m8_t __riscv_vlmul_ext_f16m8(vfloat16mf4_t value);
vfloat16m1_t __riscv_vlmul_ext_f16m1(vfloat16mf2_t value);
vfloat16m2_t __riscv_vlmul_ext_f16m2(vfloat16mf2_t value);
vfloat16m4_t __riscv_vlmul_ext_f16m4(vfloat16mf2_t value);
vfloat16m8_t __riscv_vlmul_ext_f16m8(vfloat16mf2_t value);
vfloat16m2_t __riscv_vlmul_ext_f16m2(vfloat16m1_t value);
vfloat16m4_t __riscv_vlmul_ext_f16m4(vfloat16m1_t value);
vfloat16m8_t __riscv_vlmul_ext_f16m8(vfloat16m1_t value);
vfloat16m4_t __riscv_vlmul_ext_f16m4(vfloat16m2_t value);
vfloat16m8_t __riscv_vlmul_ext_f16m8(vfloat16m2_t value);
vfloat16m8_t __riscv_vlmul_ext_f16m8(vfloat16m4_t value);
----

[[overloaded-vector-lmul-truncation]]
==== Vector LMUL Truncation Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vlmul_trunc_f16mf4(vfloat16mf2_t value);
vfloat16mf4_t __riscv_vlmul_trunc_f16mf4(vfloat16m1_t value);
vfloat16mf2_t __riscv_vlmul_trunc_f16mf2(vfloat16m1_t value);
vfloat16mf4_t __riscv_vlmul_trunc_f16mf4(vfloat16m2_t value);
vfloat16mf2_t __riscv_vlmul_trunc_f16mf2(vfloat16m2_t value);
vfloat16m1_t __riscv_vlmul_trunc_f16m1(vfloat16m2_t value);
vfloat16mf4_t __riscv_vlmul_trunc_f16mf4(vfloat16m4_t value);
vfloat16mf2_t __riscv_vlmul_trunc_f16mf2(vfloat16m4_t value);
vfloat16m1_t __riscv_vlmul_trunc_f16m1(vfloat16m4_t value);
vfloat16m2_t __riscv_vlmul_trunc_f16m2(vfloat16m4_t value);
vfloat16mf4_t __riscv_vlmul_trunc_f16mf4(vfloat16m8_t value);
vfloat16mf2_t __riscv_vlmul_trunc_f16mf2(vfloat16m8_t value);
vfloat16m1_t __riscv_vlmul_trunc_f16m1(vfloat16m8_t value);
vfloat16m2_t __riscv_vlmul_trunc_f16m2(vfloat16m8_t value);
vfloat16m4_t __riscv_vlmul_trunc_f16m4(vfloat16m8_t value);
----

[[overloaded-vector-initialization]]
==== Vector Initialization Intrinsics
Intrinsics here don't have an overloaded variant.

[[overloaded-vector-insertion]]
==== Vector Insertion Intrinsics

[,c]
----
vfloat16m2_t __riscv_vset(vfloat16m2_t dest, size_t index, vfloat16m1_t value);
vfloat16m4_t __riscv_vset(vfloat16m4_t dest, size_t index, vfloat16m1_t value);
vfloat16m4_t __riscv_vset(vfloat16m4_t dest, size_t index, vfloat16m2_t value);
vfloat16m8_t __riscv_vset(vfloat16m8_t dest, size_t index, vfloat16m1_t value);
vfloat16m8_t __riscv_vset(vfloat16m8_t dest, size_t index, vfloat16m2_t value);
vfloat16m8_t __riscv_vset(vfloat16m8_t dest, size_t index, vfloat16m4_t value);
vfloat16mf4x2_t __riscv_vset(vfloat16mf4x2_t dest, size_t index,
                             vfloat16mf4_t value);
vfloat16mf4x3_t __riscv_vset(vfloat16mf4x3_t dest, size_t index,
                             vfloat16mf4_t value);
vfloat16mf4x4_t __riscv_vset(vfloat16mf4x4_t dest, size_t index,
                             vfloat16mf4_t value);
vfloat16mf4x5_t __riscv_vset(vfloat16mf4x5_t dest, size_t index,
                             vfloat16mf4_t value);
vfloat16mf4x6_t __riscv_vset(vfloat16mf4x6_t dest, size_t index,
                             vfloat16mf4_t value);
vfloat16mf4x7_t __riscv_vset(vfloat16mf4x7_t dest, size_t index,
                             vfloat16mf4_t value);
vfloat16mf4x8_t __riscv_vset(vfloat16mf4x8_t dest, size_t index,
                             vfloat16mf4_t value);
vfloat16mf2x2_t __riscv_vset(vfloat16mf2x2_t dest, size_t index,
                             vfloat16mf2_t value);
vfloat16mf2x3_t __riscv_vset(vfloat16mf2x3_t dest, size_t index,
                             vfloat16mf2_t value);
vfloat16mf2x4_t __riscv_vset(vfloat16mf2x4_t dest, size_t index,
                             vfloat16mf2_t value);
vfloat16mf2x5_t __riscv_vset(vfloat16mf2x5_t dest, size_t index,
                             vfloat16mf2_t value);
vfloat16mf2x6_t __riscv_vset(vfloat16mf2x6_t dest, size_t index,
                             vfloat16mf2_t value);
vfloat16mf2x7_t __riscv_vset(vfloat16mf2x7_t dest, size_t index,
                             vfloat16mf2_t value);
vfloat16mf2x8_t __riscv_vset(vfloat16mf2x8_t dest, size_t index,
                             vfloat16mf2_t value);
vfloat16m1x2_t __riscv_vset(vfloat16m1x2_t dest, size_t index,
                            vfloat16m1_t value);
vfloat16m1x3_t __riscv_vset(vfloat16m1x3_t dest, size_t index,
                            vfloat16m1_t value);
vfloat16m1x4_t __riscv_vset(vfloat16m1x4_t dest, size_t index,
                            vfloat16m1_t value);
vfloat16m1x5_t __riscv_vset(vfloat16m1x5_t dest, size_t index,
                            vfloat16m1_t value);
vfloat16m1x6_t __riscv_vset(vfloat16m1x6_t dest, size_t index,
                            vfloat16m1_t value);
vfloat16m1x7_t __riscv_vset(vfloat16m1x7_t dest, size_t index,
                            vfloat16m1_t value);
vfloat16m1x8_t __riscv_vset(vfloat16m1x8_t dest, size_t index,
                            vfloat16m1_t value);
vfloat16m2x2_t __riscv_vset(vfloat16m2x2_t dest, size_t index,
                            vfloat16m2_t value);
vfloat16m2x3_t __riscv_vset(vfloat16m2x3_t dest, size_t index,
                            vfloat16m2_t value);
vfloat16m2x4_t __riscv_vset(vfloat16m2x4_t dest, size_t index,
                            vfloat16m2_t value);
vfloat16m4x2_t __riscv_vset(vfloat16m4x2_t dest, size_t index,
                            vfloat16m4_t value);
----

[[overloaded-vector-extraction]]
==== Vector Extraction Intrinsics

[,c]
----
vfloat16m1_t __riscv_vget_f16m1(vfloat16m2_t src, size_t index);
vfloat16m1_t __riscv_vget_f16m1(vfloat16m4_t src, size_t index);
vfloat16m1_t __riscv_vget_f16m1(vfloat16m8_t src, size_t index);
vfloat16m2_t __riscv_vget_f16m2(vfloat16m4_t src, size_t index);
vfloat16m2_t __riscv_vget_f16m2(vfloat16m8_t src, size_t index);
vfloat16m4_t __riscv_vget_f16m4(vfloat16m8_t src, size_t index);
vfloat16mf4_t __riscv_vget_f16mf4(vfloat16mf4x2_t src, size_t index);
vfloat16mf4_t __riscv_vget_f16mf4(vfloat16mf4x3_t src, size_t index);
vfloat16mf4_t __riscv_vget_f16mf4(vfloat16mf4x4_t src, size_t index);
vfloat16mf4_t __riscv_vget_f16mf4(vfloat16mf4x5_t src, size_t index);
vfloat16mf4_t __riscv_vget_f16mf4(vfloat16mf4x6_t src, size_t index);
vfloat16mf4_t __riscv_vget_f16mf4(vfloat16mf4x7_t src, size_t index);
vfloat16mf4_t __riscv_vget_f16mf4(vfloat16mf4x8_t src, size_t index);
vfloat16mf2_t __riscv_vget_f16mf2(vfloat16mf2x2_t src, size_t index);
vfloat16mf2_t __riscv_vget_f16mf2(vfloat16mf2x3_t src, size_t index);
vfloat16mf2_t __riscv_vget_f16mf2(vfloat16mf2x4_t src, size_t index);
vfloat16mf2_t __riscv_vget_f16mf2(vfloat16mf2x5_t src, size_t index);
vfloat16mf2_t __riscv_vget_f16mf2(vfloat16mf2x6_t src, size_t index);
vfloat16mf2_t __riscv_vget_f16mf2(vfloat16mf2x7_t src, size_t index);
vfloat16mf2_t __riscv_vget_f16mf2(vfloat16mf2x8_t src, size_t index);
vfloat16m1_t __riscv_vget_f16m1(vfloat16m1x2_t src, size_t index);
vfloat16m1_t __riscv_vget_f16m1(vfloat16m1x3_t src, size_t index);
vfloat16m1_t __riscv_vget_f16m1(vfloat16m1x4_t src, size_t index);
vfloat16m1_t __riscv_vget_f16m1(vfloat16m1x5_t src, size_t index);
vfloat16m1_t __riscv_vget_f16m1(vfloat16m1x6_t src, size_t index);
vfloat16m1_t __riscv_vget_f16m1(vfloat16m1x7_t src, size_t index);
vfloat16m1_t __riscv_vget_f16m1(vfloat16m1x8_t src, size_t index);
vfloat16m2_t __riscv_vget_f16m2(vfloat16m2x2_t src, size_t index);
vfloat16m2_t __riscv_vget_f16m2(vfloat16m2x3_t src, size_t index);
vfloat16m2_t __riscv_vget_f16m2(vfloat16m2x4_t src, size_t index);
vfloat16m4_t __riscv_vget_f16m4(vfloat16m4x2_t src, size_t index);
----

[[overloaded-vector-creation]]
==== Vector Creation Intrinsics
Intrinsics here don't have an overloaded variant.

=== Vector Permutation Intrinsics

[[overloaded-vector-register-gather]]
==== Vector Register Gather Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vrgather(vfloat16mf4_t vs2, vuint16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vrgather(vfloat16mf4_t vs2, size_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather(vfloat16mf2_t vs2, vuint16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather(vfloat16mf2_t vs2, size_t vs1, size_t vl);
vfloat16m1_t __riscv_vrgather(vfloat16m1_t vs2, vuint16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vrgather(vfloat16m1_t vs2, size_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgather(vfloat16m2_t vs2, vuint16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgather(vfloat16m2_t vs2, size_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgather(vfloat16m4_t vs2, vuint16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgather(vfloat16m4_t vs2, size_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgather(vfloat16m8_t vs2, vuint16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgather(vfloat16m8_t vs2, size_t vs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vrgather(vbool64_t vm, vfloat16mf4_t vs2,
                               vuint16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vrgather(vbool64_t vm, vfloat16mf4_t vs2, size_t vs1,
                               size_t vl);
vfloat16mf2_t __riscv_vrgather(vbool32_t vm, vfloat16mf2_t vs2,
                               vuint16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather(vbool32_t vm, vfloat16mf2_t vs2, size_t vs1,
                               size_t vl);
vfloat16m1_t __riscv_vrgather(vbool16_t vm, vfloat16m1_t vs2, vuint16m1_t vs1,
                              size_t vl);
vfloat16m1_t __riscv_vrgather(vbool16_t vm, vfloat16m1_t vs2, size_t vs1,
                              size_t vl);
vfloat16m2_t __riscv_vrgather(vbool8_t vm, vfloat16m2_t vs2, vuint16m2_t vs1,
                              size_t vl);
vfloat16m2_t __riscv_vrgather(vbool8_t vm, vfloat16m2_t vs2, size_t vs1,
                              size_t vl);
vfloat16m4_t __riscv_vrgather(vbool4_t vm, vfloat16m4_t vs2, vuint16m4_t vs1,
                              size_t vl);
vfloat16m4_t __riscv_vrgather(vbool4_t vm, vfloat16m4_t vs2, size_t vs1,
                              size_t vl);
vfloat16m8_t __riscv_vrgather(vbool2_t vm, vfloat16m8_t vs2, vuint16m8_t vs1,
                              size_t vl);
vfloat16m8_t __riscv_vrgather(vbool2_t vm, vfloat16m8_t vs2, size_t vs1,
                              size_t vl);
----

[[overloaded-vector-compress]]
==== Vector Compress Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vcompress(vfloat16mf4_t vs2, vbool64_t vs1, size_t vl);
vfloat16mf2_t __riscv_vcompress(vfloat16mf2_t vs2, vbool32_t vs1, size_t vl);
vfloat16m1_t __riscv_vcompress(vfloat16m1_t vs2, vbool16_t vs1, size_t vl);
vfloat16m2_t __riscv_vcompress(vfloat16m2_t vs2, vbool8_t vs1, size_t vl);
vfloat16m4_t __riscv_vcompress(vfloat16m4_t vs2, vbool4_t vs1, size_t vl);
vfloat16m8_t __riscv_vcompress(vfloat16m8_t vs2, vbool2_t vs1, size_t vl);
----

=== Vector Float16 Intrinsics

[[overloaded-widening-floating-pointinteger-type-convert]]
==== Widening Floating-Point/Integer Type-Convert Intrinsics

[,c]
----
vfloat32mf2_t __riscv_vfwcvt_f(vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f(vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f(vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f(vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f(vfloat16m4_t vs2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwcvt_f(vbool64_t vm, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f(vbool32_t vm, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f(vbool16_t vm, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f(vbool8_t vm, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f(vbool4_t vm, vfloat16m4_t vs2, size_t vl);
// masked functions
----

[[overloaded-narrowing-floating-pointinteger-type-convert]]
==== Narrowing Floating-Point/Integer Type-Convert Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfncvt_f(vfloat32mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f(vfloat32m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_f(vfloat32m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_f(vfloat32m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_f(vfloat32m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfncvt_f(vbool64_t vm, vfloat32mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f(vbool32_t vm, vfloat32m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_f(vbool16_t vm, vfloat32m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_f(vbool8_t vm, vfloat32m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_f(vbool4_t vm, vfloat32m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f(vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f(vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f(vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f(vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f(vfloat32m8_t vs2, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfncvt_f(vbool64_t vm, vfloat32mf2_t vs2,
                               unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f(vbool32_t vm, vfloat32m1_t vs2, unsigned int frm,
                               size_t vl);
vfloat16m1_t __riscv_vfncvt_f(vbool16_t vm, vfloat32m2_t vs2, unsigned int frm,
                              size_t vl);
vfloat16m2_t __riscv_vfncvt_f(vbool8_t vm, vfloat32m4_t vs2, unsigned int frm,
                              size_t vl);
vfloat16m4_t __riscv_vfncvt_f(vbool4_t vm, vfloat32m8_t vs2, unsigned int frm,
                              size_t vl);
----
