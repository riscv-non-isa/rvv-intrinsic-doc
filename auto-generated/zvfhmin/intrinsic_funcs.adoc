
=== Float16 Vector Loads and Stores Intrinsics

[[vector-unit-stride-load]]
==== Vector Unit-Stride Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vle16_v_f16mf4(const _Float16 *rs1, size_t vl);
vfloat16mf2_t __riscv_vle16_v_f16mf2(const _Float16 *rs1, size_t vl);
vfloat16m1_t __riscv_vle16_v_f16m1(const _Float16 *rs1, size_t vl);
vfloat16m2_t __riscv_vle16_v_f16m2(const _Float16 *rs1, size_t vl);
vfloat16m4_t __riscv_vle16_v_f16m4(const _Float16 *rs1, size_t vl);
vfloat16m8_t __riscv_vle16_v_f16m8(const _Float16 *rs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                       size_t vl);
vfloat16mf2_t __riscv_vle16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                       size_t vl);
vfloat16m1_t __riscv_vle16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                     size_t vl);
vfloat16m2_t __riscv_vle16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                     size_t vl);
vfloat16m4_t __riscv_vle16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                     size_t vl);
vfloat16m8_t __riscv_vle16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                     size_t vl);
----

[[vector-unit-stride-store]]
==== Vector Unit-Stride Store Intrinsics

[,c]
----
void __riscv_vse16_v_f16mf4(_Float16 *rs1, vfloat16mf4_t vs3, size_t vl);
void __riscv_vse16_v_f16mf2(_Float16 *rs1, vfloat16mf2_t vs3, size_t vl);
void __riscv_vse16_v_f16m1(_Float16 *rs1, vfloat16m1_t vs3, size_t vl);
void __riscv_vse16_v_f16m2(_Float16 *rs1, vfloat16m2_t vs3, size_t vl);
void __riscv_vse16_v_f16m4(_Float16 *rs1, vfloat16m4_t vs3, size_t vl);
void __riscv_vse16_v_f16m8(_Float16 *rs1, vfloat16m8_t vs3, size_t vl);
// masked functions
void __riscv_vse16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vfloat16mf4_t vs3,
                              size_t vl);
void __riscv_vse16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vfloat16mf2_t vs3,
                              size_t vl);
void __riscv_vse16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vfloat16m1_t vs3,
                             size_t vl);
void __riscv_vse16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vfloat16m2_t vs3,
                             size_t vl);
void __riscv_vse16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vfloat16m4_t vs3,
                             size_t vl);
void __riscv_vse16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vfloat16m8_t vs3,
                             size_t vl);
----

[[vector-strided-load]]
==== Vector Strided Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vlse16_v_f16mf4(const _Float16 *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat16mf2_t __riscv_vlse16_v_f16mf2(const _Float16 *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat16m1_t __riscv_vlse16_v_f16m1(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat16m2_t __riscv_vlse16_v_f16m2(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat16m4_t __riscv_vlse16_v_f16m4(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat16m8_t __riscv_vlse16_v_f16m8(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
// masked functions
vfloat16mf4_t __riscv_vlse16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                        ptrdiff_t rs2, size_t vl);
vfloat16mf2_t __riscv_vlse16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                        ptrdiff_t rs2, size_t vl);
vfloat16m1_t __riscv_vlse16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat16m2_t __riscv_vlse16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat16m4_t __riscv_vlse16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat16m8_t __riscv_vlse16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
----

[[vector-strided-store]]
==== Vector Strided Store Intrinsics

[,c]
----
void __riscv_vsse16_v_f16mf4(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4_t vs3,
                             size_t vl);
void __riscv_vsse16_v_f16mf2(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2_t vs3,
                             size_t vl);
void __riscv_vsse16_v_f16m1(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1_t vs3,
                            size_t vl);
void __riscv_vsse16_v_f16m2(_Float16 *rs1, ptrdiff_t rs2, vfloat16m2_t vs3,
                            size_t vl);
void __riscv_vsse16_v_f16m4(_Float16 *rs1, ptrdiff_t rs2, vfloat16m4_t vs3,
                            size_t vl);
void __riscv_vsse16_v_f16m8(_Float16 *rs1, ptrdiff_t rs2, vfloat16m8_t vs3,
                            size_t vl);
// masked functions
void __riscv_vsse16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsse16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsse16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m1_t vs3, size_t vl);
void __riscv_vsse16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m2_t vs3, size_t vl);
void __riscv_vsse16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m4_t vs3, size_t vl);
void __riscv_vsse16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m8_t vs3, size_t vl);
----

[[vector-indexed-load]]
==== Vector Indexed Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vloxei16_v_f16mf4(const _Float16 *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vloxei16_v_f16mf2(const _Float16 *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vfloat16m1_t __riscv_vloxei16_v_f16m1(const _Float16 *rs1, vuint16m1_t rs2,
                                      size_t vl);
vfloat16m2_t __riscv_vloxei16_v_f16m2(const _Float16 *rs1, vuint16m2_t rs2,
                                      size_t vl);
vfloat16m4_t __riscv_vloxei16_v_f16m4(const _Float16 *rs1, vuint16m4_t rs2,
                                      size_t vl);
vfloat16m8_t __riscv_vloxei16_v_f16m8(const _Float16 *rs1, vuint16m8_t rs2,
                                      size_t vl);
vfloat16mf4_t __riscv_vluxei16_v_f16mf4(const _Float16 *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vluxei16_v_f16mf2(const _Float16 *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vfloat16m1_t __riscv_vluxei16_v_f16m1(const _Float16 *rs1, vuint16m1_t rs2,
                                      size_t vl);
vfloat16m2_t __riscv_vluxei16_v_f16m2(const _Float16 *rs1, vuint16m2_t rs2,
                                      size_t vl);
vfloat16m4_t __riscv_vluxei16_v_f16m4(const _Float16 *rs1, vuint16m4_t rs2,
                                      size_t vl);
vfloat16m8_t __riscv_vluxei16_v_f16m8(const _Float16 *rs1, vuint16m8_t rs2,
                                      size_t vl);
// masked functions
vfloat16mf4_t __riscv_vloxei16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                          vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                          vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                        vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vloxei16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                        vuint16m2_t rs2, size_t vl);
vfloat16m4_t __riscv_vloxei16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                        vuint16m4_t rs2, size_t vl);
vfloat16m8_t __riscv_vloxei16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                        vuint16m8_t rs2, size_t vl);
vfloat16mf4_t __riscv_vluxei16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                          vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                          vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                        vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vluxei16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                        vuint16m2_t rs2, size_t vl);
vfloat16m4_t __riscv_vluxei16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                        vuint16m4_t rs2, size_t vl);
vfloat16m8_t __riscv_vluxei16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                        vuint16m8_t rs2, size_t vl);
----

[[vector-indexed-store]]
==== Vector Indexed Store Intrinsics

[,c]
----
void __riscv_vsoxei16_v_f16mf4(_Float16 *rs1, vuint16mf4_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16mf2(_Float16 *rs1, vuint16mf2_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m1(_Float16 *rs1, vuint16m1_t rs2, vfloat16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f16m2(_Float16 *rs1, vuint16m2_t rs2, vfloat16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f16m4(_Float16 *rs1, vuint16m4_t rs2, vfloat16m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f16m8(_Float16 *rs1, vuint16m8_t rs2, vfloat16m8_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16mf4(_Float16 *rs1, vuint16mf4_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16mf2(_Float16 *rs1, vuint16mf2_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m1(_Float16 *rs1, vuint16m1_t rs2, vfloat16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16m2(_Float16 *rs1, vuint16m2_t rs2, vfloat16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16m4(_Float16 *rs1, vuint16m4_t rs2, vfloat16m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16m8(_Float16 *rs1, vuint16m8_t rs2, vfloat16m8_t vs3,
                              size_t vl);
// masked functions
void __riscv_vsoxei16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint16mf4_t rs2,
                                 vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint16mf2_t rs2,
                                 vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint16m1_t rs2,
                                vfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint16m2_t rs2,
                                vfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vuint16m4_t rs2,
                                vfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vuint16m8_t rs2,
                                vfloat16m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint16mf4_t rs2,
                                 vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint16mf2_t rs2,
                                 vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint16m1_t rs2,
                                vfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint16m2_t rs2,
                                vfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vuint16m4_t rs2,
                                vfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vuint16m8_t rs2,
                                vfloat16m8_t vs3, size_t vl);
----

[[unit-stride-fault-only-first-loads]]
==== Unit-stride Fault-Only-First Loads Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vle16ff_v_f16mf4(const _Float16 *rs1, size_t *new_vl,
                                       size_t vl);
vfloat16mf2_t __riscv_vle16ff_v_f16mf2(const _Float16 *rs1, size_t *new_vl,
                                       size_t vl);
vfloat16m1_t __riscv_vle16ff_v_f16m1(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
vfloat16m2_t __riscv_vle16ff_v_f16m2(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
vfloat16m4_t __riscv_vle16ff_v_f16m4(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
vfloat16m8_t __riscv_vle16ff_v_f16m8(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16ff_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                         size_t *new_vl, size_t vl);
vfloat16mf2_t __riscv_vle16ff_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                         size_t *new_vl, size_t vl);
vfloat16m1_t __riscv_vle16ff_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
vfloat16m2_t __riscv_vle16ff_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
vfloat16m4_t __riscv_vle16ff_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
vfloat16m8_t __riscv_vle16ff_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
----

=== Float16 Vector Loads and Stores Segment Intrinsics

[[vector-unit-stride-segment-load]]
==== Vector Unit-Stride Segment Load Intrinsics

[,c]
----
vfloat16mf4x2_t __riscv_vlseg2e16_v_f16mf4x2(const _Float16 *rs1, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_v_f16mf4x3(const _Float16 *rs1, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_v_f16mf4x4(const _Float16 *rs1, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_v_f16mf4x5(const _Float16 *rs1, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_v_f16mf4x6(const _Float16 *rs1, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_v_f16mf4x7(const _Float16 *rs1, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_v_f16mf4x8(const _Float16 *rs1, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_v_f16mf2x2(const _Float16 *rs1, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_v_f16mf2x3(const _Float16 *rs1, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_v_f16mf2x4(const _Float16 *rs1, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_v_f16mf2x5(const _Float16 *rs1, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_v_f16mf2x6(const _Float16 *rs1, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_v_f16mf2x7(const _Float16 *rs1, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_v_f16mf2x8(const _Float16 *rs1, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_v_f16m1x2(const _Float16 *rs1, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_v_f16m1x3(const _Float16 *rs1, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_v_f16m1x4(const _Float16 *rs1, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_v_f16m1x5(const _Float16 *rs1, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_v_f16m1x6(const _Float16 *rs1, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_v_f16m1x7(const _Float16 *rs1, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_v_f16m1x8(const _Float16 *rs1, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_v_f16m2x2(const _Float16 *rs1, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_v_f16m2x3(const _Float16 *rs1, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_v_f16m2x4(const _Float16 *rs1, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_v_f16m4x2(const _Float16 *rs1, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_v_f16mf4x2(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_v_f16mf4x3(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_v_f16mf4x4(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_v_f16mf4x5(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_v_f16mf4x6(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_v_f16mf4x7(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_v_f16mf4x8(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_v_f16mf2x2(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_v_f16mf2x3(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_v_f16mf2x4(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_v_f16mf2x5(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_v_f16mf2x6(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_v_f16mf2x7(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_v_f16mf2x8(const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_v_f16m1x2(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_v_f16m1x3(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_v_f16m1x4(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_v_f16m1x5(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_v_f16m1x6(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_v_f16m1x7(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_v_f16m1x8(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_v_f16m2x2(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_v_f16m2x3(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_v_f16m2x4(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_v_f16m4x2(const _Float16 *rs1,
                                             size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_v_f16mf4x2_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_v_f16mf4x3_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_v_f16mf4x4_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_v_f16mf4x5_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_v_f16mf4x6_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_v_f16mf4x7_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_v_f16mf4x8_m(vbool64_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_v_f16mf2x2_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_v_f16mf2x3_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_v_f16mf2x4_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_v_f16mf2x5_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_v_f16mf2x6_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_v_f16mf2x7_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_v_f16mf2x8_m(vbool32_t vm,
                                               const _Float16 *rs1, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_v_f16m1x2_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_v_f16m1x3_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_v_f16m1x4_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_v_f16m1x5_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_v_f16m1x6_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_v_f16m1x7_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_v_f16m1x8_m(vbool16_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_v_f16m2x2_m(vbool8_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_v_f16m2x3_m(vbool8_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_v_f16m2x4_m(vbool8_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_v_f16m4x2_m(vbool4_t vm, const _Float16 *rs1,
                                             size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_v_f16mf4x2_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_v_f16mf4x3_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_v_f16mf4x4_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_v_f16mf4x5_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_v_f16mf4x6_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_v_f16mf4x7_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_v_f16mf4x8_m(vbool64_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_v_f16mf2x2_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_v_f16mf2x3_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_v_f16mf2x4_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_v_f16mf2x5_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_v_f16mf2x6_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_v_f16mf2x7_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_v_f16mf2x8_m(vbool32_t vm,
                                                 const _Float16 *rs1,
                                                 size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_v_f16m1x2_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_v_f16m1x3_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_v_f16m1x4_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_v_f16m1x5_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_v_f16m1x6_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_v_f16m1x7_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_v_f16m1x8_m(vbool16_t vm,
                                               const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_v_f16m2x2_m(vbool8_t vm, const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_v_f16m2x3_m(vbool8_t vm, const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_v_f16m2x4_m(vbool8_t vm, const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_v_f16m4x2_m(vbool4_t vm, const _Float16 *rs1,
                                               size_t *new_vl, size_t vl);
----

[[vecrtor-unit-stride-segment-store]]
==== Vector Unit-Stride Segment Store Intrinsics

[,c]
----
void __riscv_vsseg2e16_v_f16mf4x2(_Float16 *rs1, vfloat16mf4x2_t vs3,
                                  size_t vl);
void __riscv_vsseg3e16_v_f16mf4x3(_Float16 *rs1, vfloat16mf4x3_t vs3,
                                  size_t vl);
void __riscv_vsseg4e16_v_f16mf4x4(_Float16 *rs1, vfloat16mf4x4_t vs3,
                                  size_t vl);
void __riscv_vsseg5e16_v_f16mf4x5(_Float16 *rs1, vfloat16mf4x5_t vs3,
                                  size_t vl);
void __riscv_vsseg6e16_v_f16mf4x6(_Float16 *rs1, vfloat16mf4x6_t vs3,
                                  size_t vl);
void __riscv_vsseg7e16_v_f16mf4x7(_Float16 *rs1, vfloat16mf4x7_t vs3,
                                  size_t vl);
void __riscv_vsseg8e16_v_f16mf4x8(_Float16 *rs1, vfloat16mf4x8_t vs3,
                                  size_t vl);
void __riscv_vsseg2e16_v_f16mf2x2(_Float16 *rs1, vfloat16mf2x2_t vs3,
                                  size_t vl);
void __riscv_vsseg3e16_v_f16mf2x3(_Float16 *rs1, vfloat16mf2x3_t vs3,
                                  size_t vl);
void __riscv_vsseg4e16_v_f16mf2x4(_Float16 *rs1, vfloat16mf2x4_t vs3,
                                  size_t vl);
void __riscv_vsseg5e16_v_f16mf2x5(_Float16 *rs1, vfloat16mf2x5_t vs3,
                                  size_t vl);
void __riscv_vsseg6e16_v_f16mf2x6(_Float16 *rs1, vfloat16mf2x6_t vs3,
                                  size_t vl);
void __riscv_vsseg7e16_v_f16mf2x7(_Float16 *rs1, vfloat16mf2x7_t vs3,
                                  size_t vl);
void __riscv_vsseg8e16_v_f16mf2x8(_Float16 *rs1, vfloat16mf2x8_t vs3,
                                  size_t vl);
void __riscv_vsseg2e16_v_f16m1x2(_Float16 *rs1, vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16m1x3(_Float16 *rs1, vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16m1x4(_Float16 *rs1, vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_f16m1x5(_Float16 *rs1, vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_f16m1x6(_Float16 *rs1, vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_f16m1x7(_Float16 *rs1, vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_f16m1x8(_Float16 *rs1, vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16m2x2(_Float16 *rs1, vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16m2x3(_Float16 *rs1, vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16m2x4(_Float16 *rs1, vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16m4x2(_Float16 *rs1, vfloat16m4x2_t vs3, size_t vl);
// masked functions
void __riscv_vsseg2e16_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                    vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                    vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsseg5e16_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsseg6e16_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsseg7e16_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsseg8e16_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                   vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1,
                                   vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsseg3e16_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1,
                                   vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsseg4e16_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1,
                                   vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsseg2e16_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1,
                                   vfloat16m4x2_t vs3, size_t vl);
----

[[vector-strided-segment-load]]
==== Vector Strided Segment Load Intrinsics

[,c]
----
vfloat16mf4x2_t __riscv_vlsseg2e16_v_f16mf4x2(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_v_f16mf4x3(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_v_f16mf4x4(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_v_f16mf4x5(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_v_f16mf4x6(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_v_f16mf4x7(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_v_f16mf4x8(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_v_f16mf2x2(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_v_f16mf2x3(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_v_f16mf2x4(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_v_f16mf2x5(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_v_f16mf2x6(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_v_f16mf2x7(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_v_f16mf2x8(const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_v_f16m1x2(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_v_f16m1x3(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_v_f16m1x4(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_v_f16m1x5(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_v_f16m1x6(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_v_f16m1x7(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_v_f16m1x8(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_v_f16m2x2(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_v_f16m2x3(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_v_f16m2x4(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_v_f16m4x2(const _Float16 *rs1, ptrdiff_t rs2,
                                            size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_v_f16mf4x2_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_v_f16mf4x3_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_v_f16mf4x4_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_v_f16mf4x5_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_v_f16mf4x6_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_v_f16mf4x7_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_v_f16mf4x8_m(vbool64_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_v_f16mf2x2_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_v_f16mf2x3_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_v_f16mf2x4_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_v_f16mf2x5_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_v_f16mf2x6_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_v_f16mf2x7_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_v_f16mf2x8_m(vbool32_t vm,
                                                const _Float16 *rs1,
                                                ptrdiff_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_v_f16m1x2_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_v_f16m1x3_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_v_f16m1x4_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_v_f16m1x5_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_v_f16m1x6_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_v_f16m1x7_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_v_f16m1x8_m(vbool16_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_v_f16m2x2_m(vbool8_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_v_f16m2x3_m(vbool8_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_v_f16m2x4_m(vbool8_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_v_f16m4x2_m(vbool4_t vm, const _Float16 *rs1,
                                              ptrdiff_t rs2, size_t vl);
----

[[vector-strided-segment-store]]
==== Vector Strided Segment Store Intrinsics

[,c]
----
void __riscv_vssseg2e16_v_f16mf4x2(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16mf4x3(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16mf4x4(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16mf4x5(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16mf4x6(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16mf4x7(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16mf4x8(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16mf2x2(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16mf2x3(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16mf2x4(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16mf2x5(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16mf2x6(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16mf2x7(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16mf2x8(_Float16 *rs1, ptrdiff_t rs2,
                                   vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m1x2(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16m1x3(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16m1x4(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16m1x5(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16m1x6(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16m1x7(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16m1x8(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m1x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m2x2(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16m2x3(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16m2x4(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m2x4_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m4x2(_Float16 *rs1, ptrdiff_t rs2,
                                  vfloat16m4x2_t vs3, size_t vl);
// masked functions
void __riscv_vssseg2e16_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                     vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x4_t vs3, size_t vl);
void __riscv_vssseg5e16_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x5_t vs3, size_t vl);
void __riscv_vssseg6e16_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x6_t vs3, size_t vl);
void __riscv_vssseg7e16_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x7_t vs3, size_t vl);
void __riscv_vssseg8e16_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m1x8_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m2x2_t vs3, size_t vl);
void __riscv_vssseg3e16_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m2x3_t vs3, size_t vl);
void __riscv_vssseg4e16_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m2x4_t vs3, size_t vl);
void __riscv_vssseg2e16_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1, ptrdiff_t rs2,
                                    vfloat16m4x2_t vs3, size_t vl);
----

[[vector-indexed-segment-load]]
==== Vector Indexed Segment Load Intrinsics

[,c]
----
vfloat16mf4x2_t __riscv_vloxseg2ei16_v_f16mf4x2(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_v_f16mf4x3(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_v_f16mf4x4(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_v_f16mf4x5(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_v_f16mf4x6(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_v_f16mf4x7(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_v_f16mf4x8(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_v_f16mf2x2(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_v_f16mf2x3(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_v_f16mf2x4(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_v_f16mf2x5(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_v_f16mf2x6(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_v_f16mf2x7(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_v_f16mf2x8(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_v_f16m1x2(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_v_f16m1x3(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_v_f16m1x4(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_v_f16m1x5(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_v_f16m1x6(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_v_f16m1x7(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_v_f16m1x8(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_v_f16m2x2(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_v_f16m2x3(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_v_f16m2x4(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_v_f16m4x2(const _Float16 *rs1,
                                              vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_v_f16mf4x2(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_v_f16mf4x3(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_v_f16mf4x4(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_v_f16mf4x5(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_v_f16mf4x6(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_v_f16mf4x7(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_v_f16mf4x8(const _Float16 *rs1,
                                                vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_v_f16mf2x2(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_v_f16mf2x3(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_v_f16mf2x4(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_v_f16mf2x5(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_v_f16mf2x6(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_v_f16mf2x7(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_v_f16mf2x8(const _Float16 *rs1,
                                                vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_v_f16m1x2(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_v_f16m1x3(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_v_f16m1x4(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_v_f16m1x5(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_v_f16m1x6(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_v_f16m1x7(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_v_f16m1x8(const _Float16 *rs1,
                                              vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_v_f16m2x2(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_v_f16m2x3(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_v_f16m2x4(const _Float16 *rs1,
                                              vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_v_f16m4x2(const _Float16 *rs1,
                                              vuint16m4_t rs2, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei16_v_f16mf4x2_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_v_f16mf4x3_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_v_f16mf4x4_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_v_f16mf4x5_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_v_f16mf4x6_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_v_f16mf4x7_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_v_f16mf4x8_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_v_f16mf2x2_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_v_f16mf2x3_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_v_f16mf2x4_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_v_f16mf2x5_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_v_f16mf2x6_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_v_f16mf2x7_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_v_f16mf2x8_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_v_f16m1x2_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_v_f16m1x3_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_v_f16m1x4_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_v_f16m1x5_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_v_f16m1x6_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_v_f16m1x7_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_v_f16m1x8_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_v_f16m2x2_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_v_f16m2x3_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_v_f16m2x4_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_v_f16m4x2_m(vbool4_t vm,
                                                const _Float16 *rs1,
                                                vuint16m4_t rs2, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_v_f16mf4x2_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_v_f16mf4x3_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_v_f16mf4x4_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_v_f16mf4x5_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_v_f16mf4x6_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_v_f16mf4x7_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_v_f16mf4x8_m(vbool64_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf4_t rs2, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_v_f16mf2x2_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_v_f16mf2x3_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_v_f16mf2x4_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_v_f16mf2x5_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_v_f16mf2x6_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_v_f16mf2x7_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_v_f16mf2x8_m(vbool32_t vm,
                                                  const _Float16 *rs1,
                                                  vuint16mf2_t rs2, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_v_f16m1x2_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_v_f16m1x3_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_v_f16m1x4_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_v_f16m1x5_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_v_f16m1x6_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_v_f16m1x7_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_v_f16m1x8_m(vbool16_t vm,
                                                const _Float16 *rs1,
                                                vuint16m1_t rs2, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_v_f16m2x2_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_v_f16m2x3_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_v_f16m2x4_m(vbool8_t vm,
                                                const _Float16 *rs1,
                                                vuint16m2_t rs2, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_v_f16m4x2_m(vbool4_t vm,
                                                const _Float16 *rs1,
                                                vuint16m4_t rs2, size_t vl);
----

[[vector-indexed-segment-store]]
==== Vector Indexed Segment Store Intrinsics

[,c]
----
void __riscv_vsoxseg2ei16_v_f16mf4x2(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f16mf4x3(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f16mf4x4(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_f16mf4x5(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_f16mf4x6(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_f16mf4x7(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_f16mf4x8(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f16mf2x2(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f16mf2x3(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f16mf2x4(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_f16mf2x5(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_f16mf2x6(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_f16mf2x7(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_f16mf2x8(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f16m1x2(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f16m1x3(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f16m1x4(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsoxseg5ei16_v_f16m1x5(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsoxseg6ei16_v_f16m1x6(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsoxseg7ei16_v_f16m1x7(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsoxseg8ei16_v_f16m1x8(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f16m2x2(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsoxseg3ei16_v_f16m2x3(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsoxseg4ei16_v_f16m2x4(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsoxseg2ei16_v_f16m4x2(_Float16 *rs1, vuint16m4_t vs2,
                                    vfloat16m4x2_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16mf4x2(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f16mf4x3(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f16mf4x4(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_f16mf4x5(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_f16mf4x6(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_f16mf4x7(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_f16mf4x8(_Float16 *rs1, vuint16mf4_t vs2,
                                     vfloat16mf4x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16mf2x2(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f16mf2x3(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f16mf2x4(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_f16mf2x5(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_f16mf2x6(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_f16mf2x7(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_f16mf2x8(_Float16 *rs1, vuint16mf2_t vs2,
                                     vfloat16mf2x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16m1x2(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f16m1x3(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f16m1x4(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x4_t vs3, size_t vl);
void __riscv_vsuxseg5ei16_v_f16m1x5(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x5_t vs3, size_t vl);
void __riscv_vsuxseg6ei16_v_f16m1x6(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x6_t vs3, size_t vl);
void __riscv_vsuxseg7ei16_v_f16m1x7(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x7_t vs3, size_t vl);
void __riscv_vsuxseg8ei16_v_f16m1x8(_Float16 *rs1, vuint16m1_t vs2,
                                    vfloat16m1x8_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16m2x2(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x2_t vs3, size_t vl);
void __riscv_vsuxseg3ei16_v_f16m2x3(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x3_t vs3, size_t vl);
void __riscv_vsuxseg4ei16_v_f16m2x4(_Float16 *rs1, vuint16m2_t vs2,
                                    vfloat16m2x4_t vs3, size_t vl);
void __riscv_vsuxseg2ei16_v_f16m4x2(_Float16 *rs1, vuint16m4_t vs2,
                                    vfloat16m4x2_t vs3, size_t vl);
// masked functions
void __riscv_vsoxseg2ei16_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsoxseg3ei16_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsoxseg4ei16_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsoxseg5ei16_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsoxseg6ei16_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsoxseg7ei16_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsoxseg8ei16_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsoxseg2ei16_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg5ei16_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsoxseg6ei16_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsoxseg7ei16_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsoxseg8ei16_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsoxseg3ei16_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsoxseg4ei16_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsoxseg2ei16_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1,
                                      vuint16m4_t vs2, vfloat16m4x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_f16mf4x2_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_f16mf4x3_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_f16mf4x4_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_f16mf4x5_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_f16mf4x6_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_f16mf4x7_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_f16mf4x8_m(vbool64_t vm, _Float16 *rs1,
                                       vuint16mf4_t vs2, vfloat16mf4x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_f16mf2x2_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x2_t vs3,
                                       size_t vl);
void __riscv_vsuxseg3ei16_v_f16mf2x3_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x3_t vs3,
                                       size_t vl);
void __riscv_vsuxseg4ei16_v_f16mf2x4_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x4_t vs3,
                                       size_t vl);
void __riscv_vsuxseg5ei16_v_f16mf2x5_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x5_t vs3,
                                       size_t vl);
void __riscv_vsuxseg6ei16_v_f16mf2x6_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x6_t vs3,
                                       size_t vl);
void __riscv_vsuxseg7ei16_v_f16mf2x7_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x7_t vs3,
                                       size_t vl);
void __riscv_vsuxseg8ei16_v_f16mf2x8_m(vbool32_t vm, _Float16 *rs1,
                                       vuint16mf2_t vs2, vfloat16mf2x8_t vs3,
                                       size_t vl);
void __riscv_vsuxseg2ei16_v_f16m1x2_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_f16m1x3_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_f16m1x4_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg5ei16_v_f16m1x5_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x5_t vs3,
                                      size_t vl);
void __riscv_vsuxseg6ei16_v_f16m1x6_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x6_t vs3,
                                      size_t vl);
void __riscv_vsuxseg7ei16_v_f16m1x7_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x7_t vs3,
                                      size_t vl);
void __riscv_vsuxseg8ei16_v_f16m1x8_m(vbool16_t vm, _Float16 *rs1,
                                      vuint16m1_t vs2, vfloat16m1x8_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_f16m2x2_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x2_t vs3,
                                      size_t vl);
void __riscv_vsuxseg3ei16_v_f16m2x3_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x3_t vs3,
                                      size_t vl);
void __riscv_vsuxseg4ei16_v_f16m2x4_m(vbool8_t vm, _Float16 *rs1,
                                      vuint16m2_t vs2, vfloat16m2x4_t vs3,
                                      size_t vl);
void __riscv_vsuxseg2ei16_v_f16m4x2_m(vbool4_t vm, _Float16 *rs1,
                                      vuint16m4_t vs2, vfloat16m4x2_t vs3,
                                      size_t vl);
----

=== Float16 Miscellaneous Vector Utility Intrinsics

[[reinterpret-cast-conversion]]
==== Reinterpret Cast Conversion Intrinsics

[,c]
----
// Reinterpret between different type under the same SEW/LMUL
vfloat16mf4_t __riscv_vreinterpret_v_i16mf4_f16mf4(vint16mf4_t src);
vfloat16mf2_t __riscv_vreinterpret_v_i16mf2_f16mf2(vint16mf2_t src);
vfloat16m1_t __riscv_vreinterpret_v_i16m1_f16m1(vint16m1_t src);
vfloat16m2_t __riscv_vreinterpret_v_i16m2_f16m2(vint16m2_t src);
vfloat16m4_t __riscv_vreinterpret_v_i16m4_f16m4(vint16m4_t src);
vfloat16m8_t __riscv_vreinterpret_v_i16m8_f16m8(vint16m8_t src);
vfloat16mf4_t __riscv_vreinterpret_v_u16mf4_f16mf4(vuint16mf4_t src);
vfloat16mf2_t __riscv_vreinterpret_v_u16mf2_f16mf2(vuint16mf2_t src);
vfloat16m1_t __riscv_vreinterpret_v_u16m1_f16m1(vuint16m1_t src);
vfloat16m2_t __riscv_vreinterpret_v_u16m2_f16m2(vuint16m2_t src);
vfloat16m4_t __riscv_vreinterpret_v_u16m4_f16m4(vuint16m4_t src);
vfloat16m8_t __riscv_vreinterpret_v_u16m8_f16m8(vuint16m8_t src);
vuint16mf4_t __riscv_vreinterpret_v_i16mf4_u16mf4(vint16mf4_t src);
vuint16mf2_t __riscv_vreinterpret_v_i16mf2_u16mf2(vint16mf2_t src);
vuint16m1_t __riscv_vreinterpret_v_i16m1_u16m1(vint16m1_t src);
vuint16m2_t __riscv_vreinterpret_v_i16m2_u16m2(vint16m2_t src);
vuint16m4_t __riscv_vreinterpret_v_i16m4_u16m4(vint16m4_t src);
vuint16m8_t __riscv_vreinterpret_v_i16m8_u16m8(vint16m8_t src);
vint16mf4_t __riscv_vreinterpret_v_u16mf4_i16mf4(vuint16mf4_t src);
vint16mf2_t __riscv_vreinterpret_v_u16mf2_i16mf2(vuint16mf2_t src);
vint16m1_t __riscv_vreinterpret_v_u16m1_i16m1(vuint16m1_t src);
vint16m2_t __riscv_vreinterpret_v_u16m2_i16m2(vuint16m2_t src);
vint16m4_t __riscv_vreinterpret_v_u16m4_i16m4(vuint16m4_t src);
vint16m8_t __riscv_vreinterpret_v_u16m8_i16m8(vuint16m8_t src);
vint16mf4_t __riscv_vreinterpret_v_f16mf4_i16mf4(vfloat16mf4_t src);
vint16mf2_t __riscv_vreinterpret_v_f16mf2_i16mf2(vfloat16mf2_t src);
vint16m1_t __riscv_vreinterpret_v_f16m1_i16m1(vfloat16m1_t src);
vint16m2_t __riscv_vreinterpret_v_f16m2_i16m2(vfloat16m2_t src);
vint16m4_t __riscv_vreinterpret_v_f16m4_i16m4(vfloat16m4_t src);
vint16m8_t __riscv_vreinterpret_v_f16m8_i16m8(vfloat16m8_t src);
vuint16mf4_t __riscv_vreinterpret_v_f16mf4_u16mf4(vfloat16mf4_t src);
vuint16mf2_t __riscv_vreinterpret_v_f16mf2_u16mf2(vfloat16mf2_t src);
vuint16m1_t __riscv_vreinterpret_v_f16m1_u16m1(vfloat16m1_t src);
vuint16m2_t __riscv_vreinterpret_v_f16m2_u16m2(vfloat16m2_t src);
vuint16m4_t __riscv_vreinterpret_v_f16m4_u16m4(vfloat16m4_t src);
vuint16m8_t __riscv_vreinterpret_v_f16m8_u16m8(vfloat16m8_t src);
// Reinterpret between different SEW under the same LMUL
// Reinterpret between vector boolean types and LMUL=1 (m1) vector integer types
vbool64_t __riscv_vreinterpret_v_i16m1_b64(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b64_i16m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_v_i16m1_b32(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b32_i16m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_v_i16m1_b16(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b16_i16m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_v_i16m1_b8(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b8_i16m1(vbool8_t src);
vbool4_t __riscv_vreinterpret_v_i16m1_b4(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b4_i16m1(vbool4_t src);
vbool2_t __riscv_vreinterpret_v_i16m1_b2(vint16m1_t src);
vint16m1_t __riscv_vreinterpret_v_b2_i16m1(vbool2_t src);
vbool64_t __riscv_vreinterpret_v_u16m1_b64(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b64_u16m1(vbool64_t src);
vbool32_t __riscv_vreinterpret_v_u16m1_b32(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b32_u16m1(vbool32_t src);
vbool16_t __riscv_vreinterpret_v_u16m1_b16(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b16_u16m1(vbool16_t src);
vbool8_t __riscv_vreinterpret_v_u16m1_b8(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b8_u16m1(vbool8_t src);
vbool4_t __riscv_vreinterpret_v_u16m1_b4(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b4_u16m1(vbool4_t src);
vbool2_t __riscv_vreinterpret_v_u16m1_b2(vuint16m1_t src);
vuint16m1_t __riscv_vreinterpret_v_b2_u16m1(vbool2_t src);
----

[[vector-lmul-extensionn]]
==== Vector LMUL Extension Intrinsics

[,c]
----
vfloat16mf2_t __riscv_vlmul_ext_v_f16mf4_f16mf2(vfloat16mf4_t value);
vfloat16m1_t __riscv_vlmul_ext_v_f16mf4_f16m1(vfloat16mf4_t value);
vfloat16m2_t __riscv_vlmul_ext_v_f16mf4_f16m2(vfloat16mf4_t value);
vfloat16m4_t __riscv_vlmul_ext_v_f16mf4_f16m4(vfloat16mf4_t value);
vfloat16m8_t __riscv_vlmul_ext_v_f16mf4_f16m8(vfloat16mf4_t value);
vfloat16m1_t __riscv_vlmul_ext_v_f16mf2_f16m1(vfloat16mf2_t value);
vfloat16m2_t __riscv_vlmul_ext_v_f16mf2_f16m2(vfloat16mf2_t value);
vfloat16m4_t __riscv_vlmul_ext_v_f16mf2_f16m4(vfloat16mf2_t value);
vfloat16m8_t __riscv_vlmul_ext_v_f16mf2_f16m8(vfloat16mf2_t value);
vfloat16m2_t __riscv_vlmul_ext_v_f16m1_f16m2(vfloat16m1_t value);
vfloat16m4_t __riscv_vlmul_ext_v_f16m1_f16m4(vfloat16m1_t value);
vfloat16m8_t __riscv_vlmul_ext_v_f16m1_f16m8(vfloat16m1_t value);
vfloat16m4_t __riscv_vlmul_ext_v_f16m2_f16m4(vfloat16m2_t value);
vfloat16m8_t __riscv_vlmul_ext_v_f16m2_f16m8(vfloat16m2_t value);
vfloat16m8_t __riscv_vlmul_ext_v_f16m4_f16m8(vfloat16m4_t value);
----

[[vector-lmul-truncation]]
==== Vector LMUL Truncation Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vlmul_trunc_v_f16mf2_f16mf4(vfloat16mf2_t value);
vfloat16mf4_t __riscv_vlmul_trunc_v_f16m1_f16mf4(vfloat16m1_t value);
vfloat16mf2_t __riscv_vlmul_trunc_v_f16m1_f16mf2(vfloat16m1_t value);
vfloat16mf4_t __riscv_vlmul_trunc_v_f16m2_f16mf4(vfloat16m2_t value);
vfloat16mf2_t __riscv_vlmul_trunc_v_f16m2_f16mf2(vfloat16m2_t value);
vfloat16m1_t __riscv_vlmul_trunc_v_f16m2_f16m1(vfloat16m2_t value);
vfloat16mf4_t __riscv_vlmul_trunc_v_f16m4_f16mf4(vfloat16m4_t value);
vfloat16mf2_t __riscv_vlmul_trunc_v_f16m4_f16mf2(vfloat16m4_t value);
vfloat16m1_t __riscv_vlmul_trunc_v_f16m4_f16m1(vfloat16m4_t value);
vfloat16m2_t __riscv_vlmul_trunc_v_f16m4_f16m2(vfloat16m4_t value);
vfloat16mf4_t __riscv_vlmul_trunc_v_f16m8_f16mf4(vfloat16m8_t value);
vfloat16mf2_t __riscv_vlmul_trunc_v_f16m8_f16mf2(vfloat16m8_t value);
vfloat16m1_t __riscv_vlmul_trunc_v_f16m8_f16m1(vfloat16m8_t value);
vfloat16m2_t __riscv_vlmul_trunc_v_f16m8_f16m2(vfloat16m8_t value);
vfloat16m4_t __riscv_vlmul_trunc_v_f16m8_f16m4(vfloat16m8_t value);
----

[[vector-initialization]]
==== Vector Initialization Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vundefined_f16mf4();
vfloat16mf2_t __riscv_vundefined_f16mf2();
vfloat16m1_t __riscv_vundefined_f16m1();
vfloat16m2_t __riscv_vundefined_f16m2();
vfloat16m4_t __riscv_vundefined_f16m4();
vfloat16m8_t __riscv_vundefined_f16m8();
vfloat16mf4x2_t __riscv_vundefined_f16mf4x2();
vfloat16mf4x3_t __riscv_vundefined_f16mf4x3();
vfloat16mf4x4_t __riscv_vundefined_f16mf4x4();
vfloat16mf4x5_t __riscv_vundefined_f16mf4x5();
vfloat16mf4x6_t __riscv_vundefined_f16mf4x6();
vfloat16mf4x7_t __riscv_vundefined_f16mf4x7();
vfloat16mf4x8_t __riscv_vundefined_f16mf4x8();
vfloat16mf2x2_t __riscv_vundefined_f16mf2x2();
vfloat16mf2x3_t __riscv_vundefined_f16mf2x3();
vfloat16mf2x4_t __riscv_vundefined_f16mf2x4();
vfloat16mf2x5_t __riscv_vundefined_f16mf2x5();
vfloat16mf2x6_t __riscv_vundefined_f16mf2x6();
vfloat16mf2x7_t __riscv_vundefined_f16mf2x7();
vfloat16mf2x8_t __riscv_vundefined_f16mf2x8();
vfloat16m1x2_t __riscv_vundefined_f16m1x2();
vfloat16m1x3_t __riscv_vundefined_f16m1x3();
vfloat16m1x4_t __riscv_vundefined_f16m1x4();
vfloat16m1x5_t __riscv_vundefined_f16m1x5();
vfloat16m1x6_t __riscv_vundefined_f16m1x6();
vfloat16m1x7_t __riscv_vundefined_f16m1x7();
vfloat16m1x8_t __riscv_vundefined_f16m1x8();
vfloat16m2x2_t __riscv_vundefined_f16m2x2();
vfloat16m2x3_t __riscv_vundefined_f16m2x3();
vfloat16m2x4_t __riscv_vundefined_f16m2x4();
vfloat16m4x2_t __riscv_vundefined_f16m4x2();
----

[[vector-insertion]]
==== Vector Insertion Intrinsics

[,c]
----
vfloat16m2_t __riscv_vset_v_f16m1_f16m2(vfloat16m2_t dest, size_t index,
                                        vfloat16m1_t value);
vfloat16m4_t __riscv_vset_v_f16m1_f16m4(vfloat16m4_t dest, size_t index,
                                        vfloat16m1_t value);
vfloat16m4_t __riscv_vset_v_f16m2_f16m4(vfloat16m4_t dest, size_t index,
                                        vfloat16m2_t value);
vfloat16m8_t __riscv_vset_v_f16m1_f16m8(vfloat16m8_t dest, size_t index,
                                        vfloat16m1_t value);
vfloat16m8_t __riscv_vset_v_f16m2_f16m8(vfloat16m8_t dest, size_t index,
                                        vfloat16m2_t value);
vfloat16m8_t __riscv_vset_v_f16m4_f16m8(vfloat16m8_t dest, size_t index,
                                        vfloat16m4_t value);
vfloat16mf4x2_t __riscv_vset_v_f16mf4_f16mf4x2(vfloat16mf4x2_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x3_t __riscv_vset_v_f16mf4_f16mf4x3(vfloat16mf4x3_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x4_t __riscv_vset_v_f16mf4_f16mf4x4(vfloat16mf4x4_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x5_t __riscv_vset_v_f16mf4_f16mf4x5(vfloat16mf4x5_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x6_t __riscv_vset_v_f16mf4_f16mf4x6(vfloat16mf4x6_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x7_t __riscv_vset_v_f16mf4_f16mf4x7(vfloat16mf4x7_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf4x8_t __riscv_vset_v_f16mf4_f16mf4x8(vfloat16mf4x8_t dest,
                                               size_t index,
                                               vfloat16mf4_t value);
vfloat16mf2x2_t __riscv_vset_v_f16mf2_f16mf2x2(vfloat16mf2x2_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x3_t __riscv_vset_v_f16mf2_f16mf2x3(vfloat16mf2x3_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x4_t __riscv_vset_v_f16mf2_f16mf2x4(vfloat16mf2x4_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x5_t __riscv_vset_v_f16mf2_f16mf2x5(vfloat16mf2x5_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x6_t __riscv_vset_v_f16mf2_f16mf2x6(vfloat16mf2x6_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x7_t __riscv_vset_v_f16mf2_f16mf2x7(vfloat16mf2x7_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16mf2x8_t __riscv_vset_v_f16mf2_f16mf2x8(vfloat16mf2x8_t dest,
                                               size_t index,
                                               vfloat16mf2_t value);
vfloat16m1x2_t __riscv_vset_v_f16m1_f16m1x2(vfloat16m1x2_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x3_t __riscv_vset_v_f16m1_f16m1x3(vfloat16m1x3_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x4_t __riscv_vset_v_f16m1_f16m1x4(vfloat16m1x4_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x5_t __riscv_vset_v_f16m1_f16m1x5(vfloat16m1x5_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x6_t __riscv_vset_v_f16m1_f16m1x6(vfloat16m1x6_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x7_t __riscv_vset_v_f16m1_f16m1x7(vfloat16m1x7_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m1x8_t __riscv_vset_v_f16m1_f16m1x8(vfloat16m1x8_t dest, size_t index,
                                            vfloat16m1_t value);
vfloat16m2x2_t __riscv_vset_v_f16m2_f16m2x2(vfloat16m2x2_t dest, size_t index,
                                            vfloat16m2_t value);
vfloat16m2x3_t __riscv_vset_v_f16m2_f16m2x3(vfloat16m2x3_t dest, size_t index,
                                            vfloat16m2_t value);
vfloat16m2x4_t __riscv_vset_v_f16m2_f16m2x4(vfloat16m2x4_t dest, size_t index,
                                            vfloat16m2_t value);
vfloat16m4x2_t __riscv_vset_v_f16m4_f16m4x2(vfloat16m4x2_t dest, size_t index,
                                            vfloat16m4_t value);
----

[[vector-extraction]]
==== Vector Extraction Intrinsics

[,c]
----
vfloat16m1_t __riscv_vget_v_f16m2_f16m1(vfloat16m2_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m4_f16m1(vfloat16m4_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m8_f16m1(vfloat16m8_t src, size_t index);
vfloat16m2_t __riscv_vget_v_f16m4_f16m2(vfloat16m4_t src, size_t index);
vfloat16m2_t __riscv_vget_v_f16m8_f16m2(vfloat16m8_t src, size_t index);
vfloat16m4_t __riscv_vget_v_f16m8_f16m4(vfloat16m8_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x2_f16mf4(vfloat16mf4x2_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x3_f16mf4(vfloat16mf4x3_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x4_f16mf4(vfloat16mf4x4_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x5_f16mf4(vfloat16mf4x5_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x6_f16mf4(vfloat16mf4x6_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x7_f16mf4(vfloat16mf4x7_t src, size_t index);
vfloat16mf4_t __riscv_vget_v_f16mf4x8_f16mf4(vfloat16mf4x8_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x2_f16mf2(vfloat16mf2x2_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x3_f16mf2(vfloat16mf2x3_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x4_f16mf2(vfloat16mf2x4_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x5_f16mf2(vfloat16mf2x5_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x6_f16mf2(vfloat16mf2x6_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x7_f16mf2(vfloat16mf2x7_t src, size_t index);
vfloat16mf2_t __riscv_vget_v_f16mf2x8_f16mf2(vfloat16mf2x8_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x2_f16m1(vfloat16m1x2_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x3_f16m1(vfloat16m1x3_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x4_f16m1(vfloat16m1x4_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x5_f16m1(vfloat16m1x5_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x6_f16m1(vfloat16m1x6_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x7_f16m1(vfloat16m1x7_t src, size_t index);
vfloat16m1_t __riscv_vget_v_f16m1x8_f16m1(vfloat16m1x8_t src, size_t index);
vfloat16m2_t __riscv_vget_v_f16m2x2_f16m2(vfloat16m2x2_t src, size_t index);
vfloat16m2_t __riscv_vget_v_f16m2x3_f16m2(vfloat16m2x3_t src, size_t index);
vfloat16m2_t __riscv_vget_v_f16m2x4_f16m2(vfloat16m2x4_t src, size_t index);
vfloat16m4_t __riscv_vget_v_f16m4x2_f16m4(vfloat16m4x2_t src, size_t index);
----

[[vector-creation]]
==== Vector Creation Intrinsics

[,c]
----
vfloat16m2_t __riscv_vcreate_v_f16m1_f16m2(vfloat16m1_t v0, vfloat16m1_t v1);
vfloat16m4_t __riscv_vcreate_v_f16m1_f16m4(vfloat16m1_t v0, vfloat16m1_t v1,
                                           vfloat16m1_t v2, vfloat16m1_t v3);
vfloat16m8_t __riscv_vcreate_v_f16m1_f16m8(vfloat16m1_t v0, vfloat16m1_t v1,
                                           vfloat16m1_t v2, vfloat16m1_t v3,
                                           vfloat16m1_t v4, vfloat16m1_t v5,
                                           vfloat16m1_t v6, vfloat16m1_t v7);
vfloat16m4_t __riscv_vcreate_v_f16m2_f16m4(vfloat16m2_t v0, vfloat16m2_t v1);
vfloat16m8_t __riscv_vcreate_v_f16m2_f16m8(vfloat16m2_t v0, vfloat16m2_t v1,
                                           vfloat16m2_t v2, vfloat16m2_t v3);
vfloat16m8_t __riscv_vcreate_v_f16m4_f16m8(vfloat16m4_t v0, vfloat16m4_t v1);
vfloat16mf4x2_t __riscv_vcreate_v_f16mf4x2(vfloat16mf4_t v0, vfloat16mf4_t v1);
vfloat16mf4x3_t __riscv_vcreate_v_f16mf4x3(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2);
vfloat16mf4x4_t __riscv_vcreate_v_f16mf4x4(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2, vfloat16mf4_t v3);
vfloat16mf4x5_t __riscv_vcreate_v_f16mf4x5(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2, vfloat16mf4_t v3,
                                           vfloat16mf4_t v4);
vfloat16mf4x6_t __riscv_vcreate_v_f16mf4x6(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2, vfloat16mf4_t v3,
                                           vfloat16mf4_t v4, vfloat16mf4_t v5);
vfloat16mf4x7_t __riscv_vcreate_v_f16mf4x7(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2, vfloat16mf4_t v3,
                                           vfloat16mf4_t v4, vfloat16mf4_t v5,
                                           vfloat16mf4_t v6);
vfloat16mf4x8_t __riscv_vcreate_v_f16mf4x8(vfloat16mf4_t v0, vfloat16mf4_t v1,
                                           vfloat16mf4_t v2, vfloat16mf4_t v3,
                                           vfloat16mf4_t v4, vfloat16mf4_t v5,
                                           vfloat16mf4_t v6, vfloat16mf4_t v7);
vfloat16mf2x2_t __riscv_vcreate_v_f16mf2x2(vfloat16mf2_t v0, vfloat16mf2_t v1);
vfloat16mf2x3_t __riscv_vcreate_v_f16mf2x3(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2);
vfloat16mf2x4_t __riscv_vcreate_v_f16mf2x4(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2, vfloat16mf2_t v3);
vfloat16mf2x5_t __riscv_vcreate_v_f16mf2x5(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2, vfloat16mf2_t v3,
                                           vfloat16mf2_t v4);
vfloat16mf2x6_t __riscv_vcreate_v_f16mf2x6(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2, vfloat16mf2_t v3,
                                           vfloat16mf2_t v4, vfloat16mf2_t v5);
vfloat16mf2x7_t __riscv_vcreate_v_f16mf2x7(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2, vfloat16mf2_t v3,
                                           vfloat16mf2_t v4, vfloat16mf2_t v5,
                                           vfloat16mf2_t v6);
vfloat16mf2x8_t __riscv_vcreate_v_f16mf2x8(vfloat16mf2_t v0, vfloat16mf2_t v1,
                                           vfloat16mf2_t v2, vfloat16mf2_t v3,
                                           vfloat16mf2_t v4, vfloat16mf2_t v5,
                                           vfloat16mf2_t v6, vfloat16mf2_t v7);
vfloat16m1x2_t __riscv_vcreate_v_f16m1x2(vfloat16m1_t v0, vfloat16m1_t v1);
vfloat16m1x3_t __riscv_vcreate_v_f16m1x3(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2);
vfloat16m1x4_t __riscv_vcreate_v_f16m1x4(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2, vfloat16m1_t v3);
vfloat16m1x5_t __riscv_vcreate_v_f16m1x5(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2, vfloat16m1_t v3,
                                         vfloat16m1_t v4);
vfloat16m1x6_t __riscv_vcreate_v_f16m1x6(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2, vfloat16m1_t v3,
                                         vfloat16m1_t v4, vfloat16m1_t v5);
vfloat16m1x7_t __riscv_vcreate_v_f16m1x7(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2, vfloat16m1_t v3,
                                         vfloat16m1_t v4, vfloat16m1_t v5,
                                         vfloat16m1_t v6);
vfloat16m1x8_t __riscv_vcreate_v_f16m1x8(vfloat16m1_t v0, vfloat16m1_t v1,
                                         vfloat16m1_t v2, vfloat16m1_t v3,
                                         vfloat16m1_t v4, vfloat16m1_t v5,
                                         vfloat16m1_t v6, vfloat16m1_t v7);
vfloat16m2x2_t __riscv_vcreate_v_f16m2x2(vfloat16m2_t v0, vfloat16m2_t v1);
vfloat16m2x3_t __riscv_vcreate_v_f16m2x3(vfloat16m2_t v0, vfloat16m2_t v1,
                                         vfloat16m2_t v2);
vfloat16m2x4_t __riscv_vcreate_v_f16m2x4(vfloat16m2_t v0, vfloat16m2_t v1,
                                         vfloat16m2_t v2, vfloat16m2_t v3);
vfloat16m4x2_t __riscv_vcreate_v_f16m4x2(vfloat16m4_t v0, vfloat16m4_t v1);
----

=== Vector Permutation Intrinsics

[[vector-register-gather]]
==== Vector Register Gather Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vrgather_vv_f16mf4(vfloat16mf4_t vs2, vuint16mf4_t vs1,
                                         size_t vl);
vfloat16mf4_t __riscv_vrgather_vx_f16mf4(vfloat16mf4_t vs2, size_t vs1,
                                         size_t vl);
vfloat16mf2_t __riscv_vrgather_vv_f16mf2(vfloat16mf2_t vs2, vuint16mf2_t vs1,
                                         size_t vl);
vfloat16mf2_t __riscv_vrgather_vx_f16mf2(vfloat16mf2_t vs2, size_t vs1,
                                         size_t vl);
vfloat16m1_t __riscv_vrgather_vv_f16m1(vfloat16m1_t vs2, vuint16m1_t vs1,
                                       size_t vl);
vfloat16m1_t __riscv_vrgather_vx_f16m1(vfloat16m1_t vs2, size_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgather_vv_f16m2(vfloat16m2_t vs2, vuint16m2_t vs1,
                                       size_t vl);
vfloat16m2_t __riscv_vrgather_vx_f16m2(vfloat16m2_t vs2, size_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgather_vv_f16m4(vfloat16m4_t vs2, vuint16m4_t vs1,
                                       size_t vl);
vfloat16m4_t __riscv_vrgather_vx_f16m4(vfloat16m4_t vs2, size_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgather_vv_f16m8(vfloat16m8_t vs2, vuint16m8_t vs1,
                                       size_t vl);
vfloat16m8_t __riscv_vrgather_vx_f16m8(vfloat16m8_t vs2, size_t vs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vrgather_vv_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           vuint16mf4_t vs1, size_t vl);
vfloat16mf4_t __riscv_vrgather_vx_f16mf4_m(vbool64_t vm, vfloat16mf4_t vs2,
                                           size_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather_vv_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           vuint16mf2_t vs1, size_t vl);
vfloat16mf2_t __riscv_vrgather_vx_f16mf2_m(vbool32_t vm, vfloat16mf2_t vs2,
                                           size_t vs1, size_t vl);
vfloat16m1_t __riscv_vrgather_vv_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                         vuint16m1_t vs1, size_t vl);
vfloat16m1_t __riscv_vrgather_vx_f16m1_m(vbool16_t vm, vfloat16m1_t vs2,
                                         size_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgather_vv_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                         vuint16m2_t vs1, size_t vl);
vfloat16m2_t __riscv_vrgather_vx_f16m2_m(vbool8_t vm, vfloat16m2_t vs2,
                                         size_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgather_vv_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                         vuint16m4_t vs1, size_t vl);
vfloat16m4_t __riscv_vrgather_vx_f16m4_m(vbool4_t vm, vfloat16m4_t vs2,
                                         size_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgather_vv_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                         vuint16m8_t vs1, size_t vl);
vfloat16m8_t __riscv_vrgather_vx_f16m8_m(vbool2_t vm, vfloat16m8_t vs2,
                                         size_t vs1, size_t vl);
----

[[vector-compress]]
==== Vector Compress Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vcompress_vm_f16mf4(vfloat16mf4_t vs2, vbool64_t vs1,
                                          size_t vl);
vfloat16mf2_t __riscv_vcompress_vm_f16mf2(vfloat16mf2_t vs2, vbool32_t vs1,
                                          size_t vl);
vfloat16m1_t __riscv_vcompress_vm_f16m1(vfloat16m1_t vs2, vbool16_t vs1,
                                        size_t vl);
vfloat16m2_t __riscv_vcompress_vm_f16m2(vfloat16m2_t vs2, vbool8_t vs1,
                                        size_t vl);
vfloat16m4_t __riscv_vcompress_vm_f16m4(vfloat16m4_t vs2, vbool4_t vs1,
                                        size_t vl);
vfloat16m8_t __riscv_vcompress_vm_f16m8(vfloat16m8_t vs2, vbool2_t vs1,
                                        size_t vl);
----

=== Vector Float16 Intrinsics

[[widening-floating-pointinteger-type-convert]]
==== Widening Floating-Point/Integer Type-Convert Intrinsics

[,c]
----
vfloat32mf2_t __riscv_vfwcvt_f_f_v_f32mf2(vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_f_v_f32m1(vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_f_v_f32m2(vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_f_v_f32m4(vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_f_v_f32m8(vfloat16m4_t vs2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwcvt_f_f_v_f32mf2_m(vbool64_t vm, vfloat16mf4_t vs2,
                                            size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_f_v_f32m1_m(vbool32_t vm, vfloat16mf2_t vs2,
                                          size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_f_v_f32m2_m(vbool16_t vm, vfloat16m1_t vs2,
                                          size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_f_v_f32m4_m(vbool8_t vm, vfloat16m2_t vs2,
                                          size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_f_v_f32m8_m(vbool4_t vm, vfloat16m4_t vs2,
                                          size_t vl);
// masked functions
----

[[narrowing-floating-pointinteger-type-convert]]
==== Narrowing Floating-Point/Integer Type-Convert Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4(vfloat32mf2_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_f_w_f16mf4(vfloat32mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2(vfloat32m1_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_f_w_f16mf2(vfloat32m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1(vfloat32m2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_f_w_f16m1(vfloat32m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2(vfloat32m4_t vs2, size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_f_w_f16m2(vfloat32m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4(vfloat32m8_t vs2, size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_f_w_f16m4(vfloat32m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_m(vbool64_t vm, vfloat32mf2_t vs2,
                                            size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_f_w_f16mf4_m(vbool64_t vm, vfloat32mf2_t vs2,
                                                size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_m(vbool32_t vm, vfloat32m1_t vs2,
                                            size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_f_w_f16mf2_m(vbool32_t vm, vfloat32m1_t vs2,
                                                size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                          size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_f_w_f16m1_m(vbool16_t vm, vfloat32m2_t vs2,
                                              size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_m(vbool8_t vm, vfloat32m4_t vs2,
                                          size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_f_w_f16m2_m(vbool8_t vm, vfloat32m4_t vs2,
                                              size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_m(vbool4_t vm, vfloat32m8_t vs2,
                                          size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_f_w_f16m4_m(vbool4_t vm, vfloat32m8_t vs2,
                                              size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_rm(vfloat32mf2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_rm(vfloat32m1_t vs2, unsigned int frm,
                                             size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_rm(vfloat32m2_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_rm(vfloat32m4_t vs2, unsigned int frm,
                                           size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_rm(vfloat32m8_t vs2, unsigned int frm,
                                           size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfncvt_f_f_w_f16mf4_rm_m(vbool64_t vm, vfloat32mf2_t vs2,
                                               unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_f_w_f16mf2_rm_m(vbool32_t vm, vfloat32m1_t vs2,
                                               unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_f_w_f16m1_rm_m(vbool16_t vm, vfloat32m2_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_f_w_f16m2_rm_m(vbool8_t vm, vfloat32m4_t vs2,
                                             unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_f_w_f16m4_rm_m(vbool4_t vm, vfloat32m8_t vs2,
                                             unsigned int frm, size_t vl);
----
