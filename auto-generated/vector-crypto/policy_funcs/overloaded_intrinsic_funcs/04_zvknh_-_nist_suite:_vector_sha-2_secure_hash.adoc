
=== Zvknh - NIST Suite: Vector SHA-2 Secure Hash

[[policy-variant-overloaded]]
==== Vector SHA-2 message schedule

[,c]
----
vuint32mf2_t __riscv_vsha2ms_tu(vuint32mf2_t vd, vuint32mf2_t vs2,
                                vuint32mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vsha2ms_tu(vuint32m1_t vd, vuint32m1_t vs2, vuint32m1_t vs1,
                               size_t vl);
vuint32m2_t __riscv_vsha2ms_tu(vuint32m2_t vd, vuint32m2_t vs2, vuint32m2_t vs1,
                               size_t vl);
vuint32m4_t __riscv_vsha2ms_tu(vuint32m4_t vd, vuint32m4_t vs2, vuint32m4_t vs1,
                               size_t vl);
vuint32m8_t __riscv_vsha2ms_tu(vuint32m8_t vd, vuint32m8_t vs2, vuint32m8_t vs1,
                               size_t vl);
vuint64m1_t __riscv_vsha2ms_tu(vuint64m1_t vd, vuint64m1_t vs2, vuint64m1_t vs1,
                               size_t vl);
vuint64m2_t __riscv_vsha2ms_tu(vuint64m2_t vd, vuint64m2_t vs2, vuint64m2_t vs1,
                               size_t vl);
vuint64m4_t __riscv_vsha2ms_tu(vuint64m4_t vd, vuint64m4_t vs2, vuint64m4_t vs1,
                               size_t vl);
vuint64m8_t __riscv_vsha2ms_tu(vuint64m8_t vd, vuint64m8_t vs2, vuint64m8_t vs1,
                               size_t vl);
----

[[policy-variant-overloaded]]
==== Vector SHA-2 two rounds of compression

[,c]
----
vuint32mf2_t __riscv_vsha2ch_tu(vuint32mf2_t vd, vuint32mf2_t vs2,
                                vuint32mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vsha2ch_tu(vuint32m1_t vd, vuint32m1_t vs2, vuint32m1_t vs1,
                               size_t vl);
vuint32m2_t __riscv_vsha2ch_tu(vuint32m2_t vd, vuint32m2_t vs2, vuint32m2_t vs1,
                               size_t vl);
vuint32m4_t __riscv_vsha2ch_tu(vuint32m4_t vd, vuint32m4_t vs2, vuint32m4_t vs1,
                               size_t vl);
vuint32m8_t __riscv_vsha2ch_tu(vuint32m8_t vd, vuint32m8_t vs2, vuint32m8_t vs1,
                               size_t vl);
vuint64m1_t __riscv_vsha2ch_tu(vuint64m1_t vd, vuint64m1_t vs2, vuint64m1_t vs1,
                               size_t vl);
vuint64m2_t __riscv_vsha2ch_tu(vuint64m2_t vd, vuint64m2_t vs2, vuint64m2_t vs1,
                               size_t vl);
vuint64m4_t __riscv_vsha2ch_tu(vuint64m4_t vd, vuint64m4_t vs2, vuint64m4_t vs1,
                               size_t vl);
vuint64m8_t __riscv_vsha2ch_tu(vuint64m8_t vd, vuint64m8_t vs2, vuint64m8_t vs1,
                               size_t vl);
vuint32mf2_t __riscv_vsha2cl_tu(vuint32mf2_t vd, vuint32mf2_t vs2,
                                vuint32mf2_t vs1, size_t vl);
vuint32m1_t __riscv_vsha2cl_tu(vuint32m1_t vd, vuint32m1_t vs2, vuint32m1_t vs1,
                               size_t vl);
vuint32m2_t __riscv_vsha2cl_tu(vuint32m2_t vd, vuint32m2_t vs2, vuint32m2_t vs1,
                               size_t vl);
vuint32m4_t __riscv_vsha2cl_tu(vuint32m4_t vd, vuint32m4_t vs2, vuint32m4_t vs1,
                               size_t vl);
vuint32m8_t __riscv_vsha2cl_tu(vuint32m8_t vd, vuint32m8_t vs2, vuint32m8_t vs1,
                               size_t vl);
vuint64m1_t __riscv_vsha2cl_tu(vuint64m1_t vd, vuint64m1_t vs2, vuint64m1_t vs1,
                               size_t vl);
vuint64m2_t __riscv_vsha2cl_tu(vuint64m2_t vd, vuint64m2_t vs2, vuint64m2_t vs1,
                               size_t vl);
vuint64m4_t __riscv_vsha2cl_tu(vuint64m4_t vd, vuint64m4_t vs2, vuint64m4_t vs1,
                               size_t vl);
vuint64m8_t __riscv_vsha2cl_tu(vuint64m8_t vd, vuint64m8_t vs2, vuint64m8_t vs1,
                               size_t vl);
----
