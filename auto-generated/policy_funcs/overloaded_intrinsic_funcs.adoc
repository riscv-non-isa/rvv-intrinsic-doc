
== Vector Loads and Stores Intrinsics

[[policy-variant-overloadedvector-unit-stride-load]]
=== Vector Unit-Stride Load Intrinsics

``` C
vfloat16mf4_t __riscv_vle16_tu (vfloat16mf4_t maskedoff, const float16_t *base, size_t vl);
vfloat16mf2_t __riscv_vle16_tu (vfloat16mf2_t maskedoff, const float16_t *base, size_t vl);
vfloat16m1_t __riscv_vle16_tu (vfloat16m1_t maskedoff, const float16_t *base, size_t vl);
vfloat16m2_t __riscv_vle16_tu (vfloat16m2_t maskedoff, const float16_t *base, size_t vl);
vfloat16m4_t __riscv_vle16_tu (vfloat16m4_t maskedoff, const float16_t *base, size_t vl);
vfloat16m8_t __riscv_vle16_tu (vfloat16m8_t maskedoff, const float16_t *base, size_t vl);
vfloat32mf2_t __riscv_vle32_tu (vfloat32mf2_t maskedoff, const float32_t *base, size_t vl);
vfloat32m1_t __riscv_vle32_tu (vfloat32m1_t maskedoff, const float32_t *base, size_t vl);
vfloat32m2_t __riscv_vle32_tu (vfloat32m2_t maskedoff, const float32_t *base, size_t vl);
vfloat32m4_t __riscv_vle32_tu (vfloat32m4_t maskedoff, const float32_t *base, size_t vl);
vfloat32m8_t __riscv_vle32_tu (vfloat32m8_t maskedoff, const float32_t *base, size_t vl);
vfloat64m1_t __riscv_vle64_tu (vfloat64m1_t maskedoff, const float64_t *base, size_t vl);
vfloat64m2_t __riscv_vle64_tu (vfloat64m2_t maskedoff, const float64_t *base, size_t vl);
vfloat64m4_t __riscv_vle64_tu (vfloat64m4_t maskedoff, const float64_t *base, size_t vl);
vfloat64m8_t __riscv_vle64_tu (vfloat64m8_t maskedoff, const float64_t *base, size_t vl);
vint8mf8_t __riscv_vle8_tu (vint8mf8_t maskedoff, const int8_t *base, size_t vl);
vint8mf4_t __riscv_vle8_tu (vint8mf4_t maskedoff, const int8_t *base, size_t vl);
vint8mf2_t __riscv_vle8_tu (vint8mf2_t maskedoff, const int8_t *base, size_t vl);
vint8m1_t __riscv_vle8_tu (vint8m1_t maskedoff, const int8_t *base, size_t vl);
vint8m2_t __riscv_vle8_tu (vint8m2_t maskedoff, const int8_t *base, size_t vl);
vint8m4_t __riscv_vle8_tu (vint8m4_t maskedoff, const int8_t *base, size_t vl);
vint8m8_t __riscv_vle8_tu (vint8m8_t maskedoff, const int8_t *base, size_t vl);
vint16mf4_t __riscv_vle16_tu (vint16mf4_t maskedoff, const int16_t *base, size_t vl);
vint16mf2_t __riscv_vle16_tu (vint16mf2_t maskedoff, const int16_t *base, size_t vl);
vint16m1_t __riscv_vle16_tu (vint16m1_t maskedoff, const int16_t *base, size_t vl);
vint16m2_t __riscv_vle16_tu (vint16m2_t maskedoff, const int16_t *base, size_t vl);
vint16m4_t __riscv_vle16_tu (vint16m4_t maskedoff, const int16_t *base, size_t vl);
vint16m8_t __riscv_vle16_tu (vint16m8_t maskedoff, const int16_t *base, size_t vl);
vint32mf2_t __riscv_vle32_tu (vint32mf2_t maskedoff, const int32_t *base, size_t vl);
vint32m1_t __riscv_vle32_tu (vint32m1_t maskedoff, const int32_t *base, size_t vl);
vint32m2_t __riscv_vle32_tu (vint32m2_t maskedoff, const int32_t *base, size_t vl);
vint32m4_t __riscv_vle32_tu (vint32m4_t maskedoff, const int32_t *base, size_t vl);
vint32m8_t __riscv_vle32_tu (vint32m8_t maskedoff, const int32_t *base, size_t vl);
vint64m1_t __riscv_vle64_tu (vint64m1_t maskedoff, const int64_t *base, size_t vl);
vint64m2_t __riscv_vle64_tu (vint64m2_t maskedoff, const int64_t *base, size_t vl);
vint64m4_t __riscv_vle64_tu (vint64m4_t maskedoff, const int64_t *base, size_t vl);
vint64m8_t __riscv_vle64_tu (vint64m8_t maskedoff, const int64_t *base, size_t vl);
vuint8mf8_t __riscv_vle8_tu (vuint8mf8_t maskedoff, const uint8_t *base, size_t vl);
vuint8mf4_t __riscv_vle8_tu (vuint8mf4_t maskedoff, const uint8_t *base, size_t vl);
vuint8mf2_t __riscv_vle8_tu (vuint8mf2_t maskedoff, const uint8_t *base, size_t vl);
vuint8m1_t __riscv_vle8_tu (vuint8m1_t maskedoff, const uint8_t *base, size_t vl);
vuint8m2_t __riscv_vle8_tu (vuint8m2_t maskedoff, const uint8_t *base, size_t vl);
vuint8m4_t __riscv_vle8_tu (vuint8m4_t maskedoff, const uint8_t *base, size_t vl);
vuint8m8_t __riscv_vle8_tu (vuint8m8_t maskedoff, const uint8_t *base, size_t vl);
vuint16mf4_t __riscv_vle16_tu (vuint16mf4_t maskedoff, const uint16_t *base, size_t vl);
vuint16mf2_t __riscv_vle16_tu (vuint16mf2_t maskedoff, const uint16_t *base, size_t vl);
vuint16m1_t __riscv_vle16_tu (vuint16m1_t maskedoff, const uint16_t *base, size_t vl);
vuint16m2_t __riscv_vle16_tu (vuint16m2_t maskedoff, const uint16_t *base, size_t vl);
vuint16m4_t __riscv_vle16_tu (vuint16m4_t maskedoff, const uint16_t *base, size_t vl);
vuint16m8_t __riscv_vle16_tu (vuint16m8_t maskedoff, const uint16_t *base, size_t vl);
vuint32mf2_t __riscv_vle32_tu (vuint32mf2_t maskedoff, const uint32_t *base, size_t vl);
vuint32m1_t __riscv_vle32_tu (vuint32m1_t maskedoff, const uint32_t *base, size_t vl);
vuint32m2_t __riscv_vle32_tu (vuint32m2_t maskedoff, const uint32_t *base, size_t vl);
vuint32m4_t __riscv_vle32_tu (vuint32m4_t maskedoff, const uint32_t *base, size_t vl);
vuint32m8_t __riscv_vle32_tu (vuint32m8_t maskedoff, const uint32_t *base, size_t vl);
vuint64m1_t __riscv_vle64_tu (vuint64m1_t maskedoff, const uint64_t *base, size_t vl);
vuint64m2_t __riscv_vle64_tu (vuint64m2_t maskedoff, const uint64_t *base, size_t vl);
vuint64m4_t __riscv_vle64_tu (vuint64m4_t maskedoff, const uint64_t *base, size_t vl);
vuint64m8_t __riscv_vle64_tu (vuint64m8_t maskedoff, const uint64_t *base, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, size_t vl);
vfloat16mf2_t __riscv_vle16_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, size_t vl);
vfloat16m1_t __riscv_vle16_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, size_t vl);
vfloat16m2_t __riscv_vle16_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, size_t vl);
vfloat16m4_t __riscv_vle16_tum (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, size_t vl);
vfloat16m8_t __riscv_vle16_tum (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, size_t vl);
vfloat32mf2_t __riscv_vle32_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, size_t vl);
vfloat32m1_t __riscv_vle32_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, size_t vl);
vfloat32m2_t __riscv_vle32_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, size_t vl);
vfloat32m4_t __riscv_vle32_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, size_t vl);
vfloat32m8_t __riscv_vle32_tum (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, size_t vl);
vfloat64m1_t __riscv_vle64_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, size_t vl);
vfloat64m2_t __riscv_vle64_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, size_t vl);
vfloat64m4_t __riscv_vle64_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, size_t vl);
vfloat64m8_t __riscv_vle64_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, size_t vl);
vint8mf8_t __riscv_vle8_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, size_t vl);
vint8mf4_t __riscv_vle8_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, size_t vl);
vint8mf2_t __riscv_vle8_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, size_t vl);
vint8m1_t __riscv_vle8_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, size_t vl);
vint8m2_t __riscv_vle8_tum (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, size_t vl);
vint8m4_t __riscv_vle8_tum (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, size_t vl);
vint8m8_t __riscv_vle8_tum (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, size_t vl);
vint16mf4_t __riscv_vle16_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, size_t vl);
vint16mf2_t __riscv_vle16_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, size_t vl);
vint16m1_t __riscv_vle16_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, size_t vl);
vint16m2_t __riscv_vle16_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, size_t vl);
vint16m4_t __riscv_vle16_tum (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, size_t vl);
vint16m8_t __riscv_vle16_tum (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, size_t vl);
vint32mf2_t __riscv_vle32_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, size_t vl);
vint32m1_t __riscv_vle32_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, size_t vl);
vint32m2_t __riscv_vle32_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, size_t vl);
vint32m4_t __riscv_vle32_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, size_t vl);
vint32m8_t __riscv_vle32_tum (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, size_t vl);
vint64m1_t __riscv_vle64_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, size_t vl);
vint64m2_t __riscv_vle64_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, size_t vl);
vint64m4_t __riscv_vle64_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, size_t vl);
vint64m8_t __riscv_vle64_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, size_t vl);
vuint8mf8_t __riscv_vle8_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, size_t vl);
vuint8mf4_t __riscv_vle8_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, size_t vl);
vuint8mf2_t __riscv_vle8_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, size_t vl);
vuint8m1_t __riscv_vle8_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, size_t vl);
vuint8m2_t __riscv_vle8_tum (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, size_t vl);
vuint8m4_t __riscv_vle8_tum (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, size_t vl);
vuint8m8_t __riscv_vle8_tum (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, size_t vl);
vuint16mf4_t __riscv_vle16_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, size_t vl);
vuint16mf2_t __riscv_vle16_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, size_t vl);
vuint16m1_t __riscv_vle16_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, size_t vl);
vuint16m2_t __riscv_vle16_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, size_t vl);
vuint16m4_t __riscv_vle16_tum (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, size_t vl);
vuint16m8_t __riscv_vle16_tum (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, size_t vl);
vuint32mf2_t __riscv_vle32_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, size_t vl);
vuint32m1_t __riscv_vle32_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, size_t vl);
vuint32m2_t __riscv_vle32_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, size_t vl);
vuint32m4_t __riscv_vle32_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, size_t vl);
vuint32m8_t __riscv_vle32_tum (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, size_t vl);
vuint64m1_t __riscv_vle64_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, size_t vl);
vuint64m2_t __riscv_vle64_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, size_t vl);
vuint64m4_t __riscv_vle64_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, size_t vl);
vuint64m8_t __riscv_vle64_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, size_t vl);
vfloat16mf2_t __riscv_vle16_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, size_t vl);
vfloat16m1_t __riscv_vle16_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, size_t vl);
vfloat16m2_t __riscv_vle16_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, size_t vl);
vfloat16m4_t __riscv_vle16_tumu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, size_t vl);
vfloat16m8_t __riscv_vle16_tumu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, size_t vl);
vfloat32mf2_t __riscv_vle32_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, size_t vl);
vfloat32m1_t __riscv_vle32_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, size_t vl);
vfloat32m2_t __riscv_vle32_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, size_t vl);
vfloat32m4_t __riscv_vle32_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, size_t vl);
vfloat32m8_t __riscv_vle32_tumu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, size_t vl);
vfloat64m1_t __riscv_vle64_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, size_t vl);
vfloat64m2_t __riscv_vle64_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, size_t vl);
vfloat64m4_t __riscv_vle64_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, size_t vl);
vfloat64m8_t __riscv_vle64_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, size_t vl);
vint8mf8_t __riscv_vle8_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, size_t vl);
vint8mf4_t __riscv_vle8_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, size_t vl);
vint8mf2_t __riscv_vle8_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, size_t vl);
vint8m1_t __riscv_vle8_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, size_t vl);
vint8m2_t __riscv_vle8_tumu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, size_t vl);
vint8m4_t __riscv_vle8_tumu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, size_t vl);
vint8m8_t __riscv_vle8_tumu (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, size_t vl);
vint16mf4_t __riscv_vle16_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, size_t vl);
vint16mf2_t __riscv_vle16_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, size_t vl);
vint16m1_t __riscv_vle16_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, size_t vl);
vint16m2_t __riscv_vle16_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, size_t vl);
vint16m4_t __riscv_vle16_tumu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, size_t vl);
vint16m8_t __riscv_vle16_tumu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, size_t vl);
vint32mf2_t __riscv_vle32_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, size_t vl);
vint32m1_t __riscv_vle32_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, size_t vl);
vint32m2_t __riscv_vle32_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, size_t vl);
vint32m4_t __riscv_vle32_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, size_t vl);
vint32m8_t __riscv_vle32_tumu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, size_t vl);
vint64m1_t __riscv_vle64_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, size_t vl);
vint64m2_t __riscv_vle64_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, size_t vl);
vint64m4_t __riscv_vle64_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, size_t vl);
vint64m8_t __riscv_vle64_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, size_t vl);
vuint8mf8_t __riscv_vle8_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, size_t vl);
vuint8mf4_t __riscv_vle8_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, size_t vl);
vuint8mf2_t __riscv_vle8_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, size_t vl);
vuint8m1_t __riscv_vle8_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, size_t vl);
vuint8m2_t __riscv_vle8_tumu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, size_t vl);
vuint8m4_t __riscv_vle8_tumu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, size_t vl);
vuint8m8_t __riscv_vle8_tumu (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, size_t vl);
vuint16mf4_t __riscv_vle16_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, size_t vl);
vuint16mf2_t __riscv_vle16_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, size_t vl);
vuint16m1_t __riscv_vle16_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, size_t vl);
vuint16m2_t __riscv_vle16_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, size_t vl);
vuint16m4_t __riscv_vle16_tumu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, size_t vl);
vuint16m8_t __riscv_vle16_tumu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, size_t vl);
vuint32mf2_t __riscv_vle32_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, size_t vl);
vuint32m1_t __riscv_vle32_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, size_t vl);
vuint32m2_t __riscv_vle32_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, size_t vl);
vuint32m4_t __riscv_vle32_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, size_t vl);
vuint32m8_t __riscv_vle32_tumu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, size_t vl);
vuint64m1_t __riscv_vle64_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, size_t vl);
vuint64m2_t __riscv_vle64_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, size_t vl);
vuint64m4_t __riscv_vle64_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, size_t vl);
vuint64m8_t __riscv_vle64_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, size_t vl);
vfloat16mf2_t __riscv_vle16_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, size_t vl);
vfloat16m1_t __riscv_vle16_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, size_t vl);
vfloat16m2_t __riscv_vle16_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, size_t vl);
vfloat16m4_t __riscv_vle16_mu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, size_t vl);
vfloat16m8_t __riscv_vle16_mu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, size_t vl);
vfloat32mf2_t __riscv_vle32_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, size_t vl);
vfloat32m1_t __riscv_vle32_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, size_t vl);
vfloat32m2_t __riscv_vle32_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, size_t vl);
vfloat32m4_t __riscv_vle32_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, size_t vl);
vfloat32m8_t __riscv_vle32_mu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, size_t vl);
vfloat64m1_t __riscv_vle64_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, size_t vl);
vfloat64m2_t __riscv_vle64_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, size_t vl);
vfloat64m4_t __riscv_vle64_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, size_t vl);
vfloat64m8_t __riscv_vle64_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, size_t vl);
vint8mf8_t __riscv_vle8_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, size_t vl);
vint8mf4_t __riscv_vle8_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, size_t vl);
vint8mf2_t __riscv_vle8_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, size_t vl);
vint8m1_t __riscv_vle8_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, size_t vl);
vint8m2_t __riscv_vle8_mu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, size_t vl);
vint8m4_t __riscv_vle8_mu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, size_t vl);
vint8m8_t __riscv_vle8_mu (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, size_t vl);
vint16mf4_t __riscv_vle16_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, size_t vl);
vint16mf2_t __riscv_vle16_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, size_t vl);
vint16m1_t __riscv_vle16_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, size_t vl);
vint16m2_t __riscv_vle16_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, size_t vl);
vint16m4_t __riscv_vle16_mu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, size_t vl);
vint16m8_t __riscv_vle16_mu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, size_t vl);
vint32mf2_t __riscv_vle32_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, size_t vl);
vint32m1_t __riscv_vle32_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, size_t vl);
vint32m2_t __riscv_vle32_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, size_t vl);
vint32m4_t __riscv_vle32_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, size_t vl);
vint32m8_t __riscv_vle32_mu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, size_t vl);
vint64m1_t __riscv_vle64_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, size_t vl);
vint64m2_t __riscv_vle64_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, size_t vl);
vint64m4_t __riscv_vle64_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, size_t vl);
vint64m8_t __riscv_vle64_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, size_t vl);
vuint8mf8_t __riscv_vle8_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, size_t vl);
vuint8mf4_t __riscv_vle8_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, size_t vl);
vuint8mf2_t __riscv_vle8_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, size_t vl);
vuint8m1_t __riscv_vle8_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, size_t vl);
vuint8m2_t __riscv_vle8_mu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, size_t vl);
vuint8m4_t __riscv_vle8_mu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, size_t vl);
vuint8m8_t __riscv_vle8_mu (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, size_t vl);
vuint16mf4_t __riscv_vle16_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, size_t vl);
vuint16mf2_t __riscv_vle16_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, size_t vl);
vuint16m1_t __riscv_vle16_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, size_t vl);
vuint16m2_t __riscv_vle16_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, size_t vl);
vuint16m4_t __riscv_vle16_mu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, size_t vl);
vuint16m8_t __riscv_vle16_mu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, size_t vl);
vuint32mf2_t __riscv_vle32_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, size_t vl);
vuint32m1_t __riscv_vle32_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, size_t vl);
vuint32m2_t __riscv_vle32_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, size_t vl);
vuint32m4_t __riscv_vle32_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, size_t vl);
vuint32m8_t __riscv_vle32_mu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, size_t vl);
vuint64m1_t __riscv_vle64_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, size_t vl);
vuint64m2_t __riscv_vle64_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, size_t vl);
vuint64m4_t __riscv_vle64_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, size_t vl);
vuint64m8_t __riscv_vle64_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, size_t vl);
```

[[policy-variant-overloadedvector-unit-stride-store]]
=== Vector Unit-Stride Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-unit-stride]]
=== Vector Mask Load/Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-strided-load]]
=== Vector Strided Load Intrinsics

``` C
vfloat16mf4_t __riscv_vlse16_tu (vfloat16mf4_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2_t __riscv_vlse16_tu (vfloat16mf2_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1_t __riscv_vlse16_tu (vfloat16m1_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2_t __riscv_vlse16_tu (vfloat16m2_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4_t __riscv_vlse16_tu (vfloat16m4_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m8_t __riscv_vlse16_tu (vfloat16m8_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2_t __riscv_vlse32_tu (vfloat32mf2_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1_t __riscv_vlse32_tu (vfloat32m1_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2_t __riscv_vlse32_tu (vfloat32m2_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4_t __riscv_vlse32_tu (vfloat32m4_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m8_t __riscv_vlse32_tu (vfloat32m8_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1_t __riscv_vlse64_tu (vfloat64m1_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2_t __riscv_vlse64_tu (vfloat64m2_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4_t __riscv_vlse64_tu (vfloat64m4_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m8_t __riscv_vlse64_tu (vfloat64m8_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8_t __riscv_vlse8_tu (vint8mf8_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4_t __riscv_vlse8_tu (vint8mf4_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2_t __riscv_vlse8_tu (vint8mf2_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1_t __riscv_vlse8_tu (vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2_t __riscv_vlse8_tu (vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4_t __riscv_vlse8_tu (vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m8_t __riscv_vlse8_tu (vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4_t __riscv_vlse16_tu (vint16mf4_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2_t __riscv_vlse16_tu (vint16mf2_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1_t __riscv_vlse16_tu (vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2_t __riscv_vlse16_tu (vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4_t __riscv_vlse16_tu (vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m8_t __riscv_vlse16_tu (vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2_t __riscv_vlse32_tu (vint32mf2_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1_t __riscv_vlse32_tu (vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2_t __riscv_vlse32_tu (vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4_t __riscv_vlse32_tu (vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m8_t __riscv_vlse32_tu (vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1_t __riscv_vlse64_tu (vint64m1_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2_t __riscv_vlse64_tu (vint64m2_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4_t __riscv_vlse64_tu (vint64m4_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m8_t __riscv_vlse64_tu (vint64m8_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8_t __riscv_vlse8_tu (vuint8mf8_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4_t __riscv_vlse8_tu (vuint8mf4_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2_t __riscv_vlse8_tu (vuint8mf2_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1_t __riscv_vlse8_tu (vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2_t __riscv_vlse8_tu (vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4_t __riscv_vlse8_tu (vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m8_t __riscv_vlse8_tu (vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4_t __riscv_vlse16_tu (vuint16mf4_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2_t __riscv_vlse16_tu (vuint16mf2_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1_t __riscv_vlse16_tu (vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2_t __riscv_vlse16_tu (vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4_t __riscv_vlse16_tu (vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m8_t __riscv_vlse16_tu (vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2_t __riscv_vlse32_tu (vuint32mf2_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1_t __riscv_vlse32_tu (vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2_t __riscv_vlse32_tu (vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4_t __riscv_vlse32_tu (vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m8_t __riscv_vlse32_tu (vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1_t __riscv_vlse64_tu (vuint64m1_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2_t __riscv_vlse64_tu (vuint64m2_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4_t __riscv_vlse64_tu (vuint64m4_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m8_t __riscv_vlse64_tu (vuint64m8_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vlse16_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2_t __riscv_vlse16_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1_t __riscv_vlse16_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2_t __riscv_vlse16_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4_t __riscv_vlse16_tum (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m8_t __riscv_vlse16_tum (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2_t __riscv_vlse32_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1_t __riscv_vlse32_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2_t __riscv_vlse32_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4_t __riscv_vlse32_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m8_t __riscv_vlse32_tum (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1_t __riscv_vlse64_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2_t __riscv_vlse64_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4_t __riscv_vlse64_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m8_t __riscv_vlse64_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8_t __riscv_vlse8_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4_t __riscv_vlse8_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2_t __riscv_vlse8_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1_t __riscv_vlse8_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2_t __riscv_vlse8_tum (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4_t __riscv_vlse8_tum (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m8_t __riscv_vlse8_tum (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4_t __riscv_vlse16_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2_t __riscv_vlse16_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1_t __riscv_vlse16_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2_t __riscv_vlse16_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4_t __riscv_vlse16_tum (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m8_t __riscv_vlse16_tum (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2_t __riscv_vlse32_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1_t __riscv_vlse32_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2_t __riscv_vlse32_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4_t __riscv_vlse32_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m8_t __riscv_vlse32_tum (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1_t __riscv_vlse64_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2_t __riscv_vlse64_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4_t __riscv_vlse64_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m8_t __riscv_vlse64_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8_t __riscv_vlse8_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4_t __riscv_vlse8_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2_t __riscv_vlse8_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1_t __riscv_vlse8_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2_t __riscv_vlse8_tum (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4_t __riscv_vlse8_tum (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m8_t __riscv_vlse8_tum (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4_t __riscv_vlse16_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2_t __riscv_vlse16_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1_t __riscv_vlse16_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2_t __riscv_vlse16_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4_t __riscv_vlse16_tum (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m8_t __riscv_vlse16_tum (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2_t __riscv_vlse32_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1_t __riscv_vlse32_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2_t __riscv_vlse32_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4_t __riscv_vlse32_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m8_t __riscv_vlse32_tum (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1_t __riscv_vlse64_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2_t __riscv_vlse64_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4_t __riscv_vlse64_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m8_t __riscv_vlse64_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vlse16_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2_t __riscv_vlse16_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1_t __riscv_vlse16_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2_t __riscv_vlse16_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4_t __riscv_vlse16_tumu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m8_t __riscv_vlse16_tumu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2_t __riscv_vlse32_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1_t __riscv_vlse32_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2_t __riscv_vlse32_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4_t __riscv_vlse32_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m8_t __riscv_vlse32_tumu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1_t __riscv_vlse64_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2_t __riscv_vlse64_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4_t __riscv_vlse64_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m8_t __riscv_vlse64_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8_t __riscv_vlse8_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4_t __riscv_vlse8_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2_t __riscv_vlse8_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1_t __riscv_vlse8_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2_t __riscv_vlse8_tumu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4_t __riscv_vlse8_tumu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m8_t __riscv_vlse8_tumu (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4_t __riscv_vlse16_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2_t __riscv_vlse16_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1_t __riscv_vlse16_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2_t __riscv_vlse16_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4_t __riscv_vlse16_tumu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m8_t __riscv_vlse16_tumu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2_t __riscv_vlse32_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1_t __riscv_vlse32_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2_t __riscv_vlse32_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4_t __riscv_vlse32_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m8_t __riscv_vlse32_tumu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1_t __riscv_vlse64_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2_t __riscv_vlse64_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4_t __riscv_vlse64_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m8_t __riscv_vlse64_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8_t __riscv_vlse8_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4_t __riscv_vlse8_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2_t __riscv_vlse8_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1_t __riscv_vlse8_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2_t __riscv_vlse8_tumu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4_t __riscv_vlse8_tumu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m8_t __riscv_vlse8_tumu (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4_t __riscv_vlse16_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2_t __riscv_vlse16_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1_t __riscv_vlse16_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2_t __riscv_vlse16_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4_t __riscv_vlse16_tumu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m8_t __riscv_vlse16_tumu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2_t __riscv_vlse32_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1_t __riscv_vlse32_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2_t __riscv_vlse32_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4_t __riscv_vlse32_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m8_t __riscv_vlse32_tumu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1_t __riscv_vlse64_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2_t __riscv_vlse64_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4_t __riscv_vlse64_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m8_t __riscv_vlse64_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vlse16_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2_t __riscv_vlse16_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1_t __riscv_vlse16_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2_t __riscv_vlse16_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4_t __riscv_vlse16_mu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m8_t __riscv_vlse16_mu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2_t __riscv_vlse32_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1_t __riscv_vlse32_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2_t __riscv_vlse32_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4_t __riscv_vlse32_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m8_t __riscv_vlse32_mu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1_t __riscv_vlse64_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2_t __riscv_vlse64_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4_t __riscv_vlse64_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m8_t __riscv_vlse64_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8_t __riscv_vlse8_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4_t __riscv_vlse8_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2_t __riscv_vlse8_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1_t __riscv_vlse8_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2_t __riscv_vlse8_mu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4_t __riscv_vlse8_mu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m8_t __riscv_vlse8_mu (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4_t __riscv_vlse16_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2_t __riscv_vlse16_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1_t __riscv_vlse16_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2_t __riscv_vlse16_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4_t __riscv_vlse16_mu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m8_t __riscv_vlse16_mu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2_t __riscv_vlse32_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1_t __riscv_vlse32_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2_t __riscv_vlse32_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4_t __riscv_vlse32_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m8_t __riscv_vlse32_mu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1_t __riscv_vlse64_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2_t __riscv_vlse64_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4_t __riscv_vlse64_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m8_t __riscv_vlse64_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8_t __riscv_vlse8_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4_t __riscv_vlse8_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2_t __riscv_vlse8_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1_t __riscv_vlse8_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2_t __riscv_vlse8_mu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4_t __riscv_vlse8_mu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m8_t __riscv_vlse8_mu (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4_t __riscv_vlse16_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2_t __riscv_vlse16_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1_t __riscv_vlse16_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2_t __riscv_vlse16_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4_t __riscv_vlse16_mu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m8_t __riscv_vlse16_mu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2_t __riscv_vlse32_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1_t __riscv_vlse32_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2_t __riscv_vlse32_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4_t __riscv_vlse32_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m8_t __riscv_vlse32_mu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1_t __riscv_vlse64_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2_t __riscv_vlse64_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4_t __riscv_vlse64_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m8_t __riscv_vlse64_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, ptrdiff_t bstride, size_t vl);
```

[[policy-variant-overloadedvector-strided-store]]
=== Vector Strided Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-indexed-load]]
=== Vector Indexed Load Intrinsics

``` C
vfloat16mf4_t __riscv_vloxei8_tu (vfloat16mf4_t maskedoff, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei8_tu (vfloat16mf2_t maskedoff, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei8_tu (vfloat16m1_t maskedoff, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei8_tu (vfloat16m2_t maskedoff, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei8_tu (vfloat16m4_t maskedoff, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16m8_t __riscv_vloxei8_tu (vfloat16m8_t maskedoff, const float16_t *base, vuint8m4_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei16_tu (vfloat16mf4_t maskedoff, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei16_tu (vfloat16mf2_t maskedoff, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei16_tu (vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei16_tu (vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei16_tu (vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16m8_t __riscv_vloxei16_tu (vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei32_tu (vfloat16mf4_t maskedoff, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei32_tu (vfloat16mf2_t maskedoff, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei32_tu (vfloat16m1_t maskedoff, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei32_tu (vfloat16m2_t maskedoff, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei32_tu (vfloat16m4_t maskedoff, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei64_tu (vfloat16mf4_t maskedoff, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei64_tu (vfloat16mf2_t maskedoff, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei64_tu (vfloat16m1_t maskedoff, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei64_tu (vfloat16m2_t maskedoff, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei8_tu (vfloat32mf2_t maskedoff, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei8_tu (vfloat32m1_t maskedoff, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei8_tu (vfloat32m2_t maskedoff, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei8_tu (vfloat32m4_t maskedoff, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei8_tu (vfloat32m8_t maskedoff, const float32_t *base, vuint8m2_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei16_tu (vfloat32mf2_t maskedoff, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei16_tu (vfloat32m1_t maskedoff, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei16_tu (vfloat32m2_t maskedoff, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei16_tu (vfloat32m4_t maskedoff, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei16_tu (vfloat32m8_t maskedoff, const float32_t *base, vuint16m4_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei32_tu (vfloat32mf2_t maskedoff, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei32_tu (vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei32_tu (vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei32_tu (vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei32_tu (vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei64_tu (vfloat32mf2_t maskedoff, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei64_tu (vfloat32m1_t maskedoff, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei64_tu (vfloat32m2_t maskedoff, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei64_tu (vfloat32m4_t maskedoff, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei8_tu (vfloat64m1_t maskedoff, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei8_tu (vfloat64m2_t maskedoff, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei8_tu (vfloat64m4_t maskedoff, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei8_tu (vfloat64m8_t maskedoff, const float64_t *base, vuint8m1_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei16_tu (vfloat64m1_t maskedoff, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei16_tu (vfloat64m2_t maskedoff, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei16_tu (vfloat64m4_t maskedoff, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei16_tu (vfloat64m8_t maskedoff, const float64_t *base, vuint16m2_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei32_tu (vfloat64m1_t maskedoff, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei32_tu (vfloat64m2_t maskedoff, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei32_tu (vfloat64m4_t maskedoff, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei32_tu (vfloat64m8_t maskedoff, const float64_t *base, vuint32m4_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei64_tu (vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei64_tu (vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei64_tu (vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei64_tu (vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei8_tu (vfloat16mf4_t maskedoff, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei8_tu (vfloat16mf2_t maskedoff, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei8_tu (vfloat16m1_t maskedoff, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei8_tu (vfloat16m2_t maskedoff, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei8_tu (vfloat16m4_t maskedoff, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16m8_t __riscv_vluxei8_tu (vfloat16m8_t maskedoff, const float16_t *base, vuint8m4_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei16_tu (vfloat16mf4_t maskedoff, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei16_tu (vfloat16mf2_t maskedoff, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei16_tu (vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei16_tu (vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei16_tu (vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16m8_t __riscv_vluxei16_tu (vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei32_tu (vfloat16mf4_t maskedoff, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei32_tu (vfloat16mf2_t maskedoff, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei32_tu (vfloat16m1_t maskedoff, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei32_tu (vfloat16m2_t maskedoff, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei32_tu (vfloat16m4_t maskedoff, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei64_tu (vfloat16mf4_t maskedoff, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei64_tu (vfloat16mf2_t maskedoff, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei64_tu (vfloat16m1_t maskedoff, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei64_tu (vfloat16m2_t maskedoff, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei8_tu (vfloat32mf2_t maskedoff, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei8_tu (vfloat32m1_t maskedoff, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei8_tu (vfloat32m2_t maskedoff, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei8_tu (vfloat32m4_t maskedoff, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei8_tu (vfloat32m8_t maskedoff, const float32_t *base, vuint8m2_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei16_tu (vfloat32mf2_t maskedoff, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei16_tu (vfloat32m1_t maskedoff, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei16_tu (vfloat32m2_t maskedoff, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei16_tu (vfloat32m4_t maskedoff, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei16_tu (vfloat32m8_t maskedoff, const float32_t *base, vuint16m4_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei32_tu (vfloat32mf2_t maskedoff, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei32_tu (vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei32_tu (vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei32_tu (vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei32_tu (vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei64_tu (vfloat32mf2_t maskedoff, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei64_tu (vfloat32m1_t maskedoff, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei64_tu (vfloat32m2_t maskedoff, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei64_tu (vfloat32m4_t maskedoff, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei8_tu (vfloat64m1_t maskedoff, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei8_tu (vfloat64m2_t maskedoff, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei8_tu (vfloat64m4_t maskedoff, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei8_tu (vfloat64m8_t maskedoff, const float64_t *base, vuint8m1_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei16_tu (vfloat64m1_t maskedoff, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei16_tu (vfloat64m2_t maskedoff, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei16_tu (vfloat64m4_t maskedoff, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei16_tu (vfloat64m8_t maskedoff, const float64_t *base, vuint16m2_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei32_tu (vfloat64m1_t maskedoff, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei32_tu (vfloat64m2_t maskedoff, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei32_tu (vfloat64m4_t maskedoff, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei32_tu (vfloat64m8_t maskedoff, const float64_t *base, vuint32m4_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei64_tu (vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei64_tu (vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei64_tu (vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei64_tu (vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei8_tu (vint8mf8_t maskedoff, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei8_tu (vint8mf4_t maskedoff, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei8_tu (vint8mf2_t maskedoff, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1_t __riscv_vloxei8_tu (vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2_t __riscv_vloxei8_tu (vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4_t __riscv_vloxei8_tu (vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8m8_t __riscv_vloxei8_tu (vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei16_tu (vint8mf8_t maskedoff, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei16_tu (vint8mf4_t maskedoff, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei16_tu (vint8mf2_t maskedoff, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1_t __riscv_vloxei16_tu (vint8m1_t maskedoff, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2_t __riscv_vloxei16_tu (vint8m2_t maskedoff, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4_t __riscv_vloxei16_tu (vint8m4_t maskedoff, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei32_tu (vint8mf8_t maskedoff, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei32_tu (vint8mf4_t maskedoff, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei32_tu (vint8mf2_t maskedoff, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1_t __riscv_vloxei32_tu (vint8m1_t maskedoff, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2_t __riscv_vloxei32_tu (vint8m2_t maskedoff, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei64_tu (vint8mf8_t maskedoff, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei64_tu (vint8mf4_t maskedoff, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei64_tu (vint8mf2_t maskedoff, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1_t __riscv_vloxei64_tu (vint8m1_t maskedoff, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei8_tu (vint16mf4_t maskedoff, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei8_tu (vint16mf2_t maskedoff, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1_t __riscv_vloxei8_tu (vint16m1_t maskedoff, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2_t __riscv_vloxei8_tu (vint16m2_t maskedoff, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4_t __riscv_vloxei8_tu (vint16m4_t maskedoff, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16m8_t __riscv_vloxei8_tu (vint16m8_t maskedoff, const int16_t *base, vuint8m4_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei16_tu (vint16mf4_t maskedoff, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei16_tu (vint16mf2_t maskedoff, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1_t __riscv_vloxei16_tu (vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2_t __riscv_vloxei16_tu (vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4_t __riscv_vloxei16_tu (vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16m8_t __riscv_vloxei16_tu (vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei32_tu (vint16mf4_t maskedoff, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei32_tu (vint16mf2_t maskedoff, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1_t __riscv_vloxei32_tu (vint16m1_t maskedoff, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2_t __riscv_vloxei32_tu (vint16m2_t maskedoff, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4_t __riscv_vloxei32_tu (vint16m4_t maskedoff, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei64_tu (vint16mf4_t maskedoff, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei64_tu (vint16mf2_t maskedoff, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1_t __riscv_vloxei64_tu (vint16m1_t maskedoff, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2_t __riscv_vloxei64_tu (vint16m2_t maskedoff, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei8_tu (vint32mf2_t maskedoff, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1_t __riscv_vloxei8_tu (vint32m1_t maskedoff, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2_t __riscv_vloxei8_tu (vint32m2_t maskedoff, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4_t __riscv_vloxei8_tu (vint32m4_t maskedoff, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32m8_t __riscv_vloxei8_tu (vint32m8_t maskedoff, const int32_t *base, vuint8m2_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei16_tu (vint32mf2_t maskedoff, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1_t __riscv_vloxei16_tu (vint32m1_t maskedoff, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2_t __riscv_vloxei16_tu (vint32m2_t maskedoff, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4_t __riscv_vloxei16_tu (vint32m4_t maskedoff, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32m8_t __riscv_vloxei16_tu (vint32m8_t maskedoff, const int32_t *base, vuint16m4_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei32_tu (vint32mf2_t maskedoff, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1_t __riscv_vloxei32_tu (vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2_t __riscv_vloxei32_tu (vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4_t __riscv_vloxei32_tu (vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32m8_t __riscv_vloxei32_tu (vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei64_tu (vint32mf2_t maskedoff, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1_t __riscv_vloxei64_tu (vint32m1_t maskedoff, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2_t __riscv_vloxei64_tu (vint32m2_t maskedoff, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4_t __riscv_vloxei64_tu (vint32m4_t maskedoff, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1_t __riscv_vloxei8_tu (vint64m1_t maskedoff, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2_t __riscv_vloxei8_tu (vint64m2_t maskedoff, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4_t __riscv_vloxei8_tu (vint64m4_t maskedoff, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m8_t __riscv_vloxei8_tu (vint64m8_t maskedoff, const int64_t *base, vuint8m1_t bindex, size_t vl);
vint64m1_t __riscv_vloxei16_tu (vint64m1_t maskedoff, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2_t __riscv_vloxei16_tu (vint64m2_t maskedoff, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4_t __riscv_vloxei16_tu (vint64m4_t maskedoff, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m8_t __riscv_vloxei16_tu (vint64m8_t maskedoff, const int64_t *base, vuint16m2_t bindex, size_t vl);
vint64m1_t __riscv_vloxei32_tu (vint64m1_t maskedoff, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2_t __riscv_vloxei32_tu (vint64m2_t maskedoff, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4_t __riscv_vloxei32_tu (vint64m4_t maskedoff, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m8_t __riscv_vloxei32_tu (vint64m8_t maskedoff, const int64_t *base, vuint32m4_t bindex, size_t vl);
vint64m1_t __riscv_vloxei64_tu (vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2_t __riscv_vloxei64_tu (vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4_t __riscv_vloxei64_tu (vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint64m8_t __riscv_vloxei64_tu (vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei8_tu (vint8mf8_t maskedoff, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei8_tu (vint8mf4_t maskedoff, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei8_tu (vint8mf2_t maskedoff, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1_t __riscv_vluxei8_tu (vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2_t __riscv_vluxei8_tu (vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4_t __riscv_vluxei8_tu (vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8m8_t __riscv_vluxei8_tu (vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei16_tu (vint8mf8_t maskedoff, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei16_tu (vint8mf4_t maskedoff, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei16_tu (vint8mf2_t maskedoff, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1_t __riscv_vluxei16_tu (vint8m1_t maskedoff, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2_t __riscv_vluxei16_tu (vint8m2_t maskedoff, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4_t __riscv_vluxei16_tu (vint8m4_t maskedoff, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei32_tu (vint8mf8_t maskedoff, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei32_tu (vint8mf4_t maskedoff, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei32_tu (vint8mf2_t maskedoff, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1_t __riscv_vluxei32_tu (vint8m1_t maskedoff, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2_t __riscv_vluxei32_tu (vint8m2_t maskedoff, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei64_tu (vint8mf8_t maskedoff, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei64_tu (vint8mf4_t maskedoff, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei64_tu (vint8mf2_t maskedoff, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1_t __riscv_vluxei64_tu (vint8m1_t maskedoff, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei8_tu (vint16mf4_t maskedoff, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei8_tu (vint16mf2_t maskedoff, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1_t __riscv_vluxei8_tu (vint16m1_t maskedoff, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2_t __riscv_vluxei8_tu (vint16m2_t maskedoff, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4_t __riscv_vluxei8_tu (vint16m4_t maskedoff, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16m8_t __riscv_vluxei8_tu (vint16m8_t maskedoff, const int16_t *base, vuint8m4_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei16_tu (vint16mf4_t maskedoff, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei16_tu (vint16mf2_t maskedoff, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1_t __riscv_vluxei16_tu (vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2_t __riscv_vluxei16_tu (vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4_t __riscv_vluxei16_tu (vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16m8_t __riscv_vluxei16_tu (vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei32_tu (vint16mf4_t maskedoff, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei32_tu (vint16mf2_t maskedoff, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1_t __riscv_vluxei32_tu (vint16m1_t maskedoff, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2_t __riscv_vluxei32_tu (vint16m2_t maskedoff, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4_t __riscv_vluxei32_tu (vint16m4_t maskedoff, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei64_tu (vint16mf4_t maskedoff, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei64_tu (vint16mf2_t maskedoff, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1_t __riscv_vluxei64_tu (vint16m1_t maskedoff, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2_t __riscv_vluxei64_tu (vint16m2_t maskedoff, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei8_tu (vint32mf2_t maskedoff, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1_t __riscv_vluxei8_tu (vint32m1_t maskedoff, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2_t __riscv_vluxei8_tu (vint32m2_t maskedoff, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4_t __riscv_vluxei8_tu (vint32m4_t maskedoff, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32m8_t __riscv_vluxei8_tu (vint32m8_t maskedoff, const int32_t *base, vuint8m2_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei16_tu (vint32mf2_t maskedoff, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1_t __riscv_vluxei16_tu (vint32m1_t maskedoff, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2_t __riscv_vluxei16_tu (vint32m2_t maskedoff, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4_t __riscv_vluxei16_tu (vint32m4_t maskedoff, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32m8_t __riscv_vluxei16_tu (vint32m8_t maskedoff, const int32_t *base, vuint16m4_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei32_tu (vint32mf2_t maskedoff, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1_t __riscv_vluxei32_tu (vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2_t __riscv_vluxei32_tu (vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4_t __riscv_vluxei32_tu (vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32m8_t __riscv_vluxei32_tu (vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei64_tu (vint32mf2_t maskedoff, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1_t __riscv_vluxei64_tu (vint32m1_t maskedoff, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2_t __riscv_vluxei64_tu (vint32m2_t maskedoff, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4_t __riscv_vluxei64_tu (vint32m4_t maskedoff, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1_t __riscv_vluxei8_tu (vint64m1_t maskedoff, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2_t __riscv_vluxei8_tu (vint64m2_t maskedoff, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4_t __riscv_vluxei8_tu (vint64m4_t maskedoff, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m8_t __riscv_vluxei8_tu (vint64m8_t maskedoff, const int64_t *base, vuint8m1_t bindex, size_t vl);
vint64m1_t __riscv_vluxei16_tu (vint64m1_t maskedoff, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2_t __riscv_vluxei16_tu (vint64m2_t maskedoff, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4_t __riscv_vluxei16_tu (vint64m4_t maskedoff, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m8_t __riscv_vluxei16_tu (vint64m8_t maskedoff, const int64_t *base, vuint16m2_t bindex, size_t vl);
vint64m1_t __riscv_vluxei32_tu (vint64m1_t maskedoff, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2_t __riscv_vluxei32_tu (vint64m2_t maskedoff, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4_t __riscv_vluxei32_tu (vint64m4_t maskedoff, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m8_t __riscv_vluxei32_tu (vint64m8_t maskedoff, const int64_t *base, vuint32m4_t bindex, size_t vl);
vint64m1_t __riscv_vluxei64_tu (vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2_t __riscv_vluxei64_tu (vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4_t __riscv_vluxei64_tu (vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint64m8_t __riscv_vluxei64_tu (vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei8_tu (vuint8mf8_t maskedoff, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei8_tu (vuint8mf4_t maskedoff, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei8_tu (vuint8mf2_t maskedoff, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei8_tu (vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei8_tu (vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4_t __riscv_vloxei8_tu (vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8m8_t __riscv_vloxei8_tu (vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei16_tu (vuint8mf8_t maskedoff, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei16_tu (vuint8mf4_t maskedoff, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei16_tu (vuint8mf2_t maskedoff, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei16_tu (vuint8m1_t maskedoff, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei16_tu (vuint8m2_t maskedoff, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4_t __riscv_vloxei16_tu (vuint8m4_t maskedoff, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei32_tu (vuint8mf8_t maskedoff, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei32_tu (vuint8mf4_t maskedoff, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei32_tu (vuint8mf2_t maskedoff, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei32_tu (vuint8m1_t maskedoff, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei32_tu (vuint8m2_t maskedoff, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei64_tu (vuint8mf8_t maskedoff, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei64_tu (vuint8mf4_t maskedoff, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei64_tu (vuint8mf2_t maskedoff, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei64_tu (vuint8m1_t maskedoff, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei8_tu (vuint16mf4_t maskedoff, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei8_tu (vuint16mf2_t maskedoff, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei8_tu (vuint16m1_t maskedoff, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei8_tu (vuint16m2_t maskedoff, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei8_tu (vuint16m4_t maskedoff, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16m8_t __riscv_vloxei8_tu (vuint16m8_t maskedoff, const uint16_t *base, vuint8m4_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei16_tu (vuint16mf4_t maskedoff, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei16_tu (vuint16mf2_t maskedoff, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei16_tu (vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei16_tu (vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei16_tu (vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16m8_t __riscv_vloxei16_tu (vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei32_tu (vuint16mf4_t maskedoff, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei32_tu (vuint16mf2_t maskedoff, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei32_tu (vuint16m1_t maskedoff, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei32_tu (vuint16m2_t maskedoff, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei32_tu (vuint16m4_t maskedoff, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei64_tu (vuint16mf4_t maskedoff, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei64_tu (vuint16mf2_t maskedoff, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei64_tu (vuint16m1_t maskedoff, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei64_tu (vuint16m2_t maskedoff, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei8_tu (vuint32mf2_t maskedoff, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei8_tu (vuint32m1_t maskedoff, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei8_tu (vuint32m2_t maskedoff, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei8_tu (vuint32m4_t maskedoff, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei8_tu (vuint32m8_t maskedoff, const uint32_t *base, vuint8m2_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei16_tu (vuint32mf2_t maskedoff, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei16_tu (vuint32m1_t maskedoff, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei16_tu (vuint32m2_t maskedoff, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei16_tu (vuint32m4_t maskedoff, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei16_tu (vuint32m8_t maskedoff, const uint32_t *base, vuint16m4_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei32_tu (vuint32mf2_t maskedoff, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei32_tu (vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei32_tu (vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei32_tu (vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei32_tu (vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei64_tu (vuint32mf2_t maskedoff, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei64_tu (vuint32m1_t maskedoff, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei64_tu (vuint32m2_t maskedoff, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei64_tu (vuint32m4_t maskedoff, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei8_tu (vuint64m1_t maskedoff, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei8_tu (vuint64m2_t maskedoff, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei8_tu (vuint64m4_t maskedoff, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei8_tu (vuint64m8_t maskedoff, const uint64_t *base, vuint8m1_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei16_tu (vuint64m1_t maskedoff, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei16_tu (vuint64m2_t maskedoff, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei16_tu (vuint64m4_t maskedoff, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei16_tu (vuint64m8_t maskedoff, const uint64_t *base, vuint16m2_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei32_tu (vuint64m1_t maskedoff, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei32_tu (vuint64m2_t maskedoff, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei32_tu (vuint64m4_t maskedoff, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei32_tu (vuint64m8_t maskedoff, const uint64_t *base, vuint32m4_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei64_tu (vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei64_tu (vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei64_tu (vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei64_tu (vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei8_tu (vuint8mf8_t maskedoff, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei8_tu (vuint8mf4_t maskedoff, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei8_tu (vuint8mf2_t maskedoff, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei8_tu (vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei8_tu (vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4_t __riscv_vluxei8_tu (vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8m8_t __riscv_vluxei8_tu (vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei16_tu (vuint8mf8_t maskedoff, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei16_tu (vuint8mf4_t maskedoff, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei16_tu (vuint8mf2_t maskedoff, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei16_tu (vuint8m1_t maskedoff, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei16_tu (vuint8m2_t maskedoff, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4_t __riscv_vluxei16_tu (vuint8m4_t maskedoff, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei32_tu (vuint8mf8_t maskedoff, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei32_tu (vuint8mf4_t maskedoff, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei32_tu (vuint8mf2_t maskedoff, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei32_tu (vuint8m1_t maskedoff, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei32_tu (vuint8m2_t maskedoff, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei64_tu (vuint8mf8_t maskedoff, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei64_tu (vuint8mf4_t maskedoff, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei64_tu (vuint8mf2_t maskedoff, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei64_tu (vuint8m1_t maskedoff, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei8_tu (vuint16mf4_t maskedoff, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei8_tu (vuint16mf2_t maskedoff, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei8_tu (vuint16m1_t maskedoff, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei8_tu (vuint16m2_t maskedoff, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei8_tu (vuint16m4_t maskedoff, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16m8_t __riscv_vluxei8_tu (vuint16m8_t maskedoff, const uint16_t *base, vuint8m4_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei16_tu (vuint16mf4_t maskedoff, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei16_tu (vuint16mf2_t maskedoff, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei16_tu (vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei16_tu (vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei16_tu (vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16m8_t __riscv_vluxei16_tu (vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei32_tu (vuint16mf4_t maskedoff, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei32_tu (vuint16mf2_t maskedoff, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei32_tu (vuint16m1_t maskedoff, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei32_tu (vuint16m2_t maskedoff, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei32_tu (vuint16m4_t maskedoff, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei64_tu (vuint16mf4_t maskedoff, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei64_tu (vuint16mf2_t maskedoff, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei64_tu (vuint16m1_t maskedoff, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei64_tu (vuint16m2_t maskedoff, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei8_tu (vuint32mf2_t maskedoff, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei8_tu (vuint32m1_t maskedoff, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei8_tu (vuint32m2_t maskedoff, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei8_tu (vuint32m4_t maskedoff, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei8_tu (vuint32m8_t maskedoff, const uint32_t *base, vuint8m2_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei16_tu (vuint32mf2_t maskedoff, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei16_tu (vuint32m1_t maskedoff, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei16_tu (vuint32m2_t maskedoff, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei16_tu (vuint32m4_t maskedoff, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei16_tu (vuint32m8_t maskedoff, const uint32_t *base, vuint16m4_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei32_tu (vuint32mf2_t maskedoff, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei32_tu (vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei32_tu (vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei32_tu (vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei32_tu (vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei64_tu (vuint32mf2_t maskedoff, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei64_tu (vuint32m1_t maskedoff, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei64_tu (vuint32m2_t maskedoff, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei64_tu (vuint32m4_t maskedoff, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei8_tu (vuint64m1_t maskedoff, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei8_tu (vuint64m2_t maskedoff, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei8_tu (vuint64m4_t maskedoff, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei8_tu (vuint64m8_t maskedoff, const uint64_t *base, vuint8m1_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei16_tu (vuint64m1_t maskedoff, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei16_tu (vuint64m2_t maskedoff, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei16_tu (vuint64m4_t maskedoff, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei16_tu (vuint64m8_t maskedoff, const uint64_t *base, vuint16m2_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei32_tu (vuint64m1_t maskedoff, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei32_tu (vuint64m2_t maskedoff, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei32_tu (vuint64m4_t maskedoff, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei32_tu (vuint64m8_t maskedoff, const uint64_t *base, vuint32m4_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei64_tu (vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei64_tu (vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei64_tu (vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei64_tu (vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vloxei8_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei8_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei8_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei8_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei8_tum (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16m8_t __riscv_vloxei8_tum (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint8m4_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei16_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei16_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei16_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei16_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei16_tum (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16m8_t __riscv_vloxei16_tum (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei32_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei32_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei32_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei32_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei32_tum (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei64_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei64_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei64_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei64_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei8_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei8_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei8_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei8_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei8_tum (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint8m2_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei16_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei16_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei16_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei16_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei16_tum (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint16m4_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei32_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei32_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei32_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei32_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei32_tum (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei64_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei64_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei64_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei64_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei8_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei8_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei8_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei8_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint8m1_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei16_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei16_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei16_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei16_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint16m2_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei32_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei32_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei32_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei32_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint32m4_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei64_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei64_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei64_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei64_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei8_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei8_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei8_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei8_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei8_tum (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16m8_t __riscv_vluxei8_tum (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint8m4_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei16_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei16_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei16_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei16_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei16_tum (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16m8_t __riscv_vluxei16_tum (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei32_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei32_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei32_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei32_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei32_tum (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei64_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei64_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei64_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei64_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei8_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei8_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei8_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei8_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei8_tum (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint8m2_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei16_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei16_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei16_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei16_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei16_tum (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint16m4_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei32_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei32_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei32_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei32_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei32_tum (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei64_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei64_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei64_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei64_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei8_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei8_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei8_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei8_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint8m1_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei16_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei16_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei16_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei16_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint16m2_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei32_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei32_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei32_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei32_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint32m4_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei64_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei64_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei64_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei64_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei8_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei8_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei8_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1_t __riscv_vloxei8_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2_t __riscv_vloxei8_tum (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4_t __riscv_vloxei8_tum (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8m8_t __riscv_vloxei8_tum (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei16_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei16_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei16_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1_t __riscv_vloxei16_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2_t __riscv_vloxei16_tum (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4_t __riscv_vloxei16_tum (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei32_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei32_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei32_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1_t __riscv_vloxei32_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2_t __riscv_vloxei32_tum (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei64_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei64_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei64_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1_t __riscv_vloxei64_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei8_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei8_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1_t __riscv_vloxei8_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2_t __riscv_vloxei8_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4_t __riscv_vloxei8_tum (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16m8_t __riscv_vloxei8_tum (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint8m4_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei16_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei16_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1_t __riscv_vloxei16_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2_t __riscv_vloxei16_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4_t __riscv_vloxei16_tum (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16m8_t __riscv_vloxei16_tum (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei32_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei32_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1_t __riscv_vloxei32_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2_t __riscv_vloxei32_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4_t __riscv_vloxei32_tum (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei64_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei64_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1_t __riscv_vloxei64_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2_t __riscv_vloxei64_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei8_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1_t __riscv_vloxei8_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2_t __riscv_vloxei8_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4_t __riscv_vloxei8_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32m8_t __riscv_vloxei8_tum (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint8m2_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei16_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1_t __riscv_vloxei16_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2_t __riscv_vloxei16_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4_t __riscv_vloxei16_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32m8_t __riscv_vloxei16_tum (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint16m4_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei32_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1_t __riscv_vloxei32_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2_t __riscv_vloxei32_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4_t __riscv_vloxei32_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32m8_t __riscv_vloxei32_tum (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei64_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1_t __riscv_vloxei64_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2_t __riscv_vloxei64_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4_t __riscv_vloxei64_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1_t __riscv_vloxei8_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2_t __riscv_vloxei8_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4_t __riscv_vloxei8_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m8_t __riscv_vloxei8_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint8m1_t bindex, size_t vl);
vint64m1_t __riscv_vloxei16_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2_t __riscv_vloxei16_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4_t __riscv_vloxei16_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m8_t __riscv_vloxei16_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint16m2_t bindex, size_t vl);
vint64m1_t __riscv_vloxei32_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2_t __riscv_vloxei32_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4_t __riscv_vloxei32_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m8_t __riscv_vloxei32_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint32m4_t bindex, size_t vl);
vint64m1_t __riscv_vloxei64_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2_t __riscv_vloxei64_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4_t __riscv_vloxei64_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint64m8_t __riscv_vloxei64_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei8_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei8_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei8_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1_t __riscv_vluxei8_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2_t __riscv_vluxei8_tum (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4_t __riscv_vluxei8_tum (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8m8_t __riscv_vluxei8_tum (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei16_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei16_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei16_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1_t __riscv_vluxei16_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2_t __riscv_vluxei16_tum (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4_t __riscv_vluxei16_tum (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei32_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei32_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei32_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1_t __riscv_vluxei32_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2_t __riscv_vluxei32_tum (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei64_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei64_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei64_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1_t __riscv_vluxei64_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei8_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei8_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1_t __riscv_vluxei8_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2_t __riscv_vluxei8_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4_t __riscv_vluxei8_tum (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16m8_t __riscv_vluxei8_tum (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint8m4_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei16_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei16_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1_t __riscv_vluxei16_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2_t __riscv_vluxei16_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4_t __riscv_vluxei16_tum (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16m8_t __riscv_vluxei16_tum (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei32_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei32_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1_t __riscv_vluxei32_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2_t __riscv_vluxei32_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4_t __riscv_vluxei32_tum (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei64_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei64_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1_t __riscv_vluxei64_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2_t __riscv_vluxei64_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei8_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1_t __riscv_vluxei8_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2_t __riscv_vluxei8_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4_t __riscv_vluxei8_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32m8_t __riscv_vluxei8_tum (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint8m2_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei16_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1_t __riscv_vluxei16_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2_t __riscv_vluxei16_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4_t __riscv_vluxei16_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32m8_t __riscv_vluxei16_tum (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint16m4_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei32_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1_t __riscv_vluxei32_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2_t __riscv_vluxei32_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4_t __riscv_vluxei32_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32m8_t __riscv_vluxei32_tum (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei64_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1_t __riscv_vluxei64_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2_t __riscv_vluxei64_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4_t __riscv_vluxei64_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1_t __riscv_vluxei8_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2_t __riscv_vluxei8_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4_t __riscv_vluxei8_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m8_t __riscv_vluxei8_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint8m1_t bindex, size_t vl);
vint64m1_t __riscv_vluxei16_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2_t __riscv_vluxei16_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4_t __riscv_vluxei16_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m8_t __riscv_vluxei16_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint16m2_t bindex, size_t vl);
vint64m1_t __riscv_vluxei32_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2_t __riscv_vluxei32_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4_t __riscv_vluxei32_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m8_t __riscv_vluxei32_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint32m4_t bindex, size_t vl);
vint64m1_t __riscv_vluxei64_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2_t __riscv_vluxei64_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4_t __riscv_vluxei64_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint64m8_t __riscv_vluxei64_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei8_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei8_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei8_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei8_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei8_tum (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4_t __riscv_vloxei8_tum (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8m8_t __riscv_vloxei8_tum (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei16_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei16_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei16_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei16_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei16_tum (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4_t __riscv_vloxei16_tum (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei32_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei32_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei32_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei32_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei32_tum (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei64_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei64_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei64_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei64_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei8_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei8_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei8_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei8_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei8_tum (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16m8_t __riscv_vloxei8_tum (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint8m4_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei16_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei16_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei16_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei16_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei16_tum (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16m8_t __riscv_vloxei16_tum (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei32_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei32_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei32_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei32_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei32_tum (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei64_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei64_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei64_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei64_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei8_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei8_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei8_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei8_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei8_tum (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint8m2_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei16_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei16_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei16_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei16_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei16_tum (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint16m4_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei32_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei32_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei32_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei32_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei32_tum (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei64_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei64_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei64_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei64_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei8_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei8_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei8_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei8_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint8m1_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei16_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei16_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei16_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei16_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint16m2_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei32_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei32_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei32_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei32_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint32m4_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei64_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei64_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei64_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei64_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei8_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei8_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei8_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei8_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei8_tum (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4_t __riscv_vluxei8_tum (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8m8_t __riscv_vluxei8_tum (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei16_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei16_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei16_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei16_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei16_tum (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4_t __riscv_vluxei16_tum (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei32_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei32_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei32_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei32_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei32_tum (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei64_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei64_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei64_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei64_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei8_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei8_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei8_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei8_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei8_tum (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16m8_t __riscv_vluxei8_tum (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint8m4_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei16_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei16_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei16_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei16_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei16_tum (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16m8_t __riscv_vluxei16_tum (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei32_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei32_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei32_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei32_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei32_tum (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei64_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei64_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei64_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei64_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei8_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei8_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei8_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei8_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei8_tum (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint8m2_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei16_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei16_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei16_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei16_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei16_tum (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint16m4_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei32_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei32_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei32_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei32_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei32_tum (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei64_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei64_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei64_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei64_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei8_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei8_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei8_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei8_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint8m1_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei16_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei16_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei16_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei16_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint16m2_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei32_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei32_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei32_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei32_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint32m4_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei64_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei64_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei64_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei64_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vloxei8_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei8_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei8_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei8_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei8_tumu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16m8_t __riscv_vloxei8_tumu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint8m4_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei16_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei16_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei16_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei16_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei16_tumu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16m8_t __riscv_vloxei16_tumu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei32_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei32_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei32_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei32_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei32_tumu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei64_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei64_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei64_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei64_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei8_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei8_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei8_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei8_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei8_tumu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint8m2_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei16_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei16_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei16_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei16_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei16_tumu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint16m4_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei32_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei32_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei32_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei32_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei32_tumu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei64_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei64_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei64_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei64_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei8_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei8_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei8_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei8_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint8m1_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei16_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei16_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei16_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei16_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint16m2_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei32_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei32_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei32_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei32_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint32m4_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei64_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei64_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei64_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei64_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei8_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei8_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei8_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei8_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei8_tumu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16m8_t __riscv_vluxei8_tumu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint8m4_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei16_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei16_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei16_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei16_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei16_tumu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16m8_t __riscv_vluxei16_tumu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei32_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei32_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei32_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei32_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei32_tumu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei64_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei64_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei64_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei64_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei8_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei8_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei8_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei8_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei8_tumu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint8m2_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei16_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei16_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei16_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei16_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei16_tumu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint16m4_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei32_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei32_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei32_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei32_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei32_tumu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei64_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei64_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei64_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei64_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei8_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei8_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei8_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei8_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint8m1_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei16_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei16_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei16_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei16_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint16m2_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei32_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei32_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei32_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei32_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint32m4_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei64_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei64_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei64_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei64_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei8_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei8_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei8_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1_t __riscv_vloxei8_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2_t __riscv_vloxei8_tumu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4_t __riscv_vloxei8_tumu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8m8_t __riscv_vloxei8_tumu (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei16_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei16_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei16_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1_t __riscv_vloxei16_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2_t __riscv_vloxei16_tumu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4_t __riscv_vloxei16_tumu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei32_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei32_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei32_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1_t __riscv_vloxei32_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2_t __riscv_vloxei32_tumu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei64_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei64_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei64_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1_t __riscv_vloxei64_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei8_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei8_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1_t __riscv_vloxei8_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2_t __riscv_vloxei8_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4_t __riscv_vloxei8_tumu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16m8_t __riscv_vloxei8_tumu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint8m4_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei16_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei16_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1_t __riscv_vloxei16_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2_t __riscv_vloxei16_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4_t __riscv_vloxei16_tumu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16m8_t __riscv_vloxei16_tumu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei32_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei32_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1_t __riscv_vloxei32_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2_t __riscv_vloxei32_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4_t __riscv_vloxei32_tumu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei64_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei64_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1_t __riscv_vloxei64_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2_t __riscv_vloxei64_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei8_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1_t __riscv_vloxei8_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2_t __riscv_vloxei8_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4_t __riscv_vloxei8_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32m8_t __riscv_vloxei8_tumu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint8m2_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei16_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1_t __riscv_vloxei16_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2_t __riscv_vloxei16_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4_t __riscv_vloxei16_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32m8_t __riscv_vloxei16_tumu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint16m4_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei32_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1_t __riscv_vloxei32_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2_t __riscv_vloxei32_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4_t __riscv_vloxei32_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32m8_t __riscv_vloxei32_tumu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei64_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1_t __riscv_vloxei64_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2_t __riscv_vloxei64_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4_t __riscv_vloxei64_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1_t __riscv_vloxei8_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2_t __riscv_vloxei8_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4_t __riscv_vloxei8_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m8_t __riscv_vloxei8_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint8m1_t bindex, size_t vl);
vint64m1_t __riscv_vloxei16_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2_t __riscv_vloxei16_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4_t __riscv_vloxei16_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m8_t __riscv_vloxei16_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint16m2_t bindex, size_t vl);
vint64m1_t __riscv_vloxei32_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2_t __riscv_vloxei32_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4_t __riscv_vloxei32_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m8_t __riscv_vloxei32_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint32m4_t bindex, size_t vl);
vint64m1_t __riscv_vloxei64_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2_t __riscv_vloxei64_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4_t __riscv_vloxei64_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint64m8_t __riscv_vloxei64_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei8_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei8_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei8_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1_t __riscv_vluxei8_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2_t __riscv_vluxei8_tumu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4_t __riscv_vluxei8_tumu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8m8_t __riscv_vluxei8_tumu (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei16_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei16_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei16_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1_t __riscv_vluxei16_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2_t __riscv_vluxei16_tumu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4_t __riscv_vluxei16_tumu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei32_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei32_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei32_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1_t __riscv_vluxei32_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2_t __riscv_vluxei32_tumu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei64_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei64_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei64_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1_t __riscv_vluxei64_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei8_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei8_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1_t __riscv_vluxei8_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2_t __riscv_vluxei8_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4_t __riscv_vluxei8_tumu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16m8_t __riscv_vluxei8_tumu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint8m4_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei16_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei16_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1_t __riscv_vluxei16_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2_t __riscv_vluxei16_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4_t __riscv_vluxei16_tumu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16m8_t __riscv_vluxei16_tumu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei32_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei32_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1_t __riscv_vluxei32_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2_t __riscv_vluxei32_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4_t __riscv_vluxei32_tumu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei64_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei64_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1_t __riscv_vluxei64_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2_t __riscv_vluxei64_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei8_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1_t __riscv_vluxei8_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2_t __riscv_vluxei8_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4_t __riscv_vluxei8_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32m8_t __riscv_vluxei8_tumu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint8m2_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei16_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1_t __riscv_vluxei16_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2_t __riscv_vluxei16_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4_t __riscv_vluxei16_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32m8_t __riscv_vluxei16_tumu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint16m4_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei32_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1_t __riscv_vluxei32_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2_t __riscv_vluxei32_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4_t __riscv_vluxei32_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32m8_t __riscv_vluxei32_tumu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei64_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1_t __riscv_vluxei64_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2_t __riscv_vluxei64_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4_t __riscv_vluxei64_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1_t __riscv_vluxei8_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2_t __riscv_vluxei8_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4_t __riscv_vluxei8_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m8_t __riscv_vluxei8_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint8m1_t bindex, size_t vl);
vint64m1_t __riscv_vluxei16_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2_t __riscv_vluxei16_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4_t __riscv_vluxei16_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m8_t __riscv_vluxei16_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint16m2_t bindex, size_t vl);
vint64m1_t __riscv_vluxei32_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2_t __riscv_vluxei32_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4_t __riscv_vluxei32_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m8_t __riscv_vluxei32_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint32m4_t bindex, size_t vl);
vint64m1_t __riscv_vluxei64_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2_t __riscv_vluxei64_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4_t __riscv_vluxei64_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint64m8_t __riscv_vluxei64_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei8_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei8_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei8_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei8_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei8_tumu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4_t __riscv_vloxei8_tumu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8m8_t __riscv_vloxei8_tumu (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei16_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei16_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei16_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei16_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei16_tumu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4_t __riscv_vloxei16_tumu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei32_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei32_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei32_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei32_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei32_tumu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei64_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei64_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei64_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei64_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei8_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei8_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei8_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei8_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei8_tumu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16m8_t __riscv_vloxei8_tumu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint8m4_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei16_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei16_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei16_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei16_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei16_tumu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16m8_t __riscv_vloxei16_tumu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei32_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei32_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei32_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei32_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei32_tumu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei64_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei64_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei64_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei64_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei8_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei8_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei8_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei8_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei8_tumu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint8m2_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei16_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei16_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei16_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei16_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei16_tumu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint16m4_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei32_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei32_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei32_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei32_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei32_tumu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei64_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei64_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei64_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei64_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei8_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei8_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei8_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei8_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint8m1_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei16_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei16_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei16_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei16_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint16m2_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei32_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei32_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei32_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei32_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint32m4_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei64_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei64_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei64_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei64_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei8_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei8_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei8_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei8_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei8_tumu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4_t __riscv_vluxei8_tumu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8m8_t __riscv_vluxei8_tumu (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei16_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei16_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei16_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei16_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei16_tumu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4_t __riscv_vluxei16_tumu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei32_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei32_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei32_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei32_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei32_tumu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei64_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei64_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei64_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei64_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei8_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei8_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei8_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei8_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei8_tumu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16m8_t __riscv_vluxei8_tumu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint8m4_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei16_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei16_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei16_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei16_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei16_tumu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16m8_t __riscv_vluxei16_tumu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei32_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei32_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei32_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei32_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei32_tumu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei64_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei64_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei64_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei64_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei8_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei8_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei8_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei8_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei8_tumu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint8m2_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei16_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei16_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei16_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei16_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei16_tumu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint16m4_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei32_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei32_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei32_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei32_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei32_tumu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei64_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei64_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei64_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei64_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei8_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei8_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei8_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei8_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint8m1_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei16_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei16_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei16_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei16_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint16m2_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei32_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei32_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei32_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei32_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint32m4_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei64_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei64_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei64_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei64_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vloxei8_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei8_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei8_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei8_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei8_mu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16m8_t __riscv_vloxei8_mu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint8m4_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei16_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei16_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei16_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei16_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei16_mu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16m8_t __riscv_vloxei16_mu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei32_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei32_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei32_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei32_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4_t __riscv_vloxei32_mu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vloxei64_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2_t __riscv_vloxei64_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1_t __riscv_vloxei64_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2_t __riscv_vloxei64_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei8_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei8_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei8_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei8_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei8_mu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint8m2_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei16_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei16_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei16_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei16_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei16_mu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint16m4_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei32_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei32_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei32_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei32_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32m8_t __riscv_vloxei32_mu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vloxei64_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1_t __riscv_vloxei64_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2_t __riscv_vloxei64_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4_t __riscv_vloxei64_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei8_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei8_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei8_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei8_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint8m1_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei16_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei16_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei16_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei16_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint16m2_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei32_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei32_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei32_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei32_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint32m4_t bindex, size_t vl);
vfloat64m1_t __riscv_vloxei64_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2_t __riscv_vloxei64_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4_t __riscv_vloxei64_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat64m8_t __riscv_vloxei64_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei8_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei8_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei8_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei8_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei8_mu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16m8_t __riscv_vluxei8_mu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint8m4_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei16_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei16_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei16_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei16_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei16_mu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16m8_t __riscv_vluxei16_mu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei32_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei32_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei32_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei32_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4_t __riscv_vluxei32_mu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4_t __riscv_vluxei64_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2_t __riscv_vluxei64_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1_t __riscv_vluxei64_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2_t __riscv_vluxei64_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei8_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei8_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei8_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei8_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei8_mu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint8m2_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei16_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei16_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei16_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei16_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei16_mu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint16m4_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei32_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei32_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei32_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei32_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32m8_t __riscv_vluxei32_mu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex, size_t vl);
vfloat32mf2_t __riscv_vluxei64_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1_t __riscv_vluxei64_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2_t __riscv_vluxei64_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4_t __riscv_vluxei64_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei8_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei8_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei8_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei8_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint8m1_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei16_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei16_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei16_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei16_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint16m2_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei32_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei32_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei32_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei32_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint32m4_t bindex, size_t vl);
vfloat64m1_t __riscv_vluxei64_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2_t __riscv_vluxei64_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4_t __riscv_vluxei64_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat64m8_t __riscv_vluxei64_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei8_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei8_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei8_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1_t __riscv_vloxei8_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2_t __riscv_vloxei8_mu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4_t __riscv_vloxei8_mu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8m8_t __riscv_vloxei8_mu (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei16_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei16_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei16_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1_t __riscv_vloxei16_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2_t __riscv_vloxei16_mu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4_t __riscv_vloxei16_mu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei32_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei32_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei32_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1_t __riscv_vloxei32_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2_t __riscv_vloxei32_mu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8_t __riscv_vloxei64_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4_t __riscv_vloxei64_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2_t __riscv_vloxei64_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1_t __riscv_vloxei64_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei8_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei8_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1_t __riscv_vloxei8_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2_t __riscv_vloxei8_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4_t __riscv_vloxei8_mu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16m8_t __riscv_vloxei8_mu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint8m4_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei16_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei16_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1_t __riscv_vloxei16_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2_t __riscv_vloxei16_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4_t __riscv_vloxei16_mu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16m8_t __riscv_vloxei16_mu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei32_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei32_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1_t __riscv_vloxei32_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2_t __riscv_vloxei32_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4_t __riscv_vloxei32_mu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4_t __riscv_vloxei64_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2_t __riscv_vloxei64_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1_t __riscv_vloxei64_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2_t __riscv_vloxei64_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei8_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1_t __riscv_vloxei8_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2_t __riscv_vloxei8_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4_t __riscv_vloxei8_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32m8_t __riscv_vloxei8_mu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint8m2_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei16_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1_t __riscv_vloxei16_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2_t __riscv_vloxei16_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4_t __riscv_vloxei16_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32m8_t __riscv_vloxei16_mu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint16m4_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei32_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1_t __riscv_vloxei32_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2_t __riscv_vloxei32_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4_t __riscv_vloxei32_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32m8_t __riscv_vloxei32_mu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex, size_t vl);
vint32mf2_t __riscv_vloxei64_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1_t __riscv_vloxei64_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2_t __riscv_vloxei64_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4_t __riscv_vloxei64_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1_t __riscv_vloxei8_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2_t __riscv_vloxei8_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4_t __riscv_vloxei8_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m8_t __riscv_vloxei8_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint8m1_t bindex, size_t vl);
vint64m1_t __riscv_vloxei16_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2_t __riscv_vloxei16_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4_t __riscv_vloxei16_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m8_t __riscv_vloxei16_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint16m2_t bindex, size_t vl);
vint64m1_t __riscv_vloxei32_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2_t __riscv_vloxei32_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4_t __riscv_vloxei32_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m8_t __riscv_vloxei32_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint32m4_t bindex, size_t vl);
vint64m1_t __riscv_vloxei64_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2_t __riscv_vloxei64_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4_t __riscv_vloxei64_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint64m8_t __riscv_vloxei64_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei8_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei8_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei8_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1_t __riscv_vluxei8_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2_t __riscv_vluxei8_mu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4_t __riscv_vluxei8_mu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8m8_t __riscv_vluxei8_mu (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei16_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei16_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei16_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1_t __riscv_vluxei16_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2_t __riscv_vluxei16_mu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4_t __riscv_vluxei16_mu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei32_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei32_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei32_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1_t __riscv_vluxei32_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2_t __riscv_vluxei32_mu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8_t __riscv_vluxei64_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4_t __riscv_vluxei64_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2_t __riscv_vluxei64_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1_t __riscv_vluxei64_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei8_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei8_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1_t __riscv_vluxei8_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2_t __riscv_vluxei8_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4_t __riscv_vluxei8_mu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16m8_t __riscv_vluxei8_mu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint8m4_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei16_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei16_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1_t __riscv_vluxei16_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2_t __riscv_vluxei16_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4_t __riscv_vluxei16_mu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16m8_t __riscv_vluxei16_mu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei32_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei32_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1_t __riscv_vluxei32_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2_t __riscv_vluxei32_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4_t __riscv_vluxei32_mu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4_t __riscv_vluxei64_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2_t __riscv_vluxei64_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1_t __riscv_vluxei64_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2_t __riscv_vluxei64_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei8_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1_t __riscv_vluxei8_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2_t __riscv_vluxei8_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4_t __riscv_vluxei8_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32m8_t __riscv_vluxei8_mu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint8m2_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei16_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1_t __riscv_vluxei16_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2_t __riscv_vluxei16_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4_t __riscv_vluxei16_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32m8_t __riscv_vluxei16_mu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint16m4_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei32_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1_t __riscv_vluxei32_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2_t __riscv_vluxei32_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4_t __riscv_vluxei32_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32m8_t __riscv_vluxei32_mu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex, size_t vl);
vint32mf2_t __riscv_vluxei64_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1_t __riscv_vluxei64_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2_t __riscv_vluxei64_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4_t __riscv_vluxei64_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1_t __riscv_vluxei8_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2_t __riscv_vluxei8_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4_t __riscv_vluxei8_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m8_t __riscv_vluxei8_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint8m1_t bindex, size_t vl);
vint64m1_t __riscv_vluxei16_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2_t __riscv_vluxei16_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4_t __riscv_vluxei16_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m8_t __riscv_vluxei16_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint16m2_t bindex, size_t vl);
vint64m1_t __riscv_vluxei32_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2_t __riscv_vluxei32_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4_t __riscv_vluxei32_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m8_t __riscv_vluxei32_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint32m4_t bindex, size_t vl);
vint64m1_t __riscv_vluxei64_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2_t __riscv_vluxei64_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4_t __riscv_vluxei64_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint64m8_t __riscv_vluxei64_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei8_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei8_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei8_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei8_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei8_mu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4_t __riscv_vloxei8_mu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8m8_t __riscv_vloxei8_mu (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei16_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei16_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei16_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei16_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei16_mu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4_t __riscv_vloxei16_mu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei32_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei32_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei32_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei32_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2_t __riscv_vloxei32_mu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vloxei64_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4_t __riscv_vloxei64_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2_t __riscv_vloxei64_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1_t __riscv_vloxei64_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei8_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei8_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei8_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei8_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei8_mu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16m8_t __riscv_vloxei8_mu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint8m4_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei16_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei16_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei16_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei16_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei16_mu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16m8_t __riscv_vloxei16_mu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei32_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei32_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei32_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei32_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4_t __riscv_vloxei32_mu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vloxei64_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2_t __riscv_vloxei64_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1_t __riscv_vloxei64_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2_t __riscv_vloxei64_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei8_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei8_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei8_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei8_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei8_mu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint8m2_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei16_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei16_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei16_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei16_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei16_mu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint16m4_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei32_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei32_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei32_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei32_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32m8_t __riscv_vloxei32_mu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vloxei64_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1_t __riscv_vloxei64_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2_t __riscv_vloxei64_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4_t __riscv_vloxei64_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei8_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei8_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei8_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei8_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint8m1_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei16_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei16_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei16_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei16_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint16m2_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei32_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei32_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei32_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei32_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint32m4_t bindex, size_t vl);
vuint64m1_t __riscv_vloxei64_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2_t __riscv_vloxei64_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4_t __riscv_vloxei64_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint64m8_t __riscv_vloxei64_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei8_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei8_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei8_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei8_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei8_mu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4_t __riscv_vluxei8_mu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8m8_t __riscv_vluxei8_mu (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei16_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei16_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei16_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei16_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei16_mu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4_t __riscv_vluxei16_mu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei32_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei32_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei32_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei32_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2_t __riscv_vluxei32_mu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8_t __riscv_vluxei64_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4_t __riscv_vluxei64_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2_t __riscv_vluxei64_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1_t __riscv_vluxei64_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei8_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei8_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei8_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei8_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei8_mu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16m8_t __riscv_vluxei8_mu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint8m4_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei16_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei16_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei16_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei16_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei16_mu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16m8_t __riscv_vluxei16_mu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei32_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei32_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei32_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei32_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4_t __riscv_vluxei32_mu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4_t __riscv_vluxei64_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2_t __riscv_vluxei64_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1_t __riscv_vluxei64_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2_t __riscv_vluxei64_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei8_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei8_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei8_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei8_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei8_mu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint8m2_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei16_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei16_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei16_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei16_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei16_mu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint16m4_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei32_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei32_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei32_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei32_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32m8_t __riscv_vluxei32_mu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex, size_t vl);
vuint32mf2_t __riscv_vluxei64_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1_t __riscv_vluxei64_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2_t __riscv_vluxei64_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4_t __riscv_vluxei64_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei8_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei8_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei8_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei8_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint8m1_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei16_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei16_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei16_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei16_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint16m2_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei32_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei32_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei32_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei32_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint32m4_t bindex, size_t vl);
vuint64m1_t __riscv_vluxei64_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2_t __riscv_vluxei64_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4_t __riscv_vluxei64_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint64m8_t __riscv_vluxei64_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex, size_t vl);
```

[[policy-variant-overloadedvector-indexed-store]]
=== Vector Indexed Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedunit-stride-fault-only-first-loads]]
=== Unit-stride Fault-Only-First Loads Intrinsics

``` C
vfloat16mf4_t __riscv_vle16ff_tu (vfloat16mf4_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2_t __riscv_vle16ff_tu (vfloat16mf2_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1_t __riscv_vle16ff_tu (vfloat16m1_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2_t __riscv_vle16ff_tu (vfloat16m2_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4_t __riscv_vle16ff_tu (vfloat16m4_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m8_t __riscv_vle16ff_tu (vfloat16m8_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2_t __riscv_vle32ff_tu (vfloat32mf2_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1_t __riscv_vle32ff_tu (vfloat32m1_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2_t __riscv_vle32ff_tu (vfloat32m2_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4_t __riscv_vle32ff_tu (vfloat32m4_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m8_t __riscv_vle32ff_tu (vfloat32m8_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1_t __riscv_vle64ff_tu (vfloat64m1_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2_t __riscv_vle64ff_tu (vfloat64m2_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4_t __riscv_vle64ff_tu (vfloat64m4_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m8_t __riscv_vle64ff_tu (vfloat64m8_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8_t __riscv_vle8ff_tu (vint8mf8_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4_t __riscv_vle8ff_tu (vint8mf4_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2_t __riscv_vle8ff_tu (vint8mf2_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1_t __riscv_vle8ff_tu (vint8m1_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2_t __riscv_vle8ff_tu (vint8m2_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4_t __riscv_vle8ff_tu (vint8m4_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m8_t __riscv_vle8ff_tu (vint8m8_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4_t __riscv_vle16ff_tu (vint16mf4_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2_t __riscv_vle16ff_tu (vint16mf2_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1_t __riscv_vle16ff_tu (vint16m1_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2_t __riscv_vle16ff_tu (vint16m2_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4_t __riscv_vle16ff_tu (vint16m4_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m8_t __riscv_vle16ff_tu (vint16m8_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2_t __riscv_vle32ff_tu (vint32mf2_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1_t __riscv_vle32ff_tu (vint32m1_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2_t __riscv_vle32ff_tu (vint32m2_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4_t __riscv_vle32ff_tu (vint32m4_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m8_t __riscv_vle32ff_tu (vint32m8_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1_t __riscv_vle64ff_tu (vint64m1_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2_t __riscv_vle64ff_tu (vint64m2_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4_t __riscv_vle64ff_tu (vint64m4_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m8_t __riscv_vle64ff_tu (vint64m8_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8_t __riscv_vle8ff_tu (vuint8mf8_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4_t __riscv_vle8ff_tu (vuint8mf4_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2_t __riscv_vle8ff_tu (vuint8mf2_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1_t __riscv_vle8ff_tu (vuint8m1_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2_t __riscv_vle8ff_tu (vuint8m2_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4_t __riscv_vle8ff_tu (vuint8m4_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m8_t __riscv_vle8ff_tu (vuint8m8_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4_t __riscv_vle16ff_tu (vuint16mf4_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2_t __riscv_vle16ff_tu (vuint16mf2_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1_t __riscv_vle16ff_tu (vuint16m1_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2_t __riscv_vle16ff_tu (vuint16m2_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4_t __riscv_vle16ff_tu (vuint16m4_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m8_t __riscv_vle16ff_tu (vuint16m8_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2_t __riscv_vle32ff_tu (vuint32mf2_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1_t __riscv_vle32ff_tu (vuint32m1_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2_t __riscv_vle32ff_tu (vuint32m2_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4_t __riscv_vle32ff_tu (vuint32m4_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m8_t __riscv_vle32ff_tu (vuint32m8_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1_t __riscv_vle64ff_tu (vuint64m1_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2_t __riscv_vle64ff_tu (vuint64m2_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4_t __riscv_vle64ff_tu (vuint64m4_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m8_t __riscv_vle64ff_tu (vuint64m8_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16ff_tum (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2_t __riscv_vle16ff_tum (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1_t __riscv_vle16ff_tum (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2_t __riscv_vle16ff_tum (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4_t __riscv_vle16ff_tum (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m8_t __riscv_vle16ff_tum (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2_t __riscv_vle32ff_tum (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1_t __riscv_vle32ff_tum (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2_t __riscv_vle32ff_tum (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4_t __riscv_vle32ff_tum (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m8_t __riscv_vle32ff_tum (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1_t __riscv_vle64ff_tum (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2_t __riscv_vle64ff_tum (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4_t __riscv_vle64ff_tum (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m8_t __riscv_vle64ff_tum (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8_t __riscv_vle8ff_tum (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4_t __riscv_vle8ff_tum (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2_t __riscv_vle8ff_tum (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1_t __riscv_vle8ff_tum (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2_t __riscv_vle8ff_tum (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4_t __riscv_vle8ff_tum (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m8_t __riscv_vle8ff_tum (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4_t __riscv_vle16ff_tum (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2_t __riscv_vle16ff_tum (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1_t __riscv_vle16ff_tum (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2_t __riscv_vle16ff_tum (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4_t __riscv_vle16ff_tum (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m8_t __riscv_vle16ff_tum (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2_t __riscv_vle32ff_tum (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1_t __riscv_vle32ff_tum (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2_t __riscv_vle32ff_tum (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4_t __riscv_vle32ff_tum (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m8_t __riscv_vle32ff_tum (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1_t __riscv_vle64ff_tum (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2_t __riscv_vle64ff_tum (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4_t __riscv_vle64ff_tum (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m8_t __riscv_vle64ff_tum (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8_t __riscv_vle8ff_tum (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4_t __riscv_vle8ff_tum (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2_t __riscv_vle8ff_tum (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1_t __riscv_vle8ff_tum (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2_t __riscv_vle8ff_tum (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4_t __riscv_vle8ff_tum (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m8_t __riscv_vle8ff_tum (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4_t __riscv_vle16ff_tum (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2_t __riscv_vle16ff_tum (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1_t __riscv_vle16ff_tum (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2_t __riscv_vle16ff_tum (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4_t __riscv_vle16ff_tum (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m8_t __riscv_vle16ff_tum (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2_t __riscv_vle32ff_tum (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1_t __riscv_vle32ff_tum (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2_t __riscv_vle32ff_tum (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4_t __riscv_vle32ff_tum (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m8_t __riscv_vle32ff_tum (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1_t __riscv_vle64ff_tum (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2_t __riscv_vle64ff_tum (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4_t __riscv_vle64ff_tum (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m8_t __riscv_vle64ff_tum (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16ff_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2_t __riscv_vle16ff_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1_t __riscv_vle16ff_tumu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2_t __riscv_vle16ff_tumu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4_t __riscv_vle16ff_tumu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m8_t __riscv_vle16ff_tumu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2_t __riscv_vle32ff_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1_t __riscv_vle32ff_tumu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2_t __riscv_vle32ff_tumu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4_t __riscv_vle32ff_tumu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m8_t __riscv_vle32ff_tumu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1_t __riscv_vle64ff_tumu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2_t __riscv_vle64ff_tumu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4_t __riscv_vle64ff_tumu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m8_t __riscv_vle64ff_tumu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8_t __riscv_vle8ff_tumu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4_t __riscv_vle8ff_tumu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2_t __riscv_vle8ff_tumu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1_t __riscv_vle8ff_tumu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2_t __riscv_vle8ff_tumu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4_t __riscv_vle8ff_tumu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m8_t __riscv_vle8ff_tumu (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4_t __riscv_vle16ff_tumu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2_t __riscv_vle16ff_tumu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1_t __riscv_vle16ff_tumu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2_t __riscv_vle16ff_tumu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4_t __riscv_vle16ff_tumu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m8_t __riscv_vle16ff_tumu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2_t __riscv_vle32ff_tumu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1_t __riscv_vle32ff_tumu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2_t __riscv_vle32ff_tumu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4_t __riscv_vle32ff_tumu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m8_t __riscv_vle32ff_tumu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1_t __riscv_vle64ff_tumu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2_t __riscv_vle64ff_tumu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4_t __riscv_vle64ff_tumu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m8_t __riscv_vle64ff_tumu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8_t __riscv_vle8ff_tumu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4_t __riscv_vle8ff_tumu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2_t __riscv_vle8ff_tumu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1_t __riscv_vle8ff_tumu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2_t __riscv_vle8ff_tumu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4_t __riscv_vle8ff_tumu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m8_t __riscv_vle8ff_tumu (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4_t __riscv_vle16ff_tumu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2_t __riscv_vle16ff_tumu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1_t __riscv_vle16ff_tumu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2_t __riscv_vle16ff_tumu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4_t __riscv_vle16ff_tumu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m8_t __riscv_vle16ff_tumu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2_t __riscv_vle32ff_tumu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1_t __riscv_vle32ff_tumu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2_t __riscv_vle32ff_tumu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4_t __riscv_vle32ff_tumu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m8_t __riscv_vle32ff_tumu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1_t __riscv_vle64ff_tumu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2_t __riscv_vle64ff_tumu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4_t __riscv_vle64ff_tumu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m8_t __riscv_vle64ff_tumu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16ff_mu (vbool64_t mask, vfloat16mf4_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2_t __riscv_vle16ff_mu (vbool32_t mask, vfloat16mf2_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1_t __riscv_vle16ff_mu (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2_t __riscv_vle16ff_mu (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4_t __riscv_vle16ff_mu (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m8_t __riscv_vle16ff_mu (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2_t __riscv_vle32ff_mu (vbool64_t mask, vfloat32mf2_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1_t __riscv_vle32ff_mu (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2_t __riscv_vle32ff_mu (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4_t __riscv_vle32ff_mu (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m8_t __riscv_vle32ff_mu (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1_t __riscv_vle64ff_mu (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2_t __riscv_vle64ff_mu (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4_t __riscv_vle64ff_mu (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m8_t __riscv_vle64ff_mu (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8_t __riscv_vle8ff_mu (vbool64_t mask, vint8mf8_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4_t __riscv_vle8ff_mu (vbool32_t mask, vint8mf4_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2_t __riscv_vle8ff_mu (vbool16_t mask, vint8mf2_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1_t __riscv_vle8ff_mu (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2_t __riscv_vle8ff_mu (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4_t __riscv_vle8ff_mu (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint8m8_t __riscv_vle8ff_mu (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4_t __riscv_vle16ff_mu (vbool64_t mask, vint16mf4_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2_t __riscv_vle16ff_mu (vbool32_t mask, vint16mf2_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1_t __riscv_vle16ff_mu (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2_t __riscv_vle16ff_mu (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4_t __riscv_vle16ff_mu (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint16m8_t __riscv_vle16ff_mu (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2_t __riscv_vle32ff_mu (vbool64_t mask, vint32mf2_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1_t __riscv_vle32ff_mu (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2_t __riscv_vle32ff_mu (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4_t __riscv_vle32ff_mu (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint32m8_t __riscv_vle32ff_mu (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1_t __riscv_vle64ff_mu (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2_t __riscv_vle64ff_mu (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4_t __riscv_vle64ff_mu (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vint64m8_t __riscv_vle64ff_mu (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8_t __riscv_vle8ff_mu (vbool64_t mask, vuint8mf8_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4_t __riscv_vle8ff_mu (vbool32_t mask, vuint8mf4_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2_t __riscv_vle8ff_mu (vbool16_t mask, vuint8mf2_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1_t __riscv_vle8ff_mu (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2_t __riscv_vle8ff_mu (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4_t __riscv_vle8ff_mu (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m8_t __riscv_vle8ff_mu (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4_t __riscv_vle16ff_mu (vbool64_t mask, vuint16mf4_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2_t __riscv_vle16ff_mu (vbool32_t mask, vuint16mf2_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1_t __riscv_vle16ff_mu (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2_t __riscv_vle16ff_mu (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4_t __riscv_vle16ff_mu (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m8_t __riscv_vle16ff_mu (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2_t __riscv_vle32ff_mu (vbool64_t mask, vuint32mf2_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1_t __riscv_vle32ff_mu (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2_t __riscv_vle32ff_mu (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4_t __riscv_vle32ff_mu (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m8_t __riscv_vle32ff_mu (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1_t __riscv_vle64ff_mu (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2_t __riscv_vle64ff_mu (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4_t __riscv_vle64ff_mu (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m8_t __riscv_vle64ff_mu (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, size_t *new_vl, size_t vl);
```

== Vector Loads and Stores Segment Instructions

[[policy-variant-overloadedvector-unit-stride-segment-load]]
=== Vector Unit-Stride Segment Load Intrinsics

``` C
vfloat16mf4x2_t __riscv_vlseg2e16_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
```

[[policy-variant-overloadedvecrtor-unit-stride-segment-store]]
=== Vector Unit-Stride Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-strided-segment-load]]
=== Vector Strided Segment Load Intrinsics

``` C
vfloat16mf4x2_t __riscv_vlsseg2e16_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x2_t __riscv_vlsseg2e32_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x2_t __riscv_vlsseg2e8_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x2_t __riscv_vlsseg2e32_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x2_t __riscv_vlsseg2e8_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x2_t __riscv_vlsseg2e32_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x2_t __riscv_vlsseg2e8_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x2_t __riscv_vlsseg2e32_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x2_t __riscv_vlsseg2e8_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
```

[[policy-variant-overloadedvector-strided-segment-store]]
=== Vector Strided Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-indexed-segment-load]]
=== Vector Indexed Segment Load Intrinsics

``` C
vfloat16mf4x2_t __riscv_vloxseg2ei8_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei8_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei8_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei8_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei8_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei8_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei8_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei8_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei8_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei8_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei8_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei8_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei8_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei8_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei8_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei8_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei8_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei8_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei8_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei8_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei8_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei8_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei8_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei8_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei8_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei16_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei32_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei32_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei32_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei32_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei32_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei32_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei32_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei32_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei32_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei32_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei32_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei32_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei32_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei32_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei32_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei32_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei32_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei32_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei32_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei32_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei32_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei32_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei32_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei32_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei32_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei64_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei64_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei64_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei64_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei64_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei64_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei64_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei64_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei64_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei64_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei64_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei64_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei64_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei64_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei64_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei64_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei64_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei64_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei64_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei64_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei64_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei64_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei64_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei64_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei8_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei8_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei8_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei8_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei8_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei8_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei8_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei8_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei8_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei8_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei8_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei8_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei8_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei8_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei8_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei8_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei8_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei8_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei16_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei16_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei16_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei16_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei16_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei16_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei16_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei16_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei16_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei16_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei16_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei16_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei16_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei16_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei16_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei16_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei16_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei16_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei32_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei8_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei8_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei8_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei8_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei8_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei8_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei8_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei8_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei8_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei8_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei8_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei16_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei16_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei16_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei16_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei16_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei16_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei16_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei16_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei16_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei16_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei16_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei8_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei8_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei8_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei8_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei8_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei8_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei8_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei8_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei8_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei8_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei8_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei8_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei8_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei8_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei8_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei8_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei8_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei8_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei8_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei8_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei8_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei8_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei8_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei8_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei8_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei32_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei32_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei32_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei32_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei32_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei32_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei32_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei32_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei32_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei32_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei32_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei32_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei32_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei32_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei32_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei32_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei32_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei32_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei32_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei32_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei32_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei32_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei32_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei32_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei32_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei64_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei64_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei64_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei64_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei64_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei64_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei64_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei64_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei64_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei64_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei64_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei64_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei64_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei64_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei64_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei64_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei64_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei64_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei64_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei64_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei64_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei64_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei64_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei64_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei8_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei8_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei8_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei8_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei8_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei8_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei8_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei8_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei8_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei8_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei8_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei8_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei8_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei8_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei8_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei8_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei8_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei8_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei16_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei16_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei16_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei16_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei16_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei16_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei16_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei16_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei16_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei16_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei16_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei16_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei16_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei16_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei16_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei16_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei16_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei16_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei8_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei8_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei8_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei8_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei8_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei8_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei8_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei8_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei8_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei8_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei8_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei16_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei16_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei16_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei16_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei16_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei16_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei16_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei16_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei16_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei16_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei16_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei8_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei8_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei8_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei8_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei8_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei8_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei8_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei8_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei32_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei32_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei32_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei32_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei32_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei32_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei32_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei64_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei64_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei64_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei64_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei64_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei64_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei8_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei8_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei8_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei8_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei8_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei8_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei8_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei32_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei32_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei32_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei32_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei32_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei32_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei32_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei64_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei64_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei64_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei64_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei64_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei64_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei8_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei8_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei8_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei8_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei8_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei8_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei8_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei32_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei32_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei32_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei32_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei32_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei32_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei32_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei64_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei64_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei64_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei64_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei64_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei64_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei8_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei8_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei8_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei8_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei8_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei8_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei8_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei32_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei32_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei32_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei32_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei32_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei32_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei32_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei64_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei64_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei64_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei64_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei64_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei64_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei8_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei8_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei8_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei8_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei8_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei8_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei8_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei32_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei32_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei32_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei32_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei32_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei32_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei32_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei64_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei64_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei64_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei64_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei64_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei64_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei8_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei8_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei8_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei8_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei8_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei8_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei8_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei32_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei32_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei32_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei32_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei32_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei32_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei32_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei64_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei64_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei64_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei64_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei64_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei64_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
```

[[policy-variant-overloadedvector-indexed-segment-store]]
=== Vector Indexed Segment Store Intrinsics
Intrinsics here don't have a policy variant.

== Vector Integer Arithmetic Instructions

[[policy-variant-overloadedvector-single-width-integer-add-and-subtract]]
=== Vector Single-Width Integer Add and Subtract Intrinsics

``` C
vint8mf8_t __riscv_vadd_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vadd_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vadd_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vadd_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vadd_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vadd_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vadd_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vadd_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vadd_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vadd_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vadd_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vadd_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vadd_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vadd_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vadd_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vadd_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vadd_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vadd_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vadd_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vadd_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vadd_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vadd_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vadd_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vadd_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vadd_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vadd_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vadd_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vadd_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vadd_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vadd_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vadd_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vadd_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vadd_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vadd_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vadd_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vadd_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vadd_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vadd_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vadd_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vadd_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vadd_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vadd_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vadd_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vadd_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vsub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsub_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsub_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsub_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsub_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsub_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsub_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsub_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsub_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsub_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsub_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsub_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsub_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsub_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsub_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsub_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsub_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsub_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsub_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsub_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsub_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsub_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsub_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsub_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsub_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsub_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsub_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsub_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsub_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsub_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsub_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsub_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsub_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vrsub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vrsub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vrsub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vrsub_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vrsub_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vrsub_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vrsub_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vrsub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vrsub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vrsub_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vrsub_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vrsub_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vrsub_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vrsub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vrsub_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vrsub_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vrsub_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vrsub_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vrsub_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vrsub_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vrsub_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vrsub_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vneg_tu (vint8mf8_t maskedoff, vint8mf8_t op1, size_t vl);
vint8mf4_t __riscv_vneg_tu (vint8mf4_t maskedoff, vint8mf4_t op1, size_t vl);
vint8mf2_t __riscv_vneg_tu (vint8mf2_t maskedoff, vint8mf2_t op1, size_t vl);
vint8m1_t __riscv_vneg_tu (vint8m1_t maskedoff, vint8m1_t op1, size_t vl);
vint8m2_t __riscv_vneg_tu (vint8m2_t maskedoff, vint8m2_t op1, size_t vl);
vint8m4_t __riscv_vneg_tu (vint8m4_t maskedoff, vint8m4_t op1, size_t vl);
vint8m8_t __riscv_vneg_tu (vint8m8_t maskedoff, vint8m8_t op1, size_t vl);
vint16mf4_t __riscv_vneg_tu (vint16mf4_t maskedoff, vint16mf4_t op1, size_t vl);
vint16mf2_t __riscv_vneg_tu (vint16mf2_t maskedoff, vint16mf2_t op1, size_t vl);
vint16m1_t __riscv_vneg_tu (vint16m1_t maskedoff, vint16m1_t op1, size_t vl);
vint16m2_t __riscv_vneg_tu (vint16m2_t maskedoff, vint16m2_t op1, size_t vl);
vint16m4_t __riscv_vneg_tu (vint16m4_t maskedoff, vint16m4_t op1, size_t vl);
vint16m8_t __riscv_vneg_tu (vint16m8_t maskedoff, vint16m8_t op1, size_t vl);
vint32mf2_t __riscv_vneg_tu (vint32mf2_t maskedoff, vint32mf2_t op1, size_t vl);
vint32m1_t __riscv_vneg_tu (vint32m1_t maskedoff, vint32m1_t op1, size_t vl);
vint32m2_t __riscv_vneg_tu (vint32m2_t maskedoff, vint32m2_t op1, size_t vl);
vint32m4_t __riscv_vneg_tu (vint32m4_t maskedoff, vint32m4_t op1, size_t vl);
vint32m8_t __riscv_vneg_tu (vint32m8_t maskedoff, vint32m8_t op1, size_t vl);
vint64m1_t __riscv_vneg_tu (vint64m1_t maskedoff, vint64m1_t op1, size_t vl);
vint64m2_t __riscv_vneg_tu (vint64m2_t maskedoff, vint64m2_t op1, size_t vl);
vint64m4_t __riscv_vneg_tu (vint64m4_t maskedoff, vint64m4_t op1, size_t vl);
vint64m8_t __riscv_vneg_tu (vint64m8_t maskedoff, vint64m8_t op1, size_t vl);
vuint8mf8_t __riscv_vadd_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vadd_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vadd_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vadd_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vadd_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vadd_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vadd_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vadd_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vadd_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vadd_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vadd_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vadd_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vadd_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vadd_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vadd_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vadd_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vadd_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vadd_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vadd_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vadd_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vadd_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vadd_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vadd_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vadd_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vadd_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vadd_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vadd_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vadd_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vadd_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vadd_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vadd_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vadd_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vadd_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vadd_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vadd_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vadd_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vadd_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vadd_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vadd_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vadd_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vadd_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vadd_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vadd_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vadd_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vsub_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsub_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsub_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsub_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsub_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsub_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsub_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsub_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsub_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsub_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsub_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsub_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsub_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsub_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsub_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsub_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsub_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsub_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsub_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsub_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsub_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsub_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsub_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsub_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsub_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsub_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsub_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsub_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsub_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsub_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsub_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsub_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsub_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsub_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsub_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsub_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsub_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsub_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsub_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsub_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsub_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsub_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsub_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsub_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vrsub_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vrsub_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vrsub_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vrsub_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vrsub_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vrsub_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vrsub_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vrsub_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vrsub_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vrsub_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vrsub_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vrsub_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vrsub_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vrsub_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vrsub_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vrsub_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vrsub_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vrsub_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vrsub_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vrsub_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vrsub_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vrsub_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vadd_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vadd_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vadd_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vadd_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vadd_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vadd_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vadd_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vadd_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vadd_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vadd_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vadd_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vadd_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vadd_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vadd_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vadd_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vadd_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vadd_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vadd_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vadd_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vadd_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vadd_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vadd_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vadd_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vadd_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vadd_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vadd_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vadd_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vadd_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vadd_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vadd_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vadd_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vadd_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vadd_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vadd_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vadd_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vadd_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vadd_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vadd_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vadd_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vadd_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vadd_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vadd_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vadd_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vadd_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vsub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vrsub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vrsub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vrsub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vrsub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vrsub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vrsub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vrsub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vrsub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vrsub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vrsub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vrsub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vrsub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vrsub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vrsub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vrsub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vrsub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vrsub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vrsub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vrsub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vrsub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vrsub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vrsub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vneg_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t vl);
vint8mf4_t __riscv_vneg_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t vl);
vint8mf2_t __riscv_vneg_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t vl);
vint8m1_t __riscv_vneg_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t vl);
vint8m2_t __riscv_vneg_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t vl);
vint8m4_t __riscv_vneg_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t vl);
vint8m8_t __riscv_vneg_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t vl);
vint16mf4_t __riscv_vneg_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t vl);
vint16mf2_t __riscv_vneg_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t vl);
vint16m1_t __riscv_vneg_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t vl);
vint16m2_t __riscv_vneg_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t vl);
vint16m4_t __riscv_vneg_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t vl);
vint16m8_t __riscv_vneg_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t vl);
vint32mf2_t __riscv_vneg_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t vl);
vint32m1_t __riscv_vneg_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t vl);
vint32m2_t __riscv_vneg_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t vl);
vint32m4_t __riscv_vneg_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t vl);
vint32m8_t __riscv_vneg_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t vl);
vint64m1_t __riscv_vneg_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t vl);
vint64m2_t __riscv_vneg_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t vl);
vint64m4_t __riscv_vneg_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t vl);
vint64m8_t __riscv_vneg_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t vl);
vuint8mf8_t __riscv_vadd_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vadd_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vadd_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vadd_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vadd_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vadd_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vadd_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vadd_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vadd_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vadd_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vadd_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vadd_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vadd_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vadd_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vadd_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vadd_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vadd_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vadd_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vadd_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vadd_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vadd_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vadd_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vadd_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vadd_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vadd_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vadd_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vadd_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vadd_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vadd_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vadd_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vadd_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vadd_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vadd_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vadd_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vadd_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vadd_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vadd_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vadd_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vadd_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vadd_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vadd_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vadd_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vadd_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vadd_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vsub_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsub_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsub_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsub_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsub_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsub_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsub_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsub_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsub_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsub_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsub_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsub_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsub_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsub_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsub_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsub_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsub_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsub_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsub_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsub_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsub_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsub_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsub_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsub_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsub_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsub_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsub_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsub_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsub_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsub_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsub_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsub_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsub_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsub_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsub_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsub_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsub_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsub_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsub_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsub_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsub_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsub_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsub_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsub_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vrsub_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vrsub_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vrsub_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vrsub_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vrsub_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vrsub_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vrsub_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vrsub_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vrsub_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vrsub_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vrsub_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vrsub_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vrsub_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vrsub_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vrsub_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vrsub_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vrsub_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vrsub_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vrsub_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vrsub_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vrsub_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vrsub_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vadd_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vadd_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vadd_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vadd_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vadd_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vadd_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vadd_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vadd_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vadd_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vadd_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vadd_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vadd_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vadd_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vadd_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vadd_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vadd_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vadd_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vadd_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vadd_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vadd_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vadd_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vadd_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vadd_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vadd_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vadd_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vadd_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vadd_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vadd_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vadd_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vadd_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vadd_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vadd_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vadd_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vadd_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vadd_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vadd_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vadd_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vadd_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vadd_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vadd_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vadd_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vadd_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vadd_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vadd_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vsub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vrsub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vrsub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vrsub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vrsub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vrsub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vrsub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vrsub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vrsub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vrsub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vrsub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vrsub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vrsub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vrsub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vrsub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vrsub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vrsub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vrsub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vrsub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vrsub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vrsub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vrsub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vrsub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vneg_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t vl);
vint8mf4_t __riscv_vneg_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t vl);
vint8mf2_t __riscv_vneg_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t vl);
vint8m1_t __riscv_vneg_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t vl);
vint8m2_t __riscv_vneg_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t vl);
vint8m4_t __riscv_vneg_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t vl);
vint8m8_t __riscv_vneg_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t vl);
vint16mf4_t __riscv_vneg_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t vl);
vint16mf2_t __riscv_vneg_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t vl);
vint16m1_t __riscv_vneg_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t vl);
vint16m2_t __riscv_vneg_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t vl);
vint16m4_t __riscv_vneg_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t vl);
vint16m8_t __riscv_vneg_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t vl);
vint32mf2_t __riscv_vneg_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t vl);
vint32m1_t __riscv_vneg_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t vl);
vint32m2_t __riscv_vneg_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t vl);
vint32m4_t __riscv_vneg_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t vl);
vint32m8_t __riscv_vneg_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t vl);
vint64m1_t __riscv_vneg_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t vl);
vint64m2_t __riscv_vneg_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t vl);
vint64m4_t __riscv_vneg_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t vl);
vint64m8_t __riscv_vneg_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t vl);
vuint8mf8_t __riscv_vadd_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vadd_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vadd_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vadd_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vadd_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vadd_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vadd_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vadd_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vadd_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vadd_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vadd_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vadd_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vadd_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vadd_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vadd_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vadd_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vadd_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vadd_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vadd_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vadd_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vadd_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vadd_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vadd_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vadd_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vadd_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vadd_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vadd_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vadd_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vadd_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vadd_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vadd_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vadd_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vadd_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vadd_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vadd_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vadd_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vadd_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vadd_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vadd_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vadd_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vadd_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vadd_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vadd_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vadd_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vsub_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsub_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsub_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsub_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsub_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsub_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsub_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsub_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsub_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsub_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsub_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsub_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsub_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsub_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsub_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsub_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsub_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsub_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsub_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsub_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsub_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsub_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsub_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsub_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsub_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsub_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsub_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsub_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsub_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsub_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsub_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsub_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsub_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsub_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsub_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsub_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsub_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsub_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsub_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsub_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsub_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsub_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsub_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsub_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vrsub_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vrsub_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vrsub_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vrsub_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vrsub_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vrsub_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vrsub_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vrsub_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vrsub_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vrsub_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vrsub_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vrsub_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vrsub_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vrsub_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vrsub_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vrsub_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vrsub_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vrsub_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vrsub_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vrsub_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vrsub_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vrsub_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vadd_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vadd_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vadd_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vadd_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vadd_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vadd_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vadd_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vadd_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vadd_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vadd_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vadd_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vadd_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vadd_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vadd_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vadd_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vadd_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vadd_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vadd_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vadd_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vadd_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vadd_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vadd_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vadd_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vadd_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vadd_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vadd_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vadd_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vadd_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vadd_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vadd_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vadd_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vadd_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vadd_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vadd_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vadd_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vadd_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vadd_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vadd_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vadd_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vadd_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vadd_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vadd_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vadd_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vadd_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vsub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vrsub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vrsub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vrsub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vrsub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vrsub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vrsub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vrsub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vrsub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vrsub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vrsub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vrsub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vrsub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vrsub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vrsub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vrsub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vrsub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vrsub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vrsub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vrsub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vrsub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vrsub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vrsub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vneg_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t vl);
vint8mf4_t __riscv_vneg_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t vl);
vint8mf2_t __riscv_vneg_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t vl);
vint8m1_t __riscv_vneg_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t vl);
vint8m2_t __riscv_vneg_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t vl);
vint8m4_t __riscv_vneg_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t vl);
vint8m8_t __riscv_vneg_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t vl);
vint16mf4_t __riscv_vneg_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t vl);
vint16mf2_t __riscv_vneg_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t vl);
vint16m1_t __riscv_vneg_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t vl);
vint16m2_t __riscv_vneg_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t vl);
vint16m4_t __riscv_vneg_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t vl);
vint16m8_t __riscv_vneg_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t vl);
vint32mf2_t __riscv_vneg_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t vl);
vint32m1_t __riscv_vneg_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t vl);
vint32m2_t __riscv_vneg_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t vl);
vint32m4_t __riscv_vneg_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t vl);
vint32m8_t __riscv_vneg_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t vl);
vint64m1_t __riscv_vneg_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t vl);
vint64m2_t __riscv_vneg_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t vl);
vint64m4_t __riscv_vneg_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t vl);
vint64m8_t __riscv_vneg_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t vl);
vuint8mf8_t __riscv_vadd_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vadd_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vadd_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vadd_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vadd_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vadd_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vadd_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vadd_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vadd_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vadd_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vadd_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vadd_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vadd_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vadd_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vadd_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vadd_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vadd_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vadd_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vadd_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vadd_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vadd_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vadd_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vadd_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vadd_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vadd_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vadd_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vadd_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vadd_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vadd_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vadd_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vadd_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vadd_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vadd_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vadd_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vadd_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vadd_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vadd_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vadd_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vadd_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vadd_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vadd_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vadd_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vadd_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vadd_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vsub_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsub_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsub_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsub_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsub_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsub_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsub_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsub_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsub_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsub_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsub_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsub_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsub_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsub_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsub_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsub_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsub_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsub_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsub_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsub_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsub_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsub_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsub_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsub_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsub_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsub_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsub_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsub_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsub_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsub_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsub_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsub_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsub_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsub_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsub_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsub_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsub_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsub_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsub_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsub_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsub_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsub_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsub_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsub_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vrsub_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vrsub_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vrsub_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vrsub_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vrsub_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vrsub_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vrsub_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vrsub_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vrsub_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vrsub_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vrsub_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vrsub_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vrsub_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vrsub_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vrsub_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vrsub_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vrsub_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vrsub_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vrsub_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vrsub_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vrsub_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vrsub_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
```

[[policy-variant-overloadedvector-widening-integer-add-subtract]]
=== Vector Widening Integer Add/Subtract Intrinsics

``` C
vint16mf4_t __riscv_vwadd_vv_tu (vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_vx_tu (vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_wv_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_wx_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_vv_tu (vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_vx_tu (vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_wv_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_wx_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwadd_vv_tu (vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwadd_vx_tu (vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwadd_wv_tu (vint16m1_t maskedoff, vint16m1_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwadd_wx_tu (vint16m1_t maskedoff, vint16m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwadd_vv_tu (vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwadd_vx_tu (vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwadd_wv_tu (vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwadd_wx_tu (vint16m2_t maskedoff, vint16m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwadd_vv_tu (vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwadd_vx_tu (vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwadd_wv_tu (vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwadd_wx_tu (vint16m4_t maskedoff, vint16m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwadd_vv_tu (vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwadd_vx_tu (vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwadd_wv_tu (vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwadd_wx_tu (vint16m8_t maskedoff, vint16m8_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_vv_tu (vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_vx_tu (vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_wv_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_wx_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwadd_vv_tu (vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwadd_vx_tu (vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwadd_wv_tu (vint32m1_t maskedoff, vint32m1_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwadd_wx_tu (vint32m1_t maskedoff, vint32m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwadd_vv_tu (vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwadd_vx_tu (vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwadd_wv_tu (vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwadd_wx_tu (vint32m2_t maskedoff, vint32m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwadd_vv_tu (vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwadd_vx_tu (vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwadd_wv_tu (vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwadd_wx_tu (vint32m4_t maskedoff, vint32m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwadd_vv_tu (vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwadd_vx_tu (vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwadd_wv_tu (vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwadd_wx_tu (vint32m8_t maskedoff, vint32m8_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwadd_vv_tu (vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwadd_vx_tu (vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vwadd_wv_tu (vint64m1_t maskedoff, vint64m1_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwadd_wx_tu (vint64m1_t maskedoff, vint64m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwadd_vv_tu (vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwadd_vx_tu (vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwadd_wv_tu (vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwadd_wx_tu (vint64m2_t maskedoff, vint64m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwadd_vv_tu (vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwadd_vx_tu (vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwadd_wv_tu (vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwadd_wx_tu (vint64m4_t maskedoff, vint64m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwadd_vv_tu (vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwadd_vx_tu (vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwadd_wv_tu (vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwadd_wx_tu (vint64m8_t maskedoff, vint64m8_t op1, int32_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_vv_tu (vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_vx_tu (vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_wv_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_wx_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_vv_tu (vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_vx_tu (vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_wv_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_wx_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwsub_vv_tu (vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwsub_vx_tu (vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwsub_wv_tu (vint16m1_t maskedoff, vint16m1_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwsub_wx_tu (vint16m1_t maskedoff, vint16m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwsub_vv_tu (vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwsub_vx_tu (vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwsub_wv_tu (vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwsub_wx_tu (vint16m2_t maskedoff, vint16m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwsub_vv_tu (vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwsub_vx_tu (vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwsub_wv_tu (vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwsub_wx_tu (vint16m4_t maskedoff, vint16m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwsub_vv_tu (vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwsub_vx_tu (vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwsub_wv_tu (vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwsub_wx_tu (vint16m8_t maskedoff, vint16m8_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_vv_tu (vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_vx_tu (vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_wv_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_wx_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwsub_vv_tu (vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwsub_vx_tu (vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwsub_wv_tu (vint32m1_t maskedoff, vint32m1_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwsub_wx_tu (vint32m1_t maskedoff, vint32m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwsub_vv_tu (vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwsub_vx_tu (vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwsub_wv_tu (vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwsub_wx_tu (vint32m2_t maskedoff, vint32m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwsub_vv_tu (vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwsub_vx_tu (vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwsub_wv_tu (vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwsub_wx_tu (vint32m4_t maskedoff, vint32m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwsub_vv_tu (vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwsub_vx_tu (vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwsub_wv_tu (vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwsub_wx_tu (vint32m8_t maskedoff, vint32m8_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwsub_vv_tu (vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwsub_vx_tu (vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vwsub_wv_tu (vint64m1_t maskedoff, vint64m1_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwsub_wx_tu (vint64m1_t maskedoff, vint64m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwsub_vv_tu (vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwsub_vx_tu (vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwsub_wv_tu (vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwsub_wx_tu (vint64m2_t maskedoff, vint64m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwsub_vv_tu (vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwsub_vx_tu (vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwsub_wv_tu (vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwsub_wx_tu (vint64m4_t maskedoff, vint64m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwsub_vv_tu (vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwsub_vx_tu (vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwsub_wv_tu (vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwsub_wx_tu (vint64m8_t maskedoff, vint64m8_t op1, int32_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_vv_tu (vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_vx_tu (vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_wv_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_wx_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_vv_tu (vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_vx_tu (vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_wv_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_wx_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_vv_tu (vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_vx_tu (vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_wv_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_wx_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_vv_tu (vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_vx_tu (vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_wv_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_wx_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_vv_tu (vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_vx_tu (vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_wv_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_wx_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_vv_tu (vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_vx_tu (vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_wv_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_wx_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_vv_tu (vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_vx_tu (vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_wv_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_wx_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_vv_tu (vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_vx_tu (vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_wv_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_wx_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_vv_tu (vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_vx_tu (vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_wv_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_wx_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_vv_tu (vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_vx_tu (vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_wv_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_wx_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_vv_tu (vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_vx_tu (vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_wv_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_wx_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_vv_tu (vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_vx_tu (vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_wv_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_wx_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_vv_tu (vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_vx_tu (vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_wv_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_wx_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_vv_tu (vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_vx_tu (vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_wv_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_wx_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_vv_tu (vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_vx_tu (vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_wv_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_wx_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_vv_tu (vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_vx_tu (vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_wv_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_wx_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_vv_tu (vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_vx_tu (vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_wv_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_wx_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_vv_tu (vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_vx_tu (vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_wv_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_wx_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_vv_tu (vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_vx_tu (vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_wv_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_wx_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_vv_tu (vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_vx_tu (vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_wv_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_wx_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_vv_tu (vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_vx_tu (vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_wv_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_wx_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_vv_tu (vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_vx_tu (vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_wv_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_wx_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_vv_tu (vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_vx_tu (vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_wv_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_wx_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_vv_tu (vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_vx_tu (vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_wv_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_wx_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_vv_tu (vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_vx_tu (vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_wv_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_wx_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_vv_tu (vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_vx_tu (vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_wv_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_wx_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_vv_tu (vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_vx_tu (vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_wv_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_wx_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_vv_tu (vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_vx_tu (vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_wv_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_wx_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_vv_tu (vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_vx_tu (vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_wv_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_wx_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_vv_tu (vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_vx_tu (vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_wv_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_wx_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwadd_vv_tum (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_vx_tum (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_wv_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_wx_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_vv_tum (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_vx_tum (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_wv_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_wx_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwadd_vv_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwadd_vx_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwadd_wv_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwadd_wx_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwadd_vv_tum (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwadd_vx_tum (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwadd_wv_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwadd_wx_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwadd_vv_tum (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwadd_vx_tum (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwadd_wv_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwadd_wx_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwadd_vv_tum (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwadd_vx_tum (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwadd_wv_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwadd_wx_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_vv_tum (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_vx_tum (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_wv_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_wx_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwadd_vv_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwadd_vx_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwadd_wv_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwadd_wx_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwadd_vv_tum (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwadd_vx_tum (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwadd_wv_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwadd_wx_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwadd_vv_tum (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwadd_vx_tum (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwadd_wv_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwadd_wx_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwadd_vv_tum (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwadd_vx_tum (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwadd_wv_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwadd_wx_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwadd_vv_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwadd_vx_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vwadd_wv_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwadd_wx_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwadd_vv_tum (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwadd_vx_tum (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwadd_wv_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwadd_wx_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwadd_vv_tum (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwadd_vx_tum (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwadd_wv_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwadd_wx_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwadd_vv_tum (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwadd_vx_tum (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwadd_wv_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwadd_wx_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_vv_tum (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_vx_tum (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_wv_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_wx_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_vv_tum (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_vx_tum (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_wv_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_wx_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwsub_vv_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwsub_vx_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwsub_wv_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwsub_wx_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwsub_vv_tum (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwsub_vx_tum (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwsub_wv_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwsub_wx_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwsub_vv_tum (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwsub_vx_tum (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwsub_wv_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwsub_wx_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwsub_vv_tum (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwsub_vx_tum (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwsub_wv_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwsub_wx_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_vv_tum (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_vx_tum (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_wv_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_wx_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwsub_vv_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwsub_vx_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwsub_wv_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwsub_wx_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwsub_vv_tum (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwsub_vx_tum (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwsub_wv_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwsub_wx_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwsub_vv_tum (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwsub_vx_tum (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwsub_wv_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwsub_wx_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwsub_vv_tum (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwsub_vx_tum (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwsub_wv_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwsub_wx_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwsub_vv_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwsub_vx_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vwsub_wv_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwsub_wx_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwsub_vv_tum (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwsub_vx_tum (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwsub_wv_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwsub_wx_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwsub_vv_tum (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwsub_vx_tum (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwsub_wv_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwsub_wx_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwsub_vv_tum (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwsub_vx_tum (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwsub_wv_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwsub_wx_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_vv_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_vx_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_wv_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_wx_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_vv_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_vx_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_wv_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_wx_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_vv_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_vx_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_wv_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_wx_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_vv_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_vx_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_wv_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_wx_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_vv_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_vx_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_wv_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_wx_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_vv_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_vx_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_wv_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_wx_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_vv_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_vx_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_wv_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_wx_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_vv_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_vx_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_wv_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_wx_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_vv_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_vx_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_wv_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_wx_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_vv_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_vx_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_wv_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_wx_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_vv_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_vx_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_wv_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_wx_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_vv_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_vx_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_wv_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_wx_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_vv_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_vx_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_wv_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_wx_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_vv_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_vx_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_wv_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_wx_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_vv_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_vx_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_wv_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_wx_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_vv_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_vx_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_wv_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_wx_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_vv_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_vx_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_wv_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_wx_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_vv_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_vx_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_wv_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_wx_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_vv_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_vx_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_wv_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_wx_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_vv_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_vx_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_wv_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_wx_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_vv_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_vx_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_wv_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_wx_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_vv_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_vx_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_wv_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_wx_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_vv_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_vx_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_wv_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_wx_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_vv_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_vx_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_wv_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_wx_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_vv_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_vx_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_wv_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_wx_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_vv_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_vx_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_wv_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_wx_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_vv_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_vx_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_wv_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_wx_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_vv_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_vx_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_wv_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_wx_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_vv_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_vx_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_wv_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_wx_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_vv_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_vx_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_wv_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_wx_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwadd_vv_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_vx_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_wv_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_wx_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_vv_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_vx_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_wv_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_wx_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwadd_vv_tumu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwadd_vx_tumu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwadd_wv_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwadd_wx_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwadd_vv_tumu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwadd_vx_tumu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwadd_wv_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwadd_wx_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwadd_vv_tumu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwadd_vx_tumu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwadd_wv_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwadd_wx_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwadd_vv_tumu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwadd_vx_tumu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwadd_wv_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwadd_wx_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_vv_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_vx_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_wv_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_wx_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwadd_vv_tumu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwadd_vx_tumu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwadd_wv_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwadd_wx_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwadd_vv_tumu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwadd_vx_tumu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwadd_wv_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwadd_wx_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwadd_vv_tumu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwadd_vx_tumu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwadd_wv_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwadd_wx_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwadd_vv_tumu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwadd_vx_tumu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwadd_wv_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwadd_wx_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwadd_vv_tumu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwadd_vx_tumu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vwadd_wv_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwadd_wx_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwadd_vv_tumu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwadd_vx_tumu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwadd_wv_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwadd_wx_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwadd_vv_tumu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwadd_vx_tumu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwadd_wv_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwadd_wx_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwadd_vv_tumu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwadd_vx_tumu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwadd_wv_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwadd_wx_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_vv_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_vx_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_wv_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_wx_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_vv_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_vx_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_wv_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_wx_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwsub_vv_tumu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwsub_vx_tumu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwsub_wv_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwsub_wx_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwsub_vv_tumu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwsub_vx_tumu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwsub_wv_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwsub_wx_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwsub_vv_tumu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwsub_vx_tumu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwsub_wv_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwsub_wx_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwsub_vv_tumu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwsub_vx_tumu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwsub_wv_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwsub_wx_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_vv_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_vx_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_wv_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_wx_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwsub_vv_tumu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwsub_vx_tumu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwsub_wv_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwsub_wx_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwsub_vv_tumu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwsub_vx_tumu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwsub_wv_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwsub_wx_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwsub_vv_tumu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwsub_vx_tumu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwsub_wv_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwsub_wx_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwsub_vv_tumu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwsub_vx_tumu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwsub_wv_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwsub_wx_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwsub_vv_tumu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwsub_vx_tumu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vwsub_wv_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwsub_wx_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwsub_vv_tumu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwsub_vx_tumu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwsub_wv_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwsub_wx_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwsub_vv_tumu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwsub_vx_tumu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwsub_wv_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwsub_wx_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwsub_vv_tumu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwsub_vx_tumu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwsub_wv_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwsub_wx_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_vv_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_vx_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_wv_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_wx_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_vv_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_vx_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_wv_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_wx_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_vv_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_vx_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_wv_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_wx_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_vv_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_vx_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_wv_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_wx_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_vv_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_vx_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_wv_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_wx_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_vv_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_vx_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_wv_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_wx_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_vv_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_vx_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_wv_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_wx_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_vv_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_vx_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_wv_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_wx_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_vv_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_vx_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_wv_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_wx_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_vv_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_vx_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_wv_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_wx_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_vv_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_vx_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_wv_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_wx_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_vv_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_vx_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_wv_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_wx_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_vv_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_vx_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_wv_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_wx_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_vv_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_vx_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_wv_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_wx_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_vv_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_vx_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_wv_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_wx_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_vv_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_vx_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_wv_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_wx_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_vv_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_vx_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_wv_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_wx_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_vv_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_vx_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_wv_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_wx_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_vv_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_vx_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_wv_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_wx_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_vv_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_vx_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_wv_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_wx_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_vv_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_vx_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_wv_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_wx_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_vv_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_vx_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_wv_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_wx_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_vv_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_vx_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_wv_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_wx_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_vv_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_vx_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_wv_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_wx_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_vv_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_vx_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_wv_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_wx_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_vv_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_vx_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_wv_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_wx_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_vv_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_vx_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_wv_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_wx_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_vv_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_vx_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_wv_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_wx_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_vv_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_vx_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_wv_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_wx_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_vv_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_vx_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_wv_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_wx_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwadd_vv_mu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_vx_mu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_wv_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwadd_wx_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_vv_mu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_vx_mu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_wv_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwadd_wx_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwadd_vv_mu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwadd_vx_mu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwadd_wv_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwadd_wx_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwadd_vv_mu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwadd_vx_mu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwadd_wv_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwadd_wx_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwadd_vv_mu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwadd_vx_mu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwadd_wv_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwadd_wx_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwadd_vv_mu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwadd_vx_mu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwadd_wv_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwadd_wx_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_vv_mu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_vx_mu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_wv_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwadd_wx_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwadd_vv_mu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwadd_vx_mu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwadd_wv_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwadd_wx_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwadd_vv_mu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwadd_vx_mu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwadd_wv_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwadd_wx_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwadd_vv_mu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwadd_vx_mu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwadd_wv_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwadd_wx_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwadd_vv_mu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwadd_vx_mu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwadd_wv_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwadd_wx_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwadd_vv_mu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwadd_vx_mu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vwadd_wv_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwadd_wx_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwadd_vv_mu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwadd_vx_mu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwadd_wv_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwadd_wx_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwadd_vv_mu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwadd_vx_mu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwadd_wv_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwadd_wx_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwadd_vv_mu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwadd_vx_mu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwadd_wv_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwadd_wx_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_vv_mu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_vx_mu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_wv_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwsub_wx_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_vv_mu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_vx_mu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_wv_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwsub_wx_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwsub_vv_mu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwsub_vx_mu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwsub_wv_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwsub_wx_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwsub_vv_mu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwsub_vx_mu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwsub_wv_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwsub_wx_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwsub_vv_mu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwsub_vx_mu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwsub_wv_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwsub_wx_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwsub_vv_mu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwsub_vx_mu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwsub_wv_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwsub_wx_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_vv_mu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_vx_mu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_wv_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwsub_wx_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwsub_vv_mu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwsub_vx_mu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwsub_wv_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwsub_wx_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwsub_vv_mu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwsub_vx_mu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwsub_wv_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwsub_wx_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwsub_vv_mu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwsub_vx_mu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwsub_wv_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwsub_wx_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwsub_vv_mu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwsub_vx_mu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwsub_wv_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwsub_wx_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwsub_vv_mu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwsub_vx_mu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vwsub_wv_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwsub_wx_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwsub_vv_mu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwsub_vx_mu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwsub_wv_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwsub_wx_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwsub_vv_mu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwsub_vx_mu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwsub_wv_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwsub_wx_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwsub_vv_mu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwsub_vx_mu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwsub_wv_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwsub_wx_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_vv_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_vx_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_wv_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwaddu_wx_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_vv_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_vx_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_wv_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwaddu_wx_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_vv_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_vx_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_wv_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwaddu_wx_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_vv_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_vx_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_wv_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwaddu_wx_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_vv_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_vx_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_wv_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwaddu_wx_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_vv_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_vx_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_wv_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwaddu_wx_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_vv_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_vx_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_wv_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwaddu_wx_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_vv_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_vx_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_wv_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwaddu_wx_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_vv_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_vx_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_wv_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwaddu_wx_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_vv_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_vx_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_wv_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwaddu_wx_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_vv_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_vx_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_wv_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwaddu_wx_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_vv_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_vx_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_wv_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwaddu_wx_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_vv_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_vx_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_wv_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwaddu_wx_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_vv_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_vx_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_wv_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwaddu_wx_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_vv_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_vx_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_wv_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwaddu_wx_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_vv_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_vx_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_wv_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwsubu_wx_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_vv_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_vx_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_wv_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwsubu_wx_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_vv_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_vx_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_wv_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwsubu_wx_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_vv_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_vx_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_wv_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwsubu_wx_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_vv_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_vx_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_wv_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwsubu_wx_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_vv_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_vx_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_wv_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwsubu_wx_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_vv_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_vx_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_wv_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwsubu_wx_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_vv_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_vx_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_wv_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwsubu_wx_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_vv_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_vx_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_wv_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwsubu_wx_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_vv_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_vx_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_wv_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwsubu_wx_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_vv_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_vx_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_wv_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwsubu_wx_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_vv_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_vx_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_wv_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwsubu_wx_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_vv_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_vx_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_wv_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwsubu_wx_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_vv_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_vx_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_wv_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwsubu_wx_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_vv_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_vx_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_wv_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwsubu_wx_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2, size_t vl);
```

[[policy-variant-overloadedvector-integer-widening]]
=== Vector Integer Widening Intrinsics

``` C
vint16mf4_t __riscv_vwcvt_x_tu (vint16mf4_t maskedoff, vint8mf8_t src, size_t vl);
vint16mf2_t __riscv_vwcvt_x_tu (vint16mf2_t maskedoff, vint8mf4_t src, size_t vl);
vint16m1_t __riscv_vwcvt_x_tu (vint16m1_t maskedoff, vint8mf2_t src, size_t vl);
vint16m2_t __riscv_vwcvt_x_tu (vint16m2_t maskedoff, vint8m1_t src, size_t vl);
vint16m4_t __riscv_vwcvt_x_tu (vint16m4_t maskedoff, vint8m2_t src, size_t vl);
vint16m8_t __riscv_vwcvt_x_tu (vint16m8_t maskedoff, vint8m4_t src, size_t vl);
vuint16mf4_t __riscv_vwcvtu_x_tu (vuint16mf4_t maskedoff, vuint8mf8_t src, size_t vl);
vuint16mf2_t __riscv_vwcvtu_x_tu (vuint16mf2_t maskedoff, vuint8mf4_t src, size_t vl);
vuint16m1_t __riscv_vwcvtu_x_tu (vuint16m1_t maskedoff, vuint8mf2_t src, size_t vl);
vuint16m2_t __riscv_vwcvtu_x_tu (vuint16m2_t maskedoff, vuint8m1_t src, size_t vl);
vuint16m4_t __riscv_vwcvtu_x_tu (vuint16m4_t maskedoff, vuint8m2_t src, size_t vl);
vuint16m8_t __riscv_vwcvtu_x_tu (vuint16m8_t maskedoff, vuint8m4_t src, size_t vl);
vint32mf2_t __riscv_vwcvt_x_tu (vint32mf2_t maskedoff, vint16mf4_t src, size_t vl);
vint32m1_t __riscv_vwcvt_x_tu (vint32m1_t maskedoff, vint16mf2_t src, size_t vl);
vint32m2_t __riscv_vwcvt_x_tu (vint32m2_t maskedoff, vint16m1_t src, size_t vl);
vint32m4_t __riscv_vwcvt_x_tu (vint32m4_t maskedoff, vint16m2_t src, size_t vl);
vint32m8_t __riscv_vwcvt_x_tu (vint32m8_t maskedoff, vint16m4_t src, size_t vl);
vuint32mf2_t __riscv_vwcvtu_x_tu (vuint32mf2_t maskedoff, vuint16mf4_t src, size_t vl);
vuint32m1_t __riscv_vwcvtu_x_tu (vuint32m1_t maskedoff, vuint16mf2_t src, size_t vl);
vuint32m2_t __riscv_vwcvtu_x_tu (vuint32m2_t maskedoff, vuint16m1_t src, size_t vl);
vuint32m4_t __riscv_vwcvtu_x_tu (vuint32m4_t maskedoff, vuint16m2_t src, size_t vl);
vuint32m8_t __riscv_vwcvtu_x_tu (vuint32m8_t maskedoff, vuint16m4_t src, size_t vl);
vint64m1_t __riscv_vwcvt_x_tu (vint64m1_t maskedoff, vint32mf2_t src, size_t vl);
vint64m2_t __riscv_vwcvt_x_tu (vint64m2_t maskedoff, vint32m1_t src, size_t vl);
vint64m4_t __riscv_vwcvt_x_tu (vint64m4_t maskedoff, vint32m2_t src, size_t vl);
vint64m8_t __riscv_vwcvt_x_tu (vint64m8_t maskedoff, vint32m4_t src, size_t vl);
vuint64m1_t __riscv_vwcvtu_x_tu (vuint64m1_t maskedoff, vuint32mf2_t src, size_t vl);
vuint64m2_t __riscv_vwcvtu_x_tu (vuint64m2_t maskedoff, vuint32m1_t src, size_t vl);
vuint64m4_t __riscv_vwcvtu_x_tu (vuint64m4_t maskedoff, vuint32m2_t src, size_t vl);
vuint64m8_t __riscv_vwcvtu_x_tu (vuint64m8_t maskedoff, vuint32m4_t src, size_t vl);
// masked functions
vint16mf4_t __riscv_vwcvt_x_tum (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t src, size_t vl);
vint16mf2_t __riscv_vwcvt_x_tum (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t src, size_t vl);
vint16m1_t __riscv_vwcvt_x_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t src, size_t vl);
vint16m2_t __riscv_vwcvt_x_tum (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t src, size_t vl);
vint16m4_t __riscv_vwcvt_x_tum (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t src, size_t vl);
vint16m8_t __riscv_vwcvt_x_tum (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t src, size_t vl);
vuint16mf4_t __riscv_vwcvtu_x_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t src, size_t vl);
vuint16mf2_t __riscv_vwcvtu_x_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t src, size_t vl);
vuint16m1_t __riscv_vwcvtu_x_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t src, size_t vl);
vuint16m2_t __riscv_vwcvtu_x_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t src, size_t vl);
vuint16m4_t __riscv_vwcvtu_x_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t src, size_t vl);
vuint16m8_t __riscv_vwcvtu_x_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t src, size_t vl);
vint32mf2_t __riscv_vwcvt_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t src, size_t vl);
vint32m1_t __riscv_vwcvt_x_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t src, size_t vl);
vint32m2_t __riscv_vwcvt_x_tum (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t src, size_t vl);
vint32m4_t __riscv_vwcvt_x_tum (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t src, size_t vl);
vint32m8_t __riscv_vwcvt_x_tum (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t src, size_t vl);
vuint32mf2_t __riscv_vwcvtu_x_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t src, size_t vl);
vuint32m1_t __riscv_vwcvtu_x_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t src, size_t vl);
vuint32m2_t __riscv_vwcvtu_x_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t src, size_t vl);
vuint32m4_t __riscv_vwcvtu_x_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t src, size_t vl);
vuint32m8_t __riscv_vwcvtu_x_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t src, size_t vl);
vint64m1_t __riscv_vwcvt_x_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t src, size_t vl);
vint64m2_t __riscv_vwcvt_x_tum (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t src, size_t vl);
vint64m4_t __riscv_vwcvt_x_tum (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t src, size_t vl);
vint64m8_t __riscv_vwcvt_x_tum (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t src, size_t vl);
vuint64m1_t __riscv_vwcvtu_x_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t src, size_t vl);
vuint64m2_t __riscv_vwcvtu_x_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t src, size_t vl);
vuint64m4_t __riscv_vwcvtu_x_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t src, size_t vl);
vuint64m8_t __riscv_vwcvtu_x_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t src, size_t vl);
// masked functions
vint16mf4_t __riscv_vwcvt_x_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t src, size_t vl);
vint16mf2_t __riscv_vwcvt_x_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t src, size_t vl);
vint16m1_t __riscv_vwcvt_x_tumu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t src, size_t vl);
vint16m2_t __riscv_vwcvt_x_tumu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t src, size_t vl);
vint16m4_t __riscv_vwcvt_x_tumu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t src, size_t vl);
vint16m8_t __riscv_vwcvt_x_tumu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t src, size_t vl);
vuint16mf4_t __riscv_vwcvtu_x_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t src, size_t vl);
vuint16mf2_t __riscv_vwcvtu_x_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t src, size_t vl);
vuint16m1_t __riscv_vwcvtu_x_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t src, size_t vl);
vuint16m2_t __riscv_vwcvtu_x_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t src, size_t vl);
vuint16m4_t __riscv_vwcvtu_x_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t src, size_t vl);
vuint16m8_t __riscv_vwcvtu_x_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t src, size_t vl);
vint32mf2_t __riscv_vwcvt_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t src, size_t vl);
vint32m1_t __riscv_vwcvt_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t src, size_t vl);
vint32m2_t __riscv_vwcvt_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t src, size_t vl);
vint32m4_t __riscv_vwcvt_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t src, size_t vl);
vint32m8_t __riscv_vwcvt_x_tumu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t src, size_t vl);
vuint32mf2_t __riscv_vwcvtu_x_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t src, size_t vl);
vuint32m1_t __riscv_vwcvtu_x_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t src, size_t vl);
vuint32m2_t __riscv_vwcvtu_x_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t src, size_t vl);
vuint32m4_t __riscv_vwcvtu_x_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t src, size_t vl);
vuint32m8_t __riscv_vwcvtu_x_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t src, size_t vl);
vint64m1_t __riscv_vwcvt_x_tumu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t src, size_t vl);
vint64m2_t __riscv_vwcvt_x_tumu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t src, size_t vl);
vint64m4_t __riscv_vwcvt_x_tumu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t src, size_t vl);
vint64m8_t __riscv_vwcvt_x_tumu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t src, size_t vl);
vuint64m1_t __riscv_vwcvtu_x_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t src, size_t vl);
vuint64m2_t __riscv_vwcvtu_x_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t src, size_t vl);
vuint64m4_t __riscv_vwcvtu_x_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t src, size_t vl);
vuint64m8_t __riscv_vwcvtu_x_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t src, size_t vl);
// masked functions
vint16mf4_t __riscv_vwcvt_x_mu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t src, size_t vl);
vint16mf2_t __riscv_vwcvt_x_mu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t src, size_t vl);
vint16m1_t __riscv_vwcvt_x_mu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t src, size_t vl);
vint16m2_t __riscv_vwcvt_x_mu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t src, size_t vl);
vint16m4_t __riscv_vwcvt_x_mu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t src, size_t vl);
vint16m8_t __riscv_vwcvt_x_mu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t src, size_t vl);
vuint16mf4_t __riscv_vwcvtu_x_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t src, size_t vl);
vuint16mf2_t __riscv_vwcvtu_x_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t src, size_t vl);
vuint16m1_t __riscv_vwcvtu_x_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t src, size_t vl);
vuint16m2_t __riscv_vwcvtu_x_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t src, size_t vl);
vuint16m4_t __riscv_vwcvtu_x_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t src, size_t vl);
vuint16m8_t __riscv_vwcvtu_x_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t src, size_t vl);
vint32mf2_t __riscv_vwcvt_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t src, size_t vl);
vint32m1_t __riscv_vwcvt_x_mu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t src, size_t vl);
vint32m2_t __riscv_vwcvt_x_mu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t src, size_t vl);
vint32m4_t __riscv_vwcvt_x_mu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t src, size_t vl);
vint32m8_t __riscv_vwcvt_x_mu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t src, size_t vl);
vuint32mf2_t __riscv_vwcvtu_x_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t src, size_t vl);
vuint32m1_t __riscv_vwcvtu_x_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t src, size_t vl);
vuint32m2_t __riscv_vwcvtu_x_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t src, size_t vl);
vuint32m4_t __riscv_vwcvtu_x_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t src, size_t vl);
vuint32m8_t __riscv_vwcvtu_x_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t src, size_t vl);
vint64m1_t __riscv_vwcvt_x_mu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t src, size_t vl);
vint64m2_t __riscv_vwcvt_x_mu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t src, size_t vl);
vint64m4_t __riscv_vwcvt_x_mu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t src, size_t vl);
vint64m8_t __riscv_vwcvt_x_mu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t src, size_t vl);
vuint64m1_t __riscv_vwcvtu_x_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t src, size_t vl);
vuint64m2_t __riscv_vwcvtu_x_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t src, size_t vl);
vuint64m4_t __riscv_vwcvtu_x_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t src, size_t vl);
vuint64m8_t __riscv_vwcvtu_x_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t src, size_t vl);
```

[[policy-variant-overloadedvector-integer-extension]]
=== Vector Integer Extension Intrinsics

``` C
vint16mf4_t __riscv_vsext_vf2_tu (vint16mf4_t maskedoff, vint8mf8_t op1, size_t vl);
vint16mf2_t __riscv_vsext_vf2_tu (vint16mf2_t maskedoff, vint8mf4_t op1, size_t vl);
vint16m1_t __riscv_vsext_vf2_tu (vint16m1_t maskedoff, vint8mf2_t op1, size_t vl);
vint16m2_t __riscv_vsext_vf2_tu (vint16m2_t maskedoff, vint8m1_t op1, size_t vl);
vint16m4_t __riscv_vsext_vf2_tu (vint16m4_t maskedoff, vint8m2_t op1, size_t vl);
vint16m8_t __riscv_vsext_vf2_tu (vint16m8_t maskedoff, vint8m4_t op1, size_t vl);
vint32mf2_t __riscv_vsext_vf4_tu (vint32mf2_t maskedoff, vint8mf8_t op1, size_t vl);
vint32m1_t __riscv_vsext_vf4_tu (vint32m1_t maskedoff, vint8mf4_t op1, size_t vl);
vint32m2_t __riscv_vsext_vf4_tu (vint32m2_t maskedoff, vint8mf2_t op1, size_t vl);
vint32m4_t __riscv_vsext_vf4_tu (vint32m4_t maskedoff, vint8m1_t op1, size_t vl);
vint32m8_t __riscv_vsext_vf4_tu (vint32m8_t maskedoff, vint8m2_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf8_tu (vint64m1_t maskedoff, vint8mf8_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf8_tu (vint64m2_t maskedoff, vint8mf4_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf8_tu (vint64m4_t maskedoff, vint8mf2_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf8_tu (vint64m8_t maskedoff, vint8m1_t op1, size_t vl);
vint32mf2_t __riscv_vsext_vf2_tu (vint32mf2_t maskedoff, vint16mf4_t op1, size_t vl);
vint32m1_t __riscv_vsext_vf2_tu (vint32m1_t maskedoff, vint16mf2_t op1, size_t vl);
vint32m2_t __riscv_vsext_vf2_tu (vint32m2_t maskedoff, vint16m1_t op1, size_t vl);
vint32m4_t __riscv_vsext_vf2_tu (vint32m4_t maskedoff, vint16m2_t op1, size_t vl);
vint32m8_t __riscv_vsext_vf2_tu (vint32m8_t maskedoff, vint16m4_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf4_tu (vint64m1_t maskedoff, vint16mf4_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf4_tu (vint64m2_t maskedoff, vint16mf2_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf4_tu (vint64m4_t maskedoff, vint16m1_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf4_tu (vint64m8_t maskedoff, vint16m2_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf2_tu (vint64m1_t maskedoff, vint32mf2_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf2_tu (vint64m2_t maskedoff, vint32m1_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf2_tu (vint64m4_t maskedoff, vint32m2_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf2_tu (vint64m8_t maskedoff, vint32m4_t op1, size_t vl);
vuint16mf4_t __riscv_vzext_vf2_tu (vuint16mf4_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint16mf2_t __riscv_vzext_vf2_tu (vuint16mf2_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint16m1_t __riscv_vzext_vf2_tu (vuint16m1_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint16m2_t __riscv_vzext_vf2_tu (vuint16m2_t maskedoff, vuint8m1_t op1, size_t vl);
vuint16m4_t __riscv_vzext_vf2_tu (vuint16m4_t maskedoff, vuint8m2_t op1, size_t vl);
vuint16m8_t __riscv_vzext_vf2_tu (vuint16m8_t maskedoff, vuint8m4_t op1, size_t vl);
vuint32mf2_t __riscv_vzext_vf4_tu (vuint32mf2_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint32m1_t __riscv_vzext_vf4_tu (vuint32m1_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint32m2_t __riscv_vzext_vf4_tu (vuint32m2_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint32m4_t __riscv_vzext_vf4_tu (vuint32m4_t maskedoff, vuint8m1_t op1, size_t vl);
vuint32m8_t __riscv_vzext_vf4_tu (vuint32m8_t maskedoff, vuint8m2_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf8_tu (vuint64m1_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf8_tu (vuint64m2_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf8_tu (vuint64m4_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf8_tu (vuint64m8_t maskedoff, vuint8m1_t op1, size_t vl);
vuint32mf2_t __riscv_vzext_vf2_tu (vuint32mf2_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint32m1_t __riscv_vzext_vf2_tu (vuint32m1_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint32m2_t __riscv_vzext_vf2_tu (vuint32m2_t maskedoff, vuint16m1_t op1, size_t vl);
vuint32m4_t __riscv_vzext_vf2_tu (vuint32m4_t maskedoff, vuint16m2_t op1, size_t vl);
vuint32m8_t __riscv_vzext_vf2_tu (vuint32m8_t maskedoff, vuint16m4_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf4_tu (vuint64m1_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf4_tu (vuint64m2_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf4_tu (vuint64m4_t maskedoff, vuint16m1_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf4_tu (vuint64m8_t maskedoff, vuint16m2_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf2_tu (vuint64m1_t maskedoff, vuint32mf2_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf2_tu (vuint64m2_t maskedoff, vuint32m1_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf2_tu (vuint64m4_t maskedoff, vuint32m2_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf2_tu (vuint64m8_t maskedoff, vuint32m4_t op1, size_t vl);
// masked functions
vint16mf4_t __riscv_vsext_vf2_tum (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, size_t vl);
vint16mf2_t __riscv_vsext_vf2_tum (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, size_t vl);
vint16m1_t __riscv_vsext_vf2_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, size_t vl);
vint16m2_t __riscv_vsext_vf2_tum (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, size_t vl);
vint16m4_t __riscv_vsext_vf2_tum (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, size_t vl);
vint16m8_t __riscv_vsext_vf2_tum (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, size_t vl);
vint32mf2_t __riscv_vsext_vf4_tum (vbool64_t mask, vint32mf2_t maskedoff, vint8mf8_t op1, size_t vl);
vint32m1_t __riscv_vsext_vf4_tum (vbool32_t mask, vint32m1_t maskedoff, vint8mf4_t op1, size_t vl);
vint32m2_t __riscv_vsext_vf4_tum (vbool16_t mask, vint32m2_t maskedoff, vint8mf2_t op1, size_t vl);
vint32m4_t __riscv_vsext_vf4_tum (vbool8_t mask, vint32m4_t maskedoff, vint8m1_t op1, size_t vl);
vint32m8_t __riscv_vsext_vf4_tum (vbool4_t mask, vint32m8_t maskedoff, vint8m2_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf8_tum (vbool64_t mask, vint64m1_t maskedoff, vint8mf8_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf8_tum (vbool32_t mask, vint64m2_t maskedoff, vint8mf4_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf8_tum (vbool16_t mask, vint64m4_t maskedoff, vint8mf2_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf8_tum (vbool8_t mask, vint64m8_t maskedoff, vint8m1_t op1, size_t vl);
vint32mf2_t __riscv_vsext_vf2_tum (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, size_t vl);
vint32m1_t __riscv_vsext_vf2_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, size_t vl);
vint32m2_t __riscv_vsext_vf2_tum (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, size_t vl);
vint32m4_t __riscv_vsext_vf2_tum (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, size_t vl);
vint32m8_t __riscv_vsext_vf2_tum (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf4_tum (vbool64_t mask, vint64m1_t maskedoff, vint16mf4_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf4_tum (vbool32_t mask, vint64m2_t maskedoff, vint16mf2_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf4_tum (vbool16_t mask, vint64m4_t maskedoff, vint16m1_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf4_tum (vbool8_t mask, vint64m8_t maskedoff, vint16m2_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf2_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf2_tum (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf2_tum (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf2_tum (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, size_t vl);
vuint16mf4_t __riscv_vzext_vf2_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint16mf2_t __riscv_vzext_vf2_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint16m1_t __riscv_vzext_vf2_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint16m2_t __riscv_vzext_vf2_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, size_t vl);
vuint16m4_t __riscv_vzext_vf2_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, size_t vl);
vuint16m8_t __riscv_vzext_vf2_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, size_t vl);
vuint32mf2_t __riscv_vzext_vf4_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint32m1_t __riscv_vzext_vf4_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint32m2_t __riscv_vzext_vf4_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint32m4_t __riscv_vzext_vf4_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint8m1_t op1, size_t vl);
vuint32m8_t __riscv_vzext_vf4_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint8m2_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf8_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf8_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf8_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf8_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint8m1_t op1, size_t vl);
vuint32mf2_t __riscv_vzext_vf2_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint32m1_t __riscv_vzext_vf2_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint32m2_t __riscv_vzext_vf2_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, size_t vl);
vuint32m4_t __riscv_vzext_vf2_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, size_t vl);
vuint32m8_t __riscv_vzext_vf2_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf4_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf4_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf4_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint16m1_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf4_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint16m2_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf2_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf2_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf2_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf2_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, size_t vl);
// masked functions
vint16mf4_t __riscv_vsext_vf2_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, size_t vl);
vint16mf2_t __riscv_vsext_vf2_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, size_t vl);
vint16m1_t __riscv_vsext_vf2_tumu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, size_t vl);
vint16m2_t __riscv_vsext_vf2_tumu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, size_t vl);
vint16m4_t __riscv_vsext_vf2_tumu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, size_t vl);
vint16m8_t __riscv_vsext_vf2_tumu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, size_t vl);
vint32mf2_t __riscv_vsext_vf4_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint8mf8_t op1, size_t vl);
vint32m1_t __riscv_vsext_vf4_tumu (vbool32_t mask, vint32m1_t maskedoff, vint8mf4_t op1, size_t vl);
vint32m2_t __riscv_vsext_vf4_tumu (vbool16_t mask, vint32m2_t maskedoff, vint8mf2_t op1, size_t vl);
vint32m4_t __riscv_vsext_vf4_tumu (vbool8_t mask, vint32m4_t maskedoff, vint8m1_t op1, size_t vl);
vint32m8_t __riscv_vsext_vf4_tumu (vbool4_t mask, vint32m8_t maskedoff, vint8m2_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf8_tumu (vbool64_t mask, vint64m1_t maskedoff, vint8mf8_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf8_tumu (vbool32_t mask, vint64m2_t maskedoff, vint8mf4_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf8_tumu (vbool16_t mask, vint64m4_t maskedoff, vint8mf2_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf8_tumu (vbool8_t mask, vint64m8_t maskedoff, vint8m1_t op1, size_t vl);
vint32mf2_t __riscv_vsext_vf2_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, size_t vl);
vint32m1_t __riscv_vsext_vf2_tumu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, size_t vl);
vint32m2_t __riscv_vsext_vf2_tumu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, size_t vl);
vint32m4_t __riscv_vsext_vf2_tumu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, size_t vl);
vint32m8_t __riscv_vsext_vf2_tumu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf4_tumu (vbool64_t mask, vint64m1_t maskedoff, vint16mf4_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf4_tumu (vbool32_t mask, vint64m2_t maskedoff, vint16mf2_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf4_tumu (vbool16_t mask, vint64m4_t maskedoff, vint16m1_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf4_tumu (vbool8_t mask, vint64m8_t maskedoff, vint16m2_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf2_tumu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf2_tumu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf2_tumu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf2_tumu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, size_t vl);
vuint16mf4_t __riscv_vzext_vf2_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint16mf2_t __riscv_vzext_vf2_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint16m1_t __riscv_vzext_vf2_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint16m2_t __riscv_vzext_vf2_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, size_t vl);
vuint16m4_t __riscv_vzext_vf2_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, size_t vl);
vuint16m8_t __riscv_vzext_vf2_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, size_t vl);
vuint32mf2_t __riscv_vzext_vf4_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint32m1_t __riscv_vzext_vf4_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint32m2_t __riscv_vzext_vf4_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint32m4_t __riscv_vzext_vf4_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint8m1_t op1, size_t vl);
vuint32m8_t __riscv_vzext_vf4_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint8m2_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf8_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf8_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf8_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf8_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint8m1_t op1, size_t vl);
vuint32mf2_t __riscv_vzext_vf2_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint32m1_t __riscv_vzext_vf2_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint32m2_t __riscv_vzext_vf2_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, size_t vl);
vuint32m4_t __riscv_vzext_vf2_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, size_t vl);
vuint32m8_t __riscv_vzext_vf2_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf4_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf4_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf4_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint16m1_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf4_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint16m2_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf2_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf2_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf2_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf2_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, size_t vl);
// masked functions
vint16mf4_t __riscv_vsext_vf2_mu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, size_t vl);
vint16mf2_t __riscv_vsext_vf2_mu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, size_t vl);
vint16m1_t __riscv_vsext_vf2_mu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, size_t vl);
vint16m2_t __riscv_vsext_vf2_mu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, size_t vl);
vint16m4_t __riscv_vsext_vf2_mu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, size_t vl);
vint16m8_t __riscv_vsext_vf2_mu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, size_t vl);
vint32mf2_t __riscv_vsext_vf4_mu (vbool64_t mask, vint32mf2_t maskedoff, vint8mf8_t op1, size_t vl);
vint32m1_t __riscv_vsext_vf4_mu (vbool32_t mask, vint32m1_t maskedoff, vint8mf4_t op1, size_t vl);
vint32m2_t __riscv_vsext_vf4_mu (vbool16_t mask, vint32m2_t maskedoff, vint8mf2_t op1, size_t vl);
vint32m4_t __riscv_vsext_vf4_mu (vbool8_t mask, vint32m4_t maskedoff, vint8m1_t op1, size_t vl);
vint32m8_t __riscv_vsext_vf4_mu (vbool4_t mask, vint32m8_t maskedoff, vint8m2_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf8_mu (vbool64_t mask, vint64m1_t maskedoff, vint8mf8_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf8_mu (vbool32_t mask, vint64m2_t maskedoff, vint8mf4_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf8_mu (vbool16_t mask, vint64m4_t maskedoff, vint8mf2_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf8_mu (vbool8_t mask, vint64m8_t maskedoff, vint8m1_t op1, size_t vl);
vint32mf2_t __riscv_vsext_vf2_mu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, size_t vl);
vint32m1_t __riscv_vsext_vf2_mu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, size_t vl);
vint32m2_t __riscv_vsext_vf2_mu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, size_t vl);
vint32m4_t __riscv_vsext_vf2_mu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, size_t vl);
vint32m8_t __riscv_vsext_vf2_mu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf4_mu (vbool64_t mask, vint64m1_t maskedoff, vint16mf4_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf4_mu (vbool32_t mask, vint64m2_t maskedoff, vint16mf2_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf4_mu (vbool16_t mask, vint64m4_t maskedoff, vint16m1_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf4_mu (vbool8_t mask, vint64m8_t maskedoff, vint16m2_t op1, size_t vl);
vint64m1_t __riscv_vsext_vf2_mu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, size_t vl);
vint64m2_t __riscv_vsext_vf2_mu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, size_t vl);
vint64m4_t __riscv_vsext_vf2_mu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, size_t vl);
vint64m8_t __riscv_vsext_vf2_mu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, size_t vl);
vuint16mf4_t __riscv_vzext_vf2_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint16mf2_t __riscv_vzext_vf2_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint16m1_t __riscv_vzext_vf2_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint16m2_t __riscv_vzext_vf2_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, size_t vl);
vuint16m4_t __riscv_vzext_vf2_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, size_t vl);
vuint16m8_t __riscv_vzext_vf2_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, size_t vl);
vuint32mf2_t __riscv_vzext_vf4_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint32m1_t __riscv_vzext_vf4_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint32m2_t __riscv_vzext_vf4_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint32m4_t __riscv_vzext_vf4_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint8m1_t op1, size_t vl);
vuint32m8_t __riscv_vzext_vf4_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint8m2_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf8_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf8_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf8_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf8_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint8m1_t op1, size_t vl);
vuint32mf2_t __riscv_vzext_vf2_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint32m1_t __riscv_vzext_vf2_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint32m2_t __riscv_vzext_vf2_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, size_t vl);
vuint32m4_t __riscv_vzext_vf2_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, size_t vl);
vuint32m8_t __riscv_vzext_vf2_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf4_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf4_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf4_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint16m1_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf4_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint16m2_t op1, size_t vl);
vuint64m1_t __riscv_vzext_vf2_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, size_t vl);
vuint64m2_t __riscv_vzext_vf2_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, size_t vl);
vuint64m4_t __riscv_vzext_vf2_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, size_t vl);
vuint64m8_t __riscv_vzext_vf2_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, size_t vl);
```

[[policy-variant-overloadedvector-integer-add-with-carry-subtract-with-borrow]]
=== Vector Integer Add-with-Carry / Subtract-with-Borrow Intrinsics

``` C
vint8mf8_t __riscv_vadc_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, vbool64_t carryin, size_t vl);
vint8mf8_t __riscv_vadc_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, vbool64_t carryin, size_t vl);
vint8mf4_t __riscv_vadc_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, vbool32_t carryin, size_t vl);
vint8mf4_t __riscv_vadc_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, vbool32_t carryin, size_t vl);
vint8mf2_t __riscv_vadc_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, vbool16_t carryin, size_t vl);
vint8mf2_t __riscv_vadc_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, vbool16_t carryin, size_t vl);
vint8m1_t __riscv_vadc_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, vbool8_t carryin, size_t vl);
vint8m1_t __riscv_vadc_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, vbool8_t carryin, size_t vl);
vint8m2_t __riscv_vadc_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, vbool4_t carryin, size_t vl);
vint8m2_t __riscv_vadc_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, vbool4_t carryin, size_t vl);
vint8m4_t __riscv_vadc_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, vbool2_t carryin, size_t vl);
vint8m4_t __riscv_vadc_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, vbool2_t carryin, size_t vl);
vint8m8_t __riscv_vadc_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, vbool1_t carryin, size_t vl);
vint8m8_t __riscv_vadc_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, vbool1_t carryin, size_t vl);
vint16mf4_t __riscv_vadc_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, vbool64_t carryin, size_t vl);
vint16mf4_t __riscv_vadc_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, vbool64_t carryin, size_t vl);
vint16mf2_t __riscv_vadc_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, vbool32_t carryin, size_t vl);
vint16mf2_t __riscv_vadc_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, vbool32_t carryin, size_t vl);
vint16m1_t __riscv_vadc_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, vbool16_t carryin, size_t vl);
vint16m1_t __riscv_vadc_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, vbool16_t carryin, size_t vl);
vint16m2_t __riscv_vadc_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, vbool8_t carryin, size_t vl);
vint16m2_t __riscv_vadc_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, vbool8_t carryin, size_t vl);
vint16m4_t __riscv_vadc_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, vbool4_t carryin, size_t vl);
vint16m4_t __riscv_vadc_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, vbool4_t carryin, size_t vl);
vint16m8_t __riscv_vadc_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, vbool2_t carryin, size_t vl);
vint16m8_t __riscv_vadc_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, vbool2_t carryin, size_t vl);
vint32mf2_t __riscv_vadc_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, vbool64_t carryin, size_t vl);
vint32mf2_t __riscv_vadc_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, vbool64_t carryin, size_t vl);
vint32m1_t __riscv_vadc_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, vbool32_t carryin, size_t vl);
vint32m1_t __riscv_vadc_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, vbool32_t carryin, size_t vl);
vint32m2_t __riscv_vadc_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, vbool16_t carryin, size_t vl);
vint32m2_t __riscv_vadc_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, vbool16_t carryin, size_t vl);
vint32m4_t __riscv_vadc_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, vbool8_t carryin, size_t vl);
vint32m4_t __riscv_vadc_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, vbool8_t carryin, size_t vl);
vint32m8_t __riscv_vadc_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, vbool4_t carryin, size_t vl);
vint32m8_t __riscv_vadc_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, vbool4_t carryin, size_t vl);
vint64m1_t __riscv_vadc_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, vbool64_t carryin, size_t vl);
vint64m1_t __riscv_vadc_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, vbool64_t carryin, size_t vl);
vint64m2_t __riscv_vadc_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, vbool32_t carryin, size_t vl);
vint64m2_t __riscv_vadc_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, vbool32_t carryin, size_t vl);
vint64m4_t __riscv_vadc_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, vbool16_t carryin, size_t vl);
vint64m4_t __riscv_vadc_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, vbool16_t carryin, size_t vl);
vint64m8_t __riscv_vadc_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, vbool8_t carryin, size_t vl);
vint64m8_t __riscv_vadc_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, vbool8_t carryin, size_t vl);
vint8mf8_t __riscv_vsbc_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, vbool64_t borrowin, size_t vl);
vint8mf8_t __riscv_vsbc_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, vbool64_t borrowin, size_t vl);
vint8mf4_t __riscv_vsbc_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, vbool32_t borrowin, size_t vl);
vint8mf4_t __riscv_vsbc_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, vbool32_t borrowin, size_t vl);
vint8mf2_t __riscv_vsbc_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, vbool16_t borrowin, size_t vl);
vint8mf2_t __riscv_vsbc_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, vbool16_t borrowin, size_t vl);
vint8m1_t __riscv_vsbc_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, vbool8_t borrowin, size_t vl);
vint8m1_t __riscv_vsbc_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, vbool8_t borrowin, size_t vl);
vint8m2_t __riscv_vsbc_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, vbool4_t borrowin, size_t vl);
vint8m2_t __riscv_vsbc_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, vbool4_t borrowin, size_t vl);
vint8m4_t __riscv_vsbc_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, vbool2_t borrowin, size_t vl);
vint8m4_t __riscv_vsbc_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, vbool2_t borrowin, size_t vl);
vint8m8_t __riscv_vsbc_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, vbool1_t borrowin, size_t vl);
vint8m8_t __riscv_vsbc_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, vbool1_t borrowin, size_t vl);
vint16mf4_t __riscv_vsbc_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, vbool64_t borrowin, size_t vl);
vint16mf4_t __riscv_vsbc_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, vbool64_t borrowin, size_t vl);
vint16mf2_t __riscv_vsbc_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, vbool32_t borrowin, size_t vl);
vint16mf2_t __riscv_vsbc_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, vbool32_t borrowin, size_t vl);
vint16m1_t __riscv_vsbc_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, vbool16_t borrowin, size_t vl);
vint16m1_t __riscv_vsbc_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, vbool16_t borrowin, size_t vl);
vint16m2_t __riscv_vsbc_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, vbool8_t borrowin, size_t vl);
vint16m2_t __riscv_vsbc_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, vbool8_t borrowin, size_t vl);
vint16m4_t __riscv_vsbc_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, vbool4_t borrowin, size_t vl);
vint16m4_t __riscv_vsbc_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, vbool4_t borrowin, size_t vl);
vint16m8_t __riscv_vsbc_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, vbool2_t borrowin, size_t vl);
vint16m8_t __riscv_vsbc_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, vbool2_t borrowin, size_t vl);
vint32mf2_t __riscv_vsbc_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, vbool64_t borrowin, size_t vl);
vint32mf2_t __riscv_vsbc_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, vbool64_t borrowin, size_t vl);
vint32m1_t __riscv_vsbc_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, vbool32_t borrowin, size_t vl);
vint32m1_t __riscv_vsbc_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, vbool32_t borrowin, size_t vl);
vint32m2_t __riscv_vsbc_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, vbool16_t borrowin, size_t vl);
vint32m2_t __riscv_vsbc_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, vbool16_t borrowin, size_t vl);
vint32m4_t __riscv_vsbc_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, vbool8_t borrowin, size_t vl);
vint32m4_t __riscv_vsbc_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, vbool8_t borrowin, size_t vl);
vint32m8_t __riscv_vsbc_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, vbool4_t borrowin, size_t vl);
vint32m8_t __riscv_vsbc_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, vbool4_t borrowin, size_t vl);
vint64m1_t __riscv_vsbc_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, vbool64_t borrowin, size_t vl);
vint64m1_t __riscv_vsbc_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, vbool64_t borrowin, size_t vl);
vint64m2_t __riscv_vsbc_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, vbool32_t borrowin, size_t vl);
vint64m2_t __riscv_vsbc_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, vbool32_t borrowin, size_t vl);
vint64m4_t __riscv_vsbc_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, vbool16_t borrowin, size_t vl);
vint64m4_t __riscv_vsbc_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, vbool16_t borrowin, size_t vl);
vint64m8_t __riscv_vsbc_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, vbool8_t borrowin, size_t vl);
vint64m8_t __riscv_vsbc_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, vbool8_t borrowin, size_t vl);
vuint8mf8_t __riscv_vadc_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, vbool64_t carryin, size_t vl);
vuint8mf8_t __riscv_vadc_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, vbool64_t carryin, size_t vl);
vuint8mf4_t __riscv_vadc_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, vbool32_t carryin, size_t vl);
vuint8mf4_t __riscv_vadc_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, vbool32_t carryin, size_t vl);
vuint8mf2_t __riscv_vadc_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, vbool16_t carryin, size_t vl);
vuint8mf2_t __riscv_vadc_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, vbool16_t carryin, size_t vl);
vuint8m1_t __riscv_vadc_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, vbool8_t carryin, size_t vl);
vuint8m1_t __riscv_vadc_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, vbool8_t carryin, size_t vl);
vuint8m2_t __riscv_vadc_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, vbool4_t carryin, size_t vl);
vuint8m2_t __riscv_vadc_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, vbool4_t carryin, size_t vl);
vuint8m4_t __riscv_vadc_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, vbool2_t carryin, size_t vl);
vuint8m4_t __riscv_vadc_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, vbool2_t carryin, size_t vl);
vuint8m8_t __riscv_vadc_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, vbool1_t carryin, size_t vl);
vuint8m8_t __riscv_vadc_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, vbool1_t carryin, size_t vl);
vuint16mf4_t __riscv_vadc_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, vbool64_t carryin, size_t vl);
vuint16mf4_t __riscv_vadc_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, vbool64_t carryin, size_t vl);
vuint16mf2_t __riscv_vadc_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, vbool32_t carryin, size_t vl);
vuint16mf2_t __riscv_vadc_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, vbool32_t carryin, size_t vl);
vuint16m1_t __riscv_vadc_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, vbool16_t carryin, size_t vl);
vuint16m1_t __riscv_vadc_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, vbool16_t carryin, size_t vl);
vuint16m2_t __riscv_vadc_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, vbool8_t carryin, size_t vl);
vuint16m2_t __riscv_vadc_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, vbool8_t carryin, size_t vl);
vuint16m4_t __riscv_vadc_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, vbool4_t carryin, size_t vl);
vuint16m4_t __riscv_vadc_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, vbool4_t carryin, size_t vl);
vuint16m8_t __riscv_vadc_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, vbool2_t carryin, size_t vl);
vuint16m8_t __riscv_vadc_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, vbool2_t carryin, size_t vl);
vuint32mf2_t __riscv_vadc_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, vbool64_t carryin, size_t vl);
vuint32mf2_t __riscv_vadc_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, vbool64_t carryin, size_t vl);
vuint32m1_t __riscv_vadc_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, vbool32_t carryin, size_t vl);
vuint32m1_t __riscv_vadc_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, vbool32_t carryin, size_t vl);
vuint32m2_t __riscv_vadc_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, vbool16_t carryin, size_t vl);
vuint32m2_t __riscv_vadc_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, vbool16_t carryin, size_t vl);
vuint32m4_t __riscv_vadc_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, vbool8_t carryin, size_t vl);
vuint32m4_t __riscv_vadc_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, vbool8_t carryin, size_t vl);
vuint32m8_t __riscv_vadc_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, vbool4_t carryin, size_t vl);
vuint32m8_t __riscv_vadc_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, vbool4_t carryin, size_t vl);
vuint64m1_t __riscv_vadc_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, vbool64_t carryin, size_t vl);
vuint64m1_t __riscv_vadc_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, vbool64_t carryin, size_t vl);
vuint64m2_t __riscv_vadc_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, vbool32_t carryin, size_t vl);
vuint64m2_t __riscv_vadc_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, vbool32_t carryin, size_t vl);
vuint64m4_t __riscv_vadc_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, vbool16_t carryin, size_t vl);
vuint64m4_t __riscv_vadc_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, vbool16_t carryin, size_t vl);
vuint64m8_t __riscv_vadc_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, vbool8_t carryin, size_t vl);
vuint64m8_t __riscv_vadc_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, vbool8_t carryin, size_t vl);
vuint8mf8_t __riscv_vsbc_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, vbool64_t borrowin, size_t vl);
vuint8mf8_t __riscv_vsbc_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, vbool64_t borrowin, size_t vl);
vuint8mf4_t __riscv_vsbc_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, vbool32_t borrowin, size_t vl);
vuint8mf4_t __riscv_vsbc_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, vbool32_t borrowin, size_t vl);
vuint8mf2_t __riscv_vsbc_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, vbool16_t borrowin, size_t vl);
vuint8mf2_t __riscv_vsbc_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, vbool16_t borrowin, size_t vl);
vuint8m1_t __riscv_vsbc_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, vbool8_t borrowin, size_t vl);
vuint8m1_t __riscv_vsbc_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, vbool8_t borrowin, size_t vl);
vuint8m2_t __riscv_vsbc_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, vbool4_t borrowin, size_t vl);
vuint8m2_t __riscv_vsbc_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, vbool4_t borrowin, size_t vl);
vuint8m4_t __riscv_vsbc_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, vbool2_t borrowin, size_t vl);
vuint8m4_t __riscv_vsbc_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, vbool2_t borrowin, size_t vl);
vuint8m8_t __riscv_vsbc_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, vbool1_t borrowin, size_t vl);
vuint8m8_t __riscv_vsbc_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, vbool1_t borrowin, size_t vl);
vuint16mf4_t __riscv_vsbc_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, vbool64_t borrowin, size_t vl);
vuint16mf4_t __riscv_vsbc_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, vbool64_t borrowin, size_t vl);
vuint16mf2_t __riscv_vsbc_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, vbool32_t borrowin, size_t vl);
vuint16mf2_t __riscv_vsbc_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, vbool32_t borrowin, size_t vl);
vuint16m1_t __riscv_vsbc_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, vbool16_t borrowin, size_t vl);
vuint16m1_t __riscv_vsbc_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, vbool16_t borrowin, size_t vl);
vuint16m2_t __riscv_vsbc_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, vbool8_t borrowin, size_t vl);
vuint16m2_t __riscv_vsbc_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, vbool8_t borrowin, size_t vl);
vuint16m4_t __riscv_vsbc_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, vbool4_t borrowin, size_t vl);
vuint16m4_t __riscv_vsbc_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, vbool4_t borrowin, size_t vl);
vuint16m8_t __riscv_vsbc_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, vbool2_t borrowin, size_t vl);
vuint16m8_t __riscv_vsbc_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, vbool2_t borrowin, size_t vl);
vuint32mf2_t __riscv_vsbc_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, vbool64_t borrowin, size_t vl);
vuint32mf2_t __riscv_vsbc_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, vbool64_t borrowin, size_t vl);
vuint32m1_t __riscv_vsbc_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, vbool32_t borrowin, size_t vl);
vuint32m1_t __riscv_vsbc_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, vbool32_t borrowin, size_t vl);
vuint32m2_t __riscv_vsbc_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, vbool16_t borrowin, size_t vl);
vuint32m2_t __riscv_vsbc_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, vbool16_t borrowin, size_t vl);
vuint32m4_t __riscv_vsbc_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, vbool8_t borrowin, size_t vl);
vuint32m4_t __riscv_vsbc_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, vbool8_t borrowin, size_t vl);
vuint32m8_t __riscv_vsbc_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, vbool4_t borrowin, size_t vl);
vuint32m8_t __riscv_vsbc_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, vbool4_t borrowin, size_t vl);
vuint64m1_t __riscv_vsbc_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, vbool64_t borrowin, size_t vl);
vuint64m1_t __riscv_vsbc_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, vbool64_t borrowin, size_t vl);
vuint64m2_t __riscv_vsbc_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, vbool32_t borrowin, size_t vl);
vuint64m2_t __riscv_vsbc_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, vbool32_t borrowin, size_t vl);
vuint64m4_t __riscv_vsbc_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, vbool16_t borrowin, size_t vl);
vuint64m4_t __riscv_vsbc_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, vbool16_t borrowin, size_t vl);
vuint64m8_t __riscv_vsbc_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, vbool8_t borrowin, size_t vl);
vuint64m8_t __riscv_vsbc_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, vbool8_t borrowin, size_t vl);
```

[[policy-variant-overloadedvector-integer-carry-out-borrow-out]]
=== Vector Integer Carry-out / Borrow-out Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-bitwise-binary-logical]]
=== Vector Bitwise Binary Logical Intrinsics

``` C
vint8mf8_t __riscv_vand_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vand_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vand_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vand_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vand_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vand_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vand_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vand_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vand_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vand_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vand_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vand_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vand_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vand_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vand_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vand_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vand_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vand_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vand_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vand_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vand_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vand_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vand_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vand_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vand_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vand_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vand_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vand_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vand_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vand_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vand_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vand_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vand_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vand_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vand_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vand_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vand_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vand_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vand_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vand_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vand_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vand_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vand_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vand_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vor_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vor_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vor_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vor_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vor_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vor_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vor_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vor_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vor_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vor_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vor_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vor_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vor_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vor_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vor_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vor_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vor_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vor_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vor_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vor_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vor_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vor_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vor_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vor_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vor_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vor_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vor_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vor_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vor_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vor_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vor_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vor_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vor_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vor_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vor_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vor_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vor_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vor_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vor_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vor_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vor_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vor_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vor_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vor_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vxor_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vxor_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vxor_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vxor_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vxor_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vxor_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vxor_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vxor_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vxor_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vxor_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vxor_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vxor_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vxor_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vxor_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vxor_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vxor_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vxor_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vxor_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vxor_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vxor_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vxor_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vxor_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vxor_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vxor_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vxor_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vxor_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vxor_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vxor_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vxor_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vxor_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vxor_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vxor_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vxor_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vxor_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vxor_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vxor_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vxor_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vxor_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vxor_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vxor_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vxor_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vxor_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vxor_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vxor_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vand_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vand_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vand_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vand_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vand_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vand_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vand_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vand_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vand_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vand_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vand_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vand_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vand_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vand_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vand_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vand_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vand_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vand_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vand_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vand_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vand_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vand_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vand_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vand_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vand_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vand_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vand_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vand_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vand_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vand_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vand_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vand_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vand_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vand_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vand_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vand_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vand_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vand_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vand_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vand_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vand_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vand_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vand_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vand_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vor_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vor_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vor_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vor_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vor_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vor_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vor_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vor_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vor_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vor_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vor_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vor_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vor_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vor_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vor_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vor_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vor_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vor_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vor_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vor_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vor_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vor_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vor_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vor_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vor_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vor_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vor_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vor_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vor_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vor_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vor_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vor_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vor_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vor_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vor_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vor_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vor_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vor_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vor_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vor_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vor_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vor_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vor_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vor_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vxor_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vxor_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vxor_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vxor_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vxor_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vxor_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vxor_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vxor_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vxor_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vxor_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vxor_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vxor_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vxor_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vxor_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vxor_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vxor_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vxor_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vxor_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vxor_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vxor_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vxor_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vxor_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vxor_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vxor_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vxor_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vxor_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vxor_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vxor_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vxor_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vxor_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vxor_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vxor_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vxor_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vxor_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vxor_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vxor_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vxor_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vxor_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vxor_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vxor_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vxor_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vxor_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vxor_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vxor_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vand_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vand_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vand_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vand_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vand_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vand_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vand_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vand_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vand_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vand_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vand_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vand_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vand_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vand_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vand_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vand_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vand_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vand_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vand_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vand_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vand_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vand_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vand_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vand_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vand_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vand_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vand_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vand_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vand_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vand_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vand_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vand_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vand_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vand_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vand_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vand_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vand_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vand_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vand_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vand_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vand_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vand_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vand_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vand_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vor_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vor_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vor_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vor_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vor_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vor_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vor_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vor_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vor_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vor_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vor_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vor_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vor_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vor_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vor_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vor_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vor_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vor_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vor_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vor_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vor_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vor_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vor_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vor_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vor_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vor_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vor_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vor_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vor_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vor_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vor_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vor_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vor_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vor_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vor_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vor_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vor_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vor_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vor_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vor_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vor_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vor_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vor_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vor_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vxor_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vxor_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vxor_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vxor_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vxor_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vxor_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vxor_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vxor_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vxor_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vxor_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vxor_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vxor_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vxor_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vxor_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vxor_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vxor_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vxor_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vxor_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vxor_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vxor_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vxor_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vxor_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vxor_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vxor_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vxor_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vxor_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vxor_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vxor_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vxor_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vxor_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vxor_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vxor_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vxor_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vxor_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vxor_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vxor_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vxor_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vxor_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vxor_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vxor_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vxor_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vxor_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vxor_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vxor_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vand_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vand_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vand_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vand_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vand_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vand_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vand_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vand_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vand_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vand_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vand_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vand_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vand_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vand_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vand_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vand_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vand_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vand_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vand_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vand_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vand_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vand_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vand_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vand_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vand_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vand_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vand_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vand_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vand_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vand_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vand_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vand_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vand_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vand_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vand_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vand_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vand_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vand_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vand_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vand_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vand_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vand_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vand_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vand_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vor_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vor_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vor_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vor_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vor_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vor_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vor_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vor_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vor_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vor_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vor_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vor_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vor_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vor_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vor_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vor_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vor_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vor_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vor_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vor_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vor_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vor_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vor_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vor_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vor_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vor_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vor_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vor_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vor_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vor_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vor_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vor_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vor_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vor_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vor_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vor_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vor_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vor_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vor_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vor_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vor_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vor_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vor_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vor_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vxor_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vxor_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vxor_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vxor_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vxor_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vxor_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vxor_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vxor_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vxor_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vxor_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vxor_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vxor_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vxor_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vxor_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vxor_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vxor_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vxor_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vxor_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vxor_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vxor_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vxor_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vxor_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vxor_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vxor_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vxor_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vxor_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vxor_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vxor_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vxor_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vxor_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vxor_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vxor_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vxor_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vxor_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vxor_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vxor_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vxor_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vxor_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vxor_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vxor_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vxor_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vxor_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vxor_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vxor_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vand_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vand_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vand_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vand_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vand_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vand_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vand_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vand_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vand_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vand_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vand_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vand_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vand_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vand_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vand_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vand_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vand_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vand_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vand_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vand_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vand_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vand_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vand_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vand_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vand_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vand_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vand_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vand_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vand_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vand_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vand_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vand_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vand_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vand_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vand_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vand_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vand_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vand_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vand_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vand_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vand_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vand_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vand_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vand_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vor_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vor_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vor_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vor_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vor_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vor_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vor_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vor_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vor_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vor_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vor_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vor_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vor_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vor_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vor_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vor_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vor_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vor_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vor_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vor_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vor_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vor_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vor_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vor_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vor_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vor_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vor_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vor_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vor_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vor_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vor_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vor_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vor_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vor_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vor_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vor_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vor_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vor_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vor_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vor_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vor_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vor_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vor_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vor_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vxor_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vxor_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vxor_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vxor_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vxor_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vxor_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vxor_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vxor_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vxor_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vxor_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vxor_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vxor_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vxor_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vxor_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vxor_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vxor_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vxor_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vxor_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vxor_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vxor_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vxor_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vxor_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vxor_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vxor_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vxor_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vxor_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vxor_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vxor_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vxor_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vxor_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vxor_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vxor_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vxor_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vxor_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vxor_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vxor_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vxor_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vxor_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vxor_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vxor_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vxor_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vxor_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vxor_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vxor_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vand_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vand_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vand_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vand_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vand_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vand_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vand_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vand_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vand_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vand_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vand_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vand_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vand_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vand_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vand_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vand_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vand_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vand_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vand_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vand_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vand_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vand_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vand_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vand_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vand_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vand_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vand_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vand_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vand_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vand_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vand_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vand_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vand_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vand_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vand_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vand_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vand_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vand_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vand_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vand_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vand_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vand_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vand_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vand_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vor_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vor_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vor_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vor_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vor_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vor_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vor_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vor_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vor_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vor_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vor_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vor_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vor_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vor_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vor_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vor_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vor_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vor_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vor_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vor_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vor_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vor_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vor_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vor_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vor_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vor_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vor_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vor_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vor_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vor_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vor_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vor_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vor_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vor_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vor_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vor_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vor_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vor_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vor_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vor_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vor_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vor_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vor_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vor_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vxor_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vxor_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vxor_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vxor_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vxor_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vxor_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vxor_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vxor_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vxor_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vxor_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vxor_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vxor_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vxor_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vxor_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vxor_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vxor_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vxor_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vxor_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vxor_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vxor_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vxor_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vxor_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vxor_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vxor_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vxor_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vxor_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vxor_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vxor_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vxor_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vxor_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vxor_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vxor_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vxor_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vxor_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vxor_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vxor_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vxor_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vxor_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vxor_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vxor_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vxor_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vxor_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vxor_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vxor_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vand_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vand_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vand_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vand_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vand_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vand_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vand_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vand_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vand_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vand_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vand_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vand_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vand_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vand_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vand_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vand_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vand_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vand_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vand_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vand_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vand_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vand_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vand_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vand_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vand_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vand_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vand_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vand_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vand_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vand_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vand_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vand_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vand_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vand_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vand_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vand_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vand_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vand_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vand_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vand_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vand_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vand_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vand_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vand_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vor_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vor_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vor_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vor_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vor_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vor_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vor_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vor_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vor_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vor_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vor_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vor_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vor_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vor_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vor_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vor_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vor_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vor_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vor_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vor_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vor_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vor_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vor_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vor_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vor_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vor_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vor_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vor_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vor_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vor_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vor_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vor_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vor_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vor_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vor_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vor_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vor_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vor_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vor_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vor_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vor_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vor_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vor_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vor_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vxor_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vxor_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vxor_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vxor_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vxor_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vxor_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vxor_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vxor_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vxor_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vxor_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vxor_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vxor_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vxor_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vxor_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vxor_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vxor_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vxor_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vxor_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vxor_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vxor_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vxor_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vxor_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vxor_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vxor_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vxor_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vxor_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vxor_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vxor_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vxor_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vxor_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vxor_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vxor_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vxor_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vxor_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vxor_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vxor_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vxor_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vxor_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vxor_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vxor_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vxor_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vxor_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vxor_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vxor_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vand_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vand_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vand_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vand_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vand_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vand_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vand_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vand_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vand_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vand_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vand_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vand_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vand_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vand_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vand_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vand_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vand_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vand_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vand_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vand_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vand_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vand_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vand_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vand_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vand_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vand_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vand_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vand_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vand_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vand_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vand_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vand_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vand_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vand_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vand_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vand_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vand_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vand_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vand_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vand_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vand_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vand_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vand_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vand_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vor_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vor_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vor_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vor_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vor_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vor_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vor_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vor_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vor_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vor_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vor_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vor_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vor_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vor_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vor_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vor_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vor_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vor_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vor_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vor_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vor_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vor_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vor_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vor_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vor_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vor_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vor_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vor_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vor_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vor_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vor_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vor_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vor_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vor_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vor_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vor_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vor_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vor_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vor_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vor_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vor_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vor_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vor_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vor_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vxor_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vxor_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vxor_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vxor_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vxor_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vxor_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vxor_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vxor_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vxor_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vxor_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vxor_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vxor_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vxor_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vxor_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vxor_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vxor_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vxor_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vxor_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vxor_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vxor_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vxor_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vxor_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vxor_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vxor_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vxor_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vxor_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vxor_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vxor_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vxor_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vxor_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vxor_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vxor_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vxor_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vxor_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vxor_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vxor_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vxor_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vxor_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vxor_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vxor_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vxor_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vxor_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vxor_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vxor_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
```

[[policy-variant-overloadedvector-bitwise-unary-logical]]
=== Vector Bitwise Unary Logical Intrinsics

``` C
vint8mf8_t __riscv_vnot_tu (vint8mf8_t maskedoff, vint8mf8_t op1, size_t vl);
vint8mf4_t __riscv_vnot_tu (vint8mf4_t maskedoff, vint8mf4_t op1, size_t vl);
vint8mf2_t __riscv_vnot_tu (vint8mf2_t maskedoff, vint8mf2_t op1, size_t vl);
vint8m1_t __riscv_vnot_tu (vint8m1_t maskedoff, vint8m1_t op1, size_t vl);
vint8m2_t __riscv_vnot_tu (vint8m2_t maskedoff, vint8m2_t op1, size_t vl);
vint8m4_t __riscv_vnot_tu (vint8m4_t maskedoff, vint8m4_t op1, size_t vl);
vint8m8_t __riscv_vnot_tu (vint8m8_t maskedoff, vint8m8_t op1, size_t vl);
vint16mf4_t __riscv_vnot_tu (vint16mf4_t maskedoff, vint16mf4_t op1, size_t vl);
vint16mf2_t __riscv_vnot_tu (vint16mf2_t maskedoff, vint16mf2_t op1, size_t vl);
vint16m1_t __riscv_vnot_tu (vint16m1_t maskedoff, vint16m1_t op1, size_t vl);
vint16m2_t __riscv_vnot_tu (vint16m2_t maskedoff, vint16m2_t op1, size_t vl);
vint16m4_t __riscv_vnot_tu (vint16m4_t maskedoff, vint16m4_t op1, size_t vl);
vint16m8_t __riscv_vnot_tu (vint16m8_t maskedoff, vint16m8_t op1, size_t vl);
vint32mf2_t __riscv_vnot_tu (vint32mf2_t maskedoff, vint32mf2_t op1, size_t vl);
vint32m1_t __riscv_vnot_tu (vint32m1_t maskedoff, vint32m1_t op1, size_t vl);
vint32m2_t __riscv_vnot_tu (vint32m2_t maskedoff, vint32m2_t op1, size_t vl);
vint32m4_t __riscv_vnot_tu (vint32m4_t maskedoff, vint32m4_t op1, size_t vl);
vint32m8_t __riscv_vnot_tu (vint32m8_t maskedoff, vint32m8_t op1, size_t vl);
vint64m1_t __riscv_vnot_tu (vint64m1_t maskedoff, vint64m1_t op1, size_t vl);
vint64m2_t __riscv_vnot_tu (vint64m2_t maskedoff, vint64m2_t op1, size_t vl);
vint64m4_t __riscv_vnot_tu (vint64m4_t maskedoff, vint64m4_t op1, size_t vl);
vint64m8_t __riscv_vnot_tu (vint64m8_t maskedoff, vint64m8_t op1, size_t vl);
vuint8mf8_t __riscv_vnot_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint8mf4_t __riscv_vnot_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint8mf2_t __riscv_vnot_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint8m1_t __riscv_vnot_tu (vuint8m1_t maskedoff, vuint8m1_t op1, size_t vl);
vuint8m2_t __riscv_vnot_tu (vuint8m2_t maskedoff, vuint8m2_t op1, size_t vl);
vuint8m4_t __riscv_vnot_tu (vuint8m4_t maskedoff, vuint8m4_t op1, size_t vl);
vuint8m8_t __riscv_vnot_tu (vuint8m8_t maskedoff, vuint8m8_t op1, size_t vl);
vuint16mf4_t __riscv_vnot_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint16mf2_t __riscv_vnot_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint16m1_t __riscv_vnot_tu (vuint16m1_t maskedoff, vuint16m1_t op1, size_t vl);
vuint16m2_t __riscv_vnot_tu (vuint16m2_t maskedoff, vuint16m2_t op1, size_t vl);
vuint16m4_t __riscv_vnot_tu (vuint16m4_t maskedoff, vuint16m4_t op1, size_t vl);
vuint16m8_t __riscv_vnot_tu (vuint16m8_t maskedoff, vuint16m8_t op1, size_t vl);
vuint32mf2_t __riscv_vnot_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t vl);
vuint32m1_t __riscv_vnot_tu (vuint32m1_t maskedoff, vuint32m1_t op1, size_t vl);
vuint32m2_t __riscv_vnot_tu (vuint32m2_t maskedoff, vuint32m2_t op1, size_t vl);
vuint32m4_t __riscv_vnot_tu (vuint32m4_t maskedoff, vuint32m4_t op1, size_t vl);
vuint32m8_t __riscv_vnot_tu (vuint32m8_t maskedoff, vuint32m8_t op1, size_t vl);
vuint64m1_t __riscv_vnot_tu (vuint64m1_t maskedoff, vuint64m1_t op1, size_t vl);
vuint64m2_t __riscv_vnot_tu (vuint64m2_t maskedoff, vuint64m2_t op1, size_t vl);
vuint64m4_t __riscv_vnot_tu (vuint64m4_t maskedoff, vuint64m4_t op1, size_t vl);
vuint64m8_t __riscv_vnot_tu (vuint64m8_t maskedoff, vuint64m8_t op1, size_t vl);
// masked functions
vint8mf8_t __riscv_vnot_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t vl);
vint8mf4_t __riscv_vnot_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t vl);
vint8mf2_t __riscv_vnot_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t vl);
vint8m1_t __riscv_vnot_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t vl);
vint8m2_t __riscv_vnot_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t vl);
vint8m4_t __riscv_vnot_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t vl);
vint8m8_t __riscv_vnot_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t vl);
vint16mf4_t __riscv_vnot_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t vl);
vint16mf2_t __riscv_vnot_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t vl);
vint16m1_t __riscv_vnot_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t vl);
vint16m2_t __riscv_vnot_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t vl);
vint16m4_t __riscv_vnot_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t vl);
vint16m8_t __riscv_vnot_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t vl);
vint32mf2_t __riscv_vnot_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t vl);
vint32m1_t __riscv_vnot_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t vl);
vint32m2_t __riscv_vnot_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t vl);
vint32m4_t __riscv_vnot_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t vl);
vint32m8_t __riscv_vnot_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t vl);
vint64m1_t __riscv_vnot_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t vl);
vint64m2_t __riscv_vnot_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t vl);
vint64m4_t __riscv_vnot_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t vl);
vint64m8_t __riscv_vnot_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t vl);
vuint8mf8_t __riscv_vnot_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint8mf4_t __riscv_vnot_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint8mf2_t __riscv_vnot_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint8m1_t __riscv_vnot_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t vl);
vuint8m2_t __riscv_vnot_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t vl);
vuint8m4_t __riscv_vnot_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t vl);
vuint8m8_t __riscv_vnot_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t vl);
vuint16mf4_t __riscv_vnot_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint16mf2_t __riscv_vnot_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint16m1_t __riscv_vnot_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t vl);
vuint16m2_t __riscv_vnot_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t vl);
vuint16m4_t __riscv_vnot_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t vl);
vuint16m8_t __riscv_vnot_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t vl);
vuint32mf2_t __riscv_vnot_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t vl);
vuint32m1_t __riscv_vnot_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t vl);
vuint32m2_t __riscv_vnot_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t vl);
vuint32m4_t __riscv_vnot_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t vl);
vuint32m8_t __riscv_vnot_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t vl);
vuint64m1_t __riscv_vnot_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t vl);
vuint64m2_t __riscv_vnot_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t vl);
vuint64m4_t __riscv_vnot_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t vl);
vuint64m8_t __riscv_vnot_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t vl);
// masked functions
vint8mf8_t __riscv_vnot_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t vl);
vint8mf4_t __riscv_vnot_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t vl);
vint8mf2_t __riscv_vnot_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t vl);
vint8m1_t __riscv_vnot_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t vl);
vint8m2_t __riscv_vnot_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t vl);
vint8m4_t __riscv_vnot_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t vl);
vint8m8_t __riscv_vnot_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t vl);
vint16mf4_t __riscv_vnot_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t vl);
vint16mf2_t __riscv_vnot_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t vl);
vint16m1_t __riscv_vnot_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t vl);
vint16m2_t __riscv_vnot_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t vl);
vint16m4_t __riscv_vnot_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t vl);
vint16m8_t __riscv_vnot_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t vl);
vint32mf2_t __riscv_vnot_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t vl);
vint32m1_t __riscv_vnot_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t vl);
vint32m2_t __riscv_vnot_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t vl);
vint32m4_t __riscv_vnot_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t vl);
vint32m8_t __riscv_vnot_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t vl);
vint64m1_t __riscv_vnot_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t vl);
vint64m2_t __riscv_vnot_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t vl);
vint64m4_t __riscv_vnot_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t vl);
vint64m8_t __riscv_vnot_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t vl);
vuint8mf8_t __riscv_vnot_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint8mf4_t __riscv_vnot_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint8mf2_t __riscv_vnot_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint8m1_t __riscv_vnot_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t vl);
vuint8m2_t __riscv_vnot_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t vl);
vuint8m4_t __riscv_vnot_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t vl);
vuint8m8_t __riscv_vnot_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t vl);
vuint16mf4_t __riscv_vnot_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint16mf2_t __riscv_vnot_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint16m1_t __riscv_vnot_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t vl);
vuint16m2_t __riscv_vnot_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t vl);
vuint16m4_t __riscv_vnot_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t vl);
vuint16m8_t __riscv_vnot_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t vl);
vuint32mf2_t __riscv_vnot_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t vl);
vuint32m1_t __riscv_vnot_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t vl);
vuint32m2_t __riscv_vnot_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t vl);
vuint32m4_t __riscv_vnot_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t vl);
vuint32m8_t __riscv_vnot_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t vl);
vuint64m1_t __riscv_vnot_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t vl);
vuint64m2_t __riscv_vnot_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t vl);
vuint64m4_t __riscv_vnot_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t vl);
vuint64m8_t __riscv_vnot_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t vl);
// masked functions
vint8mf8_t __riscv_vnot_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t vl);
vint8mf4_t __riscv_vnot_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t vl);
vint8mf2_t __riscv_vnot_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t vl);
vint8m1_t __riscv_vnot_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t vl);
vint8m2_t __riscv_vnot_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t vl);
vint8m4_t __riscv_vnot_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t vl);
vint8m8_t __riscv_vnot_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t vl);
vint16mf4_t __riscv_vnot_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t vl);
vint16mf2_t __riscv_vnot_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t vl);
vint16m1_t __riscv_vnot_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t vl);
vint16m2_t __riscv_vnot_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t vl);
vint16m4_t __riscv_vnot_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t vl);
vint16m8_t __riscv_vnot_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t vl);
vint32mf2_t __riscv_vnot_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t vl);
vint32m1_t __riscv_vnot_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t vl);
vint32m2_t __riscv_vnot_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t vl);
vint32m4_t __riscv_vnot_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t vl);
vint32m8_t __riscv_vnot_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t vl);
vint64m1_t __riscv_vnot_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t vl);
vint64m2_t __riscv_vnot_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t vl);
vint64m4_t __riscv_vnot_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t vl);
vint64m8_t __riscv_vnot_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t vl);
vuint8mf8_t __riscv_vnot_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t vl);
vuint8mf4_t __riscv_vnot_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t vl);
vuint8mf2_t __riscv_vnot_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t vl);
vuint8m1_t __riscv_vnot_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t vl);
vuint8m2_t __riscv_vnot_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t vl);
vuint8m4_t __riscv_vnot_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t vl);
vuint8m8_t __riscv_vnot_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t vl);
vuint16mf4_t __riscv_vnot_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t vl);
vuint16mf2_t __riscv_vnot_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t vl);
vuint16m1_t __riscv_vnot_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t vl);
vuint16m2_t __riscv_vnot_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t vl);
vuint16m4_t __riscv_vnot_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t vl);
vuint16m8_t __riscv_vnot_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t vl);
vuint32mf2_t __riscv_vnot_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t vl);
vuint32m1_t __riscv_vnot_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t vl);
vuint32m2_t __riscv_vnot_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t vl);
vuint32m4_t __riscv_vnot_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t vl);
vuint32m8_t __riscv_vnot_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t vl);
vuint64m1_t __riscv_vnot_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t vl);
vuint64m2_t __riscv_vnot_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t vl);
vuint64m4_t __riscv_vnot_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t vl);
vuint64m8_t __riscv_vnot_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t vl);
```

[[policy-variant-overloadedvector-single-width-bit-shift]]
=== Vector Single-Width Bit Shift Intrinsics

``` C
vint8mf8_t __riscv_vsll_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vsll_tu (vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vsll_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vsll_tu (vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vsll_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vsll_tu (vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vsll_tu (vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vsll_tu (vint8m1_t maskedoff, vint8m1_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vsll_tu (vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vsll_tu (vint8m2_t maskedoff, vint8m2_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vsll_tu (vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vsll_tu (vint8m4_t maskedoff, vint8m4_t op1, size_t shift, size_t vl);
vint8m8_t __riscv_vsll_tu (vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, size_t vl);
vint8m8_t __riscv_vsll_tu (vint8m8_t maskedoff, vint8m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vsll_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vsll_tu (vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vsll_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vsll_tu (vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vsll_tu (vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vsll_tu (vint16m1_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vsll_tu (vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vsll_tu (vint16m2_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vsll_tu (vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vsll_tu (vint16m4_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint16m8_t __riscv_vsll_tu (vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, size_t vl);
vint16m8_t __riscv_vsll_tu (vint16m8_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vsll_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vsll_tu (vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vsll_tu (vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vsll_tu (vint32m1_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vsll_tu (vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vsll_tu (vint32m2_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vsll_tu (vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vsll_tu (vint32m4_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint32m8_t __riscv_vsll_tu (vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, size_t vl);
vint32m8_t __riscv_vsll_tu (vint32m8_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint64m1_t __riscv_vsll_tu (vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, size_t vl);
vint64m1_t __riscv_vsll_tu (vint64m1_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint64m2_t __riscv_vsll_tu (vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, size_t vl);
vint64m2_t __riscv_vsll_tu (vint64m2_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint64m4_t __riscv_vsll_tu (vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, size_t vl);
vint64m4_t __riscv_vsll_tu (vint64m4_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint64m8_t __riscv_vsll_tu (vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, size_t vl);
vint64m8_t __riscv_vsll_tu (vint64m8_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vint8mf8_t __riscv_vsra_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vsra_tu (vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vsra_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vsra_tu (vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vsra_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vsra_tu (vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vsra_tu (vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vsra_tu (vint8m1_t maskedoff, vint8m1_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vsra_tu (vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vsra_tu (vint8m2_t maskedoff, vint8m2_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vsra_tu (vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vsra_tu (vint8m4_t maskedoff, vint8m4_t op1, size_t shift, size_t vl);
vint8m8_t __riscv_vsra_tu (vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, size_t vl);
vint8m8_t __riscv_vsra_tu (vint8m8_t maskedoff, vint8m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vsra_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vsra_tu (vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vsra_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vsra_tu (vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vsra_tu (vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vsra_tu (vint16m1_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vsra_tu (vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vsra_tu (vint16m2_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vsra_tu (vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vsra_tu (vint16m4_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint16m8_t __riscv_vsra_tu (vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, size_t vl);
vint16m8_t __riscv_vsra_tu (vint16m8_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vsra_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vsra_tu (vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vsra_tu (vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vsra_tu (vint32m1_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vsra_tu (vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vsra_tu (vint32m2_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vsra_tu (vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vsra_tu (vint32m4_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint32m8_t __riscv_vsra_tu (vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, size_t vl);
vint32m8_t __riscv_vsra_tu (vint32m8_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint64m1_t __riscv_vsra_tu (vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, size_t vl);
vint64m1_t __riscv_vsra_tu (vint64m1_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint64m2_t __riscv_vsra_tu (vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, size_t vl);
vint64m2_t __riscv_vsra_tu (vint64m2_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint64m4_t __riscv_vsra_tu (vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, size_t vl);
vint64m4_t __riscv_vsra_tu (vint64m4_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint64m8_t __riscv_vsra_tu (vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, size_t vl);
vint64m8_t __riscv_vsra_tu (vint64m8_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vsll_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vsll_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vsll_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vsll_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vsll_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vsll_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vsll_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vsll_tu (vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vsll_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vsll_tu (vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vsll_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vsll_tu (vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, size_t vl);
vuint8m8_t __riscv_vsll_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, size_t vl);
vuint8m8_t __riscv_vsll_tu (vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vsll_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vsll_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vsll_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vsll_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vsll_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vsll_tu (vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vsll_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vsll_tu (vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vsll_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vsll_tu (vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint16m8_t __riscv_vsll_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, size_t vl);
vuint16m8_t __riscv_vsll_tu (vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vsll_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vsll_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vsll_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vsll_tu (vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vsll_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vsll_tu (vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vsll_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vsll_tu (vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint32m8_t __riscv_vsll_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, size_t vl);
vuint32m8_t __riscv_vsll_tu (vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint64m1_t __riscv_vsll_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, size_t vl);
vuint64m1_t __riscv_vsll_tu (vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint64m2_t __riscv_vsll_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, size_t vl);
vuint64m2_t __riscv_vsll_tu (vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint64m4_t __riscv_vsll_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, size_t vl);
vuint64m4_t __riscv_vsll_tu (vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint64m8_t __riscv_vsll_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, size_t vl);
vuint64m8_t __riscv_vsll_tu (vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vsrl_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vsrl_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vsrl_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vsrl_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vsrl_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vsrl_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vsrl_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vsrl_tu (vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vsrl_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vsrl_tu (vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vsrl_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vsrl_tu (vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, size_t vl);
vuint8m8_t __riscv_vsrl_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, size_t vl);
vuint8m8_t __riscv_vsrl_tu (vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vsrl_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vsrl_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vsrl_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vsrl_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vsrl_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vsrl_tu (vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vsrl_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vsrl_tu (vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vsrl_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vsrl_tu (vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint16m8_t __riscv_vsrl_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, size_t vl);
vuint16m8_t __riscv_vsrl_tu (vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vsrl_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vsrl_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vsrl_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vsrl_tu (vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vsrl_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vsrl_tu (vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vsrl_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vsrl_tu (vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint32m8_t __riscv_vsrl_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, size_t vl);
vuint32m8_t __riscv_vsrl_tu (vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint64m1_t __riscv_vsrl_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, size_t vl);
vuint64m1_t __riscv_vsrl_tu (vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint64m2_t __riscv_vsrl_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, size_t vl);
vuint64m2_t __riscv_vsrl_tu (vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint64m4_t __riscv_vsrl_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, size_t vl);
vuint64m4_t __riscv_vsrl_tu (vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint64m8_t __riscv_vsrl_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, size_t vl);
vuint64m8_t __riscv_vsrl_tu (vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
// masked functions
vint8mf8_t __riscv_vsll_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vsll_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vsll_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vsll_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vsll_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vsll_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vsll_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vsll_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vsll_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vsll_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vsll_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vsll_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, size_t vl);
vint8m8_t __riscv_vsll_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, size_t vl);
vint8m8_t __riscv_vsll_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vsll_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vsll_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vsll_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vsll_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vsll_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vsll_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vsll_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vsll_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vsll_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vsll_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint16m8_t __riscv_vsll_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, size_t vl);
vint16m8_t __riscv_vsll_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vsll_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vsll_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vsll_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vsll_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vsll_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vsll_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vsll_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vsll_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint32m8_t __riscv_vsll_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, size_t vl);
vint32m8_t __riscv_vsll_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint64m1_t __riscv_vsll_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, size_t vl);
vint64m1_t __riscv_vsll_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint64m2_t __riscv_vsll_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, size_t vl);
vint64m2_t __riscv_vsll_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint64m4_t __riscv_vsll_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, size_t vl);
vint64m4_t __riscv_vsll_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint64m8_t __riscv_vsll_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, size_t vl);
vint64m8_t __riscv_vsll_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vint8mf8_t __riscv_vsra_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vsra_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vsra_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vsra_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vsra_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vsra_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vsra_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vsra_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vsra_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vsra_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vsra_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vsra_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, size_t vl);
vint8m8_t __riscv_vsra_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, size_t vl);
vint8m8_t __riscv_vsra_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vsra_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vsra_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vsra_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vsra_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vsra_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vsra_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vsra_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vsra_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vsra_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vsra_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint16m8_t __riscv_vsra_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, size_t vl);
vint16m8_t __riscv_vsra_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vsra_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vsra_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vsra_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vsra_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vsra_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vsra_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vsra_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vsra_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint32m8_t __riscv_vsra_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, size_t vl);
vint32m8_t __riscv_vsra_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint64m1_t __riscv_vsra_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, size_t vl);
vint64m1_t __riscv_vsra_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint64m2_t __riscv_vsra_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, size_t vl);
vint64m2_t __riscv_vsra_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint64m4_t __riscv_vsra_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, size_t vl);
vint64m4_t __riscv_vsra_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint64m8_t __riscv_vsra_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, size_t vl);
vint64m8_t __riscv_vsra_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vsll_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vsll_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vsll_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vsll_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vsll_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vsll_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vsll_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vsll_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vsll_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vsll_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vsll_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vsll_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, size_t vl);
vuint8m8_t __riscv_vsll_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, size_t vl);
vuint8m8_t __riscv_vsll_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vsll_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vsll_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vsll_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vsll_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vsll_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vsll_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vsll_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vsll_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vsll_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vsll_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint16m8_t __riscv_vsll_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, size_t vl);
vuint16m8_t __riscv_vsll_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vsll_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vsll_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vsll_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vsll_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vsll_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vsll_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vsll_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vsll_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint32m8_t __riscv_vsll_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, size_t vl);
vuint32m8_t __riscv_vsll_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint64m1_t __riscv_vsll_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, size_t vl);
vuint64m1_t __riscv_vsll_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint64m2_t __riscv_vsll_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, size_t vl);
vuint64m2_t __riscv_vsll_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint64m4_t __riscv_vsll_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, size_t vl);
vuint64m4_t __riscv_vsll_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint64m8_t __riscv_vsll_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, size_t vl);
vuint64m8_t __riscv_vsll_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vsrl_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vsrl_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vsrl_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vsrl_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vsrl_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vsrl_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vsrl_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vsrl_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vsrl_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vsrl_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vsrl_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vsrl_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, size_t vl);
vuint8m8_t __riscv_vsrl_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, size_t vl);
vuint8m8_t __riscv_vsrl_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vsrl_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vsrl_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vsrl_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vsrl_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vsrl_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vsrl_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vsrl_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vsrl_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vsrl_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vsrl_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint16m8_t __riscv_vsrl_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, size_t vl);
vuint16m8_t __riscv_vsrl_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vsrl_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vsrl_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vsrl_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vsrl_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vsrl_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vsrl_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vsrl_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vsrl_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint32m8_t __riscv_vsrl_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, size_t vl);
vuint32m8_t __riscv_vsrl_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint64m1_t __riscv_vsrl_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, size_t vl);
vuint64m1_t __riscv_vsrl_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint64m2_t __riscv_vsrl_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, size_t vl);
vuint64m2_t __riscv_vsrl_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint64m4_t __riscv_vsrl_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, size_t vl);
vuint64m4_t __riscv_vsrl_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint64m8_t __riscv_vsrl_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, size_t vl);
vuint64m8_t __riscv_vsrl_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
// masked functions
vint8mf8_t __riscv_vsll_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vsll_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vsll_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vsll_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vsll_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vsll_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vsll_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vsll_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vsll_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vsll_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vsll_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vsll_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, size_t vl);
vint8m8_t __riscv_vsll_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, size_t vl);
vint8m8_t __riscv_vsll_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vsll_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vsll_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vsll_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vsll_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vsll_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vsll_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vsll_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vsll_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vsll_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vsll_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint16m8_t __riscv_vsll_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, size_t vl);
vint16m8_t __riscv_vsll_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vsll_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vsll_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vsll_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vsll_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vsll_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vsll_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vsll_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vsll_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint32m8_t __riscv_vsll_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, size_t vl);
vint32m8_t __riscv_vsll_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint64m1_t __riscv_vsll_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, size_t vl);
vint64m1_t __riscv_vsll_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint64m2_t __riscv_vsll_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, size_t vl);
vint64m2_t __riscv_vsll_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint64m4_t __riscv_vsll_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, size_t vl);
vint64m4_t __riscv_vsll_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint64m8_t __riscv_vsll_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, size_t vl);
vint64m8_t __riscv_vsll_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vint8mf8_t __riscv_vsra_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vsra_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vsra_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vsra_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vsra_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vsra_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vsra_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vsra_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vsra_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vsra_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vsra_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vsra_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, size_t vl);
vint8m8_t __riscv_vsra_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, size_t vl);
vint8m8_t __riscv_vsra_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vsra_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vsra_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vsra_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vsra_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vsra_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vsra_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vsra_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vsra_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vsra_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vsra_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint16m8_t __riscv_vsra_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, size_t vl);
vint16m8_t __riscv_vsra_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vsra_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vsra_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vsra_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vsra_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vsra_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vsra_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vsra_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vsra_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint32m8_t __riscv_vsra_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, size_t vl);
vint32m8_t __riscv_vsra_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint64m1_t __riscv_vsra_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, size_t vl);
vint64m1_t __riscv_vsra_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint64m2_t __riscv_vsra_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, size_t vl);
vint64m2_t __riscv_vsra_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint64m4_t __riscv_vsra_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, size_t vl);
vint64m4_t __riscv_vsra_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint64m8_t __riscv_vsra_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, size_t vl);
vint64m8_t __riscv_vsra_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vsll_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vsll_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vsll_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vsll_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vsll_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vsll_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vsll_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vsll_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vsll_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vsll_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vsll_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vsll_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, size_t vl);
vuint8m8_t __riscv_vsll_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, size_t vl);
vuint8m8_t __riscv_vsll_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vsll_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vsll_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vsll_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vsll_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vsll_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vsll_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vsll_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vsll_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vsll_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vsll_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint16m8_t __riscv_vsll_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, size_t vl);
vuint16m8_t __riscv_vsll_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vsll_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vsll_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vsll_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vsll_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vsll_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vsll_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vsll_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vsll_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint32m8_t __riscv_vsll_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, size_t vl);
vuint32m8_t __riscv_vsll_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint64m1_t __riscv_vsll_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, size_t vl);
vuint64m1_t __riscv_vsll_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint64m2_t __riscv_vsll_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, size_t vl);
vuint64m2_t __riscv_vsll_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint64m4_t __riscv_vsll_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, size_t vl);
vuint64m4_t __riscv_vsll_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint64m8_t __riscv_vsll_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, size_t vl);
vuint64m8_t __riscv_vsll_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vsrl_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vsrl_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vsrl_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vsrl_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vsrl_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vsrl_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vsrl_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vsrl_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vsrl_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vsrl_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vsrl_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vsrl_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, size_t vl);
vuint8m8_t __riscv_vsrl_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, size_t vl);
vuint8m8_t __riscv_vsrl_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vsrl_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vsrl_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vsrl_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vsrl_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vsrl_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vsrl_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vsrl_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vsrl_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vsrl_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vsrl_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint16m8_t __riscv_vsrl_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, size_t vl);
vuint16m8_t __riscv_vsrl_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vsrl_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vsrl_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vsrl_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vsrl_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vsrl_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vsrl_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vsrl_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vsrl_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint32m8_t __riscv_vsrl_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, size_t vl);
vuint32m8_t __riscv_vsrl_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint64m1_t __riscv_vsrl_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, size_t vl);
vuint64m1_t __riscv_vsrl_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint64m2_t __riscv_vsrl_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, size_t vl);
vuint64m2_t __riscv_vsrl_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint64m4_t __riscv_vsrl_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, size_t vl);
vuint64m4_t __riscv_vsrl_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint64m8_t __riscv_vsrl_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, size_t vl);
vuint64m8_t __riscv_vsrl_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
// masked functions
vint8mf8_t __riscv_vsll_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vsll_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vsll_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vsll_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vsll_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vsll_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vsll_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vsll_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vsll_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vsll_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vsll_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vsll_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, size_t vl);
vint8m8_t __riscv_vsll_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, size_t vl);
vint8m8_t __riscv_vsll_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vsll_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vsll_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vsll_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vsll_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vsll_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vsll_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vsll_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vsll_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vsll_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vsll_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint16m8_t __riscv_vsll_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, size_t vl);
vint16m8_t __riscv_vsll_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vsll_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vsll_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vsll_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vsll_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vsll_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vsll_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vsll_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vsll_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint32m8_t __riscv_vsll_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, size_t vl);
vint32m8_t __riscv_vsll_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint64m1_t __riscv_vsll_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, size_t vl);
vint64m1_t __riscv_vsll_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint64m2_t __riscv_vsll_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, size_t vl);
vint64m2_t __riscv_vsll_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint64m4_t __riscv_vsll_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, size_t vl);
vint64m4_t __riscv_vsll_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint64m8_t __riscv_vsll_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, size_t vl);
vint64m8_t __riscv_vsll_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vint8mf8_t __riscv_vsra_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vsra_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vsra_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vsra_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vsra_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vsra_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vsra_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vsra_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vsra_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vsra_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vsra_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vsra_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, size_t vl);
vint8m8_t __riscv_vsra_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, size_t vl);
vint8m8_t __riscv_vsra_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vsra_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vsra_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vsra_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vsra_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vsra_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vsra_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vsra_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vsra_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vsra_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vsra_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint16m8_t __riscv_vsra_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, size_t vl);
vint16m8_t __riscv_vsra_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vsra_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vsra_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vsra_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vsra_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vsra_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vsra_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vsra_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vsra_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint32m8_t __riscv_vsra_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, size_t vl);
vint32m8_t __riscv_vsra_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint64m1_t __riscv_vsra_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, size_t vl);
vint64m1_t __riscv_vsra_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint64m2_t __riscv_vsra_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, size_t vl);
vint64m2_t __riscv_vsra_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint64m4_t __riscv_vsra_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, size_t vl);
vint64m4_t __riscv_vsra_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint64m8_t __riscv_vsra_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, size_t vl);
vint64m8_t __riscv_vsra_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vsll_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vsll_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vsll_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vsll_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vsll_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vsll_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vsll_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vsll_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vsll_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vsll_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vsll_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vsll_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, size_t vl);
vuint8m8_t __riscv_vsll_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, size_t vl);
vuint8m8_t __riscv_vsll_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vsll_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vsll_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vsll_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vsll_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vsll_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vsll_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vsll_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vsll_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vsll_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vsll_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint16m8_t __riscv_vsll_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, size_t vl);
vuint16m8_t __riscv_vsll_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vsll_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vsll_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vsll_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vsll_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vsll_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vsll_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vsll_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vsll_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint32m8_t __riscv_vsll_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, size_t vl);
vuint32m8_t __riscv_vsll_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint64m1_t __riscv_vsll_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, size_t vl);
vuint64m1_t __riscv_vsll_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint64m2_t __riscv_vsll_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, size_t vl);
vuint64m2_t __riscv_vsll_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint64m4_t __riscv_vsll_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, size_t vl);
vuint64m4_t __riscv_vsll_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint64m8_t __riscv_vsll_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, size_t vl);
vuint64m8_t __riscv_vsll_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vsrl_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vsrl_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vsrl_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vsrl_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vsrl_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vsrl_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vsrl_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vsrl_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vsrl_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vsrl_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vsrl_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vsrl_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, size_t vl);
vuint8m8_t __riscv_vsrl_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, size_t vl);
vuint8m8_t __riscv_vsrl_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vsrl_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vsrl_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vsrl_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vsrl_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vsrl_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vsrl_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vsrl_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vsrl_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vsrl_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vsrl_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint16m8_t __riscv_vsrl_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, size_t vl);
vuint16m8_t __riscv_vsrl_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vsrl_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vsrl_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vsrl_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vsrl_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vsrl_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vsrl_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vsrl_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vsrl_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint32m8_t __riscv_vsrl_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, size_t vl);
vuint32m8_t __riscv_vsrl_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint64m1_t __riscv_vsrl_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, size_t vl);
vuint64m1_t __riscv_vsrl_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint64m2_t __riscv_vsrl_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, size_t vl);
vuint64m2_t __riscv_vsrl_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint64m4_t __riscv_vsrl_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, size_t vl);
vuint64m4_t __riscv_vsrl_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint64m8_t __riscv_vsrl_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, size_t vl);
vuint64m8_t __riscv_vsrl_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
```

[[policy-variant-overloadedvector-narrowing-integer-right-shift]]
=== Vector Narrowing Integer Right Shift Intrinsics

``` C
vint8mf8_t __riscv_vnsra_tu (vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vnsra_tu (vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vnsra_tu (vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vnsra_tu (vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vnsra_tu (vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vnsra_tu (vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vnsra_tu (vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vnsra_tu (vint8m1_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vnsra_tu (vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vnsra_tu (vint8m2_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vnsra_tu (vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vnsra_tu (vint8m4_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vnsra_tu (vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vnsra_tu (vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vnsra_tu (vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vnsra_tu (vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vnsra_tu (vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vnsra_tu (vint16m1_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vnsra_tu (vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vnsra_tu (vint16m2_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vnsra_tu (vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vnsra_tu (vint16m4_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vnsra_tu (vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vnsra_tu (vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vnsra_tu (vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vnsra_tu (vint32m1_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vnsra_tu (vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vnsra_tu (vint32m2_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vnsra_tu (vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vnsra_tu (vint32m4_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vnsrl_tu (vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vnsrl_tu (vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vnsrl_tu (vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vnsrl_tu (vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vnsrl_tu (vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vnsrl_tu (vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vnsrl_tu (vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vnsrl_tu (vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vnsrl_tu (vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vnsrl_tu (vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vnsrl_tu (vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vnsrl_tu (vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vnsrl_tu (vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vnsrl_tu (vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vnsrl_tu (vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vnsrl_tu (vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vnsrl_tu (vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vnsrl_tu (vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vnsrl_tu (vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vnsrl_tu (vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vnsrl_tu (vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vnsrl_tu (vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vnsrl_tu (vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vnsrl_tu (vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vnsrl_tu (vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vnsrl_tu (vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vnsrl_tu (vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vnsrl_tu (vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vnsrl_tu (vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vnsrl_tu (vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
// masked functions
vint8mf8_t __riscv_vnsra_tum (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vnsra_tum (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vnsra_tum (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vnsra_tum (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vnsra_tum (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vnsra_tum (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vnsra_tum (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vnsra_tum (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vnsra_tum (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vnsra_tum (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vnsra_tum (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vnsra_tum (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vnsra_tum (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vnsra_tum (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vnsra_tum (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vnsra_tum (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vnsra_tum (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vnsra_tum (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vnsra_tum (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vnsra_tum (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vnsra_tum (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vnsra_tum (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vnsra_tum (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vnsra_tum (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vnsra_tum (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vnsra_tum (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vnsra_tum (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vnsra_tum (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vnsra_tum (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vnsra_tum (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vnsrl_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vnsrl_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vnsrl_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vnsrl_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vnsrl_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vnsrl_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vnsrl_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vnsrl_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vnsrl_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vnsrl_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vnsrl_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vnsrl_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vnsrl_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vnsrl_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vnsrl_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vnsrl_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vnsrl_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vnsrl_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vnsrl_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vnsrl_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vnsrl_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vnsrl_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vnsrl_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vnsrl_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vnsrl_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vnsrl_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vnsrl_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vnsrl_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vnsrl_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vnsrl_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
// masked functions
vint8mf8_t __riscv_vnsra_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vnsra_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vnsra_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vnsra_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vnsra_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vnsra_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vnsra_tumu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vnsra_tumu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vnsra_tumu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vnsra_tumu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vnsra_tumu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vnsra_tumu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vnsra_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vnsra_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vnsra_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vnsra_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vnsra_tumu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vnsra_tumu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vnsra_tumu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vnsra_tumu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vnsra_tumu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vnsra_tumu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vnsra_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vnsra_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vnsra_tumu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vnsra_tumu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vnsra_tumu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vnsra_tumu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vnsra_tumu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vnsra_tumu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vnsrl_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vnsrl_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vnsrl_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vnsrl_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vnsrl_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vnsrl_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vnsrl_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vnsrl_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vnsrl_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vnsrl_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vnsrl_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vnsrl_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vnsrl_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vnsrl_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vnsrl_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vnsrl_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vnsrl_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vnsrl_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vnsrl_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vnsrl_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vnsrl_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vnsrl_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vnsrl_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vnsrl_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vnsrl_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vnsrl_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vnsrl_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vnsrl_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vnsrl_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vnsrl_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
// masked functions
vint8mf8_t __riscv_vnsra_mu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, size_t vl);
vint8mf8_t __riscv_vnsra_mu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, size_t vl);
vint8mf4_t __riscv_vnsra_mu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, size_t vl);
vint8mf4_t __riscv_vnsra_mu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, size_t vl);
vint8mf2_t __riscv_vnsra_mu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, size_t vl);
vint8mf2_t __riscv_vnsra_mu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, size_t vl);
vint8m1_t __riscv_vnsra_mu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, size_t vl);
vint8m1_t __riscv_vnsra_mu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, size_t shift, size_t vl);
vint8m2_t __riscv_vnsra_mu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, size_t vl);
vint8m2_t __riscv_vnsra_mu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, size_t shift, size_t vl);
vint8m4_t __riscv_vnsra_mu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, size_t vl);
vint8m4_t __riscv_vnsra_mu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, size_t shift, size_t vl);
vint16mf4_t __riscv_vnsra_mu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, size_t vl);
vint16mf4_t __riscv_vnsra_mu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, size_t vl);
vint16mf2_t __riscv_vnsra_mu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, size_t vl);
vint16mf2_t __riscv_vnsra_mu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, size_t vl);
vint16m1_t __riscv_vnsra_mu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, size_t vl);
vint16m1_t __riscv_vnsra_mu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, size_t shift, size_t vl);
vint16m2_t __riscv_vnsra_mu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, size_t vl);
vint16m2_t __riscv_vnsra_mu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, size_t shift, size_t vl);
vint16m4_t __riscv_vnsra_mu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, size_t vl);
vint16m4_t __riscv_vnsra_mu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, size_t shift, size_t vl);
vint32mf2_t __riscv_vnsra_mu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, size_t vl);
vint32mf2_t __riscv_vnsra_mu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, size_t vl);
vint32m1_t __riscv_vnsra_mu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, size_t vl);
vint32m1_t __riscv_vnsra_mu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, size_t shift, size_t vl);
vint32m2_t __riscv_vnsra_mu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, size_t vl);
vint32m2_t __riscv_vnsra_mu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, size_t shift, size_t vl);
vint32m4_t __riscv_vnsra_mu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, size_t vl);
vint32m4_t __riscv_vnsra_mu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, size_t shift, size_t vl);
vuint8mf8_t __riscv_vnsrl_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, size_t vl);
vuint8mf8_t __riscv_vnsrl_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, size_t vl);
vuint8mf4_t __riscv_vnsrl_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, size_t vl);
vuint8mf4_t __riscv_vnsrl_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, size_t vl);
vuint8mf2_t __riscv_vnsrl_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, size_t vl);
vuint8mf2_t __riscv_vnsrl_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, size_t vl);
vuint8m1_t __riscv_vnsrl_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, size_t vl);
vuint8m1_t __riscv_vnsrl_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, size_t vl);
vuint8m2_t __riscv_vnsrl_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, size_t vl);
vuint8m2_t __riscv_vnsrl_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, size_t vl);
vuint8m4_t __riscv_vnsrl_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, size_t vl);
vuint8m4_t __riscv_vnsrl_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, size_t vl);
vuint16mf4_t __riscv_vnsrl_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, size_t vl);
vuint16mf4_t __riscv_vnsrl_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, size_t vl);
vuint16mf2_t __riscv_vnsrl_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, size_t vl);
vuint16mf2_t __riscv_vnsrl_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, size_t vl);
vuint16m1_t __riscv_vnsrl_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, size_t vl);
vuint16m1_t __riscv_vnsrl_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, size_t vl);
vuint16m2_t __riscv_vnsrl_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, size_t vl);
vuint16m2_t __riscv_vnsrl_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, size_t vl);
vuint16m4_t __riscv_vnsrl_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, size_t vl);
vuint16m4_t __riscv_vnsrl_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, size_t vl);
vuint32mf2_t __riscv_vnsrl_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, size_t vl);
vuint32mf2_t __riscv_vnsrl_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, size_t vl);
vuint32m1_t __riscv_vnsrl_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, size_t vl);
vuint32m1_t __riscv_vnsrl_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, size_t vl);
vuint32m2_t __riscv_vnsrl_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, size_t vl);
vuint32m2_t __riscv_vnsrl_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, size_t vl);
vuint32m4_t __riscv_vnsrl_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, size_t vl);
vuint32m4_t __riscv_vnsrl_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, size_t vl);
```

[[policy-variant-overloadedvector-integer-narrowing]]
=== Vector Integer Narrowing Intrinsics

``` C
vint8mf8_t __riscv_vncvt_x_tu (vint8mf8_t maskedoff, vint16mf4_t src, size_t vl);
vint8mf4_t __riscv_vncvt_x_tu (vint8mf4_t maskedoff, vint16mf2_t src, size_t vl);
vint8mf2_t __riscv_vncvt_x_tu (vint8mf2_t maskedoff, vint16m1_t src, size_t vl);
vint8m1_t __riscv_vncvt_x_tu (vint8m1_t maskedoff, vint16m2_t src, size_t vl);
vint8m2_t __riscv_vncvt_x_tu (vint8m2_t maskedoff, vint16m4_t src, size_t vl);
vint8m4_t __riscv_vncvt_x_tu (vint8m4_t maskedoff, vint16m8_t src, size_t vl);
vuint8mf8_t __riscv_vncvt_x_tu (vuint8mf8_t maskedoff, vuint16mf4_t src, size_t vl);
vuint8mf4_t __riscv_vncvt_x_tu (vuint8mf4_t maskedoff, vuint16mf2_t src, size_t vl);
vuint8mf2_t __riscv_vncvt_x_tu (vuint8mf2_t maskedoff, vuint16m1_t src, size_t vl);
vuint8m1_t __riscv_vncvt_x_tu (vuint8m1_t maskedoff, vuint16m2_t src, size_t vl);
vuint8m2_t __riscv_vncvt_x_tu (vuint8m2_t maskedoff, vuint16m4_t src, size_t vl);
vuint8m4_t __riscv_vncvt_x_tu (vuint8m4_t maskedoff, vuint16m8_t src, size_t vl);
vint16mf4_t __riscv_vncvt_x_tu (vint16mf4_t maskedoff, vint32mf2_t src, size_t vl);
vint16mf2_t __riscv_vncvt_x_tu (vint16mf2_t maskedoff, vint32m1_t src, size_t vl);
vint16m1_t __riscv_vncvt_x_tu (vint16m1_t maskedoff, vint32m2_t src, size_t vl);
vint16m2_t __riscv_vncvt_x_tu (vint16m2_t maskedoff, vint32m4_t src, size_t vl);
vint16m4_t __riscv_vncvt_x_tu (vint16m4_t maskedoff, vint32m8_t src, size_t vl);
vuint16mf4_t __riscv_vncvt_x_tu (vuint16mf4_t maskedoff, vuint32mf2_t src, size_t vl);
vuint16mf2_t __riscv_vncvt_x_tu (vuint16mf2_t maskedoff, vuint32m1_t src, size_t vl);
vuint16m1_t __riscv_vncvt_x_tu (vuint16m1_t maskedoff, vuint32m2_t src, size_t vl);
vuint16m2_t __riscv_vncvt_x_tu (vuint16m2_t maskedoff, vuint32m4_t src, size_t vl);
vuint16m4_t __riscv_vncvt_x_tu (vuint16m4_t maskedoff, vuint32m8_t src, size_t vl);
vint32mf2_t __riscv_vncvt_x_tu (vint32mf2_t maskedoff, vint64m1_t src, size_t vl);
vint32m1_t __riscv_vncvt_x_tu (vint32m1_t maskedoff, vint64m2_t src, size_t vl);
vint32m2_t __riscv_vncvt_x_tu (vint32m2_t maskedoff, vint64m4_t src, size_t vl);
vint32m4_t __riscv_vncvt_x_tu (vint32m4_t maskedoff, vint64m8_t src, size_t vl);
vuint32mf2_t __riscv_vncvt_x_tu (vuint32mf2_t maskedoff, vuint64m1_t src, size_t vl);
vuint32m1_t __riscv_vncvt_x_tu (vuint32m1_t maskedoff, vuint64m2_t src, size_t vl);
vuint32m2_t __riscv_vncvt_x_tu (vuint32m2_t maskedoff, vuint64m4_t src, size_t vl);
vuint32m4_t __riscv_vncvt_x_tu (vuint32m4_t maskedoff, vuint64m8_t src, size_t vl);
// masked functions
vint8mf8_t __riscv_vncvt_x_tum (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t src, size_t vl);
vint8mf4_t __riscv_vncvt_x_tum (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t src, size_t vl);
vint8mf2_t __riscv_vncvt_x_tum (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t src, size_t vl);
vint8m1_t __riscv_vncvt_x_tum (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t src, size_t vl);
vint8m2_t __riscv_vncvt_x_tum (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t src, size_t vl);
vint8m4_t __riscv_vncvt_x_tum (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t src, size_t vl);
vuint8mf8_t __riscv_vncvt_x_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t src, size_t vl);
vuint8mf4_t __riscv_vncvt_x_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t src, size_t vl);
vuint8mf2_t __riscv_vncvt_x_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t src, size_t vl);
vuint8m1_t __riscv_vncvt_x_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t src, size_t vl);
vuint8m2_t __riscv_vncvt_x_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t src, size_t vl);
vuint8m4_t __riscv_vncvt_x_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t src, size_t vl);
vint16mf4_t __riscv_vncvt_x_tum (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t src, size_t vl);
vint16mf2_t __riscv_vncvt_x_tum (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t src, size_t vl);
vint16m1_t __riscv_vncvt_x_tum (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t src, size_t vl);
vint16m2_t __riscv_vncvt_x_tum (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t src, size_t vl);
vint16m4_t __riscv_vncvt_x_tum (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t src, size_t vl);
vuint16mf4_t __riscv_vncvt_x_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t src, size_t vl);
vuint16mf2_t __riscv_vncvt_x_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t src, size_t vl);
vuint16m1_t __riscv_vncvt_x_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t src, size_t vl);
vuint16m2_t __riscv_vncvt_x_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t src, size_t vl);
vuint16m4_t __riscv_vncvt_x_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t src, size_t vl);
vint32mf2_t __riscv_vncvt_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t src, size_t vl);
vint32m1_t __riscv_vncvt_x_tum (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t src, size_t vl);
vint32m2_t __riscv_vncvt_x_tum (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t src, size_t vl);
vint32m4_t __riscv_vncvt_x_tum (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t src, size_t vl);
vuint32mf2_t __riscv_vncvt_x_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t src, size_t vl);
vuint32m1_t __riscv_vncvt_x_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t src, size_t vl);
vuint32m2_t __riscv_vncvt_x_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t src, size_t vl);
vuint32m4_t __riscv_vncvt_x_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t src, size_t vl);
// masked functions
vint8mf8_t __riscv_vncvt_x_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t src, size_t vl);
vint8mf4_t __riscv_vncvt_x_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t src, size_t vl);
vint8mf2_t __riscv_vncvt_x_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t src, size_t vl);
vint8m1_t __riscv_vncvt_x_tumu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t src, size_t vl);
vint8m2_t __riscv_vncvt_x_tumu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t src, size_t vl);
vint8m4_t __riscv_vncvt_x_tumu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t src, size_t vl);
vuint8mf8_t __riscv_vncvt_x_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t src, size_t vl);
vuint8mf4_t __riscv_vncvt_x_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t src, size_t vl);
vuint8mf2_t __riscv_vncvt_x_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t src, size_t vl);
vuint8m1_t __riscv_vncvt_x_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t src, size_t vl);
vuint8m2_t __riscv_vncvt_x_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t src, size_t vl);
vuint8m4_t __riscv_vncvt_x_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t src, size_t vl);
vint16mf4_t __riscv_vncvt_x_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t src, size_t vl);
vint16mf2_t __riscv_vncvt_x_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t src, size_t vl);
vint16m1_t __riscv_vncvt_x_tumu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t src, size_t vl);
vint16m2_t __riscv_vncvt_x_tumu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t src, size_t vl);
vint16m4_t __riscv_vncvt_x_tumu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t src, size_t vl);
vuint16mf4_t __riscv_vncvt_x_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t src, size_t vl);
vuint16mf2_t __riscv_vncvt_x_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t src, size_t vl);
vuint16m1_t __riscv_vncvt_x_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t src, size_t vl);
vuint16m2_t __riscv_vncvt_x_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t src, size_t vl);
vuint16m4_t __riscv_vncvt_x_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t src, size_t vl);
vint32mf2_t __riscv_vncvt_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t src, size_t vl);
vint32m1_t __riscv_vncvt_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t src, size_t vl);
vint32m2_t __riscv_vncvt_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t src, size_t vl);
vint32m4_t __riscv_vncvt_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t src, size_t vl);
vuint32mf2_t __riscv_vncvt_x_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t src, size_t vl);
vuint32m1_t __riscv_vncvt_x_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t src, size_t vl);
vuint32m2_t __riscv_vncvt_x_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t src, size_t vl);
vuint32m4_t __riscv_vncvt_x_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t src, size_t vl);
// masked functions
vint8mf8_t __riscv_vncvt_x_mu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t src, size_t vl);
vint8mf4_t __riscv_vncvt_x_mu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t src, size_t vl);
vint8mf2_t __riscv_vncvt_x_mu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t src, size_t vl);
vint8m1_t __riscv_vncvt_x_mu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t src, size_t vl);
vint8m2_t __riscv_vncvt_x_mu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t src, size_t vl);
vint8m4_t __riscv_vncvt_x_mu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t src, size_t vl);
vuint8mf8_t __riscv_vncvt_x_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t src, size_t vl);
vuint8mf4_t __riscv_vncvt_x_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t src, size_t vl);
vuint8mf2_t __riscv_vncvt_x_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t src, size_t vl);
vuint8m1_t __riscv_vncvt_x_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t src, size_t vl);
vuint8m2_t __riscv_vncvt_x_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t src, size_t vl);
vuint8m4_t __riscv_vncvt_x_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t src, size_t vl);
vint16mf4_t __riscv_vncvt_x_mu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t src, size_t vl);
vint16mf2_t __riscv_vncvt_x_mu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t src, size_t vl);
vint16m1_t __riscv_vncvt_x_mu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t src, size_t vl);
vint16m2_t __riscv_vncvt_x_mu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t src, size_t vl);
vint16m4_t __riscv_vncvt_x_mu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t src, size_t vl);
vuint16mf4_t __riscv_vncvt_x_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t src, size_t vl);
vuint16mf2_t __riscv_vncvt_x_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t src, size_t vl);
vuint16m1_t __riscv_vncvt_x_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t src, size_t vl);
vuint16m2_t __riscv_vncvt_x_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t src, size_t vl);
vuint16m4_t __riscv_vncvt_x_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t src, size_t vl);
vint32mf2_t __riscv_vncvt_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t src, size_t vl);
vint32m1_t __riscv_vncvt_x_mu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t src, size_t vl);
vint32m2_t __riscv_vncvt_x_mu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t src, size_t vl);
vint32m4_t __riscv_vncvt_x_mu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t src, size_t vl);
vuint32mf2_t __riscv_vncvt_x_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t src, size_t vl);
vuint32m1_t __riscv_vncvt_x_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t src, size_t vl);
vuint32m2_t __riscv_vncvt_x_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t src, size_t vl);
vuint32m4_t __riscv_vncvt_x_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t src, size_t vl);
```

[[policy-variant-overloadedvector-integer-comparison]]
=== Vector Integer Compare Intrinsics

``` C
// masked functions
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vbool2_t __riscv_vmseq_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vbool2_t __riscv_vmseq_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vbool1_t __riscv_vmseq_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vbool1_t __riscv_vmseq_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vbool2_t __riscv_vmseq_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vbool2_t __riscv_vmseq_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vbool2_t __riscv_vmsne_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vbool2_t __riscv_vmsne_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vbool1_t __riscv_vmsne_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vbool1_t __riscv_vmsne_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vbool2_t __riscv_vmsne_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vbool2_t __riscv_vmsne_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vbool64_t __riscv_vmslt_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmslt_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vbool32_t __riscv_vmslt_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmslt_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vbool16_t __riscv_vmslt_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmslt_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vbool8_t __riscv_vmslt_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vbool8_t __riscv_vmslt_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vbool4_t __riscv_vmslt_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vbool4_t __riscv_vmslt_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vbool2_t __riscv_vmslt_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vbool2_t __riscv_vmslt_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vbool1_t __riscv_vmslt_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vbool1_t __riscv_vmslt_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vbool64_t __riscv_vmslt_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmslt_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vbool32_t __riscv_vmslt_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmslt_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vbool16_t __riscv_vmslt_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vbool16_t __riscv_vmslt_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vbool8_t __riscv_vmslt_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vbool8_t __riscv_vmslt_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vbool4_t __riscv_vmslt_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vbool4_t __riscv_vmslt_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vbool2_t __riscv_vmslt_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vbool2_t __riscv_vmslt_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vbool64_t __riscv_vmslt_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmslt_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vbool32_t __riscv_vmslt_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vbool32_t __riscv_vmslt_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vbool16_t __riscv_vmslt_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vbool16_t __riscv_vmslt_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vbool8_t __riscv_vmslt_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vbool8_t __riscv_vmslt_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vbool4_t __riscv_vmslt_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vbool4_t __riscv_vmslt_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vbool64_t __riscv_vmslt_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vbool64_t __riscv_vmslt_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vbool32_t __riscv_vmslt_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vbool32_t __riscv_vmslt_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vbool16_t __riscv_vmslt_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vbool16_t __riscv_vmslt_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vbool8_t __riscv_vmslt_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vbool8_t __riscv_vmslt_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vbool64_t __riscv_vmsle_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmsle_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vbool32_t __riscv_vmsle_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmsle_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vbool16_t __riscv_vmsle_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmsle_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vbool8_t __riscv_vmsle_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vbool8_t __riscv_vmsle_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vbool4_t __riscv_vmsle_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vbool4_t __riscv_vmsle_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vbool2_t __riscv_vmsle_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vbool2_t __riscv_vmsle_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vbool1_t __riscv_vmsle_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vbool1_t __riscv_vmsle_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vbool64_t __riscv_vmsle_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmsle_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vbool32_t __riscv_vmsle_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmsle_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vbool16_t __riscv_vmsle_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vbool16_t __riscv_vmsle_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vbool8_t __riscv_vmsle_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vbool8_t __riscv_vmsle_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vbool4_t __riscv_vmsle_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vbool4_t __riscv_vmsle_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vbool2_t __riscv_vmsle_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vbool2_t __riscv_vmsle_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vbool64_t __riscv_vmsle_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmsle_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vbool32_t __riscv_vmsle_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vbool32_t __riscv_vmsle_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vbool16_t __riscv_vmsle_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vbool16_t __riscv_vmsle_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vbool8_t __riscv_vmsle_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vbool8_t __riscv_vmsle_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vbool4_t __riscv_vmsle_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vbool4_t __riscv_vmsle_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vbool64_t __riscv_vmsle_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vbool64_t __riscv_vmsle_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vbool32_t __riscv_vmsle_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vbool32_t __riscv_vmsle_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vbool16_t __riscv_vmsle_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vbool16_t __riscv_vmsle_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vbool8_t __riscv_vmsle_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vbool8_t __riscv_vmsle_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vbool64_t __riscv_vmsgt_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmsgt_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vbool32_t __riscv_vmsgt_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmsgt_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vbool16_t __riscv_vmsgt_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmsgt_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vbool8_t __riscv_vmsgt_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vbool8_t __riscv_vmsgt_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vbool4_t __riscv_vmsgt_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vbool4_t __riscv_vmsgt_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vbool2_t __riscv_vmsgt_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vbool2_t __riscv_vmsgt_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vbool1_t __riscv_vmsgt_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vbool1_t __riscv_vmsgt_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vbool64_t __riscv_vmsgt_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmsgt_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vbool32_t __riscv_vmsgt_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmsgt_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vbool16_t __riscv_vmsgt_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vbool16_t __riscv_vmsgt_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vbool8_t __riscv_vmsgt_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vbool8_t __riscv_vmsgt_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vbool4_t __riscv_vmsgt_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vbool4_t __riscv_vmsgt_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vbool2_t __riscv_vmsgt_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vbool2_t __riscv_vmsgt_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vbool64_t __riscv_vmsgt_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmsgt_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vbool32_t __riscv_vmsgt_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vbool32_t __riscv_vmsgt_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vbool16_t __riscv_vmsgt_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vbool16_t __riscv_vmsgt_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vbool8_t __riscv_vmsgt_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vbool8_t __riscv_vmsgt_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vbool4_t __riscv_vmsgt_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vbool4_t __riscv_vmsgt_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vbool64_t __riscv_vmsgt_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vbool64_t __riscv_vmsgt_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vbool32_t __riscv_vmsgt_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vbool32_t __riscv_vmsgt_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vbool16_t __riscv_vmsgt_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vbool16_t __riscv_vmsgt_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vbool8_t __riscv_vmsgt_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vbool8_t __riscv_vmsgt_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vbool64_t __riscv_vmsge_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmsge_mu (vbool64_t mask, vbool64_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vbool32_t __riscv_vmsge_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmsge_mu (vbool32_t mask, vbool32_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vbool16_t __riscv_vmsge_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmsge_mu (vbool16_t mask, vbool16_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vbool8_t __riscv_vmsge_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vbool8_t __riscv_vmsge_mu (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vbool4_t __riscv_vmsge_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vbool4_t __riscv_vmsge_mu (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vbool2_t __riscv_vmsge_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vbool2_t __riscv_vmsge_mu (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vbool1_t __riscv_vmsge_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vbool1_t __riscv_vmsge_mu (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vbool64_t __riscv_vmsge_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmsge_mu (vbool64_t mask, vbool64_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vbool32_t __riscv_vmsge_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmsge_mu (vbool32_t mask, vbool32_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vbool16_t __riscv_vmsge_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vbool16_t __riscv_vmsge_mu (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vbool8_t __riscv_vmsge_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vbool8_t __riscv_vmsge_mu (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vbool4_t __riscv_vmsge_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vbool4_t __riscv_vmsge_mu (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vbool2_t __riscv_vmsge_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vbool2_t __riscv_vmsge_mu (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vbool64_t __riscv_vmsge_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmsge_mu (vbool64_t mask, vbool64_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vbool32_t __riscv_vmsge_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vbool32_t __riscv_vmsge_mu (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vbool16_t __riscv_vmsge_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vbool16_t __riscv_vmsge_mu (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vbool8_t __riscv_vmsge_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vbool8_t __riscv_vmsge_mu (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vbool4_t __riscv_vmsge_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vbool4_t __riscv_vmsge_mu (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vbool64_t __riscv_vmsge_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vbool64_t __riscv_vmsge_mu (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vbool32_t __riscv_vmsge_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vbool32_t __riscv_vmsge_mu (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vbool16_t __riscv_vmsge_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vbool16_t __riscv_vmsge_mu (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vbool8_t __riscv_vmsge_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vbool8_t __riscv_vmsge_mu (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vbool2_t __riscv_vmseq_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vbool2_t __riscv_vmseq_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vbool1_t __riscv_vmseq_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vbool1_t __riscv_vmseq_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vbool2_t __riscv_vmseq_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vbool2_t __riscv_vmseq_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vbool4_t __riscv_vmseq_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vbool64_t __riscv_vmseq_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vbool32_t __riscv_vmseq_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vbool16_t __riscv_vmseq_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vbool8_t __riscv_vmseq_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vbool2_t __riscv_vmsne_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vbool2_t __riscv_vmsne_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vbool1_t __riscv_vmsne_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vbool1_t __riscv_vmsne_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vbool2_t __riscv_vmsne_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vbool2_t __riscv_vmsne_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vbool4_t __riscv_vmsne_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vbool64_t __riscv_vmsne_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vbool32_t __riscv_vmsne_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vbool16_t __riscv_vmsne_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vbool8_t __riscv_vmsne_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vbool64_t __riscv_vmsltu_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmsltu_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vbool32_t __riscv_vmsltu_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmsltu_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vbool16_t __riscv_vmsltu_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmsltu_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vbool8_t __riscv_vmsltu_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vbool8_t __riscv_vmsltu_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vbool4_t __riscv_vmsltu_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vbool4_t __riscv_vmsltu_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vbool2_t __riscv_vmsltu_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vbool2_t __riscv_vmsltu_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vbool1_t __riscv_vmsltu_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vbool1_t __riscv_vmsltu_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vbool64_t __riscv_vmsltu_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmsltu_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vbool32_t __riscv_vmsltu_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmsltu_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vbool16_t __riscv_vmsltu_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vbool16_t __riscv_vmsltu_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vbool8_t __riscv_vmsltu_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vbool8_t __riscv_vmsltu_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vbool4_t __riscv_vmsltu_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vbool4_t __riscv_vmsltu_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vbool2_t __riscv_vmsltu_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vbool2_t __riscv_vmsltu_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vbool64_t __riscv_vmsltu_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmsltu_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vbool32_t __riscv_vmsltu_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vbool32_t __riscv_vmsltu_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vbool16_t __riscv_vmsltu_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vbool16_t __riscv_vmsltu_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vbool8_t __riscv_vmsltu_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vbool8_t __riscv_vmsltu_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vbool4_t __riscv_vmsltu_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vbool4_t __riscv_vmsltu_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vbool64_t __riscv_vmsltu_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vbool64_t __riscv_vmsltu_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vbool32_t __riscv_vmsltu_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vbool32_t __riscv_vmsltu_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vbool16_t __riscv_vmsltu_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vbool16_t __riscv_vmsltu_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vbool8_t __riscv_vmsltu_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vbool8_t __riscv_vmsltu_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vbool64_t __riscv_vmsleu_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmsleu_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vbool32_t __riscv_vmsleu_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmsleu_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vbool16_t __riscv_vmsleu_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmsleu_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vbool8_t __riscv_vmsleu_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vbool8_t __riscv_vmsleu_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vbool4_t __riscv_vmsleu_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vbool4_t __riscv_vmsleu_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vbool2_t __riscv_vmsleu_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vbool2_t __riscv_vmsleu_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vbool1_t __riscv_vmsleu_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vbool1_t __riscv_vmsleu_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vbool64_t __riscv_vmsleu_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmsleu_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vbool32_t __riscv_vmsleu_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmsleu_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vbool16_t __riscv_vmsleu_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vbool16_t __riscv_vmsleu_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vbool8_t __riscv_vmsleu_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vbool8_t __riscv_vmsleu_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vbool4_t __riscv_vmsleu_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vbool4_t __riscv_vmsleu_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vbool2_t __riscv_vmsleu_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vbool2_t __riscv_vmsleu_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vbool64_t __riscv_vmsleu_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmsleu_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vbool32_t __riscv_vmsleu_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vbool32_t __riscv_vmsleu_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vbool16_t __riscv_vmsleu_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vbool16_t __riscv_vmsleu_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vbool8_t __riscv_vmsleu_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vbool8_t __riscv_vmsleu_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vbool4_t __riscv_vmsleu_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vbool4_t __riscv_vmsleu_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vbool64_t __riscv_vmsleu_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vbool64_t __riscv_vmsleu_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vbool32_t __riscv_vmsleu_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vbool32_t __riscv_vmsleu_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vbool16_t __riscv_vmsleu_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vbool16_t __riscv_vmsleu_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vbool8_t __riscv_vmsleu_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vbool8_t __riscv_vmsleu_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vbool64_t __riscv_vmsgtu_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmsgtu_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vbool32_t __riscv_vmsgtu_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmsgtu_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vbool16_t __riscv_vmsgtu_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmsgtu_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vbool8_t __riscv_vmsgtu_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vbool8_t __riscv_vmsgtu_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vbool4_t __riscv_vmsgtu_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vbool4_t __riscv_vmsgtu_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vbool2_t __riscv_vmsgtu_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vbool2_t __riscv_vmsgtu_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vbool1_t __riscv_vmsgtu_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vbool1_t __riscv_vmsgtu_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vbool64_t __riscv_vmsgtu_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmsgtu_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vbool32_t __riscv_vmsgtu_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmsgtu_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vbool16_t __riscv_vmsgtu_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vbool16_t __riscv_vmsgtu_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vbool8_t __riscv_vmsgtu_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vbool8_t __riscv_vmsgtu_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vbool4_t __riscv_vmsgtu_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vbool4_t __riscv_vmsgtu_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vbool2_t __riscv_vmsgtu_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vbool2_t __riscv_vmsgtu_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vbool64_t __riscv_vmsgtu_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmsgtu_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vbool32_t __riscv_vmsgtu_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vbool32_t __riscv_vmsgtu_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vbool16_t __riscv_vmsgtu_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vbool16_t __riscv_vmsgtu_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vbool8_t __riscv_vmsgtu_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vbool8_t __riscv_vmsgtu_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vbool4_t __riscv_vmsgtu_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vbool4_t __riscv_vmsgtu_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vbool64_t __riscv_vmsgtu_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vbool64_t __riscv_vmsgtu_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vbool32_t __riscv_vmsgtu_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vbool32_t __riscv_vmsgtu_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vbool16_t __riscv_vmsgtu_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vbool16_t __riscv_vmsgtu_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vbool8_t __riscv_vmsgtu_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vbool8_t __riscv_vmsgtu_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vbool64_t __riscv_vmsgeu_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vbool64_t __riscv_vmsgeu_mu (vbool64_t mask, vbool64_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vbool32_t __riscv_vmsgeu_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vbool32_t __riscv_vmsgeu_mu (vbool32_t mask, vbool32_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vbool16_t __riscv_vmsgeu_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vbool16_t __riscv_vmsgeu_mu (vbool16_t mask, vbool16_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vbool8_t __riscv_vmsgeu_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vbool8_t __riscv_vmsgeu_mu (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vbool4_t __riscv_vmsgeu_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vbool4_t __riscv_vmsgeu_mu (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vbool2_t __riscv_vmsgeu_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vbool2_t __riscv_vmsgeu_mu (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vbool1_t __riscv_vmsgeu_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vbool1_t __riscv_vmsgeu_mu (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vbool64_t __riscv_vmsgeu_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vbool64_t __riscv_vmsgeu_mu (vbool64_t mask, vbool64_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vbool32_t __riscv_vmsgeu_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vbool32_t __riscv_vmsgeu_mu (vbool32_t mask, vbool32_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vbool16_t __riscv_vmsgeu_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vbool16_t __riscv_vmsgeu_mu (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vbool8_t __riscv_vmsgeu_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vbool8_t __riscv_vmsgeu_mu (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vbool4_t __riscv_vmsgeu_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vbool4_t __riscv_vmsgeu_mu (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vbool2_t __riscv_vmsgeu_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vbool2_t __riscv_vmsgeu_mu (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vbool64_t __riscv_vmsgeu_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vbool64_t __riscv_vmsgeu_mu (vbool64_t mask, vbool64_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vbool32_t __riscv_vmsgeu_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vbool32_t __riscv_vmsgeu_mu (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vbool16_t __riscv_vmsgeu_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vbool16_t __riscv_vmsgeu_mu (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vbool8_t __riscv_vmsgeu_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vbool8_t __riscv_vmsgeu_mu (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vbool4_t __riscv_vmsgeu_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vbool4_t __riscv_vmsgeu_mu (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vbool64_t __riscv_vmsgeu_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vbool64_t __riscv_vmsgeu_mu (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vbool32_t __riscv_vmsgeu_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vbool32_t __riscv_vmsgeu_mu (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vbool16_t __riscv_vmsgeu_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vbool16_t __riscv_vmsgeu_mu (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vbool8_t __riscv_vmsgeu_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vbool8_t __riscv_vmsgeu_mu (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
```

[[policy-variant-overloadedvector-integer-minmax]]
=== Vector Integer Min/Max Intrinsics

``` C
vint8mf8_t __riscv_vmin_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmin_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmin_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmin_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmin_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmin_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmin_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmin_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmin_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmin_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmin_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmin_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmin_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmin_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmin_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmin_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmin_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmin_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmin_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmin_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmin_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmin_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmin_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmin_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmin_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmin_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmin_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmin_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmin_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmin_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmin_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmin_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmin_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmin_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmin_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmin_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmin_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmin_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmin_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmin_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmin_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmin_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmin_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmin_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmax_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmax_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmax_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmax_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmax_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmax_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmax_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmax_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmax_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmax_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmax_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmax_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmax_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmax_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmax_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmax_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmax_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmax_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmax_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmax_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmax_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmax_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmax_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmax_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmax_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmax_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmax_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmax_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmax_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmax_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmax_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmax_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmax_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmax_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmax_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmax_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmax_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmax_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmax_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmax_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmax_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmax_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmax_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmax_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vminu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vminu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vminu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vminu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vminu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vminu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vminu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vminu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vminu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vminu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vminu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vminu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vminu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vminu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vminu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vminu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vminu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vminu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vminu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vminu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vminu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vminu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vminu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vminu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vminu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vminu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vminu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vminu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vminu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vminu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vminu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vminu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vminu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vminu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vminu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vminu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vminu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vminu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vminu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vminu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vminu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vminu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vminu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vminu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmaxu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmaxu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmaxu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmaxu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmaxu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmaxu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmaxu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmaxu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmaxu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmaxu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmaxu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmaxu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmaxu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmaxu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmaxu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmaxu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmaxu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmaxu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmaxu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmaxu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmaxu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmaxu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmaxu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmaxu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmaxu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmaxu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmaxu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmaxu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmaxu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmaxu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmaxu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmaxu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmaxu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmaxu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmaxu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmaxu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmaxu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmaxu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmaxu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmaxu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmaxu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmaxu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmaxu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmaxu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vmin_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmin_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmin_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmin_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmin_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmin_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmin_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmin_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmin_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmin_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmin_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmin_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmin_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmin_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmin_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmin_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmin_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmin_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmin_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmin_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmin_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmin_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmin_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmin_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmin_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmin_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmin_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmin_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmin_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmin_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmin_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmin_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmin_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmin_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmin_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmin_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmin_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmin_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmin_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmin_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmin_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmin_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmin_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmin_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmax_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmax_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmax_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmax_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmax_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmax_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmax_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmax_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmax_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmax_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmax_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmax_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmax_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmax_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmax_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmax_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmax_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmax_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmax_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmax_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmax_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmax_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmax_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmax_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmax_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmax_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmax_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmax_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmax_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmax_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmax_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmax_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmax_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmax_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmax_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmax_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmax_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmax_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmax_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmax_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmax_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmax_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmax_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmax_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vminu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vminu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vminu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vminu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vminu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vminu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vminu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vminu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vminu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vminu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vminu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vminu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vminu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vminu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vminu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vminu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vminu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vminu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vminu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vminu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vminu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vminu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vminu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vminu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vminu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vminu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vminu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vminu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vminu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vminu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vminu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vminu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vminu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vminu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vminu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vminu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vminu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vminu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vminu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vminu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vminu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vminu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vminu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vminu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmaxu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmaxu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmaxu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmaxu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmaxu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmaxu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmaxu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmaxu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmaxu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmaxu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmaxu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmaxu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmaxu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmaxu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmaxu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmaxu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmaxu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmaxu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmaxu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmaxu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmaxu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmaxu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmaxu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmaxu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmaxu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmaxu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmaxu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmaxu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmaxu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmaxu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmaxu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmaxu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmaxu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmaxu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmaxu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmaxu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmaxu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmaxu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmaxu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmaxu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmaxu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmaxu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmaxu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmaxu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vmin_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmin_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmin_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmin_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmin_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmin_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmin_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmin_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmin_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmin_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmin_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmin_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmin_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmin_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmin_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmin_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmin_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmin_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmin_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmin_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmin_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmin_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmin_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmin_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmin_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmin_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmin_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmin_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmin_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmin_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmin_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmin_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmin_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmin_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmin_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmin_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmin_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmin_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmin_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmin_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmin_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmin_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmin_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmin_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmax_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmax_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmax_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmax_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmax_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmax_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmax_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmax_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmax_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmax_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmax_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmax_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmax_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmax_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmax_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmax_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmax_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmax_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmax_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmax_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmax_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmax_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmax_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmax_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmax_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmax_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmax_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmax_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmax_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmax_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmax_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmax_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmax_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmax_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmax_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmax_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmax_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmax_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmax_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmax_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmax_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmax_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmax_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmax_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vminu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vminu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vminu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vminu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vminu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vminu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vminu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vminu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vminu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vminu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vminu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vminu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vminu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vminu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vminu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vminu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vminu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vminu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vminu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vminu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vminu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vminu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vminu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vminu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vminu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vminu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vminu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vminu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vminu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vminu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vminu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vminu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vminu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vminu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vminu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vminu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vminu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vminu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vminu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vminu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vminu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vminu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vminu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vminu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmaxu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmaxu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmaxu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmaxu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmaxu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmaxu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmaxu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmaxu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmaxu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmaxu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmaxu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmaxu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmaxu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmaxu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmaxu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmaxu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmaxu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmaxu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmaxu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmaxu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmaxu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmaxu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmaxu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmaxu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmaxu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmaxu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmaxu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmaxu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmaxu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmaxu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmaxu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmaxu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmaxu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmaxu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmaxu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmaxu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmaxu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmaxu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmaxu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmaxu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmaxu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmaxu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmaxu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmaxu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vmin_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmin_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmin_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmin_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmin_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmin_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmin_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmin_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmin_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmin_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmin_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmin_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmin_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmin_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmin_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmin_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmin_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmin_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmin_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmin_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmin_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmin_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmin_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmin_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmin_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmin_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmin_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmin_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmin_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmin_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmin_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmin_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmin_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmin_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmin_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmin_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmin_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmin_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmin_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmin_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmin_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmin_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmin_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmin_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmax_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmax_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmax_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmax_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmax_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmax_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmax_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmax_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmax_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmax_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmax_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmax_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmax_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmax_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmax_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmax_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmax_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmax_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmax_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmax_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmax_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmax_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmax_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmax_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmax_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmax_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmax_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmax_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmax_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmax_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmax_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmax_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmax_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmax_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmax_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmax_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmax_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmax_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmax_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmax_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmax_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmax_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmax_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmax_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vminu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vminu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vminu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vminu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vminu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vminu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vminu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vminu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vminu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vminu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vminu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vminu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vminu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vminu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vminu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vminu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vminu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vminu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vminu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vminu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vminu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vminu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vminu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vminu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vminu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vminu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vminu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vminu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vminu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vminu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vminu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vminu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vminu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vminu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vminu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vminu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vminu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vminu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vminu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vminu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vminu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vminu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vminu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vminu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmaxu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmaxu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmaxu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmaxu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmaxu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmaxu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmaxu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmaxu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmaxu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmaxu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmaxu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmaxu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmaxu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmaxu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmaxu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmaxu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmaxu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmaxu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmaxu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmaxu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmaxu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmaxu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmaxu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmaxu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmaxu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmaxu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmaxu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmaxu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmaxu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmaxu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmaxu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmaxu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmaxu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmaxu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmaxu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmaxu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmaxu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmaxu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmaxu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmaxu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmaxu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmaxu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmaxu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmaxu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
```

[[policy-variant-overloadedvector-single-width-integer-multiply]]
=== Vector Single-Width Integer Multiply Intrinsics

``` C
vint8mf8_t __riscv_vmul_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmul_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmul_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmul_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmul_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmul_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmul_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmul_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmul_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmul_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmul_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmul_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmul_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmul_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmul_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmul_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmul_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmul_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmul_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmul_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmul_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmul_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmul_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmul_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmul_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmul_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmul_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmul_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmul_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmul_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmul_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmul_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmul_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmul_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmul_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmul_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmul_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmul_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmul_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmul_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmul_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmul_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmul_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmul_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmulh_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmulh_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmulh_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmulh_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmulh_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmulh_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmulh_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmulh_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmulh_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmulh_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmulh_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmulh_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmulh_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmulh_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmulh_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmulh_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmulh_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmulh_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmulh_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmulh_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmulh_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmulh_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmulh_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmulh_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmulh_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmulh_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmulh_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmulh_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmulh_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmulh_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmulh_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmulh_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmulh_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmulh_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmulh_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmulh_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmulh_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmulh_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmulh_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmulh_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmulh_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmulh_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmulh_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmulh_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmulhsu_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmulhsu_tu (vint8mf8_t maskedoff, vint8mf8_t op1, uint8_t op2, size_t vl);
vint8mf4_t __riscv_vmulhsu_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmulhsu_tu (vint8mf4_t maskedoff, vint8mf4_t op1, uint8_t op2, size_t vl);
vint8mf2_t __riscv_vmulhsu_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmulhsu_tu (vint8mf2_t maskedoff, vint8mf2_t op1, uint8_t op2, size_t vl);
vint8m1_t __riscv_vmulhsu_tu (vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmulhsu_tu (vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2, size_t vl);
vint8m2_t __riscv_vmulhsu_tu (vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmulhsu_tu (vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2, size_t vl);
vint8m4_t __riscv_vmulhsu_tu (vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmulhsu_tu (vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2, size_t vl);
vint8m8_t __riscv_vmulhsu_tu (vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmulhsu_tu (vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2, size_t vl);
vint16mf4_t __riscv_vmulhsu_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmulhsu_tu (vint16mf4_t maskedoff, vint16mf4_t op1, uint16_t op2, size_t vl);
vint16mf2_t __riscv_vmulhsu_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmulhsu_tu (vint16mf2_t maskedoff, vint16mf2_t op1, uint16_t op2, size_t vl);
vint16m1_t __riscv_vmulhsu_tu (vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmulhsu_tu (vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2, size_t vl);
vint16m2_t __riscv_vmulhsu_tu (vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmulhsu_tu (vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2, size_t vl);
vint16m4_t __riscv_vmulhsu_tu (vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmulhsu_tu (vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2, size_t vl);
vint16m8_t __riscv_vmulhsu_tu (vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmulhsu_tu (vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2, size_t vl);
vint32mf2_t __riscv_vmulhsu_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmulhsu_tu (vint32mf2_t maskedoff, vint32mf2_t op1, uint32_t op2, size_t vl);
vint32m1_t __riscv_vmulhsu_tu (vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmulhsu_tu (vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2, size_t vl);
vint32m2_t __riscv_vmulhsu_tu (vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmulhsu_tu (vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2, size_t vl);
vint32m4_t __riscv_vmulhsu_tu (vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmulhsu_tu (vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2, size_t vl);
vint32m8_t __riscv_vmulhsu_tu (vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmulhsu_tu (vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2, size_t vl);
vint64m1_t __riscv_vmulhsu_tu (vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmulhsu_tu (vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2, size_t vl);
vint64m2_t __riscv_vmulhsu_tu (vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmulhsu_tu (vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2, size_t vl);
vint64m4_t __riscv_vmulhsu_tu (vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmulhsu_tu (vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2, size_t vl);
vint64m8_t __riscv_vmulhsu_tu (vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmulhsu_tu (vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmul_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmul_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmul_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmul_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmul_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmul_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmul_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmul_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmul_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmul_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmul_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmul_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmul_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmul_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmul_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmul_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmul_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmul_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmul_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmul_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmul_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmul_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmul_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmul_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmul_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmul_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmul_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmul_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmul_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmul_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmul_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmul_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmul_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmul_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmul_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmul_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmul_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmul_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmul_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmul_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmul_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmul_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmul_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmul_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmulhu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmulhu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmulhu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmulhu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmulhu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmulhu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmulhu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmulhu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmulhu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmulhu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmulhu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmulhu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmulhu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmulhu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmulhu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmulhu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmulhu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmulhu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmulhu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmulhu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmulhu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmulhu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmulhu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmulhu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmulhu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmulhu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmulhu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmulhu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmulhu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmulhu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmulhu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmulhu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmulhu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmulhu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmulhu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmulhu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmulhu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmulhu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmulhu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmulhu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmulhu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmulhu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmulhu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmulhu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vmul_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmul_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmul_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmul_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmul_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmul_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmul_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmul_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmul_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmul_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmul_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmul_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmul_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmul_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmul_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmul_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmul_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmul_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmul_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmul_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmul_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmul_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmul_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmul_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmul_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmul_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmul_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmul_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmul_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmul_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmul_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmul_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmul_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmul_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmul_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmul_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmul_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmul_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmul_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmul_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmul_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmul_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmul_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmul_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmulh_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmulh_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmulh_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmulh_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmulh_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmulh_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmulh_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmulh_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmulh_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmulh_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmulh_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmulh_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmulh_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmulh_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmulh_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmulh_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmulh_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmulh_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmulh_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmulh_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmulh_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmulh_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmulh_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmulh_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmulh_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmulh_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmulh_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmulh_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmulh_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmulh_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmulh_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmulh_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmulh_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmulh_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmulh_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmulh_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmulh_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmulh_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmulh_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmulh_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmulh_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmulh_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmulh_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmulh_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmulhsu_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmulhsu_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, uint8_t op2, size_t vl);
vint8mf4_t __riscv_vmulhsu_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmulhsu_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, uint8_t op2, size_t vl);
vint8mf2_t __riscv_vmulhsu_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmulhsu_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, uint8_t op2, size_t vl);
vint8m1_t __riscv_vmulhsu_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmulhsu_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2, size_t vl);
vint8m2_t __riscv_vmulhsu_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmulhsu_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2, size_t vl);
vint8m4_t __riscv_vmulhsu_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmulhsu_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2, size_t vl);
vint8m8_t __riscv_vmulhsu_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmulhsu_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2, size_t vl);
vint16mf4_t __riscv_vmulhsu_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmulhsu_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, uint16_t op2, size_t vl);
vint16mf2_t __riscv_vmulhsu_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmulhsu_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, uint16_t op2, size_t vl);
vint16m1_t __riscv_vmulhsu_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmulhsu_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2, size_t vl);
vint16m2_t __riscv_vmulhsu_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmulhsu_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2, size_t vl);
vint16m4_t __riscv_vmulhsu_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmulhsu_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2, size_t vl);
vint16m8_t __riscv_vmulhsu_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmulhsu_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2, size_t vl);
vint32mf2_t __riscv_vmulhsu_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmulhsu_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, uint32_t op2, size_t vl);
vint32m1_t __riscv_vmulhsu_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmulhsu_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2, size_t vl);
vint32m2_t __riscv_vmulhsu_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmulhsu_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2, size_t vl);
vint32m4_t __riscv_vmulhsu_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmulhsu_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2, size_t vl);
vint32m8_t __riscv_vmulhsu_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmulhsu_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2, size_t vl);
vint64m1_t __riscv_vmulhsu_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmulhsu_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2, size_t vl);
vint64m2_t __riscv_vmulhsu_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmulhsu_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2, size_t vl);
vint64m4_t __riscv_vmulhsu_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmulhsu_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2, size_t vl);
vint64m8_t __riscv_vmulhsu_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmulhsu_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmul_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmul_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmul_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmul_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmul_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmul_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmul_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmul_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmul_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmul_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmul_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmul_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmul_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmul_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmul_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmul_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmul_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmul_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmul_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmul_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmul_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmul_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmul_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmul_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmul_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmul_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmul_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmul_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmul_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmul_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmul_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmul_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmul_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmul_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmul_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmul_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmul_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmul_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmul_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmul_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmul_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmul_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmul_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmul_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmulhu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmulhu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmulhu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmulhu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmulhu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmulhu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmulhu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmulhu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmulhu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmulhu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmulhu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmulhu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmulhu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmulhu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmulhu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmulhu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmulhu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmulhu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmulhu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmulhu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmulhu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmulhu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmulhu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmulhu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmulhu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmulhu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmulhu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmulhu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmulhu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmulhu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmulhu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmulhu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmulhu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmulhu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmulhu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmulhu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmulhu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmulhu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmulhu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmulhu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmulhu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmulhu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmulhu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmulhu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vmul_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmul_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmul_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmul_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmul_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmul_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmul_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmul_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmul_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmul_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmul_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmul_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmul_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmul_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmul_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmul_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmul_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmul_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmul_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmul_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmul_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmul_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmul_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmul_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmul_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmul_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmul_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmul_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmul_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmul_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmul_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmul_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmul_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmul_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmul_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmul_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmul_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmul_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmul_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmul_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmul_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmul_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmul_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmul_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmulh_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmulh_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmulh_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmulh_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmulh_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmulh_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmulh_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmulh_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmulh_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmulh_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmulh_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmulh_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmulh_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmulh_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmulh_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmulh_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmulh_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmulh_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmulh_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmulh_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmulh_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmulh_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmulh_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmulh_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmulh_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmulh_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmulh_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmulh_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmulh_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmulh_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmulh_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmulh_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmulh_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmulh_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmulh_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmulh_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmulh_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmulh_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmulh_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmulh_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmulh_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmulh_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmulh_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmulh_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmulhsu_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmulhsu_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, uint8_t op2, size_t vl);
vint8mf4_t __riscv_vmulhsu_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmulhsu_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, uint8_t op2, size_t vl);
vint8mf2_t __riscv_vmulhsu_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmulhsu_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, uint8_t op2, size_t vl);
vint8m1_t __riscv_vmulhsu_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmulhsu_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2, size_t vl);
vint8m2_t __riscv_vmulhsu_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmulhsu_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2, size_t vl);
vint8m4_t __riscv_vmulhsu_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmulhsu_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2, size_t vl);
vint8m8_t __riscv_vmulhsu_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmulhsu_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2, size_t vl);
vint16mf4_t __riscv_vmulhsu_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmulhsu_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, uint16_t op2, size_t vl);
vint16mf2_t __riscv_vmulhsu_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmulhsu_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, uint16_t op2, size_t vl);
vint16m1_t __riscv_vmulhsu_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmulhsu_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2, size_t vl);
vint16m2_t __riscv_vmulhsu_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmulhsu_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2, size_t vl);
vint16m4_t __riscv_vmulhsu_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmulhsu_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2, size_t vl);
vint16m8_t __riscv_vmulhsu_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmulhsu_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2, size_t vl);
vint32mf2_t __riscv_vmulhsu_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmulhsu_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, uint32_t op2, size_t vl);
vint32m1_t __riscv_vmulhsu_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmulhsu_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2, size_t vl);
vint32m2_t __riscv_vmulhsu_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmulhsu_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2, size_t vl);
vint32m4_t __riscv_vmulhsu_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmulhsu_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2, size_t vl);
vint32m8_t __riscv_vmulhsu_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmulhsu_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2, size_t vl);
vint64m1_t __riscv_vmulhsu_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmulhsu_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2, size_t vl);
vint64m2_t __riscv_vmulhsu_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmulhsu_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2, size_t vl);
vint64m4_t __riscv_vmulhsu_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmulhsu_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2, size_t vl);
vint64m8_t __riscv_vmulhsu_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmulhsu_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmul_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmul_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmul_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmul_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmul_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmul_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmul_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmul_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmul_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmul_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmul_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmul_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmul_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmul_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmul_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmul_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmul_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmul_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmul_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmul_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmul_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmul_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmul_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmul_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmul_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmul_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmul_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmul_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmul_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmul_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmul_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmul_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmul_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmul_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmul_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmul_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmul_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmul_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmul_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmul_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmul_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmul_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmul_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmul_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmulhu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmulhu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmulhu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmulhu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmulhu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmulhu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmulhu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmulhu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmulhu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmulhu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmulhu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmulhu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmulhu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmulhu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmulhu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmulhu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmulhu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmulhu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmulhu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmulhu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmulhu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmulhu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmulhu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmulhu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmulhu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmulhu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmulhu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmulhu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmulhu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmulhu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmulhu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmulhu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmulhu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmulhu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmulhu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmulhu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmulhu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmulhu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmulhu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmulhu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmulhu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmulhu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmulhu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmulhu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vmul_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmul_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmul_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmul_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmul_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmul_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmul_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmul_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmul_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmul_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmul_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmul_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmul_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmul_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmul_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmul_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmul_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmul_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmul_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmul_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmul_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmul_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmul_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmul_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmul_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmul_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmul_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmul_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmul_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmul_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmul_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmul_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmul_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmul_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmul_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmul_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmul_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmul_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmul_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmul_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmul_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmul_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmul_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmul_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmulh_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmulh_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vmulh_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmulh_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vmulh_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmulh_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vmulh_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmulh_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vmulh_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmulh_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vmulh_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmulh_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vmulh_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmulh_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vmulh_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmulh_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vmulh_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmulh_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vmulh_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmulh_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vmulh_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmulh_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vmulh_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmulh_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vmulh_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmulh_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vmulh_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmulh_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vmulh_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmulh_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vmulh_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmulh_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vmulh_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmulh_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vmulh_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmulh_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vmulh_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmulh_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vmulh_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmulh_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vmulh_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmulh_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vmulh_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmulh_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vmulhsu_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vmulhsu_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, uint8_t op2, size_t vl);
vint8mf4_t __riscv_vmulhsu_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vmulhsu_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, uint8_t op2, size_t vl);
vint8mf2_t __riscv_vmulhsu_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vmulhsu_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, uint8_t op2, size_t vl);
vint8m1_t __riscv_vmulhsu_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2, size_t vl);
vint8m1_t __riscv_vmulhsu_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2, size_t vl);
vint8m2_t __riscv_vmulhsu_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2, size_t vl);
vint8m2_t __riscv_vmulhsu_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2, size_t vl);
vint8m4_t __riscv_vmulhsu_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2, size_t vl);
vint8m4_t __riscv_vmulhsu_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2, size_t vl);
vint8m8_t __riscv_vmulhsu_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2, size_t vl);
vint8m8_t __riscv_vmulhsu_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2, size_t vl);
vint16mf4_t __riscv_vmulhsu_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vmulhsu_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, uint16_t op2, size_t vl);
vint16mf2_t __riscv_vmulhsu_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vmulhsu_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, uint16_t op2, size_t vl);
vint16m1_t __riscv_vmulhsu_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint16m1_t __riscv_vmulhsu_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2, size_t vl);
vint16m2_t __riscv_vmulhsu_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint16m2_t __riscv_vmulhsu_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2, size_t vl);
vint16m4_t __riscv_vmulhsu_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint16m4_t __riscv_vmulhsu_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2, size_t vl);
vint16m8_t __riscv_vmulhsu_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2, size_t vl);
vint16m8_t __riscv_vmulhsu_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2, size_t vl);
vint32mf2_t __riscv_vmulhsu_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vmulhsu_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, uint32_t op2, size_t vl);
vint32m1_t __riscv_vmulhsu_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2, size_t vl);
vint32m1_t __riscv_vmulhsu_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2, size_t vl);
vint32m2_t __riscv_vmulhsu_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2, size_t vl);
vint32m2_t __riscv_vmulhsu_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2, size_t vl);
vint32m4_t __riscv_vmulhsu_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2, size_t vl);
vint32m4_t __riscv_vmulhsu_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2, size_t vl);
vint32m8_t __riscv_vmulhsu_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2, size_t vl);
vint32m8_t __riscv_vmulhsu_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2, size_t vl);
vint64m1_t __riscv_vmulhsu_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2, size_t vl);
vint64m1_t __riscv_vmulhsu_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2, size_t vl);
vint64m2_t __riscv_vmulhsu_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2, size_t vl);
vint64m2_t __riscv_vmulhsu_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2, size_t vl);
vint64m4_t __riscv_vmulhsu_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2, size_t vl);
vint64m4_t __riscv_vmulhsu_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2, size_t vl);
vint64m8_t __riscv_vmulhsu_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2, size_t vl);
vint64m8_t __riscv_vmulhsu_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmul_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmul_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmul_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmul_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmul_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmul_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmul_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmul_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmul_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmul_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmul_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmul_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmul_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmul_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmul_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmul_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmul_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmul_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmul_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmul_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmul_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmul_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmul_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmul_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmul_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmul_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmul_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmul_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmul_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmul_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmul_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmul_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmul_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmul_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmul_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmul_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmul_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmul_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmul_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmul_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmul_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmul_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmul_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmul_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vmulhu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vmulhu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vmulhu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vmulhu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vmulhu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vmulhu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vmulhu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vmulhu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vmulhu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vmulhu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vmulhu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vmulhu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vmulhu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vmulhu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vmulhu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vmulhu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vmulhu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vmulhu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vmulhu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vmulhu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vmulhu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vmulhu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vmulhu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vmulhu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vmulhu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vmulhu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vmulhu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vmulhu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vmulhu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vmulhu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vmulhu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vmulhu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vmulhu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vmulhu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vmulhu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vmulhu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vmulhu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vmulhu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vmulhu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vmulhu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vmulhu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vmulhu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vmulhu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vmulhu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
```

[[policy-variant-overloadedvector-integer-divide]]
=== Vector Integer Divide Intrinsics

``` C
vint8mf8_t __riscv_vdiv_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vdiv_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vdiv_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vdiv_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vdiv_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vdiv_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vdiv_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vdiv_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vdiv_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vdiv_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vdiv_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vdiv_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vdiv_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vdiv_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vdiv_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vdiv_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vdiv_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vdiv_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vdiv_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vdiv_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vdiv_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vdiv_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vdiv_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vdiv_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vdiv_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vdiv_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vdiv_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vdiv_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vdiv_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vdiv_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vdiv_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vdiv_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vdiv_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vdiv_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vdiv_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vdiv_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vdiv_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vdiv_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vdiv_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vdiv_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vdiv_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vdiv_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vdiv_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vdiv_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vrem_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vrem_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vrem_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vrem_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vrem_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vrem_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vrem_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vrem_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vrem_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vrem_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vrem_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vrem_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vrem_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vrem_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vrem_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vrem_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vrem_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vrem_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vrem_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vrem_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vrem_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vrem_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vrem_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vrem_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vrem_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vrem_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vrem_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vrem_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vrem_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vrem_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vrem_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vrem_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vrem_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vrem_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vrem_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vrem_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vrem_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vrem_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vrem_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vrem_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vrem_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vrem_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vrem_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vrem_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vdivu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vdivu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vdivu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vdivu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vdivu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vdivu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vdivu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vdivu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vdivu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vdivu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vdivu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vdivu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vdivu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vdivu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vdivu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vdivu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vdivu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vdivu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vdivu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vdivu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vdivu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vdivu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vdivu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vdivu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vdivu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vdivu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vdivu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vdivu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vdivu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vdivu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vdivu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vdivu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vdivu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vdivu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vdivu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vdivu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vdivu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vdivu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vdivu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vdivu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vdivu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vdivu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vdivu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vdivu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vremu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vremu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vremu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vremu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vremu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vremu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vremu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vremu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vremu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vremu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vremu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vremu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vremu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vremu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vremu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vremu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vremu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vremu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vremu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vremu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vremu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vremu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vremu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vremu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vremu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vremu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vremu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vremu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vremu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vremu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vremu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vremu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vremu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vremu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vremu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vremu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vremu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vremu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vremu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vremu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vremu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vremu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vremu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vremu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vdiv_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vdiv_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vdiv_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vdiv_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vdiv_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vdiv_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vdiv_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vdiv_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vdiv_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vdiv_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vdiv_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vdiv_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vdiv_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vdiv_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vdiv_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vdiv_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vdiv_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vdiv_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vdiv_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vdiv_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vdiv_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vdiv_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vdiv_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vdiv_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vdiv_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vdiv_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vdiv_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vdiv_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vdiv_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vdiv_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vdiv_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vdiv_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vdiv_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vdiv_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vdiv_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vdiv_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vdiv_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vdiv_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vdiv_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vdiv_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vdiv_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vdiv_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vdiv_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vdiv_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vrem_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vrem_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vrem_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vrem_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vrem_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vrem_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vrem_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vrem_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vrem_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vrem_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vrem_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vrem_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vrem_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vrem_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vrem_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vrem_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vrem_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vrem_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vrem_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vrem_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vrem_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vrem_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vrem_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vrem_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vrem_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vrem_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vrem_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vrem_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vrem_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vrem_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vrem_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vrem_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vrem_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vrem_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vrem_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vrem_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vrem_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vrem_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vrem_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vrem_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vrem_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vrem_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vrem_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vrem_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vdivu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vdivu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vdivu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vdivu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vdivu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vdivu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vdivu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vdivu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vdivu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vdivu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vdivu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vdivu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vdivu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vdivu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vdivu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vdivu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vdivu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vdivu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vdivu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vdivu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vdivu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vdivu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vdivu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vdivu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vdivu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vdivu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vdivu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vdivu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vdivu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vdivu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vdivu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vdivu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vdivu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vdivu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vdivu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vdivu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vdivu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vdivu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vdivu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vdivu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vdivu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vdivu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vdivu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vdivu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vremu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vremu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vremu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vremu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vremu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vremu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vremu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vremu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vremu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vremu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vremu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vremu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vremu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vremu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vremu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vremu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vremu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vremu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vremu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vremu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vremu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vremu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vremu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vremu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vremu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vremu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vremu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vremu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vremu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vremu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vremu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vremu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vremu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vremu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vremu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vremu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vremu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vremu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vremu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vremu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vremu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vremu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vremu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vremu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vdiv_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vdiv_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vdiv_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vdiv_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vdiv_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vdiv_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vdiv_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vdiv_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vdiv_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vdiv_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vdiv_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vdiv_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vdiv_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vdiv_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vdiv_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vdiv_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vdiv_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vdiv_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vdiv_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vdiv_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vdiv_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vdiv_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vdiv_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vdiv_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vdiv_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vdiv_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vdiv_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vdiv_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vdiv_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vdiv_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vdiv_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vdiv_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vdiv_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vdiv_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vdiv_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vdiv_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vdiv_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vdiv_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vdiv_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vdiv_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vdiv_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vdiv_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vdiv_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vdiv_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vrem_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vrem_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vrem_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vrem_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vrem_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vrem_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vrem_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vrem_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vrem_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vrem_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vrem_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vrem_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vrem_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vrem_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vrem_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vrem_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vrem_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vrem_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vrem_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vrem_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vrem_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vrem_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vrem_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vrem_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vrem_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vrem_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vrem_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vrem_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vrem_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vrem_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vrem_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vrem_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vrem_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vrem_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vrem_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vrem_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vrem_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vrem_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vrem_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vrem_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vrem_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vrem_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vrem_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vrem_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vdivu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vdivu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vdivu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vdivu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vdivu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vdivu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vdivu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vdivu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vdivu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vdivu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vdivu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vdivu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vdivu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vdivu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vdivu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vdivu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vdivu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vdivu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vdivu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vdivu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vdivu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vdivu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vdivu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vdivu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vdivu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vdivu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vdivu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vdivu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vdivu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vdivu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vdivu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vdivu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vdivu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vdivu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vdivu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vdivu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vdivu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vdivu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vdivu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vdivu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vdivu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vdivu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vdivu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vdivu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vremu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vremu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vremu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vremu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vremu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vremu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vremu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vremu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vremu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vremu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vremu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vremu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vremu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vremu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vremu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vremu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vremu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vremu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vremu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vremu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vremu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vremu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vremu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vremu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vremu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vremu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vremu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vremu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vremu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vremu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vremu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vremu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vremu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vremu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vremu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vremu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vremu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vremu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vremu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vremu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vremu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vremu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vremu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vremu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vdiv_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vdiv_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vdiv_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vdiv_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vdiv_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vdiv_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vdiv_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vdiv_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vdiv_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vdiv_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vdiv_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vdiv_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vdiv_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vdiv_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vdiv_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vdiv_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vdiv_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vdiv_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vdiv_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vdiv_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vdiv_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vdiv_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vdiv_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vdiv_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vdiv_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vdiv_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vdiv_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vdiv_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vdiv_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vdiv_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vdiv_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vdiv_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vdiv_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vdiv_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vdiv_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vdiv_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vdiv_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vdiv_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vdiv_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vdiv_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vdiv_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vdiv_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vdiv_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vdiv_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vrem_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vrem_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vrem_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vrem_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vrem_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vrem_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vrem_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vrem_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vrem_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vrem_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vrem_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vrem_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vrem_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vrem_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vrem_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vrem_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vrem_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vrem_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vrem_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vrem_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vrem_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vrem_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vrem_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vrem_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vrem_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vrem_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vrem_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vrem_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vrem_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vrem_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vrem_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vrem_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vrem_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vrem_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vrem_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vrem_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vrem_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vrem_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vrem_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vrem_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vrem_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vrem_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vrem_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vrem_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vdivu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vdivu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vdivu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vdivu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vdivu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vdivu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vdivu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vdivu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vdivu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vdivu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vdivu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vdivu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vdivu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vdivu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vdivu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vdivu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vdivu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vdivu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vdivu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vdivu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vdivu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vdivu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vdivu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vdivu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vdivu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vdivu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vdivu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vdivu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vdivu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vdivu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vdivu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vdivu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vdivu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vdivu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vdivu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vdivu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vdivu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vdivu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vdivu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vdivu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vdivu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vdivu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vdivu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vdivu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vremu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vremu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vremu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vremu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vremu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vremu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vremu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vremu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vremu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vremu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vremu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vremu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vremu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vremu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vremu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vremu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vremu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vremu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vremu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vremu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vremu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vremu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vremu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vremu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vremu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vremu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vremu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vremu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vremu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vremu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vremu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vremu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vremu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vremu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vremu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vremu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vremu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vremu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vremu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vremu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vremu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vremu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vremu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vremu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
```

[[policy-variant-overloadedvector-widening-integer-multiply]]
=== Vector Widening Integer Multiply Intrinsics

``` C
vint16mf4_t __riscv_vwmul_tu (vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwmul_tu (vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwmul_tu (vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwmul_tu (vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwmul_tu (vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwmul_tu (vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwmul_tu (vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwmul_tu (vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwmul_tu (vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwmul_tu (vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwmul_tu (vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwmul_tu (vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwmul_tu (vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwmul_tu (vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwmul_tu (vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwmul_tu (vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwmul_tu (vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwmul_tu (vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwmul_tu (vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwmul_tu (vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwmul_tu (vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwmul_tu (vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwmul_tu (vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwmul_tu (vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwmul_tu (vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwmul_tu (vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwmul_tu (vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwmul_tu (vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwmul_tu (vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwmul_tu (vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint16mf4_t __riscv_vwmulsu_tu (vint16mf4_t maskedoff, vint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwmulsu_tu (vint16mf4_t maskedoff, vint8mf8_t op1, uint8_t op2, size_t vl);
vint16mf2_t __riscv_vwmulsu_tu (vint16mf2_t maskedoff, vint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwmulsu_tu (vint16mf2_t maskedoff, vint8mf4_t op1, uint8_t op2, size_t vl);
vint16m1_t __riscv_vwmulsu_tu (vint16m1_t maskedoff, vint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwmulsu_tu (vint16m1_t maskedoff, vint8mf2_t op1, uint8_t op2, size_t vl);
vint16m2_t __riscv_vwmulsu_tu (vint16m2_t maskedoff, vint8m1_t op1, vuint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwmulsu_tu (vint16m2_t maskedoff, vint8m1_t op1, uint8_t op2, size_t vl);
vint16m4_t __riscv_vwmulsu_tu (vint16m4_t maskedoff, vint8m2_t op1, vuint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwmulsu_tu (vint16m4_t maskedoff, vint8m2_t op1, uint8_t op2, size_t vl);
vint16m8_t __riscv_vwmulsu_tu (vint16m8_t maskedoff, vint8m4_t op1, vuint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwmulsu_tu (vint16m8_t maskedoff, vint8m4_t op1, uint8_t op2, size_t vl);
vint32mf2_t __riscv_vwmulsu_tu (vint32mf2_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwmulsu_tu (vint32mf2_t maskedoff, vint16mf4_t op1, uint16_t op2, size_t vl);
vint32m1_t __riscv_vwmulsu_tu (vint32m1_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwmulsu_tu (vint32m1_t maskedoff, vint16mf2_t op1, uint16_t op2, size_t vl);
vint32m2_t __riscv_vwmulsu_tu (vint32m2_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwmulsu_tu (vint32m2_t maskedoff, vint16m1_t op1, uint16_t op2, size_t vl);
vint32m4_t __riscv_vwmulsu_tu (vint32m4_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwmulsu_tu (vint32m4_t maskedoff, vint16m2_t op1, uint16_t op2, size_t vl);
vint32m8_t __riscv_vwmulsu_tu (vint32m8_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwmulsu_tu (vint32m8_t maskedoff, vint16m4_t op1, uint16_t op2, size_t vl);
vint64m1_t __riscv_vwmulsu_tu (vint64m1_t maskedoff, vint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwmulsu_tu (vint64m1_t maskedoff, vint32mf2_t op1, uint32_t op2, size_t vl);
vint64m2_t __riscv_vwmulsu_tu (vint64m2_t maskedoff, vint32m1_t op1, vuint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwmulsu_tu (vint64m2_t maskedoff, vint32m1_t op1, uint32_t op2, size_t vl);
vint64m4_t __riscv_vwmulsu_tu (vint64m4_t maskedoff, vint32m2_t op1, vuint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwmulsu_tu (vint64m4_t maskedoff, vint32m2_t op1, uint32_t op2, size_t vl);
vint64m8_t __riscv_vwmulsu_tu (vint64m8_t maskedoff, vint32m4_t op1, vuint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwmulsu_tu (vint64m8_t maskedoff, vint32m4_t op1, uint32_t op2, size_t vl);
vuint16mf4_t __riscv_vwmulu_tu (vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwmulu_tu (vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwmulu_tu (vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwmulu_tu (vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwmulu_tu (vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwmulu_tu (vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwmulu_tu (vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwmulu_tu (vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwmulu_tu (vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwmulu_tu (vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwmulu_tu (vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwmulu_tu (vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwmulu_tu (vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwmulu_tu (vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwmulu_tu (vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwmulu_tu (vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwmulu_tu (vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwmulu_tu (vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwmulu_tu (vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwmulu_tu (vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwmulu_tu (vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwmulu_tu (vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwmulu_tu (vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwmulu_tu (vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwmulu_tu (vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwmulu_tu (vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwmulu_tu (vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwmulu_tu (vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwmulu_tu (vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwmulu_tu (vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwmul_tum (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwmul_tum (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwmul_tum (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwmul_tum (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwmul_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwmul_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwmul_tum (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwmul_tum (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwmul_tum (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwmul_tum (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwmul_tum (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwmul_tum (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwmul_tum (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwmul_tum (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwmul_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwmul_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwmul_tum (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwmul_tum (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwmul_tum (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwmul_tum (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwmul_tum (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwmul_tum (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwmul_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwmul_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwmul_tum (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwmul_tum (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwmul_tum (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwmul_tum (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwmul_tum (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwmul_tum (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint16mf4_t __riscv_vwmulsu_tum (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwmulsu_tum (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, uint8_t op2, size_t vl);
vint16mf2_t __riscv_vwmulsu_tum (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwmulsu_tum (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, uint8_t op2, size_t vl);
vint16m1_t __riscv_vwmulsu_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwmulsu_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, uint8_t op2, size_t vl);
vint16m2_t __riscv_vwmulsu_tum (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vuint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwmulsu_tum (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, uint8_t op2, size_t vl);
vint16m4_t __riscv_vwmulsu_tum (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vuint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwmulsu_tum (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, uint8_t op2, size_t vl);
vint16m8_t __riscv_vwmulsu_tum (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vuint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwmulsu_tum (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, uint8_t op2, size_t vl);
vint32mf2_t __riscv_vwmulsu_tum (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwmulsu_tum (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, uint16_t op2, size_t vl);
vint32m1_t __riscv_vwmulsu_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwmulsu_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, uint16_t op2, size_t vl);
vint32m2_t __riscv_vwmulsu_tum (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwmulsu_tum (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, uint16_t op2, size_t vl);
vint32m4_t __riscv_vwmulsu_tum (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwmulsu_tum (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, uint16_t op2, size_t vl);
vint32m8_t __riscv_vwmulsu_tum (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwmulsu_tum (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, uint16_t op2, size_t vl);
vint64m1_t __riscv_vwmulsu_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwmulsu_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, uint32_t op2, size_t vl);
vint64m2_t __riscv_vwmulsu_tum (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vuint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwmulsu_tum (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, uint32_t op2, size_t vl);
vint64m4_t __riscv_vwmulsu_tum (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vuint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwmulsu_tum (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, uint32_t op2, size_t vl);
vint64m8_t __riscv_vwmulsu_tum (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vuint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwmulsu_tum (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, uint32_t op2, size_t vl);
vuint16mf4_t __riscv_vwmulu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwmulu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwmulu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwmulu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwmulu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwmulu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwmulu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwmulu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwmulu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwmulu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwmulu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwmulu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwmulu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwmulu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwmulu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwmulu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwmulu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwmulu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwmulu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwmulu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwmulu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwmulu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwmulu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwmulu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwmulu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwmulu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwmulu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwmulu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwmulu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwmulu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwmul_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwmul_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwmul_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwmul_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwmul_tumu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwmul_tumu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwmul_tumu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwmul_tumu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwmul_tumu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwmul_tumu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwmul_tumu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwmul_tumu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwmul_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwmul_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwmul_tumu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwmul_tumu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwmul_tumu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwmul_tumu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwmul_tumu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwmul_tumu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwmul_tumu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwmul_tumu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwmul_tumu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwmul_tumu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwmul_tumu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwmul_tumu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwmul_tumu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwmul_tumu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwmul_tumu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwmul_tumu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint16mf4_t __riscv_vwmulsu_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwmulsu_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, uint8_t op2, size_t vl);
vint16mf2_t __riscv_vwmulsu_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwmulsu_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, uint8_t op2, size_t vl);
vint16m1_t __riscv_vwmulsu_tumu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwmulsu_tumu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, uint8_t op2, size_t vl);
vint16m2_t __riscv_vwmulsu_tumu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vuint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwmulsu_tumu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, uint8_t op2, size_t vl);
vint16m4_t __riscv_vwmulsu_tumu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vuint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwmulsu_tumu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, uint8_t op2, size_t vl);
vint16m8_t __riscv_vwmulsu_tumu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vuint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwmulsu_tumu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, uint8_t op2, size_t vl);
vint32mf2_t __riscv_vwmulsu_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwmulsu_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, uint16_t op2, size_t vl);
vint32m1_t __riscv_vwmulsu_tumu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwmulsu_tumu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, uint16_t op2, size_t vl);
vint32m2_t __riscv_vwmulsu_tumu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwmulsu_tumu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, uint16_t op2, size_t vl);
vint32m4_t __riscv_vwmulsu_tumu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwmulsu_tumu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, uint16_t op2, size_t vl);
vint32m8_t __riscv_vwmulsu_tumu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwmulsu_tumu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, uint16_t op2, size_t vl);
vint64m1_t __riscv_vwmulsu_tumu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwmulsu_tumu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, uint32_t op2, size_t vl);
vint64m2_t __riscv_vwmulsu_tumu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vuint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwmulsu_tumu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, uint32_t op2, size_t vl);
vint64m4_t __riscv_vwmulsu_tumu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vuint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwmulsu_tumu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, uint32_t op2, size_t vl);
vint64m8_t __riscv_vwmulsu_tumu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vuint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwmulsu_tumu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, uint32_t op2, size_t vl);
vuint16mf4_t __riscv_vwmulu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwmulu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwmulu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwmulu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwmulu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwmulu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwmulu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwmulu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwmulu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwmulu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwmulu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwmulu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwmulu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwmulu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwmulu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwmulu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwmulu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwmulu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwmulu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwmulu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwmulu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwmulu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwmulu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwmulu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwmulu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwmulu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwmulu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwmulu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwmulu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwmulu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwmul_mu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwmul_mu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint16mf2_t __riscv_vwmul_mu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwmul_mu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint16m1_t __riscv_vwmul_mu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwmul_mu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint16m2_t __riscv_vwmul_mu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwmul_mu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint16m4_t __riscv_vwmul_mu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwmul_mu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint16m8_t __riscv_vwmul_mu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwmul_mu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint32mf2_t __riscv_vwmul_mu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwmul_mu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint32m1_t __riscv_vwmul_mu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwmul_mu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint32m2_t __riscv_vwmul_mu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwmul_mu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint32m4_t __riscv_vwmul_mu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwmul_mu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint32m8_t __riscv_vwmul_mu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwmul_mu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint64m1_t __riscv_vwmul_mu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwmul_mu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint64m2_t __riscv_vwmul_mu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwmul_mu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint64m4_t __riscv_vwmul_mu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwmul_mu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint64m8_t __riscv_vwmul_mu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwmul_mu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint16mf4_t __riscv_vwmulsu_mu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vint16mf4_t __riscv_vwmulsu_mu (vbool64_t mask, vint16mf4_t maskedoff, vint8mf8_t op1, uint8_t op2, size_t vl);
vint16mf2_t __riscv_vwmulsu_mu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vint16mf2_t __riscv_vwmulsu_mu (vbool32_t mask, vint16mf2_t maskedoff, vint8mf4_t op1, uint8_t op2, size_t vl);
vint16m1_t __riscv_vwmulsu_mu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vint16m1_t __riscv_vwmulsu_mu (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t op1, uint8_t op2, size_t vl);
vint16m2_t __riscv_vwmulsu_mu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vuint8m1_t op2, size_t vl);
vint16m2_t __riscv_vwmulsu_mu (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, uint8_t op2, size_t vl);
vint16m4_t __riscv_vwmulsu_mu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vuint8m2_t op2, size_t vl);
vint16m4_t __riscv_vwmulsu_mu (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, uint8_t op2, size_t vl);
vint16m8_t __riscv_vwmulsu_mu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vuint8m4_t op2, size_t vl);
vint16m8_t __riscv_vwmulsu_mu (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, uint8_t op2, size_t vl);
vint32mf2_t __riscv_vwmulsu_mu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint32mf2_t __riscv_vwmulsu_mu (vbool64_t mask, vint32mf2_t maskedoff, vint16mf4_t op1, uint16_t op2, size_t vl);
vint32m1_t __riscv_vwmulsu_mu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint32m1_t __riscv_vwmulsu_mu (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t op1, uint16_t op2, size_t vl);
vint32m2_t __riscv_vwmulsu_mu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint32m2_t __riscv_vwmulsu_mu (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, uint16_t op2, size_t vl);
vint32m4_t __riscv_vwmulsu_mu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint32m4_t __riscv_vwmulsu_mu (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, uint16_t op2, size_t vl);
vint32m8_t __riscv_vwmulsu_mu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint32m8_t __riscv_vwmulsu_mu (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, uint16_t op2, size_t vl);
vint64m1_t __riscv_vwmulsu_mu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vint64m1_t __riscv_vwmulsu_mu (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t op1, uint32_t op2, size_t vl);
vint64m2_t __riscv_vwmulsu_mu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vuint32m1_t op2, size_t vl);
vint64m2_t __riscv_vwmulsu_mu (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, uint32_t op2, size_t vl);
vint64m4_t __riscv_vwmulsu_mu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vuint32m2_t op2, size_t vl);
vint64m4_t __riscv_vwmulsu_mu (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, uint32_t op2, size_t vl);
vint64m8_t __riscv_vwmulsu_mu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vuint32m4_t op2, size_t vl);
vint64m8_t __riscv_vwmulsu_mu (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, uint32_t op2, size_t vl);
vuint16mf4_t __riscv_vwmulu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint16mf4_t __riscv_vwmulu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint16mf2_t __riscv_vwmulu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vwmulu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint16m1_t __riscv_vwmulu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint16m1_t __riscv_vwmulu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint16m2_t __riscv_vwmulu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint16m2_t __riscv_vwmulu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint16m4_t __riscv_vwmulu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint16m4_t __riscv_vwmulu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint16m8_t __riscv_vwmulu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint16m8_t __riscv_vwmulu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint32mf2_t __riscv_vwmulu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint32mf2_t __riscv_vwmulu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint32m1_t __riscv_vwmulu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint32m1_t __riscv_vwmulu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint32m2_t __riscv_vwmulu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint32m2_t __riscv_vwmulu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint32m4_t __riscv_vwmulu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint32m4_t __riscv_vwmulu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint32m8_t __riscv_vwmulu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint32m8_t __riscv_vwmulu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint64m1_t __riscv_vwmulu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint64m1_t __riscv_vwmulu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint64m2_t __riscv_vwmulu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint64m2_t __riscv_vwmulu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint64m4_t __riscv_vwmulu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint64m4_t __riscv_vwmulu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint64m8_t __riscv_vwmulu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint64m8_t __riscv_vwmulu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
```

[[policy-variant-overloadedvector-single-width-integer-multiply-add]]
=== Vector Single-Width Integer Multiply-Add Intrinsics

``` C
vint8mf8_t __riscv_vmacc_tu (vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmacc_tu (vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc_tu (vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc_tu (vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc_tu (vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc_tu (vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmacc_tu (vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmacc_tu (vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmacc_tu (vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmacc_tu (vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmacc_tu (vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmacc_tu (vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmacc_tu (vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmacc_tu (vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc_tu (vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc_tu (vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_tu (vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_tu (vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_tu (vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_tu (vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmacc_tu (vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmacc_tu (vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmacc_tu (vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmacc_tu (vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmacc_tu (vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmacc_tu (vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc_tu (vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc_tu (vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_tu (vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_tu (vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmacc_tu (vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmacc_tu (vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmacc_tu (vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmacc_tu (vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmacc_tu (vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmacc_tu (vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmacc_tu (vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmacc_tu (vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmacc_tu (vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmacc_tu (vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmacc_tu (vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmacc_tu (vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmacc_tu (vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmacc_tu (vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_tu (vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_tu (vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_tu (vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_tu (vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_tu (vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_tu (vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac_tu (vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac_tu (vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac_tu (vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac_tu (vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac_tu (vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac_tu (vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac_tu (vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac_tu (vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac_tu (vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac_tu (vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_tu (vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_tu (vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_tu (vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_tu (vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_tu (vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_tu (vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_tu (vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_tu (vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_tu (vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_tu (vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac_tu (vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac_tu (vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_tu (vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_tu (vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_tu (vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_tu (vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_tu (vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_tu (vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_tu (vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_tu (vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_tu (vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_tu (vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_tu (vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_tu (vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_tu (vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_tu (vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_tu (vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_tu (vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd_tu (vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd_tu (vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd_tu (vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd_tu (vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd_tu (vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd_tu (vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmadd_tu (vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmadd_tu (vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmadd_tu (vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmadd_tu (vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmadd_tu (vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmadd_tu (vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmadd_tu (vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmadd_tu (vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd_tu (vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd_tu (vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_tu (vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_tu (vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_tu (vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_tu (vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmadd_tu (vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmadd_tu (vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmadd_tu (vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmadd_tu (vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmadd_tu (vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmadd_tu (vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd_tu (vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd_tu (vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_tu (vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_tu (vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmadd_tu (vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmadd_tu (vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmadd_tu (vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmadd_tu (vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmadd_tu (vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmadd_tu (vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmadd_tu (vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmadd_tu (vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmadd_tu (vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmadd_tu (vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmadd_tu (vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmadd_tu (vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmadd_tu (vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmadd_tu (vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_tu (vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_tu (vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_tu (vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_tu (vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_tu (vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_tu (vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub_tu (vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub_tu (vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub_tu (vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub_tu (vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub_tu (vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub_tu (vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub_tu (vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub_tu (vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub_tu (vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub_tu (vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_tu (vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_tu (vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_tu (vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_tu (vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_tu (vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_tu (vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_tu (vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_tu (vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_tu (vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_tu (vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub_tu (vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub_tu (vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_tu (vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_tu (vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_tu (vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_tu (vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_tu (vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_tu (vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_tu (vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_tu (vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_tu (vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_tu (vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_tu (vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_tu (vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_tu (vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_tu (vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_tu (vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_tu (vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc_tu (vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc_tu (vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc_tu (vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc_tu (vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc_tu (vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc_tu (vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc_tu (vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc_tu (vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc_tu (vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc_tu (vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc_tu (vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc_tu (vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc_tu (vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc_tu (vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc_tu (vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc_tu (vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc_tu (vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc_tu (vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc_tu (vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc_tu (vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_tu (vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_tu (vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_tu (vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_tu (vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_tu (vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_tu (vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_tu (vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_tu (vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc_tu (vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc_tu (vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_tu (vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_tu (vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_tu (vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_tu (vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_tu (vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_tu (vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_tu (vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_tu (vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_tu (vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_tu (vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_tu (vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_tu (vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_tu (vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_tu (vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_tu (vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_tu (vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_tu (vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_tu (vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_tu (vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_tu (vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_tu (vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_tu (vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac_tu (vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac_tu (vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac_tu (vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac_tu (vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac_tu (vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac_tu (vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac_tu (vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac_tu (vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac_tu (vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac_tu (vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac_tu (vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac_tu (vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_tu (vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_tu (vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_tu (vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_tu (vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_tu (vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_tu (vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_tu (vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_tu (vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac_tu (vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac_tu (vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_tu (vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_tu (vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_tu (vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_tu (vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_tu (vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_tu (vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_tu (vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_tu (vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_tu (vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_tu (vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_tu (vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_tu (vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_tu (vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_tu (vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_tu (vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_tu (vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd_tu (vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd_tu (vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd_tu (vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd_tu (vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd_tu (vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd_tu (vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd_tu (vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd_tu (vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd_tu (vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd_tu (vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd_tu (vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd_tu (vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd_tu (vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd_tu (vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd_tu (vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd_tu (vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd_tu (vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd_tu (vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_tu (vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_tu (vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_tu (vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_tu (vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_tu (vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_tu (vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_tu (vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_tu (vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd_tu (vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd_tu (vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_tu (vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_tu (vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_tu (vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_tu (vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_tu (vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_tu (vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_tu (vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_tu (vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_tu (vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_tu (vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_tu (vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_tu (vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_tu (vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_tu (vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_tu (vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_tu (vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_tu (vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_tu (vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_tu (vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_tu (vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_tu (vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_tu (vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub_tu (vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub_tu (vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub_tu (vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub_tu (vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub_tu (vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub_tu (vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub_tu (vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub_tu (vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub_tu (vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub_tu (vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub_tu (vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub_tu (vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_tu (vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_tu (vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_tu (vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_tu (vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_tu (vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_tu (vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_tu (vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_tu (vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub_tu (vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub_tu (vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_tu (vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_tu (vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_tu (vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_tu (vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_tu (vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_tu (vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_tu (vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_tu (vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_tu (vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_tu (vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_tu (vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_tu (vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_tu (vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_tu (vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
// masked functions
vint8mf8_t __riscv_vmacc_tum (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmacc_tum (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc_tum (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc_tum (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc_tum (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc_tum (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmacc_tum (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmacc_tum (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmacc_tum (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmacc_tum (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmacc_tum (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmacc_tum (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmacc_tum (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmacc_tum (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc_tum (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc_tum (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_tum (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_tum (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_tum (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_tum (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmacc_tum (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmacc_tum (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmacc_tum (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmacc_tum (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmacc_tum (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmacc_tum (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc_tum (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc_tum (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_tum (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_tum (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmacc_tum (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmacc_tum (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmacc_tum (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmacc_tum (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmacc_tum (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmacc_tum (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmacc_tum (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmacc_tum (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmacc_tum (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmacc_tum (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmacc_tum (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmacc_tum (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmacc_tum (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmacc_tum (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_tum (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_tum (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_tum (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_tum (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_tum (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_tum (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac_tum (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac_tum (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac_tum (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac_tum (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac_tum (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac_tum (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac_tum (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac_tum (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac_tum (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac_tum (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_tum (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_tum (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_tum (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_tum (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_tum (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_tum (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_tum (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_tum (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_tum (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_tum (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac_tum (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac_tum (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_tum (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_tum (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_tum (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_tum (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_tum (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_tum (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_tum (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_tum (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_tum (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_tum (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_tum (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_tum (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_tum (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_tum (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_tum (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_tum (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd_tum (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd_tum (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd_tum (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd_tum (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd_tum (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd_tum (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmadd_tum (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmadd_tum (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmadd_tum (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmadd_tum (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmadd_tum (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmadd_tum (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmadd_tum (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmadd_tum (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd_tum (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd_tum (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_tum (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_tum (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_tum (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_tum (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmadd_tum (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmadd_tum (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmadd_tum (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmadd_tum (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmadd_tum (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmadd_tum (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd_tum (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd_tum (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_tum (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_tum (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmadd_tum (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmadd_tum (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmadd_tum (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmadd_tum (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmadd_tum (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmadd_tum (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmadd_tum (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmadd_tum (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmadd_tum (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmadd_tum (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmadd_tum (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmadd_tum (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmadd_tum (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmadd_tum (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_tum (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_tum (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_tum (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_tum (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_tum (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_tum (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub_tum (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub_tum (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub_tum (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub_tum (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub_tum (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub_tum (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub_tum (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub_tum (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub_tum (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub_tum (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_tum (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_tum (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_tum (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_tum (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_tum (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_tum (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_tum (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_tum (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_tum (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_tum (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub_tum (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub_tum (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_tum (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_tum (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_tum (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_tum (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_tum (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_tum (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_tum (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_tum (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_tum (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_tum (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_tum (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_tum (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_tum (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_tum (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_tum (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_tum (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc_tum (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc_tum (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc_tum (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc_tum (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc_tum (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc_tum (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc_tum (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc_tum (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc_tum (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc_tum (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc_tum (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc_tum (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc_tum (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc_tum (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc_tum (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc_tum (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc_tum (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc_tum (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc_tum (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc_tum (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_tum (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_tum (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_tum (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_tum (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_tum (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_tum (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_tum (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_tum (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc_tum (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc_tum (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_tum (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_tum (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_tum (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_tum (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_tum (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_tum (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_tum (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_tum (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_tum (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_tum (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_tum (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_tum (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_tum (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_tum (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_tum (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_tum (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_tum (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_tum (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_tum (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_tum (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_tum (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_tum (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac_tum (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac_tum (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac_tum (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac_tum (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac_tum (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac_tum (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac_tum (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac_tum (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac_tum (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac_tum (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac_tum (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac_tum (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_tum (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_tum (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_tum (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_tum (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_tum (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_tum (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_tum (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_tum (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac_tum (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac_tum (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_tum (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_tum (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_tum (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_tum (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_tum (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_tum (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_tum (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_tum (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_tum (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_tum (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_tum (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_tum (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_tum (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_tum (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_tum (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_tum (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd_tum (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd_tum (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd_tum (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd_tum (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd_tum (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd_tum (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd_tum (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd_tum (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd_tum (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd_tum (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd_tum (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd_tum (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd_tum (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd_tum (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd_tum (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd_tum (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd_tum (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd_tum (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_tum (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_tum (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_tum (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_tum (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_tum (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_tum (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_tum (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_tum (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd_tum (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd_tum (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_tum (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_tum (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_tum (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_tum (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_tum (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_tum (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_tum (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_tum (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_tum (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_tum (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_tum (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_tum (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_tum (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_tum (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_tum (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_tum (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_tum (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_tum (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_tum (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_tum (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_tum (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_tum (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub_tum (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub_tum (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub_tum (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub_tum (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub_tum (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub_tum (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub_tum (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub_tum (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub_tum (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub_tum (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub_tum (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub_tum (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_tum (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_tum (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_tum (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_tum (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_tum (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_tum (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_tum (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_tum (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub_tum (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub_tum (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_tum (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_tum (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_tum (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_tum (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_tum (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_tum (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_tum (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_tum (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_tum (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_tum (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_tum (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_tum (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_tum (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_tum (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
// masked functions
vint8mf8_t __riscv_vmacc_tumu (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmacc_tumu (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc_tumu (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc_tumu (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc_tumu (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc_tumu (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmacc_tumu (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmacc_tumu (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmacc_tumu (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmacc_tumu (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmacc_tumu (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmacc_tumu (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmacc_tumu (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmacc_tumu (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc_tumu (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc_tumu (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_tumu (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_tumu (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_tumu (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_tumu (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmacc_tumu (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmacc_tumu (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmacc_tumu (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmacc_tumu (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmacc_tumu (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmacc_tumu (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc_tumu (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc_tumu (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_tumu (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_tumu (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmacc_tumu (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmacc_tumu (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmacc_tumu (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmacc_tumu (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmacc_tumu (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmacc_tumu (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmacc_tumu (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmacc_tumu (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmacc_tumu (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmacc_tumu (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmacc_tumu (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmacc_tumu (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmacc_tumu (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmacc_tumu (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_tumu (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_tumu (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_tumu (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_tumu (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_tumu (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_tumu (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac_tumu (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac_tumu (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac_tumu (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac_tumu (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac_tumu (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac_tumu (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac_tumu (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac_tumu (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac_tumu (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac_tumu (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_tumu (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_tumu (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_tumu (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_tumu (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_tumu (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_tumu (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_tumu (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_tumu (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_tumu (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_tumu (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac_tumu (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac_tumu (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_tumu (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_tumu (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_tumu (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_tumu (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_tumu (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_tumu (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_tumu (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_tumu (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_tumu (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_tumu (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_tumu (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_tumu (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_tumu (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_tumu (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_tumu (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_tumu (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd_tumu (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd_tumu (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd_tumu (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd_tumu (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd_tumu (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd_tumu (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmadd_tumu (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmadd_tumu (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmadd_tumu (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmadd_tumu (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmadd_tumu (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmadd_tumu (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmadd_tumu (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmadd_tumu (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd_tumu (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd_tumu (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_tumu (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_tumu (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_tumu (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_tumu (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmadd_tumu (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmadd_tumu (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmadd_tumu (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmadd_tumu (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmadd_tumu (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmadd_tumu (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd_tumu (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd_tumu (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_tumu (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_tumu (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmadd_tumu (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmadd_tumu (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmadd_tumu (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmadd_tumu (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmadd_tumu (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmadd_tumu (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmadd_tumu (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmadd_tumu (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmadd_tumu (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmadd_tumu (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmadd_tumu (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmadd_tumu (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmadd_tumu (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmadd_tumu (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_tumu (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_tumu (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_tumu (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_tumu (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_tumu (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_tumu (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub_tumu (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub_tumu (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub_tumu (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub_tumu (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub_tumu (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub_tumu (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub_tumu (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub_tumu (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub_tumu (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub_tumu (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_tumu (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_tumu (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_tumu (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_tumu (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_tumu (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_tumu (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_tumu (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_tumu (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_tumu (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_tumu (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub_tumu (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub_tumu (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_tumu (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_tumu (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_tumu (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_tumu (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_tumu (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_tumu (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_tumu (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_tumu (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_tumu (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_tumu (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_tumu (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_tumu (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_tumu (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_tumu (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_tumu (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_tumu (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc_tumu (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc_tumu (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc_tumu (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc_tumu (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc_tumu (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc_tumu (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc_tumu (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc_tumu (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc_tumu (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc_tumu (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc_tumu (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc_tumu (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc_tumu (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc_tumu (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc_tumu (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc_tumu (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc_tumu (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc_tumu (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc_tumu (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc_tumu (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_tumu (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_tumu (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_tumu (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_tumu (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_tumu (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_tumu (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_tumu (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_tumu (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc_tumu (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc_tumu (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_tumu (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_tumu (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_tumu (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_tumu (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_tumu (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_tumu (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_tumu (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_tumu (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_tumu (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_tumu (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_tumu (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_tumu (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_tumu (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_tumu (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_tumu (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_tumu (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_tumu (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_tumu (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_tumu (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_tumu (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_tumu (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_tumu (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac_tumu (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac_tumu (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac_tumu (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac_tumu (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac_tumu (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac_tumu (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac_tumu (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac_tumu (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac_tumu (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac_tumu (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac_tumu (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac_tumu (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_tumu (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_tumu (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_tumu (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_tumu (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_tumu (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_tumu (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_tumu (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_tumu (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac_tumu (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac_tumu (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_tumu (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_tumu (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_tumu (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_tumu (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_tumu (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_tumu (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_tumu (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_tumu (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_tumu (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_tumu (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_tumu (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_tumu (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_tumu (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_tumu (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_tumu (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_tumu (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd_tumu (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd_tumu (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd_tumu (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd_tumu (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd_tumu (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd_tumu (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd_tumu (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd_tumu (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd_tumu (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd_tumu (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd_tumu (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd_tumu (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd_tumu (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd_tumu (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd_tumu (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd_tumu (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd_tumu (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd_tumu (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_tumu (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_tumu (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_tumu (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_tumu (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_tumu (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_tumu (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_tumu (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_tumu (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd_tumu (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd_tumu (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_tumu (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_tumu (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_tumu (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_tumu (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_tumu (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_tumu (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_tumu (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_tumu (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_tumu (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_tumu (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_tumu (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_tumu (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_tumu (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_tumu (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_tumu (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_tumu (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_tumu (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_tumu (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_tumu (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_tumu (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_tumu (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_tumu (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub_tumu (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub_tumu (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub_tumu (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub_tumu (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub_tumu (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub_tumu (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub_tumu (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub_tumu (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub_tumu (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub_tumu (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub_tumu (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub_tumu (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_tumu (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_tumu (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_tumu (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_tumu (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_tumu (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_tumu (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_tumu (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_tumu (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub_tumu (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub_tumu (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_tumu (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_tumu (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_tumu (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_tumu (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_tumu (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_tumu (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_tumu (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_tumu (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_tumu (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_tumu (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_tumu (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_tumu (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_tumu (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_tumu (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
// masked functions
vint8mf8_t __riscv_vmacc_mu (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmacc_mu (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc_mu (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmacc_mu (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc_mu (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmacc_mu (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmacc_mu (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmacc_mu (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmacc_mu (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmacc_mu (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmacc_mu (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmacc_mu (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmacc_mu (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmacc_mu (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc_mu (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmacc_mu (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_mu (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmacc_mu (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_mu (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmacc_mu (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmacc_mu (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmacc_mu (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmacc_mu (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmacc_mu (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmacc_mu (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmacc_mu (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc_mu (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmacc_mu (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_mu (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmacc_mu (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmacc_mu (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmacc_mu (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmacc_mu (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmacc_mu (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmacc_mu (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmacc_mu (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmacc_mu (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmacc_mu (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmacc_mu (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmacc_mu (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmacc_mu (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmacc_mu (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmacc_mu (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmacc_mu (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_mu (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsac_mu (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_mu (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsac_mu (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_mu (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsac_mu (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac_mu (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsac_mu (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac_mu (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsac_mu (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac_mu (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsac_mu (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac_mu (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsac_mu (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac_mu (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsac_mu (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_mu (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsac_mu (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_mu (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsac_mu (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_mu (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsac_mu (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_mu (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsac_mu (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_mu (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsac_mu (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac_mu (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsac_mu (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_mu (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsac_mu (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_mu (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsac_mu (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_mu (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsac_mu (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_mu (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsac_mu (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_mu (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsac_mu (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_mu (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsac_mu (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_mu (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsac_mu (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_mu (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsac_mu (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd_mu (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vmadd_mu (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd_mu (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vmadd_mu (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd_mu (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vmadd_mu (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vmadd_mu (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vmadd_mu (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vmadd_mu (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vmadd_mu (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vmadd_mu (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vmadd_mu (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vmadd_mu (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vmadd_mu (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd_mu (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vmadd_mu (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_mu (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vmadd_mu (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_mu (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vmadd_mu (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vmadd_mu (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vmadd_mu (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vmadd_mu (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vmadd_mu (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vmadd_mu (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vmadd_mu (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd_mu (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vmadd_mu (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_mu (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vmadd_mu (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vmadd_mu (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vmadd_mu (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vmadd_mu (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vmadd_mu (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vmadd_mu (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vmadd_mu (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vmadd_mu (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vmadd_mu (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vmadd_mu (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vmadd_mu (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vmadd_mu (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vmadd_mu (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vmadd_mu (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vmadd_mu (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_mu (vbool64_t mask, vint8mf8_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint8mf8_t __riscv_vnmsub_mu (vbool64_t mask, vint8mf8_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_mu (vbool32_t mask, vint8mf4_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint8mf4_t __riscv_vnmsub_mu (vbool32_t mask, vint8mf4_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_mu (vbool16_t mask, vint8mf2_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint8mf2_t __riscv_vnmsub_mu (vbool16_t mask, vint8mf2_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub_mu (vbool8_t mask, vint8m1_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint8m1_t __riscv_vnmsub_mu (vbool8_t mask, vint8m1_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub_mu (vbool4_t mask, vint8m2_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint8m2_t __riscv_vnmsub_mu (vbool4_t mask, vint8m2_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub_mu (vbool2_t mask, vint8m4_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint8m4_t __riscv_vnmsub_mu (vbool2_t mask, vint8m4_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub_mu (vbool1_t mask, vint8m8_t vd, vint8m8_t vs1, vint8m8_t vs2, size_t vl);
vint8m8_t __riscv_vnmsub_mu (vbool1_t mask, vint8m8_t vd, int8_t rs1, vint8m8_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub_mu (vbool64_t mask, vint16mf4_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint16mf4_t __riscv_vnmsub_mu (vbool64_t mask, vint16mf4_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_mu (vbool32_t mask, vint16mf2_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint16mf2_t __riscv_vnmsub_mu (vbool32_t mask, vint16mf2_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_mu (vbool16_t mask, vint16m1_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint16m1_t __riscv_vnmsub_mu (vbool16_t mask, vint16m1_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_mu (vbool8_t mask, vint16m2_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint16m2_t __riscv_vnmsub_mu (vbool8_t mask, vint16m2_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_mu (vbool4_t mask, vint16m4_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint16m4_t __riscv_vnmsub_mu (vbool4_t mask, vint16m4_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_mu (vbool2_t mask, vint16m8_t vd, vint16m8_t vs1, vint16m8_t vs2, size_t vl);
vint16m8_t __riscv_vnmsub_mu (vbool2_t mask, vint16m8_t vd, int16_t rs1, vint16m8_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub_mu (vbool64_t mask, vint32mf2_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint32mf2_t __riscv_vnmsub_mu (vbool64_t mask, vint32mf2_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_mu (vbool32_t mask, vint32m1_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint32m1_t __riscv_vnmsub_mu (vbool32_t mask, vint32m1_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_mu (vbool16_t mask, vint32m2_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint32m2_t __riscv_vnmsub_mu (vbool16_t mask, vint32m2_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_mu (vbool8_t mask, vint32m4_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint32m4_t __riscv_vnmsub_mu (vbool8_t mask, vint32m4_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_mu (vbool4_t mask, vint32m8_t vd, vint32m8_t vs1, vint32m8_t vs2, size_t vl);
vint32m8_t __riscv_vnmsub_mu (vbool4_t mask, vint32m8_t vd, int32_t rs1, vint32m8_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_mu (vbool64_t mask, vint64m1_t vd, vint64m1_t vs1, vint64m1_t vs2, size_t vl);
vint64m1_t __riscv_vnmsub_mu (vbool64_t mask, vint64m1_t vd, int64_t rs1, vint64m1_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_mu (vbool32_t mask, vint64m2_t vd, vint64m2_t vs1, vint64m2_t vs2, size_t vl);
vint64m2_t __riscv_vnmsub_mu (vbool32_t mask, vint64m2_t vd, int64_t rs1, vint64m2_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_mu (vbool16_t mask, vint64m4_t vd, vint64m4_t vs1, vint64m4_t vs2, size_t vl);
vint64m4_t __riscv_vnmsub_mu (vbool16_t mask, vint64m4_t vd, int64_t rs1, vint64m4_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_mu (vbool8_t mask, vint64m8_t vd, vint64m8_t vs1, vint64m8_t vs2, size_t vl);
vint64m8_t __riscv_vnmsub_mu (vbool8_t mask, vint64m8_t vd, int64_t rs1, vint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc_mu (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmacc_mu (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc_mu (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmacc_mu (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc_mu (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmacc_mu (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc_mu (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmacc_mu (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc_mu (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmacc_mu (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc_mu (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmacc_mu (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc_mu (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmacc_mu (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc_mu (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmacc_mu (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc_mu (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmacc_mu (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc_mu (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmacc_mu (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_mu (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmacc_mu (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_mu (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmacc_mu (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_mu (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmacc_mu (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_mu (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmacc_mu (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc_mu (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmacc_mu (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_mu (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmacc_mu (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_mu (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmacc_mu (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_mu (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmacc_mu (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_mu (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmacc_mu (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_mu (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmacc_mu (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_mu (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmacc_mu (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_mu (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmacc_mu (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_mu (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsac_mu (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_mu (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsac_mu (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_mu (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsac_mu (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_mu (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsac_mu (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac_mu (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsac_mu (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac_mu (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsac_mu (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac_mu (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsac_mu (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac_mu (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsac_mu (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac_mu (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsac_mu (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac_mu (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsac_mu (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_mu (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsac_mu (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_mu (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsac_mu (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_mu (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsac_mu (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_mu (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsac_mu (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac_mu (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsac_mu (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_mu (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsac_mu (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_mu (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsac_mu (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_mu (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsac_mu (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_mu (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsac_mu (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_mu (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsac_mu (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_mu (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsac_mu (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_mu (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsac_mu (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_mu (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vmadd_mu (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd_mu (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vmadd_mu (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd_mu (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vmadd_mu (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd_mu (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vmadd_mu (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd_mu (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vmadd_mu (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd_mu (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vmadd_mu (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd_mu (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vmadd_mu (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd_mu (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vmadd_mu (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd_mu (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vmadd_mu (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd_mu (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vmadd_mu (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_mu (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vmadd_mu (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_mu (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vmadd_mu (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_mu (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vmadd_mu (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_mu (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vmadd_mu (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd_mu (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vmadd_mu (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_mu (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vmadd_mu (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_mu (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vmadd_mu (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_mu (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vmadd_mu (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_mu (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vmadd_mu (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_mu (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vmadd_mu (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_mu (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vmadd_mu (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_mu (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vmadd_mu (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_mu (vbool64_t mask, vuint8mf8_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint8mf8_t __riscv_vnmsub_mu (vbool64_t mask, vuint8mf8_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_mu (vbool32_t mask, vuint8mf4_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint8mf4_t __riscv_vnmsub_mu (vbool32_t mask, vuint8mf4_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_mu (vbool16_t mask, vuint8mf2_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint8mf2_t __riscv_vnmsub_mu (vbool16_t mask, vuint8mf2_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_mu (vbool8_t mask, vuint8m1_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint8m1_t __riscv_vnmsub_mu (vbool8_t mask, vuint8m1_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub_mu (vbool4_t mask, vuint8m2_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint8m2_t __riscv_vnmsub_mu (vbool4_t mask, vuint8m2_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub_mu (vbool2_t mask, vuint8m4_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint8m4_t __riscv_vnmsub_mu (vbool2_t mask, vuint8m4_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub_mu (vbool1_t mask, vuint8m8_t vd, vuint8m8_t vs1, vuint8m8_t vs2, size_t vl);
vuint8m8_t __riscv_vnmsub_mu (vbool1_t mask, vuint8m8_t vd, uint8_t rs1, vuint8m8_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub_mu (vbool64_t mask, vuint16mf4_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint16mf4_t __riscv_vnmsub_mu (vbool64_t mask, vuint16mf4_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub_mu (vbool32_t mask, vuint16mf2_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint16mf2_t __riscv_vnmsub_mu (vbool32_t mask, vuint16mf2_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub_mu (vbool16_t mask, vuint16m1_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint16m1_t __riscv_vnmsub_mu (vbool16_t mask, vuint16m1_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_mu (vbool8_t mask, vuint16m2_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint16m2_t __riscv_vnmsub_mu (vbool8_t mask, vuint16m2_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_mu (vbool4_t mask, vuint16m4_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint16m4_t __riscv_vnmsub_mu (vbool4_t mask, vuint16m4_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_mu (vbool2_t mask, vuint16m8_t vd, vuint16m8_t vs1, vuint16m8_t vs2, size_t vl);
vuint16m8_t __riscv_vnmsub_mu (vbool2_t mask, vuint16m8_t vd, uint16_t rs1, vuint16m8_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_mu (vbool64_t mask, vuint32mf2_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint32mf2_t __riscv_vnmsub_mu (vbool64_t mask, vuint32mf2_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub_mu (vbool32_t mask, vuint32m1_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint32m1_t __riscv_vnmsub_mu (vbool32_t mask, vuint32m1_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_mu (vbool16_t mask, vuint32m2_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint32m2_t __riscv_vnmsub_mu (vbool16_t mask, vuint32m2_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_mu (vbool8_t mask, vuint32m4_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint32m4_t __riscv_vnmsub_mu (vbool8_t mask, vuint32m4_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_mu (vbool4_t mask, vuint32m8_t vd, vuint32m8_t vs1, vuint32m8_t vs2, size_t vl);
vuint32m8_t __riscv_vnmsub_mu (vbool4_t mask, vuint32m8_t vd, uint32_t rs1, vuint32m8_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_mu (vbool64_t mask, vuint64m1_t vd, vuint64m1_t vs1, vuint64m1_t vs2, size_t vl);
vuint64m1_t __riscv_vnmsub_mu (vbool64_t mask, vuint64m1_t vd, uint64_t rs1, vuint64m1_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_mu (vbool32_t mask, vuint64m2_t vd, vuint64m2_t vs1, vuint64m2_t vs2, size_t vl);
vuint64m2_t __riscv_vnmsub_mu (vbool32_t mask, vuint64m2_t vd, uint64_t rs1, vuint64m2_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_mu (vbool16_t mask, vuint64m4_t vd, vuint64m4_t vs1, vuint64m4_t vs2, size_t vl);
vuint64m4_t __riscv_vnmsub_mu (vbool16_t mask, vuint64m4_t vd, uint64_t rs1, vuint64m4_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_mu (vbool8_t mask, vuint64m8_t vd, vuint64m8_t vs1, vuint64m8_t vs2, size_t vl);
vuint64m8_t __riscv_vnmsub_mu (vbool8_t mask, vuint64m8_t vd, uint64_t rs1, vuint64m8_t vs2, size_t vl);
```

[[policy-variant-overloadedvector-widening-integer-multiply-add]]
=== Vector Widening Integer Multiply-Add Intrinsics

``` C
vint16mf4_t __riscv_vwmacc_tu (vint16mf4_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmacc_tu (vint16mf4_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc_tu (vint16mf2_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc_tu (vint16mf2_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_tu (vint16m1_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_tu (vint16m1_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc_tu (vint16m2_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc_tu (vint16m2_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc_tu (vint16m4_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc_tu (vint16m4_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc_tu (vint16m8_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc_tu (vint16m8_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc_tu (vint32mf2_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc_tu (vint32mf2_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_tu (vint32m1_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_tu (vint32m1_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_tu (vint32m2_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_tu (vint32m2_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_tu (vint32m4_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_tu (vint32m4_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_tu (vint32m8_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_tu (vint32m8_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc_tu (vint64m1_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc_tu (vint64m1_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_tu (vint64m2_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_tu (vint64m2_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_tu (vint64m4_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_tu (vint64m4_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_tu (vint64m8_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_tu (vint64m8_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu_tu (vint16mf4_t vd, vint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu_tu (vint16mf4_t vd, int8_t rs1, vuint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu_tu (vint16mf2_t vd, vint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu_tu (vint16mf2_t vd, int8_t rs1, vuint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu_tu (vint16m1_t vd, vint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu_tu (vint16m1_t vd, int8_t rs1, vuint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu_tu (vint16m2_t vd, vint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu_tu (vint16m2_t vd, int8_t rs1, vuint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu_tu (vint16m4_t vd, vint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu_tu (vint16m4_t vd, int8_t rs1, vuint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu_tu (vint16m8_t vd, vint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu_tu (vint16m8_t vd, int8_t rs1, vuint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu_tu (vint32mf2_t vd, vint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu_tu (vint32mf2_t vd, int16_t rs1, vuint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu_tu (vint32m1_t vd, vint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu_tu (vint32m1_t vd, int16_t rs1, vuint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_tu (vint32m2_t vd, vint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_tu (vint32m2_t vd, int16_t rs1, vuint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_tu (vint32m4_t vd, vint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_tu (vint32m4_t vd, int16_t rs1, vuint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_tu (vint32m8_t vd, vint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_tu (vint32m8_t vd, int16_t rs1, vuint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_tu (vint64m1_t vd, vint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_tu (vint64m1_t vd, int32_t rs1, vuint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_tu (vint64m2_t vd, vint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_tu (vint64m2_t vd, int32_t rs1, vuint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_tu (vint64m4_t vd, vint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_tu (vint64m4_t vd, int32_t rs1, vuint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_tu (vint64m8_t vd, vint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_tu (vint64m8_t vd, int32_t rs1, vuint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccus_tu (vint16mf4_t vd, uint8_t rs1, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccus_tu (vint16mf2_t vd, uint8_t rs1, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccus_tu (vint16m1_t vd, uint8_t rs1, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccus_tu (vint16m2_t vd, uint8_t rs1, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccus_tu (vint16m4_t vd, uint8_t rs1, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccus_tu (vint16m8_t vd, uint8_t rs1, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccus_tu (vint32mf2_t vd, uint16_t rs1, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccus_tu (vint32m1_t vd, uint16_t rs1, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccus_tu (vint32m2_t vd, uint16_t rs1, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccus_tu (vint32m4_t vd, uint16_t rs1, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccus_tu (vint32m8_t vd, uint16_t rs1, vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccus_tu (vint64m1_t vd, uint32_t rs1, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccus_tu (vint64m2_t vd, uint32_t rs1, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccus_tu (vint64m4_t vd, uint32_t rs1, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccus_tu (vint64m8_t vd, uint32_t rs1, vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_tu (vuint16mf4_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_tu (vuint16mf4_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu_tu (vuint16mf2_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu_tu (vuint16mf2_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu_tu (vuint16m1_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu_tu (vuint16m1_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_tu (vuint16m2_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_tu (vuint16m2_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_tu (vuint16m4_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_tu (vuint16m4_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_tu (vuint16m8_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_tu (vuint16m8_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_tu (vuint32mf2_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_tu (vuint32mf2_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu_tu (vuint32m1_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu_tu (vuint32m1_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu_tu (vuint32m2_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu_tu (vuint32m2_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu_tu (vuint32m4_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu_tu (vuint32m4_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu_tu (vuint32m8_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu_tu (vuint32m8_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu_tu (vuint64m1_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu_tu (vuint64m1_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu_tu (vuint64m2_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu_tu (vuint64m2_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu_tu (vuint64m4_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu_tu (vuint64m4_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu_tu (vuint64m8_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu_tu (vuint64m8_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwmacc_tum (vbool64_t mask, vint16mf4_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmacc_tum (vbool64_t mask, vint16mf4_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc_tum (vbool32_t mask, vint16mf2_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc_tum (vbool32_t mask, vint16mf2_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_tum (vbool16_t mask, vint16m1_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_tum (vbool16_t mask, vint16m1_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc_tum (vbool8_t mask, vint16m2_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc_tum (vbool8_t mask, vint16m2_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc_tum (vbool4_t mask, vint16m4_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc_tum (vbool4_t mask, vint16m4_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc_tum (vbool2_t mask, vint16m8_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc_tum (vbool2_t mask, vint16m8_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc_tum (vbool64_t mask, vint32mf2_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc_tum (vbool64_t mask, vint32mf2_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_tum (vbool32_t mask, vint32m1_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_tum (vbool32_t mask, vint32m1_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_tum (vbool16_t mask, vint32m2_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_tum (vbool16_t mask, vint32m2_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_tum (vbool8_t mask, vint32m4_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_tum (vbool8_t mask, vint32m4_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_tum (vbool4_t mask, vint32m8_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_tum (vbool4_t mask, vint32m8_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc_tum (vbool64_t mask, vint64m1_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc_tum (vbool64_t mask, vint64m1_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_tum (vbool32_t mask, vint64m2_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_tum (vbool32_t mask, vint64m2_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_tum (vbool16_t mask, vint64m4_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_tum (vbool16_t mask, vint64m4_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_tum (vbool8_t mask, vint64m8_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_tum (vbool8_t mask, vint64m8_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu_tum (vbool64_t mask, vint16mf4_t vd, vint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu_tum (vbool64_t mask, vint16mf4_t vd, int8_t rs1, vuint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu_tum (vbool32_t mask, vint16mf2_t vd, vint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu_tum (vbool32_t mask, vint16mf2_t vd, int8_t rs1, vuint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu_tum (vbool16_t mask, vint16m1_t vd, vint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu_tum (vbool16_t mask, vint16m1_t vd, int8_t rs1, vuint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu_tum (vbool8_t mask, vint16m2_t vd, vint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu_tum (vbool8_t mask, vint16m2_t vd, int8_t rs1, vuint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu_tum (vbool4_t mask, vint16m4_t vd, vint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu_tum (vbool4_t mask, vint16m4_t vd, int8_t rs1, vuint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu_tum (vbool2_t mask, vint16m8_t vd, vint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu_tum (vbool2_t mask, vint16m8_t vd, int8_t rs1, vuint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu_tum (vbool64_t mask, vint32mf2_t vd, vint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu_tum (vbool64_t mask, vint32mf2_t vd, int16_t rs1, vuint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu_tum (vbool32_t mask, vint32m1_t vd, vint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu_tum (vbool32_t mask, vint32m1_t vd, int16_t rs1, vuint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_tum (vbool16_t mask, vint32m2_t vd, vint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_tum (vbool16_t mask, vint32m2_t vd, int16_t rs1, vuint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_tum (vbool8_t mask, vint32m4_t vd, vint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_tum (vbool8_t mask, vint32m4_t vd, int16_t rs1, vuint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_tum (vbool4_t mask, vint32m8_t vd, vint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_tum (vbool4_t mask, vint32m8_t vd, int16_t rs1, vuint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_tum (vbool64_t mask, vint64m1_t vd, vint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_tum (vbool64_t mask, vint64m1_t vd, int32_t rs1, vuint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_tum (vbool32_t mask, vint64m2_t vd, vint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_tum (vbool32_t mask, vint64m2_t vd, int32_t rs1, vuint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_tum (vbool16_t mask, vint64m4_t vd, vint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_tum (vbool16_t mask, vint64m4_t vd, int32_t rs1, vuint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_tum (vbool8_t mask, vint64m8_t vd, vint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_tum (vbool8_t mask, vint64m8_t vd, int32_t rs1, vuint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccus_tum (vbool64_t mask, vint16mf4_t vd, uint8_t rs1, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccus_tum (vbool32_t mask, vint16mf2_t vd, uint8_t rs1, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccus_tum (vbool16_t mask, vint16m1_t vd, uint8_t rs1, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccus_tum (vbool8_t mask, vint16m2_t vd, uint8_t rs1, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccus_tum (vbool4_t mask, vint16m4_t vd, uint8_t rs1, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccus_tum (vbool2_t mask, vint16m8_t vd, uint8_t rs1, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccus_tum (vbool64_t mask, vint32mf2_t vd, uint16_t rs1, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccus_tum (vbool32_t mask, vint32m1_t vd, uint16_t rs1, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccus_tum (vbool16_t mask, vint32m2_t vd, uint16_t rs1, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccus_tum (vbool8_t mask, vint32m4_t vd, uint16_t rs1, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccus_tum (vbool4_t mask, vint32m8_t vd, uint16_t rs1, vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccus_tum (vbool64_t mask, vint64m1_t vd, uint32_t rs1, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccus_tum (vbool32_t mask, vint64m2_t vd, uint32_t rs1, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccus_tum (vbool16_t mask, vint64m4_t vd, uint32_t rs1, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccus_tum (vbool8_t mask, vint64m8_t vd, uint32_t rs1, vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_tum (vbool64_t mask, vuint16mf4_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_tum (vbool64_t mask, vuint16mf4_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu_tum (vbool32_t mask, vuint16mf2_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu_tum (vbool32_t mask, vuint16mf2_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu_tum (vbool16_t mask, vuint16m1_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu_tum (vbool16_t mask, vuint16m1_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_tum (vbool8_t mask, vuint16m2_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_tum (vbool8_t mask, vuint16m2_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_tum (vbool4_t mask, vuint16m4_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_tum (vbool4_t mask, vuint16m4_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_tum (vbool2_t mask, vuint16m8_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_tum (vbool2_t mask, vuint16m8_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_tum (vbool64_t mask, vuint32mf2_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_tum (vbool64_t mask, vuint32mf2_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu_tum (vbool32_t mask, vuint32m1_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu_tum (vbool32_t mask, vuint32m1_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu_tum (vbool16_t mask, vuint32m2_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu_tum (vbool16_t mask, vuint32m2_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu_tum (vbool8_t mask, vuint32m4_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu_tum (vbool8_t mask, vuint32m4_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu_tum (vbool4_t mask, vuint32m8_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu_tum (vbool4_t mask, vuint32m8_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu_tum (vbool64_t mask, vuint64m1_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu_tum (vbool64_t mask, vuint64m1_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu_tum (vbool32_t mask, vuint64m2_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu_tum (vbool32_t mask, vuint64m2_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu_tum (vbool16_t mask, vuint64m4_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu_tum (vbool16_t mask, vuint64m4_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu_tum (vbool8_t mask, vuint64m8_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu_tum (vbool8_t mask, vuint64m8_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwmacc_tumu (vbool64_t mask, vint16mf4_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmacc_tumu (vbool64_t mask, vint16mf4_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc_tumu (vbool32_t mask, vint16mf2_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc_tumu (vbool32_t mask, vint16mf2_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_tumu (vbool16_t mask, vint16m1_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_tumu (vbool16_t mask, vint16m1_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc_tumu (vbool8_t mask, vint16m2_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc_tumu (vbool8_t mask, vint16m2_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc_tumu (vbool4_t mask, vint16m4_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc_tumu (vbool4_t mask, vint16m4_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc_tumu (vbool2_t mask, vint16m8_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc_tumu (vbool2_t mask, vint16m8_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc_tumu (vbool64_t mask, vint32mf2_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc_tumu (vbool64_t mask, vint32mf2_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_tumu (vbool32_t mask, vint32m1_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_tumu (vbool32_t mask, vint32m1_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_tumu (vbool16_t mask, vint32m2_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_tumu (vbool16_t mask, vint32m2_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_tumu (vbool8_t mask, vint32m4_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_tumu (vbool8_t mask, vint32m4_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_tumu (vbool4_t mask, vint32m8_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_tumu (vbool4_t mask, vint32m8_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc_tumu (vbool64_t mask, vint64m1_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc_tumu (vbool64_t mask, vint64m1_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_tumu (vbool32_t mask, vint64m2_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_tumu (vbool32_t mask, vint64m2_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_tumu (vbool16_t mask, vint64m4_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_tumu (vbool16_t mask, vint64m4_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_tumu (vbool8_t mask, vint64m8_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_tumu (vbool8_t mask, vint64m8_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu_tumu (vbool64_t mask, vint16mf4_t vd, vint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu_tumu (vbool64_t mask, vint16mf4_t vd, int8_t rs1, vuint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu_tumu (vbool32_t mask, vint16mf2_t vd, vint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu_tumu (vbool32_t mask, vint16mf2_t vd, int8_t rs1, vuint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu_tumu (vbool16_t mask, vint16m1_t vd, vint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu_tumu (vbool16_t mask, vint16m1_t vd, int8_t rs1, vuint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu_tumu (vbool8_t mask, vint16m2_t vd, vint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu_tumu (vbool8_t mask, vint16m2_t vd, int8_t rs1, vuint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu_tumu (vbool4_t mask, vint16m4_t vd, vint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu_tumu (vbool4_t mask, vint16m4_t vd, int8_t rs1, vuint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu_tumu (vbool2_t mask, vint16m8_t vd, vint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu_tumu (vbool2_t mask, vint16m8_t vd, int8_t rs1, vuint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu_tumu (vbool64_t mask, vint32mf2_t vd, vint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu_tumu (vbool64_t mask, vint32mf2_t vd, int16_t rs1, vuint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu_tumu (vbool32_t mask, vint32m1_t vd, vint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu_tumu (vbool32_t mask, vint32m1_t vd, int16_t rs1, vuint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_tumu (vbool16_t mask, vint32m2_t vd, vint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_tumu (vbool16_t mask, vint32m2_t vd, int16_t rs1, vuint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_tumu (vbool8_t mask, vint32m4_t vd, vint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_tumu (vbool8_t mask, vint32m4_t vd, int16_t rs1, vuint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_tumu (vbool4_t mask, vint32m8_t vd, vint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_tumu (vbool4_t mask, vint32m8_t vd, int16_t rs1, vuint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_tumu (vbool64_t mask, vint64m1_t vd, vint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_tumu (vbool64_t mask, vint64m1_t vd, int32_t rs1, vuint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_tumu (vbool32_t mask, vint64m2_t vd, vint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_tumu (vbool32_t mask, vint64m2_t vd, int32_t rs1, vuint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_tumu (vbool16_t mask, vint64m4_t vd, vint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_tumu (vbool16_t mask, vint64m4_t vd, int32_t rs1, vuint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_tumu (vbool8_t mask, vint64m8_t vd, vint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_tumu (vbool8_t mask, vint64m8_t vd, int32_t rs1, vuint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccus_tumu (vbool64_t mask, vint16mf4_t vd, uint8_t rs1, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccus_tumu (vbool32_t mask, vint16mf2_t vd, uint8_t rs1, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccus_tumu (vbool16_t mask, vint16m1_t vd, uint8_t rs1, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccus_tumu (vbool8_t mask, vint16m2_t vd, uint8_t rs1, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccus_tumu (vbool4_t mask, vint16m4_t vd, uint8_t rs1, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccus_tumu (vbool2_t mask, vint16m8_t vd, uint8_t rs1, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccus_tumu (vbool64_t mask, vint32mf2_t vd, uint16_t rs1, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccus_tumu (vbool32_t mask, vint32m1_t vd, uint16_t rs1, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccus_tumu (vbool16_t mask, vint32m2_t vd, uint16_t rs1, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccus_tumu (vbool8_t mask, vint32m4_t vd, uint16_t rs1, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccus_tumu (vbool4_t mask, vint32m8_t vd, uint16_t rs1, vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccus_tumu (vbool64_t mask, vint64m1_t vd, uint32_t rs1, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccus_tumu (vbool32_t mask, vint64m2_t vd, uint32_t rs1, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccus_tumu (vbool16_t mask, vint64m4_t vd, uint32_t rs1, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccus_tumu (vbool8_t mask, vint64m8_t vd, uint32_t rs1, vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_tumu (vbool64_t mask, vuint16mf4_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_tumu (vbool64_t mask, vuint16mf4_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu_tumu (vbool32_t mask, vuint16mf2_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu_tumu (vbool32_t mask, vuint16mf2_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu_tumu (vbool16_t mask, vuint16m1_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu_tumu (vbool16_t mask, vuint16m1_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_tumu (vbool8_t mask, vuint16m2_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_tumu (vbool8_t mask, vuint16m2_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_tumu (vbool4_t mask, vuint16m4_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_tumu (vbool4_t mask, vuint16m4_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_tumu (vbool2_t mask, vuint16m8_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_tumu (vbool2_t mask, vuint16m8_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_tumu (vbool64_t mask, vuint32mf2_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_tumu (vbool64_t mask, vuint32mf2_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu_tumu (vbool32_t mask, vuint32m1_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu_tumu (vbool32_t mask, vuint32m1_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu_tumu (vbool16_t mask, vuint32m2_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu_tumu (vbool16_t mask, vuint32m2_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu_tumu (vbool8_t mask, vuint32m4_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu_tumu (vbool8_t mask, vuint32m4_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu_tumu (vbool4_t mask, vuint32m8_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu_tumu (vbool4_t mask, vuint32m8_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu_tumu (vbool64_t mask, vuint64m1_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu_tumu (vbool64_t mask, vuint64m1_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu_tumu (vbool32_t mask, vuint64m2_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu_tumu (vbool32_t mask, vuint64m2_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu_tumu (vbool16_t mask, vuint64m4_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu_tumu (vbool16_t mask, vuint64m4_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu_tumu (vbool8_t mask, vuint64m8_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu_tumu (vbool8_t mask, vuint64m8_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
// masked functions
vint16mf4_t __riscv_vwmacc_mu (vbool64_t mask, vint16mf4_t vd, vint8mf8_t vs1, vint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmacc_mu (vbool64_t mask, vint16mf4_t vd, int8_t rs1, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc_mu (vbool32_t mask, vint16mf2_t vd, vint8mf4_t vs1, vint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmacc_mu (vbool32_t mask, vint16mf2_t vd, int8_t rs1, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_mu (vbool16_t mask, vint16m1_t vd, vint8mf2_t vs1, vint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmacc_mu (vbool16_t mask, vint16m1_t vd, int8_t rs1, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc_mu (vbool8_t mask, vint16m2_t vd, vint8m1_t vs1, vint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmacc_mu (vbool8_t mask, vint16m2_t vd, int8_t rs1, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc_mu (vbool4_t mask, vint16m4_t vd, vint8m2_t vs1, vint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmacc_mu (vbool4_t mask, vint16m4_t vd, int8_t rs1, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc_mu (vbool2_t mask, vint16m8_t vd, vint8m4_t vs1, vint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmacc_mu (vbool2_t mask, vint16m8_t vd, int8_t rs1, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc_mu (vbool64_t mask, vint32mf2_t vd, vint16mf4_t vs1, vint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmacc_mu (vbool64_t mask, vint32mf2_t vd, int16_t rs1, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_mu (vbool32_t mask, vint32m1_t vd, vint16mf2_t vs1, vint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmacc_mu (vbool32_t mask, vint32m1_t vd, int16_t rs1, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_mu (vbool16_t mask, vint32m2_t vd, vint16m1_t vs1, vint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmacc_mu (vbool16_t mask, vint32m2_t vd, int16_t rs1, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_mu (vbool8_t mask, vint32m4_t vd, vint16m2_t vs1, vint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmacc_mu (vbool8_t mask, vint32m4_t vd, int16_t rs1, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_mu (vbool4_t mask, vint32m8_t vd, vint16m4_t vs1, vint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmacc_mu (vbool4_t mask, vint32m8_t vd, int16_t rs1, vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc_mu (vbool64_t mask, vint64m1_t vd, vint32mf2_t vs1, vint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmacc_mu (vbool64_t mask, vint64m1_t vd, int32_t rs1, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_mu (vbool32_t mask, vint64m2_t vd, vint32m1_t vs1, vint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmacc_mu (vbool32_t mask, vint64m2_t vd, int32_t rs1, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_mu (vbool16_t mask, vint64m4_t vd, vint32m2_t vs1, vint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmacc_mu (vbool16_t mask, vint64m4_t vd, int32_t rs1, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_mu (vbool8_t mask, vint64m8_t vd, vint32m4_t vs1, vint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmacc_mu (vbool8_t mask, vint64m8_t vd, int32_t rs1, vint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu_mu (vbool64_t mask, vint16mf4_t vd, vint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccsu_mu (vbool64_t mask, vint16mf4_t vd, int8_t rs1, vuint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu_mu (vbool32_t mask, vint16mf2_t vd, vint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccsu_mu (vbool32_t mask, vint16mf2_t vd, int8_t rs1, vuint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu_mu (vbool16_t mask, vint16m1_t vd, vint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccsu_mu (vbool16_t mask, vint16m1_t vd, int8_t rs1, vuint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu_mu (vbool8_t mask, vint16m2_t vd, vint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccsu_mu (vbool8_t mask, vint16m2_t vd, int8_t rs1, vuint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu_mu (vbool4_t mask, vint16m4_t vd, vint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccsu_mu (vbool4_t mask, vint16m4_t vd, int8_t rs1, vuint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu_mu (vbool2_t mask, vint16m8_t vd, vint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccsu_mu (vbool2_t mask, vint16m8_t vd, int8_t rs1, vuint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu_mu (vbool64_t mask, vint32mf2_t vd, vint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccsu_mu (vbool64_t mask, vint32mf2_t vd, int16_t rs1, vuint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu_mu (vbool32_t mask, vint32m1_t vd, vint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccsu_mu (vbool32_t mask, vint32m1_t vd, int16_t rs1, vuint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_mu (vbool16_t mask, vint32m2_t vd, vint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccsu_mu (vbool16_t mask, vint32m2_t vd, int16_t rs1, vuint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_mu (vbool8_t mask, vint32m4_t vd, vint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccsu_mu (vbool8_t mask, vint32m4_t vd, int16_t rs1, vuint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_mu (vbool4_t mask, vint32m8_t vd, vint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccsu_mu (vbool4_t mask, vint32m8_t vd, int16_t rs1, vuint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_mu (vbool64_t mask, vint64m1_t vd, vint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccsu_mu (vbool64_t mask, vint64m1_t vd, int32_t rs1, vuint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_mu (vbool32_t mask, vint64m2_t vd, vint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccsu_mu (vbool32_t mask, vint64m2_t vd, int32_t rs1, vuint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_mu (vbool16_t mask, vint64m4_t vd, vint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccsu_mu (vbool16_t mask, vint64m4_t vd, int32_t rs1, vuint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_mu (vbool8_t mask, vint64m8_t vd, vint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccsu_mu (vbool8_t mask, vint64m8_t vd, int32_t rs1, vuint32m4_t vs2, size_t vl);
vint16mf4_t __riscv_vwmaccus_mu (vbool64_t mask, vint16mf4_t vd, uint8_t rs1, vint8mf8_t vs2, size_t vl);
vint16mf2_t __riscv_vwmaccus_mu (vbool32_t mask, vint16mf2_t vd, uint8_t rs1, vint8mf4_t vs2, size_t vl);
vint16m1_t __riscv_vwmaccus_mu (vbool16_t mask, vint16m1_t vd, uint8_t rs1, vint8mf2_t vs2, size_t vl);
vint16m2_t __riscv_vwmaccus_mu (vbool8_t mask, vint16m2_t vd, uint8_t rs1, vint8m1_t vs2, size_t vl);
vint16m4_t __riscv_vwmaccus_mu (vbool4_t mask, vint16m4_t vd, uint8_t rs1, vint8m2_t vs2, size_t vl);
vint16m8_t __riscv_vwmaccus_mu (vbool2_t mask, vint16m8_t vd, uint8_t rs1, vint8m4_t vs2, size_t vl);
vint32mf2_t __riscv_vwmaccus_mu (vbool64_t mask, vint32mf2_t vd, uint16_t rs1, vint16mf4_t vs2, size_t vl);
vint32m1_t __riscv_vwmaccus_mu (vbool32_t mask, vint32m1_t vd, uint16_t rs1, vint16mf2_t vs2, size_t vl);
vint32m2_t __riscv_vwmaccus_mu (vbool16_t mask, vint32m2_t vd, uint16_t rs1, vint16m1_t vs2, size_t vl);
vint32m4_t __riscv_vwmaccus_mu (vbool8_t mask, vint32m4_t vd, uint16_t rs1, vint16m2_t vs2, size_t vl);
vint32m8_t __riscv_vwmaccus_mu (vbool4_t mask, vint32m8_t vd, uint16_t rs1, vint16m4_t vs2, size_t vl);
vint64m1_t __riscv_vwmaccus_mu (vbool64_t mask, vint64m1_t vd, uint32_t rs1, vint32mf2_t vs2, size_t vl);
vint64m2_t __riscv_vwmaccus_mu (vbool32_t mask, vint64m2_t vd, uint32_t rs1, vint32m1_t vs2, size_t vl);
vint64m4_t __riscv_vwmaccus_mu (vbool16_t mask, vint64m4_t vd, uint32_t rs1, vint32m2_t vs2, size_t vl);
vint64m8_t __riscv_vwmaccus_mu (vbool8_t mask, vint64m8_t vd, uint32_t rs1, vint32m4_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_mu (vbool64_t mask, vuint16mf4_t vd, vuint8mf8_t vs1, vuint8mf8_t vs2, size_t vl);
vuint16mf4_t __riscv_vwmaccu_mu (vbool64_t mask, vuint16mf4_t vd, uint8_t rs1, vuint8mf8_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu_mu (vbool32_t mask, vuint16mf2_t vd, vuint8mf4_t vs1, vuint8mf4_t vs2, size_t vl);
vuint16mf2_t __riscv_vwmaccu_mu (vbool32_t mask, vuint16mf2_t vd, uint8_t rs1, vuint8mf4_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu_mu (vbool16_t mask, vuint16m1_t vd, vuint8mf2_t vs1, vuint8mf2_t vs2, size_t vl);
vuint16m1_t __riscv_vwmaccu_mu (vbool16_t mask, vuint16m1_t vd, uint8_t rs1, vuint8mf2_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_mu (vbool8_t mask, vuint16m2_t vd, vuint8m1_t vs1, vuint8m1_t vs2, size_t vl);
vuint16m2_t __riscv_vwmaccu_mu (vbool8_t mask, vuint16m2_t vd, uint8_t rs1, vuint8m1_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_mu (vbool4_t mask, vuint16m4_t vd, vuint8m2_t vs1, vuint8m2_t vs2, size_t vl);
vuint16m4_t __riscv_vwmaccu_mu (vbool4_t mask, vuint16m4_t vd, uint8_t rs1, vuint8m2_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_mu (vbool2_t mask, vuint16m8_t vd, vuint8m4_t vs1, vuint8m4_t vs2, size_t vl);
vuint16m8_t __riscv_vwmaccu_mu (vbool2_t mask, vuint16m8_t vd, uint8_t rs1, vuint8m4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_mu (vbool64_t mask, vuint32mf2_t vd, vuint16mf4_t vs1, vuint16mf4_t vs2, size_t vl);
vuint32mf2_t __riscv_vwmaccu_mu (vbool64_t mask, vuint32mf2_t vd, uint16_t rs1, vuint16mf4_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu_mu (vbool32_t mask, vuint32m1_t vd, vuint16mf2_t vs1, vuint16mf2_t vs2, size_t vl);
vuint32m1_t __riscv_vwmaccu_mu (vbool32_t mask, vuint32m1_t vd, uint16_t rs1, vuint16mf2_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu_mu (vbool16_t mask, vuint32m2_t vd, vuint16m1_t vs1, vuint16m1_t vs2, size_t vl);
vuint32m2_t __riscv_vwmaccu_mu (vbool16_t mask, vuint32m2_t vd, uint16_t rs1, vuint16m1_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu_mu (vbool8_t mask, vuint32m4_t vd, vuint16m2_t vs1, vuint16m2_t vs2, size_t vl);
vuint32m4_t __riscv_vwmaccu_mu (vbool8_t mask, vuint32m4_t vd, uint16_t rs1, vuint16m2_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu_mu (vbool4_t mask, vuint32m8_t vd, vuint16m4_t vs1, vuint16m4_t vs2, size_t vl);
vuint32m8_t __riscv_vwmaccu_mu (vbool4_t mask, vuint32m8_t vd, uint16_t rs1, vuint16m4_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu_mu (vbool64_t mask, vuint64m1_t vd, vuint32mf2_t vs1, vuint32mf2_t vs2, size_t vl);
vuint64m1_t __riscv_vwmaccu_mu (vbool64_t mask, vuint64m1_t vd, uint32_t rs1, vuint32mf2_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu_mu (vbool32_t mask, vuint64m2_t vd, vuint32m1_t vs1, vuint32m1_t vs2, size_t vl);
vuint64m2_t __riscv_vwmaccu_mu (vbool32_t mask, vuint64m2_t vd, uint32_t rs1, vuint32m1_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu_mu (vbool16_t mask, vuint64m4_t vd, vuint32m2_t vs1, vuint32m2_t vs2, size_t vl);
vuint64m4_t __riscv_vwmaccu_mu (vbool16_t mask, vuint64m4_t vd, uint32_t rs1, vuint32m2_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu_mu (vbool8_t mask, vuint64m8_t vd, vuint32m4_t vs1, vuint32m4_t vs2, size_t vl);
vuint64m8_t __riscv_vwmaccu_mu (vbool8_t mask, vuint64m8_t vd, uint32_t rs1, vuint32m4_t vs2, size_t vl);
```

[[policy-variant-overloadedvector-integer-merge]]
=== Vector Integer Merge Intrinsics

``` C
vint8mf8_t __riscv_vmerge_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, vbool64_t mask, size_t vl);
vint8mf8_t __riscv_vmerge_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, vbool64_t mask, size_t vl);
vint8mf4_t __riscv_vmerge_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, vbool32_t mask, size_t vl);
vint8mf4_t __riscv_vmerge_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, vbool32_t mask, size_t vl);
vint8mf2_t __riscv_vmerge_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, vbool16_t mask, size_t vl);
vint8mf2_t __riscv_vmerge_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, vbool16_t mask, size_t vl);
vint8m1_t __riscv_vmerge_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, vbool8_t mask, size_t vl);
vint8m1_t __riscv_vmerge_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, vbool8_t mask, size_t vl);
vint8m2_t __riscv_vmerge_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, vbool4_t mask, size_t vl);
vint8m2_t __riscv_vmerge_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, vbool4_t mask, size_t vl);
vint8m4_t __riscv_vmerge_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, vbool2_t mask, size_t vl);
vint8m4_t __riscv_vmerge_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, vbool2_t mask, size_t vl);
vint8m8_t __riscv_vmerge_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, vbool1_t mask, size_t vl);
vint8m8_t __riscv_vmerge_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, vbool1_t mask, size_t vl);
vint16mf4_t __riscv_vmerge_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, vbool64_t mask, size_t vl);
vint16mf4_t __riscv_vmerge_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, vbool64_t mask, size_t vl);
vint16mf2_t __riscv_vmerge_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, vbool32_t mask, size_t vl);
vint16mf2_t __riscv_vmerge_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, vbool32_t mask, size_t vl);
vint16m1_t __riscv_vmerge_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, vbool16_t mask, size_t vl);
vint16m1_t __riscv_vmerge_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, vbool16_t mask, size_t vl);
vint16m2_t __riscv_vmerge_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, vbool8_t mask, size_t vl);
vint16m2_t __riscv_vmerge_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, vbool8_t mask, size_t vl);
vint16m4_t __riscv_vmerge_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, vbool4_t mask, size_t vl);
vint16m4_t __riscv_vmerge_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, vbool4_t mask, size_t vl);
vint16m8_t __riscv_vmerge_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, vbool2_t mask, size_t vl);
vint16m8_t __riscv_vmerge_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, vbool2_t mask, size_t vl);
vint32mf2_t __riscv_vmerge_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, vbool64_t mask, size_t vl);
vint32mf2_t __riscv_vmerge_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, vbool64_t mask, size_t vl);
vint32m1_t __riscv_vmerge_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, vbool32_t mask, size_t vl);
vint32m1_t __riscv_vmerge_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, vbool32_t mask, size_t vl);
vint32m2_t __riscv_vmerge_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, vbool16_t mask, size_t vl);
vint32m2_t __riscv_vmerge_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, vbool16_t mask, size_t vl);
vint32m4_t __riscv_vmerge_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, vbool8_t mask, size_t vl);
vint32m4_t __riscv_vmerge_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, vbool8_t mask, size_t vl);
vint32m8_t __riscv_vmerge_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, vbool4_t mask, size_t vl);
vint32m8_t __riscv_vmerge_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, vbool4_t mask, size_t vl);
vint64m1_t __riscv_vmerge_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, vbool64_t mask, size_t vl);
vint64m1_t __riscv_vmerge_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, vbool64_t mask, size_t vl);
vint64m2_t __riscv_vmerge_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, vbool32_t mask, size_t vl);
vint64m2_t __riscv_vmerge_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, vbool32_t mask, size_t vl);
vint64m4_t __riscv_vmerge_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, vbool16_t mask, size_t vl);
vint64m4_t __riscv_vmerge_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, vbool16_t mask, size_t vl);
vint64m8_t __riscv_vmerge_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, vbool8_t mask, size_t vl);
vint64m8_t __riscv_vmerge_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, vbool8_t mask, size_t vl);
vuint8mf8_t __riscv_vmerge_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, vbool64_t mask, size_t vl);
vuint8mf8_t __riscv_vmerge_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, vbool64_t mask, size_t vl);
vuint8mf4_t __riscv_vmerge_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, vbool32_t mask, size_t vl);
vuint8mf4_t __riscv_vmerge_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, vbool32_t mask, size_t vl);
vuint8mf2_t __riscv_vmerge_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, vbool16_t mask, size_t vl);
vuint8mf2_t __riscv_vmerge_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, vbool16_t mask, size_t vl);
vuint8m1_t __riscv_vmerge_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, vbool8_t mask, size_t vl);
vuint8m1_t __riscv_vmerge_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, vbool8_t mask, size_t vl);
vuint8m2_t __riscv_vmerge_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, vbool4_t mask, size_t vl);
vuint8m2_t __riscv_vmerge_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, vbool4_t mask, size_t vl);
vuint8m4_t __riscv_vmerge_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, vbool2_t mask, size_t vl);
vuint8m4_t __riscv_vmerge_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, vbool2_t mask, size_t vl);
vuint8m8_t __riscv_vmerge_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, vbool1_t mask, size_t vl);
vuint8m8_t __riscv_vmerge_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, vbool1_t mask, size_t vl);
vuint16mf4_t __riscv_vmerge_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, vbool64_t mask, size_t vl);
vuint16mf4_t __riscv_vmerge_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, vbool64_t mask, size_t vl);
vuint16mf2_t __riscv_vmerge_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, vbool32_t mask, size_t vl);
vuint16mf2_t __riscv_vmerge_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, vbool32_t mask, size_t vl);
vuint16m1_t __riscv_vmerge_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, vbool16_t mask, size_t vl);
vuint16m1_t __riscv_vmerge_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, vbool16_t mask, size_t vl);
vuint16m2_t __riscv_vmerge_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, vbool8_t mask, size_t vl);
vuint16m2_t __riscv_vmerge_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, vbool8_t mask, size_t vl);
vuint16m4_t __riscv_vmerge_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, vbool4_t mask, size_t vl);
vuint16m4_t __riscv_vmerge_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, vbool4_t mask, size_t vl);
vuint16m8_t __riscv_vmerge_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, vbool2_t mask, size_t vl);
vuint16m8_t __riscv_vmerge_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, vbool2_t mask, size_t vl);
vuint32mf2_t __riscv_vmerge_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, vbool64_t mask, size_t vl);
vuint32mf2_t __riscv_vmerge_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, vbool64_t mask, size_t vl);
vuint32m1_t __riscv_vmerge_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, vbool32_t mask, size_t vl);
vuint32m1_t __riscv_vmerge_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, vbool32_t mask, size_t vl);
vuint32m2_t __riscv_vmerge_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, vbool16_t mask, size_t vl);
vuint32m2_t __riscv_vmerge_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, vbool16_t mask, size_t vl);
vuint32m4_t __riscv_vmerge_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, vbool8_t mask, size_t vl);
vuint32m4_t __riscv_vmerge_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, vbool8_t mask, size_t vl);
vuint32m8_t __riscv_vmerge_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, vbool4_t mask, size_t vl);
vuint32m8_t __riscv_vmerge_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, vbool4_t mask, size_t vl);
vuint64m1_t __riscv_vmerge_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, vbool64_t mask, size_t vl);
vuint64m1_t __riscv_vmerge_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, vbool64_t mask, size_t vl);
vuint64m2_t __riscv_vmerge_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, vbool32_t mask, size_t vl);
vuint64m2_t __riscv_vmerge_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, vbool32_t mask, size_t vl);
vuint64m4_t __riscv_vmerge_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, vbool16_t mask, size_t vl);
vuint64m4_t __riscv_vmerge_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, vbool16_t mask, size_t vl);
vuint64m8_t __riscv_vmerge_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, vbool8_t mask, size_t vl);
vuint64m8_t __riscv_vmerge_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, vbool8_t mask, size_t vl);
```

[[policy-variant-overloadedvector-integer-move]]
=== Vector Integer Move Intrinsics

``` C
vint8mf8_t __riscv_vmv_v_tu (vint8mf8_t maskedoff, vint8mf8_t src, size_t vl);
vint8mf8_t __riscv_vmv_v_tu (vint8mf8_t maskedoff, int8_t src, size_t vl);
vint8mf4_t __riscv_vmv_v_tu (vint8mf4_t maskedoff, vint8mf4_t src, size_t vl);
vint8mf4_t __riscv_vmv_v_tu (vint8mf4_t maskedoff, int8_t src, size_t vl);
vint8mf2_t __riscv_vmv_v_tu (vint8mf2_t maskedoff, vint8mf2_t src, size_t vl);
vint8mf2_t __riscv_vmv_v_tu (vint8mf2_t maskedoff, int8_t src, size_t vl);
vint8m1_t __riscv_vmv_v_tu (vint8m1_t maskedoff, vint8m1_t src, size_t vl);
vint8m1_t __riscv_vmv_v_tu (vint8m1_t maskedoff, int8_t src, size_t vl);
vint8m2_t __riscv_vmv_v_tu (vint8m2_t maskedoff, vint8m2_t src, size_t vl);
vint8m2_t __riscv_vmv_v_tu (vint8m2_t maskedoff, int8_t src, size_t vl);
vint8m4_t __riscv_vmv_v_tu (vint8m4_t maskedoff, vint8m4_t src, size_t vl);
vint8m4_t __riscv_vmv_v_tu (vint8m4_t maskedoff, int8_t src, size_t vl);
vint8m8_t __riscv_vmv_v_tu (vint8m8_t maskedoff, vint8m8_t src, size_t vl);
vint8m8_t __riscv_vmv_v_tu (vint8m8_t maskedoff, int8_t src, size_t vl);
vint16mf4_t __riscv_vmv_v_tu (vint16mf4_t maskedoff, vint16mf4_t src, size_t vl);
vint16mf4_t __riscv_vmv_v_tu (vint16mf4_t maskedoff, int16_t src, size_t vl);
vint16mf2_t __riscv_vmv_v_tu (vint16mf2_t maskedoff, vint16mf2_t src, size_t vl);
vint16mf2_t __riscv_vmv_v_tu (vint16mf2_t maskedoff, int16_t src, size_t vl);
vint16m1_t __riscv_vmv_v_tu (vint16m1_t maskedoff, vint16m1_t src, size_t vl);
vint16m1_t __riscv_vmv_v_tu (vint16m1_t maskedoff, int16_t src, size_t vl);
vint16m2_t __riscv_vmv_v_tu (vint16m2_t maskedoff, vint16m2_t src, size_t vl);
vint16m2_t __riscv_vmv_v_tu (vint16m2_t maskedoff, int16_t src, size_t vl);
vint16m4_t __riscv_vmv_v_tu (vint16m4_t maskedoff, vint16m4_t src, size_t vl);
vint16m4_t __riscv_vmv_v_tu (vint16m4_t maskedoff, int16_t src, size_t vl);
vint16m8_t __riscv_vmv_v_tu (vint16m8_t maskedoff, vint16m8_t src, size_t vl);
vint16m8_t __riscv_vmv_v_tu (vint16m8_t maskedoff, int16_t src, size_t vl);
vint32mf2_t __riscv_vmv_v_tu (vint32mf2_t maskedoff, vint32mf2_t src, size_t vl);
vint32mf2_t __riscv_vmv_v_tu (vint32mf2_t maskedoff, int32_t src, size_t vl);
vint32m1_t __riscv_vmv_v_tu (vint32m1_t maskedoff, vint32m1_t src, size_t vl);
vint32m1_t __riscv_vmv_v_tu (vint32m1_t maskedoff, int32_t src, size_t vl);
vint32m2_t __riscv_vmv_v_tu (vint32m2_t maskedoff, vint32m2_t src, size_t vl);
vint32m2_t __riscv_vmv_v_tu (vint32m2_t maskedoff, int32_t src, size_t vl);
vint32m4_t __riscv_vmv_v_tu (vint32m4_t maskedoff, vint32m4_t src, size_t vl);
vint32m4_t __riscv_vmv_v_tu (vint32m4_t maskedoff, int32_t src, size_t vl);
vint32m8_t __riscv_vmv_v_tu (vint32m8_t maskedoff, vint32m8_t src, size_t vl);
vint32m8_t __riscv_vmv_v_tu (vint32m8_t maskedoff, int32_t src, size_t vl);
vint64m1_t __riscv_vmv_v_tu (vint64m1_t maskedoff, vint64m1_t src, size_t vl);
vint64m1_t __riscv_vmv_v_tu (vint64m1_t maskedoff, int64_t src, size_t vl);
vint64m2_t __riscv_vmv_v_tu (vint64m2_t maskedoff, vint64m2_t src, size_t vl);
vint64m2_t __riscv_vmv_v_tu (vint64m2_t maskedoff, int64_t src, size_t vl);
vint64m4_t __riscv_vmv_v_tu (vint64m4_t maskedoff, vint64m4_t src, size_t vl);
vint64m4_t __riscv_vmv_v_tu (vint64m4_t maskedoff, int64_t src, size_t vl);
vint64m8_t __riscv_vmv_v_tu (vint64m8_t maskedoff, vint64m8_t src, size_t vl);
vint64m8_t __riscv_vmv_v_tu (vint64m8_t maskedoff, int64_t src, size_t vl);
vuint8mf8_t __riscv_vmv_v_tu (vuint8mf8_t maskedoff, vuint8mf8_t src, size_t vl);
vuint8mf8_t __riscv_vmv_v_tu (vuint8mf8_t maskedoff, uint8_t src, size_t vl);
vuint8mf4_t __riscv_vmv_v_tu (vuint8mf4_t maskedoff, vuint8mf4_t src, size_t vl);
vuint8mf4_t __riscv_vmv_v_tu (vuint8mf4_t maskedoff, uint8_t src, size_t vl);
vuint8mf2_t __riscv_vmv_v_tu (vuint8mf2_t maskedoff, vuint8mf2_t src, size_t vl);
vuint8mf2_t __riscv_vmv_v_tu (vuint8mf2_t maskedoff, uint8_t src, size_t vl);
vuint8m1_t __riscv_vmv_v_tu (vuint8m1_t maskedoff, vuint8m1_t src, size_t vl);
vuint8m1_t __riscv_vmv_v_tu (vuint8m1_t maskedoff, uint8_t src, size_t vl);
vuint8m2_t __riscv_vmv_v_tu (vuint8m2_t maskedoff, vuint8m2_t src, size_t vl);
vuint8m2_t __riscv_vmv_v_tu (vuint8m2_t maskedoff, uint8_t src, size_t vl);
vuint8m4_t __riscv_vmv_v_tu (vuint8m4_t maskedoff, vuint8m4_t src, size_t vl);
vuint8m4_t __riscv_vmv_v_tu (vuint8m4_t maskedoff, uint8_t src, size_t vl);
vuint8m8_t __riscv_vmv_v_tu (vuint8m8_t maskedoff, vuint8m8_t src, size_t vl);
vuint8m8_t __riscv_vmv_v_tu (vuint8m8_t maskedoff, uint8_t src, size_t vl);
vuint16mf4_t __riscv_vmv_v_tu (vuint16mf4_t maskedoff, vuint16mf4_t src, size_t vl);
vuint16mf4_t __riscv_vmv_v_tu (vuint16mf4_t maskedoff, uint16_t src, size_t vl);
vuint16mf2_t __riscv_vmv_v_tu (vuint16mf2_t maskedoff, vuint16mf2_t src, size_t vl);
vuint16mf2_t __riscv_vmv_v_tu (vuint16mf2_t maskedoff, uint16_t src, size_t vl);
vuint16m1_t __riscv_vmv_v_tu (vuint16m1_t maskedoff, vuint16m1_t src, size_t vl);
vuint16m1_t __riscv_vmv_v_tu (vuint16m1_t maskedoff, uint16_t src, size_t vl);
vuint16m2_t __riscv_vmv_v_tu (vuint16m2_t maskedoff, vuint16m2_t src, size_t vl);
vuint16m2_t __riscv_vmv_v_tu (vuint16m2_t maskedoff, uint16_t src, size_t vl);
vuint16m4_t __riscv_vmv_v_tu (vuint16m4_t maskedoff, vuint16m4_t src, size_t vl);
vuint16m4_t __riscv_vmv_v_tu (vuint16m4_t maskedoff, uint16_t src, size_t vl);
vuint16m8_t __riscv_vmv_v_tu (vuint16m8_t maskedoff, vuint16m8_t src, size_t vl);
vuint16m8_t __riscv_vmv_v_tu (vuint16m8_t maskedoff, uint16_t src, size_t vl);
vuint32mf2_t __riscv_vmv_v_tu (vuint32mf2_t maskedoff, vuint32mf2_t src, size_t vl);
vuint32mf2_t __riscv_vmv_v_tu (vuint32mf2_t maskedoff, uint32_t src, size_t vl);
vuint32m1_t __riscv_vmv_v_tu (vuint32m1_t maskedoff, vuint32m1_t src, size_t vl);
vuint32m1_t __riscv_vmv_v_tu (vuint32m1_t maskedoff, uint32_t src, size_t vl);
vuint32m2_t __riscv_vmv_v_tu (vuint32m2_t maskedoff, vuint32m2_t src, size_t vl);
vuint32m2_t __riscv_vmv_v_tu (vuint32m2_t maskedoff, uint32_t src, size_t vl);
vuint32m4_t __riscv_vmv_v_tu (vuint32m4_t maskedoff, vuint32m4_t src, size_t vl);
vuint32m4_t __riscv_vmv_v_tu (vuint32m4_t maskedoff, uint32_t src, size_t vl);
vuint32m8_t __riscv_vmv_v_tu (vuint32m8_t maskedoff, vuint32m8_t src, size_t vl);
vuint32m8_t __riscv_vmv_v_tu (vuint32m8_t maskedoff, uint32_t src, size_t vl);
vuint64m1_t __riscv_vmv_v_tu (vuint64m1_t maskedoff, vuint64m1_t src, size_t vl);
vuint64m1_t __riscv_vmv_v_tu (vuint64m1_t maskedoff, uint64_t src, size_t vl);
vuint64m2_t __riscv_vmv_v_tu (vuint64m2_t maskedoff, vuint64m2_t src, size_t vl);
vuint64m2_t __riscv_vmv_v_tu (vuint64m2_t maskedoff, uint64_t src, size_t vl);
vuint64m4_t __riscv_vmv_v_tu (vuint64m4_t maskedoff, vuint64m4_t src, size_t vl);
vuint64m4_t __riscv_vmv_v_tu (vuint64m4_t maskedoff, uint64_t src, size_t vl);
vuint64m8_t __riscv_vmv_v_tu (vuint64m8_t maskedoff, vuint64m8_t src, size_t vl);
vuint64m8_t __riscv_vmv_v_tu (vuint64m8_t maskedoff, uint64_t src, size_t vl);
```

== Vector Fixed-Point Arithmetic Instructions

[[policy-variant-overloadedvector-single-width-saturating-add-and-subtract]]
=== Vector Single-Width Saturating Add and Subtract Intrinsics

``` C
vint8mf8_t __riscv_vsadd_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsadd_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vssub_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vssub_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vssub_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vssub_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vssub_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vssub_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vssub_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vssub_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vssub_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vssub_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vssub_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vssub_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vssub_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vssub_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vssub_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vssub_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vssub_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vssub_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vssub_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vssub_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vssub_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vssub_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vssub_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vssub_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vssub_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vssub_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vssub_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vssub_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vssub_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vssub_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vsadd_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsadd_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vssub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vssub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vssub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vssub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vssub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vssub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vssub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vssub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vssub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vssub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vssub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vssub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vssub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vssub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vssub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vssub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vssub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vssub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vssub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vssub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vssub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vssub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vssub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vssub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vssub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vssub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vssub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vssub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vssub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vssub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vsadd_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsadd_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vssub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vssub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vssub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vssub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vssub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vssub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vssub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vssub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vssub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vssub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vssub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vssub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vssub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vssub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vssub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vssub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vssub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vssub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vssub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vssub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vssub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vssub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vssub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vssub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vssub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vssub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vssub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vssub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vssub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vssub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vsadd_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsadd_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsadd_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsadd_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsadd_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsadd_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsadd_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsadd_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsadd_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsadd_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsadd_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsadd_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsadd_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsadd_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsadd_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsadd_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsadd_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsadd_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsadd_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsadd_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsadd_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsadd_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsadd_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsadd_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsadd_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsadd_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsadd_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsadd_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsadd_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsadd_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsadd_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsadd_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vssub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vssub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vssub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vssub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vssub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vssub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vssub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vssub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vssub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vssub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vssub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vssub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vssub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vssub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vssub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vssub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vssub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vssub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vssub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vssub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vssub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vssub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vssub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vssub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vssub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vssub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vssub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vssub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vssub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vssub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vssub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vssub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vssub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vssub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vssub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vssub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vssub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vssub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vssub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vssub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vssub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vssub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vssub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vssub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
```

[[policy-variant-overloadedvector-single-width-averaging-add-and-subtract]]
=== Vector Single-Width Averaging Add and Subtract Intrinsics

``` C
vint8mf8_t __riscv_vaadd_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vaadd_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vaadd_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vaadd_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vaadd_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vaadd_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vaadd_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vaadd_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
```

[[policy-variant-overloadedvector-single-width-fractional-multiply-with-rounding-and-saturation]]
=== Vector Single-Width Fractional Multiply with Rounding and SaturationIntrinsics

``` C
vint8mf8_t __riscv_vsmul_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vsmul_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vsmul_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vsmul_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vsmul_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vsmul_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vsmul_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vsmul_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
```

[[policy-variant-overloadedvector-single-width-scaling-shift]]
=== Vector Single-Width Scaling Shift Intrinsics

``` C
vint8mf8_t __riscv_vssra_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vssra_tu (vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tu (vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tu (vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tu (vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tu (vint8m1_t maskedoff, vint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tu (vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tu (vint8m2_t maskedoff, vint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tu (vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tu (vint8m4_t maskedoff, vint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tu (vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tu (vint8m8_t maskedoff, vint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tu (vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tu (vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tu (vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tu (vint16m1_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tu (vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tu (vint16m2_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tu (vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tu (vint16m4_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tu (vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tu (vint16m8_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tu (vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tu (vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tu (vint32m1_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tu (vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tu (vint32m2_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tu (vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tu (vint32m4_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tu (vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tu (vint32m8_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tu (vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tu (vint64m1_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tu (vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tu (vint64m2_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tu (vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tu (vint64m4_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tu (vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tu (vint64m8_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tu (vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tu (vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tu (vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tu (vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tu (vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tu (vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tu (vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tu (vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tu (vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tu (vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tu (vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tu (vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tu (vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tu (vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tu (vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tu (vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vssra_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vssra_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vssra_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vssra_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vssra_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vssra_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
```

[[policy-variant-overloadedvector-narrowing-fixed-point-clip]]
=== Vector Narrowing Fixed-Point Clip Intrinsics

``` C
vint8mf8_t __riscv_vnclip_tu (vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vnclip_tu (vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tu (vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tu (vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tu (vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tu (vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tu (vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tu (vint8m1_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tu (vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tu (vint8m2_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tu (vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tu (vint8m4_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tu (vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tu (vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tu (vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tu (vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tu (vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tu (vint16m1_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tu (vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tu (vint16m2_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tu (vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tu (vint16m4_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tu (vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tu (vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tu (vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tu (vint32m1_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tu (vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tu (vint32m2_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tu (vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tu (vint32m4_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tu (vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tu (vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tu (vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tu (vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tu (vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tu (vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tu (vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tu (vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tu (vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tu (vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tu (vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tu (vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tu (vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tu (vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tu (vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tu (vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tu (vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tu (vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tu (vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tu (vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tu (vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tu (vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tu (vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tu (vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tu (vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tu (vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tu (vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tu (vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tu (vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tu (vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vnclip_tum (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vnclip_tum (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tum (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tum (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tum (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tum (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tum (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tum (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tum (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tum (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tum (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tum (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tum (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tum (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tum (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tum (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tum (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tum (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tum (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tum (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tum (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tum (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tum (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tum (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tum (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tum (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tum (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tum (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tum (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tum (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vnclip_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vnclip_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tumu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tumu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tumu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tumu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tumu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tumu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tumu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tumu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tumu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tumu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tumu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tumu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tumu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tumu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tumu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tumu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tumu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tumu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vnclip_mu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vnclip_mu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_mu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_mu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_mu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_mu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_mu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_mu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_mu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_mu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_mu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_mu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_mu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_mu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_mu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_mu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_mu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_mu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_mu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_mu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_mu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_mu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_mu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_mu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_mu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_mu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_mu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_mu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_mu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_mu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
```

== Vector Floating-Point Instructions

[[policy-variant-overloadedvector-single-width-floating-point-add-subtract]]
=== Vector Single-Width Floating-Point Add/Subtract Intrinsics

``` C
vfloat16mf4_t __riscv_vfadd_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfadd_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfadd_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfadd_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfadd_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfadd_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfadd_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfadd_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfadd_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfadd_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfadd_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfadd_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfadd_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfadd_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfadd_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfadd_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfadd_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfadd_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfadd_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfadd_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfadd_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfadd_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfadd_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfadd_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfadd_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfadd_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfadd_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfadd_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfadd_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfadd_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsub_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsub_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsub_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsub_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsub_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsub_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsub_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsub_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsub_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsub_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsub_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsub_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsub_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsub_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsub_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsub_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsub_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsub_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsub_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsub_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsub_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsub_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsub_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsub_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsub_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsub_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsub_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsub_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsub_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsub_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfrsub_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfrsub_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfrsub_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfrsub_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfrsub_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfrsub_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfrsub_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfrsub_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfrsub_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfrsub_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfrsub_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfrsub_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfrsub_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfrsub_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfrsub_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfneg_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfneg_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfneg_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfneg_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfneg_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfneg_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfneg_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfneg_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfneg_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfneg_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfneg_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfneg_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfneg_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfneg_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfneg_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfadd_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfadd_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfadd_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfadd_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfadd_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfadd_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfadd_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfadd_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfadd_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfadd_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfadd_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfadd_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfadd_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfadd_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfadd_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfadd_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfadd_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfadd_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfadd_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfadd_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfadd_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfadd_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfadd_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfadd_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfadd_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfadd_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfadd_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfadd_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfadd_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfadd_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsub_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsub_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsub_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsub_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsub_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsub_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsub_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsub_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsub_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsub_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsub_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsub_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsub_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsub_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsub_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsub_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsub_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsub_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsub_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsub_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsub_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsub_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsub_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsub_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsub_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsub_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsub_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsub_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsub_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsub_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfrsub_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfrsub_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfrsub_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfrsub_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfrsub_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfrsub_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfrsub_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfrsub_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfrsub_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfrsub_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfrsub_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfrsub_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfrsub_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfrsub_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfrsub_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfneg_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfneg_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfneg_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfneg_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfneg_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfneg_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfneg_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfneg_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfneg_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfneg_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfneg_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfneg_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfneg_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfneg_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfneg_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfadd_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfadd_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfadd_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfadd_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfadd_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfadd_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfadd_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfadd_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfadd_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfadd_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfadd_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfadd_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfadd_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfadd_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfadd_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfadd_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfadd_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfadd_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfadd_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfadd_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfadd_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfadd_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfadd_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfadd_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfadd_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfadd_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfadd_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfadd_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfadd_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfadd_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsub_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsub_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsub_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsub_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsub_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsub_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsub_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsub_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsub_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsub_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsub_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsub_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsub_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsub_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsub_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsub_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsub_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsub_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsub_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsub_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsub_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsub_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsub_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsub_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsub_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsub_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsub_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsub_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsub_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsub_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfrsub_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfrsub_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfrsub_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfrsub_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfrsub_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfrsub_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfrsub_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfrsub_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfrsub_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfrsub_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfrsub_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfrsub_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfrsub_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfrsub_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfrsub_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfneg_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfneg_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfneg_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfneg_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfneg_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfneg_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfneg_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfneg_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfneg_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfneg_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfneg_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfneg_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfneg_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfneg_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfneg_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfadd_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfadd_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfadd_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfadd_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfadd_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfadd_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfadd_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfadd_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfadd_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfadd_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfadd_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfadd_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfadd_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfadd_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfadd_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfadd_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfadd_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfadd_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfadd_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfadd_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfadd_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfadd_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfadd_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfadd_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfadd_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfadd_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfadd_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfadd_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfadd_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfadd_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsub_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsub_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsub_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsub_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsub_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsub_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsub_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsub_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsub_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsub_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsub_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsub_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsub_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsub_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsub_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsub_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsub_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsub_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsub_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsub_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsub_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsub_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsub_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsub_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsub_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsub_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsub_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsub_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsub_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsub_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfrsub_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfrsub_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfrsub_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfrsub_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfrsub_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfrsub_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfrsub_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfrsub_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfrsub_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfrsub_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfrsub_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfrsub_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfrsub_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfrsub_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfrsub_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfneg_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfneg_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfneg_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfneg_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfneg_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfneg_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfneg_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfneg_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfneg_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfneg_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfneg_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfneg_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfneg_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfneg_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfneg_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
vfloat16mf4_t __riscv_vfadd_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfadd_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfadd_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfadd_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfadd_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfadd_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfadd_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfadd_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfadd_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfadd_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfadd_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfadd_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfadd_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfadd_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfadd_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfadd_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfadd_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfadd_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfadd_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfadd_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfadd_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfadd_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfadd_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfadd_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfadd_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfadd_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfadd_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfadd_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfadd_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfadd_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfsub_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfsub_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsub_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsub_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsub_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsub_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsub_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsub_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsub_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsub_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsub_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsub_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsub_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsub_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsub_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsub_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsub_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsub_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsub_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsub_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsub_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsub_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsub_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsub_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsub_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsub_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsub_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsub_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsub_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsub_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfrsub_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrsub_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrsub_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrsub_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrsub_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrsub_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrsub_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrsub_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrsub_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrsub_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrsub_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrsub_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrsub_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrsub_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrsub_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfadd_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfadd_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfadd_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfadd_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfadd_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfadd_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfadd_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfadd_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfadd_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfadd_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfadd_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfadd_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfadd_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfadd_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfadd_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfadd_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfadd_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfadd_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfadd_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfadd_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfadd_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfadd_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfadd_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfadd_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfadd_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfadd_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfadd_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfadd_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfadd_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfadd_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfsub_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfsub_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsub_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsub_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsub_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsub_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsub_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsub_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsub_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsub_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsub_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsub_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsub_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsub_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsub_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsub_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsub_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsub_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsub_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsub_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsub_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsub_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsub_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsub_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsub_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsub_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsub_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsub_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsub_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsub_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfrsub_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrsub_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrsub_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrsub_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrsub_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrsub_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrsub_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrsub_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrsub_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrsub_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrsub_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrsub_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrsub_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrsub_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrsub_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfadd_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfadd_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfadd_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfadd_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfadd_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfadd_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfadd_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfadd_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfadd_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfadd_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfadd_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfadd_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfadd_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfadd_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfadd_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfadd_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfadd_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfadd_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfadd_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfadd_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfadd_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfadd_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfadd_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfadd_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfadd_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfadd_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfadd_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfadd_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfadd_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfadd_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfsub_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfsub_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsub_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsub_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsub_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsub_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsub_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsub_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsub_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsub_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsub_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsub_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsub_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsub_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsub_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsub_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsub_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsub_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsub_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsub_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsub_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsub_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsub_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsub_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsub_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsub_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsub_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsub_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsub_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsub_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfrsub_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrsub_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrsub_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrsub_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrsub_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrsub_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrsub_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrsub_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrsub_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrsub_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrsub_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrsub_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrsub_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrsub_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrsub_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfadd_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfadd_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfadd_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfadd_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfadd_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfadd_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfadd_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfadd_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfadd_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfadd_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfadd_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfadd_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfadd_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfadd_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfadd_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfadd_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfadd_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfadd_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfadd_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfadd_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfadd_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfadd_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfadd_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfadd_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfadd_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfadd_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfadd_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfadd_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfadd_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfadd_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfsub_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfsub_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsub_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsub_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsub_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsub_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsub_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsub_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsub_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsub_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsub_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsub_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsub_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsub_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsub_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsub_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsub_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsub_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsub_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsub_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsub_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsub_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsub_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsub_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsub_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsub_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsub_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsub_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsub_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsub_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfrsub_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrsub_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrsub_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrsub_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrsub_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrsub_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrsub_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrsub_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrsub_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrsub_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrsub_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrsub_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrsub_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrsub_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrsub_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
```

[[policy-variant-overloadedvector-widening-floating-point-add-subtract]]
=== Vector Widening Floating-Point Add/Subtract Intrinsics

``` C
vfloat32mf2_t __riscv_vfwadd_vv_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwadd_vv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwadd_vv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwadd_vv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vv_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwadd_vv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwadd_vv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwadd_vv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_vf_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwadd_wf_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_vv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_vf_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_wv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwadd_wf_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_vv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_vf_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_wv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwadd_wf_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_vv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_vf_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_wv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwadd_wf_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_vv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_vf_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_wv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwadd_wf_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_vv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_vf_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_wv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwadd_wf_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_vv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_vf_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_wv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwadd_wf_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_vv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_vf_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_wv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwadd_wf_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_vv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_vf_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_wv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwadd_wf_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_vf_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwsub_wf_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_vv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_vf_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_wv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwsub_wf_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_vv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_vf_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_wv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwsub_wf_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_vv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_vf_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_wv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwsub_wf_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_vv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_vf_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_wv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwsub_wf_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_vv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_vf_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_wv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwsub_wf_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_vv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_vf_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_wv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwsub_wf_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_vv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_vf_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_wv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwsub_wf_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_vv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_vf_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_wv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwsub_wf_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2, unsigned int frm, size_t vl);
```

[[policy-variant-overloadedvector-single-width-floating-point-multiply-divide]]
=== Vector Single-Width Floating-Point Multiply/Divide Intrinsics

``` C
vfloat16mf4_t __riscv_vfmul_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmul_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmul_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmul_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmul_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmul_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmul_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmul_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmul_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmul_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmul_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmul_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmul_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmul_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmul_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmul_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmul_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmul_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmul_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmul_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmul_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmul_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmul_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmul_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmul_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmul_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmul_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmul_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmul_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmul_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfdiv_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfdiv_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfdiv_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfdiv_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfdiv_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfdiv_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfdiv_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfdiv_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfdiv_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfdiv_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfdiv_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfdiv_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfdiv_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfdiv_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfdiv_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfdiv_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfdiv_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfdiv_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfdiv_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfdiv_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfdiv_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfdiv_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfdiv_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfdiv_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfrdiv_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfrdiv_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfrdiv_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfrdiv_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfrdiv_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfrdiv_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfrdiv_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfrdiv_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfrdiv_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfrdiv_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfrdiv_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfrdiv_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfrdiv_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfrdiv_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmul_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmul_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmul_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmul_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmul_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmul_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmul_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmul_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmul_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmul_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmul_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmul_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmul_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmul_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmul_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmul_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmul_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmul_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmul_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmul_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmul_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmul_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmul_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmul_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmul_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmul_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmul_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmul_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmul_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmul_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfdiv_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfdiv_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfdiv_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfdiv_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfdiv_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfdiv_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfdiv_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfdiv_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfdiv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfdiv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfdiv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfdiv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfdiv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfdiv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfdiv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfdiv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfdiv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfdiv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfdiv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfdiv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfdiv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfdiv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfdiv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfdiv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfrdiv_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfrdiv_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfrdiv_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfrdiv_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfrdiv_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfrdiv_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfrdiv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfrdiv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfrdiv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfrdiv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfrdiv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfrdiv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfrdiv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfrdiv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmul_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmul_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmul_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmul_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmul_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmul_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmul_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmul_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmul_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmul_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmul_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmul_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmul_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmul_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmul_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmul_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmul_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmul_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmul_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmul_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmul_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmul_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmul_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmul_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmul_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmul_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmul_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmul_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmul_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmul_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfdiv_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfdiv_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfdiv_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfdiv_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfdiv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfdiv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfrdiv_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfrdiv_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfrdiv_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfrdiv_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfrdiv_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfrdiv_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfrdiv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfrdiv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfrdiv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfrdiv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfrdiv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfrdiv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfrdiv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfrdiv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmul_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmul_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmul_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmul_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmul_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmul_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmul_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmul_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmul_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmul_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmul_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmul_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmul_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmul_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmul_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmul_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmul_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmul_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmul_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmul_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmul_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmul_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmul_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmul_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmul_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmul_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmul_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmul_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmul_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmul_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfdiv_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfdiv_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfdiv_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfdiv_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfdiv_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfdiv_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfdiv_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfdiv_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfdiv_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfdiv_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfdiv_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfdiv_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfdiv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfdiv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfdiv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfdiv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfdiv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfdiv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfdiv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfdiv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfdiv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfdiv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfdiv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfdiv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfdiv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfdiv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfdiv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfdiv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfdiv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfdiv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfrdiv_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfrdiv_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfrdiv_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfrdiv_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfrdiv_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfrdiv_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfrdiv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfrdiv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfrdiv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfrdiv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfrdiv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfrdiv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfrdiv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfrdiv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmul_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmul_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmul_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmul_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmul_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmul_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmul_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmul_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmul_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmul_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmul_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmul_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmul_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmul_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmul_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmul_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmul_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmul_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmul_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmul_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmul_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmul_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmul_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmul_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmul_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmul_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmul_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmul_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmul_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmul_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfdiv_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfdiv_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfdiv_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfdiv_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfdiv_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfdiv_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfdiv_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfdiv_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfdiv_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfdiv_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfdiv_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfdiv_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfdiv_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfdiv_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfdiv_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfdiv_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfdiv_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfdiv_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfdiv_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfdiv_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfdiv_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfdiv_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfdiv_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfdiv_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfrdiv_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrdiv_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrdiv_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrdiv_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrdiv_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrdiv_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrdiv_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrdiv_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrdiv_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrdiv_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrdiv_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrdiv_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrdiv_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrdiv_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmul_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmul_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmul_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmul_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmul_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmul_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmul_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmul_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmul_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmul_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmul_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmul_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmul_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmul_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmul_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmul_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmul_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmul_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmul_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmul_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmul_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmul_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmul_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmul_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmul_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmul_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmul_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmul_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmul_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmul_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfdiv_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfdiv_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfdiv_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfdiv_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfdiv_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfdiv_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfdiv_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfdiv_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfdiv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfdiv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfdiv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfdiv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfdiv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfdiv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfdiv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfdiv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfdiv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfdiv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfdiv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfdiv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfdiv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfdiv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfdiv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfdiv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfrdiv_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrdiv_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrdiv_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrdiv_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrdiv_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrdiv_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrdiv_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrdiv_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrdiv_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrdiv_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrdiv_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrdiv_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrdiv_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrdiv_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmul_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmul_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmul_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmul_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmul_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmul_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmul_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmul_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmul_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmul_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmul_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmul_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmul_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmul_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmul_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmul_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmul_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmul_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmul_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmul_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmul_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmul_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmul_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmul_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmul_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmul_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmul_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmul_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmul_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmul_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfdiv_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfdiv_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfdiv_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfdiv_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfdiv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfdiv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfdiv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfdiv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfdiv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfdiv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfrdiv_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrdiv_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrdiv_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrdiv_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrdiv_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrdiv_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrdiv_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrdiv_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrdiv_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrdiv_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrdiv_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrdiv_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrdiv_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrdiv_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmul_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmul_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmul_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmul_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmul_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmul_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmul_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmul_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmul_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmul_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmul_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmul_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmul_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmul_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmul_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmul_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmul_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmul_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmul_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmul_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmul_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmul_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmul_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmul_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmul_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmul_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmul_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmul_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmul_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmul_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfdiv_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfdiv_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfdiv_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfdiv_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfdiv_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfdiv_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfdiv_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfdiv_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfdiv_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfdiv_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfdiv_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfdiv_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfdiv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfdiv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfdiv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfdiv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfdiv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfdiv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfdiv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfdiv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfdiv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfdiv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfdiv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfdiv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfdiv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfdiv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfdiv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfdiv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfdiv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfdiv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfrdiv_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrdiv_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrdiv_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrdiv_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrdiv_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrdiv_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrdiv_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrdiv_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrdiv_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrdiv_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrdiv_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrdiv_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrdiv_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrdiv_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrdiv_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, unsigned int frm, size_t vl);
```

[[policy-variant-overloadedvector-widening-floating-point-multiply]]
=== Vector Widening Floating-Point Multiply Intrinsics

``` C
vfloat32mf2_t __riscv_vfwmul_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwmul_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwmul_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwmul_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwmul_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwmul_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwmul_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwmul_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwmul_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwmul_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwmul_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwmul_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwmul_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwmul_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwmul_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwmul_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwmul_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwmul_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmul_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwmul_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwmul_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwmul_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwmul_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwmul_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwmul_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwmul_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwmul_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwmul_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwmul_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwmul_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwmul_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwmul_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwmul_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwmul_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwmul_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwmul_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmul_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwmul_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwmul_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwmul_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwmul_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwmul_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwmul_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwmul_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwmul_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwmul_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwmul_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwmul_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwmul_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwmul_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwmul_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwmul_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwmul_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwmul_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmul_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwmul_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat32m1_t __riscv_vfwmul_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat32m1_t __riscv_vfwmul_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat32m2_t __riscv_vfwmul_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat32m2_t __riscv_vfwmul_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat32m4_t __riscv_vfwmul_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat32m4_t __riscv_vfwmul_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat32m8_t __riscv_vfwmul_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat32m8_t __riscv_vfwmul_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat64m1_t __riscv_vfwmul_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat64m1_t __riscv_vfwmul_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat64m2_t __riscv_vfwmul_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat64m2_t __riscv_vfwmul_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat64m4_t __riscv_vfwmul_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat64m4_t __riscv_vfwmul_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat64m8_t __riscv_vfwmul_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat64m8_t __riscv_vfwmul_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32mf2_t __riscv_vfwmul_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmul_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmul_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmul_tu (vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmul_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmul_tu (vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmul_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmul_tu (vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmul_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmul_tu (vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmul_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmul_tu (vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmul_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmul_tu (vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmul_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmul_tu (vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmul_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmul_tu (vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmul_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmul_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmul_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmul_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmul_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmul_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmul_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmul_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmul_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmul_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmul_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmul_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmul_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmul_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmul_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmul_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmul_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmul_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmul_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmul_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmul_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmul_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmul_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmul_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmul_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmul_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmul_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmul_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmul_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmul_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmul_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmul_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmul_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmul_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmul_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmul_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmul_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmul_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmul_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmul_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmul_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmul_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmul_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmul_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmul_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmul_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmul_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmul_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmul_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmul_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmul_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmul_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmul_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmul_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2, unsigned int frm, size_t vl);
```

[[policy-variant-overloadedvector-single-width-floating-point-fused-multiply-add]]
=== Vector Single-Width Floating-Point Fused Multiply-Add Intrinsics

``` C
vfloat16mf4_t __riscv_vfmacc_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmacc_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmacc_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmacc_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmacc_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmacc_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmacc_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmacc_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmacc_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmacc_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmacc_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmacc_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsac_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsac_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsac_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsac_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsac_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsac_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsac_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsac_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsac_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsac_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmadd_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmadd_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmadd_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmadd_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmadd_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmadd_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmadd_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmadd_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmadd_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmadd_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsub_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsub_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsub_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsub_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsub_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsub_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsub_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsub_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsub_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsub_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmacc_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmacc_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmacc_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmacc_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmacc_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmacc_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmacc_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmacc_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmacc_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmacc_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmacc_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmacc_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsac_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsac_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsac_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsac_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsac_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsac_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsac_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsac_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsac_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsac_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmadd_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmadd_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmadd_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmadd_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmadd_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmadd_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmadd_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmadd_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmadd_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmadd_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsub_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsub_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsub_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsub_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsub_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsub_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsub_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsub_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsub_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsub_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmacc_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmacc_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmacc_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmacc_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsac_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsac_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsac_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsac_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmadd_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmadd_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmadd_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmadd_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsub_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsub_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsub_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsub_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmacc_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmacc_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmacc_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmacc_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmacc_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmacc_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmacc_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmacc_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmacc_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmacc_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmacc_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmacc_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmacc_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmacc_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmacc_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmacc_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmacc_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmacc_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmacc_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmacc_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmacc_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmacc_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmacc_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmacc_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmacc_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmacc_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmacc_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmacc_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsac_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsac_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsac_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsac_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsac_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsac_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsac_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsac_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsac_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsac_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsac_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsac_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsac_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsac_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsac_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsac_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsac_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsac_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsac_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsac_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsac_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsac_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsac_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsac_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsac_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsac_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsac_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsac_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmadd_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmadd_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmadd_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmadd_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmadd_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmadd_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmadd_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmadd_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmadd_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmadd_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmadd_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmadd_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmadd_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmadd_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmadd_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmadd_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmadd_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmadd_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmadd_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmadd_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmadd_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmadd_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmadd_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmadd_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmadd_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmadd_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmadd_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmadd_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsub_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmsub_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsub_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfmsub_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsub_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfmsub_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsub_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfmsub_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsub_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfmsub_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsub_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfmsub_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsub_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfmsub_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsub_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfmsub_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfmsub_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfmsub_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfmsub_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfmsub_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfmsub_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfmsub_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfmsub_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat16m1_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat16m2_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsub_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat16m4_t __riscv_vfnmsub_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsub_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, size_t vl);
vfloat16m8_t __riscv_vfnmsub_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat32m1_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32m4_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, size_t vl);
vfloat32m8_t __riscv_vfnmsub_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, size_t vl);
vfloat64m1_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, size_t vl);
vfloat64m4_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, size_t vl);
vfloat64m8_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, size_t vl);
vfloat16mf4_t __riscv_vfmacc_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmacc_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmacc_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmacc_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmacc_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmacc_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmacc_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmacc_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmacc_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmacc_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmacc_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmacc_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmacc_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmacc_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmacc_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmacc_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmacc_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmacc_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmacc_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmacc_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmacc_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmacc_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmacc_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmacc_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmacc_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmacc_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsac_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsac_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsac_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsac_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsac_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsac_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsac_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsac_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsac_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsac_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsac_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsac_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsac_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsac_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsac_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsac_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsac_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsac_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsac_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsac_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsac_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsac_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsac_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsac_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmadd_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmadd_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmadd_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmadd_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmadd_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmadd_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmadd_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmadd_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmadd_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmadd_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmadd_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmadd_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmadd_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmadd_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmadd_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmadd_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmadd_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmadd_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmadd_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmadd_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmadd_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmadd_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmadd_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmadd_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsub_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsub_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsub_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsub_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsub_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsub_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsub_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsub_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsub_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsub_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsub_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsub_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsub_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsub_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsub_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsub_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsub_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsub_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsub_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsub_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsub_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsub_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsub_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsub_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tu (vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tu (vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tu (vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tu (vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tu (vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tu (vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tu (vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tu (vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tu (vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tu (vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tu (vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tu (vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tu (vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tu (vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tu (vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tu (vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tu (vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tu (vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tu (vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tu (vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tu (vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tu (vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tu (vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tu (vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tu (vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tu (vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tu (vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tu (vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tu (vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tu (vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmacc_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmacc_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmacc_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmacc_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmacc_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmacc_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmacc_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmacc_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmacc_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmacc_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmacc_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmacc_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmacc_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmacc_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmacc_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmacc_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmacc_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmacc_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmacc_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmacc_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmacc_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmacc_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmacc_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmacc_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmacc_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmacc_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsac_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsac_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsac_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsac_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsac_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsac_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsac_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsac_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsac_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsac_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsac_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsac_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsac_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsac_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsac_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsac_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsac_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsac_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsac_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsac_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsac_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsac_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsac_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsac_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmadd_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmadd_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmadd_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmadd_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmadd_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmadd_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmadd_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmadd_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmadd_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmadd_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmadd_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmadd_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmadd_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmadd_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmadd_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmadd_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmadd_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmadd_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmadd_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmadd_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmadd_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmadd_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmadd_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmadd_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsub_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsub_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsub_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsub_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsub_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsub_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsub_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsub_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsub_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsub_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsub_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsub_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsub_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsub_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsub_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsub_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsub_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsub_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsub_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsub_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsub_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsub_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsub_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsub_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tum (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tum (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tum (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tum (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tum (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tum (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tum (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tum (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tum (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tum (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmacc_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmacc_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmacc_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmacc_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmacc_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmacc_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmacc_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmacc_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmacc_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmacc_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmacc_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmacc_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmacc_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmacc_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmacc_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmacc_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmacc_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsac_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsac_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsac_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsac_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsac_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsac_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsac_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsac_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsac_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsac_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsac_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsac_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsac_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsac_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsac_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsac_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsac_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmadd_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmadd_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmadd_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmadd_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmadd_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmadd_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmadd_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmadd_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmadd_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmadd_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmadd_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmadd_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmadd_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmadd_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmadd_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmadd_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmadd_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsub_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsub_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsub_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsub_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsub_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsub_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsub_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsub_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsub_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsub_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tumu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsub_tumu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tumu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsub_tumu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsub_tumu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsub_tumu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsub_tumu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsub_tumu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsub_tumu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmacc_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmacc_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmacc_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmacc_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmacc_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmacc_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmacc_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmacc_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmacc_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmacc_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmacc_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmacc_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmacc_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmacc_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmacc_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmacc_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmacc_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmacc_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmacc_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmacc_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmacc_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmacc_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmacc_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmacc_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmacc_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmacc_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmacc_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmacc_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmacc_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmacc_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmacc_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmacc_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmacc_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmacc_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmacc_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmacc_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmacc_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmacc_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmacc_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmacc_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsac_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsac_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsac_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsac_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsac_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsac_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsac_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsac_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsac_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsac_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsac_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsac_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsac_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsac_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsac_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsac_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsac_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsac_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsac_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsac_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsac_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsac_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsac_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsac_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsac_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsac_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsac_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsac_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsac_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsac_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsac_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsac_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsac_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsac_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsac_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsac_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsac_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsac_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsac_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsac_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmadd_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmadd_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmadd_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmadd_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmadd_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmadd_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmadd_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmadd_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmadd_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmadd_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmadd_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmadd_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmadd_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmadd_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmadd_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmadd_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmadd_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmadd_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmadd_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmadd_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmadd_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmadd_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmadd_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmadd_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmadd_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmadd_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmadd_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmadd_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmadd_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmadd_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmadd_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmadd_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmadd_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmadd_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmadd_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmadd_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmadd_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmadd_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmadd_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmadd_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsub_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfmsub_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsub_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfmsub_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsub_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfmsub_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsub_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfmsub_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsub_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfmsub_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsub_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfmsub_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsub_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfmsub_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsub_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfmsub_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsub_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfmsub_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsub_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfmsub_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsub_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfmsub_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsub_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfmsub_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsub_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfmsub_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsub_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfmsub_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsub_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfmsub_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat16mf4_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat16mf4_t vd, float16_t rs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat16mf2_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat16mf2_t vd, float16_t rs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat16m1_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat16m1_t vd, float16_t rs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat16m2_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat16m2_t vd, float16_t rs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsub_mu (vbool4_t mask, vfloat16m4_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfnmsub_mu (vbool4_t mask, vfloat16m4_t vd, float16_t rs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsub_mu (vbool2_t mask, vfloat16m8_t vd, vfloat16m8_t vs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfnmsub_mu (vbool2_t mask, vfloat16m8_t vd, float16_t rs1, vfloat16m8_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat32mf2_t vd, float32_t rs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat32m1_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat32m1_t vd, float32_t rs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat32m2_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat32m2_t vd, float32_t rs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat32m4_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat32m4_t vd, float32_t rs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsub_mu (vbool4_t mask, vfloat32m8_t vd, vfloat32m8_t vs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfnmsub_mu (vbool4_t mask, vfloat32m8_t vd, float32_t rs1, vfloat32m8_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat64m1_t vd, vfloat64m1_t vs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfnmsub_mu (vbool64_t mask, vfloat64m1_t vd, float64_t rs1, vfloat64m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat64m2_t vd, vfloat64m2_t vs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfnmsub_mu (vbool32_t mask, vfloat64m2_t vd, float64_t rs1, vfloat64m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat64m4_t vd, vfloat64m4_t vs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfnmsub_mu (vbool16_t mask, vfloat64m4_t vd, float64_t rs1, vfloat64m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat64m8_t vd, vfloat64m8_t vs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfnmsub_mu (vbool8_t mask, vfloat64m8_t vd, float64_t rs1, vfloat64m8_t vs2, unsigned int frm, size_t vl);
```

[[policy-variant-overloadedvector-widening-floating-point-fused-multiply-add]]
=== Vector Widening Floating-Point Fused Multiply-Add Intrinsics

``` C
vfloat32mf2_t __riscv_vfwmacc_tu (vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_tu (vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tu (vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tu (vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tu (vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tu (vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tu (vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tu (vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tu (vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tu (vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tu (vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tu (vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tu (vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tu (vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tu (vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tu (vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tu (vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tu (vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tu (vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tu (vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tu (vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tu (vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tu (vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tu (vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tu (vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tu (vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tu (vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tu (vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tu (vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tu (vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tu (vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tu (vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tu (vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tu (vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tu (vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tu (vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tu (vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tu (vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tu (vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tu (vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tu (vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tu (vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tu (vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tu (vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tu (vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tu (vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tu (vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tu (vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tu (vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tu (vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tu (vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tu (vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tu (vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tu (vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tu (vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tu (vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tu (vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tu (vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tu (vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tu (vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tu (vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tu (vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tu (vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tu (vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tu (vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tu (vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tu (vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tu (vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tu (vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tu (vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tu (vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tu (vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmacc_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_tum (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tum (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tum (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tum (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tum (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tum (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tum (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tum (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tum (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tum (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tum (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tum (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tum (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tum (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tum (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tum (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tum (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tum (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tum (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tum (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tum (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tum (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tum (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tum (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tum (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tum (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tum (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tum (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tum (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tum (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tum (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tum (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tum (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tum (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tum (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tum (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tum (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tum (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tum (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tum (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tum (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tum (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tum (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tum (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tum (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tum (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tum (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tum (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tum (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tum (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tum (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tum (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tum (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tum (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tum (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tum (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tum (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tum (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tum (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tum (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tum (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tum (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tum (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tum (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tum (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tum (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tum (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tum (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tumu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tumu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tumu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tumu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tumu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tumu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tumu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tumu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tumu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tumu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tumu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tumu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tumu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tumu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tumu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tumu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tumu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tumu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tumu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tumu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tumu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tumu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tumu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tumu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tumu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tumu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tumu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tumu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tumu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tumu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tumu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tumu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmacc_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_mu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmacc_mu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmacc_mu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmacc_mu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmacc_mu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmacc_mu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmacc_mu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmacc_mu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmacc_mu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmacc_mu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmacc_mu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmacc_mu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmacc_mu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_mu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmacc_mu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_mu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmacc_mu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_mu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_mu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_mu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_mu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_mu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_mu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_mu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_mu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_mu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_mu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_mu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_mu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_mu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_mu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_mu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_mu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_mu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_mu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmsac_mu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwmsac_mu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmsac_mu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwmsac_mu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmsac_mu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwmsac_mu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmsac_mu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwmsac_mu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmsac_mu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwmsac_mu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmsac_mu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwmsac_mu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_mu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwmsac_mu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_mu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwmsac_mu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_mu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_mu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_mu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_mu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_mu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_mu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_mu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_mu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_mu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_mu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_mu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_mu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_mu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_mu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_mu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_mu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_mu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_tu (vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_tu (vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tu (vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tu (vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tu (vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tu (vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tu (vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tu (vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tu (vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tu (vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tu (vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tu (vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tu (vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tu (vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tu (vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tu (vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tu (vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tu (vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tu (vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tu (vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tu (vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tu (vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tu (vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tu (vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tu (vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tu (vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tu (vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tu (vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tu (vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tu (vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tu (vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tu (vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tu (vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tu (vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tu (vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tu (vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tu (vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tu (vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tu (vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tu (vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tu (vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tu (vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tu (vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tu (vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tu (vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tu (vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tu (vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tu (vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tu (vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tu (vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tu (vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tu (vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tu (vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tu (vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tu (vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tu (vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tu (vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tu (vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tu (vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tu (vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tu (vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tu (vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tu (vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tu (vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tu (vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tu (vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tu (vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tu (vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tu (vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tu (vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tu (vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tu (vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmacc_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_tum (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tum (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tum (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tum (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tum (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tum (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tum (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tum (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tum (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tum (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tum (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tum (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tum (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tum (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tum (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tum (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tum (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tum (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tum (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tum (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tum (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tum (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tum (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tum (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tum (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tum (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tum (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tum (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tum (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tum (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tum (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tum (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tum (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tum (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tum (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tum (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tum (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tum (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tum (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tum (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tum (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tum (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tum (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tum (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tum (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tum (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tum (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tum (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tum (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tum (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tum (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tum (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tum (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tum (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tum (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tum (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tum (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tum (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tum (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tum (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tum (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tum (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tum (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tum (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tum (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tum (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tum (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tum (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tum (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmacc_tumu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmacc_tumu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmacc_tumu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmacc_tumu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmacc_tumu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmacc_tumu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmacc_tumu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmacc_tumu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_tumu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_tumu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_tumu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_tumu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_tumu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_tumu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_tumu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_tumu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_tumu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmsac_tumu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmsac_tumu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmsac_tumu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmsac_tumu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmsac_tumu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmsac_tumu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmsac_tumu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmsac_tumu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_tumu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tumu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_tumu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tumu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_tumu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tumu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_tumu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tumu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_tumu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tumu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_tumu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tumu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_tumu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tumu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_tumu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tumu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_tumu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
// masked functions
vfloat32mf2_t __riscv_vfwmacc_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmacc_mu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmacc_mu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmacc_mu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmacc_mu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmacc_mu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmacc_mu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmacc_mu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmacc_mu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmacc_mu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmacc_mu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmacc_mu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmacc_mu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmacc_mu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmacc_mu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmacc_mu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmacc_mu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmacc_mu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmacc_mu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_mu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmacc_mu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_mu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmacc_mu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_mu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmacc_mu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_mu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmacc_mu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_mu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmacc_mu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_mu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmacc_mu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_mu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmacc_mu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_mu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmacc_mu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwmsac_mu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmsac_mu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwmsac_mu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmsac_mu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwmsac_mu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmsac_mu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwmsac_mu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmsac_mu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwmsac_mu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmsac_mu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwmsac_mu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmsac_mu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwmsac_mu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmsac_mu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwmsac_mu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmsac_mu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwmsac_mu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_mu (vbool64_t mask, vfloat32mf2_t vd, vfloat16mf4_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfwnmsac_mu (vbool64_t mask, vfloat32mf2_t vd, float16_t vs1, vfloat16mf4_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_mu (vbool32_t mask, vfloat32m1_t vd, vfloat16mf2_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwnmsac_mu (vbool32_t mask, vfloat32m1_t vd, float16_t vs1, vfloat16mf2_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_mu (vbool16_t mask, vfloat32m2_t vd, vfloat16m1_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfwnmsac_mu (vbool16_t mask, vfloat32m2_t vd, float16_t vs1, vfloat16m1_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_mu (vbool8_t mask, vfloat32m4_t vd, vfloat16m2_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfwnmsac_mu (vbool8_t mask, vfloat32m4_t vd, float16_t vs1, vfloat16m2_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_mu (vbool4_t mask, vfloat32m8_t vd, vfloat16m4_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfwnmsac_mu (vbool4_t mask, vfloat32m8_t vd, float16_t vs1, vfloat16m4_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_mu (vbool64_t mask, vfloat64m1_t vd, vfloat32mf2_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwnmsac_mu (vbool64_t mask, vfloat64m1_t vd, float32_t vs1, vfloat32mf2_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_mu (vbool32_t mask, vfloat64m2_t vd, vfloat32m1_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfwnmsac_mu (vbool32_t mask, vfloat64m2_t vd, float32_t vs1, vfloat32m1_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_mu (vbool16_t mask, vfloat64m4_t vd, vfloat32m2_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfwnmsac_mu (vbool16_t mask, vfloat64m4_t vd, float32_t vs1, vfloat32m2_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_mu (vbool8_t mask, vfloat64m8_t vd, vfloat32m4_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfwnmsac_mu (vbool8_t mask, vfloat64m8_t vd, float32_t vs1, vfloat32m4_t vs2, unsigned int frm, size_t vl);
```

[[policy-variant-overloadedvector-floating-point-square-root]]
=== Vector Floating-Point Square-Root Intrinsics

``` C
vfloat16mf4_t __riscv_vfsqrt_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfsqrt_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfsqrt_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfsqrt_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfsqrt_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfsqrt_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfsqrt_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfsqrt_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfsqrt_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfsqrt_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfsqrt_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfsqrt_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfsqrt_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfsqrt_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsqrt_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfsqrt_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfsqrt_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfsqrt_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfsqrt_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfsqrt_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfsqrt_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfsqrt_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfsqrt_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfsqrt_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfsqrt_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfsqrt_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfsqrt_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfsqrt_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsqrt_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfsqrt_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfsqrt_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfsqrt_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfsqrt_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfsqrt_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfsqrt_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfsqrt_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfsqrt_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfsqrt_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfsqrt_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfsqrt_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfsqrt_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfsqrt_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsqrt_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfsqrt_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfsqrt_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfsqrt_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfsqrt_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfsqrt_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfsqrt_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfsqrt_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfsqrt_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfsqrt_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfsqrt_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfsqrt_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfsqrt_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfsqrt_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
vfloat16mf4_t __riscv_vfsqrt_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsqrt_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsqrt_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsqrt_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsqrt_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsqrt_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsqrt_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsqrt_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsqrt_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsqrt_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsqrt_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsqrt_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsqrt_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsqrt_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsqrt_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsqrt_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsqrt_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsqrt_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsqrt_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsqrt_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsqrt_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsqrt_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsqrt_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsqrt_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsqrt_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsqrt_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsqrt_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsqrt_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsqrt_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsqrt_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsqrt_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsqrt_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsqrt_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsqrt_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsqrt_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsqrt_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsqrt_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsqrt_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsqrt_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsqrt_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsqrt_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsqrt_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsqrt_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfsqrt_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfsqrt_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfsqrt_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfsqrt_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfsqrt_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfsqrt_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfsqrt_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfsqrt_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfsqrt_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfsqrt_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfsqrt_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfsqrt_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfsqrt_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfsqrt_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, unsigned int frm, size_t vl);
```

[[policy-variant-overloadedvector-floating-point-reciprocal-square-root-estimate]]
=== Vector Floating-Point Reciprocal Square-Root Estimate Intrinsics

``` C
vfloat16mf4_t __riscv_vfrsqrt7_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfrsqrt7_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfrsqrt7_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfrsqrt7_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfrsqrt7_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfrsqrt7_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfrsqrt7_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfrsqrt7_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfrsqrt7_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfrsqrt7_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfrsqrt7_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfrsqrt7_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfrsqrt7_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfrsqrt7_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfrsqrt7_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrsqrt7_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfrsqrt7_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfrsqrt7_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfrsqrt7_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfrsqrt7_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfrsqrt7_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfrsqrt7_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfrsqrt7_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfrsqrt7_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfrsqrt7_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfrsqrt7_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfrsqrt7_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfrsqrt7_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfrsqrt7_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfrsqrt7_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrsqrt7_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfrsqrt7_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfrsqrt7_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfrsqrt7_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfrsqrt7_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfrsqrt7_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfrsqrt7_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfrsqrt7_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfrsqrt7_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfrsqrt7_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfrsqrt7_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfrsqrt7_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfrsqrt7_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfrsqrt7_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfrsqrt7_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrsqrt7_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfrsqrt7_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfrsqrt7_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfrsqrt7_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfrsqrt7_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfrsqrt7_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfrsqrt7_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfrsqrt7_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfrsqrt7_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfrsqrt7_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfrsqrt7_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfrsqrt7_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfrsqrt7_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfrsqrt7_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfrsqrt7_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
```

[[policy-variant-overloaded#1410-vector-floating-point-reciprocal-estimate]]
=== Vector Floating-Point Reciprocal Estimate Intrinsics

``` C
vfloat16mf4_t __riscv_vfrec7_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfrec7_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfrec7_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfrec7_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfrec7_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfrec7_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfrec7_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfrec7_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfrec7_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfrec7_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfrec7_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfrec7_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfrec7_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfrec7_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfrec7_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrec7_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfrec7_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfrec7_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfrec7_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfrec7_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfrec7_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfrec7_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfrec7_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfrec7_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfrec7_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfrec7_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfrec7_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfrec7_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfrec7_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfrec7_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrec7_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfrec7_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfrec7_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfrec7_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfrec7_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfrec7_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfrec7_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfrec7_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfrec7_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfrec7_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfrec7_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfrec7_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfrec7_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfrec7_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfrec7_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrec7_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfrec7_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfrec7_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfrec7_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfrec7_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfrec7_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfrec7_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfrec7_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfrec7_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfrec7_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfrec7_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfrec7_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfrec7_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfrec7_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfrec7_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
vfloat16mf4_t __riscv_vfrec7_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrec7_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrec7_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrec7_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrec7_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrec7_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrec7_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrec7_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrec7_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrec7_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrec7_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrec7_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrec7_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrec7_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrec7_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrec7_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrec7_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrec7_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrec7_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrec7_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrec7_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrec7_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrec7_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrec7_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrec7_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrec7_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrec7_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrec7_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrec7_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrec7_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrec7_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrec7_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrec7_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrec7_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrec7_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrec7_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrec7_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrec7_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrec7_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrec7_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrec7_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrec7_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrec7_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrec7_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrec7_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, unsigned int frm, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfrec7_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfrec7_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfrec7_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfrec7_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfrec7_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfrec7_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfrec7_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfrec7_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfrec7_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfrec7_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfrec7_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfrec7_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfrec7_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfrec7_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfrec7_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, unsigned int frm, size_t vl);
```

[[policy-variant-overloadedvector-floating-point-minmax]]
=== Vector Floating-Point MIN/MAX Intrinsics

``` C
vfloat16mf4_t __riscv_vfmin_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmin_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmin_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmin_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmin_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmin_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmin_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmin_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmin_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmin_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmin_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmin_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmin_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmin_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmin_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmin_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmin_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmin_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmin_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmin_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmin_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmin_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmin_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmin_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmin_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmin_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmin_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmin_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmin_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmin_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmax_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmax_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmax_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmax_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmax_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmax_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmax_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmax_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmax_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmax_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmax_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmax_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmax_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmax_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmax_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmax_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmax_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmax_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmax_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmax_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmax_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmax_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmax_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmax_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmax_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmax_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmax_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmax_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmax_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmax_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmin_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmin_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmin_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmin_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmin_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmin_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmin_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmin_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmin_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmin_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmin_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmin_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmin_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmin_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmin_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmin_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmin_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmin_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmin_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmin_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmin_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmin_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmin_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmin_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmin_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmin_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmin_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmin_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmin_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmin_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmax_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmax_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmax_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmax_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmax_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmax_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmax_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmax_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmax_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmax_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmax_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmax_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmax_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmax_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmax_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmax_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmax_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmax_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmax_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmax_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmax_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmax_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmax_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmax_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmax_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmax_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmax_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmax_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmax_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmax_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmin_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmin_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmin_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmin_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmin_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmin_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmin_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmin_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmin_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmin_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmin_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmin_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmin_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmin_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmin_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmin_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmin_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmin_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmin_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmin_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmin_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmin_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmin_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmin_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmin_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmin_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmin_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmin_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmin_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmin_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmax_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmax_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmax_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmax_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmax_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmax_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmax_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmax_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmax_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmax_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmax_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmax_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmax_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmax_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmax_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmax_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmax_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmax_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmax_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmax_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmax_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmax_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmax_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmax_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmax_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmax_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmax_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmax_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmax_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmax_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfmin_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmin_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmin_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmin_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmin_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmin_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmin_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmin_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmin_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmin_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmin_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmin_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmin_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmin_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmin_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmin_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmin_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmin_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmin_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmin_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmin_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmin_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmin_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmin_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmin_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmin_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmin_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmin_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmin_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmin_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmax_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfmax_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmax_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfmax_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfmax_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfmax_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfmax_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfmax_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfmax_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfmax_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfmax_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfmax_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmax_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfmax_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfmax_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfmax_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfmax_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfmax_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfmax_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfmax_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfmax_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfmax_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfmax_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfmax_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfmax_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfmax_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfmax_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfmax_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfmax_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfmax_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
```

[[policy-variant-overloadedvector-floating-point-sign-injection]]
=== Vector Floating-Point Sign-Injection Intrinsics

``` C
vfloat16mf4_t __riscv_vfsgnj_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnj_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnj_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnj_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnj_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnj_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnj_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnj_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnj_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnj_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnj_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnj_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnj_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnj_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnj_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnj_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnj_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnj_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnj_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnj_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnj_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnj_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnj_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnj_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnj_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnj_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnj_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnj_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjn_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjn_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjn_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjn_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjn_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjn_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjn_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjn_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjn_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjn_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjx_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjx_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjx_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjx_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjx_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjx_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjx_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjx_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjx_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjx_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsgnj_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnj_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnj_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnj_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnj_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnj_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnj_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnj_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnj_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnj_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnj_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnj_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnj_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnj_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnj_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnj_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnj_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnj_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnj_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnj_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnj_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnj_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnj_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnj_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnj_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnj_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnj_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnj_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjn_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjn_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjn_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjn_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjn_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjn_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjn_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjn_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjn_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjn_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjx_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjx_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjx_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjx_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjx_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjx_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjx_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjx_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjx_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjx_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsgnj_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnj_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnj_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnj_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnj_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnj_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnj_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnj_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnj_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnj_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnj_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnj_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnj_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnj_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnj_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnj_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnj_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnj_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnj_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnj_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnj_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnj_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnj_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnj_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnj_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnj_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnj_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnj_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjn_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjn_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjn_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjn_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjn_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjn_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjn_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjn_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjn_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjn_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjx_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjx_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjx_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjx_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjx_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjx_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjx_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjx_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjx_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjx_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfsgnj_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnj_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnj_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnj_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnj_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnj_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnj_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnj_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnj_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnj_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnj_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnj_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnj_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnj_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnj_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnj_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnj_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnj_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnj_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnj_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnj_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnj_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnj_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnj_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnj_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnj_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnj_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnj_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnj_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjn_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjn_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjn_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjn_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjn_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjn_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjn_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjn_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjn_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjn_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjn_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjn_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjn_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjn_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjn_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjn_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjn_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjn_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjn_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjn_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vfloat16mf4_t __riscv_vfsgnjx_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vfloat16mf2_t __riscv_vfsgnjx_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjx_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vfloat16m1_t __riscv_vfsgnjx_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjx_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vfloat16m2_t __riscv_vfsgnjx_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjx_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vfloat16m4_t __riscv_vfsgnjx_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjx_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vfloat16m8_t __riscv_vfsgnjx_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vfloat32mf2_t __riscv_vfsgnjx_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjx_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vfloat32m1_t __riscv_vfsgnjx_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vfloat32m2_t __riscv_vfsgnjx_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vfloat32m4_t __riscv_vfsgnjx_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vfloat32m8_t __riscv_vfsgnjx_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vfloat64m1_t __riscv_vfsgnjx_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vfloat64m2_t __riscv_vfsgnjx_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vfloat64m4_t __riscv_vfsgnjx_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vfloat64m8_t __riscv_vfsgnjx_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
```

[[policy-variant-overloadedvector-floating-point-absolute-value]]
=== Vector Floating-Point Absolute Value Intrinsics

``` C
vfloat16mf4_t __riscv_vfabs_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfabs_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfabs_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfabs_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfabs_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfabs_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfabs_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfabs_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfabs_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfabs_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfabs_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfabs_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfabs_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfabs_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfabs_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfabs_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfabs_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfabs_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfabs_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfabs_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfabs_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfabs_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfabs_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfabs_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfabs_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfabs_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfabs_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfabs_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfabs_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfabs_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfabs_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfabs_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfabs_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfabs_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfabs_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfabs_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfabs_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfabs_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfabs_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfabs_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfabs_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfabs_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfabs_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfabs_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfabs_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfabs_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vfloat16mf2_t __riscv_vfabs_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vfloat16m1_t __riscv_vfabs_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vfloat16m2_t __riscv_vfabs_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vfloat16m4_t __riscv_vfabs_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vfloat16m8_t __riscv_vfabs_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vfloat32mf2_t __riscv_vfabs_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vfloat32m1_t __riscv_vfabs_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vfloat32m2_t __riscv_vfabs_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vfloat32m4_t __riscv_vfabs_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vfloat32m8_t __riscv_vfabs_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vfloat64m1_t __riscv_vfabs_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vfloat64m2_t __riscv_vfabs_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vfloat64m4_t __riscv_vfabs_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vfloat64m8_t __riscv_vfabs_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
```

[[policy-variant-overloadedvector-floating-point-compare]]
=== Vector Floating-Point Compare Intrinsics

``` C
// masked functions
vbool64_t __riscv_vmfeq_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vbool64_t __riscv_vmfeq_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vbool32_t __riscv_vmfeq_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vbool32_t __riscv_vmfeq_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vbool16_t __riscv_vmfeq_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vbool16_t __riscv_vmfeq_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vbool8_t __riscv_vmfeq_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vbool8_t __riscv_vmfeq_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vbool4_t __riscv_vmfeq_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vbool4_t __riscv_vmfeq_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vbool2_t __riscv_vmfeq_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vbool2_t __riscv_vmfeq_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vbool64_t __riscv_vmfeq_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vbool64_t __riscv_vmfeq_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vbool32_t __riscv_vmfeq_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vbool32_t __riscv_vmfeq_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vbool16_t __riscv_vmfeq_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vbool16_t __riscv_vmfeq_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vbool8_t __riscv_vmfeq_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vbool8_t __riscv_vmfeq_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vbool4_t __riscv_vmfeq_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vbool4_t __riscv_vmfeq_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vbool64_t __riscv_vmfeq_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vbool64_t __riscv_vmfeq_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vbool32_t __riscv_vmfeq_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vbool32_t __riscv_vmfeq_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vbool16_t __riscv_vmfeq_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vbool16_t __riscv_vmfeq_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vbool8_t __riscv_vmfeq_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vbool8_t __riscv_vmfeq_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vbool64_t __riscv_vmfne_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vbool64_t __riscv_vmfne_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vbool32_t __riscv_vmfne_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vbool32_t __riscv_vmfne_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vbool16_t __riscv_vmfne_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vbool16_t __riscv_vmfne_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vbool8_t __riscv_vmfne_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vbool8_t __riscv_vmfne_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vbool4_t __riscv_vmfne_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vbool4_t __riscv_vmfne_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vbool2_t __riscv_vmfne_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vbool2_t __riscv_vmfne_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vbool64_t __riscv_vmfne_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vbool64_t __riscv_vmfne_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vbool32_t __riscv_vmfne_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vbool32_t __riscv_vmfne_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vbool16_t __riscv_vmfne_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vbool16_t __riscv_vmfne_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vbool8_t __riscv_vmfne_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vbool8_t __riscv_vmfne_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vbool4_t __riscv_vmfne_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vbool4_t __riscv_vmfne_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vbool64_t __riscv_vmfne_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vbool64_t __riscv_vmfne_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vbool32_t __riscv_vmfne_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vbool32_t __riscv_vmfne_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vbool16_t __riscv_vmfne_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vbool16_t __riscv_vmfne_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vbool8_t __riscv_vmfne_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vbool8_t __riscv_vmfne_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vbool64_t __riscv_vmflt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vbool64_t __riscv_vmflt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vbool32_t __riscv_vmflt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vbool32_t __riscv_vmflt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vbool16_t __riscv_vmflt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vbool16_t __riscv_vmflt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vbool8_t __riscv_vmflt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vbool8_t __riscv_vmflt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vbool4_t __riscv_vmflt_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vbool4_t __riscv_vmflt_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vbool2_t __riscv_vmflt_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vbool2_t __riscv_vmflt_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vbool64_t __riscv_vmflt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vbool64_t __riscv_vmflt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vbool32_t __riscv_vmflt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vbool32_t __riscv_vmflt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vbool16_t __riscv_vmflt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vbool16_t __riscv_vmflt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vbool8_t __riscv_vmflt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vbool8_t __riscv_vmflt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vbool4_t __riscv_vmflt_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vbool4_t __riscv_vmflt_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vbool64_t __riscv_vmflt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vbool64_t __riscv_vmflt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vbool32_t __riscv_vmflt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vbool32_t __riscv_vmflt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vbool16_t __riscv_vmflt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vbool16_t __riscv_vmflt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vbool8_t __riscv_vmflt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vbool8_t __riscv_vmflt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vbool64_t __riscv_vmfle_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vbool64_t __riscv_vmfle_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vbool32_t __riscv_vmfle_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vbool32_t __riscv_vmfle_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vbool16_t __riscv_vmfle_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vbool16_t __riscv_vmfle_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vbool8_t __riscv_vmfle_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vbool8_t __riscv_vmfle_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vbool4_t __riscv_vmfle_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vbool4_t __riscv_vmfle_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vbool2_t __riscv_vmfle_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vbool2_t __riscv_vmfle_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vbool64_t __riscv_vmfle_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vbool64_t __riscv_vmfle_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vbool32_t __riscv_vmfle_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vbool32_t __riscv_vmfle_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vbool16_t __riscv_vmfle_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vbool16_t __riscv_vmfle_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vbool8_t __riscv_vmfle_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vbool8_t __riscv_vmfle_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vbool4_t __riscv_vmfle_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vbool4_t __riscv_vmfle_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vbool64_t __riscv_vmfle_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vbool64_t __riscv_vmfle_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vbool32_t __riscv_vmfle_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vbool32_t __riscv_vmfle_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vbool16_t __riscv_vmfle_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vbool16_t __riscv_vmfle_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vbool8_t __riscv_vmfle_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vbool8_t __riscv_vmfle_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vbool64_t __riscv_vmfgt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vbool64_t __riscv_vmfgt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vbool32_t __riscv_vmfgt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vbool32_t __riscv_vmfgt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vbool16_t __riscv_vmfgt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vbool16_t __riscv_vmfgt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vbool8_t __riscv_vmfgt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vbool8_t __riscv_vmfgt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vbool4_t __riscv_vmfgt_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vbool4_t __riscv_vmfgt_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vbool2_t __riscv_vmfgt_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vbool2_t __riscv_vmfgt_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vbool64_t __riscv_vmfgt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vbool64_t __riscv_vmfgt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vbool32_t __riscv_vmfgt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vbool32_t __riscv_vmfgt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vbool16_t __riscv_vmfgt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vbool16_t __riscv_vmfgt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vbool8_t __riscv_vmfgt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vbool8_t __riscv_vmfgt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vbool4_t __riscv_vmfgt_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vbool4_t __riscv_vmfgt_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vbool64_t __riscv_vmfgt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vbool64_t __riscv_vmfgt_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vbool32_t __riscv_vmfgt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vbool32_t __riscv_vmfgt_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vbool16_t __riscv_vmfgt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vbool16_t __riscv_vmfgt_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vbool8_t __riscv_vmfgt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vbool8_t __riscv_vmfgt_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
vbool64_t __riscv_vmfge_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, size_t vl);
vbool64_t __riscv_vmfge_mu (vbool64_t mask, vbool64_t maskedoff, vfloat16mf4_t op1, float16_t op2, size_t vl);
vbool32_t __riscv_vmfge_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, size_t vl);
vbool32_t __riscv_vmfge_mu (vbool32_t mask, vbool32_t maskedoff, vfloat16mf2_t op1, float16_t op2, size_t vl);
vbool16_t __riscv_vmfge_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, size_t vl);
vbool16_t __riscv_vmfge_mu (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2, size_t vl);
vbool8_t __riscv_vmfge_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, size_t vl);
vbool8_t __riscv_vmfge_mu (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2, size_t vl);
vbool4_t __riscv_vmfge_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, size_t vl);
vbool4_t __riscv_vmfge_mu (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2, size_t vl);
vbool2_t __riscv_vmfge_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, size_t vl);
vbool2_t __riscv_vmfge_mu (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2, size_t vl);
vbool64_t __riscv_vmfge_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t vl);
vbool64_t __riscv_vmfge_mu (vbool64_t mask, vbool64_t maskedoff, vfloat32mf2_t op1, float32_t op2, size_t vl);
vbool32_t __riscv_vmfge_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, size_t vl);
vbool32_t __riscv_vmfge_mu (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2, size_t vl);
vbool16_t __riscv_vmfge_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, size_t vl);
vbool16_t __riscv_vmfge_mu (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2, size_t vl);
vbool8_t __riscv_vmfge_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, size_t vl);
vbool8_t __riscv_vmfge_mu (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2, size_t vl);
vbool4_t __riscv_vmfge_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, size_t vl);
vbool4_t __riscv_vmfge_mu (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2, size_t vl);
vbool64_t __riscv_vmfge_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, size_t vl);
vbool64_t __riscv_vmfge_mu (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2, size_t vl);
vbool32_t __riscv_vmfge_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, size_t vl);
vbool32_t __riscv_vmfge_mu (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2, size_t vl);
vbool16_t __riscv_vmfge_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, size_t vl);
vbool16_t __riscv_vmfge_mu (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2, size_t vl);
vbool8_t __riscv_vmfge_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, size_t vl);
vbool8_t __riscv_vmfge_mu (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2, size_t vl);
```

[[policy-variant-overloadedvector-floating-point-classify]]
=== Vector Floating-Point Classify Intrinsics

``` C
vuint16mf4_t __riscv_vfclass_tu (vuint16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vuint16mf2_t __riscv_vfclass_tu (vuint16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vuint16m1_t __riscv_vfclass_tu (vuint16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vuint16m2_t __riscv_vfclass_tu (vuint16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vuint16m4_t __riscv_vfclass_tu (vuint16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vuint16m8_t __riscv_vfclass_tu (vuint16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vuint32mf2_t __riscv_vfclass_tu (vuint32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vuint32m1_t __riscv_vfclass_tu (vuint32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vuint32m2_t __riscv_vfclass_tu (vuint32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vuint32m4_t __riscv_vfclass_tu (vuint32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vuint32m8_t __riscv_vfclass_tu (vuint32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vuint64m1_t __riscv_vfclass_tu (vuint64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vuint64m2_t __riscv_vfclass_tu (vuint64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vuint64m4_t __riscv_vfclass_tu (vuint64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vuint64m8_t __riscv_vfclass_tu (vuint64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vuint16mf4_t __riscv_vfclass_tum (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vuint16mf2_t __riscv_vfclass_tum (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vuint16m1_t __riscv_vfclass_tum (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vuint16m2_t __riscv_vfclass_tum (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vuint16m4_t __riscv_vfclass_tum (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vuint16m8_t __riscv_vfclass_tum (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vuint32mf2_t __riscv_vfclass_tum (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vuint32m1_t __riscv_vfclass_tum (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vuint32m2_t __riscv_vfclass_tum (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vuint32m4_t __riscv_vfclass_tum (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vuint32m8_t __riscv_vfclass_tum (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vuint64m1_t __riscv_vfclass_tum (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vuint64m2_t __riscv_vfclass_tum (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vuint64m4_t __riscv_vfclass_tum (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vuint64m8_t __riscv_vfclass_tum (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vuint16mf4_t __riscv_vfclass_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vuint16mf2_t __riscv_vfclass_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vuint16m1_t __riscv_vfclass_tumu (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vuint16m2_t __riscv_vfclass_tumu (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vuint16m4_t __riscv_vfclass_tumu (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vuint16m8_t __riscv_vfclass_tumu (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vuint32mf2_t __riscv_vfclass_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vuint32m1_t __riscv_vfclass_tumu (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vuint32m2_t __riscv_vfclass_tumu (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vuint32m4_t __riscv_vfclass_tumu (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vuint32m8_t __riscv_vfclass_tumu (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vuint64m1_t __riscv_vfclass_tumu (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vuint64m2_t __riscv_vfclass_tumu (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vuint64m4_t __riscv_vfclass_tumu (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vuint64m8_t __riscv_vfclass_tumu (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
// masked functions
vuint16mf4_t __riscv_vfclass_mu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t op1, size_t vl);
vuint16mf2_t __riscv_vfclass_mu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t op1, size_t vl);
vuint16m1_t __riscv_vfclass_mu (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t op1, size_t vl);
vuint16m2_t __riscv_vfclass_mu (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t op1, size_t vl);
vuint16m4_t __riscv_vfclass_mu (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t op1, size_t vl);
vuint16m8_t __riscv_vfclass_mu (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t op1, size_t vl);
vuint32mf2_t __riscv_vfclass_mu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t op1, size_t vl);
vuint32m1_t __riscv_vfclass_mu (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t op1, size_t vl);
vuint32m2_t __riscv_vfclass_mu (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t op1, size_t vl);
vuint32m4_t __riscv_vfclass_mu (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t op1, size_t vl);
vuint32m8_t __riscv_vfclass_mu (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t op1, size_t vl);
vuint64m1_t __riscv_vfclass_mu (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t op1, size_t vl);
vuint64m2_t __riscv_vfclass_mu (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t op1, size_t vl);
vuint64m4_t __riscv_vfclass_mu (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t op1, size_t vl);
vuint64m8_t __riscv_vfclass_mu (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t op1, size_t vl);
```

[[policy-variant-overloadedvector-floating-point-merge]]
=== Vector Floating-Point Merge Intrinsics

``` C
vfloat16mf4_t __riscv_vmerge_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vfloat16mf4_t op2, vbool64_t mask, size_t vl);
vfloat16mf4_t __riscv_vfmerge_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, float16_t op2, vbool64_t mask, size_t vl);
vfloat16mf2_t __riscv_vmerge_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vfloat16mf2_t op2, vbool32_t mask, size_t vl);
vfloat16mf2_t __riscv_vfmerge_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, float16_t op2, vbool32_t mask, size_t vl);
vfloat16m1_t __riscv_vmerge_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2, vbool16_t mask, size_t vl);
vfloat16m1_t __riscv_vfmerge_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2, vbool16_t mask, size_t vl);
vfloat16m2_t __riscv_vmerge_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2, vbool8_t mask, size_t vl);
vfloat16m2_t __riscv_vfmerge_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2, vbool8_t mask, size_t vl);
vfloat16m4_t __riscv_vmerge_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2, vbool4_t mask, size_t vl);
vfloat16m4_t __riscv_vfmerge_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2, vbool4_t mask, size_t vl);
vfloat16m8_t __riscv_vmerge_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2, vbool2_t mask, size_t vl);
vfloat16m8_t __riscv_vfmerge_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2, vbool2_t mask, size_t vl);
vfloat32mf2_t __riscv_vmerge_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vfloat32mf2_t op2, vbool64_t mask, size_t vl);
vfloat32mf2_t __riscv_vfmerge_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, float32_t op2, vbool64_t mask, size_t vl);
vfloat32m1_t __riscv_vmerge_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2, vbool32_t mask, size_t vl);
vfloat32m1_t __riscv_vfmerge_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2, vbool32_t mask, size_t vl);
vfloat32m2_t __riscv_vmerge_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2, vbool16_t mask, size_t vl);
vfloat32m2_t __riscv_vfmerge_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2, vbool16_t mask, size_t vl);
vfloat32m4_t __riscv_vmerge_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2, vbool8_t mask, size_t vl);
vfloat32m4_t __riscv_vfmerge_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2, vbool8_t mask, size_t vl);
vfloat32m8_t __riscv_vmerge_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2, vbool4_t mask, size_t vl);
vfloat32m8_t __riscv_vfmerge_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2, vbool4_t mask, size_t vl);
vfloat64m1_t __riscv_vmerge_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2, vbool64_t mask, size_t vl);
vfloat64m1_t __riscv_vfmerge_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2, vbool64_t mask, size_t vl);
vfloat64m2_t __riscv_vmerge_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2, vbool32_t mask, size_t vl);
vfloat64m2_t __riscv_vfmerge_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2, vbool32_t mask, size_t vl);
vfloat64m4_t __riscv_vmerge_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2, vbool16_t mask, size_t vl);
vfloat64m4_t __riscv_vfmerge_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2, vbool16_t mask, size_t vl);
vfloat64m8_t __riscv_vmerge_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2, vbool8_t mask, size_t vl);
vfloat64m8_t __riscv_vfmerge_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2, vbool8_t mask, size_t vl);
```

[[policy-variant-overloadedvector-floating-point-move]]
=== Vector Floating-Point Move Intrinsics

``` C
vfloat16mf4_t __riscv_vmv_v_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vfloat16mf4_t __riscv_vfmv_v_tu (vfloat16mf4_t maskedoff, float16_t src, size_t vl);
vfloat16mf2_t __riscv_vmv_v_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfmv_v_tu (vfloat16mf2_t maskedoff, float16_t src, size_t vl);
vfloat16m1_t __riscv_vmv_v_tu (vfloat16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vfloat16m1_t __riscv_vfmv_v_tu (vfloat16m1_t maskedoff, float16_t src, size_t vl);
vfloat16m2_t __riscv_vmv_v_tu (vfloat16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vfloat16m2_t __riscv_vfmv_v_tu (vfloat16m2_t maskedoff, float16_t src, size_t vl);
vfloat16m4_t __riscv_vmv_v_tu (vfloat16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vfloat16m4_t __riscv_vfmv_v_tu (vfloat16m4_t maskedoff, float16_t src, size_t vl);
vfloat16m8_t __riscv_vmv_v_tu (vfloat16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vfloat16m8_t __riscv_vfmv_v_tu (vfloat16m8_t maskedoff, float16_t src, size_t vl);
vfloat32mf2_t __riscv_vmv_v_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat32mf2_t __riscv_vfmv_v_tu (vfloat32mf2_t maskedoff, float32_t src, size_t vl);
vfloat32m1_t __riscv_vmv_v_tu (vfloat32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat32m1_t __riscv_vfmv_v_tu (vfloat32m1_t maskedoff, float32_t src, size_t vl);
vfloat32m2_t __riscv_vmv_v_tu (vfloat32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat32m2_t __riscv_vfmv_v_tu (vfloat32m2_t maskedoff, float32_t src, size_t vl);
vfloat32m4_t __riscv_vmv_v_tu (vfloat32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat32m4_t __riscv_vfmv_v_tu (vfloat32m4_t maskedoff, float32_t src, size_t vl);
vfloat32m8_t __riscv_vmv_v_tu (vfloat32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat32m8_t __riscv_vfmv_v_tu (vfloat32m8_t maskedoff, float32_t src, size_t vl);
vfloat64m1_t __riscv_vmv_v_tu (vfloat64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vfloat64m1_t __riscv_vfmv_v_tu (vfloat64m1_t maskedoff, float64_t src, size_t vl);
vfloat64m2_t __riscv_vmv_v_tu (vfloat64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vfloat64m2_t __riscv_vfmv_v_tu (vfloat64m2_t maskedoff, float64_t src, size_t vl);
vfloat64m4_t __riscv_vmv_v_tu (vfloat64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vfloat64m4_t __riscv_vfmv_v_tu (vfloat64m4_t maskedoff, float64_t src, size_t vl);
vfloat64m8_t __riscv_vmv_v_tu (vfloat64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat64m8_t __riscv_vfmv_v_tu (vfloat64m8_t maskedoff, float64_t src, size_t vl);
```

[[policy-variant-overloadedsingle-width-floating-pointinteger-type-convert]]
=== Single-Width Floating-Point/Integer Type-Convert Intrinsics

``` C
vint16mf4_t __riscv_vfcvt_x_tu (vint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vint16mf4_t __riscv_vfcvt_rtz_x_tu (vint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vint16mf2_t __riscv_vfcvt_x_tu (vint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vint16mf2_t __riscv_vfcvt_rtz_x_tu (vint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vint16m1_t __riscv_vfcvt_x_tu (vint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vint16m1_t __riscv_vfcvt_rtz_x_tu (vint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vint16m2_t __riscv_vfcvt_x_tu (vint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vint16m2_t __riscv_vfcvt_rtz_x_tu (vint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vint16m4_t __riscv_vfcvt_x_tu (vint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vint16m4_t __riscv_vfcvt_rtz_x_tu (vint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vint16m8_t __riscv_vfcvt_x_tu (vint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vint16m8_t __riscv_vfcvt_rtz_x_tu (vint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_tu (vuint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint16mf4_t __riscv_vfcvt_rtz_xu_tu (vuint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_tu (vuint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint16mf2_t __riscv_vfcvt_rtz_xu_tu (vuint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint16m1_t __riscv_vfcvt_xu_tu (vuint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vuint16m1_t __riscv_vfcvt_rtz_xu_tu (vuint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vuint16m2_t __riscv_vfcvt_xu_tu (vuint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vuint16m2_t __riscv_vfcvt_rtz_xu_tu (vuint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vuint16m4_t __riscv_vfcvt_xu_tu (vuint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vuint16m4_t __riscv_vfcvt_rtz_xu_tu (vuint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vuint16m8_t __riscv_vfcvt_xu_tu (vuint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vuint16m8_t __riscv_vfcvt_rtz_xu_tu (vuint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tu (vfloat16mf4_t maskedoff, vint16mf4_t src, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tu (vfloat16mf2_t maskedoff, vint16mf2_t src, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tu (vfloat16m1_t maskedoff, vint16m1_t src, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tu (vfloat16m2_t maskedoff, vint16m2_t src, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tu (vfloat16m4_t maskedoff, vint16m4_t src, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tu (vfloat16m8_t maskedoff, vint16m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tu (vfloat16mf4_t maskedoff, vuint16mf4_t src, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tu (vfloat16mf2_t maskedoff, vuint16mf2_t src, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tu (vfloat16m1_t maskedoff, vuint16m1_t src, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tu (vfloat16m2_t maskedoff, vuint16m2_t src, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tu (vfloat16m4_t maskedoff, vuint16m4_t src, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tu (vfloat16m8_t maskedoff, vuint16m8_t src, size_t vl);
vint32mf2_t __riscv_vfcvt_x_tu (vint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vint32mf2_t __riscv_vfcvt_rtz_x_tu (vint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vint32m1_t __riscv_vfcvt_x_tu (vint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vint32m1_t __riscv_vfcvt_rtz_x_tu (vint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vint32m2_t __riscv_vfcvt_x_tu (vint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vint32m2_t __riscv_vfcvt_rtz_x_tu (vint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vint32m4_t __riscv_vfcvt_x_tu (vint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vint32m4_t __riscv_vfcvt_rtz_x_tu (vint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vint32m8_t __riscv_vfcvt_x_tu (vint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vint32m8_t __riscv_vfcvt_rtz_x_tu (vint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_tu (vuint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint32mf2_t __riscv_vfcvt_rtz_xu_tu (vuint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint32m1_t __riscv_vfcvt_xu_tu (vuint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vuint32m1_t __riscv_vfcvt_rtz_xu_tu (vuint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vuint32m2_t __riscv_vfcvt_xu_tu (vuint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vuint32m2_t __riscv_vfcvt_rtz_xu_tu (vuint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vuint32m4_t __riscv_vfcvt_xu_tu (vuint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vuint32m4_t __riscv_vfcvt_rtz_xu_tu (vuint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vuint32m8_t __riscv_vfcvt_xu_tu (vuint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vuint32m8_t __riscv_vfcvt_rtz_xu_tu (vuint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tu (vfloat32mf2_t maskedoff, vint32mf2_t src, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tu (vfloat32m1_t maskedoff, vint32m1_t src, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tu (vfloat32m2_t maskedoff, vint32m2_t src, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tu (vfloat32m4_t maskedoff, vint32m4_t src, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tu (vfloat32m8_t maskedoff, vint32m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tu (vfloat32mf2_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tu (vfloat32m1_t maskedoff, vuint32m1_t src, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tu (vfloat32m2_t maskedoff, vuint32m2_t src, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tu (vfloat32m4_t maskedoff, vuint32m4_t src, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tu (vfloat32m8_t maskedoff, vuint32m8_t src, size_t vl);
vint64m1_t __riscv_vfcvt_x_tu (vint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vint64m1_t __riscv_vfcvt_rtz_x_tu (vint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vint64m2_t __riscv_vfcvt_x_tu (vint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vint64m2_t __riscv_vfcvt_rtz_x_tu (vint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vint64m4_t __riscv_vfcvt_x_tu (vint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vint64m4_t __riscv_vfcvt_rtz_x_tu (vint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vint64m8_t __riscv_vfcvt_x_tu (vint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vint64m8_t __riscv_vfcvt_rtz_x_tu (vint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vuint64m1_t __riscv_vfcvt_xu_tu (vuint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vuint64m1_t __riscv_vfcvt_rtz_xu_tu (vuint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vuint64m2_t __riscv_vfcvt_xu_tu (vuint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vuint64m2_t __riscv_vfcvt_rtz_xu_tu (vuint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vuint64m4_t __riscv_vfcvt_xu_tu (vuint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vuint64m4_t __riscv_vfcvt_rtz_xu_tu (vuint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vuint64m8_t __riscv_vfcvt_xu_tu (vuint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vuint64m8_t __riscv_vfcvt_rtz_xu_tu (vuint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tu (vfloat64m1_t maskedoff, vint64m1_t src, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tu (vfloat64m2_t maskedoff, vint64m2_t src, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tu (vfloat64m4_t maskedoff, vint64m4_t src, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tu (vfloat64m8_t maskedoff, vint64m8_t src, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tu (vfloat64m1_t maskedoff, vuint64m1_t src, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tu (vfloat64m2_t maskedoff, vuint64m2_t src, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tu (vfloat64m4_t maskedoff, vuint64m4_t src, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tu (vfloat64m8_t maskedoff, vuint64m8_t src, size_t vl);
// masked functions
vint16mf4_t __riscv_vfcvt_x_tum (vbool64_t mask, vint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vint16mf4_t __riscv_vfcvt_rtz_x_tum (vbool64_t mask, vint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vint16mf2_t __riscv_vfcvt_x_tum (vbool32_t mask, vint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vint16mf2_t __riscv_vfcvt_rtz_x_tum (vbool32_t mask, vint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vint16m1_t __riscv_vfcvt_x_tum (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vint16m1_t __riscv_vfcvt_rtz_x_tum (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vint16m2_t __riscv_vfcvt_x_tum (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vint16m2_t __riscv_vfcvt_rtz_x_tum (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vint16m4_t __riscv_vfcvt_x_tum (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vint16m4_t __riscv_vfcvt_rtz_x_tum (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vint16m8_t __riscv_vfcvt_x_tum (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vint16m8_t __riscv_vfcvt_rtz_x_tum (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint16mf4_t __riscv_vfcvt_rtz_xu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint16mf2_t __riscv_vfcvt_rtz_xu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint16m1_t __riscv_vfcvt_xu_tum (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vuint16m1_t __riscv_vfcvt_rtz_xu_tum (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vuint16m2_t __riscv_vfcvt_xu_tum (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vuint16m2_t __riscv_vfcvt_rtz_xu_tum (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vuint16m4_t __riscv_vfcvt_xu_tum (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vuint16m4_t __riscv_vfcvt_rtz_xu_tum (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vuint16m8_t __riscv_vfcvt_xu_tum (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vuint16m8_t __riscv_vfcvt_rtz_xu_tum (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vint16mf4_t src, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vint16mf2_t src, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vint16m1_t src, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vint16m2_t src, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vint16m4_t src, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tum (vbool2_t mask, vfloat16m8_t maskedoff, vint16m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vuint16mf4_t src, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vuint16mf2_t src, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vuint16m1_t src, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vuint16m2_t src, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vuint16m4_t src, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tum (vbool2_t mask, vfloat16m8_t maskedoff, vuint16m8_t src, size_t vl);
vint32mf2_t __riscv_vfcvt_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vint32mf2_t __riscv_vfcvt_rtz_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vint32m1_t __riscv_vfcvt_x_tum (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vint32m1_t __riscv_vfcvt_rtz_x_tum (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vint32m2_t __riscv_vfcvt_x_tum (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vint32m2_t __riscv_vfcvt_rtz_x_tum (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vint32m4_t __riscv_vfcvt_x_tum (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vint32m4_t __riscv_vfcvt_rtz_x_tum (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vint32m8_t __riscv_vfcvt_x_tum (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vint32m8_t __riscv_vfcvt_rtz_x_tum (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint32mf2_t __riscv_vfcvt_rtz_xu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint32m1_t __riscv_vfcvt_xu_tum (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vuint32m1_t __riscv_vfcvt_rtz_xu_tum (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vuint32m2_t __riscv_vfcvt_xu_tum (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vuint32m2_t __riscv_vfcvt_rtz_xu_tum (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vuint32m4_t __riscv_vfcvt_xu_tum (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vuint32m4_t __riscv_vfcvt_rtz_xu_tum (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vuint32m8_t __riscv_vfcvt_xu_tum (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vuint32m8_t __riscv_vfcvt_rtz_xu_tum (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vint32mf2_t src, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vint32m1_t src, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vint32m2_t src, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vint32m4_t src, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tum (vbool4_t mask, vfloat32m8_t maskedoff, vint32m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vuint32m1_t src, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vuint32m2_t src, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vuint32m4_t src, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tum (vbool4_t mask, vfloat32m8_t maskedoff, vuint32m8_t src, size_t vl);
vint64m1_t __riscv_vfcvt_x_tum (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vint64m1_t __riscv_vfcvt_rtz_x_tum (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vint64m2_t __riscv_vfcvt_x_tum (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vint64m2_t __riscv_vfcvt_rtz_x_tum (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vint64m4_t __riscv_vfcvt_x_tum (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vint64m4_t __riscv_vfcvt_rtz_x_tum (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vint64m8_t __riscv_vfcvt_x_tum (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vint64m8_t __riscv_vfcvt_rtz_x_tum (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vuint64m1_t __riscv_vfcvt_xu_tum (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vuint64m1_t __riscv_vfcvt_rtz_xu_tum (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vuint64m2_t __riscv_vfcvt_xu_tum (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vuint64m2_t __riscv_vfcvt_rtz_xu_tum (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vuint64m4_t __riscv_vfcvt_xu_tum (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vuint64m4_t __riscv_vfcvt_rtz_xu_tum (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vuint64m8_t __riscv_vfcvt_xu_tum (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vuint64m8_t __riscv_vfcvt_rtz_xu_tum (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat64m1_t maskedoff, vint64m1_t src, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat64m2_t maskedoff, vint64m2_t src, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat64m4_t maskedoff, vint64m4_t src, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat64m8_t maskedoff, vint64m8_t src, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat64m1_t maskedoff, vuint64m1_t src, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat64m2_t maskedoff, vuint64m2_t src, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat64m4_t maskedoff, vuint64m4_t src, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat64m8_t maskedoff, vuint64m8_t src, size_t vl);
// masked functions
vint16mf4_t __riscv_vfcvt_x_tumu (vbool64_t mask, vint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vint16mf4_t __riscv_vfcvt_rtz_x_tumu (vbool64_t mask, vint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vint16mf2_t __riscv_vfcvt_x_tumu (vbool32_t mask, vint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vint16mf2_t __riscv_vfcvt_rtz_x_tumu (vbool32_t mask, vint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vint16m1_t __riscv_vfcvt_x_tumu (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vint16m1_t __riscv_vfcvt_rtz_x_tumu (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vint16m2_t __riscv_vfcvt_x_tumu (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vint16m2_t __riscv_vfcvt_rtz_x_tumu (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vint16m4_t __riscv_vfcvt_x_tumu (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vint16m4_t __riscv_vfcvt_rtz_x_tumu (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vint16m8_t __riscv_vfcvt_x_tumu (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vint16m8_t __riscv_vfcvt_rtz_x_tumu (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint16mf4_t __riscv_vfcvt_rtz_xu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint16mf2_t __riscv_vfcvt_rtz_xu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint16m1_t __riscv_vfcvt_xu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vuint16m1_t __riscv_vfcvt_rtz_xu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vuint16m2_t __riscv_vfcvt_xu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vuint16m2_t __riscv_vfcvt_rtz_xu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vuint16m4_t __riscv_vfcvt_xu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vuint16m4_t __riscv_vfcvt_rtz_xu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vuint16m8_t __riscv_vfcvt_xu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vuint16m8_t __riscv_vfcvt_rtz_xu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vint16mf4_t src, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vint16mf2_t src, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vint16m1_t src, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vint16m2_t src, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vint16m4_t src, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vint16m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vuint16mf4_t src, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vuint16mf2_t src, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vuint16m1_t src, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vuint16m2_t src, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vuint16m4_t src, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vuint16m8_t src, size_t vl);
vint32mf2_t __riscv_vfcvt_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vint32mf2_t __riscv_vfcvt_rtz_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vint32m1_t __riscv_vfcvt_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vint32m1_t __riscv_vfcvt_rtz_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vint32m2_t __riscv_vfcvt_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vint32m2_t __riscv_vfcvt_rtz_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vint32m4_t __riscv_vfcvt_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vint32m4_t __riscv_vfcvt_rtz_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vint32m8_t __riscv_vfcvt_x_tumu (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vint32m8_t __riscv_vfcvt_rtz_x_tumu (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint32mf2_t __riscv_vfcvt_rtz_xu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint32m1_t __riscv_vfcvt_xu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vuint32m1_t __riscv_vfcvt_rtz_xu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vuint32m2_t __riscv_vfcvt_xu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vuint32m2_t __riscv_vfcvt_rtz_xu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vuint32m4_t __riscv_vfcvt_xu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vuint32m4_t __riscv_vfcvt_rtz_xu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vuint32m8_t __riscv_vfcvt_xu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vuint32m8_t __riscv_vfcvt_rtz_xu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vint32mf2_t src, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vint32m1_t src, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vint32m2_t src, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vint32m4_t src, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vint32m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vuint32m1_t src, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vuint32m2_t src, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vuint32m4_t src, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vuint32m8_t src, size_t vl);
vint64m1_t __riscv_vfcvt_x_tumu (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vint64m1_t __riscv_vfcvt_rtz_x_tumu (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vint64m2_t __riscv_vfcvt_x_tumu (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vint64m2_t __riscv_vfcvt_rtz_x_tumu (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vint64m4_t __riscv_vfcvt_x_tumu (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vint64m4_t __riscv_vfcvt_rtz_x_tumu (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vint64m8_t __riscv_vfcvt_x_tumu (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vint64m8_t __riscv_vfcvt_rtz_x_tumu (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vuint64m1_t __riscv_vfcvt_xu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vuint64m1_t __riscv_vfcvt_rtz_xu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vuint64m2_t __riscv_vfcvt_xu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vuint64m2_t __riscv_vfcvt_rtz_xu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vuint64m4_t __riscv_vfcvt_xu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vuint64m4_t __riscv_vfcvt_rtz_xu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vuint64m8_t __riscv_vfcvt_xu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vuint64m8_t __riscv_vfcvt_rtz_xu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vint64m1_t src, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vint64m2_t src, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vint64m4_t src, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vint64m8_t src, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vuint64m1_t src, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vuint64m2_t src, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vuint64m4_t src, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vuint64m8_t src, size_t vl);
// masked functions
vint16mf4_t __riscv_vfcvt_x_mu (vbool64_t mask, vint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vint16mf4_t __riscv_vfcvt_rtz_x_mu (vbool64_t mask, vint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vint16mf2_t __riscv_vfcvt_x_mu (vbool32_t mask, vint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vint16mf2_t __riscv_vfcvt_rtz_x_mu (vbool32_t mask, vint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vint16m1_t __riscv_vfcvt_x_mu (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vint16m1_t __riscv_vfcvt_rtz_x_mu (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vint16m2_t __riscv_vfcvt_x_mu (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vint16m2_t __riscv_vfcvt_rtz_x_mu (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vint16m4_t __riscv_vfcvt_x_mu (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vint16m4_t __riscv_vfcvt_rtz_x_mu (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vint16m8_t __riscv_vfcvt_x_mu (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vint16m8_t __riscv_vfcvt_rtz_x_mu (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint16mf4_t __riscv_vfcvt_rtz_xu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint16mf2_t __riscv_vfcvt_rtz_xu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint16m1_t __riscv_vfcvt_xu_mu (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vuint16m1_t __riscv_vfcvt_rtz_xu_mu (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src, size_t vl);
vuint16m2_t __riscv_vfcvt_xu_mu (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vuint16m2_t __riscv_vfcvt_rtz_xu_mu (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src, size_t vl);
vuint16m4_t __riscv_vfcvt_xu_mu (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vuint16m4_t __riscv_vfcvt_rtz_xu_mu (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src, size_t vl);
vuint16m8_t __riscv_vfcvt_xu_mu (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vuint16m8_t __riscv_vfcvt_rtz_xu_mu (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vint16mf4_t src, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vint16mf2_t src, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vint16m1_t src, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vint16m2_t src, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vint16m4_t src, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_mu (vbool2_t mask, vfloat16m8_t maskedoff, vint16m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vuint16mf4_t src, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vuint16mf2_t src, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vuint16m1_t src, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vuint16m2_t src, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vuint16m4_t src, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_mu (vbool2_t mask, vfloat16m8_t maskedoff, vuint16m8_t src, size_t vl);
vint32mf2_t __riscv_vfcvt_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vint32mf2_t __riscv_vfcvt_rtz_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vint32m1_t __riscv_vfcvt_x_mu (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vint32m1_t __riscv_vfcvt_rtz_x_mu (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vint32m2_t __riscv_vfcvt_x_mu (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vint32m2_t __riscv_vfcvt_rtz_x_mu (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vint32m4_t __riscv_vfcvt_x_mu (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vint32m4_t __riscv_vfcvt_rtz_x_mu (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vint32m8_t __riscv_vfcvt_x_mu (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vint32m8_t __riscv_vfcvt_rtz_x_mu (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint32mf2_t __riscv_vfcvt_rtz_xu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint32m1_t __riscv_vfcvt_xu_mu (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vuint32m1_t __riscv_vfcvt_rtz_xu_mu (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src, size_t vl);
vuint32m2_t __riscv_vfcvt_xu_mu (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vuint32m2_t __riscv_vfcvt_rtz_xu_mu (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src, size_t vl);
vuint32m4_t __riscv_vfcvt_xu_mu (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vuint32m4_t __riscv_vfcvt_rtz_xu_mu (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src, size_t vl);
vuint32m8_t __riscv_vfcvt_xu_mu (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vuint32m8_t __riscv_vfcvt_rtz_xu_mu (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vint32mf2_t src, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vint32m1_t src, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vint32m2_t src, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vint32m4_t src, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_mu (vbool4_t mask, vfloat32m8_t maskedoff, vint32m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vuint32m1_t src, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vuint32m2_t src, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vuint32m4_t src, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_mu (vbool4_t mask, vfloat32m8_t maskedoff, vuint32m8_t src, size_t vl);
vint64m1_t __riscv_vfcvt_x_mu (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vint64m1_t __riscv_vfcvt_rtz_x_mu (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vint64m2_t __riscv_vfcvt_x_mu (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vint64m2_t __riscv_vfcvt_rtz_x_mu (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vint64m4_t __riscv_vfcvt_x_mu (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vint64m4_t __riscv_vfcvt_rtz_x_mu (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vint64m8_t __riscv_vfcvt_x_mu (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vint64m8_t __riscv_vfcvt_rtz_x_mu (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vuint64m1_t __riscv_vfcvt_xu_mu (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vuint64m1_t __riscv_vfcvt_rtz_xu_mu (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src, size_t vl);
vuint64m2_t __riscv_vfcvt_xu_mu (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vuint64m2_t __riscv_vfcvt_rtz_xu_mu (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src, size_t vl);
vuint64m4_t __riscv_vfcvt_xu_mu (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vuint64m4_t __riscv_vfcvt_rtz_xu_mu (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src, size_t vl);
vuint64m8_t __riscv_vfcvt_xu_mu (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vuint64m8_t __riscv_vfcvt_rtz_xu_mu (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat64m1_t maskedoff, vint64m1_t src, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat64m2_t maskedoff, vint64m2_t src, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat64m4_t maskedoff, vint64m4_t src, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat64m8_t maskedoff, vint64m8_t src, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat64m1_t maskedoff, vuint64m1_t src, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat64m2_t maskedoff, vuint64m2_t src, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat64m4_t maskedoff, vuint64m4_t src, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat64m8_t maskedoff, vuint64m8_t src, size_t vl);
vint16mf4_t __riscv_vfcvt_x_tu (vint16mf4_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint16mf2_t __riscv_vfcvt_x_tu (vint16mf2_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint16m1_t __riscv_vfcvt_x_tu (vint16m1_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint16m2_t __riscv_vfcvt_x_tu (vint16m2_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint16m4_t __riscv_vfcvt_x_tu (vint16m4_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint16m8_t __riscv_vfcvt_x_tu (vint16m8_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_tu (vuint16mf4_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_tu (vuint16mf2_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint16m1_t __riscv_vfcvt_xu_tu (vuint16m1_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint16m2_t __riscv_vfcvt_xu_tu (vuint16m2_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint16m4_t __riscv_vfcvt_xu_tu (vuint16m4_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint16m8_t __riscv_vfcvt_xu_tu (vuint16m8_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tu (vfloat16mf4_t maskedoff, vint16mf4_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tu (vfloat16mf2_t maskedoff, vint16mf2_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tu (vfloat16m1_t maskedoff, vint16m1_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tu (vfloat16m2_t maskedoff, vint16m2_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tu (vfloat16m4_t maskedoff, vint16m4_t src, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tu (vfloat16m8_t maskedoff, vint16m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tu (vfloat16mf4_t maskedoff, vuint16mf4_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tu (vfloat16mf2_t maskedoff, vuint16mf2_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tu (vfloat16m1_t maskedoff, vuint16m1_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tu (vfloat16m2_t maskedoff, vuint16m2_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tu (vfloat16m4_t maskedoff, vuint16m4_t src, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tu (vfloat16m8_t maskedoff, vuint16m8_t src, unsigned int frm, size_t vl);
vint32mf2_t __riscv_vfcvt_x_tu (vint32mf2_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfcvt_x_tu (vint32m1_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfcvt_x_tu (vint32m2_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfcvt_x_tu (vint32m4_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vint32m8_t __riscv_vfcvt_x_tu (vint32m8_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_tu (vuint32mf2_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfcvt_xu_tu (vuint32m1_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfcvt_xu_tu (vuint32m2_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfcvt_xu_tu (vuint32m4_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint32m8_t __riscv_vfcvt_xu_tu (vuint32m8_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tu (vfloat32mf2_t maskedoff, vint32mf2_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tu (vfloat32m1_t maskedoff, vint32m1_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tu (vfloat32m2_t maskedoff, vint32m2_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tu (vfloat32m4_t maskedoff, vint32m4_t src, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tu (vfloat32m8_t maskedoff, vint32m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tu (vfloat32mf2_t maskedoff, vuint32mf2_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tu (vfloat32m1_t maskedoff, vuint32m1_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tu (vfloat32m2_t maskedoff, vuint32m2_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tu (vfloat32m4_t maskedoff, vuint32m4_t src, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tu (vfloat32m8_t maskedoff, vuint32m8_t src, unsigned int frm, size_t vl);
vint64m1_t __riscv_vfcvt_x_tu (vint64m1_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vint64m2_t __riscv_vfcvt_x_tu (vint64m2_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vint64m4_t __riscv_vfcvt_x_tu (vint64m4_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vint64m8_t __riscv_vfcvt_x_tu (vint64m8_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vuint64m1_t __riscv_vfcvt_xu_tu (vuint64m1_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vuint64m2_t __riscv_vfcvt_xu_tu (vuint64m2_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vuint64m4_t __riscv_vfcvt_xu_tu (vuint64m4_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vuint64m8_t __riscv_vfcvt_xu_tu (vuint64m8_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tu (vfloat64m1_t maskedoff, vint64m1_t src, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tu (vfloat64m2_t maskedoff, vint64m2_t src, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tu (vfloat64m4_t maskedoff, vint64m4_t src, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tu (vfloat64m8_t maskedoff, vint64m8_t src, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tu (vfloat64m1_t maskedoff, vuint64m1_t src, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tu (vfloat64m2_t maskedoff, vuint64m2_t src, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tu (vfloat64m4_t maskedoff, vuint64m4_t src, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tu (vfloat64m8_t maskedoff, vuint64m8_t src, unsigned int frm, size_t vl);
// masked functions
vint16mf4_t __riscv_vfcvt_x_tum (vbool64_t mask, vint16mf4_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint16mf2_t __riscv_vfcvt_x_tum (vbool32_t mask, vint16mf2_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint16m1_t __riscv_vfcvt_x_tum (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint16m2_t __riscv_vfcvt_x_tum (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint16m4_t __riscv_vfcvt_x_tum (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint16m8_t __riscv_vfcvt_x_tum (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint16m1_t __riscv_vfcvt_xu_tum (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint16m2_t __riscv_vfcvt_xu_tum (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint16m4_t __riscv_vfcvt_xu_tum (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint16m8_t __riscv_vfcvt_xu_tum (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vint16mf4_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vint16mf2_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vint16m1_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vint16m2_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vint16m4_t src, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tum (vbool2_t mask, vfloat16m8_t maskedoff, vint16m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vuint16mf4_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vuint16mf2_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vuint16m1_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vuint16m2_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vuint16m4_t src, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tum (vbool2_t mask, vfloat16m8_t maskedoff, vuint16m8_t src, unsigned int frm, size_t vl);
vint32mf2_t __riscv_vfcvt_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfcvt_x_tum (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfcvt_x_tum (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfcvt_x_tum (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vint32m8_t __riscv_vfcvt_x_tum (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfcvt_xu_tum (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfcvt_xu_tum (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfcvt_xu_tum (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint32m8_t __riscv_vfcvt_xu_tum (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vint32mf2_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vint32m1_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vint32m2_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vint32m4_t src, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tum (vbool4_t mask, vfloat32m8_t maskedoff, vint32m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vuint32mf2_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vuint32m1_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vuint32m2_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vuint32m4_t src, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tum (vbool4_t mask, vfloat32m8_t maskedoff, vuint32m8_t src, unsigned int frm, size_t vl);
vint64m1_t __riscv_vfcvt_x_tum (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vint64m2_t __riscv_vfcvt_x_tum (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vint64m4_t __riscv_vfcvt_x_tum (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vint64m8_t __riscv_vfcvt_x_tum (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vuint64m1_t __riscv_vfcvt_xu_tum (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vuint64m2_t __riscv_vfcvt_xu_tum (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vuint64m4_t __riscv_vfcvt_xu_tum (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vuint64m8_t __riscv_vfcvt_xu_tum (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat64m1_t maskedoff, vint64m1_t src, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat64m2_t maskedoff, vint64m2_t src, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat64m4_t maskedoff, vint64m4_t src, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat64m8_t maskedoff, vint64m8_t src, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tum (vbool64_t mask, vfloat64m1_t maskedoff, vuint64m1_t src, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tum (vbool32_t mask, vfloat64m2_t maskedoff, vuint64m2_t src, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tum (vbool16_t mask, vfloat64m4_t maskedoff, vuint64m4_t src, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tum (vbool8_t mask, vfloat64m8_t maskedoff, vuint64m8_t src, unsigned int frm, size_t vl);
// masked functions
vint16mf4_t __riscv_vfcvt_x_tumu (vbool64_t mask, vint16mf4_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint16mf2_t __riscv_vfcvt_x_tumu (vbool32_t mask, vint16mf2_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint16m1_t __riscv_vfcvt_x_tumu (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint16m2_t __riscv_vfcvt_x_tumu (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint16m4_t __riscv_vfcvt_x_tumu (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint16m8_t __riscv_vfcvt_x_tumu (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint16m1_t __riscv_vfcvt_xu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint16m2_t __riscv_vfcvt_xu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint16m4_t __riscv_vfcvt_xu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint16m8_t __riscv_vfcvt_xu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vint16mf4_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vint16mf2_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vint16m1_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vint16m2_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vint16m4_t src, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vint16m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vuint16mf4_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vuint16mf2_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vuint16m1_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vuint16m2_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vuint16m4_t src, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vuint16m8_t src, unsigned int frm, size_t vl);
vint32mf2_t __riscv_vfcvt_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfcvt_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfcvt_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfcvt_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vint32m8_t __riscv_vfcvt_x_tumu (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfcvt_xu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfcvt_xu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfcvt_xu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint32m8_t __riscv_vfcvt_xu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vint32mf2_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vint32m1_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vint32m2_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vint32m4_t src, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vint32m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vuint32mf2_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vuint32m1_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vuint32m2_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vuint32m4_t src, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vuint32m8_t src, unsigned int frm, size_t vl);
vint64m1_t __riscv_vfcvt_x_tumu (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vint64m2_t __riscv_vfcvt_x_tumu (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vint64m4_t __riscv_vfcvt_x_tumu (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vint64m8_t __riscv_vfcvt_x_tumu (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vuint64m1_t __riscv_vfcvt_xu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vuint64m2_t __riscv_vfcvt_xu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vuint64m4_t __riscv_vfcvt_xu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vuint64m8_t __riscv_vfcvt_xu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vint64m1_t src, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vint64m2_t src, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vint64m4_t src, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vint64m8_t src, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vuint64m1_t src, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vuint64m2_t src, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vuint64m4_t src, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vuint64m8_t src, unsigned int frm, size_t vl);
// masked functions
vint16mf4_t __riscv_vfcvt_x_mu (vbool64_t mask, vint16mf4_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint16mf2_t __riscv_vfcvt_x_mu (vbool32_t mask, vint16mf2_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint16m1_t __riscv_vfcvt_x_mu (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint16m2_t __riscv_vfcvt_x_mu (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint16m4_t __riscv_vfcvt_x_mu (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint16m8_t __riscv_vfcvt_x_mu (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vuint16mf4_t __riscv_vfcvt_xu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfcvt_xu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint16m1_t __riscv_vfcvt_xu_mu (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint16m2_t __riscv_vfcvt_xu_mu (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint16m4_t __riscv_vfcvt_xu_mu (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint16m8_t __riscv_vfcvt_xu_mu (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vint16mf4_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vint16mf2_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vint16m1_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vint16m2_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vint16m4_t src, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_mu (vbool2_t mask, vfloat16m8_t maskedoff, vint16m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vuint16mf4_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vuint16mf2_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vuint16m1_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vuint16m2_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfcvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vuint16m4_t src, unsigned int frm, size_t vl);
vfloat16m8_t __riscv_vfcvt_f_mu (vbool2_t mask, vfloat16m8_t maskedoff, vuint16m8_t src, unsigned int frm, size_t vl);
vint32mf2_t __riscv_vfcvt_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfcvt_x_mu (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfcvt_x_mu (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfcvt_x_mu (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vint32m8_t __riscv_vfcvt_x_mu (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfcvt_xu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfcvt_xu_mu (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfcvt_xu_mu (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfcvt_xu_mu (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint32m8_t __riscv_vfcvt_xu_mu (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vint32mf2_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vint32m1_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vint32m2_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vint32m4_t src, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_mu (vbool4_t mask, vfloat32m8_t maskedoff, vint32m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vuint32mf2_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vuint32m1_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vuint32m2_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vuint32m4_t src, unsigned int frm, size_t vl);
vfloat32m8_t __riscv_vfcvt_f_mu (vbool4_t mask, vfloat32m8_t maskedoff, vuint32m8_t src, unsigned int frm, size_t vl);
vint64m1_t __riscv_vfcvt_x_mu (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vint64m2_t __riscv_vfcvt_x_mu (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vint64m4_t __riscv_vfcvt_x_mu (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vint64m8_t __riscv_vfcvt_x_mu (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vuint64m1_t __riscv_vfcvt_xu_mu (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vuint64m2_t __riscv_vfcvt_xu_mu (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vuint64m4_t __riscv_vfcvt_xu_mu (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vuint64m8_t __riscv_vfcvt_xu_mu (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat64m1_t maskedoff, vint64m1_t src, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat64m2_t maskedoff, vint64m2_t src, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat64m4_t maskedoff, vint64m4_t src, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat64m8_t maskedoff, vint64m8_t src, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfcvt_f_mu (vbool64_t mask, vfloat64m1_t maskedoff, vuint64m1_t src, unsigned int frm, size_t vl);
vfloat64m2_t __riscv_vfcvt_f_mu (vbool32_t mask, vfloat64m2_t maskedoff, vuint64m2_t src, unsigned int frm, size_t vl);
vfloat64m4_t __riscv_vfcvt_f_mu (vbool16_t mask, vfloat64m4_t maskedoff, vuint64m4_t src, unsigned int frm, size_t vl);
vfloat64m8_t __riscv_vfcvt_f_mu (vbool8_t mask, vfloat64m8_t maskedoff, vuint64m8_t src, unsigned int frm, size_t vl);
```

[[policy-variant-overloadedwidening-floating-pointinteger-type-convert]]
=== Widening Floating-Point/Integer Type-Convert Intrinsics

``` C
vfloat16mf4_t __riscv_vfwcvt_f_tu (vfloat16mf4_t maskedoff, vint8mf8_t src, size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_tu (vfloat16mf2_t maskedoff, vint8mf4_t src, size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_tu (vfloat16m1_t maskedoff, vint8mf2_t src, size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_tu (vfloat16m2_t maskedoff, vint8m1_t src, size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_tu (vfloat16m4_t maskedoff, vint8m2_t src, size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_tu (vfloat16m8_t maskedoff, vint8m4_t src, size_t vl);
vfloat16mf4_t __riscv_vfwcvt_f_tu (vfloat16mf4_t maskedoff, vuint8mf8_t src, size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_tu (vfloat16mf2_t maskedoff, vuint8mf4_t src, size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_tu (vfloat16m1_t maskedoff, vuint8mf2_t src, size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_tu (vfloat16m2_t maskedoff, vuint8m1_t src, size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_tu (vfloat16m4_t maskedoff, vuint8m2_t src, size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_tu (vfloat16m8_t maskedoff, vuint8m4_t src, size_t vl);
vint32mf2_t __riscv_vfwcvt_x_tu (vint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vint32mf2_t __riscv_vfwcvt_rtz_x_tu (vint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vint32m1_t __riscv_vfwcvt_x_tu (vint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vint32m1_t __riscv_vfwcvt_rtz_x_tu (vint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vint32m2_t __riscv_vfwcvt_x_tu (vint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vint32m2_t __riscv_vfwcvt_rtz_x_tu (vint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vint32m4_t __riscv_vfwcvt_x_tu (vint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vint32m4_t __riscv_vfwcvt_rtz_x_tu (vint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vint32m8_t __riscv_vfwcvt_x_tu (vint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vint32m8_t __riscv_vfwcvt_rtz_x_tu (vint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_tu (vuint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint32mf2_t __riscv_vfwcvt_rtz_xu_tu (vuint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_tu (vuint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint32m1_t __riscv_vfwcvt_rtz_xu_tu (vuint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_tu (vuint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint32m2_t __riscv_vfwcvt_rtz_xu_tu (vuint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_tu (vuint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vuint32m4_t __riscv_vfwcvt_rtz_xu_tu (vuint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_tu (vuint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vuint32m8_t __riscv_vfwcvt_rtz_xu_tu (vuint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_tu (vfloat32mf2_t maskedoff, vint16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_tu (vfloat32m1_t maskedoff, vint16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_tu (vfloat32m2_t maskedoff, vint16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_tu (vfloat32m4_t maskedoff, vint16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_tu (vfloat32m8_t maskedoff, vint16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_tu (vfloat32mf2_t maskedoff, vuint16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_tu (vfloat32m1_t maskedoff, vuint16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_tu (vfloat32m2_t maskedoff, vuint16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_tu (vfloat32m4_t maskedoff, vuint16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_tu (vfloat32m8_t maskedoff, vuint16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_tu (vfloat32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_tu (vfloat32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_tu (vfloat32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_tu (vfloat32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_tu (vfloat32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vint64m1_t __riscv_vfwcvt_x_tu (vint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vint64m1_t __riscv_vfwcvt_rtz_x_tu (vint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vint64m2_t __riscv_vfwcvt_x_tu (vint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vint64m2_t __riscv_vfwcvt_rtz_x_tu (vint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vint64m4_t __riscv_vfwcvt_x_tu (vint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vint64m4_t __riscv_vfwcvt_rtz_x_tu (vint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vint64m8_t __riscv_vfwcvt_x_tu (vint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vint64m8_t __riscv_vfwcvt_rtz_x_tu (vint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_tu (vuint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint64m1_t __riscv_vfwcvt_rtz_xu_tu (vuint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_tu (vuint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint64m2_t __riscv_vfwcvt_rtz_xu_tu (vuint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_tu (vuint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vuint64m4_t __riscv_vfwcvt_rtz_xu_tu (vuint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_tu (vuint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vuint64m8_t __riscv_vfwcvt_rtz_xu_tu (vuint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_tu (vfloat64m1_t maskedoff, vint32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_tu (vfloat64m2_t maskedoff, vint32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_tu (vfloat64m4_t maskedoff, vint32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_tu (vfloat64m8_t maskedoff, vint32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_tu (vfloat64m1_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_tu (vfloat64m2_t maskedoff, vuint32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_tu (vfloat64m4_t maskedoff, vuint32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_tu (vfloat64m8_t maskedoff, vuint32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_tu (vfloat64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_tu (vfloat64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_tu (vfloat64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_tu (vfloat64m8_t maskedoff, vfloat32m4_t src, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfwcvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vint8mf8_t src, size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vint8mf4_t src, size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vint8mf2_t src, size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vint8m1_t src, size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vint8m2_t src, size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_tum (vbool2_t mask, vfloat16m8_t maskedoff, vint8m4_t src, size_t vl);
vfloat16mf4_t __riscv_vfwcvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vuint8mf8_t src, size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vuint8mf4_t src, size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vuint8mf2_t src, size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vuint8m1_t src, size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vuint8m2_t src, size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_tum (vbool2_t mask, vfloat16m8_t maskedoff, vuint8m4_t src, size_t vl);
vint32mf2_t __riscv_vfwcvt_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vint32mf2_t __riscv_vfwcvt_rtz_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vint32m1_t __riscv_vfwcvt_x_tum (vbool32_t mask, vint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vint32m1_t __riscv_vfwcvt_rtz_x_tum (vbool32_t mask, vint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vint32m2_t __riscv_vfwcvt_x_tum (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vint32m2_t __riscv_vfwcvt_rtz_x_tum (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vint32m4_t __riscv_vfwcvt_x_tum (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vint32m4_t __riscv_vfwcvt_rtz_x_tum (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vint32m8_t __riscv_vfwcvt_x_tum (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vint32m8_t __riscv_vfwcvt_rtz_x_tum (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint32mf2_t __riscv_vfwcvt_rtz_xu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_tum (vbool32_t mask, vuint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint32m1_t __riscv_vfwcvt_rtz_xu_tum (vbool32_t mask, vuint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_tum (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint32m2_t __riscv_vfwcvt_rtz_xu_tum (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_tum (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vuint32m4_t __riscv_vfwcvt_rtz_xu_tum (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_tum (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vuint32m8_t __riscv_vfwcvt_rtz_xu_tum (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vint16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vint16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vint16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vint16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_tum (vbool4_t mask, vfloat32m8_t maskedoff, vint16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vuint16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vuint16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vuint16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vuint16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_tum (vbool4_t mask, vfloat32m8_t maskedoff, vuint16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vint64m1_t __riscv_vfwcvt_x_tum (vbool64_t mask, vint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vint64m1_t __riscv_vfwcvt_rtz_x_tum (vbool64_t mask, vint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vint64m2_t __riscv_vfwcvt_x_tum (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vint64m2_t __riscv_vfwcvt_rtz_x_tum (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vint64m4_t __riscv_vfwcvt_x_tum (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vint64m4_t __riscv_vfwcvt_rtz_x_tum (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vint64m8_t __riscv_vfwcvt_x_tum (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vint64m8_t __riscv_vfwcvt_rtz_x_tum (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_tum (vbool64_t mask, vuint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint64m1_t __riscv_vfwcvt_rtz_xu_tum (vbool64_t mask, vuint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_tum (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint64m2_t __riscv_vfwcvt_rtz_xu_tum (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_tum (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vuint64m4_t __riscv_vfwcvt_rtz_xu_tum (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_tum (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vuint64m8_t __riscv_vfwcvt_rtz_xu_tum (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_tum (vbool64_t mask, vfloat64m1_t maskedoff, vint32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_tum (vbool32_t mask, vfloat64m2_t maskedoff, vint32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_tum (vbool16_t mask, vfloat64m4_t maskedoff, vint32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_tum (vbool8_t mask, vfloat64m8_t maskedoff, vint32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_tum (vbool64_t mask, vfloat64m1_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_tum (vbool32_t mask, vfloat64m2_t maskedoff, vuint32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_tum (vbool16_t mask, vfloat64m4_t maskedoff, vuint32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_tum (vbool8_t mask, vfloat64m8_t maskedoff, vuint32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t src, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfwcvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vint8mf8_t src, size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vint8mf4_t src, size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vint8mf2_t src, size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vint8m1_t src, size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vint8m2_t src, size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vint8m4_t src, size_t vl);
vfloat16mf4_t __riscv_vfwcvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vuint8mf8_t src, size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vuint8mf4_t src, size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vuint8mf2_t src, size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vuint8m1_t src, size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vuint8m2_t src, size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vuint8m4_t src, size_t vl);
vint32mf2_t __riscv_vfwcvt_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vint32mf2_t __riscv_vfwcvt_rtz_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vint32m1_t __riscv_vfwcvt_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vint32m1_t __riscv_vfwcvt_rtz_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vint32m2_t __riscv_vfwcvt_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vint32m2_t __riscv_vfwcvt_rtz_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vint32m4_t __riscv_vfwcvt_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vint32m4_t __riscv_vfwcvt_rtz_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vint32m8_t __riscv_vfwcvt_x_tumu (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vint32m8_t __riscv_vfwcvt_rtz_x_tumu (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint32mf2_t __riscv_vfwcvt_rtz_xu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint32m1_t __riscv_vfwcvt_rtz_xu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint32m2_t __riscv_vfwcvt_rtz_xu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vuint32m4_t __riscv_vfwcvt_rtz_xu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vuint32m8_t __riscv_vfwcvt_rtz_xu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vint16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vint16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vint16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vint16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vint16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vuint16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vuint16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vuint16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vuint16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vuint16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vint64m1_t __riscv_vfwcvt_x_tumu (vbool64_t mask, vint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vint64m1_t __riscv_vfwcvt_rtz_x_tumu (vbool64_t mask, vint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vint64m2_t __riscv_vfwcvt_x_tumu (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vint64m2_t __riscv_vfwcvt_rtz_x_tumu (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vint64m4_t __riscv_vfwcvt_x_tumu (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vint64m4_t __riscv_vfwcvt_rtz_x_tumu (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vint64m8_t __riscv_vfwcvt_x_tumu (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vint64m8_t __riscv_vfwcvt_rtz_x_tumu (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint64m1_t __riscv_vfwcvt_rtz_xu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint64m2_t __riscv_vfwcvt_rtz_xu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vuint64m4_t __riscv_vfwcvt_rtz_xu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vuint64m8_t __riscv_vfwcvt_rtz_xu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vint32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vint32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vint32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vint32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vuint32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vuint32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vuint32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t src, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfwcvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vint8mf8_t src, size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vint8mf4_t src, size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vint8mf2_t src, size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vint8m1_t src, size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vint8m2_t src, size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_mu (vbool2_t mask, vfloat16m8_t maskedoff, vint8m4_t src, size_t vl);
vfloat16mf4_t __riscv_vfwcvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vuint8mf8_t src, size_t vl);
vfloat16mf2_t __riscv_vfwcvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vuint8mf4_t src, size_t vl);
vfloat16m1_t __riscv_vfwcvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vuint8mf2_t src, size_t vl);
vfloat16m2_t __riscv_vfwcvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vuint8m1_t src, size_t vl);
vfloat16m4_t __riscv_vfwcvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vuint8m2_t src, size_t vl);
vfloat16m8_t __riscv_vfwcvt_f_mu (vbool2_t mask, vfloat16m8_t maskedoff, vuint8m4_t src, size_t vl);
vint32mf2_t __riscv_vfwcvt_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vint32mf2_t __riscv_vfwcvt_rtz_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vint32m1_t __riscv_vfwcvt_x_mu (vbool32_t mask, vint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vint32m1_t __riscv_vfwcvt_rtz_x_mu (vbool32_t mask, vint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vint32m2_t __riscv_vfwcvt_x_mu (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vint32m2_t __riscv_vfwcvt_rtz_x_mu (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vint32m4_t __riscv_vfwcvt_x_mu (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vint32m4_t __riscv_vfwcvt_rtz_x_mu (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vint32m8_t __riscv_vfwcvt_x_mu (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vint32m8_t __riscv_vfwcvt_rtz_x_mu (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint32mf2_t __riscv_vfwcvt_rtz_xu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_mu (vbool32_t mask, vuint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint32m1_t __riscv_vfwcvt_rtz_xu_mu (vbool32_t mask, vuint32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_mu (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint32m2_t __riscv_vfwcvt_rtz_xu_mu (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_mu (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vuint32m4_t __riscv_vfwcvt_rtz_xu_mu (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_mu (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vuint32m8_t __riscv_vfwcvt_rtz_xu_mu (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vint16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vint16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vint16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vint16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_mu (vbool4_t mask, vfloat32m8_t maskedoff, vint16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vuint16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vuint16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vuint16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vuint16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_mu (vbool4_t mask, vfloat32m8_t maskedoff, vuint16m4_t src, size_t vl);
vfloat32mf2_t __riscv_vfwcvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat16mf4_t src, size_t vl);
vfloat32m1_t __riscv_vfwcvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t src, size_t vl);
vfloat32m2_t __riscv_vfwcvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t src, size_t vl);
vfloat32m4_t __riscv_vfwcvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t src, size_t vl);
vfloat32m8_t __riscv_vfwcvt_f_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t src, size_t vl);
vint64m1_t __riscv_vfwcvt_x_mu (vbool64_t mask, vint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vint64m1_t __riscv_vfwcvt_rtz_x_mu (vbool64_t mask, vint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vint64m2_t __riscv_vfwcvt_x_mu (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vint64m2_t __riscv_vfwcvt_rtz_x_mu (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vint64m4_t __riscv_vfwcvt_x_mu (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vint64m4_t __riscv_vfwcvt_rtz_x_mu (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vint64m8_t __riscv_vfwcvt_x_mu (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vint64m8_t __riscv_vfwcvt_rtz_x_mu (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_mu (vbool64_t mask, vuint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint64m1_t __riscv_vfwcvt_rtz_xu_mu (vbool64_t mask, vuint64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_mu (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint64m2_t __riscv_vfwcvt_rtz_xu_mu (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_mu (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vuint64m4_t __riscv_vfwcvt_rtz_xu_mu (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_mu (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vuint64m8_t __riscv_vfwcvt_rtz_xu_mu (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_mu (vbool64_t mask, vfloat64m1_t maskedoff, vint32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_mu (vbool32_t mask, vfloat64m2_t maskedoff, vint32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_mu (vbool16_t mask, vfloat64m4_t maskedoff, vint32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_mu (vbool8_t mask, vfloat64m8_t maskedoff, vint32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_mu (vbool64_t mask, vfloat64m1_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_mu (vbool32_t mask, vfloat64m2_t maskedoff, vuint32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_mu (vbool16_t mask, vfloat64m4_t maskedoff, vuint32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_mu (vbool8_t mask, vfloat64m8_t maskedoff, vuint32m4_t src, size_t vl);
vfloat64m1_t __riscv_vfwcvt_f_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat64m2_t __riscv_vfwcvt_f_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat64m4_t __riscv_vfwcvt_f_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat64m8_t __riscv_vfwcvt_f_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t src, size_t vl);
vint32mf2_t __riscv_vfwcvt_x_tu (vint32mf2_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfwcvt_x_tu (vint32m1_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfwcvt_x_tu (vint32m2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfwcvt_x_tu (vint32m4_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint32m8_t __riscv_vfwcvt_x_tu (vint32m8_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_tu (vuint32mf2_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_tu (vuint32m1_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_tu (vuint32m2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_tu (vuint32m4_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_tu (vuint32m8_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint64m1_t __riscv_vfwcvt_x_tu (vint64m1_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint64m2_t __riscv_vfwcvt_x_tu (vint64m2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint64m4_t __riscv_vfwcvt_x_tu (vint64m4_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint64m8_t __riscv_vfwcvt_x_tu (vint64m8_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_tu (vuint64m1_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_tu (vuint64m2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_tu (vuint64m4_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_tu (vuint64m8_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
// masked functions
vint32mf2_t __riscv_vfwcvt_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfwcvt_x_tum (vbool32_t mask, vint32m1_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfwcvt_x_tum (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfwcvt_x_tum (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint32m8_t __riscv_vfwcvt_x_tum (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_tum (vbool32_t mask, vuint32m1_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_tum (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_tum (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_tum (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint64m1_t __riscv_vfwcvt_x_tum (vbool64_t mask, vint64m1_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint64m2_t __riscv_vfwcvt_x_tum (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint64m4_t __riscv_vfwcvt_x_tum (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint64m8_t __riscv_vfwcvt_x_tum (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_tum (vbool64_t mask, vuint64m1_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_tum (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_tum (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_tum (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
// masked functions
vint32mf2_t __riscv_vfwcvt_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfwcvt_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfwcvt_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfwcvt_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint32m8_t __riscv_vfwcvt_x_tumu (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint64m1_t __riscv_vfwcvt_x_tumu (vbool64_t mask, vint64m1_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint64m2_t __riscv_vfwcvt_x_tumu (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint64m4_t __riscv_vfwcvt_x_tumu (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint64m8_t __riscv_vfwcvt_x_tumu (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
// masked functions
vint32mf2_t __riscv_vfwcvt_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfwcvt_x_mu (vbool32_t mask, vint32m1_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfwcvt_x_mu (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfwcvt_x_mu (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint32m8_t __riscv_vfwcvt_x_mu (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfwcvt_xu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfwcvt_xu_mu (vbool32_t mask, vuint32m1_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfwcvt_xu_mu (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfwcvt_xu_mu (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint32m8_t __riscv_vfwcvt_xu_mu (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint64m1_t __riscv_vfwcvt_x_mu (vbool64_t mask, vint64m1_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint64m2_t __riscv_vfwcvt_x_mu (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint64m4_t __riscv_vfwcvt_x_mu (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint64m8_t __riscv_vfwcvt_x_mu (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint64m1_t __riscv_vfwcvt_xu_mu (vbool64_t mask, vuint64m1_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint64m2_t __riscv_vfwcvt_xu_mu (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint64m4_t __riscv_vfwcvt_xu_mu (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint64m8_t __riscv_vfwcvt_xu_mu (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
```

[[policy-variant-overloadednarrowing-floating-pointinteger-type-convert]]
=== Narrowing Floating-Point/Integer Type-Convert Intrinsics

``` C
vint8mf8_t __riscv_vfncvt_x_tu (vint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vint8mf8_t __riscv_vfncvt_rtz_x_tu (vint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vint8mf4_t __riscv_vfncvt_x_tu (vint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vint8mf4_t __riscv_vfncvt_rtz_x_tu (vint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vint8mf2_t __riscv_vfncvt_x_tu (vint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vint8mf2_t __riscv_vfncvt_rtz_x_tu (vint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vint8m1_t __riscv_vfncvt_x_tu (vint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vint8m1_t __riscv_vfncvt_rtz_x_tu (vint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vint8m2_t __riscv_vfncvt_x_tu (vint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vint8m2_t __riscv_vfncvt_rtz_x_tu (vint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vint8m4_t __riscv_vfncvt_x_tu (vint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vint8m4_t __riscv_vfncvt_rtz_x_tu (vint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_tu (vuint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint8mf8_t __riscv_vfncvt_rtz_xu_tu (vuint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_tu (vuint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint8mf4_t __riscv_vfncvt_rtz_xu_tu (vuint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_tu (vuint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint8mf2_t __riscv_vfncvt_rtz_xu_tu (vuint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint8m1_t __riscv_vfncvt_xu_tu (vuint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vuint8m1_t __riscv_vfncvt_rtz_xu_tu (vuint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vuint8m2_t __riscv_vfncvt_xu_tu (vuint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vuint8m2_t __riscv_vfncvt_rtz_xu_tu (vuint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vuint8m4_t __riscv_vfncvt_xu_tu (vuint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vuint8m4_t __riscv_vfncvt_rtz_xu_tu (vuint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vint16mf4_t __riscv_vfncvt_x_tu (vint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vint16mf4_t __riscv_vfncvt_rtz_x_tu (vint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vint16mf2_t __riscv_vfncvt_x_tu (vint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vint16mf2_t __riscv_vfncvt_rtz_x_tu (vint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vint16m1_t __riscv_vfncvt_x_tu (vint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vint16m1_t __riscv_vfncvt_rtz_x_tu (vint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vint16m2_t __riscv_vfncvt_x_tu (vint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vint16m2_t __riscv_vfncvt_rtz_x_tu (vint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vint16m4_t __riscv_vfncvt_x_tu (vint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vint16m4_t __riscv_vfncvt_rtz_x_tu (vint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_tu (vuint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint16mf4_t __riscv_vfncvt_rtz_xu_tu (vuint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_tu (vuint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint16mf2_t __riscv_vfncvt_rtz_xu_tu (vuint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint16m1_t __riscv_vfncvt_xu_tu (vuint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vuint16m1_t __riscv_vfncvt_rtz_xu_tu (vuint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vuint16m2_t __riscv_vfncvt_xu_tu (vuint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vuint16m2_t __riscv_vfncvt_rtz_xu_tu (vuint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vuint16m4_t __riscv_vfncvt_xu_tu (vuint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vuint16m4_t __riscv_vfncvt_rtz_xu_tu (vuint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tu (vfloat16mf4_t maskedoff, vint32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tu (vfloat16mf2_t maskedoff, vint32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tu (vfloat16m1_t maskedoff, vint32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tu (vfloat16m2_t maskedoff, vint32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tu (vfloat16m4_t maskedoff, vint32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tu (vfloat16mf4_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tu (vfloat16mf2_t maskedoff, vuint32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tu (vfloat16m1_t maskedoff, vuint32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tu (vfloat16m2_t maskedoff, vuint32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tu (vfloat16m4_t maskedoff, vuint32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tu (vfloat16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_tu (vfloat16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tu (vfloat16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_tu (vfloat16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tu (vfloat16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_tu (vfloat16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tu (vfloat16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_tu (vfloat16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tu (vfloat16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_tu (vfloat16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vint32mf2_t __riscv_vfncvt_x_tu (vint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vint32mf2_t __riscv_vfncvt_rtz_x_tu (vint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vint32m1_t __riscv_vfncvt_x_tu (vint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vint32m1_t __riscv_vfncvt_rtz_x_tu (vint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vint32m2_t __riscv_vfncvt_x_tu (vint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vint32m2_t __riscv_vfncvt_rtz_x_tu (vint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vint32m4_t __riscv_vfncvt_x_tu (vint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vint32m4_t __riscv_vfncvt_rtz_x_tu (vint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_tu (vuint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vuint32mf2_t __riscv_vfncvt_rtz_xu_tu (vuint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vuint32m1_t __riscv_vfncvt_xu_tu (vuint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vuint32m1_t __riscv_vfncvt_rtz_xu_tu (vuint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vuint32m2_t __riscv_vfncvt_xu_tu (vuint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vuint32m2_t __riscv_vfncvt_rtz_xu_tu (vuint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vuint32m4_t __riscv_vfncvt_xu_tu (vuint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vuint32m4_t __riscv_vfncvt_rtz_xu_tu (vuint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tu (vfloat32mf2_t maskedoff, vint64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tu (vfloat32m1_t maskedoff, vint64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tu (vfloat32m2_t maskedoff, vint64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tu (vfloat32m4_t maskedoff, vint64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tu (vfloat32mf2_t maskedoff, vuint64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tu (vfloat32m1_t maskedoff, vuint64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tu (vfloat32m2_t maskedoff, vuint64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tu (vfloat32m4_t maskedoff, vuint64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tu (vfloat32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_rod_f_tu (vfloat32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tu (vfloat32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_rod_f_tu (vfloat32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tu (vfloat32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_rod_f_tu (vfloat32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tu (vfloat32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_rod_f_tu (vfloat32m4_t maskedoff, vfloat64m8_t src, size_t vl);
// masked functions
vint8mf8_t __riscv_vfncvt_x_tum (vbool64_t mask, vint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vint8mf8_t __riscv_vfncvt_rtz_x_tum (vbool64_t mask, vint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vint8mf4_t __riscv_vfncvt_x_tum (vbool32_t mask, vint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vint8mf4_t __riscv_vfncvt_rtz_x_tum (vbool32_t mask, vint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vint8mf2_t __riscv_vfncvt_x_tum (vbool16_t mask, vint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vint8mf2_t __riscv_vfncvt_rtz_x_tum (vbool16_t mask, vint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vint8m1_t __riscv_vfncvt_x_tum (vbool8_t mask, vint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vint8m1_t __riscv_vfncvt_rtz_x_tum (vbool8_t mask, vint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vint8m2_t __riscv_vfncvt_x_tum (vbool4_t mask, vint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vint8m2_t __riscv_vfncvt_rtz_x_tum (vbool4_t mask, vint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vint8m4_t __riscv_vfncvt_x_tum (vbool2_t mask, vint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vint8m4_t __riscv_vfncvt_rtz_x_tum (vbool2_t mask, vint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint8mf8_t __riscv_vfncvt_rtz_xu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint8mf4_t __riscv_vfncvt_rtz_xu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint8mf2_t __riscv_vfncvt_rtz_xu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint8m1_t __riscv_vfncvt_xu_tum (vbool8_t mask, vuint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vuint8m1_t __riscv_vfncvt_rtz_xu_tum (vbool8_t mask, vuint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vuint8m2_t __riscv_vfncvt_xu_tum (vbool4_t mask, vuint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vuint8m2_t __riscv_vfncvt_rtz_xu_tum (vbool4_t mask, vuint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vuint8m4_t __riscv_vfncvt_xu_tum (vbool2_t mask, vuint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vuint8m4_t __riscv_vfncvt_rtz_xu_tum (vbool2_t mask, vuint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vint16mf4_t __riscv_vfncvt_x_tum (vbool64_t mask, vint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vint16mf4_t __riscv_vfncvt_rtz_x_tum (vbool64_t mask, vint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vint16mf2_t __riscv_vfncvt_x_tum (vbool32_t mask, vint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vint16mf2_t __riscv_vfncvt_rtz_x_tum (vbool32_t mask, vint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vint16m1_t __riscv_vfncvt_x_tum (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vint16m1_t __riscv_vfncvt_rtz_x_tum (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vint16m2_t __riscv_vfncvt_x_tum (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vint16m2_t __riscv_vfncvt_rtz_x_tum (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vint16m4_t __riscv_vfncvt_x_tum (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vint16m4_t __riscv_vfncvt_rtz_x_tum (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint16mf4_t __riscv_vfncvt_rtz_xu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint16mf2_t __riscv_vfncvt_rtz_xu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint16m1_t __riscv_vfncvt_xu_tum (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vuint16m1_t __riscv_vfncvt_rtz_xu_tum (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vuint16m2_t __riscv_vfncvt_xu_tum (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vuint16m2_t __riscv_vfncvt_rtz_xu_tum (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vuint16m4_t __riscv_vfncvt_xu_tum (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vuint16m4_t __riscv_vfncvt_rtz_xu_tum (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vint32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vint32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vint32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vint32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vint32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vuint32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vuint32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vuint32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vuint32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vint32mf2_t __riscv_vfncvt_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vint32mf2_t __riscv_vfncvt_rtz_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vint32m1_t __riscv_vfncvt_x_tum (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vint32m1_t __riscv_vfncvt_rtz_x_tum (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vint32m2_t __riscv_vfncvt_x_tum (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vint32m2_t __riscv_vfncvt_rtz_x_tum (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vint32m4_t __riscv_vfncvt_x_tum (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vint32m4_t __riscv_vfncvt_rtz_x_tum (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vuint32mf2_t __riscv_vfncvt_rtz_xu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vuint32m1_t __riscv_vfncvt_xu_tum (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vuint32m1_t __riscv_vfncvt_rtz_xu_tum (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vuint32m2_t __riscv_vfncvt_xu_tum (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vuint32m2_t __riscv_vfncvt_rtz_xu_tum (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vuint32m4_t __riscv_vfncvt_xu_tum (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vuint32m4_t __riscv_vfncvt_rtz_xu_tum (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vint64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vint64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vint64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vint64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vuint64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vuint64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vuint64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vuint64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_rod_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_rod_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_rod_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_rod_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src, size_t vl);
// masked functions
vint8mf8_t __riscv_vfncvt_x_tumu (vbool64_t mask, vint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vint8mf8_t __riscv_vfncvt_rtz_x_tumu (vbool64_t mask, vint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vint8mf4_t __riscv_vfncvt_x_tumu (vbool32_t mask, vint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vint8mf4_t __riscv_vfncvt_rtz_x_tumu (vbool32_t mask, vint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vint8mf2_t __riscv_vfncvt_x_tumu (vbool16_t mask, vint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vint8mf2_t __riscv_vfncvt_rtz_x_tumu (vbool16_t mask, vint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vint8m1_t __riscv_vfncvt_x_tumu (vbool8_t mask, vint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vint8m1_t __riscv_vfncvt_rtz_x_tumu (vbool8_t mask, vint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vint8m2_t __riscv_vfncvt_x_tumu (vbool4_t mask, vint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vint8m2_t __riscv_vfncvt_rtz_x_tumu (vbool4_t mask, vint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vint8m4_t __riscv_vfncvt_x_tumu (vbool2_t mask, vint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vint8m4_t __riscv_vfncvt_rtz_x_tumu (vbool2_t mask, vint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint8mf8_t __riscv_vfncvt_rtz_xu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint8mf4_t __riscv_vfncvt_rtz_xu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint8mf2_t __riscv_vfncvt_rtz_xu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint8m1_t __riscv_vfncvt_xu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vuint8m1_t __riscv_vfncvt_rtz_xu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vuint8m2_t __riscv_vfncvt_xu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vuint8m2_t __riscv_vfncvt_rtz_xu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vuint8m4_t __riscv_vfncvt_xu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vuint8m4_t __riscv_vfncvt_rtz_xu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vint16mf4_t __riscv_vfncvt_x_tumu (vbool64_t mask, vint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vint16mf4_t __riscv_vfncvt_rtz_x_tumu (vbool64_t mask, vint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vint16mf2_t __riscv_vfncvt_x_tumu (vbool32_t mask, vint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vint16mf2_t __riscv_vfncvt_rtz_x_tumu (vbool32_t mask, vint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vint16m1_t __riscv_vfncvt_x_tumu (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vint16m1_t __riscv_vfncvt_rtz_x_tumu (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vint16m2_t __riscv_vfncvt_x_tumu (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vint16m2_t __riscv_vfncvt_rtz_x_tumu (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vint16m4_t __riscv_vfncvt_x_tumu (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vint16m4_t __riscv_vfncvt_rtz_x_tumu (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint16mf4_t __riscv_vfncvt_rtz_xu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint16mf2_t __riscv_vfncvt_rtz_xu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint16m1_t __riscv_vfncvt_xu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vuint16m1_t __riscv_vfncvt_rtz_xu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vuint16m2_t __riscv_vfncvt_xu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vuint16m2_t __riscv_vfncvt_rtz_xu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vuint16m4_t __riscv_vfncvt_xu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vuint16m4_t __riscv_vfncvt_rtz_xu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vint32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vint32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vint32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vint32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vint32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vuint32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vuint32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vuint32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vuint32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vint32mf2_t __riscv_vfncvt_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vint32mf2_t __riscv_vfncvt_rtz_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vint32m1_t __riscv_vfncvt_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vint32m1_t __riscv_vfncvt_rtz_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vint32m2_t __riscv_vfncvt_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vint32m2_t __riscv_vfncvt_rtz_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vint32m4_t __riscv_vfncvt_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vint32m4_t __riscv_vfncvt_rtz_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vuint32mf2_t __riscv_vfncvt_rtz_xu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vuint32m1_t __riscv_vfncvt_xu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vuint32m1_t __riscv_vfncvt_rtz_xu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vuint32m2_t __riscv_vfncvt_xu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vuint32m2_t __riscv_vfncvt_rtz_xu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vuint32m4_t __riscv_vfncvt_xu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vuint32m4_t __riscv_vfncvt_rtz_xu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vint64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vint64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vint64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vint64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vuint64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vuint64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vuint64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vuint64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_rod_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_rod_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_rod_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_rod_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src, size_t vl);
// masked functions
vint8mf8_t __riscv_vfncvt_x_mu (vbool64_t mask, vint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vint8mf8_t __riscv_vfncvt_rtz_x_mu (vbool64_t mask, vint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vint8mf4_t __riscv_vfncvt_x_mu (vbool32_t mask, vint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vint8mf4_t __riscv_vfncvt_rtz_x_mu (vbool32_t mask, vint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vint8mf2_t __riscv_vfncvt_x_mu (vbool16_t mask, vint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vint8mf2_t __riscv_vfncvt_rtz_x_mu (vbool16_t mask, vint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vint8m1_t __riscv_vfncvt_x_mu (vbool8_t mask, vint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vint8m1_t __riscv_vfncvt_rtz_x_mu (vbool8_t mask, vint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vint8m2_t __riscv_vfncvt_x_mu (vbool4_t mask, vint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vint8m2_t __riscv_vfncvt_rtz_x_mu (vbool4_t mask, vint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vint8m4_t __riscv_vfncvt_x_mu (vbool2_t mask, vint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vint8m4_t __riscv_vfncvt_rtz_x_mu (vbool2_t mask, vint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint8mf8_t __riscv_vfncvt_rtz_xu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vfloat16mf4_t src, size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint8mf4_t __riscv_vfncvt_rtz_xu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vfloat16mf2_t src, size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint8mf2_t __riscv_vfncvt_rtz_xu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vfloat16m1_t src, size_t vl);
vuint8m1_t __riscv_vfncvt_xu_mu (vbool8_t mask, vuint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vuint8m1_t __riscv_vfncvt_rtz_xu_mu (vbool8_t mask, vuint8m1_t maskedoff, vfloat16m2_t src, size_t vl);
vuint8m2_t __riscv_vfncvt_xu_mu (vbool4_t mask, vuint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vuint8m2_t __riscv_vfncvt_rtz_xu_mu (vbool4_t mask, vuint8m2_t maskedoff, vfloat16m4_t src, size_t vl);
vuint8m4_t __riscv_vfncvt_xu_mu (vbool2_t mask, vuint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vuint8m4_t __riscv_vfncvt_rtz_xu_mu (vbool2_t mask, vuint8m4_t maskedoff, vfloat16m8_t src, size_t vl);
vint16mf4_t __riscv_vfncvt_x_mu (vbool64_t mask, vint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vint16mf4_t __riscv_vfncvt_rtz_x_mu (vbool64_t mask, vint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vint16mf2_t __riscv_vfncvt_x_mu (vbool32_t mask, vint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vint16mf2_t __riscv_vfncvt_rtz_x_mu (vbool32_t mask, vint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vint16m1_t __riscv_vfncvt_x_mu (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vint16m1_t __riscv_vfncvt_rtz_x_mu (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vint16m2_t __riscv_vfncvt_x_mu (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vint16m2_t __riscv_vfncvt_rtz_x_mu (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vint16m4_t __riscv_vfncvt_x_mu (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vint16m4_t __riscv_vfncvt_rtz_x_mu (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint16mf4_t __riscv_vfncvt_rtz_xu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint16mf2_t __riscv_vfncvt_rtz_xu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vuint16m1_t __riscv_vfncvt_xu_mu (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vuint16m1_t __riscv_vfncvt_rtz_xu_mu (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vuint16m2_t __riscv_vfncvt_xu_mu (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vuint16m2_t __riscv_vfncvt_rtz_xu_mu (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vuint16m4_t __riscv_vfncvt_xu_mu (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vuint16m4_t __riscv_vfncvt_rtz_xu_mu (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vint32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vint32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vint32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vint32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vint32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vuint32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vuint32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vuint32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vuint32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vuint32m8_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat16mf4_t __riscv_vfncvt_rod_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat32mf2_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat16mf2_t __riscv_vfncvt_rod_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat32m1_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat16m1_t __riscv_vfncvt_rod_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat16m2_t __riscv_vfncvt_rod_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vfloat16m4_t __riscv_vfncvt_rod_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src, size_t vl);
vint32mf2_t __riscv_vfncvt_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vint32mf2_t __riscv_vfncvt_rtz_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vint32m1_t __riscv_vfncvt_x_mu (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vint32m1_t __riscv_vfncvt_rtz_x_mu (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vint32m2_t __riscv_vfncvt_x_mu (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vint32m2_t __riscv_vfncvt_rtz_x_mu (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vint32m4_t __riscv_vfncvt_x_mu (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vint32m4_t __riscv_vfncvt_rtz_x_mu (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vuint32mf2_t __riscv_vfncvt_rtz_xu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vuint32m1_t __riscv_vfncvt_xu_mu (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vuint32m1_t __riscv_vfncvt_rtz_xu_mu (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vuint32m2_t __riscv_vfncvt_xu_mu (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vuint32m2_t __riscv_vfncvt_rtz_xu_mu (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vuint32m4_t __riscv_vfncvt_xu_mu (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vuint32m4_t __riscv_vfncvt_rtz_xu_mu (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vint64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vint64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vint64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vint64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vuint64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vuint64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vuint64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vuint64m8_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vfloat32mf2_t __riscv_vfncvt_rod_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat64m1_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vfloat32m1_t __riscv_vfncvt_rod_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vfloat32m2_t __riscv_vfncvt_rod_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vfloat32m4_t __riscv_vfncvt_rod_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src, size_t vl);
vint8mf8_t __riscv_vfncvt_x_tu (vint8mf8_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint8mf4_t __riscv_vfncvt_x_tu (vint8mf4_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint8mf2_t __riscv_vfncvt_x_tu (vint8mf2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint8m1_t __riscv_vfncvt_x_tu (vint8m1_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint8m2_t __riscv_vfncvt_x_tu (vint8m2_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint8m4_t __riscv_vfncvt_x_tu (vint8m4_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_tu (vuint8mf8_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_tu (vuint8mf4_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_tu (vuint8mf2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint8m1_t __riscv_vfncvt_xu_tu (vuint8m1_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint8m2_t __riscv_vfncvt_xu_tu (vuint8m2_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint8m4_t __riscv_vfncvt_xu_tu (vuint8m4_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vint16mf4_t __riscv_vfncvt_x_tu (vint16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint16mf2_t __riscv_vfncvt_x_tu (vint16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint16m1_t __riscv_vfncvt_x_tu (vint16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint16m2_t __riscv_vfncvt_x_tu (vint16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vint16m4_t __riscv_vfncvt_x_tu (vint16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_tu (vuint16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_tu (vuint16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint16m1_t __riscv_vfncvt_xu_tu (vuint16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint16m2_t __riscv_vfncvt_xu_tu (vuint16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint16m4_t __riscv_vfncvt_xu_tu (vuint16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tu (vfloat16mf4_t maskedoff, vint32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tu (vfloat16mf2_t maskedoff, vint32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tu (vfloat16m1_t maskedoff, vint32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tu (vfloat16m2_t maskedoff, vint32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tu (vfloat16m4_t maskedoff, vint32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tu (vfloat16mf4_t maskedoff, vuint32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tu (vfloat16mf2_t maskedoff, vuint32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tu (vfloat16m1_t maskedoff, vuint32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tu (vfloat16m2_t maskedoff, vuint32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tu (vfloat16m4_t maskedoff, vuint32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tu (vfloat16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tu (vfloat16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tu (vfloat16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tu (vfloat16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tu (vfloat16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vint32mf2_t __riscv_vfncvt_x_tu (vint32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfncvt_x_tu (vint32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfncvt_x_tu (vint32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfncvt_x_tu (vint32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_tu (vuint32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfncvt_xu_tu (vuint32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfncvt_xu_tu (vuint32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfncvt_xu_tu (vuint32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tu (vfloat32mf2_t maskedoff, vint64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tu (vfloat32m1_t maskedoff, vint64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tu (vfloat32m2_t maskedoff, vint64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tu (vfloat32m4_t maskedoff, vint64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tu (vfloat32mf2_t maskedoff, vuint64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tu (vfloat32m1_t maskedoff, vuint64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tu (vfloat32m2_t maskedoff, vuint64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tu (vfloat32m4_t maskedoff, vuint64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tu (vfloat32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tu (vfloat32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tu (vfloat32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tu (vfloat32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
// masked functions
vint8mf8_t __riscv_vfncvt_x_tum (vbool64_t mask, vint8mf8_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint8mf4_t __riscv_vfncvt_x_tum (vbool32_t mask, vint8mf4_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint8mf2_t __riscv_vfncvt_x_tum (vbool16_t mask, vint8mf2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint8m1_t __riscv_vfncvt_x_tum (vbool8_t mask, vint8m1_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint8m2_t __riscv_vfncvt_x_tum (vbool4_t mask, vint8m2_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint8m4_t __riscv_vfncvt_x_tum (vbool2_t mask, vint8m4_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint8m1_t __riscv_vfncvt_xu_tum (vbool8_t mask, vuint8m1_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint8m2_t __riscv_vfncvt_xu_tum (vbool4_t mask, vuint8m2_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint8m4_t __riscv_vfncvt_xu_tum (vbool2_t mask, vuint8m4_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vint16mf4_t __riscv_vfncvt_x_tum (vbool64_t mask, vint16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint16mf2_t __riscv_vfncvt_x_tum (vbool32_t mask, vint16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint16m1_t __riscv_vfncvt_x_tum (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint16m2_t __riscv_vfncvt_x_tum (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vint16m4_t __riscv_vfncvt_x_tum (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint16m1_t __riscv_vfncvt_xu_tum (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint16m2_t __riscv_vfncvt_xu_tum (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint16m4_t __riscv_vfncvt_xu_tum (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vint32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vint32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vint32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vint32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vint32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vuint32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vuint32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vuint32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vuint32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vuint32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vint32mf2_t __riscv_vfncvt_x_tum (vbool64_t mask, vint32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfncvt_x_tum (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfncvt_x_tum (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfncvt_x_tum (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfncvt_xu_tum (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfncvt_xu_tum (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfncvt_xu_tum (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vint64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vint64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vint64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vint64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vuint64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vuint64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vuint64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vuint64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
// masked functions
vint8mf8_t __riscv_vfncvt_x_tumu (vbool64_t mask, vint8mf8_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint8mf4_t __riscv_vfncvt_x_tumu (vbool32_t mask, vint8mf4_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint8mf2_t __riscv_vfncvt_x_tumu (vbool16_t mask, vint8mf2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint8m1_t __riscv_vfncvt_x_tumu (vbool8_t mask, vint8m1_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint8m2_t __riscv_vfncvt_x_tumu (vbool4_t mask, vint8m2_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint8m4_t __riscv_vfncvt_x_tumu (vbool2_t mask, vint8m4_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint8m1_t __riscv_vfncvt_xu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint8m2_t __riscv_vfncvt_xu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint8m4_t __riscv_vfncvt_xu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vint16mf4_t __riscv_vfncvt_x_tumu (vbool64_t mask, vint16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint16mf2_t __riscv_vfncvt_x_tumu (vbool32_t mask, vint16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint16m1_t __riscv_vfncvt_x_tumu (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint16m2_t __riscv_vfncvt_x_tumu (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vint16m4_t __riscv_vfncvt_x_tumu (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint16m1_t __riscv_vfncvt_xu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint16m2_t __riscv_vfncvt_xu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint16m4_t __riscv_vfncvt_xu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vint32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vint32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vint32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vint32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vint32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vuint32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vuint32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vuint32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vuint32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vuint32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vint32mf2_t __riscv_vfncvt_x_tumu (vbool64_t mask, vint32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfncvt_x_tumu (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfncvt_x_tumu (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfncvt_x_tumu (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfncvt_xu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfncvt_xu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfncvt_xu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vint64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vint64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vint64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vint64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vuint64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vuint64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vuint64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vuint64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
// masked functions
vint8mf8_t __riscv_vfncvt_x_mu (vbool64_t mask, vint8mf8_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vint8mf4_t __riscv_vfncvt_x_mu (vbool32_t mask, vint8mf4_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vint8mf2_t __riscv_vfncvt_x_mu (vbool16_t mask, vint8mf2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vint8m1_t __riscv_vfncvt_x_mu (vbool8_t mask, vint8m1_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vint8m2_t __riscv_vfncvt_x_mu (vbool4_t mask, vint8m2_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vint8m4_t __riscv_vfncvt_x_mu (vbool2_t mask, vint8m4_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vuint8mf8_t __riscv_vfncvt_xu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vfloat16mf4_t src, unsigned int frm, size_t vl);
vuint8mf4_t __riscv_vfncvt_xu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vfloat16mf2_t src, unsigned int frm, size_t vl);
vuint8mf2_t __riscv_vfncvt_xu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vfloat16m1_t src, unsigned int frm, size_t vl);
vuint8m1_t __riscv_vfncvt_xu_mu (vbool8_t mask, vuint8m1_t maskedoff, vfloat16m2_t src, unsigned int frm, size_t vl);
vuint8m2_t __riscv_vfncvt_xu_mu (vbool4_t mask, vuint8m2_t maskedoff, vfloat16m4_t src, unsigned int frm, size_t vl);
vuint8m4_t __riscv_vfncvt_xu_mu (vbool2_t mask, vuint8m4_t maskedoff, vfloat16m8_t src, unsigned int frm, size_t vl);
vint16mf4_t __riscv_vfncvt_x_mu (vbool64_t mask, vint16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vint16mf2_t __riscv_vfncvt_x_mu (vbool32_t mask, vint16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vint16m1_t __riscv_vfncvt_x_mu (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vint16m2_t __riscv_vfncvt_x_mu (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vint16m4_t __riscv_vfncvt_x_mu (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vuint16mf4_t __riscv_vfncvt_xu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vuint16mf2_t __riscv_vfncvt_xu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vuint16m1_t __riscv_vfncvt_xu_mu (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vuint16m2_t __riscv_vfncvt_xu_mu (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vuint16m4_t __riscv_vfncvt_xu_mu (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vint32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vint32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vint32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vint32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vint32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vuint32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vuint32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vuint32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vuint32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vuint32m8_t src, unsigned int frm, size_t vl);
vfloat16mf4_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat32mf2_t src, unsigned int frm, size_t vl);
vfloat16mf2_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat32m1_t src, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src, unsigned int frm, size_t vl);
vfloat16m2_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src, unsigned int frm, size_t vl);
vfloat16m4_t __riscv_vfncvt_f_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src, unsigned int frm, size_t vl);
vint32mf2_t __riscv_vfncvt_x_mu (vbool64_t mask, vint32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vint32m1_t __riscv_vfncvt_x_mu (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vint32m2_t __riscv_vfncvt_x_mu (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vint32m4_t __riscv_vfncvt_x_mu (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vuint32mf2_t __riscv_vfncvt_xu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vuint32m1_t __riscv_vfncvt_xu_mu (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vuint32m2_t __riscv_vfncvt_xu_mu (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vuint32m4_t __riscv_vfncvt_xu_mu (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vint64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vint64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vint64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vint64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vuint64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vuint64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vuint64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vuint64m8_t src, unsigned int frm, size_t vl);
vfloat32mf2_t __riscv_vfncvt_f_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat64m1_t src, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfncvt_f_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src, unsigned int frm, size_t vl);
vfloat32m2_t __riscv_vfncvt_f_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src, unsigned int frm, size_t vl);
vfloat32m4_t __riscv_vfncvt_f_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src, unsigned int frm, size_t vl);
```

== Vector Reduction Operations

[[policy-variant-overloadedvector-single-width-integer-reduction]]
=== Vector Single-Width Integer Reduction Intrinsics

``` C
vint8m1_t __riscv_vredsum_tu (vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tu (vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tu (vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tu (vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tu (vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tu (vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tu (vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tu (vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tu (vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tu (vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tu (vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tu (vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tu (vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredsum_tu (vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredsum_tu (vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredsum_tu (vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredsum_tu (vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredsum_tu (vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredsum_tu (vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredsum_tu (vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredsum_tu (vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredsum_tu (vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tu (vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tu (vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tu (vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tu (vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tu (vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tu (vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tu (vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tu (vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tu (vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tu (vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tu (vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tu (vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tu (vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmax_tu (vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmax_tu (vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmax_tu (vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmax_tu (vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmax_tu (vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmax_tu (vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmax_tu (vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmax_tu (vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmax_tu (vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tu (vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tu (vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tu (vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tu (vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tu (vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tu (vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tu (vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tu (vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tu (vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tu (vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tu (vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tu (vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tu (vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmin_tu (vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmin_tu (vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmin_tu (vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmin_tu (vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmin_tu (vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmin_tu (vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmin_tu (vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmin_tu (vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmin_tu (vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tu (vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tu (vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tu (vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tu (vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tu (vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tu (vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tu (vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tu (vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tu (vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tu (vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tu (vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tu (vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tu (vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredand_tu (vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredand_tu (vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredand_tu (vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredand_tu (vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredand_tu (vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredand_tu (vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredand_tu (vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredand_tu (vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredand_tu (vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tu (vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tu (vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tu (vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tu (vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tu (vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tu (vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tu (vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tu (vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tu (vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tu (vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tu (vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tu (vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tu (vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredor_tu (vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredor_tu (vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredor_tu (vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredor_tu (vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredor_tu (vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredor_tu (vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredor_tu (vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredor_tu (vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredor_tu (vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tu (vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tu (vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tu (vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tu (vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tu (vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tu (vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tu (vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tu (vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tu (vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tu (vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tu (vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tu (vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tu (vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredxor_tu (vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredxor_tu (vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredxor_tu (vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredxor_tu (vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredxor_tu (vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredxor_tu (vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredxor_tu (vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredxor_tu (vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredxor_tu (vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tu (vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tu (vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tu (vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tu (vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tu (vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tu (vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tu (vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tu (vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tu (vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tu (vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tu (vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tu (vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tu (vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredsum_tu (vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredsum_tu (vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredsum_tu (vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredsum_tu (vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredsum_tu (vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredsum_tu (vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredsum_tu (vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredsum_tu (vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredsum_tu (vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tu (vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tu (vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tu (vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tu (vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tu (vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tu (vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tu (vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tu (vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tu (vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tu (vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tu (vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tu (vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tu (vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredmaxu_tu (vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredmaxu_tu (vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredmaxu_tu (vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredmaxu_tu (vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredmaxu_tu (vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredmaxu_tu (vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredmaxu_tu (vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredmaxu_tu (vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredmaxu_tu (vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tu (vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tu (vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tu (vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tu (vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tu (vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tu (vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tu (vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tu (vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tu (vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tu (vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tu (vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tu (vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tu (vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredminu_tu (vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredminu_tu (vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredminu_tu (vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredminu_tu (vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredminu_tu (vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredminu_tu (vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredminu_tu (vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredminu_tu (vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredminu_tu (vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tu (vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tu (vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tu (vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tu (vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tu (vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tu (vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tu (vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tu (vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tu (vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tu (vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tu (vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tu (vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tu (vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredand_tu (vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredand_tu (vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredand_tu (vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredand_tu (vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredand_tu (vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredand_tu (vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredand_tu (vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredand_tu (vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredand_tu (vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tu (vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tu (vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tu (vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tu (vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tu (vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tu (vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tu (vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tu (vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tu (vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tu (vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tu (vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tu (vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tu (vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredor_tu (vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredor_tu (vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredor_tu (vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredor_tu (vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredor_tu (vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredor_tu (vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredor_tu (vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredor_tu (vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredor_tu (vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tu (vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tu (vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tu (vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tu (vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tu (vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tu (vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tu (vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tu (vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tu (vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tu (vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tu (vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tu (vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tu (vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredxor_tu (vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredxor_tu (vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredxor_tu (vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredxor_tu (vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredxor_tu (vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredxor_tu (vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredxor_tu (vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredxor_tu (vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredxor_tu (vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
// masked functions
vint8m1_t __riscv_vredsum_tum (vbool64_t mask, vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tum (vbool32_t mask, vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tum (vbool16_t mask, vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tum (vbool4_t mask, vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tum (vbool2_t mask, vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredsum_tum (vbool1_t mask, vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tum (vbool64_t mask, vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tum (vbool32_t mask, vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tum (vbool8_t mask, vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tum (vbool4_t mask, vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredsum_tum (vbool2_t mask, vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredsum_tum (vbool64_t mask, vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredsum_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredsum_tum (vbool16_t mask, vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredsum_tum (vbool8_t mask, vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredsum_tum (vbool4_t mask, vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredsum_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredsum_tum (vbool32_t mask, vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredsum_tum (vbool16_t mask, vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredsum_tum (vbool8_t mask, vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tum (vbool64_t mask, vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tum (vbool32_t mask, vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tum (vbool16_t mask, vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tum (vbool4_t mask, vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tum (vbool2_t mask, vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmax_tum (vbool1_t mask, vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tum (vbool64_t mask, vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tum (vbool32_t mask, vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tum (vbool8_t mask, vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tum (vbool4_t mask, vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmax_tum (vbool2_t mask, vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmax_tum (vbool64_t mask, vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmax_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmax_tum (vbool16_t mask, vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmax_tum (vbool8_t mask, vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmax_tum (vbool4_t mask, vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmax_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmax_tum (vbool32_t mask, vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmax_tum (vbool16_t mask, vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmax_tum (vbool8_t mask, vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tum (vbool64_t mask, vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tum (vbool32_t mask, vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tum (vbool16_t mask, vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tum (vbool4_t mask, vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tum (vbool2_t mask, vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredmin_tum (vbool1_t mask, vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tum (vbool64_t mask, vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tum (vbool32_t mask, vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tum (vbool8_t mask, vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tum (vbool4_t mask, vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredmin_tum (vbool2_t mask, vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmin_tum (vbool64_t mask, vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmin_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmin_tum (vbool16_t mask, vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmin_tum (vbool8_t mask, vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredmin_tum (vbool4_t mask, vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmin_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmin_tum (vbool32_t mask, vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmin_tum (vbool16_t mask, vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredmin_tum (vbool8_t mask, vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tum (vbool64_t mask, vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tum (vbool32_t mask, vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tum (vbool16_t mask, vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tum (vbool4_t mask, vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tum (vbool2_t mask, vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredand_tum (vbool1_t mask, vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tum (vbool64_t mask, vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tum (vbool32_t mask, vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tum (vbool8_t mask, vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tum (vbool4_t mask, vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredand_tum (vbool2_t mask, vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredand_tum (vbool64_t mask, vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredand_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredand_tum (vbool16_t mask, vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredand_tum (vbool8_t mask, vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredand_tum (vbool4_t mask, vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredand_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredand_tum (vbool32_t mask, vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredand_tum (vbool16_t mask, vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredand_tum (vbool8_t mask, vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tum (vbool64_t mask, vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tum (vbool32_t mask, vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tum (vbool16_t mask, vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tum (vbool4_t mask, vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tum (vbool2_t mask, vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredor_tum (vbool1_t mask, vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tum (vbool64_t mask, vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tum (vbool32_t mask, vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tum (vbool8_t mask, vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tum (vbool4_t mask, vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredor_tum (vbool2_t mask, vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredor_tum (vbool64_t mask, vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredor_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredor_tum (vbool16_t mask, vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredor_tum (vbool8_t mask, vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredor_tum (vbool4_t mask, vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredor_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredor_tum (vbool32_t mask, vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredor_tum (vbool16_t mask, vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredor_tum (vbool8_t mask, vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tum (vbool64_t mask, vint8m1_t maskedoff, vint8mf8_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tum (vbool32_t mask, vint8m1_t maskedoff, vint8mf4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tum (vbool16_t mask, vint8m1_t maskedoff, vint8mf2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tum (vbool4_t mask, vint8m1_t maskedoff, vint8m2_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tum (vbool2_t mask, vint8m1_t maskedoff, vint8m4_t vector, vint8m1_t scalar, size_t vl);
vint8m1_t __riscv_vredxor_tum (vbool1_t mask, vint8m1_t maskedoff, vint8m8_t vector, vint8m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tum (vbool64_t mask, vint16m1_t maskedoff, vint16mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tum (vbool32_t mask, vint16m1_t maskedoff, vint16mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tum (vbool8_t mask, vint16m1_t maskedoff, vint16m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tum (vbool4_t mask, vint16m1_t maskedoff, vint16m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vredxor_tum (vbool2_t mask, vint16m1_t maskedoff, vint16m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vredxor_tum (vbool64_t mask, vint32m1_t maskedoff, vint32mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredxor_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredxor_tum (vbool16_t mask, vint32m1_t maskedoff, vint32m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredxor_tum (vbool8_t mask, vint32m1_t maskedoff, vint32m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vredxor_tum (vbool4_t mask, vint32m1_t maskedoff, vint32m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vredxor_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredxor_tum (vbool32_t mask, vint64m1_t maskedoff, vint64m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredxor_tum (vbool16_t mask, vint64m1_t maskedoff, vint64m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vredxor_tum (vbool8_t mask, vint64m1_t maskedoff, vint64m8_t vector, vint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tum (vbool64_t mask, vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tum (vbool32_t mask, vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tum (vbool16_t mask, vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tum (vbool4_t mask, vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tum (vbool2_t mask, vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredsum_tum (vbool1_t mask, vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tum (vbool64_t mask, vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tum (vbool32_t mask, vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tum (vbool8_t mask, vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tum (vbool4_t mask, vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredsum_tum (vbool2_t mask, vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredsum_tum (vbool64_t mask, vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredsum_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredsum_tum (vbool16_t mask, vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredsum_tum (vbool8_t mask, vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredsum_tum (vbool4_t mask, vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredsum_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredsum_tum (vbool32_t mask, vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredsum_tum (vbool16_t mask, vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredsum_tum (vbool8_t mask, vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tum (vbool64_t mask, vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tum (vbool32_t mask, vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tum (vbool16_t mask, vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tum (vbool4_t mask, vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tum (vbool2_t mask, vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredmaxu_tum (vbool1_t mask, vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tum (vbool64_t mask, vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tum (vbool32_t mask, vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tum (vbool8_t mask, vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tum (vbool4_t mask, vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredmaxu_tum (vbool2_t mask, vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredmaxu_tum (vbool64_t mask, vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredmaxu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredmaxu_tum (vbool16_t mask, vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredmaxu_tum (vbool8_t mask, vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredmaxu_tum (vbool4_t mask, vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredmaxu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredmaxu_tum (vbool32_t mask, vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredmaxu_tum (vbool16_t mask, vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredmaxu_tum (vbool8_t mask, vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tum (vbool64_t mask, vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tum (vbool32_t mask, vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tum (vbool16_t mask, vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tum (vbool4_t mask, vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tum (vbool2_t mask, vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredminu_tum (vbool1_t mask, vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tum (vbool64_t mask, vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tum (vbool32_t mask, vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tum (vbool8_t mask, vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tum (vbool4_t mask, vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredminu_tum (vbool2_t mask, vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredminu_tum (vbool64_t mask, vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredminu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredminu_tum (vbool16_t mask, vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredminu_tum (vbool8_t mask, vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredminu_tum (vbool4_t mask, vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredminu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredminu_tum (vbool32_t mask, vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredminu_tum (vbool16_t mask, vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredminu_tum (vbool8_t mask, vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tum (vbool64_t mask, vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tum (vbool32_t mask, vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tum (vbool16_t mask, vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tum (vbool4_t mask, vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tum (vbool2_t mask, vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredand_tum (vbool1_t mask, vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tum (vbool64_t mask, vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tum (vbool32_t mask, vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tum (vbool8_t mask, vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tum (vbool4_t mask, vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredand_tum (vbool2_t mask, vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredand_tum (vbool64_t mask, vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredand_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredand_tum (vbool16_t mask, vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredand_tum (vbool8_t mask, vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredand_tum (vbool4_t mask, vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredand_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredand_tum (vbool32_t mask, vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredand_tum (vbool16_t mask, vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredand_tum (vbool8_t mask, vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tum (vbool64_t mask, vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tum (vbool32_t mask, vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tum (vbool16_t mask, vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tum (vbool4_t mask, vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tum (vbool2_t mask, vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredor_tum (vbool1_t mask, vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tum (vbool64_t mask, vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tum (vbool32_t mask, vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tum (vbool8_t mask, vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tum (vbool4_t mask, vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredor_tum (vbool2_t mask, vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredor_tum (vbool64_t mask, vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredor_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredor_tum (vbool16_t mask, vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredor_tum (vbool8_t mask, vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredor_tum (vbool4_t mask, vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredor_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredor_tum (vbool32_t mask, vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredor_tum (vbool16_t mask, vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredor_tum (vbool8_t mask, vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tum (vbool64_t mask, vuint8m1_t maskedoff, vuint8mf8_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tum (vbool32_t mask, vuint8m1_t maskedoff, vuint8mf4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tum (vbool16_t mask, vuint8m1_t maskedoff, vuint8mf2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tum (vbool4_t mask, vuint8m1_t maskedoff, vuint8m2_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tum (vbool2_t mask, vuint8m1_t maskedoff, vuint8m4_t vector, vuint8m1_t scalar, size_t vl);
vuint8m1_t __riscv_vredxor_tum (vbool1_t mask, vuint8m1_t maskedoff, vuint8m8_t vector, vuint8m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tum (vbool64_t mask, vuint16m1_t maskedoff, vuint16mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tum (vbool32_t mask, vuint16m1_t maskedoff, vuint16mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tum (vbool8_t mask, vuint16m1_t maskedoff, vuint16m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tum (vbool4_t mask, vuint16m1_t maskedoff, vuint16m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vredxor_tum (vbool2_t mask, vuint16m1_t maskedoff, vuint16m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredxor_tum (vbool64_t mask, vuint32m1_t maskedoff, vuint32mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredxor_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredxor_tum (vbool16_t mask, vuint32m1_t maskedoff, vuint32m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredxor_tum (vbool8_t mask, vuint32m1_t maskedoff, vuint32m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vredxor_tum (vbool4_t mask, vuint32m1_t maskedoff, vuint32m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredxor_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredxor_tum (vbool32_t mask, vuint64m1_t maskedoff, vuint64m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredxor_tum (vbool16_t mask, vuint64m1_t maskedoff, vuint64m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vredxor_tum (vbool8_t mask, vuint64m1_t maskedoff, vuint64m8_t vector, vuint64m1_t scalar, size_t vl);
```

[[policy-variant-overloadedvector-widening-integer-reduction]]
=== Vector Widening Integer Reduction Intrinsics

``` C
vint16m1_t __riscv_vwredsum_tu (vint16m1_t maskedoff, vint8mf8_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tu (vint16m1_t maskedoff, vint8mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tu (vint16m1_t maskedoff, vint8mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tu (vint16m1_t maskedoff, vint8m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tu (vint16m1_t maskedoff, vint8m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tu (vint16m1_t maskedoff, vint8m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tu (vint16m1_t maskedoff, vint8m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tu (vint32m1_t maskedoff, vint16mf4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tu (vint32m1_t maskedoff, vint16mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tu (vint32m1_t maskedoff, vint16m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tu (vint32m1_t maskedoff, vint16m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tu (vint32m1_t maskedoff, vint16m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tu (vint32m1_t maskedoff, vint16m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vwredsum_tu (vint64m1_t maskedoff, vint32mf2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vwredsum_tu (vint64m1_t maskedoff, vint32m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vwredsum_tu (vint64m1_t maskedoff, vint32m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vwredsum_tu (vint64m1_t maskedoff, vint32m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vwredsum_tu (vint64m1_t maskedoff, vint32m8_t vector, vint64m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tu (vuint16m1_t maskedoff, vuint8mf8_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tu (vuint16m1_t maskedoff, vuint8mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tu (vuint16m1_t maskedoff, vuint8mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tu (vuint16m1_t maskedoff, vuint8m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tu (vuint16m1_t maskedoff, vuint8m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tu (vuint16m1_t maskedoff, vuint8m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tu (vuint16m1_t maskedoff, vuint8m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tu (vuint32m1_t maskedoff, vuint16mf4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tu (vuint32m1_t maskedoff, vuint16mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tu (vuint32m1_t maskedoff, vuint16m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tu (vuint32m1_t maskedoff, vuint16m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tu (vuint32m1_t maskedoff, vuint16m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tu (vuint32m1_t maskedoff, vuint16m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vwredsumu_tu (vuint64m1_t maskedoff, vuint32mf2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vwredsumu_tu (vuint64m1_t maskedoff, vuint32m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vwredsumu_tu (vuint64m1_t maskedoff, vuint32m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vwredsumu_tu (vuint64m1_t maskedoff, vuint32m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vwredsumu_tu (vuint64m1_t maskedoff, vuint32m8_t vector, vuint64m1_t scalar, size_t vl);
// masked functions
vint16m1_t __riscv_vwredsum_tum (vbool64_t mask, vint16m1_t maskedoff, vint8mf8_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tum (vbool32_t mask, vint16m1_t maskedoff, vint8mf4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tum (vbool16_t mask, vint16m1_t maskedoff, vint8mf2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tum (vbool8_t mask, vint16m1_t maskedoff, vint8m1_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tum (vbool4_t mask, vint16m1_t maskedoff, vint8m2_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tum (vbool2_t mask, vint16m1_t maskedoff, vint8m4_t vector, vint16m1_t scalar, size_t vl);
vint16m1_t __riscv_vwredsum_tum (vbool1_t mask, vint16m1_t maskedoff, vint8m8_t vector, vint16m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tum (vbool64_t mask, vint32m1_t maskedoff, vint16mf4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tum (vbool32_t mask, vint32m1_t maskedoff, vint16mf2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tum (vbool16_t mask, vint32m1_t maskedoff, vint16m1_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tum (vbool8_t mask, vint32m1_t maskedoff, vint16m2_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tum (vbool4_t mask, vint32m1_t maskedoff, vint16m4_t vector, vint32m1_t scalar, size_t vl);
vint32m1_t __riscv_vwredsum_tum (vbool2_t mask, vint32m1_t maskedoff, vint16m8_t vector, vint32m1_t scalar, size_t vl);
vint64m1_t __riscv_vwredsum_tum (vbool64_t mask, vint64m1_t maskedoff, vint32mf2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vwredsum_tum (vbool32_t mask, vint64m1_t maskedoff, vint32m1_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vwredsum_tum (vbool16_t mask, vint64m1_t maskedoff, vint32m2_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vwredsum_tum (vbool8_t mask, vint64m1_t maskedoff, vint32m4_t vector, vint64m1_t scalar, size_t vl);
vint64m1_t __riscv_vwredsum_tum (vbool4_t mask, vint64m1_t maskedoff, vint32m8_t vector, vint64m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tum (vbool64_t mask, vuint16m1_t maskedoff, vuint8mf8_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tum (vbool32_t mask, vuint16m1_t maskedoff, vuint8mf4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint8mf2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tum (vbool8_t mask, vuint16m1_t maskedoff, vuint8m1_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tum (vbool4_t mask, vuint16m1_t maskedoff, vuint8m2_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tum (vbool2_t mask, vuint16m1_t maskedoff, vuint8m4_t vector, vuint16m1_t scalar, size_t vl);
vuint16m1_t __riscv_vwredsumu_tum (vbool1_t mask, vuint16m1_t maskedoff, vuint8m8_t vector, vuint16m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tum (vbool64_t mask, vuint32m1_t maskedoff, vuint16mf4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint16mf2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tum (vbool16_t mask, vuint32m1_t maskedoff, vuint16m1_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tum (vbool8_t mask, vuint32m1_t maskedoff, vuint16m2_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tum (vbool4_t mask, vuint32m1_t maskedoff, vuint16m4_t vector, vuint32m1_t scalar, size_t vl);
vuint32m1_t __riscv_vwredsumu_tum (vbool2_t mask, vuint32m1_t maskedoff, vuint16m8_t vector, vuint32m1_t scalar, size_t vl);
vuint64m1_t __riscv_vwredsumu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint32mf2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vwredsumu_tum (vbool32_t mask, vuint64m1_t maskedoff, vuint32m1_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vwredsumu_tum (vbool16_t mask, vuint64m1_t maskedoff, vuint32m2_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vwredsumu_tum (vbool8_t mask, vuint64m1_t maskedoff, vuint32m4_t vector, vuint64m1_t scalar, size_t vl);
vuint64m1_t __riscv_vwredsumu_tum (vbool4_t mask, vuint64m1_t maskedoff, vuint32m8_t vector, vuint64m1_t scalar, size_t vl);
```

[[policy-variant-overloadedvector-single-width-floating-point-reduction]]
=== Vector Single-Width Floating-Point Reduction Intrinsics

``` C
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredosum_tu (vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredosum_tu (vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredosum_tu (vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredosum_tu (vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredosum_tu (vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredosum_tu (vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredosum_tu (vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredosum_tu (vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredosum_tu (vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredusum_tu (vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredusum_tu (vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredusum_tu (vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredusum_tu (vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredusum_tu (vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredusum_tu (vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredusum_tu (vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredusum_tu (vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredusum_tu (vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tu (vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tu (vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tu (vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tu (vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tu (vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tu (vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmax_tu (vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmax_tu (vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmax_tu (vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmax_tu (vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmax_tu (vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmax_tu (vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmax_tu (vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmax_tu (vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmax_tu (vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tu (vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tu (vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tu (vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tu (vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tu (vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tu (vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmin_tu (vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmin_tu (vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmin_tu (vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmin_tu (vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmin_tu (vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmin_tu (vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmin_tu (vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmin_tu (vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmin_tu (vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, size_t vl);
// masked functions
vfloat16m1_t __riscv_vfredosum_tum (vbool64_t mask, vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tum (vbool32_t mask, vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tum (vbool8_t mask, vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tum (vbool4_t mask, vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tum (vbool2_t mask, vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredosum_tum (vbool64_t mask, vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredosum_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredosum_tum (vbool16_t mask, vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredosum_tum (vbool8_t mask, vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredosum_tum (vbool4_t mask, vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredosum_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredosum_tum (vbool32_t mask, vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredosum_tum (vbool16_t mask, vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredosum_tum (vbool8_t mask, vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool64_t mask, vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool32_t mask, vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool8_t mask, vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool4_t mask, vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool2_t mask, vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredusum_tum (vbool64_t mask, vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredusum_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredusum_tum (vbool16_t mask, vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredusum_tum (vbool8_t mask, vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredusum_tum (vbool4_t mask, vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredusum_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredusum_tum (vbool32_t mask, vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredusum_tum (vbool16_t mask, vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredusum_tum (vbool8_t mask, vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tum (vbool64_t mask, vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tum (vbool32_t mask, vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tum (vbool8_t mask, vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tum (vbool4_t mask, vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmax_tum (vbool2_t mask, vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmax_tum (vbool64_t mask, vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmax_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmax_tum (vbool16_t mask, vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmax_tum (vbool8_t mask, vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmax_tum (vbool4_t mask, vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmax_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmax_tum (vbool32_t mask, vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmax_tum (vbool16_t mask, vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmax_tum (vbool8_t mask, vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tum (vbool64_t mask, vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tum (vbool32_t mask, vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tum (vbool8_t mask, vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tum (vbool4_t mask, vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredmin_tum (vbool2_t mask, vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmin_tum (vbool64_t mask, vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmin_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmin_tum (vbool16_t mask, vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmin_tum (vbool8_t mask, vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfredmin_tum (vbool4_t mask, vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmin_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmin_tum (vbool32_t mask, vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmin_tum (vbool16_t mask, vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfredmin_tum (vbool8_t mask, vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_tu (vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_tu (vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_tu (vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_tu (vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_tu (vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_tu (vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_tu (vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_tu (vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_tu (vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_tu (vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tu (vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_tu (vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_tu (vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_tu (vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_tu (vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_tu (vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_tu (vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_tu (vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_tu (vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_tu (vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
// masked functions
vfloat16m1_t __riscv_vfredosum_tum (vbool64_t mask, vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_tum (vbool32_t mask, vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_tum (vbool8_t mask, vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_tum (vbool4_t mask, vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredosum_tum (vbool2_t mask, vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_tum (vbool64_t mask, vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_tum (vbool16_t mask, vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_tum (vbool8_t mask, vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredosum_tum (vbool4_t mask, vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_tum (vbool32_t mask, vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_tum (vbool16_t mask, vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredosum_tum (vbool8_t mask, vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool64_t mask, vfloat16m1_t maskedoff, vfloat16mf4_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool32_t mask, vfloat16m1_t maskedoff, vfloat16mf2_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool8_t mask, vfloat16m1_t maskedoff, vfloat16m2_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool4_t mask, vfloat16m1_t maskedoff, vfloat16m4_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat16m1_t __riscv_vfredusum_tum (vbool2_t mask, vfloat16m1_t maskedoff, vfloat16m8_t vector, vfloat16m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_tum (vbool64_t mask, vfloat32m1_t maskedoff, vfloat32mf2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_tum (vbool16_t mask, vfloat32m1_t maskedoff, vfloat32m2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_tum (vbool8_t mask, vfloat32m1_t maskedoff, vfloat32m4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfredusum_tum (vbool4_t mask, vfloat32m1_t maskedoff, vfloat32m8_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_tum (vbool32_t mask, vfloat64m1_t maskedoff, vfloat64m2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_tum (vbool16_t mask, vfloat64m1_t maskedoff, vfloat64m4_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfredusum_tum (vbool8_t mask, vfloat64m1_t maskedoff, vfloat64m8_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
```

[[policy-variant-overloadedvector-widening-floating-point-reduction]]
=== Vector Widening Floating-Point Reduction Intrinsics

``` C
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16mf4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tu (vfloat64m1_t maskedoff, vfloat32mf2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tu (vfloat64m1_t maskedoff, vfloat32m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tu (vfloat64m1_t maskedoff, vfloat32m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tu (vfloat64m1_t maskedoff, vfloat32m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tu (vfloat64m1_t maskedoff, vfloat32m8_t vector, vfloat64m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16mf4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tu (vfloat64m1_t maskedoff, vfloat32mf2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tu (vfloat64m1_t maskedoff, vfloat32m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tu (vfloat64m1_t maskedoff, vfloat32m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tu (vfloat64m1_t maskedoff, vfloat32m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tu (vfloat64m1_t maskedoff, vfloat32m8_t vector, vfloat64m1_t scalar, size_t vl);
// masked functions
vfloat32m1_t __riscv_vfwredosum_tum (vbool64_t mask, vfloat32m1_t maskedoff, vfloat16mf4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tum (vbool16_t mask, vfloat32m1_t maskedoff, vfloat16m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tum (vbool8_t mask, vfloat32m1_t maskedoff, vfloat16m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tum (vbool4_t mask, vfloat32m1_t maskedoff, vfloat16m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tum (vbool2_t mask, vfloat32m1_t maskedoff, vfloat16m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tum (vbool32_t mask, vfloat64m1_t maskedoff, vfloat32m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tum (vbool16_t mask, vfloat64m1_t maskedoff, vfloat32m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tum (vbool8_t mask, vfloat64m1_t maskedoff, vfloat32m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tum (vbool4_t mask, vfloat64m1_t maskedoff, vfloat32m8_t vector, vfloat64m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool64_t mask, vfloat32m1_t maskedoff, vfloat16mf4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool16_t mask, vfloat32m1_t maskedoff, vfloat16m1_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool8_t mask, vfloat32m1_t maskedoff, vfloat16m2_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool4_t mask, vfloat32m1_t maskedoff, vfloat16m4_t vector, vfloat32m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool2_t mask, vfloat32m1_t maskedoff, vfloat16m8_t vector, vfloat32m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tum (vbool32_t mask, vfloat64m1_t maskedoff, vfloat32m1_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tum (vbool16_t mask, vfloat64m1_t maskedoff, vfloat32m2_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tum (vbool8_t mask, vfloat64m1_t maskedoff, vfloat32m4_t vector, vfloat64m1_t scalar, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tum (vbool4_t mask, vfloat64m1_t maskedoff, vfloat32m8_t vector, vfloat64m1_t scalar, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16mf4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16mf2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16m1_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16m2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16m4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tu (vfloat32m1_t maskedoff, vfloat16m8_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tu (vfloat64m1_t maskedoff, vfloat32mf2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tu (vfloat64m1_t maskedoff, vfloat32m1_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tu (vfloat64m1_t maskedoff, vfloat32m2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tu (vfloat64m1_t maskedoff, vfloat32m4_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tu (vfloat64m1_t maskedoff, vfloat32m8_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16mf4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16mf2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16m1_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16m2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16m4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tu (vfloat32m1_t maskedoff, vfloat16m8_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tu (vfloat64m1_t maskedoff, vfloat32mf2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tu (vfloat64m1_t maskedoff, vfloat32m1_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tu (vfloat64m1_t maskedoff, vfloat32m2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tu (vfloat64m1_t maskedoff, vfloat32m4_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tu (vfloat64m1_t maskedoff, vfloat32m8_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
// masked functions
vfloat32m1_t __riscv_vfwredosum_tum (vbool64_t mask, vfloat32m1_t maskedoff, vfloat16mf4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tum (vbool16_t mask, vfloat32m1_t maskedoff, vfloat16m1_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tum (vbool8_t mask, vfloat32m1_t maskedoff, vfloat16m2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tum (vbool4_t mask, vfloat32m1_t maskedoff, vfloat16m4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredosum_tum (vbool2_t mask, vfloat32m1_t maskedoff, vfloat16m8_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tum (vbool32_t mask, vfloat64m1_t maskedoff, vfloat32m1_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tum (vbool16_t mask, vfloat64m1_t maskedoff, vfloat32m2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tum (vbool8_t mask, vfloat64m1_t maskedoff, vfloat32m4_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredosum_tum (vbool4_t mask, vfloat64m1_t maskedoff, vfloat32m8_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool64_t mask, vfloat32m1_t maskedoff, vfloat16mf4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat16mf2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool16_t mask, vfloat32m1_t maskedoff, vfloat16m1_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool8_t mask, vfloat32m1_t maskedoff, vfloat16m2_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool4_t mask, vfloat32m1_t maskedoff, vfloat16m4_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat32m1_t __riscv_vfwredusum_tum (vbool2_t mask, vfloat32m1_t maskedoff, vfloat16m8_t vector, vfloat32m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat32mf2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tum (vbool32_t mask, vfloat64m1_t maskedoff, vfloat32m1_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tum (vbool16_t mask, vfloat64m1_t maskedoff, vfloat32m2_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tum (vbool8_t mask, vfloat64m1_t maskedoff, vfloat32m4_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
vfloat64m1_t __riscv_vfwredusum_tum (vbool4_t mask, vfloat64m1_t maskedoff, vfloat32m8_t vector, vfloat64m1_t scalar, unsigned int frm, size_t vl);
```

== Vector Mask Instructions

[[policy-variant-overloadedvector-mask-register-logical]]
=== Vector Mask-Register Logical
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-count-population-in-mask-vcpopm]]
=== Vector count population in mask `vcpop.m`
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvfirst-find-first-set-mask-bit]]
=== `vfirst` find-first-set mask bit
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvmsbfm-set-before-first-mask-bit]]
=== `vmsbf.m` set-before-first mask bit

``` C
// masked functions
vbool1_t __riscv_vmsbf_mu (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1, size_t vl);
vbool2_t __riscv_vmsbf_mu (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1, size_t vl);
vbool4_t __riscv_vmsbf_mu (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1, size_t vl);
vbool8_t __riscv_vmsbf_mu (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1, size_t vl);
vbool16_t __riscv_vmsbf_mu (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1, size_t vl);
vbool32_t __riscv_vmsbf_mu (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1, size_t vl);
vbool64_t __riscv_vmsbf_mu (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1, size_t vl);
```

[[policy-variant-overloadedvmsifm-set-including-first-mask-bit]]
=== `vmsif.m` set-including-first mask bit

``` C
// masked functions
vbool1_t __riscv_vmsif_mu (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1, size_t vl);
vbool2_t __riscv_vmsif_mu (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1, size_t vl);
vbool4_t __riscv_vmsif_mu (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1, size_t vl);
vbool8_t __riscv_vmsif_mu (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1, size_t vl);
vbool16_t __riscv_vmsif_mu (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1, size_t vl);
vbool32_t __riscv_vmsif_mu (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1, size_t vl);
vbool64_t __riscv_vmsif_mu (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1, size_t vl);
```

[[policy-variant-overloadedvmsofm-set-only-first-mask-bit]]
=== `vmsof.m` set-only-first mask bit

``` C
// masked functions
vbool1_t __riscv_vmsof_mu (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1, size_t vl);
vbool2_t __riscv_vmsof_mu (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1, size_t vl);
vbool4_t __riscv_vmsof_mu (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1, size_t vl);
vbool8_t __riscv_vmsof_mu (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1, size_t vl);
vbool16_t __riscv_vmsof_mu (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1, size_t vl);
vbool32_t __riscv_vmsof_mu (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1, size_t vl);
vbool64_t __riscv_vmsof_mu (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1, size_t vl);
```

[[policy-variant-overloadedvector-iota]]
=== Vector Iota Intrinsics

``` C
vuint8mf8_t __riscv_viota_tu (vuint8mf8_t maskedoff, vbool64_t op1, size_t vl);
vuint8mf4_t __riscv_viota_tu (vuint8mf4_t maskedoff, vbool32_t op1, size_t vl);
vuint8mf2_t __riscv_viota_tu (vuint8mf2_t maskedoff, vbool16_t op1, size_t vl);
vuint8m1_t __riscv_viota_tu (vuint8m1_t maskedoff, vbool8_t op1, size_t vl);
vuint8m2_t __riscv_viota_tu (vuint8m2_t maskedoff, vbool4_t op1, size_t vl);
vuint8m4_t __riscv_viota_tu (vuint8m4_t maskedoff, vbool2_t op1, size_t vl);
vuint8m8_t __riscv_viota_tu (vuint8m8_t maskedoff, vbool1_t op1, size_t vl);
vuint16mf4_t __riscv_viota_tu (vuint16mf4_t maskedoff, vbool64_t op1, size_t vl);
vuint16mf2_t __riscv_viota_tu (vuint16mf2_t maskedoff, vbool32_t op1, size_t vl);
vuint16m1_t __riscv_viota_tu (vuint16m1_t maskedoff, vbool16_t op1, size_t vl);
vuint16m2_t __riscv_viota_tu (vuint16m2_t maskedoff, vbool8_t op1, size_t vl);
vuint16m4_t __riscv_viota_tu (vuint16m4_t maskedoff, vbool4_t op1, size_t vl);
vuint16m8_t __riscv_viota_tu (vuint16m8_t maskedoff, vbool2_t op1, size_t vl);
vuint32mf2_t __riscv_viota_tu (vuint32mf2_t maskedoff, vbool64_t op1, size_t vl);
vuint32m1_t __riscv_viota_tu (vuint32m1_t maskedoff, vbool32_t op1, size_t vl);
vuint32m2_t __riscv_viota_tu (vuint32m2_t maskedoff, vbool16_t op1, size_t vl);
vuint32m4_t __riscv_viota_tu (vuint32m4_t maskedoff, vbool8_t op1, size_t vl);
vuint32m8_t __riscv_viota_tu (vuint32m8_t maskedoff, vbool4_t op1, size_t vl);
vuint64m1_t __riscv_viota_tu (vuint64m1_t maskedoff, vbool64_t op1, size_t vl);
vuint64m2_t __riscv_viota_tu (vuint64m2_t maskedoff, vbool32_t op1, size_t vl);
vuint64m4_t __riscv_viota_tu (vuint64m4_t maskedoff, vbool16_t op1, size_t vl);
vuint64m8_t __riscv_viota_tu (vuint64m8_t maskedoff, vbool8_t op1, size_t vl);
// masked functions
vuint8mf8_t __riscv_viota_tum (vbool64_t mask, vuint8mf8_t maskedoff, vbool64_t op1, size_t vl);
vuint8mf4_t __riscv_viota_tum (vbool32_t mask, vuint8mf4_t maskedoff, vbool32_t op1, size_t vl);
vuint8mf2_t __riscv_viota_tum (vbool16_t mask, vuint8mf2_t maskedoff, vbool16_t op1, size_t vl);
vuint8m1_t __riscv_viota_tum (vbool8_t mask, vuint8m1_t maskedoff, vbool8_t op1, size_t vl);
vuint8m2_t __riscv_viota_tum (vbool4_t mask, vuint8m2_t maskedoff, vbool4_t op1, size_t vl);
vuint8m4_t __riscv_viota_tum (vbool2_t mask, vuint8m4_t maskedoff, vbool2_t op1, size_t vl);
vuint8m8_t __riscv_viota_tum (vbool1_t mask, vuint8m8_t maskedoff, vbool1_t op1, size_t vl);
vuint16mf4_t __riscv_viota_tum (vbool64_t mask, vuint16mf4_t maskedoff, vbool64_t op1, size_t vl);
vuint16mf2_t __riscv_viota_tum (vbool32_t mask, vuint16mf2_t maskedoff, vbool32_t op1, size_t vl);
vuint16m1_t __riscv_viota_tum (vbool16_t mask, vuint16m1_t maskedoff, vbool16_t op1, size_t vl);
vuint16m2_t __riscv_viota_tum (vbool8_t mask, vuint16m2_t maskedoff, vbool8_t op1, size_t vl);
vuint16m4_t __riscv_viota_tum (vbool4_t mask, vuint16m4_t maskedoff, vbool4_t op1, size_t vl);
vuint16m8_t __riscv_viota_tum (vbool2_t mask, vuint16m8_t maskedoff, vbool2_t op1, size_t vl);
vuint32mf2_t __riscv_viota_tum (vbool64_t mask, vuint32mf2_t maskedoff, vbool64_t op1, size_t vl);
vuint32m1_t __riscv_viota_tum (vbool32_t mask, vuint32m1_t maskedoff, vbool32_t op1, size_t vl);
vuint32m2_t __riscv_viota_tum (vbool16_t mask, vuint32m2_t maskedoff, vbool16_t op1, size_t vl);
vuint32m4_t __riscv_viota_tum (vbool8_t mask, vuint32m4_t maskedoff, vbool8_t op1, size_t vl);
vuint32m8_t __riscv_viota_tum (vbool4_t mask, vuint32m8_t maskedoff, vbool4_t op1, size_t vl);
vuint64m1_t __riscv_viota_tum (vbool64_t mask, vuint64m1_t maskedoff, vbool64_t op1, size_t vl);
vuint64m2_t __riscv_viota_tum (vbool32_t mask, vuint64m2_t maskedoff, vbool32_t op1, size_t vl);
vuint64m4_t __riscv_viota_tum (vbool16_t mask, vuint64m4_t maskedoff, vbool16_t op1, size_t vl);
vuint64m8_t __riscv_viota_tum (vbool8_t mask, vuint64m8_t maskedoff, vbool8_t op1, size_t vl);
// masked functions
vuint8mf8_t __riscv_viota_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vbool64_t op1, size_t vl);
vuint8mf4_t __riscv_viota_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vbool32_t op1, size_t vl);
vuint8mf2_t __riscv_viota_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vbool16_t op1, size_t vl);
vuint8m1_t __riscv_viota_tumu (vbool8_t mask, vuint8m1_t maskedoff, vbool8_t op1, size_t vl);
vuint8m2_t __riscv_viota_tumu (vbool4_t mask, vuint8m2_t maskedoff, vbool4_t op1, size_t vl);
vuint8m4_t __riscv_viota_tumu (vbool2_t mask, vuint8m4_t maskedoff, vbool2_t op1, size_t vl);
vuint8m8_t __riscv_viota_tumu (vbool1_t mask, vuint8m8_t maskedoff, vbool1_t op1, size_t vl);
vuint16mf4_t __riscv_viota_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vbool64_t op1, size_t vl);
vuint16mf2_t __riscv_viota_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vbool32_t op1, size_t vl);
vuint16m1_t __riscv_viota_tumu (vbool16_t mask, vuint16m1_t maskedoff, vbool16_t op1, size_t vl);
vuint16m2_t __riscv_viota_tumu (vbool8_t mask, vuint16m2_t maskedoff, vbool8_t op1, size_t vl);
vuint16m4_t __riscv_viota_tumu (vbool4_t mask, vuint16m4_t maskedoff, vbool4_t op1, size_t vl);
vuint16m8_t __riscv_viota_tumu (vbool2_t mask, vuint16m8_t maskedoff, vbool2_t op1, size_t vl);
vuint32mf2_t __riscv_viota_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vbool64_t op1, size_t vl);
vuint32m1_t __riscv_viota_tumu (vbool32_t mask, vuint32m1_t maskedoff, vbool32_t op1, size_t vl);
vuint32m2_t __riscv_viota_tumu (vbool16_t mask, vuint32m2_t maskedoff, vbool16_t op1, size_t vl);
vuint32m4_t __riscv_viota_tumu (vbool8_t mask, vuint32m4_t maskedoff, vbool8_t op1, size_t vl);
vuint32m8_t __riscv_viota_tumu (vbool4_t mask, vuint32m8_t maskedoff, vbool4_t op1, size_t vl);
vuint64m1_t __riscv_viota_tumu (vbool64_t mask, vuint64m1_t maskedoff, vbool64_t op1, size_t vl);
vuint64m2_t __riscv_viota_tumu (vbool32_t mask, vuint64m2_t maskedoff, vbool32_t op1, size_t vl);
vuint64m4_t __riscv_viota_tumu (vbool16_t mask, vuint64m4_t maskedoff, vbool16_t op1, size_t vl);
vuint64m8_t __riscv_viota_tumu (vbool8_t mask, vuint64m8_t maskedoff, vbool8_t op1, size_t vl);
// masked functions
vuint8mf8_t __riscv_viota_mu (vbool64_t mask, vuint8mf8_t maskedoff, vbool64_t op1, size_t vl);
vuint8mf4_t __riscv_viota_mu (vbool32_t mask, vuint8mf4_t maskedoff, vbool32_t op1, size_t vl);
vuint8mf2_t __riscv_viota_mu (vbool16_t mask, vuint8mf2_t maskedoff, vbool16_t op1, size_t vl);
vuint8m1_t __riscv_viota_mu (vbool8_t mask, vuint8m1_t maskedoff, vbool8_t op1, size_t vl);
vuint8m2_t __riscv_viota_mu (vbool4_t mask, vuint8m2_t maskedoff, vbool4_t op1, size_t vl);
vuint8m4_t __riscv_viota_mu (vbool2_t mask, vuint8m4_t maskedoff, vbool2_t op1, size_t vl);
vuint8m8_t __riscv_viota_mu (vbool1_t mask, vuint8m8_t maskedoff, vbool1_t op1, size_t vl);
vuint16mf4_t __riscv_viota_mu (vbool64_t mask, vuint16mf4_t maskedoff, vbool64_t op1, size_t vl);
vuint16mf2_t __riscv_viota_mu (vbool32_t mask, vuint16mf2_t maskedoff, vbool32_t op1, size_t vl);
vuint16m1_t __riscv_viota_mu (vbool16_t mask, vuint16m1_t maskedoff, vbool16_t op1, size_t vl);
vuint16m2_t __riscv_viota_mu (vbool8_t mask, vuint16m2_t maskedoff, vbool8_t op1, size_t vl);
vuint16m4_t __riscv_viota_mu (vbool4_t mask, vuint16m4_t maskedoff, vbool4_t op1, size_t vl);
vuint16m8_t __riscv_viota_mu (vbool2_t mask, vuint16m8_t maskedoff, vbool2_t op1, size_t vl);
vuint32mf2_t __riscv_viota_mu (vbool64_t mask, vuint32mf2_t maskedoff, vbool64_t op1, size_t vl);
vuint32m1_t __riscv_viota_mu (vbool32_t mask, vuint32m1_t maskedoff, vbool32_t op1, size_t vl);
vuint32m2_t __riscv_viota_mu (vbool16_t mask, vuint32m2_t maskedoff, vbool16_t op1, size_t vl);
vuint32m4_t __riscv_viota_mu (vbool8_t mask, vuint32m4_t maskedoff, vbool8_t op1, size_t vl);
vuint32m8_t __riscv_viota_mu (vbool4_t mask, vuint32m8_t maskedoff, vbool4_t op1, size_t vl);
vuint64m1_t __riscv_viota_mu (vbool64_t mask, vuint64m1_t maskedoff, vbool64_t op1, size_t vl);
vuint64m2_t __riscv_viota_mu (vbool32_t mask, vuint64m2_t maskedoff, vbool32_t op1, size_t vl);
vuint64m4_t __riscv_viota_mu (vbool16_t mask, vuint64m4_t maskedoff, vbool16_t op1, size_t vl);
vuint64m8_t __riscv_viota_mu (vbool8_t mask, vuint64m8_t maskedoff, vbool8_t op1, size_t vl);
```

[[policy-variant-overloadedvector-element-index]]
=== Vector Element Index Intrinsics

``` C
vuint8mf8_t __riscv_vid_tu (vuint8mf8_t maskedoff, size_t vl);
vuint8mf4_t __riscv_vid_tu (vuint8mf4_t maskedoff, size_t vl);
vuint8mf2_t __riscv_vid_tu (vuint8mf2_t maskedoff, size_t vl);
vuint8m1_t __riscv_vid_tu (vuint8m1_t maskedoff, size_t vl);
vuint8m2_t __riscv_vid_tu (vuint8m2_t maskedoff, size_t vl);
vuint8m4_t __riscv_vid_tu (vuint8m4_t maskedoff, size_t vl);
vuint8m8_t __riscv_vid_tu (vuint8m8_t maskedoff, size_t vl);
vuint16mf4_t __riscv_vid_tu (vuint16mf4_t maskedoff, size_t vl);
vuint16mf2_t __riscv_vid_tu (vuint16mf2_t maskedoff, size_t vl);
vuint16m1_t __riscv_vid_tu (vuint16m1_t maskedoff, size_t vl);
vuint16m2_t __riscv_vid_tu (vuint16m2_t maskedoff, size_t vl);
vuint16m4_t __riscv_vid_tu (vuint16m4_t maskedoff, size_t vl);
vuint16m8_t __riscv_vid_tu (vuint16m8_t maskedoff, size_t vl);
vuint32mf2_t __riscv_vid_tu (vuint32mf2_t maskedoff, size_t vl);
vuint32m1_t __riscv_vid_tu (vuint32m1_t maskedoff, size_t vl);
vuint32m2_t __riscv_vid_tu (vuint32m2_t maskedoff, size_t vl);
vuint32m4_t __riscv_vid_tu (vuint32m4_t maskedoff, size_t vl);
vuint32m8_t __riscv_vid_tu (vuint32m8_t maskedoff, size_t vl);
vuint64m1_t __riscv_vid_tu (vuint64m1_t maskedoff, size_t vl);
vuint64m2_t __riscv_vid_tu (vuint64m2_t maskedoff, size_t vl);
vuint64m4_t __riscv_vid_tu (vuint64m4_t maskedoff, size_t vl);
vuint64m8_t __riscv_vid_tu (vuint64m8_t maskedoff, size_t vl);
// masked functions
vuint8mf8_t __riscv_vid_tum (vbool64_t mask, vuint8mf8_t maskedoff, size_t vl);
vuint8mf4_t __riscv_vid_tum (vbool32_t mask, vuint8mf4_t maskedoff, size_t vl);
vuint8mf2_t __riscv_vid_tum (vbool16_t mask, vuint8mf2_t maskedoff, size_t vl);
vuint8m1_t __riscv_vid_tum (vbool8_t mask, vuint8m1_t maskedoff, size_t vl);
vuint8m2_t __riscv_vid_tum (vbool4_t mask, vuint8m2_t maskedoff, size_t vl);
vuint8m4_t __riscv_vid_tum (vbool2_t mask, vuint8m4_t maskedoff, size_t vl);
vuint8m8_t __riscv_vid_tum (vbool1_t mask, vuint8m8_t maskedoff, size_t vl);
vuint16mf4_t __riscv_vid_tum (vbool64_t mask, vuint16mf4_t maskedoff, size_t vl);
vuint16mf2_t __riscv_vid_tum (vbool32_t mask, vuint16mf2_t maskedoff, size_t vl);
vuint16m1_t __riscv_vid_tum (vbool16_t mask, vuint16m1_t maskedoff, size_t vl);
vuint16m2_t __riscv_vid_tum (vbool8_t mask, vuint16m2_t maskedoff, size_t vl);
vuint16m4_t __riscv_vid_tum (vbool4_t mask, vuint16m4_t maskedoff, size_t vl);
vuint16m8_t __riscv_vid_tum (vbool2_t mask, vuint16m8_t maskedoff, size_t vl);
vuint32mf2_t __riscv_vid_tum (vbool64_t mask, vuint32mf2_t maskedoff, size_t vl);
vuint32m1_t __riscv_vid_tum (vbool32_t mask, vuint32m1_t maskedoff, size_t vl);
vuint32m2_t __riscv_vid_tum (vbool16_t mask, vuint32m2_t maskedoff, size_t vl);
vuint32m4_t __riscv_vid_tum (vbool8_t mask, vuint32m4_t maskedoff, size_t vl);
vuint32m8_t __riscv_vid_tum (vbool4_t mask, vuint32m8_t maskedoff, size_t vl);
vuint64m1_t __riscv_vid_tum (vbool64_t mask, vuint64m1_t maskedoff, size_t vl);
vuint64m2_t __riscv_vid_tum (vbool32_t mask, vuint64m2_t maskedoff, size_t vl);
vuint64m4_t __riscv_vid_tum (vbool16_t mask, vuint64m4_t maskedoff, size_t vl);
vuint64m8_t __riscv_vid_tum (vbool8_t mask, vuint64m8_t maskedoff, size_t vl);
// masked functions
vuint8mf8_t __riscv_vid_tumu (vbool64_t mask, vuint8mf8_t maskedoff, size_t vl);
vuint8mf4_t __riscv_vid_tumu (vbool32_t mask, vuint8mf4_t maskedoff, size_t vl);
vuint8mf2_t __riscv_vid_tumu (vbool16_t mask, vuint8mf2_t maskedoff, size_t vl);
vuint8m1_t __riscv_vid_tumu (vbool8_t mask, vuint8m1_t maskedoff, size_t vl);
vuint8m2_t __riscv_vid_tumu (vbool4_t mask, vuint8m2_t maskedoff, size_t vl);
vuint8m4_t __riscv_vid_tumu (vbool2_t mask, vuint8m4_t maskedoff, size_t vl);
vuint8m8_t __riscv_vid_tumu (vbool1_t mask, vuint8m8_t maskedoff, size_t vl);
vuint16mf4_t __riscv_vid_tumu (vbool64_t mask, vuint16mf4_t maskedoff, size_t vl);
vuint16mf2_t __riscv_vid_tumu (vbool32_t mask, vuint16mf2_t maskedoff, size_t vl);
vuint16m1_t __riscv_vid_tumu (vbool16_t mask, vuint16m1_t maskedoff, size_t vl);
vuint16m2_t __riscv_vid_tumu (vbool8_t mask, vuint16m2_t maskedoff, size_t vl);
vuint16m4_t __riscv_vid_tumu (vbool4_t mask, vuint16m4_t maskedoff, size_t vl);
vuint16m8_t __riscv_vid_tumu (vbool2_t mask, vuint16m8_t maskedoff, size_t vl);
vuint32mf2_t __riscv_vid_tumu (vbool64_t mask, vuint32mf2_t maskedoff, size_t vl);
vuint32m1_t __riscv_vid_tumu (vbool32_t mask, vuint32m1_t maskedoff, size_t vl);
vuint32m2_t __riscv_vid_tumu (vbool16_t mask, vuint32m2_t maskedoff, size_t vl);
vuint32m4_t __riscv_vid_tumu (vbool8_t mask, vuint32m4_t maskedoff, size_t vl);
vuint32m8_t __riscv_vid_tumu (vbool4_t mask, vuint32m8_t maskedoff, size_t vl);
vuint64m1_t __riscv_vid_tumu (vbool64_t mask, vuint64m1_t maskedoff, size_t vl);
vuint64m2_t __riscv_vid_tumu (vbool32_t mask, vuint64m2_t maskedoff, size_t vl);
vuint64m4_t __riscv_vid_tumu (vbool16_t mask, vuint64m4_t maskedoff, size_t vl);
vuint64m8_t __riscv_vid_tumu (vbool8_t mask, vuint64m8_t maskedoff, size_t vl);
// masked functions
vuint8mf8_t __riscv_vid_mu (vbool64_t mask, vuint8mf8_t maskedoff, size_t vl);
vuint8mf4_t __riscv_vid_mu (vbool32_t mask, vuint8mf4_t maskedoff, size_t vl);
vuint8mf2_t __riscv_vid_mu (vbool16_t mask, vuint8mf2_t maskedoff, size_t vl);
vuint8m1_t __riscv_vid_mu (vbool8_t mask, vuint8m1_t maskedoff, size_t vl);
vuint8m2_t __riscv_vid_mu (vbool4_t mask, vuint8m2_t maskedoff, size_t vl);
vuint8m4_t __riscv_vid_mu (vbool2_t mask, vuint8m4_t maskedoff, size_t vl);
vuint8m8_t __riscv_vid_mu (vbool1_t mask, vuint8m8_t maskedoff, size_t vl);
vuint16mf4_t __riscv_vid_mu (vbool64_t mask, vuint16mf4_t maskedoff, size_t vl);
vuint16mf2_t __riscv_vid_mu (vbool32_t mask, vuint16mf2_t maskedoff, size_t vl);
vuint16m1_t __riscv_vid_mu (vbool16_t mask, vuint16m1_t maskedoff, size_t vl);
vuint16m2_t __riscv_vid_mu (vbool8_t mask, vuint16m2_t maskedoff, size_t vl);
vuint16m4_t __riscv_vid_mu (vbool4_t mask, vuint16m4_t maskedoff, size_t vl);
vuint16m8_t __riscv_vid_mu (vbool2_t mask, vuint16m8_t maskedoff, size_t vl);
vuint32mf2_t __riscv_vid_mu (vbool64_t mask, vuint32mf2_t maskedoff, size_t vl);
vuint32m1_t __riscv_vid_mu (vbool32_t mask, vuint32m1_t maskedoff, size_t vl);
vuint32m2_t __riscv_vid_mu (vbool16_t mask, vuint32m2_t maskedoff, size_t vl);
vuint32m4_t __riscv_vid_mu (vbool8_t mask, vuint32m4_t maskedoff, size_t vl);
vuint32m8_t __riscv_vid_mu (vbool4_t mask, vuint32m8_t maskedoff, size_t vl);
vuint64m1_t __riscv_vid_mu (vbool64_t mask, vuint64m1_t maskedoff, size_t vl);
vuint64m2_t __riscv_vid_mu (vbool32_t mask, vuint64m2_t maskedoff, size_t vl);
vuint64m4_t __riscv_vid_mu (vbool16_t mask, vuint64m4_t maskedoff, size_t vl);
vuint64m8_t __riscv_vid_mu (vbool8_t mask, vuint64m8_t maskedoff, size_t vl);
```

== Vector Permutation Instructions

[[policy-variant-overloadedinteger-scalar-move]]
=== Integer and Floating-Point Scalar Move Intrinsics

``` C
vfloat16mf4_t __riscv_vfmv_s_tu (vfloat16mf4_t maskedoff, float16_t src, size_t vl);
vfloat16mf2_t __riscv_vfmv_s_tu (vfloat16mf2_t maskedoff, float16_t src, size_t vl);
vfloat16m1_t __riscv_vfmv_s_tu (vfloat16m1_t maskedoff, float16_t src, size_t vl);
vfloat16m2_t __riscv_vfmv_s_tu (vfloat16m2_t maskedoff, float16_t src, size_t vl);
vfloat16m4_t __riscv_vfmv_s_tu (vfloat16m4_t maskedoff, float16_t src, size_t vl);
vfloat16m8_t __riscv_vfmv_s_tu (vfloat16m8_t maskedoff, float16_t src, size_t vl);
vfloat32mf2_t __riscv_vfmv_s_tu (vfloat32mf2_t maskedoff, float32_t src, size_t vl);
vfloat32m1_t __riscv_vfmv_s_tu (vfloat32m1_t maskedoff, float32_t src, size_t vl);
vfloat32m2_t __riscv_vfmv_s_tu (vfloat32m2_t maskedoff, float32_t src, size_t vl);
vfloat32m4_t __riscv_vfmv_s_tu (vfloat32m4_t maskedoff, float32_t src, size_t vl);
vfloat32m8_t __riscv_vfmv_s_tu (vfloat32m8_t maskedoff, float32_t src, size_t vl);
vfloat64m1_t __riscv_vfmv_s_tu (vfloat64m1_t maskedoff, float64_t src, size_t vl);
vfloat64m2_t __riscv_vfmv_s_tu (vfloat64m2_t maskedoff, float64_t src, size_t vl);
vfloat64m4_t __riscv_vfmv_s_tu (vfloat64m4_t maskedoff, float64_t src, size_t vl);
vfloat64m8_t __riscv_vfmv_s_tu (vfloat64m8_t maskedoff, float64_t src, size_t vl);
vint8mf8_t __riscv_vmv_s_tu (vint8mf8_t maskedoff, int8_t src, size_t vl);
vint8mf4_t __riscv_vmv_s_tu (vint8mf4_t maskedoff, int8_t src, size_t vl);
vint8mf2_t __riscv_vmv_s_tu (vint8mf2_t maskedoff, int8_t src, size_t vl);
vint8m1_t __riscv_vmv_s_tu (vint8m1_t maskedoff, int8_t src, size_t vl);
vint8m2_t __riscv_vmv_s_tu (vint8m2_t maskedoff, int8_t src, size_t vl);
vint8m4_t __riscv_vmv_s_tu (vint8m4_t maskedoff, int8_t src, size_t vl);
vint8m8_t __riscv_vmv_s_tu (vint8m8_t maskedoff, int8_t src, size_t vl);
vint16mf4_t __riscv_vmv_s_tu (vint16mf4_t maskedoff, int16_t src, size_t vl);
vint16mf2_t __riscv_vmv_s_tu (vint16mf2_t maskedoff, int16_t src, size_t vl);
vint16m1_t __riscv_vmv_s_tu (vint16m1_t maskedoff, int16_t src, size_t vl);
vint16m2_t __riscv_vmv_s_tu (vint16m2_t maskedoff, int16_t src, size_t vl);
vint16m4_t __riscv_vmv_s_tu (vint16m4_t maskedoff, int16_t src, size_t vl);
vint16m8_t __riscv_vmv_s_tu (vint16m8_t maskedoff, int16_t src, size_t vl);
vint32mf2_t __riscv_vmv_s_tu (vint32mf2_t maskedoff, int32_t src, size_t vl);
vint32m1_t __riscv_vmv_s_tu (vint32m1_t maskedoff, int32_t src, size_t vl);
vint32m2_t __riscv_vmv_s_tu (vint32m2_t maskedoff, int32_t src, size_t vl);
vint32m4_t __riscv_vmv_s_tu (vint32m4_t maskedoff, int32_t src, size_t vl);
vint32m8_t __riscv_vmv_s_tu (vint32m8_t maskedoff, int32_t src, size_t vl);
vint64m1_t __riscv_vmv_s_tu (vint64m1_t maskedoff, int64_t src, size_t vl);
vint64m2_t __riscv_vmv_s_tu (vint64m2_t maskedoff, int64_t src, size_t vl);
vint64m4_t __riscv_vmv_s_tu (vint64m4_t maskedoff, int64_t src, size_t vl);
vint64m8_t __riscv_vmv_s_tu (vint64m8_t maskedoff, int64_t src, size_t vl);
vuint8mf8_t __riscv_vmv_s_tu (vuint8mf8_t maskedoff, uint8_t src, size_t vl);
vuint8mf4_t __riscv_vmv_s_tu (vuint8mf4_t maskedoff, uint8_t src, size_t vl);
vuint8mf2_t __riscv_vmv_s_tu (vuint8mf2_t maskedoff, uint8_t src, size_t vl);
vuint8m1_t __riscv_vmv_s_tu (vuint8m1_t maskedoff, uint8_t src, size_t vl);
vuint8m2_t __riscv_vmv_s_tu (vuint8m2_t maskedoff, uint8_t src, size_t vl);
vuint8m4_t __riscv_vmv_s_tu (vuint8m4_t maskedoff, uint8_t src, size_t vl);
vuint8m8_t __riscv_vmv_s_tu (vuint8m8_t maskedoff, uint8_t src, size_t vl);
vuint16mf4_t __riscv_vmv_s_tu (vuint16mf4_t maskedoff, uint16_t src, size_t vl);
vuint16mf2_t __riscv_vmv_s_tu (vuint16mf2_t maskedoff, uint16_t src, size_t vl);
vuint16m1_t __riscv_vmv_s_tu (vuint16m1_t maskedoff, uint16_t src, size_t vl);
vuint16m2_t __riscv_vmv_s_tu (vuint16m2_t maskedoff, uint16_t src, size_t vl);
vuint16m4_t __riscv_vmv_s_tu (vuint16m4_t maskedoff, uint16_t src, size_t vl);
vuint16m8_t __riscv_vmv_s_tu (vuint16m8_t maskedoff, uint16_t src, size_t vl);
vuint32mf2_t __riscv_vmv_s_tu (vuint32mf2_t maskedoff, uint32_t src, size_t vl);
vuint32m1_t __riscv_vmv_s_tu (vuint32m1_t maskedoff, uint32_t src, size_t vl);
vuint32m2_t __riscv_vmv_s_tu (vuint32m2_t maskedoff, uint32_t src, size_t vl);
vuint32m4_t __riscv_vmv_s_tu (vuint32m4_t maskedoff, uint32_t src, size_t vl);
vuint32m8_t __riscv_vmv_s_tu (vuint32m8_t maskedoff, uint32_t src, size_t vl);
vuint64m1_t __riscv_vmv_s_tu (vuint64m1_t maskedoff, uint64_t src, size_t vl);
vuint64m2_t __riscv_vmv_s_tu (vuint64m2_t maskedoff, uint64_t src, size_t vl);
vuint64m4_t __riscv_vmv_s_tu (vuint64m4_t maskedoff, uint64_t src, size_t vl);
vuint64m8_t __riscv_vmv_s_tu (vuint64m8_t maskedoff, uint64_t src, size_t vl);
```

[[policy-variant-overloadedvector-slideup]]
=== Vector Slideup Intrinsics

``` C
vfloat16mf4_t __riscv_vslideup_tu (vfloat16mf4_t dest, vfloat16mf4_t src, size_t offset, size_t vl);
vfloat16mf2_t __riscv_vslideup_tu (vfloat16mf2_t dest, vfloat16mf2_t src, size_t offset, size_t vl);
vfloat16m1_t __riscv_vslideup_tu (vfloat16m1_t dest, vfloat16m1_t src, size_t offset, size_t vl);
vfloat16m2_t __riscv_vslideup_tu (vfloat16m2_t dest, vfloat16m2_t src, size_t offset, size_t vl);
vfloat16m4_t __riscv_vslideup_tu (vfloat16m4_t dest, vfloat16m4_t src, size_t offset, size_t vl);
vfloat16m8_t __riscv_vslideup_tu (vfloat16m8_t dest, vfloat16m8_t src, size_t offset, size_t vl);
vfloat32mf2_t __riscv_vslideup_tu (vfloat32mf2_t dest, vfloat32mf2_t src, size_t offset, size_t vl);
vfloat32m1_t __riscv_vslideup_tu (vfloat32m1_t dest, vfloat32m1_t src, size_t offset, size_t vl);
vfloat32m2_t __riscv_vslideup_tu (vfloat32m2_t dest, vfloat32m2_t src, size_t offset, size_t vl);
vfloat32m4_t __riscv_vslideup_tu (vfloat32m4_t dest, vfloat32m4_t src, size_t offset, size_t vl);
vfloat32m8_t __riscv_vslideup_tu (vfloat32m8_t dest, vfloat32m8_t src, size_t offset, size_t vl);
vfloat64m1_t __riscv_vslideup_tu (vfloat64m1_t dest, vfloat64m1_t src, size_t offset, size_t vl);
vfloat64m2_t __riscv_vslideup_tu (vfloat64m2_t dest, vfloat64m2_t src, size_t offset, size_t vl);
vfloat64m4_t __riscv_vslideup_tu (vfloat64m4_t dest, vfloat64m4_t src, size_t offset, size_t vl);
vfloat64m8_t __riscv_vslideup_tu (vfloat64m8_t dest, vfloat64m8_t src, size_t offset, size_t vl);
vint8mf8_t __riscv_vslideup_tu (vint8mf8_t dest, vint8mf8_t src, size_t offset, size_t vl);
vint8mf4_t __riscv_vslideup_tu (vint8mf4_t dest, vint8mf4_t src, size_t offset, size_t vl);
vint8mf2_t __riscv_vslideup_tu (vint8mf2_t dest, vint8mf2_t src, size_t offset, size_t vl);
vint8m1_t __riscv_vslideup_tu (vint8m1_t dest, vint8m1_t src, size_t offset, size_t vl);
vint8m2_t __riscv_vslideup_tu (vint8m2_t dest, vint8m2_t src, size_t offset, size_t vl);
vint8m4_t __riscv_vslideup_tu (vint8m4_t dest, vint8m4_t src, size_t offset, size_t vl);
vint8m8_t __riscv_vslideup_tu (vint8m8_t dest, vint8m8_t src, size_t offset, size_t vl);
vint16mf4_t __riscv_vslideup_tu (vint16mf4_t dest, vint16mf4_t src, size_t offset, size_t vl);
vint16mf2_t __riscv_vslideup_tu (vint16mf2_t dest, vint16mf2_t src, size_t offset, size_t vl);
vint16m1_t __riscv_vslideup_tu (vint16m1_t dest, vint16m1_t src, size_t offset, size_t vl);
vint16m2_t __riscv_vslideup_tu (vint16m2_t dest, vint16m2_t src, size_t offset, size_t vl);
vint16m4_t __riscv_vslideup_tu (vint16m4_t dest, vint16m4_t src, size_t offset, size_t vl);
vint16m8_t __riscv_vslideup_tu (vint16m8_t dest, vint16m8_t src, size_t offset, size_t vl);
vint32mf2_t __riscv_vslideup_tu (vint32mf2_t dest, vint32mf2_t src, size_t offset, size_t vl);
vint32m1_t __riscv_vslideup_tu (vint32m1_t dest, vint32m1_t src, size_t offset, size_t vl);
vint32m2_t __riscv_vslideup_tu (vint32m2_t dest, vint32m2_t src, size_t offset, size_t vl);
vint32m4_t __riscv_vslideup_tu (vint32m4_t dest, vint32m4_t src, size_t offset, size_t vl);
vint32m8_t __riscv_vslideup_tu (vint32m8_t dest, vint32m8_t src, size_t offset, size_t vl);
vint64m1_t __riscv_vslideup_tu (vint64m1_t dest, vint64m1_t src, size_t offset, size_t vl);
vint64m2_t __riscv_vslideup_tu (vint64m2_t dest, vint64m2_t src, size_t offset, size_t vl);
vint64m4_t __riscv_vslideup_tu (vint64m4_t dest, vint64m4_t src, size_t offset, size_t vl);
vint64m8_t __riscv_vslideup_tu (vint64m8_t dest, vint64m8_t src, size_t offset, size_t vl);
vuint8mf8_t __riscv_vslideup_tu (vuint8mf8_t dest, vuint8mf8_t src, size_t offset, size_t vl);
vuint8mf4_t __riscv_vslideup_tu (vuint8mf4_t dest, vuint8mf4_t src, size_t offset, size_t vl);
vuint8mf2_t __riscv_vslideup_tu (vuint8mf2_t dest, vuint8mf2_t src, size_t offset, size_t vl);
vuint8m1_t __riscv_vslideup_tu (vuint8m1_t dest, vuint8m1_t src, size_t offset, size_t vl);
vuint8m2_t __riscv_vslideup_tu (vuint8m2_t dest, vuint8m2_t src, size_t offset, size_t vl);
vuint8m4_t __riscv_vslideup_tu (vuint8m4_t dest, vuint8m4_t src, size_t offset, size_t vl);
vuint8m8_t __riscv_vslideup_tu (vuint8m8_t dest, vuint8m8_t src, size_t offset, size_t vl);
vuint16mf4_t __riscv_vslideup_tu (vuint16mf4_t dest, vuint16mf4_t src, size_t offset, size_t vl);
vuint16mf2_t __riscv_vslideup_tu (vuint16mf2_t dest, vuint16mf2_t src, size_t offset, size_t vl);
vuint16m1_t __riscv_vslideup_tu (vuint16m1_t dest, vuint16m1_t src, size_t offset, size_t vl);
vuint16m2_t __riscv_vslideup_tu (vuint16m2_t dest, vuint16m2_t src, size_t offset, size_t vl);
vuint16m4_t __riscv_vslideup_tu (vuint16m4_t dest, vuint16m4_t src, size_t offset, size_t vl);
vuint16m8_t __riscv_vslideup_tu (vuint16m8_t dest, vuint16m8_t src, size_t offset, size_t vl);
vuint32mf2_t __riscv_vslideup_tu (vuint32mf2_t dest, vuint32mf2_t src, size_t offset, size_t vl);
vuint32m1_t __riscv_vslideup_tu (vuint32m1_t dest, vuint32m1_t src, size_t offset, size_t vl);
vuint32m2_t __riscv_vslideup_tu (vuint32m2_t dest, vuint32m2_t src, size_t offset, size_t vl);
vuint32m4_t __riscv_vslideup_tu (vuint32m4_t dest, vuint32m4_t src, size_t offset, size_t vl);
vuint32m8_t __riscv_vslideup_tu (vuint32m8_t dest, vuint32m8_t src, size_t offset, size_t vl);
vuint64m1_t __riscv_vslideup_tu (vuint64m1_t dest, vuint64m1_t src, size_t offset, size_t vl);
vuint64m2_t __riscv_vslideup_tu (vuint64m2_t dest, vuint64m2_t src, size_t offset, size_t vl);
vuint64m4_t __riscv_vslideup_tu (vuint64m4_t dest, vuint64m4_t src, size_t offset, size_t vl);
vuint64m8_t __riscv_vslideup_tu (vuint64m8_t dest, vuint64m8_t src, size_t offset, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vslideup_tum (vbool64_t mask, vfloat16mf4_t dest, vfloat16mf4_t src, size_t offset, size_t vl);
vfloat16mf2_t __riscv_vslideup_tum (vbool32_t mask, vfloat16mf2_t dest, vfloat16mf2_t src, size_t offset, size_t vl);
vfloat16m1_t __riscv_vslideup_tum (vbool16_t mask, vfloat16m1_t dest, vfloat16m1_t src, size_t offset, size_t vl);
vfloat16m2_t __riscv_vslideup_tum (vbool8_t mask, vfloat16m2_t dest, vfloat16m2_t src, size_t offset, size_t vl);
vfloat16m4_t __riscv_vslideup_tum (vbool4_t mask, vfloat16m4_t dest, vfloat16m4_t src, size_t offset, size_t vl);
vfloat16m8_t __riscv_vslideup_tum (vbool2_t mask, vfloat16m8_t dest, vfloat16m8_t src, size_t offset, size_t vl);
vfloat32mf2_t __riscv_vslideup_tum (vbool64_t mask, vfloat32mf2_t dest, vfloat32mf2_t src, size_t offset, size_t vl);
vfloat32m1_t __riscv_vslideup_tum (vbool32_t mask, vfloat32m1_t dest, vfloat32m1_t src, size_t offset, size_t vl);
vfloat32m2_t __riscv_vslideup_tum (vbool16_t mask, vfloat32m2_t dest, vfloat32m2_t src, size_t offset, size_t vl);
vfloat32m4_t __riscv_vslideup_tum (vbool8_t mask, vfloat32m4_t dest, vfloat32m4_t src, size_t offset, size_t vl);
vfloat32m8_t __riscv_vslideup_tum (vbool4_t mask, vfloat32m8_t dest, vfloat32m8_t src, size_t offset, size_t vl);
vfloat64m1_t __riscv_vslideup_tum (vbool64_t mask, vfloat64m1_t dest, vfloat64m1_t src, size_t offset, size_t vl);
vfloat64m2_t __riscv_vslideup_tum (vbool32_t mask, vfloat64m2_t dest, vfloat64m2_t src, size_t offset, size_t vl);
vfloat64m4_t __riscv_vslideup_tum (vbool16_t mask, vfloat64m4_t dest, vfloat64m4_t src, size_t offset, size_t vl);
vfloat64m8_t __riscv_vslideup_tum (vbool8_t mask, vfloat64m8_t dest, vfloat64m8_t src, size_t offset, size_t vl);
vint8mf8_t __riscv_vslideup_tum (vbool64_t mask, vint8mf8_t dest, vint8mf8_t src, size_t offset, size_t vl);
vint8mf4_t __riscv_vslideup_tum (vbool32_t mask, vint8mf4_t dest, vint8mf4_t src, size_t offset, size_t vl);
vint8mf2_t __riscv_vslideup_tum (vbool16_t mask, vint8mf2_t dest, vint8mf2_t src, size_t offset, size_t vl);
vint8m1_t __riscv_vslideup_tum (vbool8_t mask, vint8m1_t dest, vint8m1_t src, size_t offset, size_t vl);
vint8m2_t __riscv_vslideup_tum (vbool4_t mask, vint8m2_t dest, vint8m2_t src, size_t offset, size_t vl);
vint8m4_t __riscv_vslideup_tum (vbool2_t mask, vint8m4_t dest, vint8m4_t src, size_t offset, size_t vl);
vint8m8_t __riscv_vslideup_tum (vbool1_t mask, vint8m8_t dest, vint8m8_t src, size_t offset, size_t vl);
vint16mf4_t __riscv_vslideup_tum (vbool64_t mask, vint16mf4_t dest, vint16mf4_t src, size_t offset, size_t vl);
vint16mf2_t __riscv_vslideup_tum (vbool32_t mask, vint16mf2_t dest, vint16mf2_t src, size_t offset, size_t vl);
vint16m1_t __riscv_vslideup_tum (vbool16_t mask, vint16m1_t dest, vint16m1_t src, size_t offset, size_t vl);
vint16m2_t __riscv_vslideup_tum (vbool8_t mask, vint16m2_t dest, vint16m2_t src, size_t offset, size_t vl);
vint16m4_t __riscv_vslideup_tum (vbool4_t mask, vint16m4_t dest, vint16m4_t src, size_t offset, size_t vl);
vint16m8_t __riscv_vslideup_tum (vbool2_t mask, vint16m8_t dest, vint16m8_t src, size_t offset, size_t vl);
vint32mf2_t __riscv_vslideup_tum (vbool64_t mask, vint32mf2_t dest, vint32mf2_t src, size_t offset, size_t vl);
vint32m1_t __riscv_vslideup_tum (vbool32_t mask, vint32m1_t dest, vint32m1_t src, size_t offset, size_t vl);
vint32m2_t __riscv_vslideup_tum (vbool16_t mask, vint32m2_t dest, vint32m2_t src, size_t offset, size_t vl);
vint32m4_t __riscv_vslideup_tum (vbool8_t mask, vint32m4_t dest, vint32m4_t src, size_t offset, size_t vl);
vint32m8_t __riscv_vslideup_tum (vbool4_t mask, vint32m8_t dest, vint32m8_t src, size_t offset, size_t vl);
vint64m1_t __riscv_vslideup_tum (vbool64_t mask, vint64m1_t dest, vint64m1_t src, size_t offset, size_t vl);
vint64m2_t __riscv_vslideup_tum (vbool32_t mask, vint64m2_t dest, vint64m2_t src, size_t offset, size_t vl);
vint64m4_t __riscv_vslideup_tum (vbool16_t mask, vint64m4_t dest, vint64m4_t src, size_t offset, size_t vl);
vint64m8_t __riscv_vslideup_tum (vbool8_t mask, vint64m8_t dest, vint64m8_t src, size_t offset, size_t vl);
vuint8mf8_t __riscv_vslideup_tum (vbool64_t mask, vuint8mf8_t dest, vuint8mf8_t src, size_t offset, size_t vl);
vuint8mf4_t __riscv_vslideup_tum (vbool32_t mask, vuint8mf4_t dest, vuint8mf4_t src, size_t offset, size_t vl);
vuint8mf2_t __riscv_vslideup_tum (vbool16_t mask, vuint8mf2_t dest, vuint8mf2_t src, size_t offset, size_t vl);
vuint8m1_t __riscv_vslideup_tum (vbool8_t mask, vuint8m1_t dest, vuint8m1_t src, size_t offset, size_t vl);
vuint8m2_t __riscv_vslideup_tum (vbool4_t mask, vuint8m2_t dest, vuint8m2_t src, size_t offset, size_t vl);
vuint8m4_t __riscv_vslideup_tum (vbool2_t mask, vuint8m4_t dest, vuint8m4_t src, size_t offset, size_t vl);
vuint8m8_t __riscv_vslideup_tum (vbool1_t mask, vuint8m8_t dest, vuint8m8_t src, size_t offset, size_t vl);
vuint16mf4_t __riscv_vslideup_tum (vbool64_t mask, vuint16mf4_t dest, vuint16mf4_t src, size_t offset, size_t vl);
vuint16mf2_t __riscv_vslideup_tum (vbool32_t mask, vuint16mf2_t dest, vuint16mf2_t src, size_t offset, size_t vl);
vuint16m1_t __riscv_vslideup_tum (vbool16_t mask, vuint16m1_t dest, vuint16m1_t src, size_t offset, size_t vl);
vuint16m2_t __riscv_vslideup_tum (vbool8_t mask, vuint16m2_t dest, vuint16m2_t src, size_t offset, size_t vl);
vuint16m4_t __riscv_vslideup_tum (vbool4_t mask, vuint16m4_t dest, vuint16m4_t src, size_t offset, size_t vl);
vuint16m8_t __riscv_vslideup_tum (vbool2_t mask, vuint16m8_t dest, vuint16m8_t src, size_t offset, size_t vl);
vuint32mf2_t __riscv_vslideup_tum (vbool64_t mask, vuint32mf2_t dest, vuint32mf2_t src, size_t offset, size_t vl);
vuint32m1_t __riscv_vslideup_tum (vbool32_t mask, vuint32m1_t dest, vuint32m1_t src, size_t offset, size_t vl);
vuint32m2_t __riscv_vslideup_tum (vbool16_t mask, vuint32m2_t dest, vuint32m2_t src, size_t offset, size_t vl);
vuint32m4_t __riscv_vslideup_tum (vbool8_t mask, vuint32m4_t dest, vuint32m4_t src, size_t offset, size_t vl);
vuint32m8_t __riscv_vslideup_tum (vbool4_t mask, vuint32m8_t dest, vuint32m8_t src, size_t offset, size_t vl);
vuint64m1_t __riscv_vslideup_tum (vbool64_t mask, vuint64m1_t dest, vuint64m1_t src, size_t offset, size_t vl);
vuint64m2_t __riscv_vslideup_tum (vbool32_t mask, vuint64m2_t dest, vuint64m2_t src, size_t offset, size_t vl);
vuint64m4_t __riscv_vslideup_tum (vbool16_t mask, vuint64m4_t dest, vuint64m4_t src, size_t offset, size_t vl);
vuint64m8_t __riscv_vslideup_tum (vbool8_t mask, vuint64m8_t dest, vuint64m8_t src, size_t offset, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vslideup_tumu (vbool64_t mask, vfloat16mf4_t dest, vfloat16mf4_t src, size_t offset, size_t vl);
vfloat16mf2_t __riscv_vslideup_tumu (vbool32_t mask, vfloat16mf2_t dest, vfloat16mf2_t src, size_t offset, size_t vl);
vfloat16m1_t __riscv_vslideup_tumu (vbool16_t mask, vfloat16m1_t dest, vfloat16m1_t src, size_t offset, size_t vl);
vfloat16m2_t __riscv_vslideup_tumu (vbool8_t mask, vfloat16m2_t dest, vfloat16m2_t src, size_t offset, size_t vl);
vfloat16m4_t __riscv_vslideup_tumu (vbool4_t mask, vfloat16m4_t dest, vfloat16m4_t src, size_t offset, size_t vl);
vfloat16m8_t __riscv_vslideup_tumu (vbool2_t mask, vfloat16m8_t dest, vfloat16m8_t src, size_t offset, size_t vl);
vfloat32mf2_t __riscv_vslideup_tumu (vbool64_t mask, vfloat32mf2_t dest, vfloat32mf2_t src, size_t offset, size_t vl);
vfloat32m1_t __riscv_vslideup_tumu (vbool32_t mask, vfloat32m1_t dest, vfloat32m1_t src, size_t offset, size_t vl);
vfloat32m2_t __riscv_vslideup_tumu (vbool16_t mask, vfloat32m2_t dest, vfloat32m2_t src, size_t offset, size_t vl);
vfloat32m4_t __riscv_vslideup_tumu (vbool8_t mask, vfloat32m4_t dest, vfloat32m4_t src, size_t offset, size_t vl);
vfloat32m8_t __riscv_vslideup_tumu (vbool4_t mask, vfloat32m8_t dest, vfloat32m8_t src, size_t offset, size_t vl);
vfloat64m1_t __riscv_vslideup_tumu (vbool64_t mask, vfloat64m1_t dest, vfloat64m1_t src, size_t offset, size_t vl);
vfloat64m2_t __riscv_vslideup_tumu (vbool32_t mask, vfloat64m2_t dest, vfloat64m2_t src, size_t offset, size_t vl);
vfloat64m4_t __riscv_vslideup_tumu (vbool16_t mask, vfloat64m4_t dest, vfloat64m4_t src, size_t offset, size_t vl);
vfloat64m8_t __riscv_vslideup_tumu (vbool8_t mask, vfloat64m8_t dest, vfloat64m8_t src, size_t offset, size_t vl);
vint8mf8_t __riscv_vslideup_tumu (vbool64_t mask, vint8mf8_t dest, vint8mf8_t src, size_t offset, size_t vl);
vint8mf4_t __riscv_vslideup_tumu (vbool32_t mask, vint8mf4_t dest, vint8mf4_t src, size_t offset, size_t vl);
vint8mf2_t __riscv_vslideup_tumu (vbool16_t mask, vint8mf2_t dest, vint8mf2_t src, size_t offset, size_t vl);
vint8m1_t __riscv_vslideup_tumu (vbool8_t mask, vint8m1_t dest, vint8m1_t src, size_t offset, size_t vl);
vint8m2_t __riscv_vslideup_tumu (vbool4_t mask, vint8m2_t dest, vint8m2_t src, size_t offset, size_t vl);
vint8m4_t __riscv_vslideup_tumu (vbool2_t mask, vint8m4_t dest, vint8m4_t src, size_t offset, size_t vl);
vint8m8_t __riscv_vslideup_tumu (vbool1_t mask, vint8m8_t dest, vint8m8_t src, size_t offset, size_t vl);
vint16mf4_t __riscv_vslideup_tumu (vbool64_t mask, vint16mf4_t dest, vint16mf4_t src, size_t offset, size_t vl);
vint16mf2_t __riscv_vslideup_tumu (vbool32_t mask, vint16mf2_t dest, vint16mf2_t src, size_t offset, size_t vl);
vint16m1_t __riscv_vslideup_tumu (vbool16_t mask, vint16m1_t dest, vint16m1_t src, size_t offset, size_t vl);
vint16m2_t __riscv_vslideup_tumu (vbool8_t mask, vint16m2_t dest, vint16m2_t src, size_t offset, size_t vl);
vint16m4_t __riscv_vslideup_tumu (vbool4_t mask, vint16m4_t dest, vint16m4_t src, size_t offset, size_t vl);
vint16m8_t __riscv_vslideup_tumu (vbool2_t mask, vint16m8_t dest, vint16m8_t src, size_t offset, size_t vl);
vint32mf2_t __riscv_vslideup_tumu (vbool64_t mask, vint32mf2_t dest, vint32mf2_t src, size_t offset, size_t vl);
vint32m1_t __riscv_vslideup_tumu (vbool32_t mask, vint32m1_t dest, vint32m1_t src, size_t offset, size_t vl);
vint32m2_t __riscv_vslideup_tumu (vbool16_t mask, vint32m2_t dest, vint32m2_t src, size_t offset, size_t vl);
vint32m4_t __riscv_vslideup_tumu (vbool8_t mask, vint32m4_t dest, vint32m4_t src, size_t offset, size_t vl);
vint32m8_t __riscv_vslideup_tumu (vbool4_t mask, vint32m8_t dest, vint32m8_t src, size_t offset, size_t vl);
vint64m1_t __riscv_vslideup_tumu (vbool64_t mask, vint64m1_t dest, vint64m1_t src, size_t offset, size_t vl);
vint64m2_t __riscv_vslideup_tumu (vbool32_t mask, vint64m2_t dest, vint64m2_t src, size_t offset, size_t vl);
vint64m4_t __riscv_vslideup_tumu (vbool16_t mask, vint64m4_t dest, vint64m4_t src, size_t offset, size_t vl);
vint64m8_t __riscv_vslideup_tumu (vbool8_t mask, vint64m8_t dest, vint64m8_t src, size_t offset, size_t vl);
vuint8mf8_t __riscv_vslideup_tumu (vbool64_t mask, vuint8mf8_t dest, vuint8mf8_t src, size_t offset, size_t vl);
vuint8mf4_t __riscv_vslideup_tumu (vbool32_t mask, vuint8mf4_t dest, vuint8mf4_t src, size_t offset, size_t vl);
vuint8mf2_t __riscv_vslideup_tumu (vbool16_t mask, vuint8mf2_t dest, vuint8mf2_t src, size_t offset, size_t vl);
vuint8m1_t __riscv_vslideup_tumu (vbool8_t mask, vuint8m1_t dest, vuint8m1_t src, size_t offset, size_t vl);
vuint8m2_t __riscv_vslideup_tumu (vbool4_t mask, vuint8m2_t dest, vuint8m2_t src, size_t offset, size_t vl);
vuint8m4_t __riscv_vslideup_tumu (vbool2_t mask, vuint8m4_t dest, vuint8m4_t src, size_t offset, size_t vl);
vuint8m8_t __riscv_vslideup_tumu (vbool1_t mask, vuint8m8_t dest, vuint8m8_t src, size_t offset, size_t vl);
vuint16mf4_t __riscv_vslideup_tumu (vbool64_t mask, vuint16mf4_t dest, vuint16mf4_t src, size_t offset, size_t vl);
vuint16mf2_t __riscv_vslideup_tumu (vbool32_t mask, vuint16mf2_t dest, vuint16mf2_t src, size_t offset, size_t vl);
vuint16m1_t __riscv_vslideup_tumu (vbool16_t mask, vuint16m1_t dest, vuint16m1_t src, size_t offset, size_t vl);
vuint16m2_t __riscv_vslideup_tumu (vbool8_t mask, vuint16m2_t dest, vuint16m2_t src, size_t offset, size_t vl);
vuint16m4_t __riscv_vslideup_tumu (vbool4_t mask, vuint16m4_t dest, vuint16m4_t src, size_t offset, size_t vl);
vuint16m8_t __riscv_vslideup_tumu (vbool2_t mask, vuint16m8_t dest, vuint16m8_t src, size_t offset, size_t vl);
vuint32mf2_t __riscv_vslideup_tumu (vbool64_t mask, vuint32mf2_t dest, vuint32mf2_t src, size_t offset, size_t vl);
vuint32m1_t __riscv_vslideup_tumu (vbool32_t mask, vuint32m1_t dest, vuint32m1_t src, size_t offset, size_t vl);
vuint32m2_t __riscv_vslideup_tumu (vbool16_t mask, vuint32m2_t dest, vuint32m2_t src, size_t offset, size_t vl);
vuint32m4_t __riscv_vslideup_tumu (vbool8_t mask, vuint32m4_t dest, vuint32m4_t src, size_t offset, size_t vl);
vuint32m8_t __riscv_vslideup_tumu (vbool4_t mask, vuint32m8_t dest, vuint32m8_t src, size_t offset, size_t vl);
vuint64m1_t __riscv_vslideup_tumu (vbool64_t mask, vuint64m1_t dest, vuint64m1_t src, size_t offset, size_t vl);
vuint64m2_t __riscv_vslideup_tumu (vbool32_t mask, vuint64m2_t dest, vuint64m2_t src, size_t offset, size_t vl);
vuint64m4_t __riscv_vslideup_tumu (vbool16_t mask, vuint64m4_t dest, vuint64m4_t src, size_t offset, size_t vl);
vuint64m8_t __riscv_vslideup_tumu (vbool8_t mask, vuint64m8_t dest, vuint64m8_t src, size_t offset, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vslideup_mu (vbool64_t mask, vfloat16mf4_t dest, vfloat16mf4_t src, size_t offset, size_t vl);
vfloat16mf2_t __riscv_vslideup_mu (vbool32_t mask, vfloat16mf2_t dest, vfloat16mf2_t src, size_t offset, size_t vl);
vfloat16m1_t __riscv_vslideup_mu (vbool16_t mask, vfloat16m1_t dest, vfloat16m1_t src, size_t offset, size_t vl);
vfloat16m2_t __riscv_vslideup_mu (vbool8_t mask, vfloat16m2_t dest, vfloat16m2_t src, size_t offset, size_t vl);
vfloat16m4_t __riscv_vslideup_mu (vbool4_t mask, vfloat16m4_t dest, vfloat16m4_t src, size_t offset, size_t vl);
vfloat16m8_t __riscv_vslideup_mu (vbool2_t mask, vfloat16m8_t dest, vfloat16m8_t src, size_t offset, size_t vl);
vfloat32mf2_t __riscv_vslideup_mu (vbool64_t mask, vfloat32mf2_t dest, vfloat32mf2_t src, size_t offset, size_t vl);
vfloat32m1_t __riscv_vslideup_mu (vbool32_t mask, vfloat32m1_t dest, vfloat32m1_t src, size_t offset, size_t vl);
vfloat32m2_t __riscv_vslideup_mu (vbool16_t mask, vfloat32m2_t dest, vfloat32m2_t src, size_t offset, size_t vl);
vfloat32m4_t __riscv_vslideup_mu (vbool8_t mask, vfloat32m4_t dest, vfloat32m4_t src, size_t offset, size_t vl);
vfloat32m8_t __riscv_vslideup_mu (vbool4_t mask, vfloat32m8_t dest, vfloat32m8_t src, size_t offset, size_t vl);
vfloat64m1_t __riscv_vslideup_mu (vbool64_t mask, vfloat64m1_t dest, vfloat64m1_t src, size_t offset, size_t vl);
vfloat64m2_t __riscv_vslideup_mu (vbool32_t mask, vfloat64m2_t dest, vfloat64m2_t src, size_t offset, size_t vl);
vfloat64m4_t __riscv_vslideup_mu (vbool16_t mask, vfloat64m4_t dest, vfloat64m4_t src, size_t offset, size_t vl);
vfloat64m8_t __riscv_vslideup_mu (vbool8_t mask, vfloat64m8_t dest, vfloat64m8_t src, size_t offset, size_t vl);
vint8mf8_t __riscv_vslideup_mu (vbool64_t mask, vint8mf8_t dest, vint8mf8_t src, size_t offset, size_t vl);
vint8mf4_t __riscv_vslideup_mu (vbool32_t mask, vint8mf4_t dest, vint8mf4_t src, size_t offset, size_t vl);
vint8mf2_t __riscv_vslideup_mu (vbool16_t mask, vint8mf2_t dest, vint8mf2_t src, size_t offset, size_t vl);
vint8m1_t __riscv_vslideup_mu (vbool8_t mask, vint8m1_t dest, vint8m1_t src, size_t offset, size_t vl);
vint8m2_t __riscv_vslideup_mu (vbool4_t mask, vint8m2_t dest, vint8m2_t src, size_t offset, size_t vl);
vint8m4_t __riscv_vslideup_mu (vbool2_t mask, vint8m4_t dest, vint8m4_t src, size_t offset, size_t vl);
vint8m8_t __riscv_vslideup_mu (vbool1_t mask, vint8m8_t dest, vint8m8_t src, size_t offset, size_t vl);
vint16mf4_t __riscv_vslideup_mu (vbool64_t mask, vint16mf4_t dest, vint16mf4_t src, size_t offset, size_t vl);
vint16mf2_t __riscv_vslideup_mu (vbool32_t mask, vint16mf2_t dest, vint16mf2_t src, size_t offset, size_t vl);
vint16m1_t __riscv_vslideup_mu (vbool16_t mask, vint16m1_t dest, vint16m1_t src, size_t offset, size_t vl);
vint16m2_t __riscv_vslideup_mu (vbool8_t mask, vint16m2_t dest, vint16m2_t src, size_t offset, size_t vl);
vint16m4_t __riscv_vslideup_mu (vbool4_t mask, vint16m4_t dest, vint16m4_t src, size_t offset, size_t vl);
vint16m8_t __riscv_vslideup_mu (vbool2_t mask, vint16m8_t dest, vint16m8_t src, size_t offset, size_t vl);
vint32mf2_t __riscv_vslideup_mu (vbool64_t mask, vint32mf2_t dest, vint32mf2_t src, size_t offset, size_t vl);
vint32m1_t __riscv_vslideup_mu (vbool32_t mask, vint32m1_t dest, vint32m1_t src, size_t offset, size_t vl);
vint32m2_t __riscv_vslideup_mu (vbool16_t mask, vint32m2_t dest, vint32m2_t src, size_t offset, size_t vl);
vint32m4_t __riscv_vslideup_mu (vbool8_t mask, vint32m4_t dest, vint32m4_t src, size_t offset, size_t vl);
vint32m8_t __riscv_vslideup_mu (vbool4_t mask, vint32m8_t dest, vint32m8_t src, size_t offset, size_t vl);
vint64m1_t __riscv_vslideup_mu (vbool64_t mask, vint64m1_t dest, vint64m1_t src, size_t offset, size_t vl);
vint64m2_t __riscv_vslideup_mu (vbool32_t mask, vint64m2_t dest, vint64m2_t src, size_t offset, size_t vl);
vint64m4_t __riscv_vslideup_mu (vbool16_t mask, vint64m4_t dest, vint64m4_t src, size_t offset, size_t vl);
vint64m8_t __riscv_vslideup_mu (vbool8_t mask, vint64m8_t dest, vint64m8_t src, size_t offset, size_t vl);
vuint8mf8_t __riscv_vslideup_mu (vbool64_t mask, vuint8mf8_t dest, vuint8mf8_t src, size_t offset, size_t vl);
vuint8mf4_t __riscv_vslideup_mu (vbool32_t mask, vuint8mf4_t dest, vuint8mf4_t src, size_t offset, size_t vl);
vuint8mf2_t __riscv_vslideup_mu (vbool16_t mask, vuint8mf2_t dest, vuint8mf2_t src, size_t offset, size_t vl);
vuint8m1_t __riscv_vslideup_mu (vbool8_t mask, vuint8m1_t dest, vuint8m1_t src, size_t offset, size_t vl);
vuint8m2_t __riscv_vslideup_mu (vbool4_t mask, vuint8m2_t dest, vuint8m2_t src, size_t offset, size_t vl);
vuint8m4_t __riscv_vslideup_mu (vbool2_t mask, vuint8m4_t dest, vuint8m4_t src, size_t offset, size_t vl);
vuint8m8_t __riscv_vslideup_mu (vbool1_t mask, vuint8m8_t dest, vuint8m8_t src, size_t offset, size_t vl);
vuint16mf4_t __riscv_vslideup_mu (vbool64_t mask, vuint16mf4_t dest, vuint16mf4_t src, size_t offset, size_t vl);
vuint16mf2_t __riscv_vslideup_mu (vbool32_t mask, vuint16mf2_t dest, vuint16mf2_t src, size_t offset, size_t vl);
vuint16m1_t __riscv_vslideup_mu (vbool16_t mask, vuint16m1_t dest, vuint16m1_t src, size_t offset, size_t vl);
vuint16m2_t __riscv_vslideup_mu (vbool8_t mask, vuint16m2_t dest, vuint16m2_t src, size_t offset, size_t vl);
vuint16m4_t __riscv_vslideup_mu (vbool4_t mask, vuint16m4_t dest, vuint16m4_t src, size_t offset, size_t vl);
vuint16m8_t __riscv_vslideup_mu (vbool2_t mask, vuint16m8_t dest, vuint16m8_t src, size_t offset, size_t vl);
vuint32mf2_t __riscv_vslideup_mu (vbool64_t mask, vuint32mf2_t dest, vuint32mf2_t src, size_t offset, size_t vl);
vuint32m1_t __riscv_vslideup_mu (vbool32_t mask, vuint32m1_t dest, vuint32m1_t src, size_t offset, size_t vl);
vuint32m2_t __riscv_vslideup_mu (vbool16_t mask, vuint32m2_t dest, vuint32m2_t src, size_t offset, size_t vl);
vuint32m4_t __riscv_vslideup_mu (vbool8_t mask, vuint32m4_t dest, vuint32m4_t src, size_t offset, size_t vl);
vuint32m8_t __riscv_vslideup_mu (vbool4_t mask, vuint32m8_t dest, vuint32m8_t src, size_t offset, size_t vl);
vuint64m1_t __riscv_vslideup_mu (vbool64_t mask, vuint64m1_t dest, vuint64m1_t src, size_t offset, size_t vl);
vuint64m2_t __riscv_vslideup_mu (vbool32_t mask, vuint64m2_t dest, vuint64m2_t src, size_t offset, size_t vl);
vuint64m4_t __riscv_vslideup_mu (vbool16_t mask, vuint64m4_t dest, vuint64m4_t src, size_t offset, size_t vl);
vuint64m8_t __riscv_vslideup_mu (vbool8_t mask, vuint64m8_t dest, vuint64m8_t src, size_t offset, size_t vl);
```

[[policy-variant-overloadedvector-slidedown]]
=== Vector Slidedown Intrinsics

``` C
vfloat16mf4_t __riscv_vslidedown_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t src, size_t offset, size_t vl);
vfloat16mf2_t __riscv_vslidedown_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t src, size_t offset, size_t vl);
vfloat16m1_t __riscv_vslidedown_tu (vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset, size_t vl);
vfloat16m2_t __riscv_vslidedown_tu (vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset, size_t vl);
vfloat16m4_t __riscv_vslidedown_tu (vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset, size_t vl);
vfloat16m8_t __riscv_vslidedown_tu (vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset, size_t vl);
vfloat32mf2_t __riscv_vslidedown_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t src, size_t offset, size_t vl);
vfloat32m1_t __riscv_vslidedown_tu (vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset, size_t vl);
vfloat32m2_t __riscv_vslidedown_tu (vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset, size_t vl);
vfloat32m4_t __riscv_vslidedown_tu (vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset, size_t vl);
vfloat32m8_t __riscv_vslidedown_tu (vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset, size_t vl);
vfloat64m1_t __riscv_vslidedown_tu (vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset, size_t vl);
vfloat64m2_t __riscv_vslidedown_tu (vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset, size_t vl);
vfloat64m4_t __riscv_vslidedown_tu (vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset, size_t vl);
vfloat64m8_t __riscv_vslidedown_tu (vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset, size_t vl);
vint8mf8_t __riscv_vslidedown_tu (vint8mf8_t maskedoff, vint8mf8_t src, size_t offset, size_t vl);
vint8mf4_t __riscv_vslidedown_tu (vint8mf4_t maskedoff, vint8mf4_t src, size_t offset, size_t vl);
vint8mf2_t __riscv_vslidedown_tu (vint8mf2_t maskedoff, vint8mf2_t src, size_t offset, size_t vl);
vint8m1_t __riscv_vslidedown_tu (vint8m1_t maskedoff, vint8m1_t src, size_t offset, size_t vl);
vint8m2_t __riscv_vslidedown_tu (vint8m2_t maskedoff, vint8m2_t src, size_t offset, size_t vl);
vint8m4_t __riscv_vslidedown_tu (vint8m4_t maskedoff, vint8m4_t src, size_t offset, size_t vl);
vint8m8_t __riscv_vslidedown_tu (vint8m8_t maskedoff, vint8m8_t src, size_t offset, size_t vl);
vint16mf4_t __riscv_vslidedown_tu (vint16mf4_t maskedoff, vint16mf4_t src, size_t offset, size_t vl);
vint16mf2_t __riscv_vslidedown_tu (vint16mf2_t maskedoff, vint16mf2_t src, size_t offset, size_t vl);
vint16m1_t __riscv_vslidedown_tu (vint16m1_t maskedoff, vint16m1_t src, size_t offset, size_t vl);
vint16m2_t __riscv_vslidedown_tu (vint16m2_t maskedoff, vint16m2_t src, size_t offset, size_t vl);
vint16m4_t __riscv_vslidedown_tu (vint16m4_t maskedoff, vint16m4_t src, size_t offset, size_t vl);
vint16m8_t __riscv_vslidedown_tu (vint16m8_t maskedoff, vint16m8_t src, size_t offset, size_t vl);
vint32mf2_t __riscv_vslidedown_tu (vint32mf2_t maskedoff, vint32mf2_t src, size_t offset, size_t vl);
vint32m1_t __riscv_vslidedown_tu (vint32m1_t maskedoff, vint32m1_t src, size_t offset, size_t vl);
vint32m2_t __riscv_vslidedown_tu (vint32m2_t maskedoff, vint32m2_t src, size_t offset, size_t vl);
vint32m4_t __riscv_vslidedown_tu (vint32m4_t maskedoff, vint32m4_t src, size_t offset, size_t vl);
vint32m8_t __riscv_vslidedown_tu (vint32m8_t maskedoff, vint32m8_t src, size_t offset, size_t vl);
vint64m1_t __riscv_vslidedown_tu (vint64m1_t maskedoff, vint64m1_t src, size_t offset, size_t vl);
vint64m2_t __riscv_vslidedown_tu (vint64m2_t maskedoff, vint64m2_t src, size_t offset, size_t vl);
vint64m4_t __riscv_vslidedown_tu (vint64m4_t maskedoff, vint64m4_t src, size_t offset, size_t vl);
vint64m8_t __riscv_vslidedown_tu (vint64m8_t maskedoff, vint64m8_t src, size_t offset, size_t vl);
vuint8mf8_t __riscv_vslidedown_tu (vuint8mf8_t maskedoff, vuint8mf8_t src, size_t offset, size_t vl);
vuint8mf4_t __riscv_vslidedown_tu (vuint8mf4_t maskedoff, vuint8mf4_t src, size_t offset, size_t vl);
vuint8mf2_t __riscv_vslidedown_tu (vuint8mf2_t maskedoff, vuint8mf2_t src, size_t offset, size_t vl);
vuint8m1_t __riscv_vslidedown_tu (vuint8m1_t maskedoff, vuint8m1_t src, size_t offset, size_t vl);
vuint8m2_t __riscv_vslidedown_tu (vuint8m2_t maskedoff, vuint8m2_t src, size_t offset, size_t vl);
vuint8m4_t __riscv_vslidedown_tu (vuint8m4_t maskedoff, vuint8m4_t src, size_t offset, size_t vl);
vuint8m8_t __riscv_vslidedown_tu (vuint8m8_t maskedoff, vuint8m8_t src, size_t offset, size_t vl);
vuint16mf4_t __riscv_vslidedown_tu (vuint16mf4_t maskedoff, vuint16mf4_t src, size_t offset, size_t vl);
vuint16mf2_t __riscv_vslidedown_tu (vuint16mf2_t maskedoff, vuint16mf2_t src, size_t offset, size_t vl);
vuint16m1_t __riscv_vslidedown_tu (vuint16m1_t maskedoff, vuint16m1_t src, size_t offset, size_t vl);
vuint16m2_t __riscv_vslidedown_tu (vuint16m2_t maskedoff, vuint16m2_t src, size_t offset, size_t vl);
vuint16m4_t __riscv_vslidedown_tu (vuint16m4_t maskedoff, vuint16m4_t src, size_t offset, size_t vl);
vuint16m8_t __riscv_vslidedown_tu (vuint16m8_t maskedoff, vuint16m8_t src, size_t offset, size_t vl);
vuint32mf2_t __riscv_vslidedown_tu (vuint32mf2_t maskedoff, vuint32mf2_t src, size_t offset, size_t vl);
vuint32m1_t __riscv_vslidedown_tu (vuint32m1_t maskedoff, vuint32m1_t src, size_t offset, size_t vl);
vuint32m2_t __riscv_vslidedown_tu (vuint32m2_t maskedoff, vuint32m2_t src, size_t offset, size_t vl);
vuint32m4_t __riscv_vslidedown_tu (vuint32m4_t maskedoff, vuint32m4_t src, size_t offset, size_t vl);
vuint32m8_t __riscv_vslidedown_tu (vuint32m8_t maskedoff, vuint32m8_t src, size_t offset, size_t vl);
vuint64m1_t __riscv_vslidedown_tu (vuint64m1_t maskedoff, vuint64m1_t src, size_t offset, size_t vl);
vuint64m2_t __riscv_vslidedown_tu (vuint64m2_t maskedoff, vuint64m2_t src, size_t offset, size_t vl);
vuint64m4_t __riscv_vslidedown_tu (vuint64m4_t maskedoff, vuint64m4_t src, size_t offset, size_t vl);
vuint64m8_t __riscv_vslidedown_tu (vuint64m8_t maskedoff, vuint64m8_t src, size_t offset, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vslidedown_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t src, size_t offset, size_t vl);
vfloat16mf2_t __riscv_vslidedown_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t src, size_t offset, size_t vl);
vfloat16m1_t __riscv_vslidedown_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset, size_t vl);
vfloat16m2_t __riscv_vslidedown_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset, size_t vl);
vfloat16m4_t __riscv_vslidedown_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset, size_t vl);
vfloat16m8_t __riscv_vslidedown_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset, size_t vl);
vfloat32mf2_t __riscv_vslidedown_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t src, size_t offset, size_t vl);
vfloat32m1_t __riscv_vslidedown_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset, size_t vl);
vfloat32m2_t __riscv_vslidedown_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset, size_t vl);
vfloat32m4_t __riscv_vslidedown_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset, size_t vl);
vfloat32m8_t __riscv_vslidedown_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset, size_t vl);
vfloat64m1_t __riscv_vslidedown_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset, size_t vl);
vfloat64m2_t __riscv_vslidedown_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset, size_t vl);
vfloat64m4_t __riscv_vslidedown_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset, size_t vl);
vfloat64m8_t __riscv_vslidedown_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset, size_t vl);
vint8mf8_t __riscv_vslidedown_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t src, size_t offset, size_t vl);
vint8mf4_t __riscv_vslidedown_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t src, size_t offset, size_t vl);
vint8mf2_t __riscv_vslidedown_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t src, size_t offset, size_t vl);
vint8m1_t __riscv_vslidedown_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset, size_t vl);
vint8m2_t __riscv_vslidedown_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset, size_t vl);
vint8m4_t __riscv_vslidedown_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset, size_t vl);
vint8m8_t __riscv_vslidedown_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset, size_t vl);
vint16mf4_t __riscv_vslidedown_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t src, size_t offset, size_t vl);
vint16mf2_t __riscv_vslidedown_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t src, size_t offset, size_t vl);
vint16m1_t __riscv_vslidedown_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset, size_t vl);
vint16m2_t __riscv_vslidedown_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset, size_t vl);
vint16m4_t __riscv_vslidedown_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset, size_t vl);
vint16m8_t __riscv_vslidedown_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset, size_t vl);
vint32mf2_t __riscv_vslidedown_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t src, size_t offset, size_t vl);
vint32m1_t __riscv_vslidedown_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset, size_t vl);
vint32m2_t __riscv_vslidedown_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset, size_t vl);
vint32m4_t __riscv_vslidedown_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset, size_t vl);
vint32m8_t __riscv_vslidedown_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset, size_t vl);
vint64m1_t __riscv_vslidedown_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset, size_t vl);
vint64m2_t __riscv_vslidedown_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset, size_t vl);
vint64m4_t __riscv_vslidedown_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset, size_t vl);
vint64m8_t __riscv_vslidedown_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset, size_t vl);
vuint8mf8_t __riscv_vslidedown_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t src, size_t offset, size_t vl);
vuint8mf4_t __riscv_vslidedown_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t src, size_t offset, size_t vl);
vuint8mf2_t __riscv_vslidedown_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t src, size_t offset, size_t vl);
vuint8m1_t __riscv_vslidedown_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset, size_t vl);
vuint8m2_t __riscv_vslidedown_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset, size_t vl);
vuint8m4_t __riscv_vslidedown_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset, size_t vl);
vuint8m8_t __riscv_vslidedown_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset, size_t vl);
vuint16mf4_t __riscv_vslidedown_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t src, size_t offset, size_t vl);
vuint16mf2_t __riscv_vslidedown_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t src, size_t offset, size_t vl);
vuint16m1_t __riscv_vslidedown_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset, size_t vl);
vuint16m2_t __riscv_vslidedown_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset, size_t vl);
vuint16m4_t __riscv_vslidedown_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset, size_t vl);
vuint16m8_t __riscv_vslidedown_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset, size_t vl);
vuint32mf2_t __riscv_vslidedown_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t src, size_t offset, size_t vl);
vuint32m1_t __riscv_vslidedown_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset, size_t vl);
vuint32m2_t __riscv_vslidedown_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset, size_t vl);
vuint32m4_t __riscv_vslidedown_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset, size_t vl);
vuint32m8_t __riscv_vslidedown_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset, size_t vl);
vuint64m1_t __riscv_vslidedown_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset, size_t vl);
vuint64m2_t __riscv_vslidedown_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset, size_t vl);
vuint64m4_t __riscv_vslidedown_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset, size_t vl);
vuint64m8_t __riscv_vslidedown_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vslidedown_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t src, size_t offset, size_t vl);
vfloat16mf2_t __riscv_vslidedown_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t src, size_t offset, size_t vl);
vfloat16m1_t __riscv_vslidedown_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset, size_t vl);
vfloat16m2_t __riscv_vslidedown_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset, size_t vl);
vfloat16m4_t __riscv_vslidedown_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset, size_t vl);
vfloat16m8_t __riscv_vslidedown_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset, size_t vl);
vfloat32mf2_t __riscv_vslidedown_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t src, size_t offset, size_t vl);
vfloat32m1_t __riscv_vslidedown_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset, size_t vl);
vfloat32m2_t __riscv_vslidedown_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset, size_t vl);
vfloat32m4_t __riscv_vslidedown_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset, size_t vl);
vfloat32m8_t __riscv_vslidedown_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset, size_t vl);
vfloat64m1_t __riscv_vslidedown_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset, size_t vl);
vfloat64m2_t __riscv_vslidedown_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset, size_t vl);
vfloat64m4_t __riscv_vslidedown_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset, size_t vl);
vfloat64m8_t __riscv_vslidedown_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset, size_t vl);
vint8mf8_t __riscv_vslidedown_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t src, size_t offset, size_t vl);
vint8mf4_t __riscv_vslidedown_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t src, size_t offset, size_t vl);
vint8mf2_t __riscv_vslidedown_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t src, size_t offset, size_t vl);
vint8m1_t __riscv_vslidedown_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset, size_t vl);
vint8m2_t __riscv_vslidedown_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset, size_t vl);
vint8m4_t __riscv_vslidedown_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset, size_t vl);
vint8m8_t __riscv_vslidedown_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset, size_t vl);
vint16mf4_t __riscv_vslidedown_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t src, size_t offset, size_t vl);
vint16mf2_t __riscv_vslidedown_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t src, size_t offset, size_t vl);
vint16m1_t __riscv_vslidedown_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset, size_t vl);
vint16m2_t __riscv_vslidedown_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset, size_t vl);
vint16m4_t __riscv_vslidedown_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset, size_t vl);
vint16m8_t __riscv_vslidedown_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset, size_t vl);
vint32mf2_t __riscv_vslidedown_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t src, size_t offset, size_t vl);
vint32m1_t __riscv_vslidedown_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset, size_t vl);
vint32m2_t __riscv_vslidedown_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset, size_t vl);
vint32m4_t __riscv_vslidedown_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset, size_t vl);
vint32m8_t __riscv_vslidedown_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset, size_t vl);
vint64m1_t __riscv_vslidedown_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset, size_t vl);
vint64m2_t __riscv_vslidedown_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset, size_t vl);
vint64m4_t __riscv_vslidedown_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset, size_t vl);
vint64m8_t __riscv_vslidedown_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset, size_t vl);
vuint8mf8_t __riscv_vslidedown_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t src, size_t offset, size_t vl);
vuint8mf4_t __riscv_vslidedown_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t src, size_t offset, size_t vl);
vuint8mf2_t __riscv_vslidedown_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t src, size_t offset, size_t vl);
vuint8m1_t __riscv_vslidedown_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset, size_t vl);
vuint8m2_t __riscv_vslidedown_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset, size_t vl);
vuint8m4_t __riscv_vslidedown_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset, size_t vl);
vuint8m8_t __riscv_vslidedown_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset, size_t vl);
vuint16mf4_t __riscv_vslidedown_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t src, size_t offset, size_t vl);
vuint16mf2_t __riscv_vslidedown_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t src, size_t offset, size_t vl);
vuint16m1_t __riscv_vslidedown_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset, size_t vl);
vuint16m2_t __riscv_vslidedown_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset, size_t vl);
vuint16m4_t __riscv_vslidedown_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset, size_t vl);
vuint16m8_t __riscv_vslidedown_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset, size_t vl);
vuint32mf2_t __riscv_vslidedown_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t src, size_t offset, size_t vl);
vuint32m1_t __riscv_vslidedown_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset, size_t vl);
vuint32m2_t __riscv_vslidedown_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset, size_t vl);
vuint32m4_t __riscv_vslidedown_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset, size_t vl);
vuint32m8_t __riscv_vslidedown_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset, size_t vl);
vuint64m1_t __riscv_vslidedown_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset, size_t vl);
vuint64m2_t __riscv_vslidedown_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset, size_t vl);
vuint64m4_t __riscv_vslidedown_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset, size_t vl);
vuint64m8_t __riscv_vslidedown_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vslidedown_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t src, size_t offset, size_t vl);
vfloat16mf2_t __riscv_vslidedown_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t src, size_t offset, size_t vl);
vfloat16m1_t __riscv_vslidedown_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset, size_t vl);
vfloat16m2_t __riscv_vslidedown_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset, size_t vl);
vfloat16m4_t __riscv_vslidedown_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset, size_t vl);
vfloat16m8_t __riscv_vslidedown_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset, size_t vl);
vfloat32mf2_t __riscv_vslidedown_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t src, size_t offset, size_t vl);
vfloat32m1_t __riscv_vslidedown_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset, size_t vl);
vfloat32m2_t __riscv_vslidedown_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset, size_t vl);
vfloat32m4_t __riscv_vslidedown_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset, size_t vl);
vfloat32m8_t __riscv_vslidedown_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset, size_t vl);
vfloat64m1_t __riscv_vslidedown_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset, size_t vl);
vfloat64m2_t __riscv_vslidedown_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset, size_t vl);
vfloat64m4_t __riscv_vslidedown_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset, size_t vl);
vfloat64m8_t __riscv_vslidedown_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset, size_t vl);
vint8mf8_t __riscv_vslidedown_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t src, size_t offset, size_t vl);
vint8mf4_t __riscv_vslidedown_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t src, size_t offset, size_t vl);
vint8mf2_t __riscv_vslidedown_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t src, size_t offset, size_t vl);
vint8m1_t __riscv_vslidedown_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset, size_t vl);
vint8m2_t __riscv_vslidedown_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset, size_t vl);
vint8m4_t __riscv_vslidedown_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset, size_t vl);
vint8m8_t __riscv_vslidedown_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset, size_t vl);
vint16mf4_t __riscv_vslidedown_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t src, size_t offset, size_t vl);
vint16mf2_t __riscv_vslidedown_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t src, size_t offset, size_t vl);
vint16m1_t __riscv_vslidedown_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset, size_t vl);
vint16m2_t __riscv_vslidedown_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset, size_t vl);
vint16m4_t __riscv_vslidedown_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset, size_t vl);
vint16m8_t __riscv_vslidedown_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset, size_t vl);
vint32mf2_t __riscv_vslidedown_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t src, size_t offset, size_t vl);
vint32m1_t __riscv_vslidedown_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset, size_t vl);
vint32m2_t __riscv_vslidedown_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset, size_t vl);
vint32m4_t __riscv_vslidedown_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset, size_t vl);
vint32m8_t __riscv_vslidedown_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset, size_t vl);
vint64m1_t __riscv_vslidedown_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset, size_t vl);
vint64m2_t __riscv_vslidedown_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset, size_t vl);
vint64m4_t __riscv_vslidedown_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset, size_t vl);
vint64m8_t __riscv_vslidedown_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset, size_t vl);
vuint8mf8_t __riscv_vslidedown_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t src, size_t offset, size_t vl);
vuint8mf4_t __riscv_vslidedown_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t src, size_t offset, size_t vl);
vuint8mf2_t __riscv_vslidedown_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t src, size_t offset, size_t vl);
vuint8m1_t __riscv_vslidedown_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset, size_t vl);
vuint8m2_t __riscv_vslidedown_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset, size_t vl);
vuint8m4_t __riscv_vslidedown_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset, size_t vl);
vuint8m8_t __riscv_vslidedown_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset, size_t vl);
vuint16mf4_t __riscv_vslidedown_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t src, size_t offset, size_t vl);
vuint16mf2_t __riscv_vslidedown_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t src, size_t offset, size_t vl);
vuint16m1_t __riscv_vslidedown_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset, size_t vl);
vuint16m2_t __riscv_vslidedown_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset, size_t vl);
vuint16m4_t __riscv_vslidedown_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset, size_t vl);
vuint16m8_t __riscv_vslidedown_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset, size_t vl);
vuint32mf2_t __riscv_vslidedown_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t src, size_t offset, size_t vl);
vuint32m1_t __riscv_vslidedown_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset, size_t vl);
vuint32m2_t __riscv_vslidedown_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset, size_t vl);
vuint32m4_t __riscv_vslidedown_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset, size_t vl);
vuint32m8_t __riscv_vslidedown_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset, size_t vl);
vuint64m1_t __riscv_vslidedown_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset, size_t vl);
vuint64m2_t __riscv_vslidedown_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset, size_t vl);
vuint64m4_t __riscv_vslidedown_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset, size_t vl);
vuint64m8_t __riscv_vslidedown_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset, size_t vl);
```

[[policy-variant-overloadedvector-slide1up-and-slide1down]]
=== Vector Slide1up and Slide1down Intrinsics

``` C
vfloat16mf4_t __riscv_vfslide1up_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t src, float16_t value, size_t vl);
vfloat16mf2_t __riscv_vfslide1up_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t src, float16_t value, size_t vl);
vfloat16m1_t __riscv_vfslide1up_tu (vfloat16m1_t maskedoff, vfloat16m1_t src, float16_t value, size_t vl);
vfloat16m2_t __riscv_vfslide1up_tu (vfloat16m2_t maskedoff, vfloat16m2_t src, float16_t value, size_t vl);
vfloat16m4_t __riscv_vfslide1up_tu (vfloat16m4_t maskedoff, vfloat16m4_t src, float16_t value, size_t vl);
vfloat16m8_t __riscv_vfslide1up_tu (vfloat16m8_t maskedoff, vfloat16m8_t src, float16_t value, size_t vl);
vfloat32mf2_t __riscv_vfslide1up_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t src, float32_t value, size_t vl);
vfloat32m1_t __riscv_vfslide1up_tu (vfloat32m1_t maskedoff, vfloat32m1_t src, float32_t value, size_t vl);
vfloat32m2_t __riscv_vfslide1up_tu (vfloat32m2_t maskedoff, vfloat32m2_t src, float32_t value, size_t vl);
vfloat32m4_t __riscv_vfslide1up_tu (vfloat32m4_t maskedoff, vfloat32m4_t src, float32_t value, size_t vl);
vfloat32m8_t __riscv_vfslide1up_tu (vfloat32m8_t maskedoff, vfloat32m8_t src, float32_t value, size_t vl);
vfloat64m1_t __riscv_vfslide1up_tu (vfloat64m1_t maskedoff, vfloat64m1_t src, float64_t value, size_t vl);
vfloat64m2_t __riscv_vfslide1up_tu (vfloat64m2_t maskedoff, vfloat64m2_t src, float64_t value, size_t vl);
vfloat64m4_t __riscv_vfslide1up_tu (vfloat64m4_t maskedoff, vfloat64m4_t src, float64_t value, size_t vl);
vfloat64m8_t __riscv_vfslide1up_tu (vfloat64m8_t maskedoff, vfloat64m8_t src, float64_t value, size_t vl);
vfloat16mf4_t __riscv_vfslide1down_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t src, float16_t value, size_t vl);
vfloat16mf2_t __riscv_vfslide1down_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t src, float16_t value, size_t vl);
vfloat16m1_t __riscv_vfslide1down_tu (vfloat16m1_t maskedoff, vfloat16m1_t src, float16_t value, size_t vl);
vfloat16m2_t __riscv_vfslide1down_tu (vfloat16m2_t maskedoff, vfloat16m2_t src, float16_t value, size_t vl);
vfloat16m4_t __riscv_vfslide1down_tu (vfloat16m4_t maskedoff, vfloat16m4_t src, float16_t value, size_t vl);
vfloat16m8_t __riscv_vfslide1down_tu (vfloat16m8_t maskedoff, vfloat16m8_t src, float16_t value, size_t vl);
vfloat32mf2_t __riscv_vfslide1down_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t src, float32_t value, size_t vl);
vfloat32m1_t __riscv_vfslide1down_tu (vfloat32m1_t maskedoff, vfloat32m1_t src, float32_t value, size_t vl);
vfloat32m2_t __riscv_vfslide1down_tu (vfloat32m2_t maskedoff, vfloat32m2_t src, float32_t value, size_t vl);
vfloat32m4_t __riscv_vfslide1down_tu (vfloat32m4_t maskedoff, vfloat32m4_t src, float32_t value, size_t vl);
vfloat32m8_t __riscv_vfslide1down_tu (vfloat32m8_t maskedoff, vfloat32m8_t src, float32_t value, size_t vl);
vfloat64m1_t __riscv_vfslide1down_tu (vfloat64m1_t maskedoff, vfloat64m1_t src, float64_t value, size_t vl);
vfloat64m2_t __riscv_vfslide1down_tu (vfloat64m2_t maskedoff, vfloat64m2_t src, float64_t value, size_t vl);
vfloat64m4_t __riscv_vfslide1down_tu (vfloat64m4_t maskedoff, vfloat64m4_t src, float64_t value, size_t vl);
vfloat64m8_t __riscv_vfslide1down_tu (vfloat64m8_t maskedoff, vfloat64m8_t src, float64_t value, size_t vl);
vint8mf8_t __riscv_vslide1up_tu (vint8mf8_t maskedoff, vint8mf8_t src, int8_t value, size_t vl);
vint8mf4_t __riscv_vslide1up_tu (vint8mf4_t maskedoff, vint8mf4_t src, int8_t value, size_t vl);
vint8mf2_t __riscv_vslide1up_tu (vint8mf2_t maskedoff, vint8mf2_t src, int8_t value, size_t vl);
vint8m1_t __riscv_vslide1up_tu (vint8m1_t maskedoff, vint8m1_t src, int8_t value, size_t vl);
vint8m2_t __riscv_vslide1up_tu (vint8m2_t maskedoff, vint8m2_t src, int8_t value, size_t vl);
vint8m4_t __riscv_vslide1up_tu (vint8m4_t maskedoff, vint8m4_t src, int8_t value, size_t vl);
vint8m8_t __riscv_vslide1up_tu (vint8m8_t maskedoff, vint8m8_t src, int8_t value, size_t vl);
vint16mf4_t __riscv_vslide1up_tu (vint16mf4_t maskedoff, vint16mf4_t src, int16_t value, size_t vl);
vint16mf2_t __riscv_vslide1up_tu (vint16mf2_t maskedoff, vint16mf2_t src, int16_t value, size_t vl);
vint16m1_t __riscv_vslide1up_tu (vint16m1_t maskedoff, vint16m1_t src, int16_t value, size_t vl);
vint16m2_t __riscv_vslide1up_tu (vint16m2_t maskedoff, vint16m2_t src, int16_t value, size_t vl);
vint16m4_t __riscv_vslide1up_tu (vint16m4_t maskedoff, vint16m4_t src, int16_t value, size_t vl);
vint16m8_t __riscv_vslide1up_tu (vint16m8_t maskedoff, vint16m8_t src, int16_t value, size_t vl);
vint32mf2_t __riscv_vslide1up_tu (vint32mf2_t maskedoff, vint32mf2_t src, int32_t value, size_t vl);
vint32m1_t __riscv_vslide1up_tu (vint32m1_t maskedoff, vint32m1_t src, int32_t value, size_t vl);
vint32m2_t __riscv_vslide1up_tu (vint32m2_t maskedoff, vint32m2_t src, int32_t value, size_t vl);
vint32m4_t __riscv_vslide1up_tu (vint32m4_t maskedoff, vint32m4_t src, int32_t value, size_t vl);
vint32m8_t __riscv_vslide1up_tu (vint32m8_t maskedoff, vint32m8_t src, int32_t value, size_t vl);
vint64m1_t __riscv_vslide1up_tu (vint64m1_t maskedoff, vint64m1_t src, int64_t value, size_t vl);
vint64m2_t __riscv_vslide1up_tu (vint64m2_t maskedoff, vint64m2_t src, int64_t value, size_t vl);
vint64m4_t __riscv_vslide1up_tu (vint64m4_t maskedoff, vint64m4_t src, int64_t value, size_t vl);
vint64m8_t __riscv_vslide1up_tu (vint64m8_t maskedoff, vint64m8_t src, int64_t value, size_t vl);
vint8mf8_t __riscv_vslide1down_tu (vint8mf8_t maskedoff, vint8mf8_t src, int8_t value, size_t vl);
vint8mf4_t __riscv_vslide1down_tu (vint8mf4_t maskedoff, vint8mf4_t src, int8_t value, size_t vl);
vint8mf2_t __riscv_vslide1down_tu (vint8mf2_t maskedoff, vint8mf2_t src, int8_t value, size_t vl);
vint8m1_t __riscv_vslide1down_tu (vint8m1_t maskedoff, vint8m1_t src, int8_t value, size_t vl);
vint8m2_t __riscv_vslide1down_tu (vint8m2_t maskedoff, vint8m2_t src, int8_t value, size_t vl);
vint8m4_t __riscv_vslide1down_tu (vint8m4_t maskedoff, vint8m4_t src, int8_t value, size_t vl);
vint8m8_t __riscv_vslide1down_tu (vint8m8_t maskedoff, vint8m8_t src, int8_t value, size_t vl);
vint16mf4_t __riscv_vslide1down_tu (vint16mf4_t maskedoff, vint16mf4_t src, int16_t value, size_t vl);
vint16mf2_t __riscv_vslide1down_tu (vint16mf2_t maskedoff, vint16mf2_t src, int16_t value, size_t vl);
vint16m1_t __riscv_vslide1down_tu (vint16m1_t maskedoff, vint16m1_t src, int16_t value, size_t vl);
vint16m2_t __riscv_vslide1down_tu (vint16m2_t maskedoff, vint16m2_t src, int16_t value, size_t vl);
vint16m4_t __riscv_vslide1down_tu (vint16m4_t maskedoff, vint16m4_t src, int16_t value, size_t vl);
vint16m8_t __riscv_vslide1down_tu (vint16m8_t maskedoff, vint16m8_t src, int16_t value, size_t vl);
vint32mf2_t __riscv_vslide1down_tu (vint32mf2_t maskedoff, vint32mf2_t src, int32_t value, size_t vl);
vint32m1_t __riscv_vslide1down_tu (vint32m1_t maskedoff, vint32m1_t src, int32_t value, size_t vl);
vint32m2_t __riscv_vslide1down_tu (vint32m2_t maskedoff, vint32m2_t src, int32_t value, size_t vl);
vint32m4_t __riscv_vslide1down_tu (vint32m4_t maskedoff, vint32m4_t src, int32_t value, size_t vl);
vint32m8_t __riscv_vslide1down_tu (vint32m8_t maskedoff, vint32m8_t src, int32_t value, size_t vl);
vint64m1_t __riscv_vslide1down_tu (vint64m1_t maskedoff, vint64m1_t src, int64_t value, size_t vl);
vint64m2_t __riscv_vslide1down_tu (vint64m2_t maskedoff, vint64m2_t src, int64_t value, size_t vl);
vint64m4_t __riscv_vslide1down_tu (vint64m4_t maskedoff, vint64m4_t src, int64_t value, size_t vl);
vint64m8_t __riscv_vslide1down_tu (vint64m8_t maskedoff, vint64m8_t src, int64_t value, size_t vl);
vuint8mf8_t __riscv_vslide1up_tu (vuint8mf8_t maskedoff, vuint8mf8_t src, uint8_t value, size_t vl);
vuint8mf4_t __riscv_vslide1up_tu (vuint8mf4_t maskedoff, vuint8mf4_t src, uint8_t value, size_t vl);
vuint8mf2_t __riscv_vslide1up_tu (vuint8mf2_t maskedoff, vuint8mf2_t src, uint8_t value, size_t vl);
vuint8m1_t __riscv_vslide1up_tu (vuint8m1_t maskedoff, vuint8m1_t src, uint8_t value, size_t vl);
vuint8m2_t __riscv_vslide1up_tu (vuint8m2_t maskedoff, vuint8m2_t src, uint8_t value, size_t vl);
vuint8m4_t __riscv_vslide1up_tu (vuint8m4_t maskedoff, vuint8m4_t src, uint8_t value, size_t vl);
vuint8m8_t __riscv_vslide1up_tu (vuint8m8_t maskedoff, vuint8m8_t src, uint8_t value, size_t vl);
vuint16mf4_t __riscv_vslide1up_tu (vuint16mf4_t maskedoff, vuint16mf4_t src, uint16_t value, size_t vl);
vuint16mf2_t __riscv_vslide1up_tu (vuint16mf2_t maskedoff, vuint16mf2_t src, uint16_t value, size_t vl);
vuint16m1_t __riscv_vslide1up_tu (vuint16m1_t maskedoff, vuint16m1_t src, uint16_t value, size_t vl);
vuint16m2_t __riscv_vslide1up_tu (vuint16m2_t maskedoff, vuint16m2_t src, uint16_t value, size_t vl);
vuint16m4_t __riscv_vslide1up_tu (vuint16m4_t maskedoff, vuint16m4_t src, uint16_t value, size_t vl);
vuint16m8_t __riscv_vslide1up_tu (vuint16m8_t maskedoff, vuint16m8_t src, uint16_t value, size_t vl);
vuint32mf2_t __riscv_vslide1up_tu (vuint32mf2_t maskedoff, vuint32mf2_t src, uint32_t value, size_t vl);
vuint32m1_t __riscv_vslide1up_tu (vuint32m1_t maskedoff, vuint32m1_t src, uint32_t value, size_t vl);
vuint32m2_t __riscv_vslide1up_tu (vuint32m2_t maskedoff, vuint32m2_t src, uint32_t value, size_t vl);
vuint32m4_t __riscv_vslide1up_tu (vuint32m4_t maskedoff, vuint32m4_t src, uint32_t value, size_t vl);
vuint32m8_t __riscv_vslide1up_tu (vuint32m8_t maskedoff, vuint32m8_t src, uint32_t value, size_t vl);
vuint64m1_t __riscv_vslide1up_tu (vuint64m1_t maskedoff, vuint64m1_t src, uint64_t value, size_t vl);
vuint64m2_t __riscv_vslide1up_tu (vuint64m2_t maskedoff, vuint64m2_t src, uint64_t value, size_t vl);
vuint64m4_t __riscv_vslide1up_tu (vuint64m4_t maskedoff, vuint64m4_t src, uint64_t value, size_t vl);
vuint64m8_t __riscv_vslide1up_tu (vuint64m8_t maskedoff, vuint64m8_t src, uint64_t value, size_t vl);
vuint8mf8_t __riscv_vslide1down_tu (vuint8mf8_t maskedoff, vuint8mf8_t src, uint8_t value, size_t vl);
vuint8mf4_t __riscv_vslide1down_tu (vuint8mf4_t maskedoff, vuint8mf4_t src, uint8_t value, size_t vl);
vuint8mf2_t __riscv_vslide1down_tu (vuint8mf2_t maskedoff, vuint8mf2_t src, uint8_t value, size_t vl);
vuint8m1_t __riscv_vslide1down_tu (vuint8m1_t maskedoff, vuint8m1_t src, uint8_t value, size_t vl);
vuint8m2_t __riscv_vslide1down_tu (vuint8m2_t maskedoff, vuint8m2_t src, uint8_t value, size_t vl);
vuint8m4_t __riscv_vslide1down_tu (vuint8m4_t maskedoff, vuint8m4_t src, uint8_t value, size_t vl);
vuint8m8_t __riscv_vslide1down_tu (vuint8m8_t maskedoff, vuint8m8_t src, uint8_t value, size_t vl);
vuint16mf4_t __riscv_vslide1down_tu (vuint16mf4_t maskedoff, vuint16mf4_t src, uint16_t value, size_t vl);
vuint16mf2_t __riscv_vslide1down_tu (vuint16mf2_t maskedoff, vuint16mf2_t src, uint16_t value, size_t vl);
vuint16m1_t __riscv_vslide1down_tu (vuint16m1_t maskedoff, vuint16m1_t src, uint16_t value, size_t vl);
vuint16m2_t __riscv_vslide1down_tu (vuint16m2_t maskedoff, vuint16m2_t src, uint16_t value, size_t vl);
vuint16m4_t __riscv_vslide1down_tu (vuint16m4_t maskedoff, vuint16m4_t src, uint16_t value, size_t vl);
vuint16m8_t __riscv_vslide1down_tu (vuint16m8_t maskedoff, vuint16m8_t src, uint16_t value, size_t vl);
vuint32mf2_t __riscv_vslide1down_tu (vuint32mf2_t maskedoff, vuint32mf2_t src, uint32_t value, size_t vl);
vuint32m1_t __riscv_vslide1down_tu (vuint32m1_t maskedoff, vuint32m1_t src, uint32_t value, size_t vl);
vuint32m2_t __riscv_vslide1down_tu (vuint32m2_t maskedoff, vuint32m2_t src, uint32_t value, size_t vl);
vuint32m4_t __riscv_vslide1down_tu (vuint32m4_t maskedoff, vuint32m4_t src, uint32_t value, size_t vl);
vuint32m8_t __riscv_vslide1down_tu (vuint32m8_t maskedoff, vuint32m8_t src, uint32_t value, size_t vl);
vuint64m1_t __riscv_vslide1down_tu (vuint64m1_t maskedoff, vuint64m1_t src, uint64_t value, size_t vl);
vuint64m2_t __riscv_vslide1down_tu (vuint64m2_t maskedoff, vuint64m2_t src, uint64_t value, size_t vl);
vuint64m4_t __riscv_vslide1down_tu (vuint64m4_t maskedoff, vuint64m4_t src, uint64_t value, size_t vl);
vuint64m8_t __riscv_vslide1down_tu (vuint64m8_t maskedoff, vuint64m8_t src, uint64_t value, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfslide1up_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t src, float16_t value, size_t vl);
vfloat16mf2_t __riscv_vfslide1up_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t src, float16_t value, size_t vl);
vfloat16m1_t __riscv_vfslide1up_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, float16_t value, size_t vl);
vfloat16m2_t __riscv_vfslide1up_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, float16_t value, size_t vl);
vfloat16m4_t __riscv_vfslide1up_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, float16_t value, size_t vl);
vfloat16m8_t __riscv_vfslide1up_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, float16_t value, size_t vl);
vfloat32mf2_t __riscv_vfslide1up_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t src, float32_t value, size_t vl);
vfloat32m1_t __riscv_vfslide1up_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, float32_t value, size_t vl);
vfloat32m2_t __riscv_vfslide1up_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, float32_t value, size_t vl);
vfloat32m4_t __riscv_vfslide1up_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, float32_t value, size_t vl);
vfloat32m8_t __riscv_vfslide1up_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, float32_t value, size_t vl);
vfloat64m1_t __riscv_vfslide1up_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, float64_t value, size_t vl);
vfloat64m2_t __riscv_vfslide1up_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, float64_t value, size_t vl);
vfloat64m4_t __riscv_vfslide1up_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, float64_t value, size_t vl);
vfloat64m8_t __riscv_vfslide1up_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, float64_t value, size_t vl);
vfloat16mf4_t __riscv_vfslide1down_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t src, float16_t value, size_t vl);
vfloat16mf2_t __riscv_vfslide1down_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t src, float16_t value, size_t vl);
vfloat16m1_t __riscv_vfslide1down_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, float16_t value, size_t vl);
vfloat16m2_t __riscv_vfslide1down_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, float16_t value, size_t vl);
vfloat16m4_t __riscv_vfslide1down_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, float16_t value, size_t vl);
vfloat16m8_t __riscv_vfslide1down_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, float16_t value, size_t vl);
vfloat32mf2_t __riscv_vfslide1down_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t src, float32_t value, size_t vl);
vfloat32m1_t __riscv_vfslide1down_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, float32_t value, size_t vl);
vfloat32m2_t __riscv_vfslide1down_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, float32_t value, size_t vl);
vfloat32m4_t __riscv_vfslide1down_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, float32_t value, size_t vl);
vfloat32m8_t __riscv_vfslide1down_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, float32_t value, size_t vl);
vfloat64m1_t __riscv_vfslide1down_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, float64_t value, size_t vl);
vfloat64m2_t __riscv_vfslide1down_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, float64_t value, size_t vl);
vfloat64m4_t __riscv_vfslide1down_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, float64_t value, size_t vl);
vfloat64m8_t __riscv_vfslide1down_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, float64_t value, size_t vl);
vint8mf8_t __riscv_vslide1up_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t src, int8_t value, size_t vl);
vint8mf4_t __riscv_vslide1up_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t src, int8_t value, size_t vl);
vint8mf2_t __riscv_vslide1up_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t src, int8_t value, size_t vl);
vint8m1_t __riscv_vslide1up_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, int8_t value, size_t vl);
vint8m2_t __riscv_vslide1up_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, int8_t value, size_t vl);
vint8m4_t __riscv_vslide1up_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, int8_t value, size_t vl);
vint8m8_t __riscv_vslide1up_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, int8_t value, size_t vl);
vint16mf4_t __riscv_vslide1up_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t src, int16_t value, size_t vl);
vint16mf2_t __riscv_vslide1up_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t src, int16_t value, size_t vl);
vint16m1_t __riscv_vslide1up_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, int16_t value, size_t vl);
vint16m2_t __riscv_vslide1up_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, int16_t value, size_t vl);
vint16m4_t __riscv_vslide1up_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, int16_t value, size_t vl);
vint16m8_t __riscv_vslide1up_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, int16_t value, size_t vl);
vint32mf2_t __riscv_vslide1up_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t src, int32_t value, size_t vl);
vint32m1_t __riscv_vslide1up_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, int32_t value, size_t vl);
vint32m2_t __riscv_vslide1up_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, int32_t value, size_t vl);
vint32m4_t __riscv_vslide1up_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, int32_t value, size_t vl);
vint32m8_t __riscv_vslide1up_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, int32_t value, size_t vl);
vint64m1_t __riscv_vslide1up_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, int64_t value, size_t vl);
vint64m2_t __riscv_vslide1up_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, int64_t value, size_t vl);
vint64m4_t __riscv_vslide1up_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, int64_t value, size_t vl);
vint64m8_t __riscv_vslide1up_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, int64_t value, size_t vl);
vint8mf8_t __riscv_vslide1down_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t src, int8_t value, size_t vl);
vint8mf4_t __riscv_vslide1down_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t src, int8_t value, size_t vl);
vint8mf2_t __riscv_vslide1down_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t src, int8_t value, size_t vl);
vint8m1_t __riscv_vslide1down_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, int8_t value, size_t vl);
vint8m2_t __riscv_vslide1down_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, int8_t value, size_t vl);
vint8m4_t __riscv_vslide1down_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, int8_t value, size_t vl);
vint8m8_t __riscv_vslide1down_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, int8_t value, size_t vl);
vint16mf4_t __riscv_vslide1down_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t src, int16_t value, size_t vl);
vint16mf2_t __riscv_vslide1down_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t src, int16_t value, size_t vl);
vint16m1_t __riscv_vslide1down_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, int16_t value, size_t vl);
vint16m2_t __riscv_vslide1down_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, int16_t value, size_t vl);
vint16m4_t __riscv_vslide1down_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, int16_t value, size_t vl);
vint16m8_t __riscv_vslide1down_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, int16_t value, size_t vl);
vint32mf2_t __riscv_vslide1down_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t src, int32_t value, size_t vl);
vint32m1_t __riscv_vslide1down_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, int32_t value, size_t vl);
vint32m2_t __riscv_vslide1down_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, int32_t value, size_t vl);
vint32m4_t __riscv_vslide1down_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, int32_t value, size_t vl);
vint32m8_t __riscv_vslide1down_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, int32_t value, size_t vl);
vint64m1_t __riscv_vslide1down_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, int64_t value, size_t vl);
vint64m2_t __riscv_vslide1down_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, int64_t value, size_t vl);
vint64m4_t __riscv_vslide1down_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, int64_t value, size_t vl);
vint64m8_t __riscv_vslide1down_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, int64_t value, size_t vl);
vuint8mf8_t __riscv_vslide1up_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t src, uint8_t value, size_t vl);
vuint8mf4_t __riscv_vslide1up_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t src, uint8_t value, size_t vl);
vuint8mf2_t __riscv_vslide1up_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t src, uint8_t value, size_t vl);
vuint8m1_t __riscv_vslide1up_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, uint8_t value, size_t vl);
vuint8m2_t __riscv_vslide1up_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, uint8_t value, size_t vl);
vuint8m4_t __riscv_vslide1up_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, uint8_t value, size_t vl);
vuint8m8_t __riscv_vslide1up_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, uint8_t value, size_t vl);
vuint16mf4_t __riscv_vslide1up_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t src, uint16_t value, size_t vl);
vuint16mf2_t __riscv_vslide1up_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t src, uint16_t value, size_t vl);
vuint16m1_t __riscv_vslide1up_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, uint16_t value, size_t vl);
vuint16m2_t __riscv_vslide1up_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, uint16_t value, size_t vl);
vuint16m4_t __riscv_vslide1up_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, uint16_t value, size_t vl);
vuint16m8_t __riscv_vslide1up_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, uint16_t value, size_t vl);
vuint32mf2_t __riscv_vslide1up_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t src, uint32_t value, size_t vl);
vuint32m1_t __riscv_vslide1up_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, uint32_t value, size_t vl);
vuint32m2_t __riscv_vslide1up_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, uint32_t value, size_t vl);
vuint32m4_t __riscv_vslide1up_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, uint32_t value, size_t vl);
vuint32m8_t __riscv_vslide1up_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, uint32_t value, size_t vl);
vuint64m1_t __riscv_vslide1up_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, uint64_t value, size_t vl);
vuint64m2_t __riscv_vslide1up_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, uint64_t value, size_t vl);
vuint64m4_t __riscv_vslide1up_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, uint64_t value, size_t vl);
vuint64m8_t __riscv_vslide1up_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, uint64_t value, size_t vl);
vuint8mf8_t __riscv_vslide1down_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t src, uint8_t value, size_t vl);
vuint8mf4_t __riscv_vslide1down_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t src, uint8_t value, size_t vl);
vuint8mf2_t __riscv_vslide1down_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t src, uint8_t value, size_t vl);
vuint8m1_t __riscv_vslide1down_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, uint8_t value, size_t vl);
vuint8m2_t __riscv_vslide1down_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, uint8_t value, size_t vl);
vuint8m4_t __riscv_vslide1down_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, uint8_t value, size_t vl);
vuint8m8_t __riscv_vslide1down_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, uint8_t value, size_t vl);
vuint16mf4_t __riscv_vslide1down_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t src, uint16_t value, size_t vl);
vuint16mf2_t __riscv_vslide1down_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t src, uint16_t value, size_t vl);
vuint16m1_t __riscv_vslide1down_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, uint16_t value, size_t vl);
vuint16m2_t __riscv_vslide1down_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, uint16_t value, size_t vl);
vuint16m4_t __riscv_vslide1down_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, uint16_t value, size_t vl);
vuint16m8_t __riscv_vslide1down_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, uint16_t value, size_t vl);
vuint32mf2_t __riscv_vslide1down_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t src, uint32_t value, size_t vl);
vuint32m1_t __riscv_vslide1down_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, uint32_t value, size_t vl);
vuint32m2_t __riscv_vslide1down_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, uint32_t value, size_t vl);
vuint32m4_t __riscv_vslide1down_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, uint32_t value, size_t vl);
vuint32m8_t __riscv_vslide1down_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, uint32_t value, size_t vl);
vuint64m1_t __riscv_vslide1down_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, uint64_t value, size_t vl);
vuint64m2_t __riscv_vslide1down_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, uint64_t value, size_t vl);
vuint64m4_t __riscv_vslide1down_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, uint64_t value, size_t vl);
vuint64m8_t __riscv_vslide1down_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, uint64_t value, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfslide1up_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t src, float16_t value, size_t vl);
vfloat16mf2_t __riscv_vfslide1up_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t src, float16_t value, size_t vl);
vfloat16m1_t __riscv_vfslide1up_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, float16_t value, size_t vl);
vfloat16m2_t __riscv_vfslide1up_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, float16_t value, size_t vl);
vfloat16m4_t __riscv_vfslide1up_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, float16_t value, size_t vl);
vfloat16m8_t __riscv_vfslide1up_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, float16_t value, size_t vl);
vfloat32mf2_t __riscv_vfslide1up_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t src, float32_t value, size_t vl);
vfloat32m1_t __riscv_vfslide1up_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, float32_t value, size_t vl);
vfloat32m2_t __riscv_vfslide1up_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, float32_t value, size_t vl);
vfloat32m4_t __riscv_vfslide1up_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, float32_t value, size_t vl);
vfloat32m8_t __riscv_vfslide1up_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, float32_t value, size_t vl);
vfloat64m1_t __riscv_vfslide1up_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, float64_t value, size_t vl);
vfloat64m2_t __riscv_vfslide1up_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, float64_t value, size_t vl);
vfloat64m4_t __riscv_vfslide1up_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, float64_t value, size_t vl);
vfloat64m8_t __riscv_vfslide1up_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, float64_t value, size_t vl);
vfloat16mf4_t __riscv_vfslide1down_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t src, float16_t value, size_t vl);
vfloat16mf2_t __riscv_vfslide1down_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t src, float16_t value, size_t vl);
vfloat16m1_t __riscv_vfslide1down_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, float16_t value, size_t vl);
vfloat16m2_t __riscv_vfslide1down_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, float16_t value, size_t vl);
vfloat16m4_t __riscv_vfslide1down_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, float16_t value, size_t vl);
vfloat16m8_t __riscv_vfslide1down_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, float16_t value, size_t vl);
vfloat32mf2_t __riscv_vfslide1down_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t src, float32_t value, size_t vl);
vfloat32m1_t __riscv_vfslide1down_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, float32_t value, size_t vl);
vfloat32m2_t __riscv_vfslide1down_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, float32_t value, size_t vl);
vfloat32m4_t __riscv_vfslide1down_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, float32_t value, size_t vl);
vfloat32m8_t __riscv_vfslide1down_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, float32_t value, size_t vl);
vfloat64m1_t __riscv_vfslide1down_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, float64_t value, size_t vl);
vfloat64m2_t __riscv_vfslide1down_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, float64_t value, size_t vl);
vfloat64m4_t __riscv_vfslide1down_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, float64_t value, size_t vl);
vfloat64m8_t __riscv_vfslide1down_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, float64_t value, size_t vl);
vint8mf8_t __riscv_vslide1up_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t src, int8_t value, size_t vl);
vint8mf4_t __riscv_vslide1up_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t src, int8_t value, size_t vl);
vint8mf2_t __riscv_vslide1up_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t src, int8_t value, size_t vl);
vint8m1_t __riscv_vslide1up_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, int8_t value, size_t vl);
vint8m2_t __riscv_vslide1up_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, int8_t value, size_t vl);
vint8m4_t __riscv_vslide1up_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, int8_t value, size_t vl);
vint8m8_t __riscv_vslide1up_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, int8_t value, size_t vl);
vint16mf4_t __riscv_vslide1up_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t src, int16_t value, size_t vl);
vint16mf2_t __riscv_vslide1up_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t src, int16_t value, size_t vl);
vint16m1_t __riscv_vslide1up_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, int16_t value, size_t vl);
vint16m2_t __riscv_vslide1up_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, int16_t value, size_t vl);
vint16m4_t __riscv_vslide1up_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, int16_t value, size_t vl);
vint16m8_t __riscv_vslide1up_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, int16_t value, size_t vl);
vint32mf2_t __riscv_vslide1up_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t src, int32_t value, size_t vl);
vint32m1_t __riscv_vslide1up_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, int32_t value, size_t vl);
vint32m2_t __riscv_vslide1up_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, int32_t value, size_t vl);
vint32m4_t __riscv_vslide1up_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, int32_t value, size_t vl);
vint32m8_t __riscv_vslide1up_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, int32_t value, size_t vl);
vint64m1_t __riscv_vslide1up_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, int64_t value, size_t vl);
vint64m2_t __riscv_vslide1up_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, int64_t value, size_t vl);
vint64m4_t __riscv_vslide1up_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, int64_t value, size_t vl);
vint64m8_t __riscv_vslide1up_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, int64_t value, size_t vl);
vint8mf8_t __riscv_vslide1down_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t src, int8_t value, size_t vl);
vint8mf4_t __riscv_vslide1down_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t src, int8_t value, size_t vl);
vint8mf2_t __riscv_vslide1down_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t src, int8_t value, size_t vl);
vint8m1_t __riscv_vslide1down_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, int8_t value, size_t vl);
vint8m2_t __riscv_vslide1down_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, int8_t value, size_t vl);
vint8m4_t __riscv_vslide1down_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, int8_t value, size_t vl);
vint8m8_t __riscv_vslide1down_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, int8_t value, size_t vl);
vint16mf4_t __riscv_vslide1down_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t src, int16_t value, size_t vl);
vint16mf2_t __riscv_vslide1down_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t src, int16_t value, size_t vl);
vint16m1_t __riscv_vslide1down_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, int16_t value, size_t vl);
vint16m2_t __riscv_vslide1down_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, int16_t value, size_t vl);
vint16m4_t __riscv_vslide1down_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, int16_t value, size_t vl);
vint16m8_t __riscv_vslide1down_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, int16_t value, size_t vl);
vint32mf2_t __riscv_vslide1down_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t src, int32_t value, size_t vl);
vint32m1_t __riscv_vslide1down_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, int32_t value, size_t vl);
vint32m2_t __riscv_vslide1down_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, int32_t value, size_t vl);
vint32m4_t __riscv_vslide1down_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, int32_t value, size_t vl);
vint32m8_t __riscv_vslide1down_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, int32_t value, size_t vl);
vint64m1_t __riscv_vslide1down_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, int64_t value, size_t vl);
vint64m2_t __riscv_vslide1down_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, int64_t value, size_t vl);
vint64m4_t __riscv_vslide1down_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, int64_t value, size_t vl);
vint64m8_t __riscv_vslide1down_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, int64_t value, size_t vl);
vuint8mf8_t __riscv_vslide1up_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t src, uint8_t value, size_t vl);
vuint8mf4_t __riscv_vslide1up_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t src, uint8_t value, size_t vl);
vuint8mf2_t __riscv_vslide1up_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t src, uint8_t value, size_t vl);
vuint8m1_t __riscv_vslide1up_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, uint8_t value, size_t vl);
vuint8m2_t __riscv_vslide1up_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, uint8_t value, size_t vl);
vuint8m4_t __riscv_vslide1up_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, uint8_t value, size_t vl);
vuint8m8_t __riscv_vslide1up_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, uint8_t value, size_t vl);
vuint16mf4_t __riscv_vslide1up_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t src, uint16_t value, size_t vl);
vuint16mf2_t __riscv_vslide1up_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t src, uint16_t value, size_t vl);
vuint16m1_t __riscv_vslide1up_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, uint16_t value, size_t vl);
vuint16m2_t __riscv_vslide1up_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, uint16_t value, size_t vl);
vuint16m4_t __riscv_vslide1up_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, uint16_t value, size_t vl);
vuint16m8_t __riscv_vslide1up_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, uint16_t value, size_t vl);
vuint32mf2_t __riscv_vslide1up_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t src, uint32_t value, size_t vl);
vuint32m1_t __riscv_vslide1up_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, uint32_t value, size_t vl);
vuint32m2_t __riscv_vslide1up_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, uint32_t value, size_t vl);
vuint32m4_t __riscv_vslide1up_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, uint32_t value, size_t vl);
vuint32m8_t __riscv_vslide1up_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, uint32_t value, size_t vl);
vuint64m1_t __riscv_vslide1up_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, uint64_t value, size_t vl);
vuint64m2_t __riscv_vslide1up_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, uint64_t value, size_t vl);
vuint64m4_t __riscv_vslide1up_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, uint64_t value, size_t vl);
vuint64m8_t __riscv_vslide1up_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, uint64_t value, size_t vl);
vuint8mf8_t __riscv_vslide1down_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t src, uint8_t value, size_t vl);
vuint8mf4_t __riscv_vslide1down_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t src, uint8_t value, size_t vl);
vuint8mf2_t __riscv_vslide1down_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t src, uint8_t value, size_t vl);
vuint8m1_t __riscv_vslide1down_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, uint8_t value, size_t vl);
vuint8m2_t __riscv_vslide1down_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, uint8_t value, size_t vl);
vuint8m4_t __riscv_vslide1down_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, uint8_t value, size_t vl);
vuint8m8_t __riscv_vslide1down_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, uint8_t value, size_t vl);
vuint16mf4_t __riscv_vslide1down_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t src, uint16_t value, size_t vl);
vuint16mf2_t __riscv_vslide1down_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t src, uint16_t value, size_t vl);
vuint16m1_t __riscv_vslide1down_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, uint16_t value, size_t vl);
vuint16m2_t __riscv_vslide1down_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, uint16_t value, size_t vl);
vuint16m4_t __riscv_vslide1down_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, uint16_t value, size_t vl);
vuint16m8_t __riscv_vslide1down_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, uint16_t value, size_t vl);
vuint32mf2_t __riscv_vslide1down_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t src, uint32_t value, size_t vl);
vuint32m1_t __riscv_vslide1down_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, uint32_t value, size_t vl);
vuint32m2_t __riscv_vslide1down_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, uint32_t value, size_t vl);
vuint32m4_t __riscv_vslide1down_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, uint32_t value, size_t vl);
vuint32m8_t __riscv_vslide1down_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, uint32_t value, size_t vl);
vuint64m1_t __riscv_vslide1down_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, uint64_t value, size_t vl);
vuint64m2_t __riscv_vslide1down_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, uint64_t value, size_t vl);
vuint64m4_t __riscv_vslide1down_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, uint64_t value, size_t vl);
vuint64m8_t __riscv_vslide1down_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, uint64_t value, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vfslide1up_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t src, float16_t value, size_t vl);
vfloat16mf2_t __riscv_vfslide1up_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t src, float16_t value, size_t vl);
vfloat16m1_t __riscv_vfslide1up_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, float16_t value, size_t vl);
vfloat16m2_t __riscv_vfslide1up_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, float16_t value, size_t vl);
vfloat16m4_t __riscv_vfslide1up_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, float16_t value, size_t vl);
vfloat16m8_t __riscv_vfslide1up_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, float16_t value, size_t vl);
vfloat32mf2_t __riscv_vfslide1up_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t src, float32_t value, size_t vl);
vfloat32m1_t __riscv_vfslide1up_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, float32_t value, size_t vl);
vfloat32m2_t __riscv_vfslide1up_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, float32_t value, size_t vl);
vfloat32m4_t __riscv_vfslide1up_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, float32_t value, size_t vl);
vfloat32m8_t __riscv_vfslide1up_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, float32_t value, size_t vl);
vfloat64m1_t __riscv_vfslide1up_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, float64_t value, size_t vl);
vfloat64m2_t __riscv_vfslide1up_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, float64_t value, size_t vl);
vfloat64m4_t __riscv_vfslide1up_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, float64_t value, size_t vl);
vfloat64m8_t __riscv_vfslide1up_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, float64_t value, size_t vl);
vfloat16mf4_t __riscv_vfslide1down_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t src, float16_t value, size_t vl);
vfloat16mf2_t __riscv_vfslide1down_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t src, float16_t value, size_t vl);
vfloat16m1_t __riscv_vfslide1down_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, float16_t value, size_t vl);
vfloat16m2_t __riscv_vfslide1down_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, float16_t value, size_t vl);
vfloat16m4_t __riscv_vfslide1down_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, float16_t value, size_t vl);
vfloat16m8_t __riscv_vfslide1down_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, float16_t value, size_t vl);
vfloat32mf2_t __riscv_vfslide1down_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t src, float32_t value, size_t vl);
vfloat32m1_t __riscv_vfslide1down_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, float32_t value, size_t vl);
vfloat32m2_t __riscv_vfslide1down_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, float32_t value, size_t vl);
vfloat32m4_t __riscv_vfslide1down_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, float32_t value, size_t vl);
vfloat32m8_t __riscv_vfslide1down_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, float32_t value, size_t vl);
vfloat64m1_t __riscv_vfslide1down_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, float64_t value, size_t vl);
vfloat64m2_t __riscv_vfslide1down_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, float64_t value, size_t vl);
vfloat64m4_t __riscv_vfslide1down_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, float64_t value, size_t vl);
vfloat64m8_t __riscv_vfslide1down_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, float64_t value, size_t vl);
vint8mf8_t __riscv_vslide1up_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t src, int8_t value, size_t vl);
vint8mf4_t __riscv_vslide1up_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t src, int8_t value, size_t vl);
vint8mf2_t __riscv_vslide1up_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t src, int8_t value, size_t vl);
vint8m1_t __riscv_vslide1up_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, int8_t value, size_t vl);
vint8m2_t __riscv_vslide1up_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, int8_t value, size_t vl);
vint8m4_t __riscv_vslide1up_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, int8_t value, size_t vl);
vint8m8_t __riscv_vslide1up_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, int8_t value, size_t vl);
vint16mf4_t __riscv_vslide1up_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t src, int16_t value, size_t vl);
vint16mf2_t __riscv_vslide1up_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t src, int16_t value, size_t vl);
vint16m1_t __riscv_vslide1up_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, int16_t value, size_t vl);
vint16m2_t __riscv_vslide1up_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, int16_t value, size_t vl);
vint16m4_t __riscv_vslide1up_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, int16_t value, size_t vl);
vint16m8_t __riscv_vslide1up_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, int16_t value, size_t vl);
vint32mf2_t __riscv_vslide1up_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t src, int32_t value, size_t vl);
vint32m1_t __riscv_vslide1up_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, int32_t value, size_t vl);
vint32m2_t __riscv_vslide1up_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, int32_t value, size_t vl);
vint32m4_t __riscv_vslide1up_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, int32_t value, size_t vl);
vint32m8_t __riscv_vslide1up_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, int32_t value, size_t vl);
vint64m1_t __riscv_vslide1up_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, int64_t value, size_t vl);
vint64m2_t __riscv_vslide1up_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, int64_t value, size_t vl);
vint64m4_t __riscv_vslide1up_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, int64_t value, size_t vl);
vint64m8_t __riscv_vslide1up_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, int64_t value, size_t vl);
vint8mf8_t __riscv_vslide1down_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t src, int8_t value, size_t vl);
vint8mf4_t __riscv_vslide1down_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t src, int8_t value, size_t vl);
vint8mf2_t __riscv_vslide1down_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t src, int8_t value, size_t vl);
vint8m1_t __riscv_vslide1down_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, int8_t value, size_t vl);
vint8m2_t __riscv_vslide1down_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, int8_t value, size_t vl);
vint8m4_t __riscv_vslide1down_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, int8_t value, size_t vl);
vint8m8_t __riscv_vslide1down_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, int8_t value, size_t vl);
vint16mf4_t __riscv_vslide1down_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t src, int16_t value, size_t vl);
vint16mf2_t __riscv_vslide1down_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t src, int16_t value, size_t vl);
vint16m1_t __riscv_vslide1down_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, int16_t value, size_t vl);
vint16m2_t __riscv_vslide1down_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, int16_t value, size_t vl);
vint16m4_t __riscv_vslide1down_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, int16_t value, size_t vl);
vint16m8_t __riscv_vslide1down_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, int16_t value, size_t vl);
vint32mf2_t __riscv_vslide1down_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t src, int32_t value, size_t vl);
vint32m1_t __riscv_vslide1down_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, int32_t value, size_t vl);
vint32m2_t __riscv_vslide1down_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, int32_t value, size_t vl);
vint32m4_t __riscv_vslide1down_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, int32_t value, size_t vl);
vint32m8_t __riscv_vslide1down_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, int32_t value, size_t vl);
vint64m1_t __riscv_vslide1down_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, int64_t value, size_t vl);
vint64m2_t __riscv_vslide1down_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, int64_t value, size_t vl);
vint64m4_t __riscv_vslide1down_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, int64_t value, size_t vl);
vint64m8_t __riscv_vslide1down_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, int64_t value, size_t vl);
vuint8mf8_t __riscv_vslide1up_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t src, uint8_t value, size_t vl);
vuint8mf4_t __riscv_vslide1up_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t src, uint8_t value, size_t vl);
vuint8mf2_t __riscv_vslide1up_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t src, uint8_t value, size_t vl);
vuint8m1_t __riscv_vslide1up_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, uint8_t value, size_t vl);
vuint8m2_t __riscv_vslide1up_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, uint8_t value, size_t vl);
vuint8m4_t __riscv_vslide1up_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, uint8_t value, size_t vl);
vuint8m8_t __riscv_vslide1up_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, uint8_t value, size_t vl);
vuint16mf4_t __riscv_vslide1up_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t src, uint16_t value, size_t vl);
vuint16mf2_t __riscv_vslide1up_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t src, uint16_t value, size_t vl);
vuint16m1_t __riscv_vslide1up_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, uint16_t value, size_t vl);
vuint16m2_t __riscv_vslide1up_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, uint16_t value, size_t vl);
vuint16m4_t __riscv_vslide1up_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, uint16_t value, size_t vl);
vuint16m8_t __riscv_vslide1up_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, uint16_t value, size_t vl);
vuint32mf2_t __riscv_vslide1up_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t src, uint32_t value, size_t vl);
vuint32m1_t __riscv_vslide1up_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, uint32_t value, size_t vl);
vuint32m2_t __riscv_vslide1up_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, uint32_t value, size_t vl);
vuint32m4_t __riscv_vslide1up_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, uint32_t value, size_t vl);
vuint32m8_t __riscv_vslide1up_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, uint32_t value, size_t vl);
vuint64m1_t __riscv_vslide1up_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, uint64_t value, size_t vl);
vuint64m2_t __riscv_vslide1up_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, uint64_t value, size_t vl);
vuint64m4_t __riscv_vslide1up_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, uint64_t value, size_t vl);
vuint64m8_t __riscv_vslide1up_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, uint64_t value, size_t vl);
vuint8mf8_t __riscv_vslide1down_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t src, uint8_t value, size_t vl);
vuint8mf4_t __riscv_vslide1down_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t src, uint8_t value, size_t vl);
vuint8mf2_t __riscv_vslide1down_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t src, uint8_t value, size_t vl);
vuint8m1_t __riscv_vslide1down_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, uint8_t value, size_t vl);
vuint8m2_t __riscv_vslide1down_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, uint8_t value, size_t vl);
vuint8m4_t __riscv_vslide1down_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, uint8_t value, size_t vl);
vuint8m8_t __riscv_vslide1down_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, uint8_t value, size_t vl);
vuint16mf4_t __riscv_vslide1down_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t src, uint16_t value, size_t vl);
vuint16mf2_t __riscv_vslide1down_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t src, uint16_t value, size_t vl);
vuint16m1_t __riscv_vslide1down_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, uint16_t value, size_t vl);
vuint16m2_t __riscv_vslide1down_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, uint16_t value, size_t vl);
vuint16m4_t __riscv_vslide1down_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, uint16_t value, size_t vl);
vuint16m8_t __riscv_vslide1down_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, uint16_t value, size_t vl);
vuint32mf2_t __riscv_vslide1down_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t src, uint32_t value, size_t vl);
vuint32m1_t __riscv_vslide1down_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, uint32_t value, size_t vl);
vuint32m2_t __riscv_vslide1down_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, uint32_t value, size_t vl);
vuint32m4_t __riscv_vslide1down_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, uint32_t value, size_t vl);
vuint32m8_t __riscv_vslide1down_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, uint32_t value, size_t vl);
vuint64m1_t __riscv_vslide1down_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, uint64_t value, size_t vl);
vuint64m2_t __riscv_vslide1down_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, uint64_t value, size_t vl);
vuint64m4_t __riscv_vslide1down_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, uint64_t value, size_t vl);
vuint64m8_t __riscv_vslide1down_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, uint64_t value, size_t vl);
```

[[policy-variant-overloadedvector-register-gather]]
=== Vector Register Gather Intrinsics

``` C
vfloat16mf4_t __riscv_vrgather_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vuint16mf4_t index, size_t vl);
vfloat16mf4_t __riscv_vrgather_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t index, size_t vl);
vfloat16mf2_t __riscv_vrgather_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vuint16mf2_t index, size_t vl);
vfloat16mf2_t __riscv_vrgather_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t index, size_t vl);
vfloat16m1_t __riscv_vrgather_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t index, size_t vl);
vfloat16m1_t __riscv_vrgather_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t index, size_t vl);
vfloat16m2_t __riscv_vrgather_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t index, size_t vl);
vfloat16m2_t __riscv_vrgather_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t index, size_t vl);
vfloat16m4_t __riscv_vrgather_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t index, size_t vl);
vfloat16m4_t __riscv_vrgather_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t index, size_t vl);
vfloat16m8_t __riscv_vrgather_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t index, size_t vl);
vfloat16m8_t __riscv_vrgather_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t index, size_t vl);
vfloat32mf2_t __riscv_vrgather_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vuint32mf2_t index, size_t vl);
vfloat32mf2_t __riscv_vrgather_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t index, size_t vl);
vfloat32m1_t __riscv_vrgather_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint32m1_t index, size_t vl);
vfloat32m1_t __riscv_vrgather_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t index, size_t vl);
vfloat32m2_t __riscv_vrgather_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint32m2_t index, size_t vl);
vfloat32m2_t __riscv_vrgather_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t index, size_t vl);
vfloat32m4_t __riscv_vrgather_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint32m4_t index, size_t vl);
vfloat32m4_t __riscv_vrgather_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t index, size_t vl);
vfloat32m8_t __riscv_vrgather_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint32m8_t index, size_t vl);
vfloat32m8_t __riscv_vrgather_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t index, size_t vl);
vfloat64m1_t __riscv_vrgather_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint64m1_t index, size_t vl);
vfloat64m1_t __riscv_vrgather_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t index, size_t vl);
vfloat64m2_t __riscv_vrgather_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint64m2_t index, size_t vl);
vfloat64m2_t __riscv_vrgather_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t index, size_t vl);
vfloat64m4_t __riscv_vrgather_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint64m4_t index, size_t vl);
vfloat64m4_t __riscv_vrgather_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t index, size_t vl);
vfloat64m8_t __riscv_vrgather_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint64m8_t index, size_t vl);
vfloat64m8_t __riscv_vrgather_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t index, size_t vl);
vfloat16mf4_t __riscv_vrgatherei16_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vuint16mf4_t op2, size_t vl);
vfloat16mf2_t __riscv_vrgatherei16_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vuint16mf2_t op2, size_t vl);
vfloat16m1_t __riscv_vrgatherei16_tu (vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t op2, size_t vl);
vfloat16m2_t __riscv_vrgatherei16_tu (vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t op2, size_t vl);
vfloat16m4_t __riscv_vrgatherei16_tu (vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t op2, size_t vl);
vfloat16m8_t __riscv_vrgatherei16_tu (vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t op2, size_t vl);
vfloat32mf2_t __riscv_vrgatherei16_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vuint16mf4_t op2, size_t vl);
vfloat32m1_t __riscv_vrgatherei16_tu (vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint16mf2_t op2, size_t vl);
vfloat32m2_t __riscv_vrgatherei16_tu (vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint16m1_t op2, size_t vl);
vfloat32m4_t __riscv_vrgatherei16_tu (vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint16m2_t op2, size_t vl);
vfloat32m8_t __riscv_vrgatherei16_tu (vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint16m4_t op2, size_t vl);
vfloat64m1_t __riscv_vrgatherei16_tu (vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint16mf4_t op2, size_t vl);
vfloat64m2_t __riscv_vrgatherei16_tu (vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint16mf2_t op2, size_t vl);
vfloat64m4_t __riscv_vrgatherei16_tu (vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint16m1_t op2, size_t vl);
vfloat64m8_t __riscv_vrgatherei16_tu (vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint16m2_t op2, size_t vl);
vint8mf8_t __riscv_vrgather_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t index, size_t vl);
vint8mf8_t __riscv_vrgather_tu (vint8mf8_t maskedoff, vint8mf8_t op1, size_t index, size_t vl);
vint8mf4_t __riscv_vrgather_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t index, size_t vl);
vint8mf4_t __riscv_vrgather_tu (vint8mf4_t maskedoff, vint8mf4_t op1, size_t index, size_t vl);
vint8mf2_t __riscv_vrgather_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t index, size_t vl);
vint8mf2_t __riscv_vrgather_tu (vint8mf2_t maskedoff, vint8mf2_t op1, size_t index, size_t vl);
vint8m1_t __riscv_vrgather_tu (vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t index, size_t vl);
vint8m1_t __riscv_vrgather_tu (vint8m1_t maskedoff, vint8m1_t op1, size_t index, size_t vl);
vint8m2_t __riscv_vrgather_tu (vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t index, size_t vl);
vint8m2_t __riscv_vrgather_tu (vint8m2_t maskedoff, vint8m2_t op1, size_t index, size_t vl);
vint8m4_t __riscv_vrgather_tu (vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t index, size_t vl);
vint8m4_t __riscv_vrgather_tu (vint8m4_t maskedoff, vint8m4_t op1, size_t index, size_t vl);
vint8m8_t __riscv_vrgather_tu (vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t index, size_t vl);
vint8m8_t __riscv_vrgather_tu (vint8m8_t maskedoff, vint8m8_t op1, size_t index, size_t vl);
vint16mf4_t __riscv_vrgather_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t index, size_t vl);
vint16mf4_t __riscv_vrgather_tu (vint16mf4_t maskedoff, vint16mf4_t op1, size_t index, size_t vl);
vint16mf2_t __riscv_vrgather_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t index, size_t vl);
vint16mf2_t __riscv_vrgather_tu (vint16mf2_t maskedoff, vint16mf2_t op1, size_t index, size_t vl);
vint16m1_t __riscv_vrgather_tu (vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t index, size_t vl);
vint16m1_t __riscv_vrgather_tu (vint16m1_t maskedoff, vint16m1_t op1, size_t index, size_t vl);
vint16m2_t __riscv_vrgather_tu (vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t index, size_t vl);
vint16m2_t __riscv_vrgather_tu (vint16m2_t maskedoff, vint16m2_t op1, size_t index, size_t vl);
vint16m4_t __riscv_vrgather_tu (vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t index, size_t vl);
vint16m4_t __riscv_vrgather_tu (vint16m4_t maskedoff, vint16m4_t op1, size_t index, size_t vl);
vint16m8_t __riscv_vrgather_tu (vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t index, size_t vl);
vint16m8_t __riscv_vrgather_tu (vint16m8_t maskedoff, vint16m8_t op1, size_t index, size_t vl);
vint32mf2_t __riscv_vrgather_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t index, size_t vl);
vint32mf2_t __riscv_vrgather_tu (vint32mf2_t maskedoff, vint32mf2_t op1, size_t index, size_t vl);
vint32m1_t __riscv_vrgather_tu (vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t index, size_t vl);
vint32m1_t __riscv_vrgather_tu (vint32m1_t maskedoff, vint32m1_t op1, size_t index, size_t vl);
vint32m2_t __riscv_vrgather_tu (vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t index, size_t vl);
vint32m2_t __riscv_vrgather_tu (vint32m2_t maskedoff, vint32m2_t op1, size_t index, size_t vl);
vint32m4_t __riscv_vrgather_tu (vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t index, size_t vl);
vint32m4_t __riscv_vrgather_tu (vint32m4_t maskedoff, vint32m4_t op1, size_t index, size_t vl);
vint32m8_t __riscv_vrgather_tu (vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t index, size_t vl);
vint32m8_t __riscv_vrgather_tu (vint32m8_t maskedoff, vint32m8_t op1, size_t index, size_t vl);
vint64m1_t __riscv_vrgather_tu (vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t index, size_t vl);
vint64m1_t __riscv_vrgather_tu (vint64m1_t maskedoff, vint64m1_t op1, size_t index, size_t vl);
vint64m2_t __riscv_vrgather_tu (vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t index, size_t vl);
vint64m2_t __riscv_vrgather_tu (vint64m2_t maskedoff, vint64m2_t op1, size_t index, size_t vl);
vint64m4_t __riscv_vrgather_tu (vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t index, size_t vl);
vint64m4_t __riscv_vrgather_tu (vint64m4_t maskedoff, vint64m4_t op1, size_t index, size_t vl);
vint64m8_t __riscv_vrgather_tu (vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t index, size_t vl);
vint64m8_t __riscv_vrgather_tu (vint64m8_t maskedoff, vint64m8_t op1, size_t index, size_t vl);
vint8mf8_t __riscv_vrgatherei16_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vuint16mf4_t op2, size_t vl);
vint8mf4_t __riscv_vrgatherei16_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vuint16mf2_t op2, size_t vl);
vint8mf2_t __riscv_vrgatherei16_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vuint16m1_t op2, size_t vl);
vint8m1_t __riscv_vrgatherei16_tu (vint8m1_t maskedoff, vint8m1_t op1, vuint16m2_t op2, size_t vl);
vint8m2_t __riscv_vrgatherei16_tu (vint8m2_t maskedoff, vint8m2_t op1, vuint16m4_t op2, size_t vl);
vint8m4_t __riscv_vrgatherei16_tu (vint8m4_t maskedoff, vint8m4_t op1, vuint16m8_t op2, size_t vl);
vint16mf4_t __riscv_vrgatherei16_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint16mf2_t __riscv_vrgatherei16_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint16m1_t __riscv_vrgatherei16_tu (vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint16m2_t __riscv_vrgatherei16_tu (vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint16m4_t __riscv_vrgatherei16_tu (vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint16m8_t __riscv_vrgatherei16_tu (vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2, size_t vl);
vint32mf2_t __riscv_vrgatherei16_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vint32m1_t __riscv_vrgatherei16_tu (vint32m1_t maskedoff, vint32m1_t op1, vuint16mf2_t op2, size_t vl);
vint32m2_t __riscv_vrgatherei16_tu (vint32m2_t maskedoff, vint32m2_t op1, vuint16m1_t op2, size_t vl);
vint32m4_t __riscv_vrgatherei16_tu (vint32m4_t maskedoff, vint32m4_t op1, vuint16m2_t op2, size_t vl);
vint32m8_t __riscv_vrgatherei16_tu (vint32m8_t maskedoff, vint32m8_t op1, vuint16m4_t op2, size_t vl);
vint64m1_t __riscv_vrgatherei16_tu (vint64m1_t maskedoff, vint64m1_t op1, vuint16mf4_t op2, size_t vl);
vint64m2_t __riscv_vrgatherei16_tu (vint64m2_t maskedoff, vint64m2_t op1, vuint16mf2_t op2, size_t vl);
vint64m4_t __riscv_vrgatherei16_tu (vint64m4_t maskedoff, vint64m4_t op1, vuint16m1_t op2, size_t vl);
vint64m8_t __riscv_vrgatherei16_tu (vint64m8_t maskedoff, vint64m8_t op1, vuint16m2_t op2, size_t vl);
vuint8mf8_t __riscv_vrgather_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t index, size_t vl);
vuint8mf8_t __riscv_vrgather_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t index, size_t vl);
vuint8mf4_t __riscv_vrgather_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t index, size_t vl);
vuint8mf4_t __riscv_vrgather_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t index, size_t vl);
vuint8mf2_t __riscv_vrgather_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t index, size_t vl);
vuint8mf2_t __riscv_vrgather_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t index, size_t vl);
vuint8m1_t __riscv_vrgather_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t index, size_t vl);
vuint8m1_t __riscv_vrgather_tu (vuint8m1_t maskedoff, vuint8m1_t op1, size_t index, size_t vl);
vuint8m2_t __riscv_vrgather_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t index, size_t vl);
vuint8m2_t __riscv_vrgather_tu (vuint8m2_t maskedoff, vuint8m2_t op1, size_t index, size_t vl);
vuint8m4_t __riscv_vrgather_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t index, size_t vl);
vuint8m4_t __riscv_vrgather_tu (vuint8m4_t maskedoff, vuint8m4_t op1, size_t index, size_t vl);
vuint8m8_t __riscv_vrgather_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t index, size_t vl);
vuint8m8_t __riscv_vrgather_tu (vuint8m8_t maskedoff, vuint8m8_t op1, size_t index, size_t vl);
vuint16mf4_t __riscv_vrgather_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t index, size_t vl);
vuint16mf4_t __riscv_vrgather_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t index, size_t vl);
vuint16mf2_t __riscv_vrgather_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t index, size_t vl);
vuint16mf2_t __riscv_vrgather_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t index, size_t vl);
vuint16m1_t __riscv_vrgather_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t index, size_t vl);
vuint16m1_t __riscv_vrgather_tu (vuint16m1_t maskedoff, vuint16m1_t op1, size_t index, size_t vl);
vuint16m2_t __riscv_vrgather_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t index, size_t vl);
vuint16m2_t __riscv_vrgather_tu (vuint16m2_t maskedoff, vuint16m2_t op1, size_t index, size_t vl);
vuint16m4_t __riscv_vrgather_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t index, size_t vl);
vuint16m4_t __riscv_vrgather_tu (vuint16m4_t maskedoff, vuint16m4_t op1, size_t index, size_t vl);
vuint16m8_t __riscv_vrgather_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t index, size_t vl);
vuint16m8_t __riscv_vrgather_tu (vuint16m8_t maskedoff, vuint16m8_t op1, size_t index, size_t vl);
vuint32mf2_t __riscv_vrgather_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t index, size_t vl);
vuint32mf2_t __riscv_vrgather_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t index, size_t vl);
vuint32m1_t __riscv_vrgather_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t index, size_t vl);
vuint32m1_t __riscv_vrgather_tu (vuint32m1_t maskedoff, vuint32m1_t op1, size_t index, size_t vl);
vuint32m2_t __riscv_vrgather_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t index, size_t vl);
vuint32m2_t __riscv_vrgather_tu (vuint32m2_t maskedoff, vuint32m2_t op1, size_t index, size_t vl);
vuint32m4_t __riscv_vrgather_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t index, size_t vl);
vuint32m4_t __riscv_vrgather_tu (vuint32m4_t maskedoff, vuint32m4_t op1, size_t index, size_t vl);
vuint32m8_t __riscv_vrgather_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t index, size_t vl);
vuint32m8_t __riscv_vrgather_tu (vuint32m8_t maskedoff, vuint32m8_t op1, size_t index, size_t vl);
vuint64m1_t __riscv_vrgather_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t index, size_t vl);
vuint64m1_t __riscv_vrgather_tu (vuint64m1_t maskedoff, vuint64m1_t op1, size_t index, size_t vl);
vuint64m2_t __riscv_vrgather_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t index, size_t vl);
vuint64m2_t __riscv_vrgather_tu (vuint64m2_t maskedoff, vuint64m2_t op1, size_t index, size_t vl);
vuint64m4_t __riscv_vrgather_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t index, size_t vl);
vuint64m4_t __riscv_vrgather_tu (vuint64m4_t maskedoff, vuint64m4_t op1, size_t index, size_t vl);
vuint64m8_t __riscv_vrgather_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t index, size_t vl);
vuint64m8_t __riscv_vrgather_tu (vuint64m8_t maskedoff, vuint64m8_t op1, size_t index, size_t vl);
vuint8mf8_t __riscv_vrgatherei16_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint16mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vrgatherei16_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint16mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vrgatherei16_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint16m1_t op2, size_t vl);
vuint8m1_t __riscv_vrgatherei16_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint16m2_t op2, size_t vl);
vuint8m2_t __riscv_vrgatherei16_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint16m4_t op2, size_t vl);
vuint8m4_t __riscv_vrgatherei16_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint16m8_t op2, size_t vl);
vuint16mf4_t __riscv_vrgatherei16_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vrgatherei16_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16m1_t __riscv_vrgatherei16_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m2_t __riscv_vrgatherei16_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m4_t __riscv_vrgatherei16_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m8_t __riscv_vrgatherei16_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint32mf2_t __riscv_vrgatherei16_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32m1_t __riscv_vrgatherei16_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m2_t __riscv_vrgatherei16_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m4_t __riscv_vrgatherei16_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m8_t __riscv_vrgatherei16_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint64m1_t __riscv_vrgatherei16_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint16mf4_t op2, size_t vl);
vuint64m2_t __riscv_vrgatherei16_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint16mf2_t op2, size_t vl);
vuint64m4_t __riscv_vrgatherei16_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint16m1_t op2, size_t vl);
vuint64m8_t __riscv_vrgatherei16_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint16m2_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vrgather_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vuint16mf4_t index, size_t vl);
vfloat16mf4_t __riscv_vrgather_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t index, size_t vl);
vfloat16mf2_t __riscv_vrgather_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vuint16mf2_t index, size_t vl);
vfloat16mf2_t __riscv_vrgather_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t index, size_t vl);
vfloat16m1_t __riscv_vrgather_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t index, size_t vl);
vfloat16m1_t __riscv_vrgather_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t index, size_t vl);
vfloat16m2_t __riscv_vrgather_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t index, size_t vl);
vfloat16m2_t __riscv_vrgather_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t index, size_t vl);
vfloat16m4_t __riscv_vrgather_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t index, size_t vl);
vfloat16m4_t __riscv_vrgather_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t index, size_t vl);
vfloat16m8_t __riscv_vrgather_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t index, size_t vl);
vfloat16m8_t __riscv_vrgather_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t index, size_t vl);
vfloat32mf2_t __riscv_vrgather_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vuint32mf2_t index, size_t vl);
vfloat32mf2_t __riscv_vrgather_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t index, size_t vl);
vfloat32m1_t __riscv_vrgather_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint32m1_t index, size_t vl);
vfloat32m1_t __riscv_vrgather_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t index, size_t vl);
vfloat32m2_t __riscv_vrgather_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint32m2_t index, size_t vl);
vfloat32m2_t __riscv_vrgather_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t index, size_t vl);
vfloat32m4_t __riscv_vrgather_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint32m4_t index, size_t vl);
vfloat32m4_t __riscv_vrgather_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t index, size_t vl);
vfloat32m8_t __riscv_vrgather_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint32m8_t index, size_t vl);
vfloat32m8_t __riscv_vrgather_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t index, size_t vl);
vfloat64m1_t __riscv_vrgather_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint64m1_t index, size_t vl);
vfloat64m1_t __riscv_vrgather_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t index, size_t vl);
vfloat64m2_t __riscv_vrgather_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint64m2_t index, size_t vl);
vfloat64m2_t __riscv_vrgather_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t index, size_t vl);
vfloat64m4_t __riscv_vrgather_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint64m4_t index, size_t vl);
vfloat64m4_t __riscv_vrgather_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t index, size_t vl);
vfloat64m8_t __riscv_vrgather_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint64m8_t index, size_t vl);
vfloat64m8_t __riscv_vrgather_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t index, size_t vl);
vfloat16mf4_t __riscv_vrgatherei16_tum (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vuint16mf4_t op2, size_t vl);
vfloat16mf2_t __riscv_vrgatherei16_tum (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vuint16mf2_t op2, size_t vl);
vfloat16m1_t __riscv_vrgatherei16_tum (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t op2, size_t vl);
vfloat16m2_t __riscv_vrgatherei16_tum (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t op2, size_t vl);
vfloat16m4_t __riscv_vrgatherei16_tum (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t op2, size_t vl);
vfloat16m8_t __riscv_vrgatherei16_tum (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t op2, size_t vl);
vfloat32mf2_t __riscv_vrgatherei16_tum (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vuint16mf4_t op2, size_t vl);
vfloat32m1_t __riscv_vrgatherei16_tum (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint16mf2_t op2, size_t vl);
vfloat32m2_t __riscv_vrgatherei16_tum (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint16m1_t op2, size_t vl);
vfloat32m4_t __riscv_vrgatherei16_tum (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint16m2_t op2, size_t vl);
vfloat32m8_t __riscv_vrgatherei16_tum (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint16m4_t op2, size_t vl);
vfloat64m1_t __riscv_vrgatherei16_tum (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint16mf4_t op2, size_t vl);
vfloat64m2_t __riscv_vrgatherei16_tum (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint16mf2_t op2, size_t vl);
vfloat64m4_t __riscv_vrgatherei16_tum (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint16m1_t op2, size_t vl);
vfloat64m8_t __riscv_vrgatherei16_tum (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint16m2_t op2, size_t vl);
vint8mf8_t __riscv_vrgather_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t index, size_t vl);
vint8mf8_t __riscv_vrgather_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t index, size_t vl);
vint8mf4_t __riscv_vrgather_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t index, size_t vl);
vint8mf4_t __riscv_vrgather_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t index, size_t vl);
vint8mf2_t __riscv_vrgather_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t index, size_t vl);
vint8mf2_t __riscv_vrgather_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t index, size_t vl);
vint8m1_t __riscv_vrgather_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t index, size_t vl);
vint8m1_t __riscv_vrgather_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t index, size_t vl);
vint8m2_t __riscv_vrgather_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t index, size_t vl);
vint8m2_t __riscv_vrgather_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t index, size_t vl);
vint8m4_t __riscv_vrgather_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t index, size_t vl);
vint8m4_t __riscv_vrgather_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t index, size_t vl);
vint8m8_t __riscv_vrgather_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t index, size_t vl);
vint8m8_t __riscv_vrgather_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t index, size_t vl);
vint16mf4_t __riscv_vrgather_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t index, size_t vl);
vint16mf4_t __riscv_vrgather_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t index, size_t vl);
vint16mf2_t __riscv_vrgather_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t index, size_t vl);
vint16mf2_t __riscv_vrgather_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t index, size_t vl);
vint16m1_t __riscv_vrgather_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t index, size_t vl);
vint16m1_t __riscv_vrgather_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t index, size_t vl);
vint16m2_t __riscv_vrgather_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t index, size_t vl);
vint16m2_t __riscv_vrgather_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t index, size_t vl);
vint16m4_t __riscv_vrgather_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t index, size_t vl);
vint16m4_t __riscv_vrgather_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t index, size_t vl);
vint16m8_t __riscv_vrgather_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t index, size_t vl);
vint16m8_t __riscv_vrgather_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t index, size_t vl);
vint32mf2_t __riscv_vrgather_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t index, size_t vl);
vint32mf2_t __riscv_vrgather_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t index, size_t vl);
vint32m1_t __riscv_vrgather_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t index, size_t vl);
vint32m1_t __riscv_vrgather_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t index, size_t vl);
vint32m2_t __riscv_vrgather_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t index, size_t vl);
vint32m2_t __riscv_vrgather_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t index, size_t vl);
vint32m4_t __riscv_vrgather_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t index, size_t vl);
vint32m4_t __riscv_vrgather_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t index, size_t vl);
vint32m8_t __riscv_vrgather_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t index, size_t vl);
vint32m8_t __riscv_vrgather_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t index, size_t vl);
vint64m1_t __riscv_vrgather_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t index, size_t vl);
vint64m1_t __riscv_vrgather_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t index, size_t vl);
vint64m2_t __riscv_vrgather_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t index, size_t vl);
vint64m2_t __riscv_vrgather_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t index, size_t vl);
vint64m4_t __riscv_vrgather_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t index, size_t vl);
vint64m4_t __riscv_vrgather_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t index, size_t vl);
vint64m8_t __riscv_vrgather_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t index, size_t vl);
vint64m8_t __riscv_vrgather_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t index, size_t vl);
vint8mf8_t __riscv_vrgatherei16_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint16mf4_t op2, size_t vl);
vint8mf4_t __riscv_vrgatherei16_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint16mf2_t op2, size_t vl);
vint8mf2_t __riscv_vrgatherei16_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint16m1_t op2, size_t vl);
vint8m1_t __riscv_vrgatherei16_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint16m2_t op2, size_t vl);
vint8m2_t __riscv_vrgatherei16_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint16m4_t op2, size_t vl);
vint8m4_t __riscv_vrgatherei16_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint16m8_t op2, size_t vl);
vint16mf4_t __riscv_vrgatherei16_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint16mf2_t __riscv_vrgatherei16_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint16m1_t __riscv_vrgatherei16_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint16m2_t __riscv_vrgatherei16_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint16m4_t __riscv_vrgatherei16_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint16m8_t __riscv_vrgatherei16_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2, size_t vl);
vint32mf2_t __riscv_vrgatherei16_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vint32m1_t __riscv_vrgatherei16_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint16mf2_t op2, size_t vl);
vint32m2_t __riscv_vrgatherei16_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint16m1_t op2, size_t vl);
vint32m4_t __riscv_vrgatherei16_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint16m2_t op2, size_t vl);
vint32m8_t __riscv_vrgatherei16_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint16m4_t op2, size_t vl);
vint64m1_t __riscv_vrgatherei16_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint16mf4_t op2, size_t vl);
vint64m2_t __riscv_vrgatherei16_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint16mf2_t op2, size_t vl);
vint64m4_t __riscv_vrgatherei16_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint16m1_t op2, size_t vl);
vint64m8_t __riscv_vrgatherei16_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint16m2_t op2, size_t vl);
vuint8mf8_t __riscv_vrgather_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t index, size_t vl);
vuint8mf8_t __riscv_vrgather_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t index, size_t vl);
vuint8mf4_t __riscv_vrgather_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t index, size_t vl);
vuint8mf4_t __riscv_vrgather_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t index, size_t vl);
vuint8mf2_t __riscv_vrgather_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t index, size_t vl);
vuint8mf2_t __riscv_vrgather_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t index, size_t vl);
vuint8m1_t __riscv_vrgather_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t index, size_t vl);
vuint8m1_t __riscv_vrgather_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t index, size_t vl);
vuint8m2_t __riscv_vrgather_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t index, size_t vl);
vuint8m2_t __riscv_vrgather_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t index, size_t vl);
vuint8m4_t __riscv_vrgather_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t index, size_t vl);
vuint8m4_t __riscv_vrgather_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t index, size_t vl);
vuint8m8_t __riscv_vrgather_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t index, size_t vl);
vuint8m8_t __riscv_vrgather_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t index, size_t vl);
vuint16mf4_t __riscv_vrgather_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t index, size_t vl);
vuint16mf4_t __riscv_vrgather_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t index, size_t vl);
vuint16mf2_t __riscv_vrgather_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t index, size_t vl);
vuint16mf2_t __riscv_vrgather_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t index, size_t vl);
vuint16m1_t __riscv_vrgather_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t index, size_t vl);
vuint16m1_t __riscv_vrgather_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t index, size_t vl);
vuint16m2_t __riscv_vrgather_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t index, size_t vl);
vuint16m2_t __riscv_vrgather_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t index, size_t vl);
vuint16m4_t __riscv_vrgather_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t index, size_t vl);
vuint16m4_t __riscv_vrgather_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t index, size_t vl);
vuint16m8_t __riscv_vrgather_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t index, size_t vl);
vuint16m8_t __riscv_vrgather_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t index, size_t vl);
vuint32mf2_t __riscv_vrgather_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t index, size_t vl);
vuint32mf2_t __riscv_vrgather_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t index, size_t vl);
vuint32m1_t __riscv_vrgather_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t index, size_t vl);
vuint32m1_t __riscv_vrgather_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t index, size_t vl);
vuint32m2_t __riscv_vrgather_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t index, size_t vl);
vuint32m2_t __riscv_vrgather_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t index, size_t vl);
vuint32m4_t __riscv_vrgather_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t index, size_t vl);
vuint32m4_t __riscv_vrgather_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t index, size_t vl);
vuint32m8_t __riscv_vrgather_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t index, size_t vl);
vuint32m8_t __riscv_vrgather_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t index, size_t vl);
vuint64m1_t __riscv_vrgather_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t index, size_t vl);
vuint64m1_t __riscv_vrgather_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t index, size_t vl);
vuint64m2_t __riscv_vrgather_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t index, size_t vl);
vuint64m2_t __riscv_vrgather_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t index, size_t vl);
vuint64m4_t __riscv_vrgather_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t index, size_t vl);
vuint64m4_t __riscv_vrgather_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t index, size_t vl);
vuint64m8_t __riscv_vrgather_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t index, size_t vl);
vuint64m8_t __riscv_vrgather_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t index, size_t vl);
vuint8mf8_t __riscv_vrgatherei16_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint16mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vrgatherei16_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint16mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vrgatherei16_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint16m1_t op2, size_t vl);
vuint8m1_t __riscv_vrgatherei16_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint16m2_t op2, size_t vl);
vuint8m2_t __riscv_vrgatherei16_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint16m4_t op2, size_t vl);
vuint8m4_t __riscv_vrgatherei16_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint16m8_t op2, size_t vl);
vuint16mf4_t __riscv_vrgatherei16_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vrgatherei16_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16m1_t __riscv_vrgatherei16_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m2_t __riscv_vrgatherei16_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m4_t __riscv_vrgatherei16_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m8_t __riscv_vrgatherei16_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint32mf2_t __riscv_vrgatherei16_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32m1_t __riscv_vrgatherei16_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m2_t __riscv_vrgatherei16_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m4_t __riscv_vrgatherei16_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m8_t __riscv_vrgatherei16_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint64m1_t __riscv_vrgatherei16_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint16mf4_t op2, size_t vl);
vuint64m2_t __riscv_vrgatherei16_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint16mf2_t op2, size_t vl);
vuint64m4_t __riscv_vrgatherei16_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint16m1_t op2, size_t vl);
vuint64m8_t __riscv_vrgatherei16_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint16m2_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vrgather_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vuint16mf4_t index, size_t vl);
vfloat16mf4_t __riscv_vrgather_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t index, size_t vl);
vfloat16mf2_t __riscv_vrgather_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vuint16mf2_t index, size_t vl);
vfloat16mf2_t __riscv_vrgather_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t index, size_t vl);
vfloat16m1_t __riscv_vrgather_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t index, size_t vl);
vfloat16m1_t __riscv_vrgather_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t index, size_t vl);
vfloat16m2_t __riscv_vrgather_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t index, size_t vl);
vfloat16m2_t __riscv_vrgather_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t index, size_t vl);
vfloat16m4_t __riscv_vrgather_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t index, size_t vl);
vfloat16m4_t __riscv_vrgather_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t index, size_t vl);
vfloat16m8_t __riscv_vrgather_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t index, size_t vl);
vfloat16m8_t __riscv_vrgather_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t index, size_t vl);
vfloat32mf2_t __riscv_vrgather_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vuint32mf2_t index, size_t vl);
vfloat32mf2_t __riscv_vrgather_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t index, size_t vl);
vfloat32m1_t __riscv_vrgather_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint32m1_t index, size_t vl);
vfloat32m1_t __riscv_vrgather_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t index, size_t vl);
vfloat32m2_t __riscv_vrgather_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint32m2_t index, size_t vl);
vfloat32m2_t __riscv_vrgather_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t index, size_t vl);
vfloat32m4_t __riscv_vrgather_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint32m4_t index, size_t vl);
vfloat32m4_t __riscv_vrgather_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t index, size_t vl);
vfloat32m8_t __riscv_vrgather_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint32m8_t index, size_t vl);
vfloat32m8_t __riscv_vrgather_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t index, size_t vl);
vfloat64m1_t __riscv_vrgather_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint64m1_t index, size_t vl);
vfloat64m1_t __riscv_vrgather_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t index, size_t vl);
vfloat64m2_t __riscv_vrgather_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint64m2_t index, size_t vl);
vfloat64m2_t __riscv_vrgather_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t index, size_t vl);
vfloat64m4_t __riscv_vrgather_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint64m4_t index, size_t vl);
vfloat64m4_t __riscv_vrgather_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t index, size_t vl);
vfloat64m8_t __riscv_vrgather_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint64m8_t index, size_t vl);
vfloat64m8_t __riscv_vrgather_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t index, size_t vl);
vfloat16mf4_t __riscv_vrgatherei16_tumu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vuint16mf4_t op2, size_t vl);
vfloat16mf2_t __riscv_vrgatherei16_tumu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vuint16mf2_t op2, size_t vl);
vfloat16m1_t __riscv_vrgatherei16_tumu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t op2, size_t vl);
vfloat16m2_t __riscv_vrgatherei16_tumu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t op2, size_t vl);
vfloat16m4_t __riscv_vrgatherei16_tumu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t op2, size_t vl);
vfloat16m8_t __riscv_vrgatherei16_tumu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t op2, size_t vl);
vfloat32mf2_t __riscv_vrgatherei16_tumu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vuint16mf4_t op2, size_t vl);
vfloat32m1_t __riscv_vrgatherei16_tumu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint16mf2_t op2, size_t vl);
vfloat32m2_t __riscv_vrgatherei16_tumu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint16m1_t op2, size_t vl);
vfloat32m4_t __riscv_vrgatherei16_tumu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint16m2_t op2, size_t vl);
vfloat32m8_t __riscv_vrgatherei16_tumu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint16m4_t op2, size_t vl);
vfloat64m1_t __riscv_vrgatherei16_tumu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint16mf4_t op2, size_t vl);
vfloat64m2_t __riscv_vrgatherei16_tumu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint16mf2_t op2, size_t vl);
vfloat64m4_t __riscv_vrgatherei16_tumu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint16m1_t op2, size_t vl);
vfloat64m8_t __riscv_vrgatherei16_tumu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint16m2_t op2, size_t vl);
vint8mf8_t __riscv_vrgather_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t index, size_t vl);
vint8mf8_t __riscv_vrgather_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t index, size_t vl);
vint8mf4_t __riscv_vrgather_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t index, size_t vl);
vint8mf4_t __riscv_vrgather_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t index, size_t vl);
vint8mf2_t __riscv_vrgather_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t index, size_t vl);
vint8mf2_t __riscv_vrgather_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t index, size_t vl);
vint8m1_t __riscv_vrgather_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t index, size_t vl);
vint8m1_t __riscv_vrgather_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t index, size_t vl);
vint8m2_t __riscv_vrgather_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t index, size_t vl);
vint8m2_t __riscv_vrgather_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t index, size_t vl);
vint8m4_t __riscv_vrgather_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t index, size_t vl);
vint8m4_t __riscv_vrgather_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t index, size_t vl);
vint8m8_t __riscv_vrgather_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t index, size_t vl);
vint8m8_t __riscv_vrgather_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t index, size_t vl);
vint16mf4_t __riscv_vrgather_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t index, size_t vl);
vint16mf4_t __riscv_vrgather_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t index, size_t vl);
vint16mf2_t __riscv_vrgather_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t index, size_t vl);
vint16mf2_t __riscv_vrgather_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t index, size_t vl);
vint16m1_t __riscv_vrgather_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t index, size_t vl);
vint16m1_t __riscv_vrgather_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t index, size_t vl);
vint16m2_t __riscv_vrgather_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t index, size_t vl);
vint16m2_t __riscv_vrgather_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t index, size_t vl);
vint16m4_t __riscv_vrgather_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t index, size_t vl);
vint16m4_t __riscv_vrgather_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t index, size_t vl);
vint16m8_t __riscv_vrgather_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t index, size_t vl);
vint16m8_t __riscv_vrgather_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t index, size_t vl);
vint32mf2_t __riscv_vrgather_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t index, size_t vl);
vint32mf2_t __riscv_vrgather_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t index, size_t vl);
vint32m1_t __riscv_vrgather_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t index, size_t vl);
vint32m1_t __riscv_vrgather_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t index, size_t vl);
vint32m2_t __riscv_vrgather_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t index, size_t vl);
vint32m2_t __riscv_vrgather_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t index, size_t vl);
vint32m4_t __riscv_vrgather_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t index, size_t vl);
vint32m4_t __riscv_vrgather_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t index, size_t vl);
vint32m8_t __riscv_vrgather_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t index, size_t vl);
vint32m8_t __riscv_vrgather_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t index, size_t vl);
vint64m1_t __riscv_vrgather_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t index, size_t vl);
vint64m1_t __riscv_vrgather_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t index, size_t vl);
vint64m2_t __riscv_vrgather_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t index, size_t vl);
vint64m2_t __riscv_vrgather_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t index, size_t vl);
vint64m4_t __riscv_vrgather_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t index, size_t vl);
vint64m4_t __riscv_vrgather_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t index, size_t vl);
vint64m8_t __riscv_vrgather_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t index, size_t vl);
vint64m8_t __riscv_vrgather_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t index, size_t vl);
vint8mf8_t __riscv_vrgatherei16_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint16mf4_t op2, size_t vl);
vint8mf4_t __riscv_vrgatherei16_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint16mf2_t op2, size_t vl);
vint8mf2_t __riscv_vrgatherei16_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint16m1_t op2, size_t vl);
vint8m1_t __riscv_vrgatherei16_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint16m2_t op2, size_t vl);
vint8m2_t __riscv_vrgatherei16_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint16m4_t op2, size_t vl);
vint8m4_t __riscv_vrgatherei16_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint16m8_t op2, size_t vl);
vint16mf4_t __riscv_vrgatherei16_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint16mf2_t __riscv_vrgatherei16_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint16m1_t __riscv_vrgatherei16_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint16m2_t __riscv_vrgatherei16_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint16m4_t __riscv_vrgatherei16_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint16m8_t __riscv_vrgatherei16_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2, size_t vl);
vint32mf2_t __riscv_vrgatherei16_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vint32m1_t __riscv_vrgatherei16_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint16mf2_t op2, size_t vl);
vint32m2_t __riscv_vrgatherei16_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint16m1_t op2, size_t vl);
vint32m4_t __riscv_vrgatherei16_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint16m2_t op2, size_t vl);
vint32m8_t __riscv_vrgatherei16_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint16m4_t op2, size_t vl);
vint64m1_t __riscv_vrgatherei16_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint16mf4_t op2, size_t vl);
vint64m2_t __riscv_vrgatherei16_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint16mf2_t op2, size_t vl);
vint64m4_t __riscv_vrgatherei16_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint16m1_t op2, size_t vl);
vint64m8_t __riscv_vrgatherei16_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint16m2_t op2, size_t vl);
vuint8mf8_t __riscv_vrgather_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t index, size_t vl);
vuint8mf8_t __riscv_vrgather_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t index, size_t vl);
vuint8mf4_t __riscv_vrgather_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t index, size_t vl);
vuint8mf4_t __riscv_vrgather_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t index, size_t vl);
vuint8mf2_t __riscv_vrgather_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t index, size_t vl);
vuint8mf2_t __riscv_vrgather_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t index, size_t vl);
vuint8m1_t __riscv_vrgather_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t index, size_t vl);
vuint8m1_t __riscv_vrgather_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t index, size_t vl);
vuint8m2_t __riscv_vrgather_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t index, size_t vl);
vuint8m2_t __riscv_vrgather_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t index, size_t vl);
vuint8m4_t __riscv_vrgather_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t index, size_t vl);
vuint8m4_t __riscv_vrgather_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t index, size_t vl);
vuint8m8_t __riscv_vrgather_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t index, size_t vl);
vuint8m8_t __riscv_vrgather_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t index, size_t vl);
vuint16mf4_t __riscv_vrgather_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t index, size_t vl);
vuint16mf4_t __riscv_vrgather_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t index, size_t vl);
vuint16mf2_t __riscv_vrgather_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t index, size_t vl);
vuint16mf2_t __riscv_vrgather_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t index, size_t vl);
vuint16m1_t __riscv_vrgather_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t index, size_t vl);
vuint16m1_t __riscv_vrgather_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t index, size_t vl);
vuint16m2_t __riscv_vrgather_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t index, size_t vl);
vuint16m2_t __riscv_vrgather_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t index, size_t vl);
vuint16m4_t __riscv_vrgather_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t index, size_t vl);
vuint16m4_t __riscv_vrgather_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t index, size_t vl);
vuint16m8_t __riscv_vrgather_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t index, size_t vl);
vuint16m8_t __riscv_vrgather_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t index, size_t vl);
vuint32mf2_t __riscv_vrgather_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t index, size_t vl);
vuint32mf2_t __riscv_vrgather_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t index, size_t vl);
vuint32m1_t __riscv_vrgather_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t index, size_t vl);
vuint32m1_t __riscv_vrgather_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t index, size_t vl);
vuint32m2_t __riscv_vrgather_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t index, size_t vl);
vuint32m2_t __riscv_vrgather_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t index, size_t vl);
vuint32m4_t __riscv_vrgather_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t index, size_t vl);
vuint32m4_t __riscv_vrgather_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t index, size_t vl);
vuint32m8_t __riscv_vrgather_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t index, size_t vl);
vuint32m8_t __riscv_vrgather_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t index, size_t vl);
vuint64m1_t __riscv_vrgather_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t index, size_t vl);
vuint64m1_t __riscv_vrgather_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t index, size_t vl);
vuint64m2_t __riscv_vrgather_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t index, size_t vl);
vuint64m2_t __riscv_vrgather_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t index, size_t vl);
vuint64m4_t __riscv_vrgather_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t index, size_t vl);
vuint64m4_t __riscv_vrgather_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t index, size_t vl);
vuint64m8_t __riscv_vrgather_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t index, size_t vl);
vuint64m8_t __riscv_vrgather_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t index, size_t vl);
vuint8mf8_t __riscv_vrgatherei16_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint16mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vrgatherei16_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint16mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vrgatherei16_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint16m1_t op2, size_t vl);
vuint8m1_t __riscv_vrgatherei16_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint16m2_t op2, size_t vl);
vuint8m2_t __riscv_vrgatherei16_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint16m4_t op2, size_t vl);
vuint8m4_t __riscv_vrgatherei16_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint16m8_t op2, size_t vl);
vuint16mf4_t __riscv_vrgatherei16_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vrgatherei16_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16m1_t __riscv_vrgatherei16_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m2_t __riscv_vrgatherei16_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m4_t __riscv_vrgatherei16_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m8_t __riscv_vrgatherei16_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint32mf2_t __riscv_vrgatherei16_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32m1_t __riscv_vrgatherei16_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m2_t __riscv_vrgatherei16_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m4_t __riscv_vrgatherei16_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m8_t __riscv_vrgatherei16_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint64m1_t __riscv_vrgatherei16_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint16mf4_t op2, size_t vl);
vuint64m2_t __riscv_vrgatherei16_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint16mf2_t op2, size_t vl);
vuint64m4_t __riscv_vrgatherei16_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint16m1_t op2, size_t vl);
vuint64m8_t __riscv_vrgatherei16_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint16m2_t op2, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vrgather_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vuint16mf4_t index, size_t vl);
vfloat16mf4_t __riscv_vrgather_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, size_t index, size_t vl);
vfloat16mf2_t __riscv_vrgather_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vuint16mf2_t index, size_t vl);
vfloat16mf2_t __riscv_vrgather_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, size_t index, size_t vl);
vfloat16m1_t __riscv_vrgather_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t index, size_t vl);
vfloat16m1_t __riscv_vrgather_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, size_t index, size_t vl);
vfloat16m2_t __riscv_vrgather_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t index, size_t vl);
vfloat16m2_t __riscv_vrgather_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, size_t index, size_t vl);
vfloat16m4_t __riscv_vrgather_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t index, size_t vl);
vfloat16m4_t __riscv_vrgather_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, size_t index, size_t vl);
vfloat16m8_t __riscv_vrgather_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t index, size_t vl);
vfloat16m8_t __riscv_vrgather_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, size_t index, size_t vl);
vfloat32mf2_t __riscv_vrgather_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vuint32mf2_t index, size_t vl);
vfloat32mf2_t __riscv_vrgather_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, size_t index, size_t vl);
vfloat32m1_t __riscv_vrgather_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint32m1_t index, size_t vl);
vfloat32m1_t __riscv_vrgather_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, size_t index, size_t vl);
vfloat32m2_t __riscv_vrgather_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint32m2_t index, size_t vl);
vfloat32m2_t __riscv_vrgather_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, size_t index, size_t vl);
vfloat32m4_t __riscv_vrgather_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint32m4_t index, size_t vl);
vfloat32m4_t __riscv_vrgather_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, size_t index, size_t vl);
vfloat32m8_t __riscv_vrgather_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint32m8_t index, size_t vl);
vfloat32m8_t __riscv_vrgather_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, size_t index, size_t vl);
vfloat64m1_t __riscv_vrgather_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint64m1_t index, size_t vl);
vfloat64m1_t __riscv_vrgather_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, size_t index, size_t vl);
vfloat64m2_t __riscv_vrgather_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint64m2_t index, size_t vl);
vfloat64m2_t __riscv_vrgather_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, size_t index, size_t vl);
vfloat64m4_t __riscv_vrgather_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint64m4_t index, size_t vl);
vfloat64m4_t __riscv_vrgather_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, size_t index, size_t vl);
vfloat64m8_t __riscv_vrgather_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint64m8_t index, size_t vl);
vfloat64m8_t __riscv_vrgather_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, size_t index, size_t vl);
vfloat16mf4_t __riscv_vrgatherei16_mu (vbool64_t mask, vfloat16mf4_t maskedoff, vfloat16mf4_t op1, vuint16mf4_t op2, size_t vl);
vfloat16mf2_t __riscv_vrgatherei16_mu (vbool32_t mask, vfloat16mf2_t maskedoff, vfloat16mf2_t op1, vuint16mf2_t op2, size_t vl);
vfloat16m1_t __riscv_vrgatherei16_mu (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t op2, size_t vl);
vfloat16m2_t __riscv_vrgatherei16_mu (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t op2, size_t vl);
vfloat16m4_t __riscv_vrgatherei16_mu (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t op2, size_t vl);
vfloat16m8_t __riscv_vrgatherei16_mu (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t op2, size_t vl);
vfloat32mf2_t __riscv_vrgatherei16_mu (vbool64_t mask, vfloat32mf2_t maskedoff, vfloat32mf2_t op1, vuint16mf4_t op2, size_t vl);
vfloat32m1_t __riscv_vrgatherei16_mu (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint16mf2_t op2, size_t vl);
vfloat32m2_t __riscv_vrgatherei16_mu (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint16m1_t op2, size_t vl);
vfloat32m4_t __riscv_vrgatherei16_mu (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint16m2_t op2, size_t vl);
vfloat32m8_t __riscv_vrgatherei16_mu (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint16m4_t op2, size_t vl);
vfloat64m1_t __riscv_vrgatherei16_mu (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint16mf4_t op2, size_t vl);
vfloat64m2_t __riscv_vrgatherei16_mu (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint16mf2_t op2, size_t vl);
vfloat64m4_t __riscv_vrgatherei16_mu (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint16m1_t op2, size_t vl);
vfloat64m8_t __riscv_vrgatherei16_mu (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint16m2_t op2, size_t vl);
vint8mf8_t __riscv_vrgather_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t index, size_t vl);
vint8mf8_t __riscv_vrgather_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t index, size_t vl);
vint8mf4_t __riscv_vrgather_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t index, size_t vl);
vint8mf4_t __riscv_vrgather_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t index, size_t vl);
vint8mf2_t __riscv_vrgather_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t index, size_t vl);
vint8mf2_t __riscv_vrgather_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t index, size_t vl);
vint8m1_t __riscv_vrgather_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t index, size_t vl);
vint8m1_t __riscv_vrgather_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t index, size_t vl);
vint8m2_t __riscv_vrgather_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t index, size_t vl);
vint8m2_t __riscv_vrgather_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t index, size_t vl);
vint8m4_t __riscv_vrgather_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t index, size_t vl);
vint8m4_t __riscv_vrgather_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t index, size_t vl);
vint8m8_t __riscv_vrgather_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t index, size_t vl);
vint8m8_t __riscv_vrgather_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t index, size_t vl);
vint16mf4_t __riscv_vrgather_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t index, size_t vl);
vint16mf4_t __riscv_vrgather_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t index, size_t vl);
vint16mf2_t __riscv_vrgather_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t index, size_t vl);
vint16mf2_t __riscv_vrgather_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t index, size_t vl);
vint16m1_t __riscv_vrgather_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t index, size_t vl);
vint16m1_t __riscv_vrgather_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t index, size_t vl);
vint16m2_t __riscv_vrgather_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t index, size_t vl);
vint16m2_t __riscv_vrgather_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t index, size_t vl);
vint16m4_t __riscv_vrgather_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t index, size_t vl);
vint16m4_t __riscv_vrgather_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t index, size_t vl);
vint16m8_t __riscv_vrgather_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t index, size_t vl);
vint16m8_t __riscv_vrgather_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t index, size_t vl);
vint32mf2_t __riscv_vrgather_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t index, size_t vl);
vint32mf2_t __riscv_vrgather_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t index, size_t vl);
vint32m1_t __riscv_vrgather_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t index, size_t vl);
vint32m1_t __riscv_vrgather_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t index, size_t vl);
vint32m2_t __riscv_vrgather_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t index, size_t vl);
vint32m2_t __riscv_vrgather_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t index, size_t vl);
vint32m4_t __riscv_vrgather_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t index, size_t vl);
vint32m4_t __riscv_vrgather_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t index, size_t vl);
vint32m8_t __riscv_vrgather_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t index, size_t vl);
vint32m8_t __riscv_vrgather_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t index, size_t vl);
vint64m1_t __riscv_vrgather_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t index, size_t vl);
vint64m1_t __riscv_vrgather_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t index, size_t vl);
vint64m2_t __riscv_vrgather_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t index, size_t vl);
vint64m2_t __riscv_vrgather_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t index, size_t vl);
vint64m4_t __riscv_vrgather_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t index, size_t vl);
vint64m4_t __riscv_vrgather_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t index, size_t vl);
vint64m8_t __riscv_vrgather_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t index, size_t vl);
vint64m8_t __riscv_vrgather_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t index, size_t vl);
vint8mf8_t __riscv_vrgatherei16_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint16mf4_t op2, size_t vl);
vint8mf4_t __riscv_vrgatherei16_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint16mf2_t op2, size_t vl);
vint8mf2_t __riscv_vrgatherei16_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint16m1_t op2, size_t vl);
vint8m1_t __riscv_vrgatherei16_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint16m2_t op2, size_t vl);
vint8m2_t __riscv_vrgatherei16_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint16m4_t op2, size_t vl);
vint8m4_t __riscv_vrgatherei16_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint16m8_t op2, size_t vl);
vint16mf4_t __riscv_vrgatherei16_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vint16mf2_t __riscv_vrgatherei16_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vint16m1_t __riscv_vrgatherei16_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2, size_t vl);
vint16m2_t __riscv_vrgatherei16_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2, size_t vl);
vint16m4_t __riscv_vrgatherei16_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2, size_t vl);
vint16m8_t __riscv_vrgatherei16_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2, size_t vl);
vint32mf2_t __riscv_vrgatherei16_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vint32m1_t __riscv_vrgatherei16_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint16mf2_t op2, size_t vl);
vint32m2_t __riscv_vrgatherei16_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint16m1_t op2, size_t vl);
vint32m4_t __riscv_vrgatherei16_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint16m2_t op2, size_t vl);
vint32m8_t __riscv_vrgatherei16_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint16m4_t op2, size_t vl);
vint64m1_t __riscv_vrgatherei16_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint16mf4_t op2, size_t vl);
vint64m2_t __riscv_vrgatherei16_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint16mf2_t op2, size_t vl);
vint64m4_t __riscv_vrgatherei16_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint16m1_t op2, size_t vl);
vint64m8_t __riscv_vrgatherei16_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint16m2_t op2, size_t vl);
vuint8mf8_t __riscv_vrgather_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t index, size_t vl);
vuint8mf8_t __riscv_vrgather_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t index, size_t vl);
vuint8mf4_t __riscv_vrgather_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t index, size_t vl);
vuint8mf4_t __riscv_vrgather_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t index, size_t vl);
vuint8mf2_t __riscv_vrgather_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t index, size_t vl);
vuint8mf2_t __riscv_vrgather_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t index, size_t vl);
vuint8m1_t __riscv_vrgather_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t index, size_t vl);
vuint8m1_t __riscv_vrgather_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t index, size_t vl);
vuint8m2_t __riscv_vrgather_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t index, size_t vl);
vuint8m2_t __riscv_vrgather_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t index, size_t vl);
vuint8m4_t __riscv_vrgather_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t index, size_t vl);
vuint8m4_t __riscv_vrgather_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t index, size_t vl);
vuint8m8_t __riscv_vrgather_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t index, size_t vl);
vuint8m8_t __riscv_vrgather_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t index, size_t vl);
vuint16mf4_t __riscv_vrgather_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t index, size_t vl);
vuint16mf4_t __riscv_vrgather_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t index, size_t vl);
vuint16mf2_t __riscv_vrgather_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t index, size_t vl);
vuint16mf2_t __riscv_vrgather_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t index, size_t vl);
vuint16m1_t __riscv_vrgather_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t index, size_t vl);
vuint16m1_t __riscv_vrgather_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t index, size_t vl);
vuint16m2_t __riscv_vrgather_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t index, size_t vl);
vuint16m2_t __riscv_vrgather_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t index, size_t vl);
vuint16m4_t __riscv_vrgather_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t index, size_t vl);
vuint16m4_t __riscv_vrgather_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t index, size_t vl);
vuint16m8_t __riscv_vrgather_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t index, size_t vl);
vuint16m8_t __riscv_vrgather_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t index, size_t vl);
vuint32mf2_t __riscv_vrgather_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t index, size_t vl);
vuint32mf2_t __riscv_vrgather_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t index, size_t vl);
vuint32m1_t __riscv_vrgather_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t index, size_t vl);
vuint32m1_t __riscv_vrgather_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t index, size_t vl);
vuint32m2_t __riscv_vrgather_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t index, size_t vl);
vuint32m2_t __riscv_vrgather_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t index, size_t vl);
vuint32m4_t __riscv_vrgather_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t index, size_t vl);
vuint32m4_t __riscv_vrgather_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t index, size_t vl);
vuint32m8_t __riscv_vrgather_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t index, size_t vl);
vuint32m8_t __riscv_vrgather_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t index, size_t vl);
vuint64m1_t __riscv_vrgather_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t index, size_t vl);
vuint64m1_t __riscv_vrgather_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t index, size_t vl);
vuint64m2_t __riscv_vrgather_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t index, size_t vl);
vuint64m2_t __riscv_vrgather_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t index, size_t vl);
vuint64m4_t __riscv_vrgather_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t index, size_t vl);
vuint64m4_t __riscv_vrgather_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t index, size_t vl);
vuint64m8_t __riscv_vrgather_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t index, size_t vl);
vuint64m8_t __riscv_vrgather_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t index, size_t vl);
vuint8mf8_t __riscv_vrgatherei16_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint16mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vrgatherei16_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint16mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vrgatherei16_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint16m1_t op2, size_t vl);
vuint8m1_t __riscv_vrgatherei16_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint16m2_t op2, size_t vl);
vuint8m2_t __riscv_vrgatherei16_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint16m4_t op2, size_t vl);
vuint8m4_t __riscv_vrgatherei16_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint16m8_t op2, size_t vl);
vuint16mf4_t __riscv_vrgatherei16_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf2_t __riscv_vrgatherei16_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16m1_t __riscv_vrgatherei16_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m2_t __riscv_vrgatherei16_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m4_t __riscv_vrgatherei16_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m8_t __riscv_vrgatherei16_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint32mf2_t __riscv_vrgatherei16_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint16mf4_t op2, size_t vl);
vuint32m1_t __riscv_vrgatherei16_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint16mf2_t op2, size_t vl);
vuint32m2_t __riscv_vrgatherei16_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2, size_t vl);
vuint32m4_t __riscv_vrgatherei16_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2, size_t vl);
vuint32m8_t __riscv_vrgatherei16_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2, size_t vl);
vuint64m1_t __riscv_vrgatherei16_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint16mf4_t op2, size_t vl);
vuint64m2_t __riscv_vrgatherei16_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint16mf2_t op2, size_t vl);
vuint64m4_t __riscv_vrgatherei16_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint16m1_t op2, size_t vl);
vuint64m8_t __riscv_vrgatherei16_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint16m2_t op2, size_t vl);
```

[[policy-variant-overloadedvector-compress]]
=== Vector Compress Intrinsics

``` C
vfloat16mf4_t __riscv_vcompress_tu (vfloat16mf4_t maskedoff, vfloat16mf4_t src, vbool64_t mask, size_t vl);
vfloat16mf2_t __riscv_vcompress_tu (vfloat16mf2_t maskedoff, vfloat16mf2_t src, vbool32_t mask, size_t vl);
vfloat16m1_t __riscv_vcompress_tu (vfloat16m1_t maskedoff, vfloat16m1_t src, vbool16_t mask, size_t vl);
vfloat16m2_t __riscv_vcompress_tu (vfloat16m2_t maskedoff, vfloat16m2_t src, vbool8_t mask, size_t vl);
vfloat16m4_t __riscv_vcompress_tu (vfloat16m4_t maskedoff, vfloat16m4_t src, vbool4_t mask, size_t vl);
vfloat16m8_t __riscv_vcompress_tu (vfloat16m8_t maskedoff, vfloat16m8_t src, vbool2_t mask, size_t vl);
vfloat32mf2_t __riscv_vcompress_tu (vfloat32mf2_t maskedoff, vfloat32mf2_t src, vbool64_t mask, size_t vl);
vfloat32m1_t __riscv_vcompress_tu (vfloat32m1_t maskedoff, vfloat32m1_t src, vbool32_t mask, size_t vl);
vfloat32m2_t __riscv_vcompress_tu (vfloat32m2_t maskedoff, vfloat32m2_t src, vbool16_t mask, size_t vl);
vfloat32m4_t __riscv_vcompress_tu (vfloat32m4_t maskedoff, vfloat32m4_t src, vbool8_t mask, size_t vl);
vfloat32m8_t __riscv_vcompress_tu (vfloat32m8_t maskedoff, vfloat32m8_t src, vbool4_t mask, size_t vl);
vfloat64m1_t __riscv_vcompress_tu (vfloat64m1_t maskedoff, vfloat64m1_t src, vbool64_t mask, size_t vl);
vfloat64m2_t __riscv_vcompress_tu (vfloat64m2_t maskedoff, vfloat64m2_t src, vbool32_t mask, size_t vl);
vfloat64m4_t __riscv_vcompress_tu (vfloat64m4_t maskedoff, vfloat64m4_t src, vbool16_t mask, size_t vl);
vfloat64m8_t __riscv_vcompress_tu (vfloat64m8_t maskedoff, vfloat64m8_t src, vbool8_t mask, size_t vl);
vint8mf8_t __riscv_vcompress_tu (vint8mf8_t maskedoff, vint8mf8_t src, vbool64_t mask, size_t vl);
vint8mf4_t __riscv_vcompress_tu (vint8mf4_t maskedoff, vint8mf4_t src, vbool32_t mask, size_t vl);
vint8mf2_t __riscv_vcompress_tu (vint8mf2_t maskedoff, vint8mf2_t src, vbool16_t mask, size_t vl);
vint8m1_t __riscv_vcompress_tu (vint8m1_t maskedoff, vint8m1_t src, vbool8_t mask, size_t vl);
vint8m2_t __riscv_vcompress_tu (vint8m2_t maskedoff, vint8m2_t src, vbool4_t mask, size_t vl);
vint8m4_t __riscv_vcompress_tu (vint8m4_t maskedoff, vint8m4_t src, vbool2_t mask, size_t vl);
vint8m8_t __riscv_vcompress_tu (vint8m8_t maskedoff, vint8m8_t src, vbool1_t mask, size_t vl);
vint16mf4_t __riscv_vcompress_tu (vint16mf4_t maskedoff, vint16mf4_t src, vbool64_t mask, size_t vl);
vint16mf2_t __riscv_vcompress_tu (vint16mf2_t maskedoff, vint16mf2_t src, vbool32_t mask, size_t vl);
vint16m1_t __riscv_vcompress_tu (vint16m1_t maskedoff, vint16m1_t src, vbool16_t mask, size_t vl);
vint16m2_t __riscv_vcompress_tu (vint16m2_t maskedoff, vint16m2_t src, vbool8_t mask, size_t vl);
vint16m4_t __riscv_vcompress_tu (vint16m4_t maskedoff, vint16m4_t src, vbool4_t mask, size_t vl);
vint16m8_t __riscv_vcompress_tu (vint16m8_t maskedoff, vint16m8_t src, vbool2_t mask, size_t vl);
vint32mf2_t __riscv_vcompress_tu (vint32mf2_t maskedoff, vint32mf2_t src, vbool64_t mask, size_t vl);
vint32m1_t __riscv_vcompress_tu (vint32m1_t maskedoff, vint32m1_t src, vbool32_t mask, size_t vl);
vint32m2_t __riscv_vcompress_tu (vint32m2_t maskedoff, vint32m2_t src, vbool16_t mask, size_t vl);
vint32m4_t __riscv_vcompress_tu (vint32m4_t maskedoff, vint32m4_t src, vbool8_t mask, size_t vl);
vint32m8_t __riscv_vcompress_tu (vint32m8_t maskedoff, vint32m8_t src, vbool4_t mask, size_t vl);
vint64m1_t __riscv_vcompress_tu (vint64m1_t maskedoff, vint64m1_t src, vbool64_t mask, size_t vl);
vint64m2_t __riscv_vcompress_tu (vint64m2_t maskedoff, vint64m2_t src, vbool32_t mask, size_t vl);
vint64m4_t __riscv_vcompress_tu (vint64m4_t maskedoff, vint64m4_t src, vbool16_t mask, size_t vl);
vint64m8_t __riscv_vcompress_tu (vint64m8_t maskedoff, vint64m8_t src, vbool8_t mask, size_t vl);
vuint8mf8_t __riscv_vcompress_tu (vuint8mf8_t maskedoff, vuint8mf8_t src, vbool64_t mask, size_t vl);
vuint8mf4_t __riscv_vcompress_tu (vuint8mf4_t maskedoff, vuint8mf4_t src, vbool32_t mask, size_t vl);
vuint8mf2_t __riscv_vcompress_tu (vuint8mf2_t maskedoff, vuint8mf2_t src, vbool16_t mask, size_t vl);
vuint8m1_t __riscv_vcompress_tu (vuint8m1_t maskedoff, vuint8m1_t src, vbool8_t mask, size_t vl);
vuint8m2_t __riscv_vcompress_tu (vuint8m2_t maskedoff, vuint8m2_t src, vbool4_t mask, size_t vl);
vuint8m4_t __riscv_vcompress_tu (vuint8m4_t maskedoff, vuint8m4_t src, vbool2_t mask, size_t vl);
vuint8m8_t __riscv_vcompress_tu (vuint8m8_t maskedoff, vuint8m8_t src, vbool1_t mask, size_t vl);
vuint16mf4_t __riscv_vcompress_tu (vuint16mf4_t maskedoff, vuint16mf4_t src, vbool64_t mask, size_t vl);
vuint16mf2_t __riscv_vcompress_tu (vuint16mf2_t maskedoff, vuint16mf2_t src, vbool32_t mask, size_t vl);
vuint16m1_t __riscv_vcompress_tu (vuint16m1_t maskedoff, vuint16m1_t src, vbool16_t mask, size_t vl);
vuint16m2_t __riscv_vcompress_tu (vuint16m2_t maskedoff, vuint16m2_t src, vbool8_t mask, size_t vl);
vuint16m4_t __riscv_vcompress_tu (vuint16m4_t maskedoff, vuint16m4_t src, vbool4_t mask, size_t vl);
vuint16m8_t __riscv_vcompress_tu (vuint16m8_t maskedoff, vuint16m8_t src, vbool2_t mask, size_t vl);
vuint32mf2_t __riscv_vcompress_tu (vuint32mf2_t maskedoff, vuint32mf2_t src, vbool64_t mask, size_t vl);
vuint32m1_t __riscv_vcompress_tu (vuint32m1_t maskedoff, vuint32m1_t src, vbool32_t mask, size_t vl);
vuint32m2_t __riscv_vcompress_tu (vuint32m2_t maskedoff, vuint32m2_t src, vbool16_t mask, size_t vl);
vuint32m4_t __riscv_vcompress_tu (vuint32m4_t maskedoff, vuint32m4_t src, vbool8_t mask, size_t vl);
vuint32m8_t __riscv_vcompress_tu (vuint32m8_t maskedoff, vuint32m8_t src, vbool4_t mask, size_t vl);
vuint64m1_t __riscv_vcompress_tu (vuint64m1_t maskedoff, vuint64m1_t src, vbool64_t mask, size_t vl);
vuint64m2_t __riscv_vcompress_tu (vuint64m2_t maskedoff, vuint64m2_t src, vbool32_t mask, size_t vl);
vuint64m4_t __riscv_vcompress_tu (vuint64m4_t maskedoff, vuint64m4_t src, vbool16_t mask, size_t vl);
vuint64m8_t __riscv_vcompress_tu (vuint64m8_t maskedoff, vuint64m8_t src, vbool8_t mask, size_t vl);
```

== Miscellaneous Vector Utility Intrinsics

[[policy-variant-overloadedset-vl-and-vtype]]
=== Get `vl` with specific vtype
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedset-vl-to-vlmax-with-specific-vtype]]
=== Get `VLMAX` with specific vtype
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedreinterpret-cast-conversion]]
=== Reinterpret Cast Conversion Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-lmul-extensionn]]
=== Vector LMUL Extension Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-lmul-truncation]]
=== Vector LMUL Truncation Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-initialization]]
=== Vector Initialization Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-insertion]]
=== Vector Insertion Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-extraction]]
=== Vector Extraction Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-tuple-creation]]
=== Vector Tuple Creation Intrinsics
Intrinsics here don't have a policy variant.
